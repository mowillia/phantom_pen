To date, the cover-up has worked about as well as President Donald Trump could have hoped.

Almost four years after Trump declared his campaign for the presidency, and more than 30 months since he won that office, he has successfully kept secret almost all the things he wished to keep secret. How much debt does he owe, and to whom? How much of his income derives from people who do business with the U.S. government? How much of his income derives from foreign sources? Who are his business partners, and do any of them present ethical or national-security concerns?

These basics of post-Watergate official disclosure have all been suppressed.

Incredibly, even after the delivery of Special Counsel Robert Mueller’s report, the American people still have only the haziest idea of Trump’s business connections to Russia and Russians. Do those connections cast any light on why the Russian government was so eager to have him elected president in 2016? Perhaps that information is held somewhere within the Department of Justice or the FBI, but citizens and taxpayers can only guess.

If Trump has his way, the secrecy will continue for a lot longer. In the past few days, he’s filed suit to prevent his bankers from complying with a congressional subpoena. His secretary of the Treasury has defied a never-before-questioned law and refused to surrender the president’s tax returns to the House Ways and Means Committee. His attorney general mischaracterized the Mueller report, as Mueller complained in writing, and now has operational control over the ongoing criminal prosecutions bequeathed to the Justice Department by Mueller.

Trump’s trouble is that the dike is sprouting more leaks than he has fingers with which to plug the expanding trickles. Two federal judges, one in Maryland and one in the District of Columbia, have approved lawsuits based on the U.S. Constitution’s emoluments clause demanding information about Trump’s revenues from foreign-government entities. Those lawsuits—one filed by congressional Democrats, the other by attorneys general for the state of Maryland and the District of Columbia—now proceed to two different appellate courts, the Fourth Circuit and the D.C. Circuit. At this rate, an emoluments case could reach the Supreme Court before the 2020 election.

The dispute over the president’s tax returns has not yet triggered a judicial process. Treasury Secretary Steve Mnuchin must first decide whether he will risk a contempt-of-Congress citation and shoulder personal legal risk. If the tax-return demand ends up in court, we’ll witness the unusual spectacle of a Republican administration inviting judges to reverse decades of conservative legal theory and to defy the clear letter of the law in favor of nebulous concepts of privacy. For half a century, conservative lawyers have mocked the 1965 birth-control case in which Justice William O. Douglas created a new constitutional right to privacy out of the “penumbras” formed by “emanations” of the Bill of Rights. Perhaps Douglas, like Julian Assange before him, will now transition from conservative villain to Trumpist hero.

The law very much favors Congress in the subpoena of Trump’s bankers. Congressional subpoena power extends to any subject on which Congress can constitutionally legislate, among other realms, as the Supreme Court has affirmed again and again. It’s not necessary that Congress actually have any legislation in mind, so long as it potentially could. The Supreme Court explained in 1975: “The wisdom of congressional approach or methodology is not open to judicial veto … Nor is the legitimacy of a congressional inquiry to be defined by what it produces. The very nature of the investigative function—like any research—is that it takes the searchers up some ‘blind alleys’ and into nonproductive enterprises. To be a valid legislative inquiry there need be no predictable end result.”

Meanwhile, Attorney General William Barr has just advanced a likely doomed new legal theory that a president is entitled to shut down any investigation that he feels is unfair to him: “The president does not have to sit there constitutionally and allow [a special-counsel investigation] to run its course. The president could terminate the proceeding and it would not be a corrupt intent, because he was being falsely accused.” It’s an argument for total impunity based purely on political power—and for that reason will gain no favor from either Congress or courts.

Perhaps the Trump administration hopes that it can run out the clock on the bank subpoenas and the other matters, too. But so many clocks are ticking over so many inquiries into so many areas of potential scandal. Can they all be postponed and postponed past 2020? For a president with many guilty secrets, everything turns on the ability to insert delay after delay before ultimate legal defeat. It’s not a great plan. It’s liable to go wrong, maybe catastrophically wrong. At this point, though, it’s all he’s got.



A panel of federal judges in Michigan on Thursday unanimously struck down nearly 30 of the state’s U.S. House and state legislative districts as unconstitutional. Furthermore, the court ordered special early elections for several state-Senate seats—an unusual and aggressive remedy. It’s the latest in a string of rulings that show federal courts are more open to claims that partisan gerrymandering violates the U.S. Constitution, and more willing to employ strong measures to halt it.

It will be impossible to assess the full impact of the Michigan ruling until the U.S. Supreme Court issues its ruling on a pair of partisan-gerrymandering cases that it heard in March from Maryland and North Carolina. The high court has approached partisan-gerrymandering cases cautiously, punting a Wisconsin case back to a lower court to determine whether the plaintiffs had standing.

But while the justices hesitate, partisan gerrymandering has become a major issue in lower courts. Most of these cases spring from redistricting conducted after the 2010 census. That year, Republicans dominated state legislative elections, and using their new power drew maps that heavily favored GOP candidates. They were extremely effective. In 2018, for example, Republicans held on to majorities in the Michigan legislature despite Democrats winning the popular vote in legislative races. (Republicans note that Democrats also suffer from having their voters heavily concentrated in urban areas.)

Courts have long held that racial gerrymandering is unconstitutional, but they’ve been reluctant to rule against partisan gerrymandering, for fear of meddling in political matters. Where majority parties hold redistricting power, they have generally been given wide leeway to draw maps as they see fit. In the North Carolina gerrymandering case, Republicans who drew the maps have explained that they turned to partisanship as a method of drawing maps for fear of breaking the law on racial gerrymanders.

But new technologies have shifted the playing field. First, they allowed those doing redistricting to draw ever more ruthlessly efficient partisan gerrymanders. Second, they have allowed critics of those maps to use elaborate mathematical formulas to try to convince judges that partisan gerrymandering can be determined with more than mere subjectivity. Among the leading metrics are the “efficiency gap,” a method of calculating how many votes are wasted, and simulations that demonstrate the implausibility of existing maps.

Both of those metrics factored into the Michigan case. The plaintiffs also followed in the path of plaintiffs in the Maryland and North Carolina cases, arguing that the Michigan maps violated their First Amendment and Fourteenth Amendment rights. In the former case, they say their right to free association (in this case, with other Democrats) has been violated; in the latter, they say they are being governed in a way that violates their right to equal protection. The judges on the panel, including two Bill Clinton appointees and one George H. W. Bush appointee, agreed unanimously.

“[Republican mapmakers’] primary goal was to draw maps that advantaged Republicans, disadvantaged Democrats, and ensured that Republicans could enjoy durable majorities in Michigan’s congressional delegation and in both chambers of the Michigan legislature for the entire decade,” Judge Eric L. Clay, a circuit-court judge, wrote in the opinion. “The expert evidence, documentary evidence, and testimony from map-drawers, legislators, and political operatives undeniably points to this conclusion.”

This is not the first case in which a federal court has concluded that an unconstitutional partisan gerrymander exists, following the Wisconsin, Maryland, and North Carolina cases. But it is notable because of the order of early special elections. Courts have ordered new maps drawn, but have mostly avoided ordering new elections. A rare example came in a North Carolina racial-gerrymandering case, called Covington, in 2016, but the U.S. Supreme Court, while upholding their judgment, ordered them to reconsider the special election. The judges ultimately decided against it.

But in Michigan, the court considered the Supreme Court’s test for when a new election is merited in Covington and decided to order new elections for some legislative seats.

There’s a good chance that the Supreme Court will stay the Michigan ruling pending its decision on the Maryland and North Carolina cases, which are expected by the end of this term in June, Rick Hasen, an election-law expert at UC Irvine, told me. The Supreme Court’s conservative majority is expected to be skeptical of partisan-gerrymandering claims. But if the justices end up accepting either the First or Fourteenth Amendment rationales, the Michigan ruling would quickly take effect.

Time is of the essence in the outstanding partisan-gerrymandering cases. There will be a new census next year, and with it new redistricting around the country, so the window to correct any current injustices is closing.

But in Michigan, at least, there won’t be partisan gerrymanders coming out of the legislature after the 2020 census—no matter which party ends up in control in Lansing. In November, voters overwhelmingly passed a constitutional amendment that will take redistricting out of the hands of the legislature and grant it to a new, nonpartisan, independent commission.



Stockton, California, is inland, hot, 20 percent poor, and crime-ridden. The top nine employers are schools, hospitals, the government, and Amazon, which has two giant fulfillment centers in the city. No. 10 is O’Reilly Auto Parts. It’s a good place to leave, if you can. As ever in places like this, the high schools are full of trouble and promise, and one of them—Bear Creek High School—has lately been in the news because of two of its students: Bailey Kirkeby, a junior, and Caitlin Fink, a senior.

They are thoroughly creatures of the modern age, but what impresses me about both of them is how deeply they also exemplify some of the most enduring traits of girlhood. They are hopeful, concerned about fairness, foursquare on the side of the underdog, and drenched in a romantic vision of life, in which sorrows can be easily overcome and infinite happiness is always on the horizon. Like every girl since the beginning of history—and surely, to the last syllable of recorded time—they are subjects of great interest to people who don’t mean them well. Let’s get to know them a bit.

Bailey, who is 17 years old, has long wavy hair, glasses, a heavy course load, and a raft of positions at the school newspaper, where she is the managing editor and news editor, as well as an entertainment columnist and a staff writer. Her bio posted on the paper’s website suggests that she is the kind of girl to put your money on. “With junior year testing my limits every waking moment, I am delighted to partake in my first year of journalism and relieve some of my stress through the pleasures of writing and editing,” she reports. “I joined journalism because I have a questionable obsession with the New York Times and am fascinated by the mechanics of creating a newspaper, which I get to experience by being part of the Bruin Voice staff.” One ticket out of Stockton, please.

Caitlin—this fact hits you with a hammer’s force, and there’s no point burying it—is a beautiful girl. She likes Napoleon Dynamite and The Ellen DeGeneres Show and the music of Blood on the Dance Floor. “I’m a lovey-dovey, old-school romantic,” Caitlin has said of herself, and also a bit of a pushover: “I won’t even say anything if people cut in front of me in line.”

Recently, Caitlin has been in a predicament that sparked Bailey’s attention and also her sympathy. In need of money, Caitlin began working in pornography, which has solved her short-term financial problems, but which has also led to people “saying things” about her at school. It occurred to the staff of the Bruin Voice that a story that treated Caitlin like any other inspirational student—one who had faced and overcome obstacles—a piece that allowed her to tell her side of the story, would be helpful to Caitlin and good for the paper.

Because Bailey had a class with Caitlin, she seemed the obvious choice to write it. She pitched the idea to the school newspaper’s faculty adviser, Katherine Duffel, who approved it, and soon the girl was working on a 1,000-word article about Caitlin. However, things quickly went sideways.

The superintendent of the Lodi School District heard about the article, a mysterious turn of events, as there are almost 30,000 students in the busy and troubled district, and at that point only a handful of them knew about the article. The superintendent demanded to review it before publication, and Duffel refused. “It’s just the word pornography and where people’s minds go,” she told The New York Times. “I think they lose their minds, quite frankly, when they hear that word.”

At this point, an array of powerful adults sprang into action to ensure that the students at Caitlin’s school could know all about her work in porn, and how to find it. The Student Press Law Center referred Duffel and Bailey to an attorney named Matthew Cate, who took on the case pro bono.* Major news outlets, including the Times, covered the story in lavish detail, conveying a tone of moral neutrality toward the matter of a high-school girl making porn, and of quiet but obvious disapproval toward the infringement of the student journalists’ First Amendment rights. Cate read the article, assured the district that despite its concerns (among them, that students under 18 had viewed pornography in the preparation of the piece) it did not violate the state’s education code, and the article was published on May 3.

“Throughout their high school years, students are often told to follow their dreams and pursue what they love,” the piece begins, and it presents Caitlin as someone who is doing just that. The tone is that of a Seventeen feature circa 1964, the kind that told girls what it’s like to be a stewardess or a fashion model—here is something fun, and even glamorous, that any pretty girl, from any small town, can do if she puts her mind to it. “I travel to San Francisco a lot, and I don’t have to pay anything, because someone pays for the expenses,” Caitlin says. “I’ve been trying new things, going out of my comfort zone, and meeting new people.”

The uplifting tone belies much of the reported information about Caitlin. Apparently Caitlin—who later told media outlets that she is “estranged” from her family—moved out on New Year’s Eve and is now paying $300 a month in room and board to live at a friend’s house. It’s not clear whether she began doing porn before or after this event, but it’s clear that the work—in addition to a dishwashing job—helps her pay for the room and other expenses.

She has been “verified” on Pornhub, meaning that it’s possible for her to get paid for the videos she’s uploaded to the site, but at the time of the interview, her videos had not attracted enough views to earn her any money. One recent disappointment was being sent away from her first professional video shoot—arranged by her new “agent”—when the producers saw acne on her body and decided that they no longer wanted her.

So now that you have the facts of the case, here’s a question for you: What happened to us? When did we lose the ability to interpret the signs of a girl in bad trouble?

Feminists have wrestled with their relationship to pornography ever since the early ’70s, when the Rimbaud-loving Jersey girl Andrea Dworkin joined forces with America’s most lighthearted legal scholar, Catharine MacKinnon, and created sex-negative feminism. Their arguments about the nexus between violence against women and hard-core pornography were powerful, but the whole enterprise was a hard sell in the midst of the sexual revolution.

“No woman needs intercourse; few women escape it,” Dworkin said—what happened to Rimbaud?—from deep within her overalls, and she lost the crowd. MacKinnon’s legal argument depended on pornography’s potential violation of the equal-protection clause, a delicate proposition, and one she was advancing at a time when free speech was at the very center of the youth movement. The women were raising important questions, but in 1988 the World Wide Web arrived, blotting out the sun and giving us porn without end, porn as it is now and ever shall be, porn beamed down from the starry heavens into the world’s bedrooms and bathrooms, buses and fast-food joints, church parking lots and prison cells. Porn surrounding you in the room where you sit reading this article—all you have to do is set your phone to pick up the signal.

“Not half a dozen men have ever been able to keep the whole equation of pictures in their head,” Cecilia Brady tells us in The Last Tycoon, and the same is true of internet porn. When Christ arrived, there was plenty of warning (“Who hath ascended up into heaven, or descended?”), but porn just crashed down, set its own terms, and left us on our own. It was a gyre that kept widening, and everything fell into it and disappeared, until porn was the truth and private behavior was the lie. The curtain stirring in the breeze fell into the gyre, and the missed class, and the hotel room. The shirttails tucked rapidly into chinos, the skirt quickly zippered fell into it. These things still existed, of course, but they were mediated by porn, as all sex was mediated by it—a performance of it, or a rejection of it, or an attempt to erase certain images from it.

Children learn about the mechanics of sex—or rather, that mechanics is the whole of sex—by watching women who may have been blood-tested and “verified” professionals, or who may have been so impoverished and desperate that they would have done literally anything for cash or drugs. Everyone is welcomed into this vast emporium of sex, and although the party line is that consumers bring their own desires to it and simply find the porn that suits them, the influence runs in the other direction.“If you’re with somebody for the first time,” a sex researcher at Indiana University helpfully tells her students, “don’t choke them, don’t ejaculate on their face, don’t try to have anal sex with them. These are all things that are just unlikely to go over well.”

Certainly we can reserve judgment about private sexual behavior, but we can’t pretend that the things people expect to do in bed, or expect partners to do in bed, have not been hugely—almost entirely, by this point—influenced by online porn. No wonder so much sex between young people takes place behind a thick velvet curtain of alcohol—who wouldn’t want to be under anesthesia for some of these exercises? Culture is progressive and cumulative, and so is porn, restlessly seeking and crossing the next boundary, and thereby making whatever came before it seem tame and ordinary.

The problem is that there are some very old human impulses that must now contend with porn. One of them is the tendency of deeply troubled teenage girls to act out sexually as a kind of distress signal, an attempt to get the attention of adults who may not be getting the message that they’re in a crisis. Working this out within the closed world of a high school was painful, and almost always contributed to suffering, but it was something that could be transcended—eventually everyone moves on and the past settles into place.

But working out these impulses within the pitiless economy of the vast, global pornography industry is an entirely different proposition. Whenever a third party stands to profit from the sexual choices of a woman, a door is opened into another world, far beyond the high school, the disappointed parents, the town where she lives. It’s natural that this would become the venue for these troubled girls; porn is the main determinant of high-school kids’ sexual imaginings. Girls who feel uncomfortable or shamed about their body are deeply drawn to it. “I liked the attention I got,” Caitlin says of her first foray into selling pictures online; she liked “being called beautiful. I enjoyed it because it made me feel good about myself.”

The idea, vigorously maintained by a certain kind of young porn star and by her feminist defenders, is that it is entirely possible to be an adult performer yet in private life be someone who is perhaps modest, perhaps—as Caitlin describes herself—an “old-fashioned romantic.” It’s hard to imagine that it’s possible. I suppose the model for this might be marriage, in which a woman might be extremely modest and careful in her public dealings, but in bed with her husband is a fully sexual being, her desires as carnal and adventurous as anyone else’s. But it seems to me that a troubled teenager, desperate to be called beautiful, will have her sense of self deeply affected by work in that industry, which will quickly seek to put her in ever more extreme forms of on-camera behavior.

What has happened is that within a few years of porn’s arrival, the country quickly learned what it was dealing with—something it had no power to control, something it couldn’t even keep small children from encountering—and so modern life simply adjusted itself around the new, imperial leader. The left decided to champion porn in a variety of ways, beginning with reconceiving the women who work in it as fully liberated, empowered feminists, as though every woman you see in porn is driving carpool and making the weekly Costco run. Sure, there are women in porn who do those things. Do you know what percent of the vast, global porn industry these self-actualized porn workers represent? Not a large one.

The right understands porn as a thing for sale, and so has a grudging respect for it. “It’s Trump,” the porn star Eva Lovia told Fortune at the 2016 AVN Awards when she was asked whom she was supporting for president, “because I like my money. I’m sorry! I’m sorry! I want to keep it.” The right destroyed the one force capable of challenging porn’s ubiquity: social conservatism. It gleefully elected a sleazeball whose personal history is that of a man with contempt for the ideas of personal responsibility and duty to others that were once central to social conservatism.

The right sold out social conservatism for lower taxes and “The Snake.” Our shadow first lady, Stormy Daniels, enacts an endless performance of Fatal Attraction; Donald Trump calls her “Horseface” on Twitter, and her own sleazeball lawyer—who was somehow briefly considered a potential Democratic candidate for president—is currently out on $300,000 bail in a serious extortion case. The president calls a much-loved, exceedingly minor member of the British royal family “nasty,” and his own beautiful daughter “Baby”—and there isn’t anything left of the social conservatism of yesteryear but money, and selling any valuable commodity we have remaining, from our natural resources to our international reputation to our young girls.

The only person questioning any of these notions seems to be Caitlin herself, who labors under the delusion that she’s not living on a darkling plain. “The only hard thing so far is making sure I have enough money,” she told Bailey, in the testing, hopeful way of a teenager trying to wheedle something out of adults. Maybe she had gained—from Napoleon Dynamite and Ellen—the impression that she lives in a society where the center holds, and where promising girls are not left to drift so far beyond the shoreline that no one feels impelled to consider a rescue. “Other than that”—here she is, the daughter that you and I made together, letting us know how she’s doing—“I’ve honestly been doing really good with myself.”

*This article originally stated that the Student Press Law Center referred the school to Matthew Cate. In fact, it referred Duffel and Bailey to Cate.



The Trump administration hasn’t actually released its Middle East peace plan. It’s so closely held that the Palestinians who are to be its object have not been invited into discussions of the subject. But the whispers of those who have been consulted suggest the possibility that the sequencing will commence with economic incentives for Palestinian acceptance of eventual subjugation into the state of Israel—a “one-state solution,” in diplomatic parlance.

If that is the White House senior adviser Jared Kushner’s approach, it would represent a reversal of the administration’s policy, which has until now been focused on imposing economic hardship on Palestinians in order to compel their acceptance of what Kushner terms “facts.”

The secrecy in which the Kushner plan is shrouded has not prevented the president from publicizing the plan as the “deal of the century.” The first stage is to be a “Peace for Prosperity” meeting in Bahrain, at which the administration expects Gulf states to provide $68 billion in investment to the Palestinians, Egypt, Jordan, and Lebanon to ease acceptance for subsequent political “facts”—the imposition of unwelcome political outcomes such as moving the U.S. embassy to Jerusalem.

Speaking to The New York Times, Middle East experts were derisory about the plan’s prospects. Tamara Cofman Wittes believes offering to buy Palestinian acceptance of an unstated political outcome “may sour the environment for any political plan.” Aaron David Miller argued that this isn’t a novel approach, the paper wrote: “If the United States could have bought peace in the Middle East through economic development, he said, it would have done so.” Robert Satloff concluded that “the only way to protect the long-term viability of the best aspects of the Kushner plan is to kill the plan.”

Nor does the foremost expert on prospects for Middle East peace, Jordan’s King Abdullah, consider it viable. His view is that “the only acceptable peace will be a comprehensive and lasting peace based on a two-state solution, leading to an independent Palestinian state on 4 June 1967 lines with East Jerusalem as its capital.” That is evidently not the rabbit Kushner intends to pull out of his hat.

Kushner seems to think the parties most directly involved in the Israeli-Palestinian dispute these 70 years fail to understand what they’re talking about. “If you say ‘two states,’ it means one thing to the Israelis, it means one thing to Palestinians, and we said, ‘Let’s just not say it,’” Kushner recently revealed. Kushner’s magic trick apparently relies on a sleight of hand that will use prosperity as a shiny object to distract Palestinians while their political aspirations are swept away.

The Trump administration’s Middle East peace plan sounds more like Chinese foreign policy than it does American foreign policy. American policy invokes the principle our Founders enshrined in our culture: that people have inherent rights and loan them in limited ways to governments for agreed purposes. We fail often to uphold this principle, but it is a genuine departure for an American administration not to even acknowledge it.

Moreover, other nations are less wary of our power because of our values. By tapping into the universal aspiration for human dignity and political liberty, American policy has been cheaper and easier to advance, because it works with the grain of positive political change. Our successes are seen as the advancement of a cause, not just the advancement of our interests.

China’s policy, domestic and foreign, is based on the premise that the government will create conditions for prosperity, and in return people must forsake political liberty. They prioritize “an emphasis on economic rights over individual political rights in the development of global norms,” as Michael Swaine has argued, and want an international “community of common destiny for mankind” on Chinese terms.

China would erase the truths we hold to be self-evident—that all people are endowed by our Creator with inalienable rights—by betting that their citizens, the citizens of developing countries, and even the cosseted rich of the liberal West will accept incursions on their liberty in order to have greater prosperity or affordability.

China’s defense minister, General Wei Fenghe, outright said so at the International Institute for Strategic Studies’ Shangri-la Dialogue in Singapore last weekend, justifying the forcible internment of more than a million Uighur people by arguing that “the living standard of the local people has improved.”

Jared Kushner and the rest of the Trump administration appear deaf to Benjamin Franklin’s warning that “those who would give up essential liberty, to purchase a little temporary safety, deserve neither liberty nor safety.” But the Palestinians, Jordanians, and others with hard experience of difficult trade-offs can hear it, which is why the administration’s Middle East peace plan is both dead on arrival and bad American foreign policy.

As the Trump administration displays the basest instincts of mercantilist, illiberal politics, we Americans and others should still be able to hear the sound of policy that appeals to the human spirit, and raise our voices to strengthen the sound. We should work to ensure, as Ralph Waldo Emerson wrote in his journals, that “what you are stands over you the while, & thunders, so that I cannot hear what you say to the contrary.” Expecting people to forgo their aspiration for human dignity and political representation is a message contrary to American values, and ought to be contrary to American foreign policy.



Tens of millions of people have been forced to flee their home country in recent years to escape war, famine, deadly persecution, or natural disaster. These refugees spark political controversy wherever they arrive in large numbers. For that reason, governments in Europe, North America, and Oceania have differed on how many refugees they are willing to resettle. Even Angela Merkel, who helped make Germany the Western country with the biggest population of recent refugees, found that the public’s openness was quickly exhausted.

Countless thousands suffer. They drown while trying to cross the Mediterranean Sea. They die in the Sahara desert. They die trying to cross into Mexico. They are kidnapped and sold into slavery. They die at home because they are too poor to attempt escape. With no foreseeable end to the flow of refugees determined to reach wealthy countries, where voters are growing less rather than more willing to welcome them, more tragedy is assured. And liberal humanitarians concede that their reform efforts are not working.

“The UN Global Compact on Refugees … failed to deliver meaningful change,” Amnesty International lamented last year. The final text of the compact, which aimed to improve the international community’s response to mass forcible displacement, was notably unambitious: a shameful blueprint for responsibility shirking. The compact will not change the situation for Rohingya refugees newly arrived in Bangladesh, or a generation of Somali youths born in refugee camps in Kenya, or refugees stuck in illegal and devastating limbo on the island of Nauru for the past five years. For sub-Saharan Africa, now hosting 31 percent of the global refugee population, it will provide no relief.

What is to be done?

The political scientist Eric Kaufmann argues for a controversial alternative in his recently published book, Whiteshift, a researched inquiry into how migration and demographic change are affecting politics and culture in Western societies.

Rather than settling refugees in Western countries to live alongside citizens, who will tolerate a population far smaller than the total number of people in danger, he favors building permanent, closed refugee camps on Western soil that accommodate anyone who wants to come. Refugees would have the right to move to another refugee camp or to return to their home country, but would not have the right to enter the host country. Governments would draw a bright line distinguishing refugees from migrants.

Some critics liken permanent camps to putting refugees in prison, and find the notion of segregating refugees in such places to be morally noxious. Others point to the dismal conditions in many camps past and present, and doubt that future camps would be any better. Even Ireland’s comparatively generous Direct Provision program, in which refugees are semi-segregated in relatively high-quality housing, may immiserate residents by trapping them in limbo rather than letting them begin a new life in a new community, as Masha Gessen illustrates in a perhaps overcritical dispatch in The New Yorker.

Still, the status quo is so horrific that Kaufmann’s alternative merits a hearing.

The core of the problem as Kaufmann sees it:

Paradoxically, pressure to widen the rights of asylum seekers inside Europe makes it harder to fulfill the mission of getting people to safety. Why? Because if countries believe admitting refugees is the first step to granting permanent settlement, they will be more reluctant to allow them in. Claimants in the West have their cases judged increasingly harshly due to domestic political pressure to limit the number accepted for settlement. Those whose cases fail and cannot escape lack the option to remain safely in a high-quality facility. It’s estimated that thousands of genuine refugees are returned to countries where they risk being persecuted or killed.

Kaufmann proposes to eliminate that disincentive to provide refuge.

“Western publics are more likely to accept the financial burden of housing refugees on a long-term basis than accepting them as permanent settlers because they care more about the cultural impact of refugee settlement than the economic costs,” he argues. Absent cultural fears, burden-sharing among rich nations will be easier, he writes, as “countries will not be asked to alter their ethnic composition against their inhabitants’ wishes—only to contribute funds and build facilities.”

In fact, he claims, his approach would allow the world “to absorb any number of refugees without discriminating on the basis of wealth, fitness to travel and risk appetite,” as effectively happens now. “Nobody dies in transit or gets attacked or enslaved en route.” And Western governments would have less need for gatekeeping bureaucrats. “This will offer refuge, but not settlement,” he notes, “so only those genuinely fearing for their lives will remain. There would be no need to engage in the impossible task of sorting genuine refugees from economic migrants.”

Why should long-term refugee camps be unthinkable in the West, he asks, when they are already a reality in many countries that border on conflict zones? “Why is a secure camp in the West an affront to human rights while one in Turkey or Libya is not?” (I’d add: If both are an affront to human rights, isn’t it still possible that refugees currently consigned to the camps in unstable countries would be better off if the West offered a more humane version of those camps?)

In his telling, “liberal activists and judges have strained to interpret international human rights law as generously as possible to the point where someone who arrives in Europe has a path to citizenship,” but doing so only guarantees that severe limits will be imposed on the number permitted to arrive. A lucky few will be treated better at the cost of mortal danger for many more.

Kaufmann concludes that hosting refugees in the West is a good litmus test of whether liberals are more interested in helping those in need or “making the symbolic gesture of calling for more settlement—which is guaranteed to result in doors being closed.” If the latter, they will label closed facilities prisons, he writes, “agitate to have camp residents resettled and call for facilities to be closed … We’ll revert to the status quo, in which many who flee war are sent back to die, unlucky migrants drown at sea or are preyed upon by criminals, the majority languish in underfunded camps and a small group of better-off risk-takers get lucky.”

He goes on to describe what he sees as the best version of the approach he favors: “spacious permanent migrant centers across the full range of EU countries, alongside free transportation from conflict areas,” cutting deaths at sea, expanding refuge, and improving overall conditions among migrant facilities.

“The optimal scenario is one in which every refugee can flee a conflict zone and be protected, housed, clothed, educated, and fed, receiving proper medical care,” he writes. “There should be recreational facilities and, ideally, an opportunity to work … This should be paid for by the international community, through either charities or contributions from wealthier countries.”

This is, he concludes, where the attention of Western social-justice campaigners should be focused. “The current approach is dangerous. Erasing the line between refuge and settlement makes it more likely countries will bar the door the way they did in 1939.” Would the alternative he proposes end up being better or worse?

For a critique of Kaufmann’s proposal, I contacted the Danish Refugee Council, an international humanitarian organization with 7,000 staffers and 8,000 volunteers who work in conflict areas, along transit routes, and in countries where refugees settle. Its stated aim: “a dignified life for all displaced.” Its stated methods: “In cooperation with local communities, we strive for responsible and sustainable solutions. We work toward successful integration and—whenever possible—for the fulfillment of the wish to return home.”

In response to a summary of Kaufmann’s proposal almost identical to the one that began this article, the organization forwarded the following comments, attributing them to Solveig Als, a policy adviser under the external-relations secretariat.

She began by noting that “unfortunately, Kaufmann is not alone in his belief that––as opposed to safeguarding safety, dignity and well-being of people affected by conflict––reducing rights and containing refugees either in Europe or outside Europe is the only way forward to avoid further fueling right-wing populism,” adding that “this is also true for current policy developments at the EU level, where containment policies and deterrence measures are reflected across asylum and migration policy proposals under the Common European Asylum Reform.”

Still, she argued, Kaufmann’s policy proposal is at odds with international norms that nearly 200 countries have embraced in refugee-policy negotiations:

First and foremost, an encampment policy—which appears as the cornerstone and key premise of Kaufmann’s proposal—is in direct contradiction to the new international consensus on the need to move away from containment, care and maintenance towards self-reliance and dignified lives for refugee families.

This shift towards self-reliance and out-of-camp policy is core to the recently adopted Global Compact for Refugees, which was developed over 18 months through intensive consultations and discussions among UN Member States, experts, civil society and refugees, and approved by overwhelming majority (181 UN Member States) in December last year. This remarkable political consensus that refugees and host communities are better off when refugees become included and productive members of society stands in stark contrast to the author’s hypothesis that segregation is a political necessity.

She went on to offer three additional critiques. First, right now, “long-term closed refugee camps is not the general trend in countries bordering conflicts.”

Second, countries have shifted toward housing refugees outside of camps, because evidence suggests that this helps them succeed if and when they return home:

Skilled, knowledgeable, empowered individuals and families stand a much better chance to successfully reintegrate. Returnees, especially after years and sometimes decades in displacement, do not merely have the task of resuming their lives prior to displacement; they must reinvent their lives … Old skills and livelihood strategies may no longer apply. Trauma and loss may well be associated with the return. Hence, it is important to promote a high quality of asylum where displaced persons are not merely offered ‘care & maintenance,’ but are offered opportunities to build capacities and develop skills.

Third, she offered, the Danish Refugee Council is concerned about the detention and force that the proposed “closed camp” approach is likely to entail:

While Kauffmann [sic] describes the camps as ideally spacious spaces with recreational activities and potentially opportunities to work, all evidence and experience with closed facilities for asylum seekers and refugees demonstrate that such an out-of-sight policy contributes to creating zones of exception in which violations of fundamental rights are more likely to occur. No real-life evidence suggests that pro-longed encampment is sustainable. Neither for refugees who will be forced to live in uncertainty and limbo, nor for hosting countries which will experience the effects of frustrated refugee communities.

These are formidable objections, and I sent them to Kaufmann hoping for a rebuttal. On the matter of European Union policy, he noted that while it is moving in the direction he proposes in his book, “it is important to note that containment is currently being offshored to Turkey and Libya, which do not maintain Western standards of care, and in Libya’s case even endanger the safety of the refugees. So this is sub-optimal from a human security standpoint.” He believes that EU countries ought to be administering those camps within their borders.

As for the rest, he stated that the position of the international human-rights community would benefit a minority of people needing refuge at the expense of the most needy:

I accept that containment is not ideal in terms of the lives of refugees. But many people in the world are also living lives that aren’t what I would wish for. Malnutrition, corruption, gang violence and other scourges blight their lives.

We have an obligation to keep people safe, healthy and educated, but, cruel as this sounds, not to provide them with a western-standard life. I still believe in holding out hope, which is why I recommend that countries select, by lottery, a fixed number of refugees for settlement each year. This should not be treated as a legal obligation, however.

Indeed, containment is the only way we can win acceptance among a wider range of countries for a refugee programme that pays to move people to safety in a secure way (not on flimsy rafts) in unlimited numbers. If another wave of refugees tries to reach Europe next time, it is guaranteed they will be turned away. What then? I would rather all people be safe than for a lucky few to settle while the least mobile suffer or die. The perfect is the enemy of the good.

It may be, if Steven Pinker is right, that the number of civil wars continues to decline. If numbers are moderate, I’d support the idea of allowing refugees to live and work in a society, so long as there is public support for the programme. The issue, however, is that if this comes to mimic a western life, large numbers of others will arrive, overwhelming the system. Perhaps a numerical cap could allow it to operate. For me, the key principle is to save an unlimited number of lives. Blurring the line between refuge and settlement poses a great danger to that principle, much as it did in World War II.

After pondering this exchange, I felt more informed about the risks and trade-offs of a Western push for a greatly expanded system of closed camps versus efforts to resettle more refugees in host nations. But I reached no definitive judgment on which approach would turn out better.

Adherents of the Kaufmann approach can’t be sure that deteriorating conditions in closed camps would be met with embarrassment and reform rather than the vilification of the people trapped inside. And those who believe the Danish Refugee Council model is best suited to today’s circumstances would do well to imagine a possible future in which exponentially more people seek refuge, whether due to rising sea levels or crop failures or a global pandemic disease or a regional, or even world, war. What system would best serve the world in those circumstances, and how, if at all, should the answer to that question inform the system we operate today? 

What Kaufmann and the Danish Refugee Council have in common is a determination to draw attention to an ongoing crisis, largely out of sight, that is costing the lives of innocents right now, even in a world with plenty of space and resources to protect them all.



James Carroll, the author of this month’s Atlantic’s cover story, “Abolish the Priesthood,” is famous in certain Catholic circles for his bitter denunciations of the Church. To the well-documented renunciation of his own priesthood years ago, Carroll now adds the claim that, by its very nature, the Catholic priesthood is inextricably tied to clericalism (all priests being clerics, of course), and thus to “its cult of secrecy, its theological misogyny, its sexual repressiveness, and its hierarchical power based on threats of a doom-laden afterlife.” He also argues that in its more pristine first centuries, Christianity had no priesthood and no hierarchy, and so was far more egalitarian.

Reading Carroll, I find not so much a hatred for the priesthood or the Church more generally, but rather a deep misunderstanding of Catholicism, which has resulted in a conflicted love throughout his public life. As a priest myself, I can only hope that he will one day find some peace and reconciliation.

Twenty years after James Carroll knelt before the altar at St. Paul the Apostle Church on West 59th Street in New York City and received the laying-on of hands from an archbishop, making him a priest, I knelt in the same spot and received the laying-on of hands from a cardinal.

Carroll describes that moment in his essay:

When I became a priest, I placed my hands between the hands of the bishops ordaining me—a feudal gesture derived from the vassal to his lord … I gave my loyalty to him, not to a set of principles or ideals, or even to the Church.

This, like much else in his essay, is true, but it is not quite the whole truth. What Carroll does not relate are two of the vows he was asked to affirm prior to placing his hands in those of the bishop. They were identical to the vows I made in 1989.  The ceremonial reads:

Do you resolve to exercise the ministry of the word worthily, preaching the Gospel and teaching the Catholic faith?

Do you resolve to celebrate faithfully and reverently, in accord with the Church’s tradition, the mysteries of Christ, especially the sacrifice of the Eucharist and the sacrament of Reconciliation, for the glory of God and the sanctification of the Christian people?

This is hardly the commitment of a vassal to his lord. There is much in these words that reflects the commitment we were expected to make to the Church and indispensability of the priesthood to it. But every priest’s experience is different and, in some evident ways, Carroll reflects the experience of many priests who passed through the 1960s and ’70s whose high expectations of the Church, of themselves, of their parents, and even of God failed because their presumptions and definitions were flawed from the outset.

This is evident throughout Carroll’s essay, nowhere more clearly than in how he describes his understanding and expectations of the Second Vatican Council. He sees it almost entirely in terms of discontinuity with the past. This went far beyond the “jettisoning of the Latin Mass.” He also saw the hope that Vatican II could offer a replacement of the hierarchy with some kind of liberal democracy.

I cannot understand how anyone who has actually read the documents of Vatican II could have come to such conclusions. In fact, Carroll’s entire idea of Christianity more closely resembles some of the more fundamentalist tendencies and enthusiastic movements that have periodically reared their heads in the Christian world throughout history than it does the actual reforms of Vatican II.

In Carroll’s version of history there once existed a purer, more original form of Christianity, one that had no priesthood, had no authoritative hierarchy, and was free of “misogyny” (as he defines it) and sexual oppression. But then that mean bishop, Augustine, appeared on the scene centuries later, bringing with him the notion of self-denial as the way to happiness.

Can it be that Carroll does not recall Jesus’s demand to deny oneself, to lose one’s life in order to find it? Or that he has never read the Acts of the Apostles and observed in it the emergence of the gradations of ministry from the apostles, who then extended outward their authority to collaborators in their mission, and instituted the diaconate under their direction? And while Carroll shows knowledge of extra-biblical observations of Christianity in the writings of Josephus in the first century (who wrote, as Carroll rightly notes, “around the same time that the Gospels were taking form”), how could he have missed the 11 letters written by Ignatius of Antioch to a wide diversity of Christian churches throughout the Mediterranean while on his way to martyrdom in Rome?

Those letters described an already extant, highly ordered, and intricate hierarchy with a threefold ranking of priesthood (deacon, priest or presbyter, and bishop) based on a monarchical episcopate. Moreover, long before Constantine, Justin Martyr offered a detailed description of a Eucharistic celebration written in about 153 A.D., which is a highly ordered liturgy replete with a male priest presider.

Carroll makes several references to the historic turn that took place at the Second Vatican Council with regard to the Jewish people. This included the revision of the liturgy to reflect a new sensitivity and a deepened understanding of the integrity of the abiding Jewish covenant and the Jewish people, especially in light of the Holocaust.

This awareness on Carroll’s part makes it all the more odd that he demonstrates no appreciation for the deeply Jewish nature of both Catholic worship and its priestly hierarchy. Indeed, if Carroll were serious and consistent, he would attack with the same ferocity the pre-Christian Jewish temple hierarchy, with its all-male priesthood, as something that should also have been abolished. Of course, the Catholic Church and its ministerial priesthood have undergone change and development over the centuries. Retaining the substance of the Catholic faith, the Church offers new ways of expressing that faith. In the very speech that opened the Second Vatican Council on October 11, 1962, Pope John XXIII echoed the founder of the Paulist Fathers, Father Isaac Thomas Hecker, who wrote of speaking “old truths in new forms.” “The substance of the ancient doctrine,” the pope said, “is one thing, and the way in which it is presented is another.”

This, however, is not the agenda of Carroll and a host of others of his Vatican II generation. Carroll wants to jettison not “the imperium that took [the Church] captive 1700 years ago,” but the Church itself.  Though he claims to want to recover the Gospels, Carroll is really about the business of proposing a new Gospel, one quite unrelated to the Gospel proclaimed by Christ.

No doubt, aspects of Christianity can be expressed and preserved outside of Church institutions, “partly written, partly unwritten, partly the interpretation, partly the supplement of Scripture, partly preserved in intellectual expressions, partly latent in the spirit and temper of Christians; poured to and fro in closets and upon the housetops, in liturgies, in controversial works, in obscure fragments, in sermons, in popular prejudices, in local customs,” as John Henry Newman said.  This leaves ample room for variety, debate, and dialogue. Yet for all that, the Gospel has always required an institutional apparatus, without which it simply won’t be able to perdure throughout history.

In Carroll’s new Church, he writes, “the exiles themselves will become the core,” but of course, there will be no core. Or if there is one, how long will it be before this core becomes the new “central direction” from which he dissents? The perpetual need to remake the core would result in a religious version of Groundhog Day.

In this regard, what Carroll describes as “the virtues of the Catholic faith” are especially revealing. He notes that the Church is a worldwide community of more than 1 billion, the only institution that transcends borders and time; that there are 200,000 Catholic schools and 40,000 Catholic hospitals; and that the Church is the largest nongovernmental organization and a “tribunal of justice.”   

These are observations about the Church’s institutional nature, and they reveal the residue of Carroll’s Catholicity, which is itself rooted in the fundamental dogma—yes, dogma—fought over and debated by bishops and settled by a council of bishops at Nicaea. They held that Jesus is both God and Man; that the Word who was in the beginning with God became flesh and dwelt among us.

By all means, renew the priesthood—it is sorely and embarrassingly in need of a radical renewal. But to call for its wholesale abolition is to call for the abolition of the Church itself. The Church cannot be reduced to the clergy, to be sure, but Catholicism is not the Church without its priests. James Carroll may want to bring a new Church into being. His won’t be the first such effort. But let’s be clear that his priestless Church is simply not Catholic.



Ron Chernow, the best-selling biographer and historian, has agreed to deliver the after-dinner speech at this year’s White House Correspondents’ Dinner, to be held Saturday night at the Washington Hilton. If we were to list the potential victims of our present era of post-humor comedy, his name would be near the top.

The WHCD is the event the Washington press corps throws every year to celebrate the Washington press corps. (If we don’t do it, it won’t get done.) It is best understood as a provincial trade meeting—a few hundred people in the same line of work crowd together in the poorly ventilated ballroom of a second-tier hotel to hand one another awards over plates of undercooked chicken. What separates the correspondents’ dinner from, say, the annual awards dinner of the Greater Tri-County Regional Conference of Waste Removal Technicians is that, sometime in the 1990s, people from outside the trade began to take an interest in the event.

At its height a few years ago, even top-chop movie stars (George Clooney, Nicole Kidman) accepted invitations to attend the WHCD. The president used to come. And after dinner, with tummies full and worries about salmonella fading, the tradespersons and their guests would push back from their linen-covered folding tables to enjoy a comedy routine from a famous funny person.

Or so it’s been until now—until post-humor comedy thrust poor Chernow into the saddle. The quality of the comedy at the WHCD has been declining for years, beginning at least with a canned Jay Leno routine in 2010 and tumbling down to a set of stillborn one-liners by Larry Wilmore in 2016. Most agree that bottom was touched last spring by the comedian Michelle Wolf, who took to the podium after dinner to deliver 20 minutes of jokes that bore very few joke-like features.

There had been lots of anti-Trump demonstrations lately, Wolf noted, with protesters carrying homemade signs. How many signs? “Poster board is flying off the shelves faster than Robert Mueller can say, ‘You’ve been subpoenaed!’” If there’s humor in Paul Ryan’s circumcision—and I’m willing to be persuaded—she failed to find it. Chris Christie, Wolf suggested, was fat. She provided her own kind of abortion counseling: If you do terminate a pregnancy, she advised, motioning oddly with her elbow, “you’ve gotta get that baby outa there.” At her last line she leaned intimately into the microphone: “Flint still doesn’t have clean water.”

There was disappointment and even outrage, and offense was taken in quarters where offense is often taken. At the same time, though, some of us began to suspect that Wolf was not just not funny, she wasn’t even trying not to be not funny, if you see what I mean. Take my jokes, she seemed to be saying—please! Wolf’s 20 minutes before the WHCD marked her as a champion and exemplar of the post-funny school of comedy.

Typically slow on the uptake, I first learned about this evolution in humor the way I learn about too many things, from the daily news briefing that The New York Times drops in my email queue each morning. Along with a summary of news from all over and pleas to listen to podcasts and view video, the Times provides a few lines under the heading “Late-Night Comedy”—a joke cribbed from the monologue of a late-night talk-show host the evening before. The Times obviously assumes that most of its readers are in bed by the time Colbert or Coco or Corden hits the airwaves, and the Times is almost certainly right about that. It also assumes readers will appreciate a little day-brightener from the comedians, and here the Times is on much shakier ground.

The one quality that unites these late-night jokes is that they scarcely ever make me laugh—or you either, I’m guessing. Usually I’m a cheap date for comedians, a regular Rudy Roundheels; anybody from the Three Stooges to Mrs. Maisel can get a laugh out of me. At first, I thought that the consistently unfunny lines in the Times briefing reflected poor selection—maybe a couple of tin-eared interns had been given the wrong editorial assignment. But when you follow through and click on the links, which take you to the full monologues stored in a corner of the vast Times ecosystem called “Best of Late Night,” your heart goes out to the interns. What a job. Good thing they get paid! (They do, don’t they?)

The jokes, seen in context, don’t get any funnier. Very often, they are simple statements of fact, with minimal humorous adornment. James Corden mentions that Google will soon allow you to store your driver’s license on your phone. “You have to admit,” he says, “Google is definitely making it easier and more convenient—for your personal information to be stolen by Google.” If there’s a joke in here, I suppose it rests on the word stolen, casting Google’s innovation in a larcenous light. But it’s simply true that Google makes a living using the information we hand to it on our digital silver platters. It’s not news, but if you tried hard you might make it funny.

But nobody seems to be trying. Corden’s line about Google is unusual in the late-night world only in that it’s about something other than politics, or, more specifically, President Donald Trump. Any bit of news can be made to be about Trump. The Times points me to Seth Meyers, who notes that a Dominican singer recently tried to break a world record by performing for 100 hours straight. Seth’s hot take: “‘Big deal, try performing for 14 years,’ said Melania.” (The Times, as America’s newspaper of record, adds helpfully: “referring to first lady Melania Trump.”)

Again, a simple statement of fact is enough to substitute for a real joke. On The Late Show With Stephen Colbert, Stephen Colbert (who else?) bravely “takes on” congressional Republicans and their never-ending quest to dismantle the Affordable Care Act. “Remember ‘repeal and replace?’” Colbert joshed. His audience showed premonitory signs of volcanic laughter. “‘We’re going to repeal and replace’? Well, after nine years, they still haven’t gotten around to the ‘replace’ part. [Lava gurgling from the audience.] They have no plan. [Burbling …] In fact, there is no plan to make a plan.” Krakatoa! Too true! But … true is all it is. The two-step formula of a stand-up joke, setup followed by punch line, has been edited down to the first step and left at that. Colbert notes a string of superlong (long for Twitter) tweets from Trump. “Brevity is the soul of wit,” Colbert points out with a pedantic lift of the eyebrow. “And he is evidently witless.” Late night is where punch lines go to die, to drown in the bathtub of literal-mindedness.

Of all the comedians the Times directs me to, none tries harder not to be funny than Samantha Bee of TBS. Not long ago, Bee gave a six-minute monologue on the resignation of Kirstjen Nielsen, the former secretary of homeland security. Knowing its readers are busy, busy, busy, the Times decided to summarize Bee’s monologue like so:

But [Bee] also worried that President Trump might replace Nielsen—who oversaw the administration’s notorious policy of separating migrant families trying to enter the country—with someone even more willing to enforce hard-line border policies. Before her ouster, Nielsen and Trump had been clashing over whether to embrace harsher measures, some of which Nielsen reportedly believed might fall outside the limits of the law.

Note well that this is not meant to be a news report. It’s the summary of a comedy routine. If possible, the routine itself is even more not-funny than the summary. It is lightened only by Bee’s comic affect. She poses her head at a slight angle to the camera, rolling her hands, as if she’ll take off for the stage door the minute the audience decides to come after her. Really, she doesn’t need to worry.

It’s tempting—isn’t it always?—to blame everything, including this descent into humorlessness, on Trump. It’s not quite right to say, as is often said, that Trump has no sense of humor. You could say he has a sense of what a sense of humor is, even if his own preference is for a pigtail-yanking, pull-my-finger kind of humor, full of ridicule, mugging, sarcasm, and broad-brush caricature. His campaign rallies are like overlong stand-up routines without any jokes, just as late-night comedians’ stand-up routines are coming to resemble campaign rallies, also without the jokes.

Trump’s audiences, no less than Colbert’s, are primed to laugh whenever the signal is given. Trump’s jokiness is outward-directed, always. You notice you never hear the president laugh; his own amusement with the world, his own desire to amuse, doesn’t emerge from a place deep enough for laughter, and it is always aimed away from himself. Real comedy is beyond him. Who knew it would be beyond comedians?

It’s much more likely that Trump is a symptom, or at least a correlate, rather than a cause of whatever has drained the funny from traditional joke telling. The explanation may be as simple as this: We have witnessed the death of an art form. Stand-up joke telling has died in the same way that some of us of a certain age have watched the Broadway musical die, and as our lucky grandparents before us watched the operetta die. (I would have paid to see that.) Jokes that nearly everyone understands as jokes require shared assumptions, even a broad reservoir of lightheartedness and goodwill, and we no longer share those in our fractured republic. Humor has been privatized.

While feeling terrible for the Times interns, we should reserve some sympathy for the comedians and their writers. They must be miserable. Colbert, the Jimmies Kimmel and Fallon, Corden, and the others have shown genuine comedic gifts in earlier phases of their career. Surely they don’t pay top dollar to hire subpar writers to furnish them with non-jokes and pull their slack marionette strings. It can’t be fun, much less funny, feeding line after line to a studio audience only to elicit what Seth Meyers—in an earlier, funnier phase of his career—called “clapter.” Meyers coined the term to describe a reaction that’s 2 percent laughter and 98 percent applause, a way for an audience to let the joke teller and one another know that they’re all on the same team. Still, the videos on the Times’ “Best of Late Night” page show the studio audiences clapting to the point of seizure, five nights a week. I can’t imagine how they keep it up. Maybe they get a popper of amyl nitrate with their Late Show tote bags.

Which brings us back to Ron Chernow. We can be sure there won’t be any poppers in the swag bags Saturday night. He is an amiable fellow, as agreeable in person and at the podium as he is on the page. After the Wolf disaster last year, the correspondents’ association decided to ditch the stand-up routine altogether and go highbrow. In his talk, Chernow says, he will make the case for the First Amendment, and no one could make it with greater knowledge or eloquence.

But he’s also hinting that he may leaven the gloom with a little humor of his own. One shudders at the thought. Don’t do it! Comedy is a business best left to the professionals, and as we’ve seen, even they don’t want to try it anymore.



On Saturday, Representative Justin Amash became the first Republican member of Congress to suggest that President Donald Trump should be impeached for his misdeeds, a stand that puts him at odds with the GOP and risks his future in the party.

For nine years, the libertarian-leaning Michigander has been an unusually principled and independent-minded pol, breaking partisan ranks whenever he felt the Constitution demanded it. He used Twitter to lay out his conclusions about Special Counsel Robert Mueller’s report, Attorney General William Barr’s characterizations of that report, the portions that have not been released to the public, and his belief that many of his fellow lawmakers are not fully informed about the matter.

His principal conclusions:

1. Attorney General Barr has deliberately misrepresented Mueller’s report.

2. President Trump has engaged in impeachable conduct.

3. Partisanship has eroded our system of checks and balances.

4. Few members of Congress have read the report.

About those claims, he stressed, “I offer these conclusions only after having read Mueller’s redacted report carefully and completely, having read or watched pertinent statements and testimony, and having discussed this matter with my staff, who thoroughly reviewed materials and provided me with further analysis.”

He came away regarding Barr as a liar:

In comparing Barr’s principal conclusions, congressional testimony, and other statements to Mueller’s report, it is clear that Barr intended to mislead the public about Special Counsel Robert Mueller’s analysis and findings. Barr’s misrepresentations are significant but often subtle, frequently taking the form of sleight-of-hand qualifications or logical fallacies, which he hopes people will not notice.

Then he turned to the question of impeachment, fretting that failing to use it in the face of presidential misconduct would lead to more high crimes and misdemeanors:

Under our Constitution, the president “shall be removed from Office on Impeachment for, and Conviction of, Treason, Bribery, or other high Crimes and Misdemeanors.”

While “high Crimes and Misdemeanors” is not defined, the context implies conduct that violates the public trust. Contrary to Barr’s portrayal, Mueller’s report reveals that President Trump engaged in specific actions and a pattern of behavior that meet the threshold for impeachment. In fact, Mueller’s report identifies multiple examples of conduct satisfying all the elements of obstruction of justice, and undoubtedly any person who is not the president of the United States would be indicted based on such evidence.

Impeachment, which is a special form of indictment, does not even require probable cause that a crime (e.g., obstruction of justice) has been committed; it simply requires a finding that an official has engaged in careless, abusive, corrupt, or otherwise dishonorable conduct. While impeachment should be undertaken only in extraordinary circumstances, the risk we face in an environment of extreme partisanship is not that Congress will employ it as a remedy too often but rather that Congress will employ it so rarely that it cannot deter misconduct.

Finally, he turned to his colleagues in Congress, observing, “Our system of checks and balances relies on each branch’s jealously guarding its powers and upholding its duties under our Constitution.” In contrast, he wrote, “when loyalty to a political party or to an individual trumps loyalty to the Constitution, the Rule of Law—the foundation of liberty—crumbles. We’ve witnessed members of Congress from both parties shift their views 180 degrees—on the importance of character, on the principles of obstruction of justice—depending on whether they’re discussing Bill Clinton or Donald Trump.”

He upbraided his colleagues for being underinformed, charging that few “even read Mueller’s report; their minds were made up based on partisan affiliation—and it showed, with representatives and senators from both parties issuing definitive statements on the 448-page report’s conclusions within just hours of its release.” And he concluded, “America’s institutions depend on officials to uphold both the rules and spirit of our constitutional system even when to do so is personally inconvenient or yields a politically unfavorable outcome.”

On Sunday, Trump responded on Twitter, “Never a fan of @justinamash, a total lightweight who opposes me and some of our great Republican ideas and policies just for the sake of getting his name out there through controversy. If he actually read the biased Mueller Report, ‘composed’ by 18 Angry Dems who hated Trump, he would see that it was nevertheless strong on NO COLLUSION and, ultimately, NO OBSTRUCTION … Anyway, how do you Obstruct when there is no crime and, in fact, the crimes were committed by the other side? Justin is a loser who sadly plays right into our opponents hands!”

Trump’s statement is a lie: The Mueller report was not “strong” on “no obstruction”; it presented some evidence suggesting that Trump had obstructed justice, but declined to reach a conclusive prosecutorial judgment on that question. Trump is nevertheless correct that the Muller report found “no collusion.”

In my estimation, impeaching Trump for obstruction of justice without definitive evidence of an underlying crime is highly unlikely to result in his conviction and removal from office, especially given Republican control of the Senate. And the country is now close enough to the 2020 election that deciding the matter at the ballot box may well be the most prudent of all courses.

However, I believe that Trump has committed other impeachable offenses, including his unlawful bombing of Syria, his decision to keep American troops participating in Yemen despite a congressional vote against that course, the false accusations of treason that he has made on Twitter, and his calls to abridge the freedoms of speech and the press that he vowed to protect and defend.

Most members of Congress have paid little attention to those transgressions, as their expectations of proper presidential behavior are divorced from the Constitution. Amash is different. Since he believes that impeachment is a prudent course politically, plausibly asserting that it could rein in future misbehavior, he should draw up a comprehensive list of Trump’s high crimes and misdemeanors rather than focusing narrowly on the Mueller report. Doing so would usefully clarify the strongest case for impeaching Trump.

What articles would you suggest, Representative Amash?



For the past 18 months, Sebastian Kurz, the 32-year-old chancellor of Austria, has led a coalition between his center-right People’s Party and Heinz-Christian Strache’s far-right Freedom Party. From its inception, his government was rocked by scandal: The police carried out an astonishing raid on an intelligence bureau that was in charge of spying on far-right extremists, and had in the past uncovered links between neo-Nazis and some of Strache’s colleagues. A state senator for the Freedom Party, reporters revealed, once belonged to a fraternity that openly glorified the Third Reich. (“At that point, the Jew Ben Gurion came into their midst,” go the lyrics for one of the fraternity’s songs, “and said: ‘Step on the gas, ye old Teutons, we’ll manage the seventh million.’”)

Even as these and other scandals came to dominate headlines in the country, Kurz declined to comment on most of them. His refusal to defend or condemn his coalition partner soon earned him a new nickname: Der Schweigekanzler, or the Silent Chancellor. But at a press conference he hastily convened on Saturday to address a sting video in which Strache was shown soliciting illegal donations, and promising government favors, Kurz claimed that “there were many situations in which I found it hard to tolerate this behavior.” His patience with the Freedom Party having finally come to an end, he dissolved the government and called for new elections.

The collapse of Austria’s government is reason for celebration. At no point in the past few decades had the government of a West European country damaged the basic rules and norms of liberal democracy more quickly, or more thoroughly. Anybody who cares about the survival of the separation of powers, or the freedom of the press, should rejoice that the Freedom Party is no longer in power.

Some European politicians have gone even further. István Ujhelyi, a member of the beleaguered opposition in Hungary, for example, told The Guardian that Strache was merely the “first domino” to fall: “Next up are Salvini, Le Pen, Orbán and the rest of Moscow’s far-right puppets.” But far from heralding a reversal of the populist tide, as Ujhelyi seems to believe, the fall of the Freedom Party may yet turn out to reveal populism’s astounding resilience.

A few months before ascending to the second most powerful position in the Austrian government, Heinz-Christian Strache traveled to a luxury villa on the Spanish island of Ibiza to persuade a Russian billionaire to make illicit donations to his far-right Freedom Party. “There are a few very affluent people,” he says in the video, which was shot in the summer of 2017, and released by two German publications on Friday, “who are contributing between 500,000 and 2 million euros.”

A woman asks for the names of past donors. “Our donors usually are idealists,” Strache explains as his colleague Johann Gudenus, who would go on to lead the Freedom Party’s faction in the Austrian parliament, translates his remarks. “Gaston Glock,” for example.

The Russians do not understand. “Glock, Glock,” Strache repeats, as Gudenus mimics a man taking aim with a handgun.

This video set off an earthquake that equally serious past scandals had failed to provoke. Over the past years, newspapers had, again and again, reported on the Freedom Party’s dirty dealings, its close connections to Russia, and the remarkable number of xenophobes and anti-Semites in its midst. Each time, the party’s propagandists waved such revelations off as fake news. But when voters could see, with their own eyes, how cavalierly the soon-to-be vice chancellor of the Austrian Republic promised a Russian billionaire lucrative state contracts, that defense no longer seemed plausible. It became impossible for Austrians—and for Kurz in particular—to brush off the deep hypocrisy of a party that rails against corruption while making dodgy deals with shady supporters.

In the wake of Kurz’s press conference, European commentators indulged in a rare moment of triumph. Across the continent, center-right leaders have been tempted to ally themselves with the far right. And while a few of them, such as Prime Minister Juha Sipilä of Finland, have mostly managed to co-opt their populist competitors by making them part of the government, far more have merely succeeded in emboldening the far right. Kurz’s travails can therefore serve as an urgently needed morality tale for politicians who hope to emulate his path to power: An alliance with the populist right can help you take office—but it could also lead to the sudden collapse of your government, and forevermore associate you with the stench of fraud.

Still, it would be naive to think that voters in Italy, France, or Hungary will see reason, and turn against their own populists because their Austrian allies have disgraced themselves. Across the border to Austria’s much bigger neighbor, for example, the leader of the Alternative for Germany was not especially perturbed by questions about his party’s legitimacy in the wake of the recent revelations: Strache’s behavior, Jörg Meuthen readily admitted on the country’s most closely watched political talk show, was utterly unacceptable; but, being “singular,” it had nothing to do with his own party. By the end of the program, Katarina Barley, a senior Social Democrat, worried that the attempt to tar Meuthen with Strache’s brush could ultimately strengthen him.

Demand for populism tends to outlast the popularity of particular populist leaders. In Italy, for example, Silvio Berlusconi dominated the political scene for two decades. But instead of returning to moderation when his support finally sank to the single digits, the political landscape radicalized: It is now dominated by Matteo Salvini, a xenophobic politician with close links to Austria’s Freedom Party.

Austrian voters had plenty of opportunity to understand the danger posed by the Freedom Party before the Russian video. And yet, its support has, so far, proved remarkably stable. Clearly, about a quarter of the Austrian public is comfortable with a party that openly attacks the rule of law and tolerates extreme anti-Semites in its midst.

According to the first poll taken since the video was published, the Freedom Party still retains the support of 18 percent of the electorate, down about 5 percent compared to polls taken before the scandal. That number could well go up as the party’s leaders settle on a counternarrative, and mobilize their large fan base on social media. After an uncharacteristic moment of silence, Strache has already signaled his determination to go the low road: In his first public comments since the publication of the video, he pinned the blame for his downfall on the infamous operative of an opposition party, who just so happens to be Jewish.

So yes, the revelations of the past days may well end Strache’s career. And yes, they certainly could inflict serious damage on the Freedom Party. But there is no reason to think that the spectacular self-immolation of the Austrian government hands defenders of liberal democracy anything more than a perilously short-lived victory.



As the Black Lives Matter movement rose to national prominence in 2015, a small group associated with the push to end unnecessary police killings suggested 10 specific reforms that every police agency ought to adopt, hoping to inspire informed, constructive activism in communities across the country.

On Wednesday, Campaign Zero launched a new initiative grounded in a similar premise—that changing outcomes in a country with 18,000 law-enforcement agencies requires local reform efforts “in every jurisdiction,” and that people everywhere therefore need enough information “to effectively evaluate each law enforcement agency and hold them accountable to measurable results.”

But how to achieve that?

Campaign Zero’s provisional answer is Police Scorecard, a new site that assigns grades to 100 large police departments in California. The organization chose that state because it collects and publishes more data on police agencies than most others.

Perhaps most striking in the statewide analysis: “Overall, half of people killed or seriously injured by police (49%) were unarmed.” And the deadliest locales:

Police in San Bernardino, Riverside, Stockton, Long Beach, Fremont and Bakersfield used deadly force at substantially higher rates than other major cities in California. San Jose and Los Angeles police used deadly force at 3x the rate of police in San Francisco and San Diego. And Oakland police had one of the lowest rates of deadly force, reflecting the substantial decline in use of force incidents that has followed DOJ mandated reforms to their use of force policies.

Carlsbad, a sleepy seaside municipality in North San Diego County, enjoyed the best-performing police department among those graded, while ultra-wealthy Beverly Hills performed the worst, according to analysis of data from 2016 and 2017.  

In Oakland, 12,142 arrests were made in 2016.

Over two years, San Francisco had 778 civilian complaints of police misconduct. But just one in 13 was decided in favor of the civilian.

Costa Mesa, the municipality of 114,000 where I grew up, got a D+, even though it was one of only 15 police agencies included in the study that did not use deadly force in the period under consideration, in part because “police made 10.6x as many arrests for low level offenses as for violent crimes in 2016.”

Los Angeles got an F. In 2016 and 2017, there were reportedly 131 deadly force incidents, only one in every 24 complaints resulted in rulings favoring civilians, and police made 5.4x as many arrests for low-level offenses as for violent crimes.

At this early date, read Police Scorecard with caution.

As with efforts to evaluate colleges and rank them from top to bottom, the metrics are inevitably imperfect, and the outcomes are contestable. Police Scorecard omits some major policing agencies that contract with municipalities, like the Los Angeles County Sheriff’s Department and its 9,400 deputies.

It is nevertheless a useful and constructive effort––as a blueprint for what could be built in other states, a resource for Californians wanting to learn more about local policing, and a launchpad for discussion among activists, wonks, journalists, elected officials, and others who can help refine its methodology.

If you live outside of California, urge your state to create something like the California Department of Justice’s OpenJustice database. When data are available, projects like this one can follow. If you have a specific suggestion for improvement, email me.



Updated at 10:20 a.m. ET on May 25, 2019.

Many of the tales of controversy to emerge from the Trump administration have been abstract, or complicated, or murky. Whenever anyone warns about destruction of “norms,” the conversation quickly becomes speculative—the harms are theoretical, vague, and in the future.

This makes new Washington Post reporting about President Donald Trump’s border wall especially valuable. The Post writes about how Trump has repeatedly pressured the Army Corps of Engineers and the Department of Homeland Security to award a contract for building a wall at the southern U.S. border to a North Dakota company headed by a leading Republican donor.

The story demonstrates the shortcomings of Trump’s attempt to bring private-sector techniques into government. It shows his tendency toward cronyism, his failures as a negotiator, and the ease with which a fairly primitive attention campaign can sway him. At heart, though, what it really exemplifies is Trump’s insistence on placing performative gestures over actual efficacy. And it is a concrete example—almost literally—of how the president’s violations of norms weaken the country and waste taxpayer money.

The Post reports:

In phone calls, White House meetings and conversations aboard Air Force One during the past several months, Trump has aggressively pushed Dickinson, N.D.-based Fisher Industries to Department of Homeland Security leaders and Lt. Gen. Todd Semonite, the commanding general of the Army Corps, according to the administration officials, who spoke on the condition of anonymity to discuss sensitive internal discussions.

It may be a not-very-subtle sign of the frustration in the Army that the news leaked to the Post the same day that Semonite was called to the White House and Trump once again pressed him.*

Fisher is a curious choice. The company is already suing the government after being rejected for any Army Corps contract for the border wall. Fisher was one of the companies that participated in a prototype exercise outside San Diego in 2017, but the company’s wall didn’t meet the specifications laid out by the Department of Homeland Security, which wanted a wall that agents could see through. Instead, Fisher pushed a more expensive, concrete wall, similar to the one that Trump promised during the 2016 presidential campaign. But the Fisher prototype was late and over budget. The CEO, Tommy Fisher, criticized the steel-bollard design that the government chose. Now Fisher is promising a steel wall, and it says it can build one cheaper and faster than any other contractor.

Fisher Industries has some assets, though. Tommy Fisher is a major GOP donor. He has North Dakota’s Republican Senator Kevin Cramer in his corner. He’s already working on a private-sector attempt to build a barrier on private land in New Mexico, which is backed by close Trump allies such as Steve Bannon, the former White House strategist; Erik Prince, the founder of Blackwater and brother of Education Secretary Betsy DeVos; and Kris Kobach, the former vice chair of Trump’s voter-fraud commission, who was under consideration as his “immigration czar.”

Moreover, Tommy Fisher has wisely made himself a fixture on Fox News, which the president watches obsessively. He’s used those appearances to pitch his company’s plan. And in a statement to the Post, Fisher Industries struck a positively Trumpian tone, promising to build “faster than any contractor using common construction methods” and adding, “Consistent with the goals President Trump has also outlined, Fisher’s goal is to, as expeditiously as possible, provide the best-quality border protection at the best price for the American people at our nation’s border.”

There are valid critiques of the Army Corps contract process. Like many government contracting processes, it can be sclerotic and award contracts to a crew of the usual suspects, firms that are geared not toward speed and efficiency but toward box checking. But it should be self-evident that the answer to fixing a troubled process is not for the president of the United States to personally intervene and pressure military leaders to award a contract to a specific company, controlled by a political ally, which has repeatedly failed to meet the standards laid out for the process.

Trump’s obsession with Fisher is a triumph for the company. Even as Fisher has failed to follow guidelines and changed its vision of the wall, it continues to insist it can magically do the job better and faster than anyone else. These sort of pie-in-the-sky claims, in any realm, should raise alarm bells. They do not for Trump, for a couple of reasons. First, the president has demonstrated time and again that despite his self-styled reputation as a genius negotiator, he is actually a pushover who is easily swayed.

Second, the idea of putting marketing far ahead of actual results resonates with Trump. After all, it was his business model. Whether in real estate or mattresses or get-rich-quick seminars, Trump always prioritized lavish and hyperbolic publicity schemes over the actual delivery of the promised goods or services; later in his career, he largely eschewed the product part altogether, instead licensing his name and marketing prowess and letting other people build the buildings (or manufacture the mattresses).

Trump’s micromanagement of the contracting process also reflects his M.O. at the Trump Organization, a lean company in which it was easy for the CEO to intervene in all sorts of decisions. As many a businessman turned politician has discovered, it doesn’t work that way in the public sector. Besides, all that stood to be lost at the Trump Organization was Trump’s own money—and lose it he did, profusely—as opposed to the taxpayer’s.

Trying to circumvent government guidelines in order to award a crony contract to build the wall creates the danger of a boondoggle that doesn’t really do what Trump wants the wall to do. But Trump seems indifferent to the wall’s actual efficacy. This has been true all along. The wall was always more symbolic than functional. As he has since acknowledged, there’s no need for a wall across the entire border, since some parts are topographically impassable. Moreover, few experts believe that a long wall is a cost-effective way to police illegal immigration. Trump’s lack of interest in whether and how the wall would actually work made it easy for him to occasionally, whimsically add 10 feet to his height estimate, and made it easy for him to abandon the big concrete wall in favor of a steel-bollard design.

But Trump also knows he needs to build the wall—really, any wall—or at least get a good start before the 2020 election. It was his central campaign promise in 2016, and failing to do so would risk alienating his supporters and might endanger his reelection prospects. As a result, he’s more interested in a performative wall than a wall that performs. If that means hassling the Army Corps to award a contract to a crony whose promises have fallen short repeatedly, so be it. If that means the wall that goes up ends up not being all that effective at stopping border crossings, or if it’s over budget, or if it’s behind schedule, so be it—so long as those bills come due after November 3, 2020.

* This story originally said General Mark Milley was present at Thursday's meeting. He was not.



One prays to the “Eternal Father, strong to save / Whose arm hath bound the restless wave” that The Wall Street Journal has got it horribly wrong. The newspaper reports that the United States Navy, under orders from the White House and with the approval of the acting secretary of defense and the compliance of a chain of naval officers in the Seventh Fleet, did its efficient best to conceal the name John McCain from President Donald Trump’s sight when he recently visited Yokosuka Naval Base.

The ship is under repair, so it could not be moved. But sailors hung a tarp over the ship’s name, and other measures (a strategically positioned barge) helped obscure the offending words. Sailors were told to remove all coverings that might indicate that the ship is the USS John S. McCain. They were, according to the article, given the day off, lest the name John McCain, embroidered on their caps, give offense. On the day of the presidential visit, some of the sailors present wore “Make Aircrew Great Again” patches, with something that resembled Trump’s profile on them. Subsequent stories in The New York Times and The Washington Post amended the Journal’s story somewhat, to include the assertion that naval leadership intervened at the last minute to have the tarp removed. But the basic account remained intact.

Dishonor. Not only to the late senator, nor to his father and grandfather of the same name, who rendered the same distinguished service in war and peace. Their deeds and reputations are far beyond such mean contrivances. But dishonor indeed to the civilians and officers who hold the lives of young Americans in their hands and went along with this. That the president might wish such behavior is not surprising—he is mean, petty, and vindictive, and even if he did not order this (and he quickly tweeted a denial that he had), he signaled that he wished it. It is what is known in strongman governments as “working toward the Leader.” It is the effect of a personality that contaminates and corrodes every valuable thing he touches.

Former Secretary of Defense Jim Mattis would never have agreed to this. But his successor may well have gone along with it. He is, after all, only an acting secretary, and desires the real title from a boss who likes to string ambitious men and women along.

Naval officers of the past—a Preble or a Farragut or a Nimitz—would have disdained such requests. If called on the carpet, they would have spoken up and spoken back, with the firmness expected of officers from a service known for its ornery independence. But perhaps we have fewer of those these days. Petty officers in days gone by would have growled at their enlisted men and women to keep political statements off their shoulders, and enforced the political neutrality of the armed forces. But maybe they no longer understand that public displays of partisan attachment are anathema to good order and discipline. Maybe they wanted to wear MAGA hats, too.

That this could happen to the mightiest armed forces on Earth should worry Americans far more than reports of Chinese hypersonic missiles or ace Russian-military hacking teams. When large elements of the chain of command yield to illegitimate and morally corrupt demands of this kind, there is reason to fear veins of rottenness in the whole structure. When naval officers can agree to dishonor the memory of a real hero, who suffered five years of torment and refused early release, a statesman who in his first career was blood of their blood and flesh of their flesh, and who is buried on the grounds of the Naval Academy itself, the service is in a bad way.

Those who went along with these requests disgraced themselves and disgraced the oaths they took when they joined the service or became public officials. In a just world, they would lose their commissions or resign their posts, but they will not. They will burrow more deeply in. They will do so because it is the nature of the moral compromise of someone sworn to a demanding code that weakness begets weakness, yielding begets yielding, and cowardice begets still more cowardice.

Leadership teams at companies that act this way for a while eventually blow themselves up in scandal or bankruptcy. A financial reckoning comes sooner or later, and then the shareholders or the courts or scavenging capitalists slice up the remains. But there is nothing more perilous than an armed force without honor. Democratic peoples trust the armed forces with immense, almost inconceivable reservoirs of physical force and influence. That trust, once squandered, takes a long, long time to regain.

More dangerous, a service that tolerates sycophancy will get America’s sons and daughters killed, and lead them to defeat in America’s wars. War is not per se a test of character, but it is impossible to win one without it. In wartime, the kinds of behaviors on display in the White House, the Pentagon, Indo-Pacific Command, and the Seventh Fleet will mean that the readiness reports will be lies, the backup plans imaginary, and brave men and women will be led by courtiers, not commanders. Maybe some admirals and a senior civilian or two will resign in disgrace or shame, but that is doubtful. And those who did this or condoned it will remain in charge.

Undoubtedly, many serving members of the Navy and the other services will be outraged at such an indictment. If so, they should have hard conversations with those who serve alongside them, and with their superiors, whose craven conduct is a danger to them, and to all Americans. Because if they do not call them out, no one will.

The saddest part of this presidency is not the behavior of the commander in chief of the armed forces. Everyone knew what he is and how he was likely to behave from well before he won the presidency. The saddest part is what he reveals about individuals in high places, and institutions that we once thought relatively free from moral rot. What this episode shows is that the black fungus of fear, and ambition, and servility is more pervasive than might have been imagined. It stains uniforms even as it has stained business suits. The president has merely brought it to the surface.

The first stanza of the Navy Hymn ends, “Oh, hear us when we cry to Thee/For those in peril on the sea.” Unfortunately, the peril they face is now shown to be far greater than one might ever have imagined.



Two separate stories this week about criminal justice and the right to vote offer a sharp microcosm of the difference between the major U.S. political parties.

The Democratic presidential field has spent most of the week tying itself in knots over whether prisoners should be able to vote—an important but largely abstract debate. Meanwhile, Florida Republicans are close to passing a law that allows felons to vote after serving their time, but places serious hurdles before them.

The debate demonstrates much about the two parties. It contrasts the Democratic tendency to focus on national solutions to problems with the Republican emphasis on state-level policy. It shows a Democratic tendency toward abstraction, and a Republican emphasis on action. And it suggests why conservative policy ideas are winning across the nation, despite evidence that America is a center-left country.

The Democratic conversation kicked off during a CNN town hall on Monday, where Senator Bernie Sanders said that people serving time in prison should be allowed to vote. He mentioned that Vermont’s state constitution guarantees that right. This is a neat demonstration of how Sanders’s presence in the race shakes up the Democratic primary. While Democrats have focused in recent years on the importance of re-enfranchising people who have completed prison sentences, there has been less focus on the people who are still behind bars.

Sanders forced his rivals into a difficult spot: Should they agree with him, satisfying a party base ever more focused on social justice, at the risk of being tarred as soft on crime? (Sanders himself took heat for saying that even the Boston Marathon bomber should be able to vote, although that’s the obvious implication of such a rule.) Or should they tack right against Sanders, courting centrist voters but risking activist backlash?

Mayor Pete Buttigieg opted for the latter, saying that while in prison, felons shouldn’t be able to vote. Beto O’Rourke and Julián Castro tried to split the difference, saying they backed voting rights for nonviolent-felon prisoners. Senator Elizabeth Warren was cautious, saying, “I’m not there yet.” Senator Kamala Harris was more cautious still, calling for a “conversation.”

Conversations are useful, and policy is better made deliberately than haphazardly. The question of the right of felons to vote is important—though not important to as many Americans as whether ex-cons can vote, nor as politically advantageous for those who support it. It’s unlikely, however, to be a defining issue of the Democratic campaign, and unlikely to be a top priority if the Democratic nominee wins the 2020 presidential election.

Contrast that with this week’s proceedings in Tallahassee. In November, Florida voters overwhelmingly approved a state constitutional amendment that automatically gives people who have committed felony offenses, except for murder and sex crimes, the right to vote once they complete their prison sentence as well as parole or probation. (Previously, people could apply to a state board for restoration of rights after five years, though a small portion of requests were granted.) Although some experts contended that the law might have little real impact on elections, the prospect of 1.5 million new voters in one of the swingiest states in the nation got partisan attention. Democrats hoped that ex-felons would add to their coalition; Republicans feared the same.

After the amendment passed, the Florida legislature began working on enabling legislation—in other words, hashing out the nitty-gritty of how the amendment would work in practice. Both chambers of the state house are controlled by Republicans, as is the governorship. On Wednesday, the state house passed a bill, along partisan lines, that would require people who want to vote to pay all court fees, fines, and restitution associated with their case. The state senate is considering a version that requires that restitution be paid, but not fees and fines in many cases.

Many advocates see the bill as a betrayal of the amendment’s spirit. By insisting on payment, which may be substantial, the bill would guarantee that many of the people who appeared to be in line for rights restoration under the November vote will never actually be able to cast a ballot.

In short, while Democrats are engaged in a largely theoretical exercise on the national level, Republicans are moving aggressively to achieve their political goals at the state level.

The Democratic Party has long had a national focus. In part, that’s ideological: The party tends to believe in top-down government solutions, making Washington a natural locus for policy, while Republicans have long emphasized local control. It’s also historically contingent. Starting from the 1930s, Democrats often held a strong advantage over Republicans in national politics.

Since the 2010 election, Democrats have also been badly overmatched at the local level, and while the party made significant gains in 2018, Republicans still have the upper hand in state capitals. That has allowed the GOP to implement its policy views on a range of issues. Republican-led legislatures have expanded gun rights, restricted abortion rights, and hamstrung organized labor, to choose just a few. This isn’t to say that the entire Republican Party is a well-oiled machine for implementing policy, particularly at the national level. Nine years after the Affordable Care Act passed, the GOP still hasn’t come up with a plan to replace it, despite repeated promises.

On the question of felons and voting, however, the pattern holds. Republican actions on the state level speak louder than Democrats’ conversations.



Editor's Note: Read more stories in our series about women and political power.

Seven years ago, as the Supreme Court considered a challenge to the Voting Rights Act, Justice Antonin Scalia said the quiet part loud.

The 2006 near-unanimous renewal of the landmark civil-rights bill was “attributable, very likely attributable, to a phenomenon that is called perpetuation of racial entitlement,” Scalia lectured then–Solicitor General Donald B. Verrilli. “Whenever a society adopts racial entitlements, it is very difficult to get out of them through the normal political processes.”

Scalia’s logic was clear: The 1965 law, which guaranteed black Americans’ right to the franchise in the South for the first time in 100 years, was a “racial entitlement” that Congress itself would never remove, and so the high court was duty-bound to remove it. When Chief Justice John Roberts issued his ruling invalidating the law’s provisions determining which jurisdictions with histories of racial discrimination must submit to oversight by the federal government, however, Scalia’s rationale was absent from the decision. Also absent was any mention of what part of the Constitution the invalidated provision violated.

Roberts didn’t call the Voting Rights Act a “racial entitlement.” Rather, he insisted that while he agreed with the law’s intentions—“any discrimination in voting is too much,” he wrote—close federal oversight of local election laws to prevent discrimination was no longer warranted. “Things have changed dramatically,” Roberts concluded. Shortly thereafter, Republican-controlled states moved as quickly as possible to impose restrictions on voting targeted at minority communities, as if determined to make Roberts look a fool or a liar.

The disparate approaches taken by two of the Court’s conservatives to the Voting Rights Act reflect the right’s dueling impulses toward civil-rights laws. Where Scalia rejected the very effort to guarantee black people the same right to cast a ballot as white people as a “racial entitlement,” Roberts insisted that he agreed with the law’s underlying premises, but that the statute now did more harm than good.

Lingering beneath the surface was a defining question for the American right: Does it agree with Roberts that “any discrimination in voting is too much”? Or with Scalia, who saw ensuring equal participation in the polity as a black “racial entitlement”?

The Supreme Court’s looming decision over the addition of the citizenship question on the U.S. census will hinge on the answer to that question. The census provides the basis for congressional apportionment and the distribution of federal resources. Empirical studies of the impact of adding the question have determined that it would result in a dramatic undercount of Latinos and immigrants—exactly contrary to one of the Donald Trump administration’s stated rationales, that it would provide a more accurate count.

Since the rise of Trump, the American right has been offered a stark choice between the democratic ideals it has long claimed to believe in, and the sectarian ethno-nationalism of the president, which privileges white identity and right-wing Christianity over all. Scalia didn’t quite have it right: The fundamental question for American democracy since the founding has indeed been whether it is a “racial entitlement,” but only because of those who have tried for centuries to ensure that white people alone are entitled to it.

The Roberts Court has already taken steps in this direction. Last year it endorsed Trump’s travel ban, despite the president’s public statements identifying Muslims as the ban’s target, on the basis that the order itself did not mention religion, a blueprint for allowing further discriminatory efforts to pass constitutional muster as long as the high court’s conservatives retain control. Later that year, the conservative justices, self-styled champions of the freedom of religion, denied a request by a Muslim death-row inmate to have an imam present for his execution, forcing the condemned man to make do with the prison’s Christian chaplain. In both cases, the Court’s conservatives could hide behind the letter of the law in dismissing the government’s official disapproval of Islam. But recent revelations in the census case will force the Roberts Court to decide whether America is a nation for all of its citizens, or a white man’s republic.

On the surface, State of New York v. United States Department of Commerce appears to be a dry question of administrative and constitutional law. In January 2017, the news leaked that the Trump administration wanted to add a question asking census respondents whether they were American citizens. The Trump administration enlisted the acting head of the Civil Rights Division of the Department of Justice, John Gore, to state that the question should be included to improve enforcement of the Voting Rights Act. Wilbur Ross, the head of the Department of Commerce, which administers the census, insisted to Congress that this was the reason for the addition of the question. In fact, Ross had sought the addition of the question long before this rationale was provided.

A recent Court filing by groups challenging the addition of the citizenship question shows what the administration really had in mind. The filing shows that Thomas Hofeller, the late Republican redistricting expert, concluded that adding the citizenship question would, in his words, “be advantageous to Republicans and Non-Hispanic Whites.” That analysis was offered in a 2015 memo, as Hofeller was helping Republicans draw redistricting lines that they believed would cement a majority in Congress. That memo, along with a 2017 document written by Hofeller on the subject, which contains some language identical to a later Justice Department memo on the matter, was turned over to the liberal group Common Cause by Hofeller’s daughter after his death.

Voting districts are typically drawn using total population. A switch to using the voting-age citizen population would, Hofeller concluded in his 2015 memo, expand white political power at the expense of people of color, and thereby increase Republican advantage. But, Hofeller wrote, that shift could only occur with the addition of a citizenship question to the 2020 census, which would provide the federal government with data necessary for that switch. This argument, which reappears in Hofeller’s 2017 memo, was adopted by the Justice Department in its justification for adding the citizenship question to the census, along with the legal pretext of wanting to better enforce the Voting Rights Act.

In other words, long before Trump was even elected, Republican Party insiders were plotting to increase white political power at the expense of people of color. After Trump was elected, they implemented this plan by insisting that their actual goal was the protection of minority voting rights. As with the Voting Rights Act, there was the real reason and the stated reason, the truth and the pretext. The nationalism, and the delusion.

“It just seemed like a new level of mendacity, and putting their goals out there in black and white in a way we hadn’t seen before,” says Dale Ho, one of the American Civil Liberties Union attorneys who submitted the filing on behalf of the challengers in the census case. “No one believes that anyone in this administration has any intention of enforcing the Voting Rights Act.”

The use of the Civil Rights Division, which was established to protect Americans’ fundamental rights, to undermine those very rights is a perversion of justice. But it also illustrates that Trumpism merely traveled a few stops down the road from where the Republican Party leadership had been. The risk with Trump was not that the GOP would become a vehicle for the preservation of white political and cultural hegemony; it was that he would discredit that project by making its agenda explicit, by saying, as Scalia did, the quiet part loud.

That the Republican effort to increase white political power might be motivated by partisanship rather than racism is little solace. Segregationist Democrats might not have insisted on disenfranchising black voters after Reconstruction had those voters not been staunch Republicans. Whether motivated by partisanship or racism, though, the result is the same. If the Roberts Court does not draw a line here, this will not be the last step toward reestablishing a white man’s government it will be asked to take.

The census case does not hinge on whether the citizenship question is discriminatory. Rather, as a matter of administrative law, the executive branch must follow certain procedures before making decisions. The Trump administration’s blatant dishonesty settles the question of whether it followed procedure definitively: It did not.

“This kind of smoking-gun evidence of what the real illicit reason is behind a government action is incredibly rare. Court decisions don’t require it, and it’s really quite shocking to read it so explicitly,” Wendy Weiser, a voting-rights expert at the Brennan Center, told me. “Every procedural constraint on agency decisions was violated in this case, and the reason that was provided, every lower court found, was not the real reason that the secretary of commerce added the citizenship question.”

The Trump administration has fiercely denied that Hofeller’s reasoning influenced the administration. But like most Trump-administration denials, this appears suspect. Not only did a Trump transition official, Mark Neuman, testify in a deposition that he spoke with Hofeller, who urged him to add such a question to the census, but Neuman later became an adviser to Ross. (Neuman testified that Hofeller told him that the change would increase Latino political participation.) As The New York Times reported, Neuman provided Gore with the draft of a memo endorsing the citizenship question that echoes Hofeller’s language in a 2017 document found on his hard drive word for word, and a later, more detailed memo to Ross from the Justice Department further adopts Hofeller’s reasoning and uses some of his language. The Trump administration’s reply to the filing dismisses this evidence of Hofeller’s influence on the process as “pure speculation.”

Ironically, because conservatives on the Roberts Court appear to believe that government remedies for racial discrimination are worse than racial discrimination itself, there is considerable apprehension among left-leaning attorneys about providing the high court with concrete proof of racist intent in this case or any other. They fear that such proof is liable to make the Court’s conservatives more likely to rule against them. In this case, however, the evidence that adding the question was intended to bolster white political power is also further proof that the administration did not follow the law in adding the question.

The census case is not ultimately about administrative procedure; it is, more fundamentally, about whether the Trump administration can use the federal government for the explicit purpose of increasing white political power. The Trump administration, and by extension, the conservative masses, are already on board, convinced by years of right-wing propaganda that all the opposition’s victories at the ballot box are suspect. Those elements of the Republican establishment that funded and conceived of the census scheme are all in, as well. The only remaining question is whether, and to what extent, the high court is willing to ratify this step toward white man’s government. It is not the first time it has been asked to do so.

Even before William F. Buckley declared in 1957 that “the White community in the South is entitled to take such measures as are necessary to prevail, politically and culturally, in areas in which it does not predominate numerically,” the modern conservative movement has struggled to reconcile the ethno-nationalism that moves masses of its voters with the pluralism embodied in the notion that all persons are created equal.

Trump’s victory settled the question of whether the GOP would seek to expand its base by diversifying it, or rely on the imposition of white political hegemony over a changing electorate. This is a counter-majoritarian strategy that, in the long run, relies on abandoning the pretense of liberal democracy in favor of something else: A white man’s republic, if they can keep it.



Even in our fractious, ill-tempered times, we can all come together to agree on this: $6 million is a lot to pay for a hat. That’s true even if the hat is a stovepipe model that once belonged to Abraham Lincoln. If it turns out not to have belonged to Lincoln, well then, the $6 million really does begin to look like a serious extravagance. And if you borrowed the $6 million to pay for the hat that you later discover probably isn’t Lincoln’s, the whole deal could quickly swell from extravagance to calamity.

And so it might be doing now, in Springfield, Illinois, Lincoln’s hometown and the site of the Abraham Lincoln Presidential Library and Museum. Two years after the museum opened in 2005, its sponsoring foundation borrowed $25 million to buy the Taper collection, at the time the largest collection of Lincoln stuff in private hands. Louise Taper, the eponymous collector, had, over the previous 30 years, acquired artifacts that one expert refers to, in nontechnical language, as “the superstars.”

Among her 1,500 items were Lincoln’s billfold and his eyeglasses, his favorite pen, and the gloves he wore to Ford’s Theatre the night of his murder, still flecked with blood. She owned the earliest known sample of his handwriting, a leaf torn from a schoolbook. She even owned the chamber pot he used in the White House. And the hat too—as inseparable from the Lincoln image as the whiskers, and one of only three, it was said at the time, that were known to have survived from his day to ours. An assessment placed the value of the hat alone at more than $6 million.

Nobody back in 2007 thought $25 million was a pittance, but not many people said it was an extravagance either, at least publicly. Even in perpetually broke Illinois, times were flush; the Great Recession was a little cloud no bigger than a man’s hand rising from the cornfields. At a single stroke, the museum exponentially increased the historical value of its holdings, which until then had comprised mostly documents (including some superstars of its own—one of the five handwritten copies of the Gettysburg Address, for example). The museum was self-consciously cutting-edge in its computer-powered exhibits, using holograms and life-size re-creations and a relentless sequence of optical and sonic effects to divert the attention of visitors away from their cellphones. But the climax of the visitor’s experience was to be charmingly low-tech: a final, dimly lit exhibit called the “Treasures Gallery.”

The gallery, one of the museum designers told me, was modeled on the crown-jewels chamber at the Tower of London, with the important difference that these were crown jewels American-style. There were no rubied scepters or beaded orbs or sparkling tiaras, just the briefcase and notebooks and saddlebags of a 19th-century prairie lawyer, along with early printings or handwritten copies of his greatest utterances. In the innermost circle of the Treasures Gallery, the sanctum sanctorum, the holy trinity of Lincoln artifacts shone in pools of light: a signed copy of the Emancipation Proclamation, the Gettysburg Address in Lincoln’s hand, and, of course, the hat, a towering tube trimmed in beaver skin, with two small ovals worn away on the brim, presumably from Lincoln’s fingers as he tipped it to passersby or held it fast against blowy days.

For a book I was writing, not long after the museum opened, I spent an hour at a time in the Treasures Gallery watching visitors come and go. Not often, but often enough to notice, a man or a woman fresh from the high-tech fantasia of the previous galleries would suddenly confront the plain reality of these objects and be brought to tears. As a rule, visitors lingered in this gallery of relics longer than in any other. None that I spoke with ever seemed daunted when I told them the price of the hat.

The word relic is the key, redolent of the near-mystical reverence in which generations of Americans have held Lincoln. The Catholic Church, which has more experience with the veneration of physical objects than anyone else and has, as is its custom, surrounded the practice with a rubber-band ball of complicated rules accrued over centuries, divides its saintly relics into three classes. The first comprises physical remains of the beatified. The second deals with objects the saint used or wore. The third involves anything that has come into prolonged contact with the second class.

In the cult of Lincoln—which started before his body cooled on the morning of April 15, 1865—relics of the first class are relatively rare: The most obvious are tiny fragments of his skull, collected during his autopsy by the surgeons who tried to pry loose the bullet that killed him. They are kept and occasionally displayed at the National Museum of Health and Medicine in the Washington suburb of Silver Spring, Maryland, where they draw fans who are equal parts ghoul and Lincoln buff. Purported samples of Lincoln’s hair, allegedly clipped on his deathbed or during the autopsy, come on the private market now and then, but invite skepticism from serious collectors. “If every lock of Lincoln’s hair out there was genuine,” one avid collector told me the other day, “the man would have been a woolly mammoth.” (Like the other sources I spoke with for this story, this collector did not wish to be identified by name; the world of Lincolnalia is, as he put it, “too small and incestuous” to risk the loss of any relationships, commercial or otherwise.)

Of course, such objects, when they do go on the market, are priced beyond the reach of nearly everyone, so the market has responded as markets do: It has expanded the definition of desirable Lincoln objects beyond the first, second, and third classes to the 48th class, the 87th class, the 94th class. The demand for Lincoln memorabilia, collectors say, never flags. Depending on the day, a scroll through the Lincoln pages on eBay will bring come-ons for old matchbooks from the now-defunct Lincoln Life Insurance Company, old lithographs, new copies of old lithographs, playing cards, every species of folk art, bubble-gum cards, sheet music, and … did I mention the matchbook covers? Six dollars apiece.

Perhaps most remarkable of all is the market in Lincoln forgeries. If you can’t afford a real, verifiable Lincoln signature (starting perhaps at a couple of thousand dollars), you might want a fake Lincoln document, complete with a fake Lincoln signature, if it can be shown to be from the pen of Joseph Cosey, Charles Weisberg, or another of a handful of highly skilled forgers who flourished in the early years of the past century. Mark Hofmann, the world’s most celebrated living forger, who’s now serving a life sentence in a Utah prison, specialized in faking documents associated with the Mormon Church. But he also dabbled in Lincoln, and samples of his work occasionally stir the market and excite collectors.

Caveat emptor, however. “You just have to make sure it’s a real forgery—a real Weisberg or Cosey,” that avid collector once told me. “The market’s so hot now, we’re seeing a lot of fakes.”

But the museum’s Lincoln hat—this object capable of holding grown men and women in thrall, moving some of them to tears—is it a fake too? The first public suggestion that it might be came from a tireless reporter, Dave McKinney, then with the Chicago Sun-Times. Nosing around, McKinney discovered that historians at the museum had, over time, given different stories of the hat’s origins—its “provenance,” as the trade calls it.

The hat had been passed down through a family of farmers from downstate Illinois. The family sold it for an unknown price to the state’s official historian, James Hickey, in 1958. An affidavit accompanying the sale, written by the original owner’s daughter-in-law, said that Lincoln had given the hat to her father-in-law when he visited Lincoln in Washington in 1861. In 1990, Hickey sold the hat (again, price unknown) to Louise Taper, who occasionally lent it out to special Lincoln exhibits. By this time, Hickey’s successor was describing the hat as the one Lincoln had worn “during the Civil War.” In 2012, five years after the state had bought the hat as part of the Taper collection, another historian for the Lincoln library offered still another version of the provenance. He told McKinney that Lincoln had probably given the hat to the downstate farmer at one of the Lincoln-Douglas debates in 1858.

Because no one could show that the farmer had ever traveled to Washington during the Civil War, the library historian told McKinney, “I guess you’d say we’ve taken something of a historic liberty in redating it to a much more plausible time and place.”

The hat’s defenders point out that the hat is in Lincoln’s size. It was likely made by a Springfield haberdasher during Lincoln’s time there. Beyond those claims, the trail goes cold. Even after McKinney’s first story ran, the museum continued to show the hat periodically in rotation with other artifacts, with no mention of its dubious provenance. The visitors continued to come and go, to stand before the relic and marvel. The foundation’s website still offers a clickable, 3-D image of the hat.

Now at WBEZ, a public radio station in Chicago, McKinney has stayed on the case. In September, he reported on a “highly secretive effort to authenticate the hat” by the Abraham Lincoln Presidential Library Foundation, which had taken out the loan to buy the Taper collection. The effort, begun in 2013, failed. It involved DNA tests by forensic analysts from the FBI, which found no evidence of Lincoln’s genetic material, and a study of the provenance by two historians, one from the Smithsonian and another from the Chicago History Museum.

“The current documentation,” the historians concluded, “is insufficient to claim that the hat formerly belonged to President Abraham Lincoln.” They recommended that the museum remove the hat from display until further research could establish its authenticity.

As it happened, the hat was off display when McKinney’s story aired on WBEZ. Museum officials said more research was already under way to authenticate the hat, and until the project was finished, the hat would remain in the vault.

Meanwhile, the foundation is struggling to pay off the roughly $9 million remaining on the original loan, which comes due in October. The Taper collection is the loan’s collateral and would be forfeited with a failure to pay; an auction would be held, and the collection would scatter. The state government is broke and says it can’t help. The foundation, says its vice chair, Nick Kalm, is pursuing “traditional outreach to high-net-worth individuals and foundations” to raise the money quickly. Among its other efforts is a GoFundMe page, which so far has raised nearly $35,000 toward its $9.7 million goal.

“We are going to do everything in our power,” Kalm says, “to raise enough money to work with the bank so that none of the core holdings in the museum ever see the auction block.”

In Illinois, they’ve coined their own word, hinky, to describe the irregularities—sometimes amusing, sometimes appalling—that characterize the way official business is conducted in the state. There is much about the tale of the hat that is hinky. You could begin in 1958, with the obvious conflict of interest involved in a state historian using his position to buy an apparently invaluable artifact for his own use.

On the other hand, we could also be looking at something more innocent, and more telling—a case of mass, mutual hypnosis, a will to believe so deep-seated that it overpowers any inclination to skepticism, even among men and women trained to be skeptical. Catholics will tell you that relics have a practical, theological point to them. They are a rebuke to the tendency to spiritualize the saints, to think of them as spectral beings, somehow removed from the world. Physical relics impose on believers the reality that saints were bodily creatures, just as they are.

Lincoln wasn’t a saint, of course—he probably wasn’t a Christian either. Yet for many of us, his historical importance and personal greatness are so vast that we risk untethering him from the real world. The Lincoln museum is testimony to his role in American history, a role like no other. How invigorating it is to move through the exhibits in Springfield as the evidence of his greatness piles up and, at the end, to come upon something of his own, a relic that might carry over the reality of a man: a book or a belt or a pen. Or a hat.



Minutes ago, the Islamic State released a video of the most wanted man in the world, Abu Bakr al-Baghdadi. No one has seen him publicly since his infamous speech at the al-Nuri Mosque in Mosul, Iraq, in July 2014. In today’s video, he is sitting cross-legged, with a white sheet behind him and, nearby, an automatic rifle and a few tasteful cushions. Sitting to one side, silently, are three masked men. Baghdadi speaks for about 12 minutes—calmly, simply, without any particular charisma—and his audience listens attentively and silently.

From the video we learn that Baghdadi is neither dead nor disabled. His condition was not a foregone conclusion: Russia announced in 2017 that it blew him to smithereens in an air strike, and news reports said that he suffered a crippling spinal injury. The latter is still possible; Baghdadi doesn’t stand up or gesticulate in a way that demonstrates a full range of motion. But this is not a Richard Simmons video, and we should not interpret too much from his physical modesty. His hands look a little anemic, and his ear appears to be abnormally wrinkled, like a wrestler’s or a cardiac patient’s. But overall, he does not look like someone who has been hiding in a spider hole.

To establish his survival and current good health, of course, he didn’t have to give much of a speech. Baghdadi mentions many current events that establish the video as having been filmed this month. He notes the defeat of his forces in Raqqa, Syria, and in Mosul over the past couple of years, and finally in Baghuz, Syria, only a month ago. He notes the revolutionary protests in Algeria and Sudan, both of which are recent news. And in a coda to the video, he praises the attackers behind the April 21 bombings in Sri Lanka, saying that the Islamic State was retaliating for Baghuz (and not, as Sri Lankan officials have suggested, for Christchurch).

But the content of Baghdadi’s speech is less informative than his affect. The total number of words we have seen delivered by Abu Bakr al-Baghdadi on video just doubled, and with that doubling we get not only a new explicit message but also a new profile of the man. He is not like Osama Bin Laden, who was the scion of one of Saudi Arabia’s wealthiest and most famous families, and who therefore could not control his public image. Baghdadi, by contrast, managed his image carefully. His sole previous appearance cast him in terms familiar from early Islamic history. He quoted the Prophet’s successor and father-in-law, Abu Bakr, likening himself to him; he wore the colors of the Abbasids. He delivered a speech filigreed with religious terminology and highfalutin religious diction and grammar. That self-presentation was almost comically over-managed. This one probably is, too.

And what is the image Baghdadi is attempting to project? That of a terrorist leader, an insurgent, a shadow-leader of a subterranean movement of global reach. He is wearing a pocketed vest, the kind you rarely see a mullah wear but that insurgents and fly fishermen wear all the time. The rifle by his side stresses the point. And the message itself eliminates any doubt. The rhetoric no longer soars. The language, while formal, does not take on the pious diction of his previous speech, or most of the audio releases since then. Back when Baghdadi ruled a state—complete with a well-armed military, tax collectors, and health inspectors—he and his top deputy spoke with grandiosity that inspired followers and irritated enemies. Now, as an insurgent leader again, he has dispensed with the fanciness. He governed in poetry; he terrorizes in prose.

With the fall of Baghuz, Baghdadi faced a real danger of revolt. An absent caliph is not a caliph, his enemies said. (The memory of Mullah Omar, the supreme leader of the Taliban, is fresh. His followers kept their allegiance to him for years after his death. The Islamic State ridiculed them for their zombie-like loyalty.) With this video, we know that the caliph still lives, rules, and demands oaths from his followers. Some of those followers followed him because they thought he would lead them in a series of never-ending victories. Whether they continue to follow him, now that he is an aging warlord holding court in front of a bedsheet, remains to be seen.



The final image of Knock Down the House, the hit documentary about a quartet of 2018 congressional primary candidates, shows Alexandria Ocasio-Cortez and her boyfriend newly arrived at the east plaza of the Capitol building in Washington, D.C. She has just been elected to Congress, but not yet taken office. They both start to cry; the waterworks run at a low gurgle throughout the movie, and at this point the viewer won’t be alarmed by another eruption.

Suddenly scooters appear, and the couple, with infectious delight, takes off in zigzags across the plaza, which is usually closed to tourists. The image thus combines three elements—Millennials, scooters, and trespassing—that seem designed to make a certain kind of conservative Republican’s head explode. The poor fellow will probably view the film as an exercise in trolling, a giddy, unapologetic version of his worst nightmare.

But it takes two to troll. Most viewers will be intrigued rather than annoyed by Knock Down the House; some will be inspired. The filmmakers, the wife-and-husband team of Rachel Lears and Robin Blotnick, set out to record a political movement at the moment of its creation, and there’s no mistaking the uplift implied by their final shot: Let the word go forth, from this time and content provider (Netflix), that the torch has been passed to a new generation of Americans, come of age in this century, tempered by two wars, disciplined by piles of student-loan debt, proud of their multicultural heritages. And they will be arriving on scooters.

That’s the message of the movie, anyway, and it’s perfectly tailored to invigorate a political culture dazed with Trump fatigue. Whether Lears and Blotnick make a persuasive case is another question.

Along with Ocasio-Cortez, the movie follows three other political newcomers. All were recruited by two loosely organized groups, Justice Democrats and Brand New Congress, made up of veterans of Bernie Sanders’s 2016 campaign.

Paula Jean Swearengin of West Virginia was persuaded to undertake a primary challenge to an incumbent Democratic senator, Joe Manchin, in hopes of making West Virginia into something a little less like West Virginia—less coal and more jobs, for starters. Cori Bush, a nurse in St. Louis whose work schedule sometimes forced her to campaign in scrubs, tried to unseat her local representative, also a Democrat, after the police shooting of Michael Brown in nearby Ferguson. And Amy Vilela, who blames the untimely death of her daughter on the health-care industry, quit her job as a business executive to run for an open congressional seat in Las Vegas.

Only Ocasio-Cortez made it past the primaries. Batting .250 is middling in baseball and even less impressive in politics. The survival rate suggests that the movement may not be quite as robust as the candidates and the activists who enlisted them hope.

“It’s not about any of us individually,” Vilela says on the night of her defeat, tearful but still game. “It’s about the whole movement.” Ocasio-Cortez replies that it may take a hundred women running against the establishment for each one who breaks through into the halls of power—easy for her to say, of course, since she’s the one and not the hypothetical 99. Still, politics, like baseball, is an enterprise for unbending optimists, and you can’t help but be impressed by the energy and pluck the candidates summon in fighting their uphill battles.

The viewers’ simple admiration for the tenacity and optimism that politics requires might extend to the candidates’ entrenched opponents, too, but we never really get a good look at them. The exception is Ocasio-Cortez’s target, Representative Joseph Crowley. At the time of his gibbeting, Crowley was the fourth-ranking member of the House Democratic leadership. Pink and fleshy, with a toothy perma-grin, he could have been drawn by Thomas Nast to represent the Machine Hack, the very symbol of complacent incumbent. He saw Ocasio-Cortez coming too late and never knew what hit him.

The film leaves it unclear what Crowley’s offense was, why he deserved his unhorsing—beyond being one of the world’s seemingly bottomless supply of “white dudes in suits,” to use the phrase of one activist in Knock Down the House. (It’s the filmmakers’ bad luck that they never caught him wearing a suit.) As a liberal Democrat, he sat in the middle of his caucus ideologically—no Barbara Lee or Jamie Raskin, but a reliable “yes” vote on whatever enthusiasm public-employee unions and environmentalists placed before him.

Crowley initially avoided a debate with Ocasio-Cortez but at last relented. She tagged him for living in suburban Virginia rather than his district, as so many congressional lifers do, and for sending his children to school in their neighborhood rather than to the diploma mills back home (ditto). Crowley, she charged, helped defeat an obscure amendment to the Dodd-Frank bank-regulation bill; the amendment would have helped “working families,” Ocasio-Cortez assures us. And although Crowley did his duty and called Immigration and Customs Enforcement (ICE) “fascist,” he refused to join Ocasio-Cortez in her demand that the agency be abolished.

“If you think this system is fascist,” she said to Crowley, “then why don’t you vote to eliminate it?”

He had no answer. That’s how you know when a congressman has been in Washington too long: He loses the courage of his own demagoguery.

In all this, Ocasio-Cortez demonstrates campaign skills of a high order. She walks away with the movie, and not only because she’s the only winner. She’s quick on her feet, strategically alert, and absolutely sure of what she thinks, with an eye for her opponent’s jugular and a circulatory system that by all indications functions on pure ice water. A brief interlude in which she dissects one of Crowley’s multipage, full-color mailers—“this Victoria’s Secret catalog,” she calls it—is a master class in how incumbents like Crowley misread their own voters while still managing to make political consultants fabulously rich. Her use of social media shows perfect demographic pitch: agitprop, recipes, civics lessons, life affirmations like “You can grow through your imperfections,” jumbled together and running nonstop, make her Instagram and Twitter feeds endlessly informative and enjoyable. She’s Tony Robbins, Suze Orman, and Saul Alinsky, all in one.

Another hundred iterations of Alexandria Ocasio-Cortez, working as both candidate and consultant, and her movement would be an irresistible electoral force—assuming the nation at large suddenly took on the political characteristics of her district in the Bronx and Queens. You’d never know it from the movie, but 2018 was a banner year for Democrats. They took back the House of Representatives by winning swing districts much redder than the solidly Democratic areas in which the Knock Down the House candidates ran (and mostly lost). Of the three congressional districts, only Vilela’s is home to a substantial number of Republicans.

As a piece of filmmaking, Knock Down the House is kind of a mess. In trying to track four different candidates in four different districts on four different timelines, Lears and Blotnick set themselves a high bar for narrative coherence that they are unable to clear. Important turning points come and go, on camera and off, without much explanation. Who, you sometimes wonder, is recruiting whom? The muddle works to confuse the larger themes. We never learn what this new movement exists to do, aside from offering liberal Democrats the chance to end the careers of slightly less liberal Democrats.

“We don’t care about party,” one activist says at the beginning of the movie. “We just want to get stuff done.” But political parties exist precisely because, according to 200 years of experience, they are the most efficient way to get stuff done. “It doesn’t matter if you’re Republican or Democrat,” says another. Well, yes, it does, actually. There is much talk of diversity in Knock Down the House, and the candidates and activists are indeed diverse in the predictable ways: They run the gamut of body type, from endo- to ectomorph, of regional accent, of ethnicity, of class background. But when it comes to politics—Medicare for All or a universal job guarantee—they are ideologically uniform. You’ll find more diversity of views in the locker room of the Burning Tree Club than in a recruiting session for Justice Democrats.

That’s why it’s a movement. But movements only succeed when they transcend themselves. “It’s time for everyday Americans to be represented by everyday Americans,” declares Ocasio-Cortez, the world’s most famous ex-bartender, not realizing that the minute she beat Joe Crowley she ceased to be an everyday American. The sooner she recognizes that she has now taken a place in the larger, much-loathed system, with all its demands of moderation and compromise, the greater the chances that she and her colleagues will become something more effective than a movement batting .250.

Until then, those Republicans whose heads explode at the mere sight of Ocasio-Cortez—and there are lots of them—can glue the skull fragments back in place. They have less to worry about than they think.



Ever since the release of the Mueller report, old-guard Democrats have held back on the question of impeachment. Though House Majority Leader Steny Hoyer walked back his comments that impeachment was “not worthwhile,” he set the tone for his party’s skepticism of what, Democratic leaders warn, could be a politically risky move. Meanwhile, the president announced on Twitter, “Only high crimes and misdemeanors can lead to impeachment. There were no crimes by me (No Collusion, No Obstruction), so you can’t impeach.”

Unsurprisingly, Trump is wrong—and Democrats reluctant to impeach on the basis of the Mueller report alone should consider that the report only added to a preexisting pile of potential “high crimes and misdemeanors.” A large majority of scholars agree that impeachable offenses are not limited by the criminal code; the best definition of impeachable offense comes from the legal scholar Charles Black, who argued in 1974 that the president may be impeached for “offenses (1) which are extremely serious, (2) which in some way corrupt or subvert the political and governmental process, and (3) which are plainly wrong in themselves to a person of honor, or to a good citizen, regardless of words on the statute books.”

Even setting that aside, the Mueller report sets out substantial evidence that Trump criminally obstructed justice in at least some instances. The former Justice Department and FBI official Chuck Rosenberg has said that, in the absence of the Justice Department guidelines against the indictment of a sitting president, as a prosecutor, he would have brought an obstruction case against Trump. Former U.S. Attorney Preet Bharara and former Deputy Attorney General Sally Yates have made similar arguments. And while lawbreaking is not required for impeachment, it is notable both that all three serious efforts to impeach a president in U.S. history have involved allegations of legal violations and that two of those three instances—against Richard Nixon and Bill Clinton—concerned criminal behavior, specifically obstruction of justice.

But any discussion of impeachment that focuses on the Mueller report alone, much less the possible criminal conduct detailed in the report, risks leaving out the obvious. The potentially impeachable offenses committed by the president go far, far beyond the scope of what Mueller investigated. Any impeachment inquiry should consider that conduct as well.

For example, Benjamin Wittes and Jane Chong, my colleagues at Lawfare, argued way back in August 2017 that Trump’s pardon of former Maricopa County Sheriff Joe Arpaio merited consideration in an impeachment inquiry. Arpaio, remember, was convicted of criminal contempt for his refusal to cease detaining people only on the suspicion that they had flouted immigration law. According to The Washington Post, Trump first asked then–Attorney General Jeff Sessions whether the Justice Department could drop the prosecution of Arpaio, then decided to pardon him if Arpaio was convicted at trial. How else to describe this process but as abuse of power?

What about his recent instructions to Border Patrol officers, as reported by CNN, to disobey the courts in turning back asylum seekers? His repeated calls for the criminal prosecution of his political rivals? His demands for the U.S. Postal Service to dramatically raise rates for shipping Amazon packages, for no obvious reason other than to punish Amazon CEO and Washington Post owner Jeff Bezos? His rescinding of the security clearances of a number of his high-profile critics, including former FBI Director James Comey and former CIA Director John Brennan? Or consider his repeated decisions to overrule his own intelligence agencies in declassifying sensitive information related to the Russia investigation in order to score political points, with apparent disregard for the potential consequences to the country.

Chong and Wittes have pointed to another category of potential offenses: failures of moral leadership. Here, too, the list is so long as to be impossible to reproduce in a paragraph, but to name a few: Trump’s attacks on the press as “fake news” and “the enemy of the people”; his declaration that the white nationalists and neo-Nazis marching in Charlottesville were “very fine people;” his description of Haiti, El Salvador, and various African nations as “shithole countries;” his repeated—and arguably libelous—abuse of private citizens as having committed treason; his lies—which, by The Washington Post’s count, now number more than 10,000.

Some of these instances more obviously fit within the description of “high crimes and misdemeanors” than others. One might object that many of Trump’s actions, ugly and petty though they might be, are not “extremely serious,” as Black put it—and, indeed, Black wrote that “general lowness and shabbiness ought not to be enough.” Still, I’m inclined to agree with Keith Whittington, who has suggested that high crimes and misdemeanors might, at a certain point, be treated cumulatively. “If Republican senators were forced to examine each such charge in turn,” Whittington wrote in August, “they might well find the president’s actions disquieting and misguided and yet not impeachable. The accumulation of such charges might, however, push the case for impeachment and removal over the line.”

Any discussion of “cumulative” high crimes and misdemeanors likewise has to include Trump’s conduct regarding Stormy Daniels. Talk of impeachment spiked in November 2018 after prosecutors in the U.S. Attorney’s Office for the Southern District of New York alleged that Trump’s former lawyer Michael Cohen had acted “in coordination with and at the direction of” his then client in what prosecutors charged was a criminal effort to violate campaign-finance law: Soon-to-be House Judiciary Chairman Jerry Nadler said that Trump’s involvement was “likely impeachable,” though he distinguished between an impeachable offense and an offense meriting impeachment.

In December, Bob Bauer and I argued that the Daniels payments are well within the scope of conduct that should be investigated as part of an impeachment inquiry. The case is somewhat complicated in that the bulk of the conduct at issue took place before Trump became president. But Trump’s continued involvement in coordinating payments to Cohen well into his time in office, and his insistence on lying to the public about the depth of that involvement and the initial relationship with Daniels, are relevant in evaluating the president’s failure as a leader. Consider Cohen’s account, in sworn testimony before Congress, that Trump was signing and mailing checks to refund his fixer for an illegal campaign contribution while sitting in the White House. And if preelection conduct is within the realm of what should be considered impeachable, then perhaps Trump’s involvement in his campaign’s efforts to benefit from Russian election interference—as detailed in the Mueller report—also constitutes an impeachable offense.

Taken as a whole, the picture is of a man who has no concept of the public interest as separate from his own, who has no ability to lead the country morally or even interest in doing so, who has repeatedly breached, in ways large and small, his obligation to “take care that the laws be faithfully executed” and “preserve, protect and defend the Constitution.” Notably, Congress has pointed to violations of the oath of office in impeachment proceedings against Clinton, Nixon, and Andrew Johnson.

Meanwhile, the catalog of presidential misconduct did not stop at the release of the Mueller report. Trump recently declared his administration’s plans to resist “all the subpoenas” headed his way from Congress, and has taken the unprecedented step of suing, in his personal capacity, House Oversight Committee Chairman Elijah Cummings over a subpoena to Trump’s accounting firm. In 1974, along with articles of impeachment for abuse of power and obstruction of justice, the House Judiciary Committee recommended Nixon’s impeachment on the basis that he had “failed without lawful cause or excuse to produce papers and things as directed by duly authorized subpoenas issued by the Committee on the Judiciary of the House of Representatives … and willfully disobeyed such subpoenas.” The Democratic presidential candidate and former Vice President Joe Biden recently suggested that Congress would have “no alternative but to go to … impeachment” if Trump continues to stonewall congressional investigations.

Like Trump’s cowed performance beside Russian President Vladimir Putin in Helsinki and his initial comments in defense of white supremacists after Charlottesville, the Mueller report—as a chronicle of presidential misconduct—adds useful information, but also clarifies and distills what was already known to be true. Reading the report, I was unable to shake a sense of naive amazement that this person really is the president of the United States. Part of the impeachment process—advocating for an inquiry as citizens, and conducting one on Congress’s part—is the work of maintaining this amazement and horror. It is a project of refusing to accept what has already, somehow, become acceptable.



My colleague David Frum, a supporter of the Iraq War who coined the phrase axis of evil, issued a warning in a column this week: “The project of a war with Iran is so crazy, it remains incredible that Donald Trump’s administration could truly be premeditating it,” he wrote. “But on the off, off chance that it is, here’s a word of caution from a veteran of the George W. Bush administration: Don’t do it.”

Among the reasons he offers:

The U.S. would find itself without allies except for Israel and the Gulf states. The Trump administration would find itself even more isolated politically at home. Most Americans do not support, trust, or respect Trump’s leadership.

There is no Colin Powell–like figure in this administration, no senior official who commands respect across party lines. Pitifully few people in this administration command respect even within party lines. The administration’s record of casual incompetence at minor tasks raises terrifying questions about its capacity for a gigantic undertaking like a land war against a Central Asian state.

My colleague James Fallows, an Iraq War opponent who wrote “Blind Into Baghdad,” the inside story of a historic failure, declared this week, “Military engagement with Iran would be far stupider, more reckless, and more destructive.” As he observed after watching an Iran-focused war game in 2014:

Unlike Saddam Hussein’s Iraq, a threatened Iran would have many ways to harm America and its interests. Apart from cross-border disruptions in Iraq, it might form an outright alliance with al-Qaeda to support major new attacks within the United States. It could work with other oil producers to punish America economically. It could, as [Marine Corps Colonel Thomas X.] Hammes warned, apply the logic of “asymmetric,” or “fourth-generation,” warfare, in which a superficially weak adversary avoids a direct challenge to U.S. military power and instead strikes the most vulnerable points in American civilian society, as al-Qaeda did on 9/11.

If it thought that the U.S. goal was to install a wholly new regime rather than to change the current regime’s behavior, it would have no incentive for restraint.

My colleagues aren’t alone in worrying that a disastrous war with Iran is a possibility. Last year, Trump withdrew from the nuclear deal negotiated during the Obama administration and imposed punishing sanctions on the country. Last month, testifying before the Senate Foreign Relations Committee, Secretary of State Mike Pompeo refused to acknowledge that waging war against Iran is not covered by the September 2001 Authorization to Use Military Force, which Congress passed in response to the 9/11 terrorist attacks.

This week, the Department of Defense unveiled an updated military plan that “envisions sending as many as 120,000 troops to the Middle East should Iran attack American forces or accelerate work on nuclear weapons,” The New York Times reported. “On Tuesday,” the newspaper added, “Spanish defense officials withdrew a Spanish frigate that was part of an American-led carrier strike group heading to the Persian Gulf, to avoid entanglement in any upcoming conflict.” The State Department has just evacuated some of its staff from Baghdad. And Fox News is hyping alleged ties between Iran and al-Qaeda.

In Congress and the press, the prospect of war with Iran is being treated as more worrisome than recent U.S. actions in Syria, Yemen, Libya, Somalia, and beyond, a posture that makes sense, given the likely costs of fighting that country.

Yet the relative apathy that surrounded those smaller conflicts—in Congress, the media, and the public—is a factor that makes a conflict with Iran more likely.

Picture this alternative reality:

Imagine that President Barack Obama had been greeted with massive street protests when he waged war against Libya; that favoring that intervention had prevented Hillary Clinton from advancing past the Democratic primary; that the critics now threatening Trump with impeachment had cited his missile strikes on Syria as prominently as the claim that he obstructed justice; that the Democratic presidential candidates were excoriating Trump more for complicity in Saudi Arabia’s dirty war in Yemen; and that street protesters were pressuring the White House with calls for the return home of all U.S. troops.

In this counterfactual universe of furious opposition to waging any war unlawfully, or launching any new wars of choice without demonstrating their necessity, Trump would be less likely to let hawks risk, let alone provoke, a major war. It is conceivable that he wouldn’t have appointed the hawks in the first place, or that he would have long ago fired them or reined them in to offset their political cost. It is certain that anti-war voices would have mobilized earlier, in greater numbers, to speak out against the very first steps toward war with Iran.

Instead, doves in the White House were left to make speculative cases that war would hurt Trump politically rather than being able to point to a large anti-war faction, and significant backlash is coming only after a long series of needless escalations.

The dearth of an anti-war movement may even have delayed Trump’s efforts to oppose his hawkish advisers––he reportedly said this week that he doesn’t want war, according to an article that The New York Times published yesterday.

Let all this be a lesson.

The best insurance against a catastrophic war of choice, now and going forward, is a permanent anti-war movement that opposes all illegal or imprudent wars, insisting on public debates and congressional votes, no matter how small the conflict. If Americans attempt to mobilize against only the biggest, dumbest wars, they will not get organized until it’s too late to stop some of them.



When Donald Trump was growing up in the 1950s, roughly half of the families in the New York metropolitan area read the New York Daily News. The tabloid was at the time the highest-circulation newspaper in America by far, selling more than 2 million copies each weekday and as many as 4 million on Sundays. In fact, no American newspaper has ever surpassed those numbers. But the News’ dominance was greatest in white, non-Jewish outer-borough neighborhoods such as Jamaica Estates, where the Trumps lived. Given that the man of the house, Fred C. Trump, was a major advertiser in the News and frequently appeared in its real-estate columns in the 1940s and ’50s, young Donald might have encountered it regularly—and, though adult Donald may not realize the connection, he sounds eerily like it now.

Indeed, the paper’s current left-wing politics have obscured the fact that it helped fashion a brand of right-wing populism in the years just before the president’s birth in 1946, and during his childhood, that Trump eventually rode to power.

The overlap between Trump’s rhetoric and the mid-century News is especially striking when it comes to United States foreign policy. Between 1946 and 1952, the Daily News editorial page and its politics column said dozens of times that Uncle Sam had turned into “Uncle Sap” or “Uncle Sucker,” because “so-called allies” in NATO were raking in aid money from the U.S. and failing to pay enough for their own defense. Trump has hammered away at the same message since the early days of his campaign; last December he announced, “We’re no longer the suckers, folks.”

The News also shared Trump’s concern that overly generous international deals made the U.S. a subject of ridicule. A 1946 editorial cartoon, for example, showed a jovial Stalin kicking a drunk Uncle Sam in the seat of his pants as Sam buys another round of drinks (aid money) for the Soviet dictator and his comrades. Two decades later, the Communists were still laughing. “The Red Hungarian bosses probably giggled into their cups,” an editorial told readers in 1965, when the State Department didn’t penalize the “bosses” after a mob damaged a U.S. embassy building.

Even though immigration in the 1940s was at historic lows and subject to the strictest laws in American history, the News called for further restriction. Editorials said immigrants posed a danger to Americans, with one warning in 1945 that “foreigners … want to stream here in millions, share our comparative wealth, and pull down our standard of living.” A 1943 editorial arguing against the repeal of the Chinese Exclusion Act pinpointed what the News saw as the problem: “Official Washington is infested with do-gooders who want to let the rest of the world in on [our] riches” and to “give away our country.” That notion permeated the editorial page throughout the ’40s and ’50s. One editorial in 1957 blasted “do-gooders,” “world savers,” and “bleeding hearts” for their “giveaway convulsions”—their alleged desire to dish out billions of American taxpayers’ dollars to “Socialist, semi-Socialist, or Fascist countries.”

The News had yet another name for those “do-gooders.” It labeled them “globalists,” an obscure term that the News picked up from Representative Clare Boothe Luce (and Trump picked up from Steve Bannon). The News especially liked Luce’s coinage “globaloney,” which was part of the headlines for three separate editorials in 1943. The end goal of globaloney, the last of these editorials said, was for the U.S. to “buy the Presidency of the World by means of a worldwide WPA,” or Works Progress Administration, the Depression-era jobs program, which would eventually bring “some kind of Socialism or Communism to the United States.”

To head off the threat of globalist socialism, the News offered the same prescription as Trump for restoring the country’s greatness: an “America first” policy. The paper’s publisher, Joseph Medill Patterson, was a strong supporter of the isolationist America First Committee prior to the U.S. entry into World War II, and he continued to promote the slogan in the News long after it had become associated with anti-Semites and fascist sympathizers. In 1950, the tabloid’s top political columnist, John O’Donnell, argued that “the America First philosophy was soundly right” all along.

“America first” retained a negative association when Trump adopted it during the 2016 campaign—but the candidate seemingly didn’t care, presumably because he thought it captured a view of foreign relations focused narrowly on what the U.S. stands to gain. The News unapologetically promoted that way of seeing. In a 1946 editorial devoted to “auditing” World War II, the News asked “what we got out of it” and concluded that it was only a string of Pacific islands to use as bases and temporary control of Japan (which the U.S. would use to “teach the Japs Roman letters and Arabic numerals”). In other words, a lousy deal.

Trump may enjoy angering some people with the slogan “America first.” His speech is often politically incorrect, blunt, and mildly profane, which apparently endears him to his base. The News employed the same technique: Its clear, plainspoken prose was a major selling point. The tabloid also used profanity and epithets for humor or titillation. Patterson even sent an internal memo in 1944 ordering the words “bastard” and “son of a bitch (no hyphens)” to be printed in full. In another Trumpian touch, the News gave insulting nicknames to its political opponents: Harry Truman was “High Tax Harry” or “Little Harry”; the Democratic White House adviser David Niles was “Devious Dave.”

Sometimes the News’ rhetoric had darker undertones, as when O’Donnell suggested in 1945 that “Devious Dave” Niles was part of a globalist Jewish conspiracy to bring down General George Patton. Like Trump and his allies, the paper was accused of anti-Semitism. When News cars drove through Jewish neighborhoods in the Bronx and Brooklyn during World War II, youths hounded them and called them the “Nazi News.” The B’nai B’rith organization in 1946 passed a resolution condemning the paper for trying to “incite religious animosity” and “foment hatreds” with editorials that implied that the Jews were responsible for the United States’ involvement in the war.

In fact, the News occasionally expressed some of the noxious beliefs that white nationalists who view Trump as their champion espouse today. A 1941 editorial endorsed the racist theories of the eugenicist Madison Grant, although they had been widely discredited years earlier. Foreshadowing the concerns of today’s so-called alt-right, the News fretted that white Europeans were committing “racial suicide” in World War II and would make “easy pickings” for the “yellow hordes of Asia.” Articles about Australia during the war noted approvingly that it was “white man’s country” and asked how far the U.S. should go “in trying to save Australia and New Zealand for the white race.”

The letters column of the News—labeled “Voice of the People”—could also be a forum for appalling racism. In 1959, the Voice published several letters about the lynching of Mack Charles Parker in Mississippi. One reader, who identified herself as “a Southern lady” living in New Jersey, wrote, “The people gave a dirty, sexed-up nigger just what he deserved,” adding, “I hope … they had to pick up his remains with a shovel.” Such hateful vitriol was rare—it was more common for readers to complain about black people being demanding or lazy, as in these examples from 1963—but the fact that the News printed the letter implies that it thought the letter expressed an acceptable viewpoint.

The overwhelming majority of News readers, like the overwhelming majority of Trump supporters, were not white supremacists. For most, what mattered was the paper’s claim to advocate for the “common people”—a commitment carved into stone on the facade of the headquarters Patterson built in 1930. Trump adopted a similar posture of fighting for—and, implausibly, even personifying—the “common man” in his 2016 campaign.

Trump and the News each envisioned the same type of common man as their target audience: white, working-class to middle-class, wary of intellectuals and elites. The News nicknamed its everyman Sweeney—they even had a motto, “Tell it to Sweeney!” But by the late 1960s, New York City’s demographics had changed. As the paper’s circulation manager lamented to The Wall Street Journal in 1967, “The trouble is there are fewer Sweeneys around to tell it to.” In response, the editorial page moved toward the center. It moved to the left in the 1990s, and as the News approaches its 100th birthday next month, it is still printing fiery editorials and provocative front-page headlines. Today, its main target, the president, embodies the principles the paper advocated at its height 70 years ago.



“Jews will not replace us.” When 300 neo-Nazis marched with flaming torches through the central quad of the University of Virginia on a late Friday evening in August 2017, their message was clear. The college’s response, in contrast, was a study in confusion. As a public institution, wrote then-President Teresa Sullivan, the university “must abide by state and federal law” regarding the First Amendment rights of free speech and freedom of assembly. Short of barring the “torch-bearing protesters” as an imminent threat to safety, university officials’ hands were tied. National Jewish organizations such as the Anti-Defamation League and the American Jewish Committee concurred, denouncing the shocking display of hatred but urging the public to let the “protesters” voice their “protected speech.”

Yet after the violent weekend that led to one death and multiple casualties, UVA lawyers unearthed a decades-old state law still on the books that banned the burning of objects on private or public property “with the intent of intimidating any person or group of persons.” It turned out that the Virginia General Assembly had dealt with this very problem back in the early 1950s, when the Ku Klux Klan tried to launch a new campaign in the state. The legal means to prevent this racist and anti-Semitic menace without violating the First Amendment had existed. No one had remembered to look for it.

An overlooked law written for a danger assumed to be long past. A domestic extremist movement masquerading as a political cause. An unswerving fealty to the First Amendment blinding lawyers to the violent danger staring them in the face. This lonely epilogue to Charlottesville is a fitting symbol for the current crisis facing the American civil-rights movement. White supremacists have twisted the law itself into a weapon with which to launch a frontal attack on American liberalism.

That this brazen attack took place on a campus where I teach Jewish history, including the long Jewish struggle on behalf of human rights, only underscored another historical irony. Anti-Semitism has returned with a vengeance, yet American Jews have forgotten how to fight it.

From Charlottesville to Squirrel Hill, Pennsylvania, to Poway, California, American anti-Semitism has repeatedly demonstrated its deadly propensity for violence. The common link is a social mediascape in which anti-Semitic and racist ideas and memes freely circulate, intensifying as they do so. Yet most American Jews feel powerless to fight anti-Semitism, trapped in a simplistic understanding of the First Amendment. Separate church and state, they believe, defend freedom of expression, and fight for equal treatment and a race-blind society, and over time anti-Semitism and other hatreds will dissipate. So the logic goes. Many Jewish lawyers pride themselves on their defense of civil liberties, safeguarding the expression of even unpopular views, from politics to pornography. Some proudly defend the rights of neo-Nazis and other anti-Semitic bigots.

That principled approach has its virtues. Yet in our day and age, this civil-libertarian orthodoxy has left society reliant on the fuzzier tools of tolerance education, public shaming, and private litigation to fight anti-Semitism. As a result, the press often replaces the courts as the forum for judging harmful words. Civil-rights lawyering is reduced to an exercise in punishing violent hate crimes after the fact, rather than preventing them beforehand. And worst of all, free speech and hate speech are imagined as two disconnected islands of contradictory ideologies, separated by an unbridgeable sea of constitutional law, rather than interrelated categories whose shared history stretches back to the opening years of the 20th century.

Just like Virginia’s forgotten anti–Ku Klux Klan law, there is more to the story of American Jews and civil rights than a stalwart faith in the ennobling virtues of free speech. Across the first half of the 20th century, Jewish lawyers stretched civil-rights law wider and deeper than the pursuit of absolute individual equality in order to prevent both verbal and physical attacks on Jews and other vulnerable minorities. They employed the novel legal approach of group libel. Their efforts formed part of the larger Jewish drive to defend civil liberties and seek political inclusion. They yielded striking legal innovations, including a bevy of state laws to shut down the most extreme peddlers of racism and anti-Semitism. Those laws even produced an important Supreme Court precedent, Beauharnais v. Illinois, which has never been overturned and remains relevant to contemporary civil-rights questions.

Yet even though the courts deemed group libel a legitimate way to stop hate speech without violating the First Amendment, over time American Jewish civil-rights groups edged away from their own achievement. Instead, they began to focus on the First Amendment as the ultimate counter-majoritarian instrument of self-defense against hatred. Exposing extremism would suffice to stop its spread. The teeming marketplace of ideas would crowd out the few malevolent Judeophobes and racists. Curbing present-day incitement risked future government censorship. The price of American freedom was some marginal discomfort inflicted by extremists, who were best managed through the tools of mainstream liberalism.

Today, as American society grapples with a deadly resurgence of anti-Semitism, it is well worth recovering the lost history of Jewish civil rights. For just as the roots of contemporary hatred stretch far back into the American past, so too does the forgotten record of the law’s struggle against it. Charlottesville is not only a reminder of the persistence of the past. It is a summons to reckon with American Jewish history’s timely legal lessons for today.

In August 1790, the newly elected President George Washington wrote a short note to the Jews of Newport, Rhode Island. Thanking them for their message of congratulations, he went on to praise the “Children of the Stock of Abraham who dwell in this land.” “The Government of the United States, which gives to bigotry no sanction, to persecution no assistance,” Washington memorably wrote, “requires only that they who live under its protection, should demean themselves as good citizens.”

Over time, the Newport letter came to symbolize the larger promise of religious liberty in the new American republic. Right now, these very words adorn the facade of the National Museum of American Jewish History in Philadelphia. In contrast to Europe, where ancient prejudices trailed Jews ominously into modern times, the new country announced its ideal of strict religious neutrality. The United States would privilege no one religion, for as Washington proclaimed, “All possess alike liberty of conscience and immunities of citizenship.”

Today American Jews treasure Washington’s letter like a precious birthright. Few realize that the stirring words were actually scripted for him by the Jewish community itself. Most of the ideas and much of the language were copied verbatim from the initial letter sent to Washington by Moses Seixas, a leader of Newport’s Jewish community. Yet even more striking than the language Washington cribbed is what he chose to omit from his letter. By describing Jews as entitled to civil equality despite their non-Christian status, and only at risk of discrimination for their religious beliefs, Washington effectively established a legal precedent. There would be no European-style corporate group identity or racial stigma attached to Jewishness in America. By law, American Jews would be implicitly treated as white Americans of a different religious faith.

That liberal vision, of Jews flourishing as individual citizens living in voluntary communities, neatly matched the egalitarian ideals of the young republic. It worked well in a country where Jews remained a negligible percentage of the population, and where there were virtually no Jews of color. In Washington’s day, the 1790 census counted a mere 1,500 Jews, most of whom came from Sephardic backgrounds in western Europe, amounting to 0.05 percent of the total American population. A century later, despite another wave of immigration, this time from German-speaking Central Europe, the number had risen only to 0.5 percent.

Then, in the late 19th century, millions of Yiddish-speaking eastern-European Jews began to pour into American society. Their arrival coincided with the post-Reconstruction rise of modern American nativism, Jim Crow laws, and a new current of racial anti-Semitism. Suddenly, formal religious equality was not enough to stop active discrimination from WASP elites in the urban North, or rippling threats of violence from Southern Ku Klux Klan members. New kinds of anti-Semitic mass media and populist demagogues targeted wealthier, acculturated Jews and their unwashed immigrant cousins alike. They blamed successful Jewish entrepreneurs for the ills of capitalism and poorer newcomers for their racial deviancy. Almost overnight, America decided that Jews might not count as fully white after all.

In May 1907, the management of the Marlborough-Blenheim Hotel in Atlantic City, New Jersey, turned away the family of a Jewish widow from Baltimore named Bertha Rayner Frank with a curt line: “We don’t entertain Hebrews.” In response, Louis Marshall, a renowned constitutional lawyer and the president of a newly established Jewish civil-rights organization, the American Jewish Committee, proposed an anti-discrimination law for New York State. When finally passed in 1913, the New York Civil Rights Act banned denial of service to people at restaurants, hotels, and all manner of other commercial venues based on race, color, or creed. Yet in a twist, it also prohibited any advertising that even mentioned denying accommodations to certain groups. Now it was a legally punishable offense to discriminate in deed or to defame in words.

That same year, the Anti-Defamation League launched as a second Jewish civil-rights organization. Its stated mission was “to stop, by appeals to reason and conscience and, if necessary, by appeals to law, the defamation of the Jewish people.” Over the next decade, at the behest of Jewish civil-rights groups, six more states followed New York’s lead, drafting laws that outlawed advertising and other published expressions of discrimination directed at a specific group. At root, these laws relied on a concept of group defamation, or, as it was alternately known, group libel. For hundreds of years, English common law had recognized the individual citizen’s right to sue for personal libel. Now state legislatures began to experiment with civil-rights statutes that allowed for the prosecution of individuals who defamed or injured the reputation or property of members of a minority group. Marshall even helped sponsor a draft federal law before World War I to ban the dissemination of hate literature by U.S. mail.

Targeting defamatory speech against a group was a bold step to protect the freedom of Jews, African Americans, and other minorities. Much of this work went hand in hand with the new African American civil-rights activism of groups such as the NAACP, which numbered among its senior leadership many Jewish lawyers and rabbis. Just like anti-lynching laws, group-libel statutes moved the law beyond the protection of formal equality for individuals, to an equity-based model that acknowledged group differences in society. The ideal of blind justice would not suffice when it came to a racialized society in which minorities were targeted disproportionately and distinctively—sometimes with the law’s consent.

Yet the assertive drive for positive group protection also stirred up anxieties among Jewish leaders. Some feared that anti-bias laws might not only run afoul of the First Amendment rights to freedom of speech and assembly but actually compromise the legal and political security of Jews as individual citizens. Separating Jews out as a minority group risked reinforcing anti-Semitic stereotypes. Worse still, such a move might give the American government license to treat Jews as a potentially unassimilable national or racial minority as in Europe. That fear derived from a disturbing reality. The turn-of-the-century restrictive American immigration laws banned nonwhite racial minorities, threatening to close the doors to millions of Jews fleeing extreme poverty and increasingly violent anti-Semitism in eastern Europe.

Then, in 1920, America’s most famous business tycoon, Henry Ford, began publishing a nakedly anti-Semitic newspaper with a national distribution, The Dearborn Independent. Ford promoted a variety of malicious stereotypes about Judeo-Bolshevik power, fanned fears of Jewish racial impurity, and portrayed jazz and baseball as Hebraic conspiracies to pollute American society. He even republished the Russian anti-Semitic conspiracy tract, The Protocols of the Elders of Zion.

Ford’s hate speech seemed tailor-made for the kind of group-libel law already in effect in states across the country. Yet bitter divisions quickly emerged among Jewish civil-rights leaders over how to respond, as Victoria Saker Woeste showed in her 2012 book, Henry Ford’s War on Jews and the Legal Battle for Hate Speech. In 1924, Ford’s newspaper launched a series of articles to expose “Jewish exploitation” in the American cooperative-farming industry, particularly targeting the California lawyer and cooperative activist Aaron Sapiro. Enraged by the patent falsehoods and anti-Semitic attacks, Sapiro sued in federal court in Detroit for libel.

Sapiro’s lawsuit attracted the attention of other Jewish civil-rights leaders, chief among them Marshall. By the early 1920s, Marshall had argued several cases for the NAACP at the Supreme Court, mediated labor conflicts between Jewish workers and factory owners in New York City, and pioneered environmental conservation in upstate New York. But he balked at the idea of suing Ford for libel of any kind. Marshall feared such a move would trigger more anti-Semitism and mark Jews as a racial minority. In a pretrial ruling, the judge had found that Sapiro could not sue for group libel, because Michigan had not passed a group-libel statute. When Sapiro’s personal-libel lawsuit was then dismissed on a technicality after a secret smear campaign by Ford, Marshall breathed a sigh of relief. He seized on the moment to negotiate a public apology in which Ford claimed (falsely) that he had not known his underlings were spreading anti-Semitic calumnies.

Having pioneered the progressive idea of outlawing hatred in the 1910s, a decade later now Marshall swung toward an uncompromising defense of individual free expression. Immigration fears no longer mattered, since the worst had just come to pass. In 1921 and 1924, Congress had imposed sweeping restrictions that excluded eastern-European Jews, along with many other races deemed inferior, from entering the country. Now Marshall feared that in a climate of rising nativism and conservative populism, political progressives might lose out if speech were to be overly regulated in a modern democracy.

Similar reasoning led Marshall’s fellow Jewish lawyer and great rival Louis Brandeis, the first Jewish Supreme Court justice, to write his 1927 opinion in Whitney v. California. In a ruling upholding the conviction of a California woman charged with espousing communism, Brandeis offered an eloquent defense of the moral virtues of the First Amendment.* The solution to offensive speech of all kinds, he wrote, was to “expose through discussion the falsehood and fallacies, to avert the evil by the process of education, [such that] the remedy to be applied is more speech, not enforced silence.”

Neither Ford’s pseudo-apology nor Brandeis’s soaring rhetoric, though, did much to stop the surge of anti-Semitism in American society in the late 1920s and 1930s. Racial populists such as Father Charles Coughlin began to use the new medium of radio to seek out national audiences. Propagandists mastered the art of cheap publishing on a national scale. The most famous of these new hate-merchants was Robert Edward Edmondson, the founder of the Pan-Aryan League and the premier anti-Semitic pamphleteer of his day.

Over the course of the 1930s, Edmondson published hundreds of booklets and newspaper articles, denouncing “Jewish anti-Americanism and Talmudic communism,” “the communistic Jew deal,” and the “invisible government” for destroying American business, media, government, and entertainment. He also repeatedly smeared non-Jews such as Secretary of Labor Frances Perkins, who he falsely claimed was in reality one “Rachel Lazanski” of “Russian Jewish origin” impersonating a New England WASP.

In 1936, Congressman Samuel Dickstein of New York demanded legal action. Mayor Fiorello La Guardia responded by invoking his power as chief magistrate of the city of New York to issue a summons for criminal libel, and then asking the New York County district attorney to take a personal role in the case, suggesting he charge Edmondson with “false, malicious, scandalous, and defamatory libel of and concerning all persons of the Jewish religion.” La Guardia dismissed his critics: “The right of free speech is based on the recognition that those who indulge in it or who claim it as a right must be prepared to be held responsible for their utterances or their writings if they transgress. The remedy is not by suppression or curtailment of speech or writing, but by invoking the law of criminal libel if the statement is not truthful or the motive unlawful.”

American Jews responded to Edmondson’s indictment with great enthusiasm. The Yiddish-language Jewish Daily Forward opined, “The entire population of New York, regardless of race or religion, wholeheartedly welcomes Mayor La Guardia’s swift action against the fanatics and juvenile-delinquents, who spread … social poison, wild race-hatreds, anti-Jewish calumnies, and antisemitism … that incite unlawful acts.” Rabbi Stephen S. Wise, the leader of the American Jewish Congress and a co-founder of the NAACP, showered La Guardia with praise for the “grand thing” he had accomplished. Wise mocked the murmurs of hesitation among the more anxious of his own people, the “sh-sh Jews who, instead of rejoicing over what you have done, are chiefly fearful lest, as they put it, Edmondson has his day in court—as if he had not had it already, through the publication of millions of pamphlets!”

Edmondson’s lawyer defended his client’s writings as “patriotic politico-economic educational analyses, issued under the Constitutional guarantee of free speech and free press.” His client never meant to criticize Jews in the United States or elsewhere, his lawyer insisted, only the true enemies of the American people: “Socialist Jews, Communist Jews, Bolshevist Jews, and Mongol Jews.” There was no case for group defamation, only an instance of legitimate political criticism of the wrong kinds of Jews. To ensure a fair trial, however, he insisted that the judge empanel an all-Aryan jury.

Edmondson never got his all-Aryan jury, or any jury for that matter. The case did not go to trial. Despite their initial eagerness to prosecute, the Jewish civil-rights groups, including Wise’s own American Jewish Congress, the American Jewish Committee, and the National Council of Jewish Women, all summarily retreated as the trial approached. All three submitted amicus briefs petitioning the judge to dismiss the case on the grounds that applying criminal libel in defense of any group was a mistake. In the words of Wise’s own organization, to sanction Edmondson would only make him a “‘martyr’ to the great cause of civil rights … and freedom of speech and of the press.” Better to let an anti-Semite speak his erroneous truth than expand the role of the law in the fight against anti-Semitism. The judge acquiesced and threw out the case. If the injured party itself disavowed the injury, he reasoned, how could it be called a crime?

The outbreak of World War II and the emerging news of the Nazi Holocaust shocked American Jews out of this pattern of ambivalence vis-à-vis group libel. In 1943, Wise’s American Jewish Congress successfully campaigned for a Massachusetts statute criminalizing the publication of “false written or printed material with intent to maliciously promote hatred of any group of persons in the commonwealth because of race, color or religion.” To spearhead its legal efforts, it hired Alexander Pekelis, an Italian Jewish refugee-law professor and prominent early scholar of fascism.

Fleeing Italy for the United States in 1940, Pekelis quickly emerged as a leading practitioner of the “legal realism” school of jurisprudence that emphasized law’s dynamic interaction with society. In the same New Deal spirit, Pekelis viewed law as a constructive tool for modern social reform. Across the early 1940s, he pushed forward a number of ideas for how to combine “individual protection and group action” to stop anti-Semitism. Time and again, he stressed that modern economics had changed the way people thought about law for workers and organized labor. The right to organize workers was necessary because of the power of businesses in the marketplace. Now law could do the same for members of minority groups, who were both individuals and members of a vulnerable segment of society. In a 1945 essay in The New Republic he wrote:

People singled out for attack as a group have the right to defend themselves as a group. This principle has led, in industrial relations, to collective bargaining and has provided a defense against conspiracy charges. The same principle can lead to equally important results in the field of ethnic relations. For instance, the enforcement of antidiscrimination laws should not be left to individual initiative only, but minority organizations should be given the power, analogous to that enjoyed by the unions under the National Labor Relations Act, to file charges of unfair practices.

That same year, Pekelis petitioned the Federal Communications Commission to deny an FM radio station a license to the New York Daily News on the grounds of its “consistent bias and hostility … in its editorial and news columns against Jews and Negroes” and “its readiness to publish irresponsible and defamatory news items.” During World War II, he charged, the Daily News had all but adopted the Nazi line on Jewish malfeasance and warmongering. Far from violating the First Amendment, denying bigotry a media platform would “result in a fuller protection of the basic aims of free speech and free press.”

Pekelis’s argument was echoed in an influential series of early 1940s articles by another law professor, David Riesman. He cast his proposal in terms of the larger struggle of liberalism. “Defamation and the law of defamation have become weapons in the political struggle between democracy and fascism,” he wrote. Why not extend that principle to social groups? “It is only through strengthening the protection of the groups to which an individual belongs that his own values and his own reputation can be adequately safeguarded,” he insisted. “The isolated person is as helpless in the face of systematic defamation by opposing groups … as in the face of concerted economic power.” Relying on the general theory of torts (civil damages), Riesman proposed to give Jews and other minority groups a necessary legal remedy.

The chief obstacle to such a legal move, according to Riesman, was not the legal fine print or free-speech concerns, but “the American heritage of middle-class individualistic liberalism,” which obscured the need for group protections. “Our thinking is still in terms of the ‘individual’ and the ‘state,’ and our law of defamation, such as it is, is conceived of only as a protection against individual injury, as the law of assault and battery is a protection for individual life and limb.” Where there was a political will, as in the case of labor unions, it was possible to construct legal protections for groups in society. The same could be done for Jews and other minorities.

By the end of the 1940s, eight states had enacted statutes to criminalize different forms of group libel. Meanwhile, in 1949, Senator Jacob Javits of New York and Representative Arthur Klein sponsored a bill to create a federal group-libel statute. A legal revolution seemed in the offing. Yet behind all these new laws lurked a question that had dogged similar efforts since the 1910s: Were group-libel statutes even constitutional?

In July 1951, the ACLU petitioned the Supreme Court to hear the appeal of an anti-Semitic, racist pamphleteer in Chicago convicted of violating an Illinois group-libel law. The defendant, Joseph Beauharnais, the president of the White Circle League of America, had published a pamphlet opposing the “the further encroachment, harassment and invasion of white people, their property, neighborhoods and persons, by the Negro.” The great dangers of crime and communism, “which is rife among the Negroes,” he wrote, justified the need for the white race “to assert its natural rights to self-preservation.”

The news that the ACLU would defend Beauharnais broke during the very same week as the Cicero race riot, when a mob of 4,000 white Chicagoans attacked an apartment building that housed a single African American family. In a letter to his ACLU friends, the NAACP’s Walter White questioned the logic of their decision, especially given the fact that Beauharnais had just reportedly led the mob violence in Cicero: “You will remember, of course, Mr. Justice Holmes’s famous edict that the right of free speech does not include the right to shout fire in a crowded theatre.”

Other letter writers did not mince words. “Exactly what, in the name of an all-merciful God, do you gentlemen think you are accomplishing [by defending] … the Chicago monster?” asked Isidor Shaffer of Queens. The ACLU executive director’s reply to both men was a study in condescension: “This is one of those hard choices that people who believe in all civil liberties for everybody are frequently forced to make—in a conflict between free expression and respect for the human dignity of a minority group. In asking you to join us in choosing free expression, we realize that such a choice costs you far more than it costs us.”

The price tag on principle also proved too costly for the Supreme Court. In a close 5–4 verdict, the justices ruled in Beauharnais v. Illinois that the Illinois law was constitutional. Writing for the majority, the court’s sole Jewish justice, Felix Frankfurter, himself a co-founder of the ACLU, laid out the opinion’s reasoning:

If an utterance directed at an individual may be the object of criminal sanctions, we cannot deny to a State power to punish the same utterance directed at a defined group … Long ago this Court recognized that the economic rights of an individual may depend for the effectiveness of their enforcement on rights in the group, even though not formally corporate, to which he belongs. Such group-protection on behalf of the individual may, for all we know, be a need not confined to the part that a trade union plays in effectuating rights abstractly recognized as belonging to its members.

A notable dissent came from Justice Robert Jackson, fresh from his tour as the chief U.S. prosecutor at the Nuremberg trials. “Group libel statutes represent a commendable desire to reduce sinister abuses of our freedoms of expression—abuses which I have had occasion to learn can tear apart a society, brutalize its dominant elements, and persecute, even to extermination, its minorities,” he wrote, adding charitably, “Such efforts, if properly applied, do not justify frenetic forebodings of crushed liberty.” Yet in the end, Jackson worried, such laws would “present most difficult policy and technical problems” of enforcement. Minority groups also had to acknowledge the double-edged sword: “No group interest in any particular prosecution should forget that the shoe may be on the other foot in some prosecution tomorrow.”

Frankfurter dismissed Jackson’s concerns about the logistical challenges and the potential abuse of the statute for censorship. This was merely “the price to be paid for the trial-and-error inherent in legislative efforts to deal with obstinate social issues.” When all was said and done, it would be foolish to avoid reasonable legal efforts “to curb false or malicious defamation of racial and religious groups, made in public places and by means calculated to have a powerful emotional impact on those to whom it was presented.”

Frankfurter’s majority opinion might have ushered in a new era of expanded civil-rights efforts to stamp out anti-Semitism and white supremacy in American society. Though not without its critics at the time, Beauharnais offered a powerful tool to complement the array of other state-level legal efforts to ban discrimination in housing, employment, and education. Moreover, given that the civil-rights struggle had begun to play out on the national political landscape, this law provided a means to check a new wave of Ku Klux Klan and other white-supremacist mobilization. Immediately following the verdict, for instance, an alarmed Gerald L. K. Smith, the notorious Christian-nationalist-crusade leader, wrote to the ACLU, worried that the “terrible decision handed down by the Supreme Court” might yet put his movement out of business. Though he was aware that the ACLU was full of Jewish lawyers, he still counted on its help for his cause: “I do know that it requires a philosophical Jew to defend my right of free speech.”

Smith needn’t have worried about his freedom of expression; many Jewish civil-rights lawyers were on his side. Across the board, Jewish civil-rights organizations greeted Beauharnais with silence. Fearful of the rising tide of McCarthyism, all of the major Jewish organizations declined to seize the opportunity it presented. They opted to stress their all-American bona fides and push liberalism in a different direction, rather than emphasize their minority needs. They wagered that civil libertarianism coupled with formal desegregation would suffice to secure racial and religious equality.

In 1954, Jewish organizations vigorously supported the NAACP in the Brown v. Board of Education case to strike down federal racial segregation. They followed with other state-level anti-discrimination legal initiatives and a vigorous push against religious discrimination by insisting on the larger legal separation of church and state and against school prayer. But one by one, in the 1960s, all the Jewish civil-rights organizations formally renounced their support for group libel as a legal strategy in favor of individual equal protection. Instead, they embraced the landmark 1964 Civil Rights Act, which forbids all discrimination on the basis of race, religion, color, sex, or national origin.

A rising faith in free speech, equal protection, and due process as the best antidotes for racism and anti-Semitism formed the quintessence of postwar American Jewish civil-rights work. There was a compelling logic to this approach at the time. Eliminate prejudice as a whole, treat everyone as individuals, handle hate speech as an individual pathology best fought in the classroom and church pew rather than the courtroom, and anti-Semitism would vanish together with American racism. Fulfilling liberalism’s promise meant making American justice race-blind and faith-blind, not creating new protected categories for what one Jewish activist called “imaginary groups in American society.”

Alongside this philosophical faith in mid-century liberalism, American Jews recognized tactically that defending free speech in maximalist terms could help block the rearguard actions of white supremacy. In 1962, a Montgomery, Alabama, police official sued The New York Times for libel, claiming that he had been unfairly maligned in a paid advertisement by civil-rights groups that accused local police of racial bias. The Supreme Court’s 1964 decision in New York Times v. Sullivan produced the most famous affirmation of the freedom of the press. It solidified as a core tenet of liberal faith the assumption that unfettered free speech would always serve the cause of civil rights more effectively than troublesome hate-speech laws.

But white supremacists and neo-Nazis also took note. Though Sullivan in theory left Beauharnais undisturbed, it signaled to new groups such as George Lincoln Rockwell’s American Nazi Party and the National Socialist Party of America that they had little to fear from the courts. Worse still, it inspired a cynical new tactic on the part of these groups, which began using their freedom of speech to directly target their victims.

In 1977, the National Socialist Party of America declared its intention to march, dressed in military-style uniforms displaying the swastika, through a Chicago suburb full of Jewish Holocaust survivors. Town authorities went to court to ban the march. After both the local and state courts acceded to that request, the ACLU appealed to the U.S. Supreme Court, prompting one of its most famous free-speech rulings. The ACLU dispatched two Jewish lawyers, David Goldberger and Aryeh Neier, himself a child Holocaust survivor, to argue on behalf of neo-Nazi First Amendment rights.

Just as in earlier decades, Jewish civil-rights organizations found themselves internally divided on their response. In the end, the American Jewish Committee, American Jewish Congress, and Anti-Defamation League all reversed their 1960s policy. Each submitted briefs calling, to various degrees, for modest prior restraints on the neo-Nazi provocation. Still, they focused narrowly on the use of incendiary symbols and the event’s location. “The flaunting of the swastika or a Nazi uniform,” said the American Jewish Congress official Naomi Levine, “is not an expression of a constitutionally protected idea … [but] a provocative and insulting symbol which by its very nature inflicts injury and tends to incite an immediate breach of peace.”

The tactics of these Jewish groups reflected a desire to reconcile their proud tradition of civil libertarianism with an anguished awareness that violent anti-Semitism had not disappeared from society. The old tools still applied; they just should be used with utmost discretion. This time, however, the Supreme Court chose to view hate speech not as group defamation or inciteful “fighting words” but simply as insults to Jewish feelings: The “public expression of ideas may not be prohibited merely because the ideas are themselves offensive to some of their hearers.”

Skokie marked the beginning of a new free-speech orthodoxy in American civil-rights jurisprudence. Over the course of the 1980s and 1990s, nearly all of the state group-libel statutes still on the books were repealed. A wave of progressive hate-speech codes floated in colleges and universities were consistently ruled illegal by courts. Other related anti-bias criminal statutes were deemed unconstitutional. After Skokie, courts began a march toward maximalist views of free speech.

American Jewish civil-rights groups, meanwhile, struggled to balance their proud fidelity to the First Amendment with a growing unease at the persistence of anti-Semitism. Neo-Nazi hate groups remained active, and politicians such as David Duke suggested the potential for such ideology to seep into mainstream electoral politics. The far left revealed its own brand of anti-Semitism as well, centered principally on classic tropes of exaggerated global Jewish financial and political power, along with a venomous anti-Zionism that often bled into anti-Semitism. Still other versions came directly from the Reverend Louis Farrakhan and the Nation of Islam, which targeted Jews in grossly anti-Semitic terms as racial enemies, even to the point of finding common cause with white supremacists.

These and other controversies, many centered on college campuses, tested the limits of Jewish faith in free speech as an absolute good. In search of a solution, Jewish civil-rights groups opted to privatize the battle against anti-Semitism. Across the 1980s and 1990s, they conducted private intelligence surveillance on extremists and promoted educational initiatives to combat extremism and anti-Semitism. The soft instruments of public-awareness campaigns, tolerance training, and informal advocacy replaced the harder force of legal action.

The privatization of Jewish civil rights produced one other strategy: individual civil lawsuits to bankrupt hate groups. In 1971, a white southern businessman and lawyer named Morris Dees Jr. joined with his Jewish law partner Joseph Levin and the African American activist Julian Bond to launch the Southern Poverty Law Center. Their novel approach was to use civil tort law to combat racism and anti-Semitism. In 1979, the SPLC sued several Ku Klux Klan and neo-Nazi groups for civil damages for racist attacks on individuals, winning multimillion-dollar jury verdicts. A new idea was born. Rather than task the government with silencing extremists, private citizens could simply take matters into their own hands by pursuing their material assets after the fact. The effect would be the same. Putting hate groups out of business would ensure that they could not speak freely anymore.

During the 1980s and 1990s, the SPLC grew into a multimillion-dollar nonprofit behemoth. It took advantage of a war chest filled via direct-mail fundraising and its own private intelligence work to launch a series of successful high-profile lawsuits on behalf of victims of domestic terrorism and violent hate crimes. That approach scored some wins. But it removed the burden of litigation from the government—as well as the responsibility to prevent transparently ideological abuses of free speech.

The reliance on private torts to do the work of public justice led over time to a technocratic, free-market approach to combatting extremism. Anti-Semitism and racism became economic problems to be solved through seizing assets after the fact rather than checking hate speech before it could inflict its damage. Most crucially, the regnant free-speech orthodoxy has proved increasingly ineffective in the face of a newly empowered alt-right that makes sophisticated use of digital publishing, social media, and public spectacle to market its own ideology. The whack-a-mole approach to defunding hate is unlikely to achieve the same effect as comprehensive public legal statutes. Nor will politicians’ demands for Facebook, Twitter, and other social-media companies to police their own users serve as effectively as constitutional laws that draw a clear line between legitimate expression and hate speech.

Early last spring, six months after the neo-Nazi march on Charlottesville, the U.S. Congress drafted the Anti-Semitism Awareness Act. From its name many might assume the legal measure to be intended to counter the spread of white-supremacist anti-Jewish hatred. Instead, the Anti-Semitism Awareness Act, like other related congressional bills and a bevy of new state-level statutes, is primarily intended to protect Jewish civil rights on college campuses from far-left anti-Semitism connected to the Israeli-Palestinian conflict and the BDS, or Boycott, Divestment, and Sanctions, movement. The BDS campaign is a loose coalition of activists who seek to exert pressure on Israel’s government in the context of the Israeli-Palestinian conflict, much like anti-apartheid activists did to South Africa, by ostracizing Israel and encouraging corporations to cut ties and investments. Its very vagueness about its end goals and often demonizing rhetoric have led many to conclude that its ideology crosses over from political critique into blatant anti-Semitism.

The draft bill has won acclaim from many Jewish communal organizations, including the Anti-Defamation League, Hillel International, and the American Jewish Committee. Yet other progressive Jewish groups, along with the ACLU, have denounced it as politically motivated overreach that will criminalize legitimate public debate about the Israeli-Palestinian conflict and U.S. foreign policy.

To many on the progressive left, efforts to ban offensive speech surrounding Israel and Zionism amount to political censorship stemming from a conservative political agenda. That’s why many progressives, Jews and non-Jews alike, dismiss new legal initiatives against anti-Semitism as disingenuous, illiberal moves motivated solely by Islamophobic, pro-Israel politics or gross pandering to elite GOP donors and evangelical Christians. This cynicism is compounded by a sense that American Jews do not require this sort of legal protection because they are manifestly less vulnerable than people of color and sexual minorities. At its root, moreover, the left displays a curious binary view of the law in which hate speech and free speech are completely separate phenomena, with no area of potential overlap—and a similarly naive assumption that BDS can never be anti-Semitic.

Conservatives, meanwhile, fear that left-wing anti-Semitism cloaked as anti-Zionism threatens Jews the most. They detect a common anti-Jewish thread running through the leadership of some of the core institutions at the heart of the contemporary left, including the Women’s March, the Black Lives Matter movement, the new progressive cohort in Congress, and the new cluster of anti-Zionist Jewish-youth movements. Yet their choice of solution is an odd one. For decades, conservatives have decried political correctness, campus speech codes, and identity politics. Now, however, they urge a renewal of older kinds of group legal protections precisely to meet the new dangers of anti-Semitism, particularly those that hail from the left. The First Amendment is apparently no longer quite as sacred as it used to be to them—at least not when it comes to anti-Zionism.

What neither side seems inclined to acknowledge is that another, far deeper issue is at stake—and a potential way forward. Protecting American Jews today may require revisiting legal ideas that were repeatedly proposed and abandoned by earlier generations of Jewish lawyers in their quest for civil rights. Group-libel laws hold the potential to protect Jews and other minorities from incitement and other dangerous speech that poses a new threat. They can fill the space between free speech and hate speech with a comprehensive, uniform set of laws to settle controversies otherwise reduced to media circuses and political polemics.

American Jews long ago pioneered new legal tools to combat hate from spreading through the national media, stop its entry into mainstream politics, and check its threat to minority communities. They, too, faced a world of disruptive media, populist politics, and global anti-Semitic currents. Those ideas and experiments remain available today as options to confront rising anti-Semitism and other forms of hatred across the political spectrum.

To access those legal instruments, however, will require accepting some hard truths about the place of Jews in American society and exploding some myths about the First Amendment. Progressives must accept that Jews face real threats and deserve legal protection. Conservatives must come to terms with the fact that not all offensive political speech about Zionism and Israel is anti-Semitism. Moreover, the best way to ban discriminatory behavior is not by singling out American Jews or the state of Israel for special protection, but by drafting laws that address all forms of bias equally. And everyone needs to think again about the proper balance between free speech and hate speech in American civil-rights law.

We live in an era in which what was once thought impossible has become possible. Generations of constitutional lawyers assumed that the right of free speech could never be applied to private corporations. Then came the Supreme Court Citizens United v. FEC decision. For decades, Roe v. Wade was considered settled law. Now conservatives have set their sights on overturning it. For nearly a century, law professors decried President Franklin D. Roosevelt’s 1937 attempt to “pack the Court” by expanding the size of the Supreme Court. Now progressive lawyers have begun to refloat this radical idea as a legal solution to the larger ills of American politics. All of these developments should remind us that constitutional law is a fundamentally open-ended project subject to ceaseless debate and constant reinterpretation.

When it comes to civil rights, the arc of the moral universe does not bend toward justice all by itself; humans bend it. Their hands can shape law only in the directions that their minds can imagine. That mental exercise begins with historical retrospection. If we look backwards with opened eyes, law’s forgotten past can suggest new ways to rethink its present and reenvision its future.

* This article originally stated that the Supreme Court had overturned the conviction in Whitney v. California. In fact, the Court upheld the conviction.

This article is part of “The Speech Wars,” a project supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press, and the Fetzer Institute.



Last week, the College Board announced a long-overdue innovation: It will try to put students’ SAT scores in context by providing colleges with an adversity measure that summarizes—on a scale of one to 100—the disadvantages that students suffer when they grow up in troubled neighborhoods and attend high-poverty schools.

But many in the chattering classes immediately pounced on the idea—some because the score does not explicitly take account of an applicant’s race and the particular challenges that may come with it, and others because they see it as a sneaky way of enshrining racial quotas. The adversity score’s wonkier critics faulted it for trying to reduce the complexities of a student’s circumstances—which could include a parent’s alcoholism or the premature death of a sibling—to a single number. A score based on school-wide or neighborhood-wide data, skeptics argued, could never accurately capture the gist of any one student’s life.

I have studied aspects of college admissions for decades. While the adversity measure was in development, I myself attended four meetings at the College Board to discuss the concept. I recommended, based on extensive research, that socioeconomic disadvantage be included at the family, neighborhood, and school levels. The College Board ended up using only the last two of the three.

Nevertheless, even an imperfect adversity score is better than failing to account for the difficulty so many students overcome. Research from Anthony Carnevale of Georgetown University has found that the most disadvantaged students, on average, score a whopping 784 points lower on the SAT (out of a possible 1600) than the most advantaged.

Many decades into the controversy over affirmative action in college admissions—and with a conservative Supreme Court poised, many believe, to overturn the practice—an adversity score offers colleges some way to acknowledge what everyone knows: A student who scored 1200 on the SAT despite having grown up in a high-crime neighborhood and attending high-poverty schools has more long-run potential than a student who earned 1200 while having access to the best private schools and paid tutors. In the end, even rough measures of socioeconomic disadvantage are better than no measure at all.

For all the controversy around affirmative action, most Americans think students who have thrived despite stiff obstacles deserve extra consideration. In a 2018 national poll by the Boston-based public broadcaster WGBH, only 24 percent of respondents supported using race as a factor in admissions, but 58 percent said colleges should take account of “overcoming hardships such as poverty or health problems” as an admissions factor.

The College Board’s new adversity score helps quantify for admissions officers what has been a relatively vague and amorphous sense of what obstacles a student has faced in achieving her academic record. The score is based on 31 neighborhood and school socioeconomic factors, such as the median family income and adult educational level. It does not count race, the College Board official Connie Betterton told The New York Times, because the use of racial preferences has been banned in several states where the SAT is used (including large states such as California and Florida). In an interview, Betterton told me that the adversity score omits any consideration of a student’s own financial circumstances, because to incorporate that could complicate some universities’ need-blind admissions policies.

One way or another, though, colleges should be giving greater consideration to disadvantaged students who do fairly well despite the odds. In a study of 13 selective colleges that William Bowen and his colleagues published in 2005, the researchers learned that, with the same academic profile, a student’s chances of admission increase 30 percentage points if she is a recruited athlete, 28 percentage points if she is an underrepresented minority, 20 percentage points if she is a legacy, and not at all if she comes from a low-income family. A just-released Pell Institute study found that “representation of students from low-income families at the nation’s most selective institutions is low, and relatively unchanged from 20 years ago.”

Hence the promise of an adversity score. A study of a pilot program involving eight selective universities suggests that when admissions officers have that information, they are more likely to admit disadvantaged students.

On the one hand, critics on the left are wrong to say that race is missing entirely from the College Board’s adversity score. It is precisely because racial discrimination has been a central feature of American history—and continues to bedevil us today—that African Americans and Latinos are disproportionately disadvantaged and therefore will disproportionately benefit from the adversity score. For example, just 6 percent of white youths live in neighborhoods with a more than 20 percent poverty rate, but 66 percent of black youths live in such neighborhoods.

On the other hand, critics on the right are wrong that the adversity score is just a disguised racial preference. Heather McDonald of the Manhattan Institute called the adversity score “a backdoor to racial quotas in college admissions.” But while it is true that students of color will disproportionately benefit from taking economic and educational disadvantage into account, the subset of individual students admitted will often be very different. In my personal capacity, I am an expert witness in a lawsuit challenging racial preferences at Harvard. My research has found that the proportion of black and Hispanic students who are economically advantaged—that is, members of underrepresented minorities from relatively wealthy families—would drop from 71 percent under the status quo to 29 percent under a system of socioeconomic preferences.

The widespread use of adversity scores could prove politically significant. Whereas racial preferences divide the progressive coalition by reminding working-class whites and underrepresented minorities of their differences, socioeconomic preferences would remind them of their commonalities.

The ultimate benefit of the adversity score is that it provides a quantitative counterpoint to the SAT itself. The SAT has a talismanic character—to the point that people remember their score 30 years later—in part because of its seeming precision. Having a single adversity score to counterbalance the SAT is a healthy corrective.

It is certainly true that not all obstacles can be quantified, which is why it would be crazy for universities to admit students based solely on the SAT and adversity score. They should also look at extracurricular activities, leadership, and essays that outline other obstacles a student has faced. But whatever the flaws of the College Board’s adversity score might be, it’s a number that admissions officers will have to see, and it will inevitably change the way they read the rest of an applicant’s file. It’s not as though, in the absence of such a score, colleges have done a good job of admitting substantial numbers of students who have overcome tough odds. At the least, the College Board is offering schools a simple, straightforward way to give underprivileged applicants a chance.





Subscribe to Crazy/Genius: Apple Podcasts | Spotify | Stitcher | Google Play

Ten years ago, “Move fast and break things” was the clarion call of the world’s tech giants. Well, they moved fast and broke stuff, alright. Lots of stuff. Whether it’s Facebook privacy scandals, YouTube’s radicalization of the far right, or China’s brutal use of surveillance gadgetry, digital technology seems to be a relentless force for greed, bad faith, and tyranny these days. Let’s talk about it.
“Unbreak the Internet” is the theme for the third season of Crazy/Genius, The Atlantic’s podcast on tech and culture. Over the course of eight weeks, we’ll expose the surveillance states in both western China and East New York, ask if digital platforms are an accelerant for right-wing nationalism, tell you why privacy is the climate-change crisis of the internet, and more.
The third season of Crazy/Genius returns on May 9.



In my neighborhood, there are a number of synagogues and churches. The church doors are open, welcoming all. The synagogues have armed guards, fences, door codes, and people who will stop strangers as they enter. Ostensibly these are welcomers, but their real job is to check whether these strangers wish to do the people inside harm. Our children look at the church across the street and recognize that, while Jews need protection, the kids there do not.

The attack on a Chabad synagogue in Poway, California, has reminded Jews—yet again—that their houses of prayer are not safe spaces. But for the fact that the assailant’s gun jammed, the attack could have been far worse than the October attack in Pittsburgh, which claimed 11 lives.

In the wake of the Poway attack, law-enforcement officers, government officials, and the media kept stressing that the gunman had acted alone. They may have been trying to reassure the public, and in the narrowest technical terms, they may have been correct.

But this assailant was no lone wolf. He is part of a nexus of haters. The shooters in Charleston, Pittsburgh, Christchurch, and now Poway all relied on similar language and memes. The Christchurch and Poway shooters both posted manifestos prior to their rampages. They referred their social-media followers to some of the same websites and offered similar justifications for their actions.

These gunmen may not have received direct orders from a leader, but social media have eliminated the necessity for a leader to issue orders, facilitating their radicalization. And though there is no reason to think they’ve ever met, they are deeply connected, one with the other.

White supremacism—which has at its core anti-Semitism—is nurtured by the extremist rhetoric that has become almost commonplace within the United States. It is growing and flourishing. Had this act of terror been committed by an individual influenced by ISIS or al-Qaeda, it would quickly have been labeled terrorism. Government agencies must recognize white-supremacist attacks as a form of domestic terrorism, and treat them as such.

Our president’s claim that these attacks are coming from a “small group of people” and present no “rising threat” is contradicted not only by Charleston, Poway, and Pittsburgh, but also by recent assessments by law-enforcement entities. Both the FBI and the Department of Homeland Security have warned of the threat of violence from white supremacists. In recent years, white supremacists have been responsible for more homicides than any other extremist group.

The federal government needs enhanced powers to regularly assess and share data on the activities of these individuals and groups. Federal law-enforcement agencies must be empowered to regularly assess this threat and train officers on how to address it.

But anti-Semitism itself is an equal-opportunity hatred, even if the violence it sparks is not evenly distributed. It also comes from the political left. On my own campus, a pro-Palestinian group recently called for the boycott of all Jewish groups, including Hillel and Chabad. That’s anti-Semitism.

In truth, when it comes to anti-Semitism, the right and the left often find common ground. The far right talks about the federal government as ZOG, the Zionist Occupation Government; the left sees AIPAC, the American Israel Public Affairs Committee, as a behemoth of unbelievable proportions, driving American policy in ways that are antithetical to America’s best interests. This absence of a dividing line between left and right when it comes to anti-Semitism was evident when the former Ku Klux Klan leader David Duke clicked “like” on Representative Ilhan Omar’s tweet claiming that American support of Israel is “all about the Benjamins baby.”

How can this hatred find such hospitable circumstance at diametrically opposed ends of the spectrum? Part of the answer lies in the ubiquitous nature of anti-Semitism. Jew hatred can best be compared to a herpes virus for which there is no cure. It is adaptable and thrives in a welcome environment. Anti-Semitism flourishes when anti-Semites feel emboldened and think that what they are doing will be welcomed and not looked upon askance. That is true of people on the right and the left.

Certainly the government must act, but in the interim, what can we as individuals do? Though it sounds prosaic, we must speak out against the rhetoric that gives rise to and eventually legitimizes such acts of hate. We must shame people who, though they may never, ever contemplate acting on their hate and prejudices, express Jew hatred. And, above all, we must be willing to criticize—directly and not gingerly—our political allies when they cross the line into anti-Semitism.

Acts of terror never begin with actions. They begin with words. We must place this kind of talk well outside the pale of legitimate discourse. There is nothing fine or legitimate about these views.

For the past seven decades, it has been shameful to be an open anti-Semite. We assumed that, after the Holocaust, the world recognized where anti-Semitic rhetoric can lead. We were wrong.

We must strive to banish open anti-Semitism so that we will no longer need armed guards screening worshippers as they enter their synagogues.



Alexandria Ocasio-Cortez is in the linguistic hot seat yet again. This time, she is taking heat for accusing Donald Trump’s administration of operating “concentration camps” on the southern border. Some people, it appears, would prefer that she refer to them as “tender-age facilities,” as the administration has proposed. Or, at least, some believe it is below the belt for Ocasio-Cortez to use a term that implies a parallel between Donald Trump and Adolf Hitler.

However, the idea that Ocasio-Cortez is coarsening public discourse in all its recreational nastiness is based on an almost willfully immature take on how language works. In general, the right is acutely aware that a great deal of communication is based on metaphor and playfulness. For Ocasio-Cortez’s critics to suddenly pretend that language is a matter of blankly stating observations—à la the foreign-language textbook’s “My uncle is a lawyer but my aunt has a spoon”—is a high-school debate-team feint.

Many on the left have observed that the notorious homicidal concentration camps of the Third Reich are not the only kind of concentration camp—that the term can also refer to sites that have been holding pens, such as for the Japanese in this very country at the same time that Jews were being murdered in Europe.

However, Ocasio-Cortez’s defenders are being a bit coy here, turning a blind eye (or ear) to her using the resonance of Auschwitz and Bergen-Belsen in her choice of words. The reason the term concentration camp is so rhetorically effective is not, let’s face it, due to its reference to places like the Soviet Gulag. Just as many people of late use white supremacy as a stand-in for racism because it summons images of lynching and burning crosses, one says “concentration camp” in order to summon grisly black-and-white images of horror from 1940s Europe.

The right cries foul—as did the left when Sarah Palin was cawing “Don’t retreat, reload” back in 2011, even in the wake of the shooting of Representative Gabrielle Giffords. Republicans at the time expected all to understand that this was simply colorful, metaphorical language, not a literal incitement to violence. They defend Trump’s ravings today on the same grounds. He has fondly referred to certain “old days” when a protester at one of his rallies would have been “carried out on a stretcher.” And he has suggested that he would pay the legal bills of whoever put him there. Never mind the more lexical violence, such as referring to protesting black athletes as “sons of bitches.”

Anyone expressing outrage is told to read this kind of expression as Trump simply “being real,” part entertainer and part president, someone who is just plain hard to rein in. We are told he is joking and to get over ourselves.

Well, okay then—but surely the right can let Ocasio-Cortez get away with implying certain parallels that are hard to miss between, yes, fascism and Trump’s behavior. We have no reason to suppose Trump desires to herd Mexicans and Central Americans together and put them to death. However, we have every reason to see his actions and statements as manifestations of the kind of ideology that has led to horrors of that kind. Ever floating, if not spelling out, the idea that violence is a permissible means to a glorious national end; the cult of leadership Trump encourages; the suggestion that the openly bigoted members of the alt-right are essentially good people whose views constitute a legitimate counterpoise to those who combat racism—only denialism explains how anyone could not see glimmers of likeness between Trump and Messrs. Hitler and Mussolini.

Add to this the utter heartlessness with which the Trump administration has penned people into spartan facilities, blithely separating small children from their parents, and depicting the people themselves as sinister, marauding aliens. The term tender-age facility qualifies, here, as exactly the kind of Orwellian language we associate with the fascist leaders of old. As such, the term concentration camp would seem quite admissible, when we consider that language is used to convince as much as to merely observe.

We can accept that “Don’t retreat, reload” isn’t always a command to shoot people, and that “I’ll pay the legal fees” if someone punches someone else in the face isn’t always a command to punch someone in the face. But then we must also accept that “concentration camp” harks back to the Nazis without exactly implying that Trump is literally pulling a Hitler. If the right can’t take what it dishes out, it might reconsider its comfort with metaphors of violence. In the meantime, the Trump administration’s “tender-age facility” will be, quite justifiably, Alexandria Ocasio-Cortez’s “concentration camp.”

This article is part of “The Speech Wars,” a project supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press, and the Fetzer Institute.



On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.

But whether you believe Ocasio-Cortez’s terminology was appropriate or offensive, the deeper question is why it provoked such a ferocious debate. The answer: Because for the first time in decades, the left is mounting a serious challenge to American exceptionalism.

American exceptionalism does not merely connote cultural and political uniqueness. It connotes moral superiority. Embedded in exceptionalist discourse is the belief that, because America has a special devotion to democracy and freedom, its sins are mostly incidental. The greatest evils humankind has witnessed, in places such as the Nazi death camps, are far removed from anything Americans would ever do. America’s adversaries commit crimes; America merely stumbles on its way to doing the right thing. This distinction means that, in mainstream political discourse, the ugliest terms—fascism, dictatorship, tyranny, terrorism, imperialism, genocide—are generally reserved for phenomena beyond America’s shores.

A half century ago, Vietnam so radicalized the American left that it seriously challenged these semantic boundaries. Exceptionalist assumptions underlay America’s rationale for war: The North Vietnamese were Communists; Communists were totalitarians; totalitarians committed aggression, as Hitler had in the 1930s. Thus, Hanoi was the aggressor in Vietnam, not the freedom-loving United States.

The anti-war movement inverted this moral logic. In the 1969 book that helped make him famous, American Power and the New Mandarins, Noam Chomsky argued that “by any objective standard, the United States has become the most aggressive power in the world.” Invoking some of the most notorious fascist crimes of the 1930s and 1940s, the anti-war leader Jerry Rubin declared, “Vietnam is the Guernica, the Rotterdam, and the Lidice of the 1960s.” This antiexceptionalist discourse—which denied America’s moral superiority over the adversaries it had long contrasted itself against—even penetrated the Democratic Party. In 1971, George McGovern—who the Democrats would nominate for president the following year—called Richard Nixon’s bombing of Southeast Asia “the most barbaric act committed by any modern state since the death of Adolf Hitler.”

But when the anti-war and other protest movements of the 1960s faded, so did their challenge to exceptionalist language. By the 1980s, Democrats were playing catch-up to Ronald Reagan’s flag-waving patriotism. Exceptionalism was further bolstered in the 1990s, when the fall of the Soviet Union and the seemingly global embrace of American-style democracy and capitalism appeared to reaffirm the fundamental superiority of America’s political system. During the Barack Obama years, questioning American exceptionalism was considered a career-imperiling transgression. When Republicans questioned his commitment to the creed, Obama in 2014 replied, “I believe in American exceptionalism with every fiber of my being.”   

In recent years, however, a resurgent left fueled by an influx of Millennial voters has launched a new challenge to exceptionalist discourse. Partly, it’s because a higher percentage of Millennials are people of color, who generally look more skeptically on America’s claims of moral innocence. Partly, it’s because the financial crisis has cast doubt on whether America’s economic model is preferable to those practiced in other nations. Younger Americans—a majority of whom embrace “socialism”—believe it’s not. Most of all, the challenge to exceptionalism is a response to Trump.

The generational divide is evident in polls. A 2017 Pew Research Center survey found that Americans over the age of 65 were 37 points more likely to say the “U.S. stands above all other countries in the world” than that “there are other countries that are better than the U.S.” Americans under 30 split in the opposite direction. By a margin of 16 points, they said some other countries were better. A similar divide separates liberals and conservatives. While conservatives affirm America’s superiority by a margin of almost 10 to one, liberals reject it by more than two to one.

These numbers help explain why left-leaning politicians and commentators up and down the age spectrum have grown more willing to challenge the linguistic conventions that traditionally reserved certain epithets for America’s adversaries. A few years ago, commentators rarely evoked the specter of American “authoritarianism.” Now it’s commonplace. Books such as George Orwell’s 1984 and Sinclair Lewis’s It Can’t Happen Here  hit the best-seller lists after Trump’s election. Anti-Trump activists began calling themselves “the Resistance,” a term that, by evoking the French or Polish Resistance to Nazism, implies opposition to a tyrannical regime in the United States.

With his embrace of foreign authoritarians and his cultivation of conservatism’s xenophobic and racist fringes, Trump has become a galvanizing figure for the left, which for the first time since the 1960s has begun regularly evoking the specter of American “fascism.” Ocasio-Cortez refers to Trump’s “fascist presidency.” In a video last year, Bernie Sanders quoted a scholar who accused Trump of “flirting with fascism in the open, in broad daylight.” This week, the former Obama speechwriter Ben Rhodes described parts of Trump’s kickoff reelection speech as “indistinguishable from fascist rhetoric.”

The new prominence of the “antifa” movement also testifies to this linguistic shift. The term—which is shorthand for “antifascist activists”—comes from Europe, where communists and anarchists waged street battles against fascists in the 1930s, and against neo-Nazi skinheads in the 1970s and 1980s. But when anti-skinhead activists began Americanizing the movement in the 1980s, many adapted the term: “antiracist action.” Fascism didn’t seem like an American problem. That’s no longer the case. Leftist street activists now embrace the term antifa, and the movement has grown dramatically under Trump.

In their antiexceptionalist turn, Trump-era progressives aren’t just sounding alarms about authoritarianism and fascism in the United States today; they’re also reinterpreting the American past. New scholarship has, for instance, muddied the distinction between German Nazism and early-20th-century American white supremacy. The Yale Law School Professor James Whitman’s 2017 book, Hitler’s American Model: The United States and the Making of Nazi Race Law, has gained favorable attention in The New Yorker, The New York Times, The Washington Post, and The Atlantic. After then–Attorney General Jeff Sessions declared that last year’s Pittsburgh synagogue shooting was “utterly repugnant to the values of this nation,” my Atlantic colleague Adam Serwer excavated the work of World War I–era racial theorists such as Madison Grant to show that the “seed of Nazism’s ultimate objective—the preservation of a pure white race, uncontaminated by foreign blood—was in fact sown with striking success in the United States.”

This willingness to equate American white supremacy with the barbarism that occurs in other countries has also shaped the way the left describes terrorism. In past decades, the term was reserved almost exclusively for America’s enemies, particularly in the Muslim world. Now it’s become common, not only among leftist commentators but among Democratic politicians, to apply the term to violence committed by native-born white Americans. “America’s greatest terrorist threat?” asked Representative Tom Malinowski of New Jersey in an op-ed last month. “White supremacists.”

Ocasio-Cortez’s comment about concentration camps is only the latest example of this broad challenge to American exceptionalism. She didn’t claim that Trump’s detention centers are the equivalent of Auschwitz. But she denied that America is a separate moral category, so inherently different from the world’s worst regimes that it requires a separate language. On Tuesday night she retweeted the actor George Takei, who wrote, “I know what concentration camps are. I was inside two of them, in America.” This was another act of linguistic transgression. When remembering the detention of Japanese Americans during World War II, Americans have generally employed the term internment camps—largely, the historian Roger Daniels has argued, to create a clear separation between America’s misdeeds and those of its hated foes.

Ocasio-Cortez and others on the Millennial-led left are challenging that separation now. They are challenging not only the physical and legal barriers that Trump is erecting against immigrants entering the United States, but also the conceptual barriers that American exceptionalism erects against seeing the United States as a nation capable of evil. And for Ocasio-Cortez’s critics, removing those ideological barriers is every bit as frightening as allowing migrant caravans to pass unimpeded across the Rio Grande.





Subscribe to Crazy/Genius: Apple Podcasts | Spotify | Stitcher | Google Play

Instagram influencers might be the most mocked professionals on the internet. But look closer, and they’re not just a crucial part of online retail. They’re a symbol of the future of work—independent, passionate, and economically vulnerable.

In the latest episode of Crazy/Genius, produced by Patricia Yacob and Jesse Brenneman, we speak to several influencers and consult two people who study them most closely— the Atlantic reporter Taylor Lorenz and the Cornell University professor Brooke Erin Duffy. Highlights include:

(Subscribe here.)



The sultan’s hand felt soft and gentle, more suited for a moisturizer commercial than for participating in a public stoning. By the official count, the sultan of Brunei had shaken tens of thousands of hands in the previous two days, and I worried that by the time his hand shook mine, it would be blistered or leathery. But absolute monarchs are different from you and me, and the sultan of this oil-rich Southeast Asian city-state was different dermatologically as well. When I arrived at the front of the receiving line and squeezed the royal hand, lightly, I thought of Curley in Of Mice and Men, who wore a “glove fulla vaseline” to keep his hand “soft for his wife.” (Wives, I thought, in his case. The sultan has had as many as two at a time.)

The sultan, Hassanal Bolkiah, recently attracted fury and denunciation by instituting death by stoning as punishment for male sodomy. (The prescribed punishment for sexual acts between women is less harsh.) He had foreshadowed this policy years earlier but delayed implementing it until April. Within weeks, he had reversed himself, or at least promised that he would delay the change until after the month of Ramadan. It remains delayed. I met him during last year’s open house, an annual three-day event when any man may come to the sultan of Brunei’s palace, stand in line, and shake his hand and the hands of about a dozen other members of the royal family.

Tens of thousands of handshakes in two days means less than a second per handshake. I figured in that time, I could bleat a single syllable of dissent from his sodomy policy. For some reason I spent my one syllable saying “Hi,” and got a quiet “Hello” in response before being hurried along to shake the hands of his brother and sons. Within seconds I had clasped my way through the entire receiving line, and been led to a large hall where workers gave me a tastefully wrapped fruitcake and a photograph of the sultan as parting gifts.

No politician in the United States receives adulation in quite this ritualistic way. There are rallies, adoring crowds, MAGA hats, and HOPE T-shirts. But our system is designed to discourage and prevent the courtly obeisance that happens at least annually in Brunei. Here it is understood that no politics exist except at the pleasure of the sultan, and every freedom depends on his willingness to grant it. The rally or ritual is not an ornament on the system, but a celebration or acknowledgment of the system itself, or himself. One thing you get from a nod and a weary handshake, even just once a year: a chance to look a sovereign in the eye, and confirm and obtain a physical connection to assure you that the will to whom you have surrendered remains, at least three days a year, earthbound and human. Every other day of the year, he is one of the richest men on Earth. But briefly he stands on your level.

When I was in Brunei, I heard various defenses of the sodomy policy, which came down to an assertion that the sultan rules justly, and that he is a man of honor, proud of his country’s modernity and not at all keen to cast the first stone. And in the political culture of an absolute monarchy, the personal proclivities of the sovereign are pretty much what you have to go on. If a law mandating the execution of gays were passed today in the United States (as some would like), I would see no alternative but to fight against my government. In a country where a man is sovereign, and the laws are merely an extension of his will, it might be possible that his will differs from the straightforward reading of his policy, and that he expects and hopes to stone no one at all.

Other defenses were familiar to me from other Islamist societies that criminalize gay sex: Sharia law requires certain punishments for certain crimes, and sodomy has historically been one of them; the sultanate probably won’t stone many people anyway, because potential sodomites will be deterred or driven so far underground that they’ll never be caught; and the sultan is getting older—he is now 72—and we should not be surprised that as he nears his meeting with God, he will begin setting his country in order, like a drill sergeant preparing his barracks for an inspection. He is famous for his playboy exploits, and now he is in a period of atonement.

The history (and practice) of Islamic law on sodomy isn’t as unequivocal as one might think. A few Muslim jurists have argued that because sodomy is not vaginal sex, it would be wrong to extend the logic of punishment for unlawful vaginal sex (called zina, which is generally punished with stoning) to other acts. Most Muslim scholars, including jurists from the school of Islam officially practiced in Brunei, have historically called for execution. But the standard of evidence has typically been high enough to prevent punishment in all but extremely overt cases, requiring either four witnesses or a public and unforced confession. And of course many Muslims have no interest in whipping, burning, or stoning sodomites at all.

The decision to kill gays as a matter of state policy, however abortive and hedged, is not one that lends itself to charitable interpretation from those who consider themselves broadly liberal. And indeed I find all these hedges as risible as they are sincere. They sound like cognitive dissonance: loyalty to a religion and to a sovereign, mixing uncomfortably with a cosmopolitan moral sense that says killing gays means killing gays, and is abhorrent under any circumstance. That is what I believe.

But the sultanate of Brunei is, by the standard of, say, Saudi Arabia (let alone the Islamic State), liberal. An unenforced law against homosexuality is better than a zealously enforced one, and in some cases it could conceivably be better than no law at all—if it persuades religious conservatives to ease up and compromise in other spheres. Call this the methadone theory of political Islam: If you administer a milder form of Sharia, you satisfy an appetite that might otherwise lead to a more sinister form of it. Non-Muslims who encourage indulgent attitudes toward the Muslim Brotherhood in Egypt, or Recep Tayyip Erdoğan’s AK Party in Turkey, or Sharia implementation in Aceh, Indonesia, tacitly endorse this theory.

And in Brunei, the theory may not be wholly naive. The sultan is getting old might be another way of saying: This is a phase, and it will pass when he does. Brunei resembles Miami more than it resembles Raqqah. It has swimming pools and polo grounds and nice sushi restaurants on the water. When fanatics are present, and looking around for someone to stone to death, you can feel the aggression in the air. I did not feel that in Brunei. If any country can be trusted not to stone gay people, while nonetheless demanding and reserving the right to do so, perhaps Brunei is it.

I would not recommend that gays in Brunei stick around to find out. Those with no option to leave will have to stay in the shadows. Unenforced laws can suddenly become enforced when convenient, and like laws against blasphemy, they tend to be invoked to humiliate and ruin people who are vulnerable and unpopular for other reasons. But observation of this handshake ritual did make me pause before reaching conclusions about the political culture I presumed to judge.

Behind me in line (as a Westerner and an acquaintance of high-powered Bruneians, I was allowed to cut to the front), I saw huge throngs of regular Bruneians and poor foreign laborers waiting behind cordons and dressed in their best attire, which in the case of the poor was sometimes modest. The sultan meets with his subjects during other parts of the year as well, and they seek favors and redress from him, because under this system, you can hope that he will let the rules slide, if the alternative is to enforce a manifestly unjust law.

In the United States, we have to change the law. In Brunei, one can hope to change the man whose word is the law. When ordinary citizens petition the president of the United States for the suspension of ordinary rules for their benefit, we call the process corrupt. In Brunei, it is the only process that exists, and every now and then it breaks in one’s favor. Gays and their allies, including the businesses who support and employ them, might consider whether the odds of a favorable break are good enough to merit continued work in the sultanate.

In the gift shop at the sultan’s museum I found a baseball cap, fire-engine red, with white lettering in a familiar font but without the words I was expecting:

Of course the parallels presented themselves instantly: two playboy sovereigns with authoritarian tendencies and a love of gilt palaces. They have even done business; Trump bought the sultan’s yacht in the late 1980s, and the two share a sideline in luxury hotels. According to Stormy Daniels, Trump’s preferred West Coast fornication venue was the Beverly Hills Hotel, owned by the sultan. Trump is a populist, mingling with the unwashed much more often than the sultan. But he does not pretend to be unwashed himself—rather, he cultivates an image of unobtainable wealth, like a sultan without a sultanate.

What could be more thrilling than to see a demigod briefly assume the indignities of human form, eating Burger King and traveling to places like Pensacola and Wheeling? A century ago, the historian Marc Bloch documented a phenomenon, mostly of the 15th and 16th centuries, called “the King’s touch,” in which sick European peasants would line up to receive the healing touch of their monarch. The touch was in a sense pure fraud—it healed only scrofula, a condition which often resolves by itself—but it was also popular; kings who didn’t palpate their subjects were begged to do so, and rewarded with adoration when they did. The practice stopped only in the early 19th century—not coincidentally the dawn of nationalism, liberalism, and other forms of modern politics.

Are politics regressing to premodern forms? Did they never really progress beyond them? It is possible to read too much into these rallies and rituals. But when a man is legally murdered by having bricks thrown at his head, in a country as recently advanced as Brunei, I think we will have our answer.



The week I bought my advance timed-entry tickets for “Auschwitz: Not Long Ago, Not Far Away,” the massive blockbuster exhibition that opened in May at the Museum of Jewish Heritage in downtown Manhattan, there was a swastika drawn on a desk in my children’s public middle school. It was not a big deal. The school did everything right: It informed parents; teachers talked to kids; they held an already scheduled assembly with a Holocaust survivor. Within the next few months, the public middle school in the adjacent town had six swastikas. That school also did everything right. Six swastikas were also not a big deal.

“Auschwitz: Not Long Ago, Not Far Away” is a big deal. It is such a big deal that the Museum of Jewish Heritage had to alter its floor plan to accommodate it, making room for large-scale displays such as a reconstructed barracks. Outside the museum’s front door, there is a cattle car parked on the sidewalk; online, you can watch video footage showing how it was placed there by a crane. The exhibition received massive news coverage, including segments on network TV. When I arrived before the museum opened, the line for ticket holders was already snaking out the door. In front of the cattle car, a jogger was talking loudly on a cellphone about pet sitters.

When I was 15 years old, I went to the Auschwitz-Birkenau site museum in Poland. I was there with March of the Living, a program that brings thousands of Jewish teenagers from around the world to these sites of destruction. It is the sort of trip that clever people can easily critique. But I was 15 and already deeply invested in Jewish life (I later earned a doctorate in Yiddish and Hebrew literature, subjects I teach today), and I found it profoundly moving. Being in these places with thousands of Jewish teenagers felt like a thundering announcement of the Holocaust’s failure to eradicate children like me.

This was in the 1990s, when Holocaust museums and exhibitions were opening all over the United States, including the monumental United States Holocaust Memorial Museum in Washington, D.C. Going to those new exhibitions then was predictably wrenching, but there was also something hopeful about them. Sponsored almost entirely by Jewish philanthropists and nonprofit groups, these museums were imbued with a kind of optimism, a bedrock assumption that they were, for lack of a better word, effective. The idea was that people would come to these museums and learn what the world had done to the Jews, where hatred can lead. They would then stop hating Jews.

It wasn’t a ridiculous idea, but it seems to have been proved wrong. A generation later, anti-Semitism is once again the new punk rock, and it is hard to go to these museums in 2019 without feeling that something profound has shifted.

In this newest Auschwitz exhibition, something has. The New York display originated not from Jews trying to underwrite a better future, but from a corporation called Musealia, a for-profit Spanish company whose business is blockbuster museum shows. Musealia’s best-known show is the internationally successful “Human Bodies: The Exhibition,” which consisted of cross-sectioned, colorfully dyed cadavers (sourced, it was later revealed, from the Chinese government) that aimed to teach visitors about anatomy and science. Its other wildly popular show is about the Titanic. This is, of course, not a disaster-porn company but rather an educational company—and who could argue against education?

Perhaps the earlier Holocaust museums built by the Jewish community were unsuccessful simply because of their limited reach; despite the 2 million annual visitors to the United States Holocaust Memorial Museum, two-thirds of Millennials in one recent poll were unable to identify what Auschwitz was. Six hundred thousand people saw Musealia’s Auschwitz exhibition during its six months in Madrid before it arrived in New York. Those 600,000 people have all now heard of Auschwitz. There is clearly public demand.

And the Musealia people clearly know what they are doing. The Auschwitz exhibition was produced in cooperation with numerous museums, most prominently the Auschwitz site museum in Poland, and was carefully curated by diligent historians who are world-renowned experts in this horrific field. It shows.

The Auschwitz exhibition is everything an Auschwitz exhibition should be. It is thorough, professional, tasteful, engaging, comprehensive, clear. It displays more than 700 original artifacts from the Auschwitz site museum and collections around the world. It corrects every annoying minor flaw in every other Holocaust exhibition I have ever seen. It does absolutely everything right. And it made me never want to go to another one of these exhibitions ever again.

The exhibition checks all the boxes. There are wall texts and artifacts explaining what Judaism is. Half a room describes premodern anti-Semitism. There are sections on the persecuted Roma, homosexuals, the disabled; the exhibition also carefully notes that 90 percent of those murdered in killing centers like Auschwitz were Jews. There are home movies of Jews before the war, including both religious and secular people. There are video testimonies from survivors.

The exhibition is dependable. There is a room about the First World War’s devastation, and another on the rise of Nazism. The audio guide says thoughtful things about bystanders and complicity. There are cartoons and children’s picture books showing Jews with hooked noses and bags of money, images familiar today to anyone who has been Jewish on Twitter. There are photos of signs reading Kauft nicht bei Juden, Don’t Buy from Jews, a sentiment familiar today to anyone who has been Jewish on a college campus with a boycott-Israel campaign. There is a section about the refusal of the world to take in Jewish refugees. Somewhere there is a Torah scroll.

The exhibition is relentless. After an hour and a half, I marveled that I was barely past Kristallnacht. What the hell is taking so long? I found myself thinking, alarmed by how annoyed I was. Can’t they invade Poland already? Kill us all and get it over with! It took another hour’s worth of audio guide before I made it to the Auschwitz selection ramp, where bewildered Jews were unloaded from cattle cars and separated into those who would die immediately and those who would die in a few more weeks.

Somehow after I got through the gas chambers, there was still, impossibly, another hour left. (How can there still be an hour left? Isn’t everyone dead?) Forced labor, medical experiments, the processing of stolen goods, acts of resistance, and finally liberation—all of it was covered in what came to feel like a forced march (which, yes, was covered too). It was in the gas-chamber room, where I was introduced to a steel-mesh column that, as the wall text explained, was used to drop Zyklon B pesticide pellets into the gas chamber, killing hundreds of naked people within 15 minutes, that I began to wonder what the purpose of all this is.

I don’t mean the purpose of killing millions of people with pesticide pellets in a steel-mesh column in a gas chamber. That part, the supposedly mysterious part, is abundantly clear: People will do absolutely anything to blame their problems on others. No, what I’m wondering about is the purpose of my knowing all these obscene facts, in such granular detail.

I already know the official answer, of course: Everyone must learn the depths to which humanity can sink. Those who do not study history are bound to repeat it. I attended public middle school; I have been taught these things. But as I read the endless wall texts describing the specific quantities of poison used to murder 90 percent of Europe’s Jewish children, something else occurred to me. Perhaps presenting all these facts has the opposite effect from what we think. Perhaps we are giving people ideas.

I don’t mean giving people ideas about how to murder Jews. There is no shortage of ideas like that, going back to Pharaoh’s decree in the Book of Exodus about drowning Hebrew baby boys in the Nile. I mean, rather, that perhaps we are giving people ideas about our standards. Yes, everyone must learn about the Holocaust so as not to repeat it. But this has come to mean that anything short of the Holocaust is, well, not the Holocaust. The bar is rather high.

Shooting people in a synagogue in San Diego or Pittsburgh isn’t “systemic”; it’s an act of a “lone wolf.” And it’s not the Holocaust. The same is true for arson attacks against two different Boston-area synagogues, followed by similar attacks on Jewish institutions in Chicago a few days later, along with physical assaults on religious Jews on the streets of New York—all of which happened within a week of my visit to the Auschwitz show.

Lobbing missiles at sleeping children in Israel’s Kiryat Gat, where my husband’s cousins spent the week of my museum visit dragging their kids to bomb shelters, isn’t an attempt to bring “Death to the Jews,” no matter how frequently the people lobbing the missiles broadcast those very words; the wily Jews there figured out how to prevent their children from dying in large piles, so it is clearly no big deal.

Doxxing Jewish journalists is definitely not the Holocaust. Harassing Jewish college students is also not the Holocaust. Trolling Jews on social media is not the Holocaust either, even when it involves Photoshopping them into gas chambers. (Give the trolls credit: They have definitely heard of Auschwitz.) Even hounding ancient Jewish communities out of entire countries and seizing all their assets—which happened in a dozen Muslim nations whose Jewish communities predated the Islamic conquest, countries that are now all almost entirely Judenrein—is emphatically not the Holocaust. It is quite amazing how many things are not the Holocaust.

The day of my visit to the museum, the rabbi of my synagogue attended a meeting arranged by police for local clergy, including him and seven Christian ministers and priests. The topic of the meeting was security. Even before the Pittsburgh massacre, membership dues at my synagogue included security fees. But apparently these local churches do not charge their congregants security fees. The rabbi later told me how he sat in stunned silence as church officials discussed whether to put a lock on a church door. “A lock on the door,” the rabbi said to me afterward, stupefied.

He didn’t have to say what I already knew from the emails the synagogue routinely sends: that it’s increased the rent-a-cops’ hours, that it’s done active-shooter training with the nursery-school staff, that further initiatives are in place which “cannot be made public.” “A lock on the door,” he repeated, astounded. “They just have no idea.”

He is young, this rabbi—younger than me. He was realizing the same thing I realized at the Auschwitz exhibition, about the specificity of our experience. I feel the need to apologize here, to acknowledge that yes, this rabbi and I both know that many non-Jewish houses of worship in other places also require rent-a-cops, to announce that yes, we both know that other groups have been persecuted too—and this degrading need to recite these middle-school-obvious facts is itself an illustration of the problem, which is that dead Jews are only worth discussing if they are part of something bigger, something more. Some other people might go to Holocaust museums to feel sad, and then to feel proud of themselves for feeling sad. They will have learned something important, discovered a fancy metaphor for the limits of Western civilization. The problem is that for us, dead Jews aren’t a metaphor, but rather actual people we do not want our children to become.

The Auschwitz exhibition labors mightily to personalize, to humanize, and these are exactly the moments when its cracks show. Some of the artifacts have stories attached to them, such as the inscribed tin engagement ring a woman hid under her tongue. But most of the personal items—a baby carriage, a child’s shoe, eyeglasses, a onesie—are completely divorced from the people who owned them.

The audio guide humbly speculates about who these people might have been: “She might have been a housewife or a factory worker or a musician …” The idea isn’t subtle: This woman could be you. But to make her you, we have to deny that she was actually herself. These musings turn people into metaphors, and it slowly becomes clear to me that this is the goal. Despite doing absolutely everything right, this exhibition is not that different from “Human Bodies,” full of dead people pressed into service to teach us something.

At the end of the show, onscreen survivors talk in a loop about how people need to love one another. While listening to this, it occurs to me that I have never read survivor literature in Yiddish—the language spoken by 80 percent of victims—suggesting this idea. In Yiddish, speaking only to other Jews, survivors talk about their murdered families, about their destroyed centuries-old communities, about Jewish national independence, about Jewish history, about self-defense, and on rare occasions, about vengeance. Love rarely comes up; why would it? But it comes up here, in this for-profit exhibition. Here is the ultimate message, the final solution.

That the Holocaust drives home the importance of love is an idea, like the idea that Holocaust education prevents anti-Semitism, that seems entirely unobjectionable. It is entirely objectionable. The Holocaust didn’t happen because of a lack of love. It happened because entire societies abdicated responsibility for their own problems, and instead blamed them on the people who represented—have always represented, since they first introduced the idea of commandedness to the world—the thing they were most afraid of: responsibility.

Then as now, Jews were cast in the role of civilization’s nagging mothers, loathed in life and loved only once they are safely dead. In the years since I walked through Auschwitz at 15, I have become a nagging mother. And I find myself furious, being lectured by this exhibition about love—as if the murder of millions of people was actually a morality play, a bumper sticker, a metaphor. I do not want my children to be someone else’s metaphor. (Of course, they already are.)

My husband’s grandfather once owned a bus company in Poland. Like my husband and some of our children, he was a person who was good at fixing broken things. He would watch professional mechanics repairing his buses, and then never rehired them: He only needed to observe them once, and then he forever knew what to do.

Years after his death, my mother-in-law came across a photograph of her father with people she didn’t recognize: a woman and two little girls, about 7 and 9 years old. Her mother, also a survivor, reluctantly told her that these were her father’s original wife and children. When the Nazis came to her father’s town, they seized his bus company and executed his wife and daughters in front of him. Then they kept him alive to repair the buses. They had heard that he was good at fixing broken things.

The Auschwitz exhibition does everything right, and fixes nothing. I walked out of the museum, past the texting joggers by the cattle car, and I felt utterly broken. There is a swastika on a desk in my children’s public middle school, and it is no big deal. There is no one alive who can fix me.



Does Hillary Clinton really keep hot sauce in her purse? How can Bernie Sanders truly be a socialist if he’s a millionaire? Are Alexandria Ocasio-Cortez’s humble roots, featured prominently in her campaign video, enough to prove her authenticity?

“Be authentic”—there may be no more ubiquitous piece of advice to candidates for office. Yet there’s little agreement on what authenticity actually means, perhaps because the concept is often applied in ways that seem contradictory. An authenticity deficit was widely seen as one of the reasons Mitt Romney lost to Barack Obama in 2012. Four years later, it contributed to Hillary Clinton’s defeat to Donald Trump. How can the same quality account for the success of two figures as different as Trump and Obama? How can Trump in particular—an inveterate fabricator born to fabulous wealth who poses as the self-made tribune of the working class—come across as so authentic to so many?

The answer is that, when we talk about authenticity in politics, it turns out we’re usually describing something specific: Candidates from Obama to Trump to the Democratic presidential hopeful Pete Buttigieg seem authentic to the extent that they seem to be saying what they’re really thinking, rather than what they’re “supposed” to say. The key word here is seem.

In a paper published last month in the Journal of Personality and Social Psychology, the academics Rachel Gershon and Rosanna K. Smith described the results of a variety of tests showing that listeners perceived speakers to be less authentic when they were told that the speakers were repeating themselves. Self-repetition, they argue, “confronts observers with the performative nature of the interaction” and challenges our assumption that “social interactions, even those that are typically performed and repeated, are assumed to be unique.”

In other words, we’re wired to assume that all speech is extemporaneous. When that assumption is revealed to be false, we penalize the speaker. This is true, the authors found, even in contexts where it makes no sense to expect speakers not to repeat themselves, such as listening to a tour guide or a stand-up comic.

This finding helps make sense of the Obama-Trump paradox. Authenticity is not about being honest; it’s about seeming unscripted. If you sound rehearsed, then you can’t possibly be saying whatever you’re thinking right now; you’re saying something you decided to say at some moment in the past. Obama and Trump both have an uncommon ability to avoid that pitfall—even if they do so in very different ways.

As a candidate and as president, Obama had the gift of seeming unrehearsed. He could deliver scripted speeches with the emotion, humor, energy, and surprise of someone articulating his ideas for the first time. Recall that one of the ways Republicans tried to bring him down was to point out that he was reading from teleprompters: They sought to undermine his authenticity by puncturing the illusion that he was speaking off the top of his head. (Indeed, a major thread of the conservative reaction to Obama, including Trump’s birther conspiracy theory, was to avoid engaging with him on substance and instead insinuate that he was not what he seemed—that he was inauthentic.)

At the other end of the spectrum we find Hillary Clinton. Despite her obvious qualifications, she was hamstrung as a presidential candidate by an inability to sound like a normal person when addressing large audiences. Her performances in the major televised contexts in which most Americans saw her in 2016 were generally robotic and awkward—filled with strange pauses and painfully delivered jokes, drained of spontaneity. That, as much as anything, explains why voters were so primed to entertain questions about her authenticity and trustworthiness. (Clinton, to be sure, was also held to unfair standards because of her sex. But her problem was a variation of the same one that male candidates such as Al Gore and John Kerry faced before her.)

Trump achieves authenticity in a more unusual way. First, of course, he brazenly violates all kinds of taboos—against racism, sexism, authoritarianism, and so on. This scans as authentic because, even if it’s a calculated play to his supporters’ worst instincts, it’s clearly not what any political consultant would tell a candidate to do. Second, even more uniquely, Trump really does speak extemporaneously. In his rallies and TV appearances, he ad-libs and rambles wildly off topic. (Ditto his Twitter feed.) This is why, as so many others have noted, Trump is at his least Trump-like when he’s reading a scripted speech like the State of the Union address. It also may be why aspiring mini-Trumps haven’t been particularly successful at the ballot box: When standard Republicans try to rebrand as MAGA diehards without re-creating Trump’s gonzo showmanship, voters don’t buy it.

So the paradox of a serial liar such as Trump coming across as authentic isn’t much of a paradox at all. Trump lies authentically. He is so committed to saying whatever he feels like that he doesn’t let the truth get in the way.

Of course, authenticity isn’t exclusively about public speaking. A candidate’s biography, political positions, and track record all play a role. But public speaking has outsize importance, at least at the national level, simply because voters overwhelmingly get their input about a candidate’s personality by seeing them give a speech or interview or participate in a televised debate.

What does that tell us about the 2020 race? Among the current crop of presidential hopefuls, several have the knack for authenticity. Bernie Sanders paces the field with his ragged self-presentation and his blunt criticism of the wealthy and capitalism itself. Kamala Harris has an effective natural style. But the candidate who most fully embodies the Obama brand of authenticity-as-effective-performance—and whose surprising prominence is utterly inexplicable without it—is Buttigieg. If you’ve heard anything about the South Bend, Indiana, mayor, it’s probably that he’s awfully smart. But there are plenty of highly intelligent people in the race, and it’s not clear that Buttigieg is truly smarter than any of them. For all his stated commitment to “bringing forward good ideas,” he has yet to make an original policy argument, unlike many of his rivals; he recently proposed a tax credit for child care, something he could literally have pulled from Clinton’s 2016 campaign site.

What sets Buttigieg apart as a political talent, then, is not really his intellect. It’s his ability to give a speech, or answer questions onstage, in a way that makes it seem as though he’s earnestly thinking through his beliefs in real time. “Like Obama before him, like [Bill] Clinton before that, he ruminates in public,” said the journalist Ezra Klein by way of introducing Buttigieg to his podcast audience. “Unlike a lot of politicians, he’s willing to say quite a bit.” Klein probably understands, on some level, that these men aren’t really ruminating; Clinton and Obama were deeply calculating politicians, and all indications are that Buttigieg—a former Rhodes Scholar and McKinsey consultant who took seven months away from his mayoral duties to serve in the Navy Reserve in Afghanistan—is one too. But just as Trump’s most loyal voters can’t help but be taken in by the billionaire president’s man-of-the-people routine, well-educated liberals can’t help being drawn to someone who plays the part of the thoughtful intellectual.

This raises an obvious question: If the art of authenticity resides in making the scripted seem spontaneous, doesn’t that make it fundamentally inauthentic?

Short answer: yes. Great orators such as Obama—or Ronald Reagan, literally an actor—have the gift of obscuring the artificiality of political communication. Most normal people, ironically, would come across as spectacularly inauthentic if forced to give a campaign speech, because they would be stiff and rehearsed. “In reality, all politicians are strategic about the image and behaviors they present to voters,” wrote the political scientist Brendan Nyhan in 2015. “Some just hide the artifice better than others.”

That doesn’t mean we should ignore authenticity entirely, however. Convincing illusions have real-world effects. When a magician makes a card vanish and reappear, you know deep down that your eyes have been fooled; still, your brain can’t help but perceive the illusion as real. Authenticity is like political magic. The best you can do is remind yourself it’s a trick.



In 2019, Juneteenth will be celebrated as emancipation was in the old days: with calls for reparations. As the country marks 154 years since news of the end of slavery belatedly came to Texas, the House Judiciary Committee will hold a hearing on the subject of reparations for black Americans. It is a watershed moment in the larger debate over American policy and memory with regard to an enduring sin.

The hearing marks a return to the early black-American celebrations and jubilees, which were staged even as formerly enslaved people beseeched the Freedmen’s Bureau or the Union Army for land. And that’s for good reason. Juneteenth has always had a contradiction at its core: It is a second Independence Day braided together with reminders of ongoing oppression. Its spread from Texas to the rest of the United States accelerated in the wake of the assassination of Martin Luther King Jr., as a sort of home-going for King and other victims of white-supremacist violence, fusing sorrow and jubilation.

For decades, the successes of the civil-rights movement elevated the jubilation. But in recent years, the tenor of Juneteenth has changed. Black Americans see more clearly just how deep white supremacy rests in the country’s bones. The sorrow now predominates, and with it comes an urgency to hold power to account, and to remember who and what is owed.

Amid the wreckage of Reconstruction, the sociologist W. E. B. Du Bois wrote Black Reconstruction in America, a celebration of freedom demanded and claimed, and a lamentation of the collapse of an era in which the country could have truly made good on its promises to the enslaved. In it, he made a prediction. “This the American black man knows: his fight here is a fight to the finish,” Du Bois wrote. “Either he dies or wins. If he wins it will be by no subterfuge or evasion of amalgamation. He will enter modern civilization here in America as a black man on terms of perfect and unlimited equality with any white man, or he will enter not at all. Either extermination root and branch, or absolute equality. There can be no compromise. This is the last great battle of the West.”

For Du Bois, the path to a full liberation included restitution, land redistribution, the guarantee of a quality education, and positive and proactive protections for civil rights for the formerly enslaved and their descendants. Until those goals were achieved, he predicted, black Americans would be consigned to an unsteady state of second-class citizenship that would always tend toward oblivion. To Du Bois, if true material equality could not be enforced and racial hegemony smashed even by might of victorious arms, then it was proof that white supremacy would always have the power to escape any cage placed around it. Securing reparations, and a companion package of reforms that actually siphoned power from white elites and gave it to black laborers, was not just a practical necessity, but a moral test.

Of course, America failed that examination. None of Du Bois’s aims were accomplished in full. Redemption destroyed Reconstruction, and Jim Crow enacted another century of formalized and state-enforced theft from black people by white people. Even the end of Jim Crow was marked by an incomplete reconstruction. Black civil-rights leaders were assassinated in waves, and the economic and housing reforms pushed at the end of the civil-rights movement were never realized. Affirmative action was diminished by white resistance, and, against the wishes of Justice Thurgood Marshall, the Supreme Court eliminated racial quotas. Black farmers never received anything near full compensation for land stolen with the assistance of the federal government, and the proactive protections of the Voting Rights Act were largely dismantled by the Court in 2013.

Du Bois’s prediction now seems prophetic. The rejection of labor protections gave rise to sharecropping and reified a racial wealth hierarchy that has never been overturned. The failure to redistribute land from the enslavers to the enslaved that Du Bois chronicled led directly to the Great Migration, as black families fled their homes in search of genuine opportunity. Arriving in cities such as Chicago, they were met instead with a new round of dispossession. Discriminatory contract buying of homes in Chicago cost them between $3 billion and $4 billion. The absence of proactive protections for the black vote paved the way for disenfranchisement, and for the unsteady state of voting rights. The civil-rights-era efforts by the federal government to enforce equality were abandoned in many places, restoring a segregated health-care system and segregated schools.

Now, however, a growing body of research and reporting has tied those rejections of pro-equality policies to visible racial disparities in health and wealth. These linkages in many cases have provided data to back concerns within black communities that have long been dismissed as conspiratorial ravings. Yes, police really are stealing from black communities by way of discriminatory tickets. Yes, much of the conservative push to enact more restrictive voting laws is intended to dilute black voting power. Those linkages are empowering in a way, cutting through decades of gaslighting and disbelief. And they all point to the potential utility of reparations, not just as a way to address the legacy of slavery, but as the only way to reckon with the caste system that America allowed to be built as it looked the other way after slavery’s end.

The idea of reparations is somehow both avant-garde and extraordinarily old. Its reemergence stems from a broad reassessment of the trajectory of black America’s material conditions, and a realization that even with the extraordinary efforts of individual black people and some political and economic protections, true equality always appears just out of reach.

The reparations debate now necessarily extends beyond slavery, drawing from Jim Crow and more recent discriminatory practices in the North and West. Scholars are producing estimates of exactly how much wealth was stolen by tools such as restrictive covenants and mass incarceration. And, critically, researchers have also clearly outlined exactly how state power helped produce the wealth of those who have it: through favorable tax policy, social insurance, powerful institutions, and massive land and wealth transfers. America has pursued most of the programs Du Bois desperately wanted to create during Reconstruction. But the country has enacted them mostly for white people instead of the scions of the enslaved.

There is a ledger, and more and more black Americans believe it must be balanced. Resistance to that notion is perhaps best encapsulated by Senate Majority Leader Mitch McConnell, who said on Tuesday: “I don’t want reparations for something that happened 150 years ago … We’ve tried to deal with the original sin of slavery by passing civil-rights legislation and electing an African American president.” Conveniently, McConnell did not mention Jim Crow, the reason it took 100 years for civil-rights legislation to be passed after the Civil War. And if he does view the election of President Barack Obama as a duly appointed form of reparations, then McConnell’s own resistance to, and repeated stonewalling of, Obama’s presidency deserve some probing.

In American politics, as President Donald Trump’s career suggests, time and inertia confer legitimacy. The national celebration of emancipation has reverted to a purely historic endeavor, one stripped of the demand for full equality. Slavery has been relegated to a hazily indistinct past, and the ways in which it obviously influenced modern law are elided. Among those who wish to share in the font of white political power, this mythology is purposeful and empowering.

Memory, however, is powerful enough to expose myth. And memory is the purpose of Juneteenth. The testimonies of people who were enslaved, as well as their children, grandchildren, and distant descendants, are integral parts of the holiday. In predicting that the black community would either attain equality or be eliminated “root and branch,” Du Bois underestimated the strength of memory, which has allowed the black community to endure.

On Juneteenth, it seizes the narrative, reminding the country of its original debt, and the debts it has since accrued. And this Juneteenth, that reminder will be delivered in the seat of American power. This is, and has always been, the highest purpose of jubilee: to deliver a moral accounting.



It would be the first vivid memory of his life.

George W. Bush, then in the second grade, had been dispatched by his teacher to help carry a Victrola phonograph back to the principal’s office. He and his classmate Bill Sallee were lugging it down a covered walkway when George spotted his parents’ car pulling into the parking lot. They had been away on one of their frequent trips to New York. “I remember the pea-green car,” George W. Bush told me in an interview 65 years later. “I saw him pull up. I thought I saw Robin in the back.” He asked his teacher if he could go say hello to his parents and his little sister.

He knew Robin had been sick, but he had no idea that she might die. She wasn’t with them, his parents told him in the car. She was never coming home.

Decades later, in an interview in the living room of her Houston home, Barbara Bush was still torn over whether as parents they had made the right decision, trying to protect their young son by not being candid about what was going on. “We should have told him that she was very, very sick,” she told me, tears welling in her eyes. I apologized for making her cry. “That’s normal,” she replied. “Don’t worry about that.” A pastel portrait of Robin was hanging on the wall, within her line of sight. “He’s never really forgiven me for that, or us. I can understand that. We just didn’t know what to do. He was a little boy.”

Robin Bush’s illness and her death from leukemia, at the age of 3, would forever change Barbara Bush. The experience would steel her resolve and broaden her understanding of the ways the innocent can be caught and crushed by the unfairness of life. It would leave an indelible stamp on her about what matters, and what doesn’t. It would cement a bond between her and her firstborn son that would last until Barbara’s passing. And it would demonstrate the fierce maternal determination to protect her children at all costs that would define the rest of her life.

Barbara Bush set one rule: No crying in front of Robin.

The little girl was very sick from the start. When she was checked into Sloan Kettering hospital in New York, the doctors there were sure her pediatrician back in Midland, Texas, had gotten the blood test wrong; Robin’s white-blood-cell count was just too high to be accurate. But when they retested her blood, they registered the same results. It was the highest white-blood-cell count the experts had ever seen.

The treatments were torturous, the odds they would succeed remote. “How we hated bone-marrow tests,” Barbara Bush recalled, an agonizing procedure even for adults. Robin would be awake as doctors used a biopsy needle to collect a sample of marrow from a bone. Sometimes Robin would be “panicked, crying,” George Bush said. There were endless, painful blood transfusions, and as the hospital had requested, a parade of family members and friends journeyed to Sloan Kettering to replace the pints of blood that Robin used. More than once, Barbara would be called to help when her sister or a friend passed out while donating blood.

Her mother would spend just about every waking moment by Robin’s side, while her husband shuttled between New York and Texas, where he was scrambling to launch his new oil venture.

Every morning when he was back in Midland, George Bush would drop by First Presbyterian Church at 6:30 a.m. to pray for Robin. In the beginning, only the custodian was around to notice. Then the minister began showing up to join him. The two men never talked. They would sit quietly until Bush felt ready to face the day. At the time, Bush was teaching a Sunday-school class for teenagers at the church. He often would arrive disheveled and unshaven, with no lesson prepared. Instead, he would sit with the small group of students and talk about life, death, war, faith, hope, and despair. There was no stricture against crying there.

Barbara Bush didn’t want her little girl unsettled by seeing the adults in her life in tears. But George Bush, a man of open emotion, found it almost impossible to comply. Again and again, he would tell Robin he had to go to the bathroom and then step into the hallway to regain his composure. “We used to laugh and wonder if Robin thought he had the weakest bladder in the world,” Barbara Bush said. “Not true. He just had the most tender heart.”

He knew how hard it was on Barbara to be the stoic, to be the one in control. Years later, George Bush wrote a revealing aside in a letter to a constituent in his congressional district who had been diagnosed with cancer. “Someone had to look into Robin’s eyes and give her comfort and love,” he said, “and somehow, Paul, I didn’t have the guts.”

Barbara Bush became part of the hospital’s community of parents, an involuntary club bound by pain and hope. “We understood each other,” she said. The journey to Texas had broadened Barbara’s horizons from her days of growing up in affluent Rye and attending boarding school at Ashley Hall, in South Carolina. The long days in the hospital ward were eye-opening in a whole new dimension.

She realized how lucky she was in some ways. She had a stable home and a supportive spouse. They had health insurance and family assets. Some of the other mothers were dealing with family fissures and financial strains, which made their ordeal even harder. Sloan Kettering didn’t charge those who couldn’t pay, but there were other expenses and dislocations that debilitated some.

“I remember one precious little boy named Joey, whose mother had a big family in upstate New York,” she said. “Her husband was a laborer and was trying to cope with schools, bills, and meals. She worried all the time.” Joey’s mom rented a cheap room in the Bronx and would commute to the hospital by bus and subway each day, wearing her bedroom slippers for comfort.

“As Joey’s time drew near, I met her one day in the parents’ room and asked about her son. ‘Joey’s bad, Barbara,’ she said, then unintentionally mangled a Bible verse”; Barbara realized she found her version of it comforting. “‘Do you remember in the Bible where it says, “Let the little children suffer and they will come unto me”? Joey is really suffering.’” (Years later, Barbara Bush would remember Joey when Ronald McDonald House Charities, which provides housing and support for the families of hospitalized children, asked her to help headline their annual fundraising dinner. She accepted. What a difference the organization could have made for Joey’s mom if it had existed then, she thought.)

Cancer proved to be a terrible equalizer. Neither money nor power nor position had given Robin any more refuge from leukemia than Joey had.

Like every other parent at the hospital, the Bushes were desperate, ready to grasp at straws. One day, several friends phoned George Bush after hearing Paul Harvey on his radio program describe a doctor in Kansas who had discovered a cure for leukemia. After five frantic hours, Bush managed to get through to the doctor on the phone. He had been swamped by calls from parents who would do anything to save their children, but all he had to offer was one more unproven medicine then being tested. Barbara Bush later chastised Paul Harvey for causing such heartbreak. “He raised our hopes only to have them dashed,” she said.

True to form, Robin’s disease did go into remission for a time. Once that summer, they traveled to the family home in Kennebunkport, Maine, and Robin got to see her brothers. Then she made a brief trip to Texas, the farthest the hospital had let a leukemia patient go. It was a chance for her to see her home in Midland, and for her family and friends to see her, one more time.

Many in Midland shied away, worried that leukemia might be contagious. Barbara Bush never forgot the pain that caused her. Later, as first lady, she would make a point of embracing HIV/AIDS patients at a time when many were skittish.

But before long Robin had to return to the hospital in New York, her health failing, the treatments no longer working. Robin caught pneumonia and spent time in an oxygen tent. Her legs were covered with bruises. There were dozens of painful open sores on her torso. She was bleeding internally. Barbara and the doctors called George Bush in Texas to discuss one more operation. “I said, ‘No, we’ve done enough to her,’” Bush told them. There was nothing more that could be done. “We thought it was time to let her go.”

He flew back to New York. By the time he arrived, Robin had slipped into a coma.

“One minute she was there, and the next she was gone,” Barbara Bush said. “I truly felt her soul go out of that beautiful little body.” Her mother combed Robin’s curly blond hair for one last time. Barbara was 28 years old when her daughter died in her arms.

“Like an oak in the wind, she was tossed, but she would not be moved,” the author Richard Ben Cramer would write of Barbara’s forbearance. She had accomplished her mission. She had never cried in front of her frail little girl, not once. Now the tears could flow, and they did.

The Bushes already had decided to donate Robin’s body to research in hopes that it would speed understanding of the disease, that it might help save some other child. While she had been sick, they had overheard grieving family members in the next room berate a doctor who had asked if they would give their child’s body to science. They took a lesson from that, and applied it when their time came to answer that hard question.

Robin’s burial would be delayed to allow time for the researchers to examine her. George and Barbara scheduled a memorial service for family and a handful of friends at Christ Church in Greenwich before they returned to Midland. They were at the home of George’s parents, getting ready in an upstairs bedroom. They could hear the others gathering on the first floor. Suddenly, Barbara’s stoicism evaporated. She couldn’t face anyone, she told her husband. She couldn’t do it. She was done.

George looked out the window and saw Barbara’s sister and brother-in-law, Martha and Walt Rafferty, walking up the driveway. “Sure, and with the O’Raffertys, it is going to be a grand wake!” he told her. It was the sort of deliberately goofy comment that could make her laugh, that would help her to hold it together one more time.

At the moment, they were all reeling. No one was sleeping through the night.

In those first weeks, young Georgie struggled. Not long after his sister’s death, he went over to the house of a friend, Randall Roden, for a sleepover, but he had such terrifying nightmares that his mother had to come over to the house to comfort him.

Barbara Bush herself would wake up with a wave of grief so fierce that the pain felt physical. During the day, she hated it when friends avoided saying Robin’s name, as though the little girl could or should be forgotten. She was exhausted by condolence calls from people she hardly knew, and by the awkward comments some would make in an effort to comfort her. Once, walking into the living room, she got a glimpse of a friend practicing sad expressions in a mirror; Barbara backed out of the room and came in again, more noisily. “At least it wasn’t your firstborn and a boy at that,” a visitor said. Barbara was speechless and enraged. “I just needed somebody to blame,” she said.

A study in the 1970s estimated that as many as 90 percent of bereaved couples found themselves in serious marital difficulty within months after the death of a child. The most serious problems developed when the mother and the father coped differently with their grief. Often fathers would take refuge in their work and try not to dwell on the loss, the researchers found, while mothers wanted to talk about their child, to express their pain. That disconnect would fray their bonds, sometimes irreparably.

But George Bush defied that stereotype of his gender and his times. It was Barbara who wanted to rush through a grieving process that could not be hurried; he refused to let her do that. “I wanted to get back to real life, but there is a dance that you have to go through to get there,” she said. “When I wanted to cut out, George made me talk to him, and he shared with me.” He reminded her that others were feeling the same pain she felt. He felt it, as did their son, and their relatives back east, and their friends in Texas. Night after night, he would hold her as she cried herself to sleep.

Robin’s illness deepened her young mother’s faith, and it made her both harder and softer. On the inside, Barbara Bush emerged more aware of the fragility of life and the universality of grief. On the outside, she developed a survivor’s armor, and with it even less patience for the general boneheadedness of people. She had never been one to suffer fools gladly. Now her impatience was sharpened, even if those fools were well meaning. She had never paid much attention to what she wore or how her hair looked. Now she cared even less.

And she clung to her eldest child.

He was the only one of the children who could share with his parents his own memories of Robin. “I feel very close to George, very,” Barbara Bush told me. “He went all through the Robin thing. He really took care of me.”

During the fall of 1953, after being away for most of the previous six months in New York, she focused on Georgie and little Jeb. “Mother’s reaction was to envelop herself totally around me,” George W. Bush recalled. “She kind of smothered me and then recognized that it was the wrong thing to do.” One breezy day, Barbara was in her bedroom when she overheard Mike Proctor, the boy who lived across the street, ask Georgie if he wanted to come over and play. He did, he replied, but he couldn’t leave his mother. She needed him. “That started my cure,” Barbara Bush said. “I realized I was too much of a burden for a little 7-year-old boy to carry.”

This article was adapted from The Matriarch: Barbara Bush and the Making of an American Dynasty, by Susan Page.



Updated at 1:44 p.m. ET on May 1, 2019.

When William Barr was appointed attorney general, his critics warned that Barr would do everything he could to either interfere with Special Counsel Robert Mueller’s work or suppress his report. In his confirmation hearings, Barr pledged to release as much of the report as he could under the law.

He followed through: There have been no indications of interference, and he released the 448-page report in April with relatively light redactions. But Barr was more clever. While still making the report public, Barr managed to mislead the public and Congress, spinning Mueller’s findings in a way that hobbled their impact and protected the president.

The gap between Barr’s statements and what Mueller actually concluded is clear from any comparison of Barr’s initial summary of conclusions to Congress, released March 24, and his April 18 prerelease press conference with the actual text of Mueller’s report. But you don’t have to take it from me, or from your own reading. Take it from Mueller himself. In a letter to Barr on March 27, first reported by The Washington Post on Tuesday night, Mueller took issue, calmly but strenuously, with Barr’s public representations.

“The summary letter the Department sent to Congress and released to the public late in the afternoon of March 24 did not fully capture the context, nature, and substance of this Office’s work and conclusion,” Mueller wrote. “There is now public confusion about critical aspects of the results of our investigation. This threatens to undermine a central purpose for which the Department appointed the Special Counsel: to assure full public confidence in the outcome of the investigations.”

The letter is measured in the way that one would expect the staid, lifelong G-man to be. Mueller does not directly accuse Barr of misleading anyone, though it’s difficult to take any other conclusion from his words. (Barr says Mueller told him that media coverage was misinterpreting the letter, which is a cop-out, and ignores the fact that Mueller pointed to the letter itself.) But the timeline that Mueller lays out, and the very fact of the letter, suggests strong frustration, especially given Mueller’s extremely tight-lipped approach throughout the investigation.

Mueller writes that he first told Barr on March 5 that his team was writing introductions and executive summaries that would make for effective and accurate summaries of his conclusions. He reiterated that on March 24, two days after he delivered the report to Barr. Barr then released his summary, which he now insists is not a summary, to Congress and the public, later that afternoon.

Based on a plain reading of Barr’s letter, immediate media reports portrayed Mueller as having found no collusion and no obstruction of justice. In fact, the report’s findings on both of these questions were considerably more nuanced; Mueller avoided the fraught and nonlegal term collusion, saying he found no criminal conspiracy but considerable links between Donald Trump’s campaign and Russia, and strongly suggested that Trump had obstructed justice, even while saying he didn’t feel he could charge Trump.

Mueller was immediately worried. The following day, March 25, he wrote, his team “communicated our concern to the Department.” Apparently not receiving any satisfactory response, Mueller escalated his efforts, writing his letter to Barr on March 27. Putting the complaint in writing formalized it. It also all but guaranteed that the the letter would eventually make it to the public, as it now has. Lawyers are typically very careful about what they do and don’t put in writing for precisely that reason, but throughout the Trump presidency, government officials have seen the need to write memos for posterity when concerned about actions by the administration.

How did Barr respond to this? The two men spoke on March 28, according to the Post, and the attorney general pressed Mueller on whether anything in his letter to Congress was factually inaccurate. Mueller reportedly said no, but that’s beside the point. Even if no specific sentence in the letter was wrong, it misleadingly downplayed the gravity and scope of the report, and misrepresented the thinking behind Mueller’s decision not to bring obstruction charges. “We used the language from the report to state those bottom-line conclusions,” Barr said in testimony to the Senate Judiciary Committee on Wednesday. But as a side-by-side comparison of Barr’s and Mueller’s words shows, the attorney general selectively quoted from the report, and took many of those quotations out of context. The result was, as Mueller noted, that the public was misled about the contents of the report.

Barr did not release the executive summaries, as Mueller apparently wanted him to do, deciding to instead forge forward with releasing the report in toto. Barr said on Wednesday that he felt releasing parts of the report piecemeal would simply confuse the public. But that same critique could be leveled even more powerfully at his own, misleading-by-omission summary. And by releasing his own four-page letter, Barr sidestepped the pressure to immediately release the report’s own summaries.

Not only that, but Barr then proceeded to give a baffling press conference on April 18, the morning the Mueller report was published. The press conference came before any member of Congress or the public had seen the report, and allowed Barr to once again frame the special counsel’s report as he saw fit. Once again, Barr offered a seriously misleading view of what was in the report. Portraying Trump as the victim of the whole proceeding, he repeatedly stated that there was no “collusion,” starting to sound like an echo of Trump’s Twitter feed. Barr insisted that Trump had “fully cooperated with the special counsel’s investigation.” That claim was straightforwardly contradicted by the report itself, which pointed out multiple instances of the White House resisting cooperation, not least of them Trump’s refusal to be interviewed by investigators or to answer written questions about obstruction.

Though Barr and Mueller are old friends and colleagues, they seem to be talking past each other in these exchanges. Clearly, the two men had differences of opinion about obstruction—Mueller implies he would have charged Trump were he not president, while Barr insists Mueller said otherwise in their conversations. Barr said Wednesday that he was surprised Mueller hedged on the obstruction question, but felt that he needed to make a decision. But Mueller’s letter doesn’t object to Barr’s decision or question his authority to make it. Mueller’s problem was that Barr was misleading the public.

Barr seems to be very concerned with buttressing his expansive view of executive prerogatives. The New York Times lays out a point of tension:

Mr. Mueller’s report, the attorney general and the other senior law enforcement officials believed, read like it had been written for consumption by Congress and the public, not like a confidential report to Mr. Barr, as required under the regulations governing the special counsel.

Indeed, as my colleague Yoni Appelbaum has noted, the report reads as an impeachment referral to Congress—very directly. It’s easy to see why Barr might have been upset, given his view of the law. But he was also boxed in. He had already pledged to release the report publicly.

One need not judge Barr’s motivations—whether he’s genuinely concerned about executive power or simply trying to defend Trump—to see how misleading his comments were, or how effective they were. By the time anyone outside the Justice Department saw the Mueller report, they’d already been exposed to Barr’s misleading letter and press conference. He had, by Mueller’s reckoning, allowed incorrect interpretations of the report’s findings to circulate in public for two weeks. Senator Chris Coons, a Delaware Democrat, explained the importance during Wednesday’s hearing.

“A critical three weeks passed between when you delivered the letter with the focus on the principal conclusions and when we ultimately got the redacted report,” Coons said. “My concern is that that gave President Trump and his folks more than three weeks of an open field to say, ‘I was completely exonerated.’”

As a way of defusing the findings of the investigation, it was tremendously successful. Even though the report can read as an impeachment referral to Congress, by the time its full text was released, the ardor for impeachment hearings among legislators and the public had faded. As Barr visits Capitol Hill this week, members of Congress are debating whether the president can theoretically be charged with a crime, the actions of the Hillary Clinton campaign, and of course the exchanges between Mueller and Barr. That’s far better for Trump than having Congress discuss the actual substance of the report.

In his prepared testimony Wednesday, Barr noted that senators had asked him to commit to allowing Mueller to finish his work without interference and to release the report. “I believe that the record speaks for itself,” Barr said. He’s right. Rather than clumsily suppress the report, Barr did something much subtler—and far more effective.



Anyone who remembers the 1994 Republican “Contract With America” might have found it jarring to read Beto O’Rourke’s voting-rights plan, released this week.

Along with a range of other policies, from automatic voter registration to campaign-finance reform, the Democratic presidential candidate and former congressman calls for term limits for members of the House, Senate, and Supreme Court.

While term limits for the justices have become a popular cause in both parties, term limits for Congress are an idea that left popular circulation around the time Newt Gingrich stepped down as speaker of the House. When the GOP reclaimed the House in a stunning victory in 1994, the new majority began implementing reforms. One of those was term limits—in fact, Republicans wanted the same 12-year limits (six terms for the House, two for the Senate) that O’Rourke suggests. But the move would have required a constitutional amendment, and it fell short. Many of its former proponents went on to break their own voluntary term limits. The idea has seldom been heard since.

Probably for good reason, as the plan raised a host of objections. O’Rourke writes, “If we want to truly have faith in those we serve, if we want our government to reflect the diversity and strength and creativity of our communities, and if we want to inspire a new generation of voters, then let’s help clear the way for new leaders to step up and bring their unique experiences, expertise, and energy to bear on the problems and opportunities we’re facing.”

But as O’Rourke’s former House colleagues Joe Crowley and Mike Capuano can attest, voters are perfectly willing to turn out incumbents in favor of younger, nonwhite leaders. Term limits are arguably antidemocratic, since they take choice away from voters. They make it harder for Congress to pass the sort of major legislation O’Rourke calls for in the same breath, because they imperil the creation of expertise and coalitions. With legislators turning over frequently, term limits concentrate power among unelected staffers, and among lobbyists and outside policy interests.

Yet the parallel with the 1994 Republican Revolution is telling. O’Rourke, like many of the other Democrats running for president this year, is proposing sweeping systemic reforms to the political system. That’s a shift for the Democratic Party. For decades, the party has tended to pledge to make the existing system work better, while Republicans have promised voters that they’ll radically change the system. Perhaps not coincidentally, that period has coincided with a right-wing ascendancy inside American politics.

It has not always been thus. During the Progressive period of the early 20th century, liberals rallied around a series of major systemic reforms. They pushed to break up trusts. They expanded the vote, and demanded recall elections and popular referenda. They passed the Seventeenth Amendment, mandating the direct election of senators by voters, rather than by state legislatures.

Democrats took up this mantle, from Franklin D. Roosevelt’s New Deal to Lyndon B. Johnson’s Great Society. Republicans could still win presidential elections, but as with Dwight Eisenhower, they were often offering just a scaled-back version of Democratic big-government ideas. The GOP was supine.

And then it wasn’t. Starting in the 1960s, conservatives retook the initiative with an argument that government was the problem, culminating in Ronald Reagan’s presidency. Democrats mostly retained a firm grasp on Congress until 1994, when the GOP won both houses, partly on the back of the “Contract With America.” Democrats adjusted to the new reality by largely accepting it. In a mirror image of Eisenhower, Bill Clinton signaled his acquiescence to the new order, declaring in his 1996 State of the Union address that “the era of big government is over.” He oversaw a huge overhaul of welfare and balanced the federal budget. His most aggressive liberal initiative, health-care reform, died early in his term. Insofar as Clinton had an argument about government, it was the center-right’s.

The next Democratic president, Barack Obama, wasn’t a systemic reformer either. Running for office, Obama promised “change” and an improved government, but his explanation for how that would happen was vague and aspirational; in any case, it did not involve major structural changes, but instead depended on making the existing system work better. Obama’s policy approach was more aggressive than Clinton’s—he managed to finally pass a form of universal health insurance, as well as new regulations on the financial industry—but true to form, he focused on legislating through existing channels, rather than changing those channels.

Contrasting it with the early-1900s reform push, my colleague Yoni Appelbaum summed up the problem with this approach in 2011:

The current progressive movement has, by contrast, tended to promise better policies and improved implementation, while rallying to the defense of government from its critics. It insists that government should do better, but not that we need a better government. Whatever its intellectual merits, this approach has a fatal political flaw: most Americans number themselves among government’s critics. They don’t think government works terribly well, and they are disinclined to support politicians who do.

Clinton and Obama would argue that they were achieving what was possible given current politics. Perhaps they underestimated their ability to change politics, or perhaps the politics have indeed changed, but today’s Democrats have forsaken that vision in favor of embracing systemic changes.

Many of them are proposing things that would require constitutional amendments, all the more notable since there hasn’t been a substantive amendment since 1971. To name just a few: O’Rourke wants term limits. As I wrote earlier this week, radical reforms to the Supreme Court, including court packing, have become central to party thinking, even for cautious candidates such as O’Rourke and Mayor Pete Buttigieg. Obama achieved universal insurance coverage through the private-insurance system; several Democrats want to bulldoze it entirely with Medicare for All schemes. Senator Elizabeth Warren has been perhaps the most aggressive of the bunch, pushing everything from abolishing the filibuster to busting trusts to enshrining a right to vote.

These stances are notable because, with the exception of Warren and Senator Bernie Sanders, few of these politicians were suggesting major overhauls of the American political and economic system even a few years ago. But the shifts among presidential contenders reflect a growing taste for big schemes among voters. Four out of five Democrats want the Electoral College abolished, according to a recent NBC News/Wall Street Journal poll. (On Wednesday, legislators in Oregon voted to make it the 15th blue state to join a compact that would effectively do an end run around the Electoral College.)

Meanwhile, the Republican Party’s idea pantry seems increasingly bare. While Donald Trump’s unorthodox approach overshadowed this, it’s notable that the most memorable idea from Bobby Jindal, acclaimed as one of the party’s brightest thinkers in recent years, was that the GOP should “stop being the stupid party.” An unimpeachable idea, one might think—or one might have thought before 2016—but not exactly inspirational. The lack of new ideas was on display when, with unified control of the White House and Congress in 2017 and 2018, the only major initiative Republicans managed to pass was a set of tax cuts. Moreover, that turned out to be a failure, both as a matter of policy and politics. Cutting taxes was revolutionary when Reagan did it, but 30-odd years later, it’s the status quo.

Whether the embrace of radical systemic changes can power Democrats to the White House in 2020 remains to be seen. Sometimes the effects of these shifts are slow to bear fruit: The seeds of Reagan’s victory in 1980 were sown in Barry Goldwater’s 1964 rout. But if Democrats do commit to systemic reforms, they could reshape the balance of American politics in ways that will far exceed the impact of any proposed term limits.



When journalists, including me, point out that Joe Biden is running as a candidate of nostalgia, it’s usually a reference to his argument that he can return things to a pre-2016 idyll of American unity and happiness. But the former vice president’s backward look has taken a weird turn this week as Biden delivered a confusing story involving a long-dead Democratic segregationist senator from Mississippi.

“I was in a caucus with James O. Eastland,” Biden said at a fundraiser. “He never called me ‘boy,’ he always called me ‘son.’”

The anecdote made no sense, either as storytelling or as politics. “Boy” is a well-known situational racial epithet in the South, but why would Eastland have called Biden by it? What substantive difference between the two terms was Biden trying to underscore? As it turns out, Biden has used the story in the past, in a much less garbled version, saying the much older Eastland called him “son” rather than “senator.”

Yet in a broader sense, Biden’s invocation of Eastland still makes no sense. Biden is obviously not endorsing Eastland’s segregationism. The point was to recall a time when “civility” in the Senate could overcome political differences, which complements Biden’s message that the country needs a more tempered, friendly political discourse. As Jonathan Chait notes, the post–World War II consensus was built in part on a mutual agreement by leaders to move slowly on civil rights. However clubby things were in the Senate, Eastland’s black constituents did not experience the racial discrimination he repeatedly voted to uphold as “civility.”

Recriminations came quickly. The Washington Post reported that staffers had pleaded with Biden not to talk about Eastland. Other Democratic presidential hopefuls criticized Biden, led by Senator Cory Booker, who said he should apologize. Biden fired back, saying that Booker “knows better. There’s not a racist bone in my body,” and saying Booker was the one who should apologize. (He did not.)

There are several ways to read Biden’s response. One is that Biden’s temper got the better of him, as it has, to his detriment, in past presidential races. Another, more cynical view is that Biden is acting quite deliberately—calculating that he’s strong enough among black voters and core Democrats to withstand the controversy, and that refusing to back down will play well with white voters who might go for either Trump or Biden.

When I have pointed out the dissonances of Biden running on a nostalgia ticket, a common response has been, So what? He’s way out in front of the Democratic field, so clearly it’s working. Yet his invocation of Eastland is a concrete demonstration of the risks of the nostalgia campaign. Biden’s coalition fuses together support from African Americans and from older white voters, and his supporters remember the past in two different, perhaps mutually incompatible, ways.

Any time you start waxing nostalgic, someone’s going to ask which golden era you’re recalling—and someone’s going to have a good reason why that era wasn’t as golden as you say. Older white voters who don’t like either the crassness of Trump or the combative liberalism of Alexandria Ocasio-Cortez may indeed look fondly on the late 1970s and early 1980s as halcyon days. But black voters are unlikely to look quite so fondly on mentions of Eastland—nor on the other examples of Biden praising Dixiecrats that have resurfaced in the past couple days.

Biden could have made the same point in a less inflammatory way by citing more recent examples of working with Republicans to pass bipartisan bills. Perhaps he simply resorted to the shopworn Eastland anecdote because it’s familiar and comfortable. Perhaps he really believes it’s the best illustration of how compromise works.

But compromise in the service of what? Biden’s anecdote is a tactic in search of a strategy. While his rivals offer vast reimaginings of the political landscape, Biden has centered his campaign on opposing Trump. Yet it’s hard to see how even the relatively modest proposals Biden offers fit into this paradigm. Biden wants to address climate change, make it easier to vote, reform campaign finance, and improve labor protections. All of these are anathema to the current Republican Party, and without a unifying common cause—like defeating the Soviet Union, for example—it’s not clear what compromise Biden could offer to entice GOP politicians to work with him.

Biden ought to know this better than anyone, having been involved in the Obama administration’s health-care push. Democrats borrowed the individual mandate from conservative think-tank plans, largely adopted a plan modeled by Republican Governor Mitt Romney in Massachusetts, and made accommodations with the private-insurance industry. This didn’t entice GOP crossover support.

Given Biden’s history, the press has been standing watch for The Gaffe that could blow up his front-running campaign. Bringing up one now obscure senator is probably not that gaffe, but it’s the sort of problem that could spell real trouble for him. Biden is obviously confident in his rapport with black voters, especially older ones, but those voters aren’t an immovable monolith. Twelve years ago, they were strongly in Hillary Clinton’s corner and wary of the newcomer Barack Obama—until they were not. Perhaps Biden should keep that more recent history in his mind, rather than reaching back to the 1970s.



Say what you will about Joe Biden, but you can’t accuse him of pessimism.

Speaking at a fundraiser on Monday, the former vice president and current Democratic front-runner said that Republicans in Congress will soon be ready to work across the aisle once again.

“With Trump gone, you’re going to begin to see things change. Because these folks know better. They know this isn’t what they’re supposed to be doing,” Biden said. Yet on Tuesday, barnstorming in Iowa, Biden told audiences that Trump is “an existential threat.”

These ideas point to the contradiction at the heart of Biden’s campaign. On the one hand, Biden is—more stridently than most of his Democratic rivals—running a campaign against Trump. While some of the other candidates see Trump as merely the apotheosis of long-running trends in American society toward xenophobia, isolationism, plutocracy, and kleptocracy, Biden sees Trump as aberrant. This allows Biden to offer a nostalgic campaign, which, as I have written, is itself an aberration among Democrats historically: Vote for me, and we’ll put things back the way they were.

Biden said Monday, “Four years of this president will go down as an aberration … Eight years of Donald Trump will fundamentally change who we are in profound ways.” How can it be that Trump poses an existential threat, and if he serves two terms, it would produce a profound shift in American society, but that if he serves only four years, it will be easy to return to the supposed idyll that existed before 2016? The idea beggars belief.

There’s no question: It’s a lot easier to reverse four years of policy than it is to reverse eight years of policy, as the Trump administration has shown. Trump has managed to roll back some of Barack Obama’s policies, especially those instituted through executive action during his second term. But the Affordable Care Act has proved very difficult to dislodge, despite a months-long frontal assault that consumed much of Trump’s first year in office.

But Biden isn’t really talking about policy, is he? He’s talking about the sense of despair and frustration that seems to suffuse much of the country today—a spirit that animated some Trump voters to support him in 2016, and has animated many of those who voted against him ever since. It’s different from policy, though it is inextricably related: You don’t get family separations at the border without the cruelty-driven worldview of the administration.

He’s also talking about the way Republican officeholders are behaving, which is another essential ingredient to Trump enacting his agenda. Biden has previously promised that GOP members will have an “epiphany” once Trump is out of office (and, presumably, Biden is in). “This ain’t your father’s Republican Party,” Biden said Monday. If your dad is Biden’s father’s age, or even Biden’s age, that’s true. If your father is younger, it probably isn’t. As political scientists have shown, both parties have become more ideologically homogeneous and polarized in recent decades, but the Republican Party has become especially polarized. (By some measures, the process started in the late 1970s, just as Biden was finishing his first term in the Senate.)

Despite the inexorable process of polarization, Democrats continue to insist that Republicans will embrace bipartisanship any moment now. Seven years ago this month, Biden’s old boss told supporters at a rally that everything would work better after the 2012 election: “My expectation is that if we can break this fever, that we can invest in clean energy and energy efficiency because that’s not a partisan issue.” This didn’t happen. The idea that it would be more likely after a Biden victory over Trump is even more far-fetched, given that the process of polarization has continued another seven years, and given the passions that Trump arouses.

One needn’t accept the deep historical critiques of American society leveled by Elizabeth Warren and Bernie Sanders to acknowledge that Republican polarization isn’t a Trump-era phenomenon. Trump represents a culmination of the process, rather than a swerve away from it. The Republican Party will not always be the party of Trump, but it will never again be the party of Bob Dole. (Democrats back then denounced Dole as an extremist, too, of course. It’s never going to be the party of Howard Baker either.) Meanwhile, Trump has catalyzed the polarization of the Democratic Party as well.

This is not to say that the specific actions the president is taking won’t have a lasting impact of their own. Even if Trump doesn’t win reelection, his actions will reverberate for years to come, though it’s difficult to predict which ones will have the greatest influence.

Some of the effects are murky: No one knows what the long-term impact of Trump winking at foreign assistance to win elections, discarding conflict-of-interest rules, or knocking down any number of norms will be. Others are more concrete. Alliances that were shaken by the George W. Bush administration and haltingly rebuilt under Obama will be harder to repair after a second rupture. Trump’s judicial nominees will shape American jurisprudence for a generation. The conservative media have been remade. Dozens of Republican candidates are running in different proportions on Trump’s style and substance. His current aides will populate government for decades to come. (Consider how many alumni of the Reagan administration, so far away from Trump in many respects, work for him: Attorney General Bill Barr, National Security Adviser John Bolton, the Venezuela envoy Elliott Abrams.)

If Biden’s “existential threat” language sounds familiar, that’s because Hillary Clinton mounted a similar argument against Trump in 2016. It was an attempt to meet fire with fire: Trump was campaigning by trying to spread fear, and Clinton offered her own dose of fear in response. Anat Shenker told Molly Ball that Clinton risked merely amplifying Trump’s message. Can Biden have more success? Maybe he can: After all, the dangers of a Trump presidency are no longer hypothetical but concrete. That only underscores, however, how impossible a task reclaiming the old “normal” really is.



Attorney General William Barr has repeatedly used the word spying to refer to the counterintelligence investigation into Russian contacts with Donald Trump’s team in 2016. Barr’s loose use of language risks a panoply of harms, undermining public confidence in three vital goods: the nonpartisan nature of the intelligence community’s work, the generally robust framework for intelligence oversight, and the facts and conclusions of the intelligence community itself.

Does Barr know what he’s saying? In a recent interview on CBS, Barr said that “as a lawyer, I always interpret the word treason not colloquially, but legally.” He also touted his intelligence background from his early days at the CIA. Like lawyers, intelligence analysts are trained to carefully consider the importance of their words. Analysts and lawyers alike know that word choice makes a difference in shading, tone, and received meaning, and that the audience matters when choosing your words.

“Spying” is neither a legal standard nor a term of art. None of the statutes, executive orders, or minimization procedures that govern U.S. intelligence activities refers to “spying.” Each of those legal authorities uses much more precise language, such as “electronic surveillance,” “covert action,” or the “collection, processing, analysis, and dissemination” of information.

Spying is a word that’s been shaped by pop culture, invoking John le Carré novels and James Bond movies. It also carries with it the echoes of the mid-1970s Church and Pike Committee investigations into abuses by the intelligence community (IC)—investigations that Barr says shaped his views of intelligence operations. Barr’s use of the word spying to describe a counterintelligence investigation can only have a negative effect on public perception. This is dangerous in a number of ways.

In fact, all of the information published in Special Counsel Robert Mueller’s report indicates that there was a lawful, proper predicate for the work done by the FBI and others in investigating whether the Russian government was attempting to cultivate relationships or curry favor with members of the Trump campaign and organization in order to sway American politics in 2016. There’s been no credible indication that the investigation was improperly motivated or driven to achieve partisan aims in the United States.

Barr’s own references in his CBS interview to the lessons of intelligence reform in the 1970s are apt ones. During the hearings held by the Church and Pike Committees, bipartisan groups of elected officials brought the U.S. IC to account for a host of misdeeds committed since the end of World War II. Congress concluded that the FBI, CIA, NSA, Defense Intelligence Agency, and military intelligence had collected too much information, used it improperly, and targeted people and groups for reasons having more to do with “subversive activity”—combatting social unrest—than with foreign intelligence threats. The committees concluded that these abuses had been made possible, in part, by a loose and permissive framework of authorities enabling surveillance and tepid congressional and executive-branch oversight.

The Church Committee issued a multivolume report recommending a comprehensive series of reforms that would keep the IC accountable to the American public and force it to live up to its best ideals. Following those recommendations, stringent oversight mechanisms were put in place across all three branches of government: The permanent House and Senate intelligence-oversight committees were created, legislative frameworks such as the Foreign Intelligence Surveillance Act were passed, and Executive Order 12333 defined the scope of IC agencies’ authorities and required attorney-general-approved guidelines to minimize the risk of intrusion on the rights of U.S. persons.

The framework of reforms launched by the Church and Pike Committee investigations hasn’t been perfect, but it’s been continuously strengthened since then, with the establishment of independent boards and commissions such as the Privacy and Civil Liberties Oversight Board, the appointment of inspectors general at multiple levels and within every component of the IC, the widespread appointment of privacy and civil-liberties officers, and other moves toward increased transparency.

While these reforms have not precluded missteps, the track record of the past half century demonstrates that the oversight framework is indeed robust: When IC agencies, or individuals within them, overstep their bounds, those actions have often been identified quickly and addressed with a combination of tailored responses or systemic reforms. Most of the intelligence controversies of recent years have been focused not on unauthorized activities, but on whether activities approved by judges and permitted under the law are consistent, from a public-policy perspective, with American values.

That’s a very different problem than a vague and unfounded notion that the IC, or its officers, has gone rogue. In other words, the framework put in place by the Church Committee has worked quite well to prevent improper surveillance against Americans. To throw around terms such as spying unfairly—and inaccurately—suggests that the IC is still playing fast and loose.

One of the many abuses identified in the Church report was its conclusion that information had been collected and disseminated in order to serve the purely political interests of an intelligence agency or the administration, and to influence social policy and political action. The report described how these politically motivated abuses had taken place under every administration from Franklin D. Roosevelt to Richard Nixon.

This history is one of many reasons so few political appointees are in the IC, and why IC personnel are “further restricted” under the Hatch Act and barred from political activity. Today, at the working level where the daily grind of intelligence gathering is done, most IC personnel stay in the business for many years and through multiple administrations; partisan domestic politics rarely enters into their day-to-day intelligence work. The baseless insinuations that it does will do lasting damage to the credibility of the IC.

It’s ironic, perhaps, that the 1976 congressional investigation that so influenced Barr found that a series of attorneys general had been guilty of politically motivated misuse of the intelligence apparatus. In his response to the Mueller report, Barr has argued that there can’t be obstruction of justice without an underlying crime, leaving commentators to scratch their head over difficult questions of divining people’s intent from their actions. We may not be able to divine Barr’s intent in making repeated references to “spying.” But we know he’s producing a detrimental impact.



Somewhere inside my fertility clinic’s laboratory, in a tank of liquid nitrogen, there are several vials with my name on them. The vials contain five embryos, frozen at the blastocyst stage since early 2013, when they were created from a single round of in vitro fertilization, or IVF, using my eggs and my husband’s sperm. I have never seen the vials, but my husband and I pay a storage fee—currently $45 a month—to keep them preserved. In the six-plus years we’ve had them in storage, we’ve paid more than $3,000 to the third-party company in charge of billing, administration, and what the company calls “disposition”: that is, what happens to the embryos when they are no longer part of our family-building plan.

A human blastocyst is an embryo 0.1 to 0.2 millimeters in diameter, round like a soccer ball. It consists of about 100 cells, divided into an inner mass, which could become a fetus, and an outer shell, which could become a placenta. IVF patients whose cycles produce a number of embryos are often advised to allow them to reach the blastocyst stage, when doctors can determine which embryo has the best chance of implantation and development, before transferring or freezing them. Even at this stage, the chances are not great—about half of blastocyst transfers will fail to implant, or will result in a chemical pregnancy or miscarriage.

During my IVF cycle, I kept a small black notebook with me during phone calls and meetings with our doctor and embryologist. I recorded the number, quality, and stage of development of our embryos in my most careful handwriting, and I taped four-leaf clovers, found on my daily river walks, in the pages that followed. Up to that point, those embryos were my most costly and meaningful investment. They were precious to me, because they represented what my husband and I believed was our best chance of building our family. We were extremely lucky—from the initial group of embryos, our two daughters were born: Beatrice, in 2013; and Harriet, in 2018. They are the great joys of our life.

I think of the remaining five embryos often these days because we are at the “disposition” stage—our family is complete—and also because the question of embryonic personhood has made its way again into the courts. The “heartbeat” laws outlawing abortion after six weeks’ gestation in Ohio, Georgia, and other states were intended to provoke litigation. In a recent Supreme Court opinion, Justice Clarence Thomas evoked the eugenics movement and described the fetus as an “unborn child.” As others have noted, Thomas’s opinion signals receptivity to the ultimate test, and potential undoing, of Roe v. Wade, a ruling grounded in a woman’s right to privacy. If fetuses, or even embryos, are given the status of persons, her privacy won’t matter. All abortion and possibly some forms of birth control could then be deemed unconstitutional.

Most Americans agree that women should have at least some access to abortion; we also agree that a cryopreserved blastocyst is not the same as a child. These moral judgments are meaningful. As the anti-abortion movement poses the question of fetal personhood, deciding what to do with our embryos has been instructive to me in thinking it through. Leaving those vials in the freezer would be unthinkable if a 0.1-millimeter embryo, or a pea-size fetus, was truly a child. Instinctively, though, we know otherwise.

The choices my husband and I have are as follows: donate our embryos to another couple or individual, donate them to medical research, thaw them and discard them, or continue paying for their storage indefinitely.

Because we know, from years of trying, how hard overcoming infertility can be, donating them might make sense; surely this would give someone else the same joy that we experienced. If we donate them to research, perhaps we could contribute, in some small way, to the cure for a debilitating disease. Or we could ask the clinic to thaw the embryos and dispose of the remains (though we’d be wasting the opportunity for science to benefit from embryonic stem cells). For me, the only option that is completely off the table is what we are doing now—continuing to store them, at $45 a month.

While writing this essay, I tried to find the black notebook that had once been so precious to me—the one in which I had listed our embryos and their stages of development, and in which I had taped a photo of the blastocyst that developed into my older daughter. I looked on my desk, in my dresser, and on the several bookshelves where I thought it could be. I didn’t find the notebook, but I did find many signs of my actual children: a song written by Beatrice, which I typed up at Christmas; books by Sandra Boynton and Arnold Lobel; some costume jewelry and paper fans; a canister of glitter, which I am always trying to hide from Beatrice; and the many crystals, rocks, and geodes that Beatrice is always trying to hide from Harriet. I realized that, for me, the embryos are not special, or meaningful, or worth protecting or preserving now that they are not part of my family plan.

Abortion opponents commonly treat birth as the finish line, the point at which they can stop worrying about the welfare of a child and her mother (in North Carolina, where I live, the same politicians oppose Medicaid expansion, for example). But most parents, especially mothers, know that the finish line does not exist. My children, their friends, and every person walking or crawling on this planet have vast and often unaccounted-for needs that stretch far into the future. They need to breathe clean air and drink uncontaminated water. They need education and health care and healthy food. They need to be kept safe from gun violence. They need protection from the floods and hurricanes and tornadoes and fires that are terrifyingly more common and severe thanks to global warming. One day, they will need reproductive health care.

Forty-five dollars a month is not much—I pay more each month toward my phone bill, and to drive and park my car at work. But $45 would also buy books for a classroom library, compost bins for a community garden, or supplies for an after-school theater program. It could contribute to someone’s health care, including their reproductive health care. In the end, I would much rather take care of the people who are here now—the needy, beautiful humans who already surround us.



The conventions of mainstream journalism make it difficult to challenge America’s self-conception as a peace-loving nation. But the unlovely truth is this: Throughout its history, America has attacked countries that did not threaten it. To carry out such wars, American leaders have contrived pretexts to justify American aggression. That’s what Donald Trump’s administration—and especially its national security adviser, John Bolton—is doing now with Iran.

The historical examples abound. William McKinley’s administration sought a pretext for war in 1898, when—driven by the desire to evict Spain from its colonies in the Caribbean—it ignored evidence that an internal explosion, not a Spanish attack, had blown up the USS Maine in Havana’s harbor. In 1964, Lyndon Johnson exaggerated a North Vietnamese attack on U.S. destroyers in the Gulf of Tonkin to win congressional approval to escalate the Vietnam War. In 1986, Ronald Reagan’s administration sent warplanes toward Libya’s coast to provoke the missile fire that would justify an American bombing campaign. In 1997, according to the memoir of General Hugh Shelton, former chairman of the Joint Chiefs of Staff, a top official in Bill Clinton’s administration suggested that the general lure Saddam Hussein into shooting down a U-2 spy plane over Iraq so the U.S. would have the “precipitous event” it needed “to go in and take out Saddam.” (Shelton refused.) In their book, Hubris, David Corn and Michael Isikoff recount a 2002 CIA plan to help Iraqi exiles take over an Iraqi air base and thus, in the words of one of the plan’s authors, “create an incident in which Saddam lashes out” so “you’d have a premise for war.”

Bolton is doing something similar today. For more than a decade, he’s consistently promoted war with Iran. All that has changed are the pretexts he’s offering to justify one.

In January 2007, President George W. Bush accused Iran’s Revolutionary Guard Corps of “providing material support for attacks on American troops” in Iraq and launched a series of raids in which American soldiers detained Iranian officials there. U.S. and British intelligence analysts cast doubt on the claims of top Bush officials that Iran was a major driver of the Iraqi insurgency. Nonetheless, in internal administration discussions that summer, Vice President Dick Cheney reportedly urged air strikes against alleged insurgent training camps in Iran. And Bolton, who had left the Bush administration the previous year, publicly endorsed the idea. He argued on Fox News that the U.S. “is fully entitled to take defensive measures, which could include going after the Revolutionary Guards inside Iran.”

But Bolton was just getting started. In 2008, he offered another rationale for striking Iran: that in addition to supporting anti-American forces in Iraq, it was “doing much the same by aiding the Taliban in Afghanistan.” Over the next few years, as American soldiers left Iraq, Bolton’s initial rationale faded. But his desire for war did not. From 2012 to 2015 he repeatedly called for bombing Iran to stop its nuclear program.

Since becoming Trump’s national security adviser, Bolton has continued this pattern. Along with Secretary of State Mike Pompeo, he’s offered justification after justification for attacking Iran. When one hasn’t worked, he’s found another.

Last September, a militia linked to Iran allegedly launched three mortars into an open lot near the U.S. embassy in Baghdad, hurting no one. According to The New York Times, then–Defense Secretary Jim Mattis dismissed the attack as “insignificant.” But Bolton demanded that the military draw up plans for retaliation. “People were shocked,” one former administration official told The Wall Street Journal. “It was mind-boggling how cavalier they were about hitting Iran.”

Mattis averted an American strike. But he couldn’t stop Bolton from giving a speech that same month that all but advertised his desire for war. Addressing Iran’s leaders, Bolton announced, “If you cross us, our allies or our partners, if you harm our citizens, if you continue to lie, cheat and deceive, yes, there will indeed be hell to pay … We are watching and we will come after you.”

In November, according to The New Yorker, Bolton found another pretext for military action. Iran was preparing to test-fire a medium-range ballistic missile, and Bolton suggested shooting it down. Again, he was overruled.

Then, in January, Iran launched a satellite into space. “This is in defiance of UNSCR 2231,” Pompeo tweeted. “We won’t stand by while the regime threatens international security.” The New York Times noted that “the Pentagon and intelligence agencies disagreed with Mr. Pompeo’s interpretation of the threat posed by the satellite launches,” which Iran had been conducting since 2005. Yet again, security officials reined in Pompeo and Bolton. But within the military, alarm was spreading. “Senior Pentagon officials are voicing deepening fears,” another Times piece reported that month, “that President Trump’s hawkish national security adviser, John R. Bolton, could precipitate a conflict with Iran.”

The fears were well placed. In April, Pompeo told Congress, “There is no doubt there is a connection” between al-Qaeda and Iran—which raised the prospect that the Trump administration would not request new congressional authorization for war with Tehran. It would simply invoke the authorization against al-Qaeda that Congress passed three days after 9/11.

That same month, Bolton and Pompeo pushed through a decision to designate Iran’s Revolutionary Guard as a terrorist group, overriding the objection of General Joseph Dunford, the chairman of the Joint Chiefs of Staff, and other military officials, who warned, according to the Times, that the move “could incite retaliation by Tehran against American troops and intelligence officers.”

Still, Bolton and his fellow hawks turned up the pressure even further. In April, the Trump administration announced that the U.S.—having already reimposed sanctions on Iran after withdrawing from the 2015 nuclear deal—was eliminating the waivers that permitted China, India, Japan, South Korea, and Turkey to buy Iranian oil. The goal, in Pompeo’s words, was to drive Tehran’s oil exports—which provide roughly 40 percent of its government revenue—to “zero.” In May, the administration added sanctions on Iranian steel, aluminum, iron, and copper, which comprise 10 percent of the country’s exports.

By May, events were bearing out the Pentagon’s fears. “In private meetings,” the Times noted, “military officials have warned the White House that its maximum-pressure campaign against Iran is motivating … threats to United States troops and American interests in the Middle East.” The former Bush-administration official Kori Schake observed that “every single European government believes that the increased threat we’re seeing from Iran now is a reaction to the United States leaving the Iran nuclear agreement and trying to force Iranian capitulation on other issues.”

This was the plan: Provoke Iran until it provides a pretext for America to strike. (What comes after such a strike is something Bolton has not publicly discussed as national security adviser. In his previous writing, he has generally breezed past the subject while vaguely suggesting that an attack might help foment regime change.)

In May, Bolton announced that the U.S. was sending an aircraft-carrier strike group and Air Force bombers to the Middle East and warned that “any attack on United States interests or on those of our allies will be met with unrelenting force.” Pompeo added that the U.S. would hold the “Iranian leadership directly accountable” for any attack by a “third-party proxy, whether that’s a Shia militia group or the Houthis or Hezbollah.” The conditions Bolton and Pompeo laid out were broad and vague enough that accusing Iran of violating them would be easy. What constitutes an “interest” of American allies like Saudi Arabia and the United Arab Emirates is far from clear. And many experts don’t believe that Tehran—which Pompeo said would be held responsible for the misdeeds of the Houthi rebels in Yemen—has much operational control over them. In his eagerness to find evidence of Iranian aggression, Pompeo in June blamed Tehran for a suicide attack in Kabul for which the Taliban had claimed responsibility. The Washington Post reported that Pompeo’s claim “surprised regional experts and a former U.S. diplomat, who said it would be unusual for Iran to launch an attack inside the Afghan capital.”

Now Bolton and Pompeo are accusing Iran of attacking ships carrying oil out of the Persian Gulf. Even American allies have viewed these claims skeptically, and for good reason: In the Bush administration, Bolton was notorious for being, in the words of one former colleague, “cavalier not just with intelligence, but with facts,” and “impervious to information that goes against his preconceived ideological views.”

Moreover, if Iran really is attacking oil tankers, the Trump administration’s own actions are a big part of the reason. As the Israeli analyst Ehud Yaari noted in May, “The Iranians’ motto is, if you’re going to prohibit exporting our oil … which is an economic catastrophe for Iran, then we will interfere with the oil exports of other people.” In the words of Karim Sadjadpour, an Iran expert at the Carnegie Endowment for International Peace, “Iran was getting repeatedly punched in the face by the Trump administration, and they’ve been warning for months there will be consequences.”

One of those consequences, Iran announced this week, will be its violation of the limitations on uranium enrichment codified in the 2015 nuclear deal. A spokesman for Bolton called the move “nuclear blackmail” that “must be met with increased international pressure.” The hypocrisy is astounding. After massively expanding sanctions—and thus denying Iran the key benefits it was promised under the nuclear deal—the Trump administration is now threatening Iran for potentially violating an international agreement that the United States has been brazenly violating for more than a year.

Trump himself has downplayed the tanker attacks as “very minor.” But whether he can ease the tensions that his aides have systematically inflamed is unclear. Meanwhile, Bolton and Pompeo are nearing their endgame. Since they were appointed to their positions last year, they have been seeking justifications for war with Iran. Now that they have succeeded in provoking Tehran into violating the nuclear deal and, perhaps, interfering with commercial shipping, they’re pretending they had nothing to do with any of this. They’re mere bystanders to Iranian belligerence, to which Americans may reluctantly feel compelled to respond.

For more than a century, this false innocence has been a feature of every unprovoked American war. And it is this false innocence that Americans must relentlessly challenge if they wish to avoid war with Iran now.



Among the biggest surprises of the Democratic presidential campaign so far are the rise of Pete Buttigieg and the resurgence of Elizabeth Warren, both of whom, according to a new Des Moines Register poll, have moved into a virtual tie for second place in Iowa with Bernie Sanders. In many ways, the Buttigieg and Warren phenomena are distinct: Buttigieg promises generational change; Warren is almost 70. Buttigieg emphasizes his success in a conservative state; Warren stresses her willingness to challenge corporate power. Buttigieg has become a darling of the big donors whom Warren eschews.

What unites them, and separates them from Sanders and Joe Biden, is their unabashed intellectualism. Both have made braininess central to their political brand. And it’s working—a fact that offers a window into the changing culture of the Democratic Party.

Warren and Buttigieg don’t showcase their smarts in exactly the same way. Warren does it with deep dives into policy: proposal after detailed proposal on subjects such as housing, climate change, child care, college tuition, and antitrust. Her campaign sells Warren has a plan for that T-shirts. She talks gleefully about “nerding out” on policy, and when asked at a CNN town hall whether she preferred being a politician or a professor, she replied, “Oh, teaching, are you kidding?”

If Warren plays the brilliant professor, Buttigieg plays the brilliant student. Among the people who introduced him when he announced for president was a former teacher who began her remarks by describing how he had wowed the judges at a high-school economics competition sponsored by the Federal Reserve. Type Pete Buttigieg into Google, and one of the prompts you get is “languages.” News reports often mention that he speaks seven, and this spring a video of him speaking Norwegian went viral. In April, he filmed a video in French offering his condolences for the fire at Notre-Dame.

It’s not unusual for Democratic presidential candidates to have impressive resumes. Bill Clinton is a Rhodes Scholar; Barack Obama was the president of the Harvard Law Review. Cory Booker and Julián Castro attended Stanford; Amy Klobuchar went to Yale. In fact, every president since Ronald Reagan has been a product of the Ivy League.

What’s new is that Warren and Buttigieg are leaning into their credentialed intellectualism rather than worrying that it will make them appear elitist. That’s exactly what Clinton’s advisers feared in the summer of 1992, when the Arkansas governor was trailing both George H. W. Bush and the businessman Ross Perot, who boasted that he was assembling a team of “Road Scholars in Washington—that’s r-o-a-d scholars, the people who are street smart and have common sense.” Clinton’s advisers responded with a biographical video, titled “The Man From Hope,” which emphasized his small-town roots and avoided mentioning that he had attended Georgetown University and Oxford. In the film’s only reference to Yale Law School, Hillary Clinton notes that Bill didn’t want to serve on the school’s law review, because he was more interested in returning to Arkansas to be a “country lawyer.”

Bill Clinton’s anxiety about appearing smarter than thou seemed borne out when George W. Bush used Al Gore’s academic affectations against him in 2000. After a widely discussed New Yorker essay in which Gore confessed his fondness for Maurice Merleau-Ponty’s book Phenomenology of Perception, Talk magazine asked Bush to admit a weakness. He answered slyly, “Sitting down and reading a 500-page book on public policy or philosophy or something.”

A similar dynamic played out in 2004. Like Buttigieg, John Kerry speaks French. But Kerry didn’t showcase that ability while running for president. To the contrary, Republicans used his linguistic skills to undermine his Americanness. Then–House Majority Leader Tom DeLay delighted GOP audiences by beginning speeches by saying “Hello, or as John Kerry might say, ‘Bonjour.’”

Bush’s and DeLay’s attacks reflected a shift in the culture of the GOP. As late as 1994, according to the Pew Research Center, voters who had graduated from college were 15 points more likely to identify as Republicans than Democrats, and voters with graduate degrees were almost evenly split between the two parties. By 2017, college graduates’ partisan leanings had flipped: They now favored Democrats by 15 points. Among Americans with graduate degrees, the shift has been even starker. The Democratic advantage, which stood at two points in 1994, had grown to 32 points by 2017.

As a result, the educational composition of the two parties has diverged. From 1997 to 2017, the share of registered Republican voters who finished college stayed the same. Among Democrats, it rose by 15 points. This shift has influenced the way the two parties see education itself. In 2010, Democrats were seven points more likely than Republicans to say that colleges and universities have a positive effect on America. By 2017, they were 36 points more likely.

Now a decade or two after Bush and DeLay realized that anti-intellectualism mobilizes Republicans, Warren and Buttigieg have realized that intellectualism mobilizes Democrats. Unlike Biden and Sanders, they both poll significantly better among voters with college degrees, who in recent decades have grown substantially as a share of the Democratic primary electorate. Buttigieg’s reputation for detailed, thoughtful answers—as showcased in his widely hailed CNN and Fox News town-hall events—has helped elevate him above his closest generational rival, Beto O’Rourke. And Warren’s unabashed wonkery has helped her close the gap with Sanders on the party’s left flank.

Warren and Buttigieg are also likely benefiting from the contrast with Donald Trump. “Wouldn’t it be great to have a president who was really smart. I mean really, really, really smart,” declared Steve Adler, the mayor of Austin, Texas, at Buttigieg’s announcement rally. “Someone who spoke multiple languages, including having a beautiful command of English.”

If Warren or Buttigieg wins the nomination, the 2020 presidential race will feature the most profound intellectual contrast in modern American history. It’s difficult to envision a debate between Warren, who asks crowds, “Do I have any net-metering wonks out here?” and Trump, who claims that tariffs are a payment China makes into the United States Treasury. Or between Buttigieg, who speaks about John Rawls and James Joyce, and Trump, who speaks about “Two Corinthians.”

It’s likely Republicans would try to turn intellectualism into a negative for either Warren or Buttigieg. After all, the general electorate is neither as highly educated nor as favorably disposed toward higher education as Democratic primary voters. It’s a tactic that’s worked in the past. What’s harder to know is what will happen if a Democratic nominee wears these attacks as a badge of honor. To the debates over whether America is ready for a woman or a gay president, Warren and Buttigieg are adding an additional wrinkle: Is it ready for a nerd president, too?



“Basically, my entire adult life has been one where it’s a little bit illegible where you’re supposed to be as a Democrat on foreign policy,” Pete Buttigieg told me last weekend. He was preparing to give his first speech on the subject, today at Indiana University. So far, most of the Democratic candidates have avoided the question of how they’d conduct foreign policy, and the voters and the press have made that easy for them.

When candidates decide to say something about global affairs, they tend to quarantine their views in a single all-encompassing speech, as if to get the topic out of the way. Elizabeth Warren gave hers in Washington in November. Bernie Sanders has actually given two, in Missouri in 2017 and last fall at Johns Hopkins. None of the other candidates has given even one.

This silence about America’s role in the world is strange. The quest to replace Donald Trump presents the first chance since the end of the Cold War for Democrats to think fundamentally anew about foreign policy. The liberal internationalist approach of the Bill Clinton years aimed to enlarge the sphere of capitalist democracies, manage the world’s chaos, and extend American influence, through free trade, NATO expansion, diplomatic deal making, and occasional military intervention.

The high-water mark was the American-led peace agreement in 1995 that ended the war in Bosnia and repaired damage to the transatlantic alliance. September 11, the Iraq War, and the financial crisis threw this consensus into confusion. Those were the early years of Buttigieg’s adult life, when Democratic foreign policy became “a little bit illegible.” Still, the approach of the ’90s persisted into Barack Obama’s presidency—free trade, diplomacy, ongoing war—even as Obama himself became more and more skeptical of American overreach.

Hillary Clinton, a holdover from the unipolar moment, was the last of the muscular interventionists. Her defeat marked the demise of the old liberal internationalism, and Trump has shattered what was left of it. But this landscape of ruins is also an open field. In his Indiana speech, Buttigieg welcomed “a season for thinking about what comes next with greater urgency and, in certain ways, greater freedom than has been available to a president for some time.”

Most of the energy in the new thinking is on the left. Sanders has called for a foreign policy based on the worldwide struggle against oligarchy and corporate power—a “global progressive movement” for economic equality, democratic rights, and environmental sustainability. In this view, American dominance has been a mixed bag at best, a force for ill as much as good, and it should yield to a transnational movement led by citizens, not just governments.

As Peter Beinart has pointed out, this idea goes back to World War II and the appeal in 1942 by FDR’s Vice President Henry Wallace for a foreign policy of “the common man.” Wallace wanted to extend the New Deal into the postwar period as a worldwide crusade for equality. Sanders wants to take his “political revolution” at home and join it to a worldwide campaign against authoritarians and for “the people.” It isn’t the foreign policy of a nation-state so much as the extension of movement politics across borders, as if President Sanders would be the leader of a global nonprofit organization, not a country.

Where does Buttigieg come down? When I asked him which recent presidents might serve as models for foreign-policy making in his administration, he didn’t single anyone out. “What’s interesting about the period certainly since the Cold War is how hard it is to say there’s been a real alignment that many of us could feel like we’re signed up for,” he said. “Most of what I get out of looking at the past is cautionary tales, and just reminders of how hazardous it is.”

After our interview, he got back to me with the name of an earlier president—Harry S. Truman, the namesake of one of Buttigieg’s dogs. In 1948, Truman defeated Wallace, the Progressive Party candidate, and made liberal anti-communism the doctrine of the postwar Democratic Party.

Buttigieg doesn’t have anything like a doctrine yet, or even detailed policy positions, and he doesn’t speak Truman’s rough-hewn Middle American. When Buttigieg talks about foreign policy, he sounds more like a Rhodes Scholar and McKinsey consultant than like a midwestern mayor or a veteran—“challenges and opportunities,” “You’ve got diplomatic, economic, information, and cybertools in your toolkit in addition to the hard-security assets.”

Buttigieg spent seven months as a Navy intelligence officer in Kabul in 2014, which was supposed to be the last year of the American war in Afghanistan. Five years later, American troops are still there. Buttigieg is a critic of ill-defined military intervention generally. “I believe we should use force when there is a clear and present threat to the U.S.,” he said in his speech, “when it’s necessary to deter and defend against an attack on or imminent threat against the United States, our citizens at home or abroad, or our treaty allies, and when we act as part of a legitimate international coalition to prevent genocide or other atrocities.” Those conditions would have ruled out the war in Iraq, of course, which Buttigieg opposed while he was at Harvard, but also military intervention in the Syrian civil war. When I asked whether he would have ordered missile strikes after the Syrian regime massacred civilians with chemical weapons outside Damascus in the summer of 2013, the answer was no, not without the support of allies and Congress.

That was also Obama’s position. (Buttigieg added that the “deeper problem” was Obama’s original red line, which turned out to be erasable.) But Buttigieg doesn’t see Obama’s foreign policies as useful guides to the future. Both Republican and Democratic presidents since the Cold War have failed to connect events overseas with the lives of ordinary Americans. It wasn’t until his last months in office, just days after the election of Trump, that Obama said, “Globalization needs a course correction.” That failure to see the connection between foreign and domestic policy explains the public’s exhaustion with unexplained commitments and its loss of faith in foreign-policy elites.

Buttigieg is placed by age and experience—a Millennial, a veteran of the forever war, the mayor of a struggling industrial city—to insist on making the connection. “Everything we have to say about foreign policy has to be tied back to what it means at home,” he told me. In other words, every geopolitical move should be evaluated by its effect on American workers, farmers, and citizens.

Ever since the ’90s, for example, America’s relationship with China has generally been more beneficial for elites than for ordinary Americans. “I’m not among the Democrats who think that China’s nothing to worry about,” Buttigieg said. He might have been talking about Sanders, who barely mentioned China in his two speeches, and then described it not as an economic and political threat but as a global partner on climate change. “While I think it’s a real strategic failure to just poke them in the eye with tariffs and see what happens,” Buttigieg went on, “I think it’s not wrong to perceive a real challenge from China.” Under Trump, he admitted, “there’s something about the orientation on China that I think is not completely wrong.”

But where Trump sees a merely economic rival, Buttigieg sees a dangerous ideological model (“the perfection of dictatorship”) whose stability and success look more and more attractive to other countries. To prevail against that competition, America has to be true to its own claims about itself. “If the U.S. is perceived as seeking to dominate the world as a matter of just calculation around our interests, then I think it’s going to be morally suspect, and it’s going to arouse a lot of resentment around the world and ultimately be self-defeating.” But the rising popularity of Chinese-style authoritarianism and Russian-style oligarchy make it all the more important “that American values be vindicated globally … It’s actually a moment that kind of makes me, more than usual, feel patriotically committed to American values, at least American values at our best and what they’re supposed to be.” In framing a picture of the next few decades as a battle of competing ideologies, Buttigieg sounds a bit like Truman at the beginning of the Cold War.

Buttigieg wants to set a generous narrative of national identity against Trump’s cramped and cruel vision, and against the progressive hostility to any national identity at all. It won’t be easy. He speaks of the compassion of his Indiana neighbors toward refugees, their desire to be part of “a greater project” than just America First. But the strongest political emotions of the moment are fear, disillusionment, and hatred. As impressive as he is personally, Buttigieg hasn’t yet found the words, the music, and the policies to make his appeal convincing.



Pete Buttigieg’s foreign-policy speech started with a thinly veiled jab at President Barack Obama and his vice president, Joe Biden. For “the better part of my lifetime,” Buttigieg said, “it has been difficult to identify a consistent foreign policy in the Democratic Party.”

“We need a strategy. Not just to deal with individual threats, rivalries, and opportunities, but to manage global trends,” he said. And he warned that “Democrats can no more turn the clock back to the 1990s than Republicans can return us to the 1950s, and we should not try.” In case anyone had missed the point, he added, “Much was already broken when this president arrived.” Buttigieg offered plenty of criticism of President Donald Trump, of course, but his message was clear: I will be different from my Democratic predecessors. 

But in the hour that followed, Buttigieg sounded very Obamaesque. He even began with an introduction by Lee Hamilton, whom Obama admired and embraced in 2007. Buttigieg was thoughtful in how to deal with individual threats and challenges, including climate change and right-wing terrorism, but did not offer an overarching strategic vision. He was passionate about modernizing the American system at home to prepare for the future. He spoke of living our values at home, just as Obama and Biden do. He struck a middle ground on intervention, calling for an end to the wars of 9/11 but outlining criteria that would allow for future interventions, even unilateral, if the stakes are high enough and other options have been exhausted. He made time for technocratic fixes to the national-security bureaucracy. He praised allies in general but mentioned none by name, except those with whom he had a problem. Obamaesque indeed.

By contrast, whether you agree with them or not, Bernie Sanders and Elizabeth Warren have been crystal clear in what they see wrong in the Obama years. They believe the former president tolerated a rigged global economy, did not pay enough attention to oligarchic authoritarianism, and set the defense budget far too high. There is a centrist critique too: Obama was too complacent about the trajectory of world politics, did not take geopolitical competition seriously enough, and proved too risk-averse. Buttigieg seemed to want to have it both ways—to be the candidate of change within his party without ever quite explaining what that meant.

The closest he came was on China—the most impressive part of his speech, along with the passage on climate change—admirably warning of the rise of techno-authoritarianism and condemning reeducation camps in Xinjiang. Buttigieg seems genuinely offended and worried by China’s challenge to liberal values. He told The Atlantic’s George Packer that China seeks “the perfection of dictatorship,” that “it’s not wrong to perceive a real challenge from China,” and that the Trump administration’s orientation on China is not completely incorrect. In other recent interviews, he has spoken about the China challenge, and he tweeted about the anniversary of Tiananmen and Hong Kong, so this has been building for a while.

But even on China, there were missed opportunities. He did not say, as former Obama-administration officials have written, that successive administrations have gotten China wrong in important ways—this would have allowed him to make the case for a break with Obama. Although he implied as much, he stopped short of explicitly stating that the United States is in a geopolitical competition. He said nothing about his affirmative vision for the Asia-Pacific, the key geopolitical element of any China policy. He spoke about improving domestic competitiveness, but Warren has gone further in calling for an industrial policy to invest in key technologies where the Chinese mercantilist system may have an edge. The China frame has a lot of potential as a political message, but Buttigieg will need to do more to explicitly link his foreign policy to his economic agenda.

International economics may be where Buttigieg is most vulnerable. He promised to take the concerns of the middle class into account. However, he also said that “globalization is not going away,” and that the way to deal with its challenges is to harness the potential of global markets, support immigration, and leverage the education system.

It was all a bit mid-2000s. There was no suggestion that the United States and like-minded countries could change the patterns of globalization if they so desired. Trade was mentioned only in passing. We were left none the wiser as to whether Buttigieg supported the Trans-Pacific Partnership or the Transatlantic Trade and Investment Partnership or the World Trade Organization. He did call for updating international institutions, but that was a line that could have been—and indeed was—uttered by Obama in 2007. Then it was fresh. Now, without details and with adverse shifts in Brazil, China, and Russia, it sounds clichéd.

Unless he changes course quickly, Buttigieg has created a real opening for the other candidates to go after him on globalization. Even if he manages to parry those attacks, he missed an opportunity. There is a middle ground between the old consensus of the 2000s and Warren and Sanders’s argument that globalization is essentially a conspiracy perpetuated on the American people by corporations and vested interests. Some economists, such as Larry Summers, now advocate for a policy of “responsible nationalism,” pressing for more stringent regulation and making sure companies don’t use international tax law to their advantage. There’s innovative thinking among Democrats on how to work around a flawed WTO and build an international coalition to address Chinese mercantilism, but Buttigieg did not offer it to his audience.

One topic Buttigieg did distinguish himself on was military intervention, and there he might have laid a trap of his own for his more progressive rivals. Intervention is not very popular among Democrats at the moment. Sanders and Warren have railed against it, but haven’t outlined any criteria for when they would intervene. Buttigieg did. He said that vital interests would have to be at stake and that force must be a last resort. Unilateral intervention would be justified only in exceptional circumstances. He embraced the doctrine of Responsibility to Protect, which provides for intervention to stop genocide.

Progressives will be tempted to criticize him, but he can fairly ask what their criteria are: Do they propose never to intervene, even if confronted with an imminent human-rights atrocity with congressional support and a viable military plan? However, he may have undermined his own message in his interview with Packer when he said he would have opposed limited military strikes on Syria in 2013 because the U.S. lacked allied and congressional support. (In fact, American allies generally backed U.S. strikes.) He said he would never have drawn the red line in the first place—which prompts the question of whether he would tolerate the use of chemical weapons without punishment.

Buttigieg took a firm line against Israeli annexation of the West Bank, suggesting he understands the role of power and leverage in American foreign policy. However, his pledge to simply rejoin the Iran nuclear deal as if nothing had happened smacked of naïveté—repairing the damage Trump has wrought will be a much more complex and difficult task.

Buttigieg also struck a different note than progressives typically sound on the defense budget. He asked the right question—does America have the right type of military?—rather than calling for unilateral cuts. He made a powerful case for modernization to deal with future threats. He made important points on disseminating the truth in an age of deep fakes and state-sponsored disinformation. Yet he was weak on geopolitics. His discussion of Asia was confined entirely to China and North Korea, and his discussion of Europe was entirely about Russia. He had nothing to say about the major trends in East Asia or Europe, although he did speak more about Africa.

Reading between the lines of his speech and recent interviews, there might be a way to understand Buttigieg’s policies that he himself is not yet willing to articulate. He is an heir to Obama’s cautious and intellectual worldview—except that while Obama was, at heart, a realist influenced by the writings of Reinhold Niebuhr and the actions of Brent Scowcroft, Buttigieg is more motivated by values. Buttigieg is, at heart, a liberal internationalist who is looking beyond interventions to challenges posed by great powers, bridging the gap between the Obama and Clinton wings of his party. He fears that, left untended, threats to liberty abroad will ultimately threaten liberty at home. Buttigieg still has a lot of work to do to unpack what this means, but if he sticks to it and is bolder than he was on Tuesday, he may be able to articulate the alternative he promised.



For more than 30 years, the critic Camille Paglia has taught at the University of the Arts in Philadelphia. Now a faction of art-school censors wants her fired for sharing wrong opinions on matters of sex, gender identity, and sexual assault.

“Camille Paglia should be removed from UArts faculty and replaced by a queer person of color,” an online petition declares. “If, due to tenure, it is absolutely illegal to remove her, then the University must at least offer alternate sections of the classes she teaches, instead taught by professors who respect transgender students and survivors of sexual assault.” Regardless, the students behind the petition want her banned from holding speaking events or selling books on campus. In their telling, her ideas “are not merely ‘controversial,’ they are dangerous.”

Others believe that the student activists are trying to set a dangerous precedent that would undermine freedom of expression and free academic inquiry. “The effort to remove her for expressing her *opinions* strikes me as political correctness run amuck,” a faculty member emailed. “Instead of discussing and debating, they attempt to shame and destroy. This is pure tribalism. It is exactly what Donald Trump does when he encounters something he doesn’t like.” Most at the institution seem to hold positions somewhere in between.

Camille Paglia, who identifies as transgender, joined the University of the Arts in 1984 when older institutions were merging in order to create it. While UArts no longer awards tenure, Paglia is among a few long-serving faculty members grandfathered into a prior system. According to detractors, “Paglia has been teaching at UArts for many years, and has only become more controversial over time.” In fact, she has always been controversial.

In Paglia’s first book, Sexual Personae: Art and Decadence From Nefertiti to Emily Dickinson, she describes sex and nature as “brutal, daemonic” forces, “criticizes feminists for sentimentality or wishful thinking about the causes of rape, violence, and poor relations between the sexes,” and roots sex differences in biology. Seven publishers rejected the book before Yale University Press bought it in 1990; Sexual Personae was then savaged by feminist critics on the way to becoming an unexpected, 700-page best seller. And it sparked a national debate about art, history, gender, ideas that offend, free inquiry, and political correctness.

The fight over Sexual Personae was especially vicious at Connecticut College, where a student suggested adding the book to the institution’s 1992 summer-reading list. Some professors were so outraged that they tried to block its inclusion.

“During meetings with the committee, professors denounced the work as ‘trash’ and compared it to Hitler’s ‘Mein Kampf,’” the Hartford Courant reported. In the campus newspaper, the head of the women’s-studies program opined, “Whenever we think about freedom of expression, we need to think also about the damage that certain kinds of speech can do. Let’s not be fooled by packaging into mistaking any hate-speech or sexist or racist doctrine for ideas.”

But Claire L. Gaudiani, the president of the college, countered, “It is a bizarre idea to think that by placing a book on a reading list that an academic community is endorsing any book as a community. For those who take offense at the various passages is understandable, but we cannot let that influence the book’s selection.”

Sexual Personae stayed on the list.

The student who originally proposed it commented at the time, “I got angry because I was seeing a great deal of intolerance that I would have sworn a few months ago did not exist at Connecticut College. I fear a little bit for the future of the reading program with people here who might try to stifle the diversity of ideas.”

As incoming freshmen arrived for the fall semester, the controversy was still simmering, according to an account published in August 1992 in The New York Times:

Students interviewed on campus said they were more motivated to read the book because the controversy has provoked so much discussion. “When someone tells you not to read something, I suppose that makes you all the more curious to see what all the fuss is about,” said one incoming freshman woman. “I agreed with some things in the book and disagree with others, but I certainly think I am capable of understanding it and discussing its meaning. It’s pretty condescending for a professor to think that freshmen aren’t capable of that …”

The president of the student government, Colleen Shanley, added: “Now that I’ve started reading the book, I can’t see why people have been opposed to it. But I feel that it’s when people don’t talk about something that it can become really dangerous. I may not agree with the book’s content, but we should not be removing books from reading lists because don’t agree with them.”

In The Washington Post, the columnist Nat Hentoff argued that “the students in particular saved the book––and the intellectual credibility––of Connecticut College,” endorsing the question posed by one among them: “What is more dangerous––to talk about ideas in the open, or to pretend they do not exist? If we cannot discuss controversial ideas here, where can we have open-minded debate?”

Paglia has been outspoken ever since, transgressing against conservative and progressive pieties alike while commenting on matters of art, culture, politics, and identity. Now it is a group of students, rather than professors, who believe it is more dangerous to talk openly about her ideas than to ban them from campus.

Any student, regardless of ideology or personal identity, risks discomfort attending a Paglia lecture, given the pedagogical approach she has described:

The idea that ‘self-esteem’ should be the purpose of education: this is social-welfare propaganda. Development of our intellect and of our abilities has to be the focus … You build identity. Maybe identity comes through conflict. For example, my struggles with gender, my struggles with sexual orientation, my anguish over so many decades produced my work … Sometimes conflict is creative …

If there’s no pressure on you, there’s no pressure to create.

So we have got to stop this idea that we must make life “easy” for people in school … No. Maybe the world is harsh and cruel, and maybe the world of intellect is challenging and confrontational and uncomfortable. Maybe we have to deal with people who hate us, directly, face-to-face. That’s important. You develop your sense of identity by dealing with the things which would obliterate your identity. It does not help you to develop your identity by putting a cushion between yourself and the hateful reality that’s out there.

This month’s protests began when it was announced that Paglia would give a lecture titled “Ambiguous Images:  Sexual Duality and Sexual Multiplicity in Western Art.” According to a letter that two student activists released, “Joseph McAndrew (they/them), a gender non-binary creative writing major, brought this lecture to the student body’s attention through social media and raised their concerns to Title IX and other University administration about the school giving Camille a platform. This led to the University reaching out to ​Deja Lynn Alvarez, a local transgender activist, to facilitate a talk-back after Camille’s lecture. Students were informed the day before the lecture that Camille had no plans to stay for the talk-back.”

It is rare for student activists to argue that a tenured faculty member at their own institution should be denied a platform. Otherwise, the protest tactics on display at UArts fit with standard practice: Activists begin with social-media callouts; they urge authority figures to impose outcomes that they favor, without regard for overall student opinion; they try to marshal antidiscrimination law to limit freedom of expression. David Bernstein described this process in his 2004 book, You Can’t Say That.

To help justify the effort to suppress Paglia’s speech, student activists pointed to an interview posted to YouTube in which she dismissed some allegations of campus sexual assault:





The girls have been coached now to imagine that the world is a dangerous place, but not one that they can control on their own … They expect the omnipresence of authority figures … They’re college students and they expect that a mistake that they might make at a fraternity party and that they may regret six months later or a year later, that somehow this isn’t ridiculous? To me, it is ridiculous that any university ever tolerated a complaint of a girl coming in six months or a year after an event. If a real rape was committed go frigging report it …

A student cited those remarks in an email explaining why she supports the anti-Paglia protests: “As a survivor of sexual assault, I would never feel comfortable taking a class with someone who stated that ‘It’s ridiculous … that any university ever tolerated a complaint of a girl coming in six months or a year after an event,’ or that ‘If a real rape was committed, go friggin’ report it to police.’ Perhaps this is an ‘opinion,’ but it’s a dangerous one, one that propagates rape culture and victim-blaming. For this and other reasons, I find her place as an educator at this university extremely concerning and problematic.”

Even if students who feel that way should be able to avoid Paglia’s classes, they should not try to impose their preferences on their peers.

UArts administrators felt similarly, declining to cancel the public lecture that Paglia was scheduled to deliver. The student activists responded by protesting the event. In an open letter, the student Sheridan Merrick described what happened next:

We sat out of the way of the door, simply holding signs and chatting amongst ourselves. When the doors to the event were opened, students had the option of attending the lecture (during which no protest signs would be allowed into the space), or remaining in the lobby. Most students chose to peacefully observe the lecture. As students entered … security guards carefully counted the number of audience members and immediately cut students off at the maximum capacity (180 people), no standing room allowed. All other entrances to the recital hall were locked and blocked by security guards.

Around 30 to 40 minutes into Camille’s talk, the fire alarm went off (rumor has it due to it being pulled by a student in protest, though I have no way of confirming this), and Terra building was evacuated. Students who were in class or rehearsal joined those who had been protesting outside of Terra building, chanting: “We believe survivors, trans lives matter.” There were probably around two hundred students chanting this, but I can’t be sure. I only observed one or two students (cisgender “allies”) become even remotely aggressive in their behavior, and by this I mean shouting curse words.

Two UArts educators who were present described how they experienced the same event in emails to me. One wanted to voice “the frustrations of some of the students in attendance, a number of them trans and queer identifying, who under unthinkable pressures from their peer group to conform to the political agenda du jour, showed up that night not to protest but to listen, presumably out of a belief that the ideas that challenge them are often the ideas most likely to nourish them.” While they might “deplore much of what she has said about trans identity and rape culture,” the educator continued, “they also didn’t assume that Camille’s scholarship was therefore invalid or dangerous or traumatizing. It’s the studiousness, integrity, and (yes) courage like theirs that often goes unremarked upon in coverage of these campus eruptions.”

The other educator pointed out that the person who pulled the fire alarm interfered not only with the educational opportunities of students who chose to attend Paglia’s public lecture, but also everyone else taking classes in the building. This educator noted how much money students spend to attend classes:

I take it, and them, very seriously. In one class the students were to finish projects that they had been working on for weeks, with focused assistance. The fire alarm took them out of class for over an hour while they stood outside to listen to a group screaming “trans lives matter!” at them. What did this produce? Projects weren’t finished, the class wasn’t finished, the students lost out. I don’t care if they were black, trans AND disabled—I was there to help them learn 100 percent. And I was blocked from doing that, that night.

A third educator spoke with students and relayed their perspective. “My students seemed to feel as though they were crossing something of a picket line just to be attending the event without the intent of shouting Camille down,” he emailed. “That an opinion differing from the majority’s, even at a place of supposed open mindedness and tolerance, can so readily be codified as ‘harmful’ and/or ‘violent’ is deeply concerning to me. And that Camille holds her own, perhaps unique, opinions should not automatically make her a threat.”

As significant as the protest itself was the response by UArts President David Yager, who released a long statement defending free expression. Its core message:

Across our nation it is all too common that opinions expressed that differ from one another’s––especially those that are controversial––can spark passion and even outrage, often resulting in calls to suppress that speech. That simply cannot be allowed to happen. I firmly believe that limiting the range of voices in society erodes our democracy. Universities, moreover, are at the heart of the revolutionary notion of free expression: promoting the free exchange of ideas is part of the core reason for their existence. That open interchange of opinions and beliefs includes all members of the UArts community: faculty, students and staff, in and out of the classroom. We are dedicated to fostering a climate conducive to respectful intellectual debate that empowers and equips our students to meet the challenges they will face in their futures.

I believe this resolve holds even greater importance at an art school. Artists over the centuries have suffered censorship, and even persecution, for the expression of their beliefs through their work. My answer is simple: not now, not at UArts.

Later, when student activists launched their online petition, they included the demand, “Yager must apologize for his wildly ignorant and hypocritical letter.”

In a phone interview, Yager told me that he admires the impulse of today’s students to involve themselves in social-justice causes that are greater than themselves, that freedom of expression is especially sacrosanct at an art college, and that he is attentive to the fact that any impingement on Paglia’s ideas, regardless of the merits of those ideas, would have a chilling effect on all speech.

“I would hate to neuter all faculty,” he said.

Yager’s concerns seem warranted. While reporting on this story, I emailed scores of UArts faculty members to solicit comment. A few were willing to speak on the record. Many more on both sides of the controversy insisted that their comments be kept off the record or anonymous. They feared openly participating in a debate about a major event at their institution––even after their university president put out an uncompromising statement in support of free speech––though none expressed any view that couldn’t be broadcast on NPR.

“I’m a faculty member at UArts,” one wrote. “I received your email and thought it prudent to respond using my personal email address. I very much doubt that the IT dept is currently monitoring email activity. BUT they have the ability AND certainly can look up records without privacy concerns. So this is a bit safer. Especially since if I do speak with you it’d be paramount that I be OFF the record. The university has social media/email policies for their faculty.”

Another educator at the college emailed:

In his response, Pres. Yager notes that universities are “at the heart of the revolutionary notion of free expression,” but it is tenure that is supposed to protect academics and give them this freedom he mentions. The vast majority of UArts’ faculty are adjunct or un-tenured full- and part-time instructors who don’t have the same privileges and platform as Dr. Paglia, which makes the whole scenario unbalanced. UArts’ compensation for adjuncts is below average and adjuncts here are not eligible for healthcare or benefits. Within the liberal arts area, Dr. Paglia may be the only tenured faculty member. I think the ethical and appropriate response to this situation is for UArts to commit to hiring more full-time and tenured faculty.

A third educator wrote, “Please do not include my name in your article. Things are rather tense at UArts and we are living in cancel culture, after all. I am in close emotional proximity to students who have signed and promoted the petition. I am not willing to share my thoughts publicly but will consent to share anonymously.” The view this educator feared sharing:

I do not believe she should be removed as a faculty member but I also believe the school belongs to the students. They do not feel safe and I applaud them for taking action to change their environment. I cannot support their cause, however. I believe Paglia represents intellectual dissent within an institution (academia, at large) that often seeks to maintain the status quo and mediocrity of vision. Her perspective, as historically informed and contextualized, is far more objective than students with a limited and subjective scope of understanding at this point in their lives can intellectually grapple with. I think that if they truly listened, they might hear her voice more clearly as someone who seeks to empower the individual above all else.

“Ultimately,” the faculty member concluded, “it is their loss.”

Something has gone wrong in academia when so many faculty members are unwilling to express common viewpoints under their own names.

To better understand the student-activist perspective, I emailed Sheridan Merrick, who posted the Change.org petition. Paglia has been teaching for at least 35 years, I pointed out. If her ideas are not merely controversial but “dangerous,” that implies they have harmed students. Is that the case?

In reply, Merrick cited statistics about the percentage of transgender adults who report having attempted suicide or suffered hate crimes. From there she reasoned:

Paglia’s comments have echoed the hateful language that pushes so many transgender people to contemplate suicide, and encourage transphobic people to react to transgender people violently. We have been experiencing an interesting phenomenon where Paglia’s supporters have been signing our petition in order to leave dissenting comments (this is especially odd considering they have a counter petition that they are welcome to sign). Some of these comments are extremely concerning and blatantly transphobic.

Just one example: “You are either born male, female, or deformed (physically or mentally). Trans people are mentally diseased and often violent. If they are not able to accept the reality of their disease and cope with it they must be removed from society by any means necessary. Some might argue that the high suicide rate among those suffering from this severe mental disease is nature correcting itself. Camille Paglia is a transgender person who was able to accept and overcome her mental disease. Be like Camille.”

Like it or not, Paglia’s philosophies empower people like this, who would have transgender people “removed from society by any means necessary” (this is a violent threat). This has a lasting, negative impact on the transgender community at UArts––whether it be through the psychological damage that comes with being told that you are deformed and diseased and deserve to die, or whether it be through people like Paglia’s supporters acting on their violent beliefs. To have her spouting these beliefs in the classroom and elsewhere makes life more difficult––and dangerous––for transgender students.

I personally know at least one person who, due to Paglia’s comments, has experienced suicidal thoughts and has considered leaving the University. The comments that many of us have been receiving online have caused public safety at our school to be told to up their security game, in case our (very queer) student body is targeted by angry supporters of hers. This is what we mean when we say that her views are not merely controversial, but dangerous.

That argument—a speaker is responsible for harms that are theoretical, indirect, and so diffuse as to encompass actions of strangers who put themselves on the same side of a controversy —is untenable. Suppressing speech because it might indirectly cause danger depending on how people other than the speaker may react is an authoritarian move. And this approach to speech, applied consistently, would of course impede the actions of the anti-Paglia protesters as well.

After all, Paglia identifies as transgender, making her a member of the group at heightened risk of suicide. She was subjected to angry chants from perhaps 200 students, including two cisgender students who shouted curse words at her, not to mention an ongoing effort to take away her livelihood and force her from her longtime community. Social-media protests and the Change.org petition led to vitriol and threats, as in any major culture-war controversy. So treated, many people would suffer more psychological distress than if they saw a YouTube clip, however odious, that didn’t target them personally.

What’s more, when student activists strategically engage in protests, callouts, and other behavior expressly calculated to “make life more difficult” for others, they could indirectly inspire outside parties to engage in threats or even attacks.

Merrick also offered a more bureaucratic line of argument:

The faculty handbook states the following:

“Gender-based harassment is defined as any unwelcome verbal or non-verbal contact or conduct based upon sex or gender, sexual orientation, gender identity or gender expression. Gender-based harassment need not be sexual in nature to be specifically prohibited by this policy. Gender-based harassment includes, but is not limited to, the following: physical assault or physical interference intended to harass on the basis of gender; inappropriate graphics or other displays of gender degrading materials; sexist jokes, anecdotes, or slurs; and insulting, demeaning or derogatory conduct direct toward a person on the basis of their gender. This policy applies to conduct that occurs:

(1) On University premises or property; and/or

(2) In the context of University employment, education, research, recreational, social or artistic activity, irrespective of the location of the occurrence, if the conduct has or can be reasonably predicted to have a continuing negative effect on the University and its students, faculty, visiting faculty, affiliates, staff, contractors, vendors, visitors or guests.”

It seems to me that referring to transgender students as “sniveling little maniacs” is insulting, demeaning, and derogatory towards people on the basis of gender.

The “sniveling little maniacs” quote comes from an event where Paglia was asked about efforts to oust Jordan Peterson from the University of Toronto, after Peterson said professors should not have to use their students’ preferred pronouns. In context, it is clear that “sniveling little maniacs,” whether objectionable or not, refers to activists who believe they are justified in forcing their pronoun choices on others, not transgender students generally. Here is the clip:





Once again, the student activists wield a double-edged sword. If Paglia’s comments qualify as “insulting, demeaning, and derogatory towards people on the basis of gender,” so does lots of speech that is very common on the academic left. For example, locutions such as mansplaining, man-spreading, white male rage, male privilege, toxic masculinity, male gaze, manterrupting, and bropropriating would all be subject to challenge under similarly broad readings of the very same passages in the faculty handbook.

In contrast, robust speech protections like the ones that permitted the Paglia lecture would enable UArts to host events with speakers like the feminist scholar Suzanna Danuta Walters. “Is it really so illogical to hate men?” she asked in a provocative op-ed in The Washington Post. “For all the power of #MeToo and #TimesUp and the women’s marches, only a relatively few men have been called to task … But we’re not supposed to hate them because … #NotAllMen … when they have gone low for all of human history, maybe it’s time for us to go all Thelma and Louise and Foxy Brown on their collective butts.”

Would progressive student activists at UArts favor the expansive interpretation of antidiscrimination language that they are urging if they understood that it would likely result in the suppression of many voices on the identitarian left? Perhaps they anticipate a different outcome: UArts could employ a double standard, allowing academics to freely criticize members of some identity groups but not others, because men are historically privileged while women, gay people, and people of other gender identities are historically marginalized.

But adopting different standards for different identity groups—which would of course never fly in a legal context—would ultimately hurt historically marginalized groups.

Paglia possesses all sorts of knowledge that any student could benefit from understanding. (Understanding doesn’t imply agreeing.) The identitarian conceit is that trans people and survivors of sexual assault can’t learn from Paglia, because she renders them “unsafe.” Meanwhile, cis white males are acculturated to believe that they can always learn from anyone, even professors overtly hostile to their race, sexual orientation, or gender identity. In this way, left-identitarianism encourages historically marginalized groups to believe that they are less resilient and less capable than their white, male classmates. They suggest, falsely, that “harm” is the only possible result of listening to controversial (or even offensive) ideas.

There are, finally, political costs of illiberal activism. By targeting Paglia’s job, student activists may alienate people who are open to substantive critiques of her ideas, yet insistent on the absolute necessity of safeguarding a culture of free speech, regardless of whether the speech in question is “correct” or “incorrect.” They fail to heed Henry Louis Gates’s prescient warning not to divide the liberal civil-rights and civil-liberties communities.

The activists also fail to heed a much older lesson that art students ought to know best: Nothing makes an act of free expression more intriguing than an attempt to censor it.

This article originally misstated when Camille Paglia was hired by one year.

This article is part of “The Speech Wars,” a project supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press, and the Fetzer Institute.



The weekend of August 12, 2017, may well have been a turning point in recent American history, but it’s not entirely clear which way things turned.

That weekend was when neo-Nazis and white supremacists marched in Charlottesville, Virginia. Marchers chanted “Jews will not replace us” and employed other anti-Semitic slogans. There were multiple violent clashes, and one woman, Heather Heyer, was killed when James Alex Fields Jr., one of the marchers, drove his car into a crowd. And President Donald Trump infamously equivocated about the incident. Trump said there were “very fine people on both sides” and then vacillated over the course of several days, declining to mount a sincere and forceful condemnation of the march.

By any objective standard, the incident was one of the lowest points of an administration defined by its nadirs, and the immediate reaction showed that public opinion concurred. Americans condemned Trump’s response, and his approval hit a record low.

Yet almost two years later, the political effects of the violence remain unpredictable, as the past week showed. Former Vice President Joe Biden looked to Charlottesville as a focus for his presidential-campaign announcement, and found it to be more slippery than he had intended. Trump, meanwhile, showed no squeamishness in defending himself over his response. And a shooting at a synagogue in suburban San Diego, California, showed how anti-Semitic attacks have become a horrifyingly familiar part of contemporary American life.

Biden decided to frame his campaign launch around a case against Trump. That’s somewhat in contrast to many other Democratic presidential candidates who, while not downplaying their moral revulsion to Trump, have tended to situate it as just one of a few issues. To sum up his case that Trump represents a “threat to this nation … unlike any I had ever seen in my lifetime,” Biden seized on Charlottesville, which occasioned one of his first major interventions in the national debate after the 2016 election. He reportedly planned a visit to Charlottesville at the start of his campaign, and he structured his announcement video around the march and words by Charlottesville’s most famous resident, Thomas Jefferson.

It didn’t go as smoothly as Biden must have imagined. Charlottesvillians, resentful at having their town turned into a symbol for white supremacy or a political prop, bridled at the plan. The video went forward, but without a visit, and Biden was criticized for not speaking with Heyer’s mother, Susan Bro, before he released it. (Bro told The New York Times that she was not “traumatized” by the video.)

Despite the bruising reaction to Trump’s comments in August 2017, he didn’t shy away from discussing the issue on Friday, when reporters asked him about Biden’s announcement:

Reporter: Mr. President, do you still think there were “very fine people on both sides” in Charlottesville?

Trump: Oh, I’ve answered that question. And if you look at what I said, you will see that that question was answered perfectly. And I was talking about people that went because they felt very strongly about the monument to Robert E. Lee, a great general. Whether you like it or not, he was one of the great generals.

I have spoken to many generals here, right at the White House, and many people thought—of the generals, they think that he was maybe their favorite general. People were there protesting the taking down of the monument of Robert E. Lee. Everybody knows that.

There’s a lot of nonsense in this answer. There is not a statue of Lee in downtown Charlottesville because of the cleverness of his military maneuvers, nor was there an effort to take the statue down because anyone was angry about his tactical choices at Gettysburg. Lee is controversial because he was a brutal slaveholder and the military leader of a treasonous rebellion against the United States government for the purpose of preserving black slavery.

An attempt by the Charlottesville city government to remove the statue was the excuse for white supremacists to march there in August 2017, but there’s not a direct connection between, say, supporting the preservation of historical monuments (to accept the most innocent explanation for opposing the statue’s removal) and anti-Semitism. Trump is, ironically, engaging in revisionist history: The backlash to his remarks came not because he supported leaving the statue of Lee intact; it was provoked by his inability to condemn the “Jews will not replace us” crowd without resorting to both-sidesism, complaining of an “egregious display of hatred, bigotry, and violence on many sides.”

It is true that many people who oppose removing Confederate statues are neither neo-Nazis nor white supremacists. It is also true that these were not the people marching with tiki torches in Charlottesville. As I noted at the time, Trump was speaking a double language. On the one hand, he was offering the barest condemnation of the neo-Nazis. On the other hand, the softness of his condemnation, and his insistence on claiming that there were good people, left white supremacists an opportunity to see in Trump an ally, and avoided alienating people in the president’s coalition who wouldn’t self-identify as white supremacists but who object strenuously to the removal of Confederate monuments.

Trump’s patterns of speech make a close reading of his comments a bit of a fool’s errand, but at the time, most Americans saw through his doublespeak. Since then, however, Trump and some of his defenders have insisted that he was merely misinterpreted, and that his comments were always about historic preservation. That’s what Trump attempted to claim on Friday. In any case, his embrace of the question shows that he’s not scared of the impact of his comments on his political standing. Of course, Trump will defend any number of things to the hilt, and has often been his own worst enemy politically.

But Trump is also making a rational political calculation. His defense of the marchers in Charlottesville had bad short-term political effects, in terms of his polling, and even bad medium-term effects: It’s likely part of the mix that powered Democrats to a big win in November 2018. But Trump’s popularity has rebounded (and sunk, and rebounded) since August 2017. By many indications, Trump has largely kept his base together, and he’s either a slight favorite or close to even in projections of the 2020 presidential race. The president has concluded that voter anger about Charlottesville is baked in, and he might be right. Or Biden might prove that he’s wrong. But as Biden’s stumbles around the topic show, Charlottesville doesn’t make for a simple tool to wield against Trump.

Meanwhile, the consequences of shrugging off anti-Semitic violence remain with the nation. On Saturday, a man walked into a synagogue in Poway, California, and opened fire, killing one woman and injuring three others, including the rabbi. Police say he was shouting anti-Semitic slurs, and he’s tentatively linked to a hate-filled manifesto posted online. It takes away nothing from the horror of the crime to say that it feels familiar, following not just the October 2018 massacre at a synagogue in Pittsburgh but also a rise in reports of anti-Semitic incidents overall. None of this felt nearly so normal before the march in Charlottesville. Something changed that weekend, but it’s premature to say what.



The HBO series Chernobyl is not only majestic television, but also a reminder that the world is a better place than it used to be. This seems counterintuitive to people who have become accustomed to declaring that we are living in bad times, the worst times, or even the End Times. But as the series draws to a close, Chernobyl should serve as a reminder not only that the world is fortunate that the Soviet Union is gone, but of how much we now take the political and technological improvements of the 21st century for granted.

It is especially important not to process everything in Chernobyl through the lens of our current politics, which seem frivolous compared with the events of the 1980s. (I was a young Soviet expert in training in 1986, and I remember the sense that Chernobyl had moved global events in ways even my experienced mentors could not fully understand at the time.) In a dustup over the series on Twitter, the writer Stephen King and the Fox News personality Dan Bongino both took a catastrophe that almost nearly overwhelms human comprehension even today and tried to wrap it around their own agendas. “It’s impossible to watch HBO’s CHERNOBYL without thinking of Donald Trump,” King tweeted. It is, of course, completely possible to watch the series without thinking of Trump. For his part, Bongino responded to King by railing against “Hollywood elitists.” Chernobyl, Bongino insisted, “was a failure of socialism … the exact opposite of the Trump deregulation and tax cut agenda.”

The show’s writer, Craig Mazin, got the last word. During a beautifully rendered scene, an elderly Communist Party apparatchik sits silently at a meeting of plant managers and local officials, all of whom are giving in to panic. He then rises and exhorts his comrades to gaze upon the portrait of the Soviet leader Vladimir Lenin on the wall, and to remember that Lenin would be proud of them—even though one of the reactors had already exploded and was, at that moment, on the verge of melting through the earth around them.

“Chernobyl,” Mazin tweeted to Bongino, “was a failure of humans whose loyalty to (or fear of) a broken governing party overruled their sense of decency and rationality. You’re the old man with the cane. You just worship a different man’s portrait.”

That burn showed a screenwriter’s deft touch, and Bongino got what he deserved. And yet the disaster that poisoned nearly 1,000 square miles of Soviet Ukraine grew out of a problem much broader than Lenin’s doomed cult of personality. From its inception, the Soviet Union was governed by a fundamentally psychotic regime that over successive generations was unable to comprehend reality, process information, or see beyond its own fevered and paranoid outlook. Chernobyl was a shock to the global system for many reasons, but not least because it was a terrifying reminder of what life might look like if the Kremlin and its authoritarian system of bureaucrats and policemen ever succeeded in ruling the rest of the world.

Like Chernobyl, the triumph of Lenin and the Bolsheviks and the creation of the Soviet state decades earlier was a freak accident, a strange detour of history. The historian Dmitri Volkogonov—a Soviet general who was once so trusted by the regime that he was assigned to write the official biography of Joseph Stalin—later declared bitterly in his autopsy of the Soviet period that Lenin and his comrades were European intellectuals who stumbled into power after “years of sitting in isolation and making up schemes for Communist revolution.”

Once they captured a state, however, they were determined to keep it, and a regime founded by chance and based on a lie soon began to believe in its own infallibility. Socialism and communism were just words; the power and survival of the Soviet Communist Party were paramount. No one life was of any particular importance.

The most chilling moment in Chernobyl—in a way, worse than the explosion of the reactor itself—comes when the scientist assigned to help deal with the accident, Valery Legasov, stops a senior KGB official named Charkov to plead the case of a researcher who has been arrested. When Legasov asks about his researcher, Charkov pretends not to know who she is. Legasov notes that she was followed, and Charkov points to two goons down the hall. “And they follow me. The KGB is a circle of accountability, nothing more.” Legasov asks again for his associate’s release, and in return Charkov asks whether the professor will be “accountable” for her. When Legasov says he will, the old spy says, “Then it is done.” When Legasov begins to repeat her name—so the KGB knows whom to release—Charkov says, “I know who she is,” and walks away.

This exchange did not really happen—the detained scientist in the series is a composite character. Yet this scene captures something about the Soviet regime both at its most mundane and at its most dangerous. Everyone was accountable to everyone else. Any show of public defiance, or even a misplaced comment, could carry severe consequences. But at a moment of great peril to millions of Soviet citizens and millions more people around the world, no one was accountable. Every bureaucrat and manager simply repeated the mantra of the gray, authoritarian system that produced them: I had my job. I did my job. I fulfilled my tasks. I did nothing wrong.

In this environment, falsehoods are policy. In the hours following the explosion and the fire, Soviet authorities insanely tried to keep a spiraling nuclear disaster a state secret, hoping against all odds that they could hide a gigantic conflagration from American satellites and a massive release of radiation from even their country’s closest neighbors.

This state, run by delusional old men chasing, imprisoning, and shooting millions of their fellow citizens in a “circle of accountability,” controlled thousands of nuclear weapons pointed at the United States and its allies. We all lived under the constant threat that the commitment of a group of paranoids to ideas first bruited about in the coffeehouses of Victorian Europe would lead to global extermination.

The Soviet Union is gone. The Russian Federation is a menace to peace, but Vladimir Putin is a second-rate mobster compared to the cool and brutal masters of the state that raised him. Soviet reactors no longer groan and strain in secrecy, and the last few RBMK-type plants in Russia are nearing the end of their lives, their flaws no longer hidden from the rest of the world. Instead of a combined force of tens of thousands of U.S. and Soviet warheads ready to immolate almost every major city in the Northern Hemisphere, each side has contented itself (for now) with roughly 1,500 weapons apiece.

Chernobyl is a grimly beautiful portrait of a diseased political system that died a more peaceful death than it deserved. Americans—and the rest of the world—should be happy that it is gone. We should also be grateful for our narrow escape not only from the burning reactors in the marshes of Pripyat, but from a state led by a cabal of dangerous men who, for the better part of a century, hijacked the fate of billions of human beings.



Lobster is Maine’s top export. Like many Americans with something to sell, Maine’s trappers benefited from positive turns in China’s economic development. The movement of tens of millions of people out of poverty and into the middle class increased demand for a source of protein—and a Chinese New Year delicacy—that Maine could happily provide.

Yet in the wake of President Donald Trump’s trade war, American lobster sales to China have decreased by 70 percent. China’s 25 percent retaliatory tariff on American lobster was only the start. Beijing has actively helped Chinese grocers and restaurants by also reducing the costs of their finding new, non-American suppliers. It has cut the Chinese tariff on lobster bought from Canada, Maine’s fierce rival in the lobster business. As a result, Canada has seen its lobster exports to China nearly double. Maine may never recover its previously dominant position in this export market.

This story is not singular. Trump started the trade war by levying new taxes on $250 billion worth of Chinese exports. China retaliated both by increasing the duties Americans face and by decreasing the tariffs that confront everyone else: It has cut tariffs on thousands of products from the rest of the world’s fisheries, farmers, and firms.

Even as Tariff Man, as Trump likes to refer to himself, focuses only on disruption, Beijing is evidently operating on a higher level. China is outplaying the United States on two fronts.

First, while Trump is on the verge of slapping tariffs on almost everything the U.S. imports from China, Beijing is picking and choosing wisely. It went to town on American soybeans, in part because it knew that Brazil and Argentina could provide ample alternative supplies. But it has left untouched other American exports that are more difficult to replace. China could, for instance, force its state-owned airlines to immediately shift from buying Boeing to European-based Airbus, but those companies would run into trouble accessing the parts and services needed to keep their costly existing fleets running. Beijing has therefore mostly spared the aircraft sector from retaliation thus far.

Second, Trump has no real mitigation strategy to help the Americans facing the entirely foreseeable costs of his policies. Yes, he’s giving out tens of billions of dollars in agricultural subsidies—but that is, of course, a cost borne by Americans, not international rivals. His separate trade restrictions on nearly $50 billion in steel and aluminum imports have only worsened the effects of his fight with China; these restrictions have burdened American farmers by raising the cost of the equipment needed for harvesting or storing the crops they are now unable to sell abroad. And he’s compounding this short-term pain with possible long-term damage to previously healthy international relationships: Those steel and aluminum tariffs have mostly targeted trade from allies such as Europe, Canada, and Japan—not China. He also conducted a needlessly contentious renegotiation of the North American Free Trade Agreement, and has threatened tariffs on tens of billions of dollars’ worth of Japanese and European cars.

By contrast, China is helping its citizens by making new friends. One way to offset the rising prices to Chinese consumers otherwise stuck buying American is to lower their costs if they switch. On average, it is now 14 percent cheaper in China to buy something from Canada, Japan, Brazil, or Europe than it is to buy something from the United States. Beijing is making it worthwhile for its consumers to develop new commercial relationships. And once those new ties are formed, the Chinese may not bother to switch back.

When Trump first began imposing tariffs in early 2018, his key trade strategist, Peter Navarro, infamously said, “I don’t believe any country in the world is going to retaliate.” Navarro was wrong, of course, as foes (China, Russia) and friends (European Union, Canada, Mexico) alike all immediately retaliated against American exports.

More worrisome than Navarro’s rhetoric was how it revealed a fundamental misunderstanding of how trade works. In each of its provocations, Trump’s team sees trade through the narrow lens of a two-country world: America versus whomever the administration has chosen to antagonize that day.

America can easily lose even when there is no retaliation at all. Anytime another country lowers its tariff to someone else—but not the United States—the global economy leaves America one step further behind.

Trump chose this outcome once when he pulled out of the Trans-Pacific Partnership agreement in January 2017. The result is that ranchers in Australia, New Zealand, and Canada now have access to the lucrative Japanese beef market and Americans do not. Beijing’s positive overtures toward America’s former economic allies suggest Trump’s unilateral approach toward China is likely to replay itself.

Lobster may be the canary in Trump’s trade-war coal mine. Maine’s congressional delegation—made up of two Democrats, one independent, and one Republican—has shined a spotlight on the industry’s hard times by requesting that the Trump administration provide it with the same sort of federal assistance already doled out to farmers.

Trump keeps pushing the rest of the world away and into China’s corner. China is enticing the world to stay.



Updated at 10:14 a.m. ET on April 29, 2019.

China is making a risky bet in the Middle East. By focusing on economic development and adhering to the principle of noninterference in internal affairs, Beijing believes it can deepen relations with countries that are otherwise nearly at war with one another—all the while avoiding any significant role in the political affairs of the region. This is likely to prove naive, particularly if U.S. allies begin to stand up for their interests.

In meetings I attended earlier this month in Beijing on China’s position in the Middle East, sponsored by the Carnegie-Tsinghua Center, Chinese officials, academics, and business leaders expressed a common view that China can avoid political entanglement by promoting development from Tehran to Tel Aviv. China may soon find, however, that its purely transactional approach is unsustainable in this intractable region—placing its own investments at risk and opening new opportunities for the United States.

Over the past three years, China has charted an ambitious future in the Middle East by forging “comprehensive strategic partnerships” with Iran, the United Arab Emirates, Saudi Arabia, and Egypt. This is the highest level of diplomatic relations China can provide, and Beijing believes these four countries anchor a neutral position that will prove more stable over the long term than that of the United States. China has also made massive investments in infrastructure throughout the region, including in Israel, where China is now the second-largest trading partner behind the United States.

China’s interests in the Middle East are both structural and strategic. Structurally, China needs the natural resources of the region, whereas the United States—now the world’s largest oil producer—does not. China is also seeking new markets to absorb its excess industrial capacity, and sees the Middle East poised for growth after decades of wars, woeful infrastructure, and popular discontent. Strategically, together with Russia, China is taking advantage of the uncertainty produced by ever-shifting U.S. policies, including zero-sum prescriptions for Iran and Syria that are unlikely to produce desired outcomes anytime soon. Regional governments in turn have welcomed China’s embrace, and its offer of investment without pressure to politically reform or respect human rights.

China’s President Xi Jinping previewed this more assertive Middle East strategy in a landmark address in Cairo three years ago. There, he declared that China does not seek a “sphere of influence” in the region—even while sinking nearly $100 billion in investments there through ports, roads, and rail projects. He alleged China rejects “proxy” contests—even while concluding a strategic partnership with Iran, the main sponsor of proxies in the region. And he warned against “all forms of discrimination and prejudice against any specific ethnic group and religion”—even while reportedly forcing 1 million Muslims into reeducation camps in China’s Xinjiang province.

Such contradictions can be maintained only so long as traditional U.S. allies in the region now welcoming Chinese investment allow them to be maintained. These U.S. allies do not shy from asserting their broader interests with Washington or expressing disagreement where policies diverge, and it is time they do the same with Beijing.

As the United States questions Chinese investment and intentions, particularly in the areas of technology and ports such as Israel’s Haifa, it can also challenge traditional allies as to whether they are granting China a free ride on what remains a largely U.S.-led security architecture. Such an arrangement should be as unacceptable to American partners in the region as it is to Washington. At the very least, these partners, together with Washington, can demand that Beijing utilize its emerging influence—particularly with Tehran and Damascus—to pursue measures that promote longer-term stability.

This might include action in the following four areas.

First, China can pressure Tehran to pull back its proxies and formations from Syria that threaten Israel. Emerging voices in Beijing seem to recognize that some Iranian activities in Syria present risks to Israel—and that an Israeli-Iranian conflict would jeopardize China’s own position in the region. Recent commentary in the government-backed Global Times, for example, recommended that Iran pull back its proxies from Syria. Formalizing this policy would be in the mutual interests of Beijing, Washington, and even Moscow—which has implicitly recognized Israel’s right to defend itself against Iran’s import of offensive weapons systems into Syria.

Second, China can demand Syria’s President Bashar al-Assad cooperate in the UN-backed political process and withhold significant reconstruction assistance until he does so. To date, China has backed Assad to the hilt in the UN Security Council, issuing six vetoes of resolutions designed to assess accountability for war crimes. It appears to have demanded little from Assad in return, a situation that belies its claim of neutrality on regional matters. As one of the few countries likely to help bankroll Syria’s longer-term reconstruction, China can have significant influence in Damascus. In 2015, it voted for UN Security Council Resolution 2254—which calls for constitutional reform and UN-backed elections—and now it should help ensure its full implementation.

Third, China can unequivocally call for the release of Xiyue Wang, a Beijing-born American citizen who remains wrongfully detained in Iran. In recent years, China has stoked nationalist sentiment by claiming through popular movies that it’s prepared to protect its citizens whenever they find themselves in trouble overseas. It should not extend “comprehensive strategic partnership” status to Iran while at the same time looking the other way in this case. Wang’s wife and child are Chinese citizens. He is an innocent scholar. China should help secure his release.*

Finally, China can help support UN-led stabilization programs in areas such as Mosul that were once controlled by ISIS and are now seeking to rebuild. Chinese investment has largely avoided areas outside its controversial Belt and Road Initiative; but supporting recovery from ISIS—and mitigating the risks of its reemergence—is in the interests of the region and the rest of the world. China can also help resource the UN Security Council–mandated Investigated Tribunal on ISIS Accountability (UNITAD), which is doing historic work to document ISIS crimes and bring justice to its victims.

None of these initiatives would require a breach of China’s so-called noninterference policy. Each is also important for longer-term stability in the region, and thus a return on the investments China is now making from Cairo to Dubai. So, even by Beijing’s standards of transactional diplomacy, they fit the definition of “win-win” and may even present areas for practical cooperation between China and the United States.

The failure to support such uncontroversial aims, by contrast, would call into question China’s longer-term intentions as a benign power focused on development.

It is not possible to stop China’s emergence in the Middle East altogether. But the U.S. can still shape its position and role—and its friends in the region should help. Agreeing on a common agenda as outlined above would be a good first step.

* This article originally stated that Xiyue Wang is a dual-national. In fact, he holds only American citizenship. We regret the error.



In Tuesday’s ruling on Indiana’s abortion law, Justice Clarence Thomas took the national debate over the right to choose to a dark new place: eugenics. His 20-page concurring opinion included an extensive discussion of the eugenics movement of the early 20th century. Thomas argued that as the justices consider abortion going forward, they should pay more attention to its potential to become a “tool of eugenic manipulation.”

In making his argument, Thomas cited my book Imbeciles: The Supreme Court, American Eugenics, and the Sterilization of Carrie Buck repeatedly. (He also cited an article I wrote about Harvard’s ties to eugenics). I don’t want to appear ungrateful: It’s an honor to be relied on by the highest court in the land, and these days, nonfiction authors appreciate just being read at all. But Thomas used the history of eugenics misleadingly, and in ways that could dangerously distort the debate over abortion.

Thomas’s opinion came as an addendum to a decision that sidestepped the most difficult issues raised by the Indiana law. Although the Court upheld Indiana’s requirement that abortion providers bury or cremate fetal remains, it refused to reinstate another part of the law that banned abortions solely because of the sex or disability of the fetus. The New York Times reported that the decision was “an apparent compromise.” It says a lot about where abortion law is today that upholding a law requiring a woman to allow her aborted fetus to be given the funerary rites of a dead child—and possibly to pay a hefty bill for it—now counts as a “compromise.”

Thomas did not object to the Court’s ruling, but he offered up his lengthy treatise on eugenics to help the Court when it considers more laws like Indiana’s in the future. His motivation was apparently to put a new weapon in the arsenal of the anti-abortion movement. If you do not buy the argument that abortion ends a human life, how about the idea that it is an attempt to restrict reproduction in order to “improve” the human race?

Thomas relied on a kind of historical guilt-by-association. “The foundations for legalizing abortion in America were laid during the early 20th century birth-control movement,” he wrote. The birth-control movement, in turn, “developed alongside the American eugenics movement.” Therefore, he suggested, abortion is inseparable from America’s history of eugenics.

In supporting his claim, Thomas cited real history that is not particularly relevant to abortion. It is true, as Thomas said, that Margaret Sanger, the founder of Planned Parenthood, supported eugenics and that she had some pretty offensive views. (Anyone who doubts that should read what Sanger had to say about “slum mothers” in her book The Pivot of Civilization.) It is also true that Congress passed the Immigration Act of 1924, which sharply diminished immigration of Eastern European Jews and Italians, in part out of a desire to enforce racial “purity.” And Thomas is correct that the Supreme Court played a lamentable role in the eugenics era with its 1927 ruling in Buck v. Bell, the subject of my book. The Court upheld a Virginia law that authorized the state to sterilize people it considered unworthy of reproducing, and it allowed the state to sterilize Carrie Buck, the poor young woman at the center of the case.

None of this was about abortion, however. The most prominent American eugenicists did not support abortion. As the intellectual leader of the movement, Harry Laughlin—the head of the infamous Eugenics Record Office, on Long Island—put it, the goal of modern eugenics was “preventing the procreation of defectives rather than destroying them before birth.” In fact, at the height of the eugenics movement, abortion was outlawed throughout the United States, so it was not going to be the mechanism for changing the American gene pool.

The American eugenics movement overwhelmingly supported not abortion but forced sterilization. More than half of the states adopted laws like Virginia’s, which allowed the state to sterilize people it deemed unworthy of reproducing because of physical or mental deficiencies or other “failings,” such as alcoholism or poverty.

Between eugenic sterilization and abortion lie two crucial differences: who is making the decision, and why they are making it. In eugenic sterilization, the state decides who may not reproduce, and acts with the goal of “improving” the population. In abortion, a woman decides not to reproduce, for personal reasons related to a specific pregnancy.

That is ultimately where Thomas’s argument falls apart. A woman in Indiana who has an abortion because the child will be born with a severe disability is not acting eugenically—she is not trying to uplift the human race. She is simply deciding that she does not want to give birth to a child who, for example, would die in infancy after a brief life of extreme pain.

Thomas’s concurring opinion is an example of a common form of argumentation: the false analogy to a universally acknowledged historical atrocity. Extremists in the anti-abortion movement do this a great deal—for example, by comparing abortion to the Holocaust. Of course, this form of argumentation is not limited to the abortion debate; a top technology adviser to President Donald Trump once said, “The demonization of carbon dioxide is just like the demonization of the poor Jews under Hitler.”

Carbon dioxide’s problems are not analogous to the Jews’ problems under Hitler, and allowing a woman to decide whether to give birth is not analogous to the Final Solution—or to the misdeeds of the eugenics era. When the time comes for the Court to once again consider a statute like Indiana’s, Thomas’s eugenics history should not be its guide.

Despite all of this, I will admit to having been a little bit pleased when I read Thomas’s opinion—and not only because, as a journalist friend said, the references to Imbeciles were “good for the brand.” Americans today know too little about the American eugenics movement. This history speaks powerfully to our time, although not in the way Thomas suggested.

Eugenics may indeed be making a comeback. Representative Steve King, the Iowa Republican and immigration hard-liner, echoed the concerns of the movement when he tweeted, “We can’t restore our civilization with somebody else’s babies.” So did Trump when he reportedly said that the United States needs fewer immigrants from “shithole countries” and “more people from places like Norway.” And so did white supremacists in Charlottesville, Virginia, when they chanted, “Jews will not replace us.”

Thomas is absolutely right that we need to remember our eugenics past and make sure that we do not make the same mistakes again. He is absolutely wrong that individual women making independent decisions about their pregnancies are the eugenicists of our time.



When the Democratic presidential candidate Elizabeth Warren put forth a sweeping plan to cancel student debt last week, she also exposed the deep divide between how liberals and conservatives think—and, inadvertently, why liberals often have so much trouble getting their ideas enacted into law.

Under the plan that Warren announced, about 42 million Americans would have up to $50,000 in outstanding debts canceled. Philip Klein, the executive editor of the conservative Washington Examiner, quickly chimed in with a tweet and a blog post criticizing the senator’s proposal as unfair.

New post: "Elizabeth Warren's plan to cancel student loan debt would be a slap in the face to all those who struggled to pay off their loans" https://t.co/4g6No2MRVm

Taken aback that Klein would cast his objection to Warren’s plan as a matter of justice, the Twitter left erupted with outrage and mockery.

Things were worse for people in the past so it would be unfair to make them better for people in the future is not an argument that makes sense if you think about it for more than a second.

Child labor regulations a slap in the face to children who worked in coal mines https://t.co/llwzoNn1zB

Personally, I understand the feelings that Klein’s post brought forth. I too am a liberal who believes that it is unconscionable to plunge 20-year-olds deeply into debt merely for wanting to educate themselves. More broadly, I favor many of the policy ideas that Warren has been rolling out. As an American-born psychology professor now living in Canada, I am a strong supporter of my adopted country’s universal health system, which has served my family admirably.

Yet because I’ve also spent the past few years studying how perceptions of unfairness differ for liberals and conservatives, Klein’s language didn’t surprise me in the least. There is more than one way to decide who is deserving of what.

One is by need: Some people have more than they need, and others need more than they have. Even when liberal leaders describe policies that are beneficial to everyone, they make it clear that the most important beneficiaries are those whose needs are most urgent. Indeed, Warren’s plan was also criticized from the left for insufficiently prioritizing those who need debt relief the most.

Still, there are other ways of judging what’s fair. Conservatives tend to value equity, or proportionality, and they see unfairness when people are asked to contribute more than they should expect to receive in return, or when people receive more than they contribute. Consider a hypothetical comparison of two people who graduated from college five years ago with equal amounts of debt. Jessie successfully implemented a plan to pay off the debt in five years, while Sam still has much to repay. Warren’s plan forgives Sam’s debt, but offers nothing to Jessie, despite her industriousness and self-discipline. To add insult to injury, Jessie must contribute tax dollars to the $640 billion fund necessary to forgive outstanding loans, including Sam’s.

Pundits on the left often argue, using survey data as evidence, that a majority of Americans hold liberal values. For example, a majority of Americans support specific programs, like Social Security and Medicare, that have been created and defended by Democratic politicians. However, although Social Security and Medicare are motivated by the need principle (they do much to prevent poverty among the elderly), they are also motivated by the equity principle (what people receive in retirement is related to what they contributed while working). In other words, widespread support for such programs does not demonstrate a majority preference for need-minded values.

Liberal commentators’ failure to understand these dynamics was evident in the many condescending responses to the Tea Party cry “Keep your government hands off my Medicare!” To many liberals, this cry was a simultaneously hilarious and horrifying reminder of the Republicans’ ignorance: OMG, they don’t even realize Medicare is a government program! To me, it was a reminder that Medicare, funded by a payroll tax, is an equitable program, treated rightfully by working people—as in Aesop’s fable about the ant and the grasshopper—as the wintertime fruit of their summertime labor.

This conservative version of fairness is wired deeply in the human brain, and liberals ignore it at their peril. In the laboratory, psychologists study the roots of economic and political attitudes through exercises like the ultimatum game, in which one player (the allocator) makes an offer to another player (the recipient) about how to split a small pot of money put up by the researchers. The recipient can accept the other player’s offer and take the cash—or reject it, in which case neither player gets anything. Not surprisingly, when the allocator offers a 50-50 split, recipients accept it.

However, very unfair offers, such as a 90-10 split favoring the allocator, are often rejected by recipients, even though 10 percent of the pot is better than no money at all. When researchers measure the brain activity of recipients considering unfair offers, consistent activation is shown in an area called the anterior insula, which is known to be the cortical hub for visceral signals corresponding to emotional distress.

Why would the brain’s default mode be to reject something in favor of nothing? Cognitive scientists have discovered that such seemingly irrational behavior often has an adaptive purpose. Rejection of unfair treatment, for example, has the purpose of enforcing social norms about the allocation of resources. Acceptance of an unfair offer now all but guarantees continued mistreatment at the hands of the allocator, whereas rejection sends a clear message: Don’t take advantage of me, and don’t help yourself to more than you deserve.

Behavioral scientists have documented similar dynamics in our primate relatives. Studies by Sarah Brosnan of Georgia State University and Frans de Waal of Emory University, for example, demonstrated that monkeys trained to give a token to a human experimenter in exchange for a piece of cucumber would start refusing to participate when they witnessed another monkey receiving a tastier grape for the same effort. The monkeys were particularly upset when grapes were given to another monkey for no effort at all, sometimes throwing the (formerly satisfactory) cucumber in protest.

One might conclude from this that liberals, in their emphasis on helping the needy, are superior to conservatives because they strive to overcome biological determinism. Yet one could also accuse liberals of neglecting other definitions of fairness and—to their political detriment—of paying too little attention to how many other human beings instinctively think.

American liberals looking fondly over their northern border often misunderstand why policies considered left-wing in the United States are so popular in Canada. Middle-class Canadians support their health-care system not because it’s good for the needy, but because it’s good for themselves. When they get angry about threats to their health-care system, it is because they take the threat personally—they are defending their own interests rather than those of some underprivileged stranger.

In the United States, Social Security is popular for similar reasons. Taken at face value, liberals’ emphasis on need and conservatives’ preference for proportionality would seem to predict very different policy preferences. If Social Security were strictly proportional, those who made the largest contributions during their working years would receive the most benefits during retirement. Instead, low-income individuals receive more than they contribute, and high-income individuals receive less than they contribute.

Why, then, is Social Security so popular among conservative voters? For one thing, the contribution-to-benefit ratio is proportional for middle-income individuals. One might say that Social Security is sufficiently proportional to reassure conservatives—excepting those with high incomes—that it does not violate their sense of fairness. Does this mean that it is inconsistent with liberal values such as helping those in need? No. The fact that low-income individuals receive more than they contribute does much to mitigate poverty among elderly citizens.

Unlike Warren’s loan-cancellation program, her child-care proposal could find a similar sweet spot, although conservatives might argue that a truly universal program would extend subsidies to families with a stay-at-home parent. Bernie Sanders’s proposal for Medicare for all might have broad appeal as well, and its positive reception by an audience of Fox News viewers at his recent town hall is an encouraging sign that universal economic policies, framed as such, will be seen as fair by liberals and conservatives alike.

One way or another, liberals must recognize that many Americans define “fairness” in terms other than aid to the neediest—and should craft their messages for 2020 accordingly. Donald Trump’s recent budget proposal includes cuts to Social Security and Medicare. Will Democrats be smart enough to point out that he’s threatening benefits that Americans have paid for and that they deserve?

This article was adapted from America the Fair: Using Brain Science to Create a More Just Nation by Dan Meegan, published by Cornell University Press.



When David Brooks started writing his column in The New York Times more than a decade and a half ago, he became an instant star. Today, he’s one of America’s most influential columnists, insightful and elegant, able to catalyze debates on topics simply by writing about them. Yet anyone who has regularly read Brooks over the years—or, in my case, who knows and admires him—can see that his outlook has changed in some important ways.

It’s less Brooks’s politics that has changed—he still describes himself as a Burkean conservative—than his purpose as a writer. When he started out at the Times in 2003, Brooks told me recently, his primary goal was to “represent a Theodore Roosevelt, Whig Party Republicanism. It was a political purpose.” He still tries to do that, he says, but he believes our discussion is “over-politicized and under-moralized, and so we talk too much about every poll and not enough about how to feel gratitude, how to do forgiveness, how to do ritual. So I try to shift the public conversation a little over in the direction of moral and relational life.”

This shift in outlook is manifest most clearly in Brook’s new book, The Second Mountain: The Quest for a Moral Life. It’s not a book you might expect from the author of Bobos in Paradise. The book addresses the commitments that define a life of meaning and purpose, including family and spouse, vocation, and community. But I read it as, first and foremost, a memoir of a journey toward religious faith.

Brooks argues that life on the “first mountain”—the mountain of personal goals, worldly success, career ambitions, and traveling in the right social circles—is transitory and ultimately unsatisfying. Eventually, though, if you’re fortunate, you find yourself on the “second mountain,” one characterized by other-centeredness and self-giving. (Often, though not always, the path to the second mountain is marked by hardships and failures.)

Men and women who live on the first mountain may find happiness, but people living on the second mountain find something deeper—joy. (Brooks defines happiness as the victory and expansion of the self, while joy is found in transcending the self and serving others.) Brooks wrote this book not because he felt he had found joy, but because he wanted to study people who had. “I take the curriculum of other people’s knowledge and I pass it along,” he says in his introduction.

When he was young, according to Brooks, life was “a very intellectual thing, a material thing, and I just never had any sensation of anything that spiritual.” It was not that he was hostile to religion, he said, “but I grew up in a more or less secular world and its categories were my assumptions.”

As he got older, he experienced more of the vicissitudes of life. And the more attention he paid to people, the more he wrote about them, he realized “it didn’t make sense to me that they were just sacks of genetic material. It only made sense to me that they had souls. That some piece of them that had no material dimension, no size or shape but gave them infinite dignity, every single one of them. Once you start with the idea that each person has a soul, it’s an easy leap to [conclude] that there’s some connection there, there’s some flowing force.”

Once Brooks came to believe people had souls, “it definitely changed the human anthropology.” He began to see “various glimpses of another layer of life”—and among those layers he began to see and take seriously is religious faith.

When he was young, he told me, paraphrasing the poet and author Christian Wiman, “my mental categories were not adequate to reality as I experienced it.” But over time, his perspective shifted. “I went from a very clear nonbeliever to somebody who felt belief was good for others but it didn’t really particularly impact me and then, to a growing awareness which felt more like recognizing something that was latent in me, that I actually do have belief,” he said.
He describes his faith journey as “stories coming to truth.” He says “the Exodus story now seems like a true story, and I mean that in a spiritual way and not necessarily in a historical way.” He seems content to leave it to theologians to determine which genres apply to which Biblical accounts—historical narrative, wisdom literature, poetry, prophecy and so forth. “But the formation of a people in the wilderness, that is a sort of elemental mythic pattern of life that seems to be woven into the universe.”

“Similarly,” he adds, “the scapegoat story [found in Leviticus 16] is woven into the fabric of reality. And then the scapegoat who forgives his tormentors and who dies for others”— represented in the person of Jesus—“it’s the best we can do to understand a moral reality of the universe.”

It strikes me that this is the quest Brooks is on: to better understand the moral reality of things and more fully align our lives to it. Religious faith is a way to help him and many of the rest of us do that, though even for the most faithful, their understanding of things is at best partial, their ability to see things limited, their perceptions colored by their experiences. We all see through a glass darkly.

Brooks’s own particular faith journey is what you might expect from a “border stalker,” a phrase the artist Makoto Fujimura uses to describe people who are perpetually on the line between different worlds. This disposition was undoubtedly reinforced by growing up in a secular Jewish home while attending an Episcopal school and, for many years, an Episcopal camp.

Brooks spent his childhood “in the crossroads between two great moral ecologies,” he writes. “But I didn’t grow up in a theology book; I grew up in the late-twentieth-century American version of Judaism, and the late-twentieth-century version of Christianity.” He adds, “I grew up either the most Christiany Jew on earth or the most Jewy Christian, a plight made survivable by the fact that I was certain God did not exist.”

Brooks describes himself these days as “a wandering Jew and a confused Christian.” He told me “Judaism seems more real to me than it ever did. On the other hand, celestial grandeur is found in the Beatitudes. The Beatitudes seem like a moral system that is pure goodness.” As he puts it in the book, “I can’t unread Matthew.”
When talking about what he hopes people will take away from his discussion of faith in the book, he said, “I guess to be open to this possibility.” Note well: to be open to the possibility of faith, not insistent on it. As he writes, “I don’t ask you to believe in God or not believe in God. I’m a writer, not a missionary. But I do ask you to believe you have a soul.”

“I wanted to make faith, and the journey towards faith, seem very ordinary,” Brooks told me. “There’s nothing super miraculous and there are no dramatic moments. There’s just a gradual suffusion, a gradual understanding.”

He says that, like a lot of people, he had to overcome thousands of years of institutional religion to get to where he is. He told me he was less persuaded by the people who were fervent believers than by the people who were periodic and doubting believers. (“Some people have really fervent conversion experiences and fervent present awareness of God,” he says. “That seems like a very genuine way to perceive God. It just doesn’t happen to be mine.”)

And, invoking the novelist and theologian Frederick Buechner, Brooks told me that “faith is change.” It’s here one moment and gone the next. “It’s ups and downs, and it’s always movements. It’s a continued journey of exploration.” And it’s a journey that has created in him new desires. “The temptations of worldliness are very strong,” Brooks acknowledged, “and I’m now glad I have another anchor.” Brooks added that in some respects he’s sadder than he was, in part because faith offers a much higher ideal that we’re sure to fall short of, and can make one more aware of the brokenness of the world and more attuned to the suffering and pain of others.

I concluded our interview by asking Brooks to describe grace, one of the most elusive theological concepts, and what it might have to offer the world. Grace is “unmerited love,” Brooks said. He then cited a passage from Annie Dillard’s Teaching a Stone to Talk:

In the deeps are the violence and terror of which psychology has warned us. But if you ride these monsters deeper down, if you drop with them farther over the world’s rim, you find what our sciences cannot locate or name, the substrate, the ocean or matrix or ether which buoys the rest, which gives goodness its power for good, and evil its power for evil, the unified field: our complex and inexplicable caring for each other, and for our life together here.

Building on this sentiment, Brooks told me, “We have this amazing ability to care about each other and to love each other and love God in ways that are beyond any normal requirement. So we’re just made that way. And it is a gracious universe that gave us this capacity, and it seems to me it didn’t have to be that way.”

He’s realized over the years, Brooks told me, that as writers and conversationalists, “we don’t spend enough time on desire and where desire comes from.”

“We were implanted somehow with these very high and lofty desires,” Brooks said, “and across human history, those desires have almost always included the desire to meet God.” That, in a sense, is a form of grace. “The world is just much more enchanted than it needs to be,” he told me. “We’ve been given these gifts.”

And if the world was a more grace-filled place? “If you see other people as souls, it’s much harder to loathe groups of them. You realize we all stereotype to a degree, but you realize the wrongness of that.” He added, “In any encounter, if you treat the other person as an infinite soul, you’ll probably end up treating them the way you should be treating them.”  

One of the striking things about The Second Mountain  is how transparent Brooks is, sharing stories of people he’s encountered, his own struggles and doubts, his shifting perspectives, his time in the valley. In 2013, Brooks explains, his life was crashing; his marriage ended and he found himself “unplanted, lonely, humiliated, scattered.” In looking back, he says he prioritized time over people, productivity over relationships. Rather than keeping readers at a safe distance, he opens a door to his interior world.

Interestingly, he told me, “the first draft [of the book] didn’t have any of me in it.” But someone who was helping to research the book said, “You have to put yourself in this book.” Others made the same comment. “So I do it more than I anticipated,” he said. “In retrospect, it was the right call, because it’s a book about relationships and vulnerability, and if I’m not willing to be vulnerable as an author, there’s something hypocritical about it.”

“Of course I hesitated,” Brooks admitted to me, “because vulnerability is a painful thing to do in this culture, where there’s so much attack and counterattack, and you’re handing your enemies easy targets. But I figured I had no choice.”

Actually, Brooks did have a choice, which makes his decision to be transparent that much more impressive. Some of his critics have used his vulnerability against him, because cynics will do what cynics will do. For them, a person who decides to bring readers along on a translucent journey toward a more meaningful life—even one that is at times self-critical—is committing an unforgivable sin. So transparency doesn’t go over too well with everyone, especially when it is twinned to an authentic exploration of faith, including one that is unfolding and doesn’t fit into neat and tidy categories.

Certain orthodox Christians will be uneasy that Brooks voices doubt and is uncertain about the physical resurrection of Jesus. Certain people of the Jewish faith will be hurt because they believe he is leaving the Jewish fold. And certain progressives—particularly of the cynical and woke variety—won’t like the fact that he finds Jesus a more compelling figure than Alexandria Ocasio-Cortez.

They each want Brooks to be more like them, to see the world just as they do. But Brooks will continue to politely decline. He has his own story to tell, his own life to live, his own experiences to share, his own heroes to introduce us to.

In reading this book, you have the sense you’re on a journey with a friend. The book speaks to deep human longings and to the particular challenges of our time—loneliness, alienation, social isolation, hyper-individualism. It helps that it does so with elegance, thoughtfulness, a personal touch and great integrity. And here’s my hunch: The Second Mountain will not only be widely read; it will change countless lives.



On March 29, 1994, the Texas lawyer Mandy Welch rose to argue before the Supreme Court on behalf of a condemned prisoner named Frank McFarland.

Justice Antonin Scalia, however, wanted to put Welch’s law firm, the Texas Resource Center, on trial. McFarland’s petition, Scalia said, had been filed late in the process, disrupting Court procedure. He was not interested in her explanation: Her firm had originally tried to recruit volunteer counsel for McFarland, and finally had to take him on itself—one of 220 death-penalty cases being handled by 18 young lawyers. “I just want you to know that I am not happy with the performance of the Texas Resource Center in the cases that come before me as circuit justice,” Scalia said.

“I wasn’t prepared” for Scalia’s wrath, Welch told me in an interview recently. “It was easy for me to respond with the feeling that if you understood what happened, you would know that we had no control over any of [the timing].” (The case concerned McFarland’s right to counsel for a habeas corpus petition; though he won on that issue, he was eventually executed anyway.)

Scalia’s ire against the capital-defense bar has survived his death. This term, members of the new conservative majority have been in high dudgeon about death appeals. The conservatives’ complaints home in on a specific point: Capital punishment in the U.S. would go off smoothly if lawyers would just stop making up claims at the last minute. Having looked at the record in these cases, I wonder whether their anger represents judicial pique more than sober legal critique.

The rumble kicked off on February 7, when the Court, in an unsigned opinion, allowed the state of Alabama to execute a Muslim inmate, Domineque Ray, without permitting his imam to join him in the death chamber. The Court argued that Ray had waited too long to raise the issue.

On March 28, the Court did grant a stay of execution to a Texas inmate who wanted a Buddhist priest in the chamber. Justices Clarence Thomas and Neil Gorsuch dissented; Justice Brett Kavanaugh suggested Texas just ban all spiritual advisers, which the state did a few days later.

In between those two seemingly contradictory decisions, on March 6, the Court, in a case called Bucklew v. Precythe, rejected, 5–4, a challenge by an inmate with an unusual medical condition. Because his oral cavity was full of fragile blood-filled tumors, Russell Bucklew argued that Missouri’s method of lethal injection would be so painful that it would violate the Eighth Amendment—not necessarily in general, but specifically as applied to him. In the majority opinion, Gorsuch suggested that Bucklew’s counsel had deliberately waited to raise the claim until a few weeks before his execution date. He urged lower courts to “protect settled state judgments … by invoking their ‘equitable powers’ to dismiss or curtail suits that are pursued in a ‘dilatory’ fashion.”

Justice Stephen Breyer tartly said in dissent, “[i]t might be possible to end delays by limiting constitutional protections for prisoners on death row. But to do so would require us to pay too high a constitutional price.” Justice Sonia Sotomayor, in another dissent, wrote: “There are higher values than ensuring that executions run on time.”

In yet one more death-penalty case, Justice Samuel Alito angrily returned to the Texas Buddhist-prisoner issue. “This Court receives an application to stay virtually every execution,” he wrote; “in the great majority of cases, no good reason for the late filing is apparent. By countenancing the dilatory litigation in this case, the Court, I fear, will encourage this damaging practice.”

The conservative majority has made clear how this issue looks from its perch. But how does it look to the Mandy Welches of the world—those who litigate death-penalty appeals? Let’s start with Bucklew, the case of the inmate with the medical condition.

Paul Cassell, a professor at the University of Utah School of Law, argues that Bucklew could have brought this challenge years ago. Cassell is, among other things, a former federal district judge and perhaps the nation’s most prominent advocate of victim-rights legislation. He co-wrote an amicus brief in Bucklew on behalf of a crime-victims’ group and the sister of one of the murder victims. The brief alleged Bucklew had engaged in “decades-long abusive litigation, strategic posturing, and dilatory tactics” and that his lawyers had chosen to “keep an as-applied challenge (based on his benign oral tumors) in reserve, ready to use when most strategically advantageous.” Bucklew’s lawyers, Cassell told me in an interview, had been “deploying his condition for tactical advantage” by “holding his ‘as applied’ challenge” until the last minute.

But Robert Hochman, who represented Bucklew at the high court, says that if in fact there is a problem with capital-defense lawyers, “Mr. Bucklew’s case could not have been a worse occasion to highlight it.” Most of the delay, Hochman argues, was not of Bucklew’s—or his lawyer’s—making.

The apparent delay arose in part because the appeals process for state death-penalty cases is so complex. The first step for a condemned prisoner is a “direct appeal” to the state’s highest court (if denied, it may be followed by petition for review to the U.S. Supreme Court). Under the Sixth Amendment, defendants are entitled to state-provided counsel during this stage. But after that, a defendant enters the world of state “post-conviction” proceedings—and there, the Constitution does not require appointed counsel. Some, but not all, states provide counsel at this stage. In states that don’t provide appointed counsel, the inmates must hope for volunteers from advocacy organizations or the private bar. And even states that do provide it do not necessarily offer the funding to pay lawyers, experts, and investigators—without whom a death-penalty case is unmanageable.

Prisoners who are unsuccessful in state post-conviction proceedings may file a federal habeas corpus petition. If denied, that may go up the ladder again to the Supreme Court. A statute provides funding for counsel at this stage. But Congress has strictly limited the timing and number of habeas petitions. A petition filed too soon, or too late, may be denied, leaving no chance to file another. A last-minute petition, however, may be filed when an issue could not have been raised earlier, and those may go to the high court as well. The process is like a maze where a wrong turn by a lawyer may spell death for a client.

So delay is almost built into a sentence of death. But there were specific reasons why Bucklew’s claim about his medical condition took so long to reach the high court.

Bucklew’s state appeal and post-conviction proceedings were complete by 2001, and his first federal habeas corpus petition ended in 2006. But only on April 9, 2014—more than eight years later—did Missouri announce an execution date: May 21, barely six weeks away.

Earlier, Bucklew had joined a case brought by a group of inmates alleging that the state’s execution protocol was “cruel and unusual punishment” when used against any inmate. That case was dismissed on May 2, three weeks after the execution date was set; only a week later, on May 9, Bucklew brought the “as applied” challenge. Even if the execution protocol was constitutional in most cases, he argued, it would violate the Eighth Amendment in his particular case because of his medical condition.

Hochman and Bucklew’s Missouri lawyer, Cheryl Pilate, both cite reasons why the “as applied” challenge wasn’t brought earlier. For one thing, Missouri did not announce its specific execution protocol until 2012—and it revised it in 2013. To win, Bucklew had the burden of showing that this specific protocol would cause him excessive suffering because of his specific condition. Until the protocol was announced, there was nothing to challenge.

Second, an “as applied” challenge like Bucklew’s can’t succeed without expert testimony on both the specific protocol and the effect it will have on the inmate’s medical condition. To mount an effective challenge, a lawyer will need investigators, experts in evidence, psychology, or “mitigation” factors in sentencing hearings. Many states don’t routinely supply such funds.

“You can’t make an argument that has any chance of winning unless you have a medical expert,” Pilate told me. The state consistently refused to grant her funding for expert testimony. “I had no money,” she said. “I had no experts. I had no resources.” Her four-lawyer law firm could not fund a complete defense; she tried cold-calling other lawyers and firms to recruit help: “These cases take you to the edge of financial catastrophe.” Bucklew’s family managed to put up a small amount of expense money to recruit experts, she said; after Sidley, Hochman’s firm, entered the case, it funded more expert evidence.

Bucklew’s disease, meanwhile, is progressive. His tumors had been steadily expanding during his years in prison, meaning that expert testimony in 2007—had there been any—would have been out of date by 2014. Bringing a federal habeas corpus petition based on out-of-date or incomplete medical information would have risked forfeiting Bucklew’s only shot at relief.

Because of the long delays and the rules limiting federal habeas corpus, lawyers defending condemned prisoners are shooting at a moving target. Execution protocols change. In many cases, a prisoner’s medical or mental condition is at issue—and that will change, and may worsen, as the years go by. The law changes also. During the eight years Bucklew was waiting for an execution date, the Supreme Court heard two major challenges to lethal injection as a method of execution. Either decision might have altered the landscape for his appeals.

There’s another problem faced by inmates like Bucklew. Aaron Katz of the Boston-based mega-firm Ropes & Gray argues that “on these method of execution claims … the states are pretty routinely playing hide the ball—they change drugs, change the amount of drugs,” and change the methods by which they will be administered.

Katz represented Christopher Price, an Alabama inmate who wanted the Court to forbid his execution by Alabama’s lethal-injection protocol, and instead order the state to use nitrogen gas, which is a state-approved method of execution. Price’s request was denied because of a missed filing deadline, and he was executed on May 30, after yet another round of emergency appeals—appeals that underline Katz’s point about secrecy. At Alabama’s request, the briefs and exhibits were kept “under seal,” meaning no one could read them in their entirety. The purpose of the seal was apparently to keep secret information about the state’s execution protocols. If that information were on the public record, prisoners bringing future challenges could proceed more quickly. This situation isn’t an anomaly: Since the beginning of 2011, according to the Death Penalty Information Center, “legislatures in thirteen states have enacted new secrecy statutes that conceal vital information about the execution process.”

Katz rejects the idea that inmate appeals should or could be brought well before an execution date is set. “Are we supposed to be filing shotgun litigation at random times and jamming up the federal courts?” he asks. “You’re going to have hundreds of inmates filing at all times. I don’t see why that would be better.”

Everyone agrees that a major reason for late-stage appeals is that, in many states, defendants facing a death sentence do not get the best court-appointed counsel at trial. As Brandon Garrett points out in his book End of Its Rope: How Killing the Death Penalty Can Revive Criminal Justice, many states over the past 30 years have moved to a statewide system of full-time state-paid capital defenders and away from trial counsel appointed for a small fee by the trial judge. For all its Atticus Finch romance, that system too often produced abysmal defense at trial. “By 2013,” he writes, “almost all death penalty states provided state-level capital representation at trial … and only a few holdouts, most notably Alabama, Florida, and Nevada,” do not. Death sentences have dropped dramatically in the states that have these systems. “States with shoddy lawyers for the defense,” Garrett writes, “represent what remains of the American death penalty.” That means fewer new death sentences, which, in time, will mean fewer late nights for the justices.

But that reduction will take time. More than 2,700 prisoners remain on death row across the nation. And many states, particularly in the “death belt” that stretches from Florida to Texas, are determined to keep the gurneys running.

Supporters of the death penalty regard the long delays as miscarriages of justice. “We focus a lot on defendants, and defendants have rights that should be safeguarded throughout the process,” Cassell, the former judge turned victim-rights scholar, told me. “But there is another side and that is victims, who have to put their lives on hold each time there’s a motion or a hearing.” He added, “If you look at the national statistics, you can see increasing periods of delay that cannot be explained by lack of counsel.”

There’s no doubt that death sentences usually lead to long delays. Are death-penalty lawyers really the reason for them? From my own reporting about capital punishment, the problem seems more diffuse. At very best, the recent spleen emanating from the Court’s right wing is bad manners. (The Court’s death caucus is, after all, winning most of the votes that seem to embitter them so.) But the threat goes beyond politesse: The Court’s angry pronouncements could intimidate private lawyers who would usually consider helping with death appeals, and send a message to state and federal judges that death appeals are to be given short shrift.

Capital-defense lawyers do try to halt what Justice Harry Blackmun once called “the machinery of death.” To me, that seems no different from what other lawyers do, in great cases and small. The Exxon Valdez oil tanker spilled more than 10 million gallons of crude oil into Alaska’s Prince William Sound in 1989; the company, represented by the best lawyers in America, delayed final judgment in a tort suit for 20 years. Prison-rights groups sued the state of California in 1990 over flaws in its prison mental-health system; five years later, a federal court concluded that system violated the Eighth Amendment. The state missed court-ordered deadlines to improve it for the next 15 years, before the Supreme Court called it to heel. When private and public money inspires such legal solicitude, are we surprised that capital-defense lawyers fight to preserve their clients’ lives?

“I say that you want to do everything in your client’s interest,” says Chris Adams, an experienced capital-defense lawyer in Charleston, South Carolina. “If I’m his lawyer, I’m going to litigate every legitimate issue that we have.” Aaron Katz, the lawyer who represented Christopher Price in the Alabama method-of-execution case, puts it more simply: “I genuinely don’t want our client to suffer in his last few minutes. That takes priority.”



Thirty years ago this week, I watched the news from Beijing and started shredding my bedding. It was the night before my college graduation, I had been studying Chinese politics, and news had broken that college students just like us had been gunned down in Tiananmen Square after weeks of peaceful and exhilarating democracy protests—carried on international TV. In the iconic square where Mao Zedong had proclaimed the People’s Republic decades before, bespectacled students from China’s best universities had camped out, putting up posters with slogans of freedom in Chinese and English. A “goddess of democracy” figure modeled after the Statue of Liberty embodied their hopes—and ours—for political liberation in China.

On my campus back then were just a handful of students majoring in East Asian studies. Learning of the brutal crackdown in Beijing, we somehow found one another, gathered our friends, and stayed up making hundreds of white armbands for classmates to wear at commencement the next day. Grappling with the cold realities of the “real world” we were about to enter, we didn’t know what else to do. So we tore sheets and cried for what might have been.

The June 4, 1989, massacre was a horrifying spectacle that the Chinese government has sought to erase from national memory ever since. But, 30 years later, contemplating what might have been is more important than ever. In hindsight, Tiananmen Square serves as a continuing reminder about just how much China has defied, and continues to defy, the odds and predictions of experts. The fact is that generations of American policy makers, political scientists, and economists have gotten China wrong more often than they’ve gotten China right. In domestic politics, economic development, and foreign policy, China has charted a surprising path that flies in the face of professional prognostications, general theories about anything, and the experience of other nations.

Today, as policy makers and commentators confidently assert that trade wars are easy to win or that hot wars with China are either impossible or inevitable, the experience of being proved wrong again and again should remind us that events will, more than likely, not turn out as predicted.

In the 1950s and ’60s, American policy toward China suffered because of the “monolithic communism” view that had captured U.S. foreign-policy circles. Although we now know that China and the Soviet Union had very different communist models and national interests—and that their relationship was exceptionally troubled—successive administrations in the United States put China and the Soviet Union into the same enemy camp. Not until the Nixon administration did the United States began normalizing relations with China in what would be one of the greatest diplomatic triumphs in American history. Had American leaders recognized and capitalized upon the Sino-Soviet split earlier, one wonders how history might have unfolded differently.

Economic assessments weren’t any better. If you were an economist in the early years after World War II, the Nobel laureate Michael Spence has pointed out, you would have predicted that African nations were more likely to develop faster than China because they had greater natural-resource wealth. And you would have been dead wrong. In 1960, the average GDP per capita in the Democratic Republic of Congo was $220, about twice the per capita GDP in both Nigeria and China. By 2017, China’s GDP per capita had skyrocketed to nearly $9,000—more than four times that of Nigeria and 19 times greater than Congo’s. Since the Chinese government embarked on its modernization program, in 1978, Beijing has lifted more than 850 million people out of poverty and sustained the fastest economic growth in human history.

China’s domestic political system has also defied predictions. Many declared that China would eventually go the way of the other “Asian tigers”—Japan, Taiwan, and South Korea—which became more democratic as they grew rich. That never happened. And when the democratic wave swept across the communist world from 1989 to 1991, ending the Cold War and leading some to declare that the “end of history” had arrived, it skipped China. With dizzying speed, the Berlin Wall fell, East and West Germany were reunified, the Soviet Union collapsed, the Iron Curtain tumbled, and all the former communist regimes of Eastern Europe were replaced by democratically elected governments. The communist old guard was ousted just about everywhere except Beijing. When China’s moment of reckoning came, Communist Party leaders chose bullets, not ballots. And they made a long-shot, long-term Faustian deal to guarantee economic development in exchange for continued party control that has lasted ever since.

Since 1989, successive Democratic and Republican administrations have banked on the idea that integrating China into the World Trade Organization would turn China into a responsible stakeholder and make the Middle Kingdom more like Western capitalist democracies. Instead, China has used the liberal international order to secure its illiberal political system and create unfair trade advantages for its favored domestic corporations while engaging in intellectual-property theft so massive that, in 2012, General Keith Alexander, then the nation’s top cyberwarrior and director of the National Security Agency, called it “the greatest transfer of wealth in history.” This, from a man not known for overstating.

Why have so many been so off about China for so long? In part it’s because policy makers and academics alike look for patterns, not exceptions. We are trained to generalize across cases and use history as a guide to the future. But China has always been sui generis—an innovator in the ancient world that became a poverty-stricken nation in the modern one; a nation with a deep and proud imperial history ruled by a post-1949 Communist leadership with an aversion to remembering it; a rural nation with some of the world’s most sophisticated high-tech surveillance.

There is also a fundamental disconnect in how American and Chinese leaders see time. For Americans, memories are short, attention is fleeting, and policy lurches from crisis to crisis. In Washington, passing a budget and keeping the lights on seem more and more like heroic acts. In China, by contrast, memories are long, attention is enduring, and the government plans for the long haul. China’s rise in artificial intelligence and other technologies has been in the works for years. Its military modernization started in the 1990s. Back then, a Chinese admiral was asked how long before China would build its own aircraft carrier. He replied, “in the near future”—by which he meant sometime before 2050.

These different views of time hang over modern geopolitics. For American leaders, U.S. global leadership is the way of things. For Chinese leaders, it is an aberration: China was a great power until the Opium Wars in the 1840s ushered in a “century of humiliation” by the West. In Beijing, China’s rise isn’t new. It’s a reversion to the way things used to be.

Donald Trump’s administration has turned the page, acknowledging that the United States and China are locked in a competitive struggle with some mutual interests and many conflicting ones. The administration’s fundamental China shift doesn’t get the attention or praise it deserves. Even so, getting U.S. policy on China right won’t be easy. Our economies are tightly interconnected, our domestic politics are each highly charged, and our security interests are more and more at odds. A good China policy starts by recognizing that China’s rise is in many ways unique, and that general patterns and predictions may obscure more than they clarify.



In a week during which, among other things, the White House defied multiple congressional subpoenas, the commander in chief threatened armed conflict with Mexico, and we learned that the number of Americans breathing unsafe air is at an all-time high, presidential politics was largely consumed by the following question: Should the Boston Marathon bomber be allowed to vote from jail? The odds of Dzhokhar Tsarnaev swinging an election from death row are approximately zero. But if Democrats aren’t careful, the odds of these inconsequential controversies dominating election season are dismayingly high.

Outlier hypotheticals have, of course, been around for quite a while. The most famous example came at the beginning of an October 1988 debate between the presidential candidates Michael Dukakis and George H. W. Bush. “If Kitty Dukakis were raped and murdered,” CNN’s Bernard Shaw asked the Massachusetts governor, “Would you favor an irrevocable death penalty for the killer?”

It was highly unlikely, to say the least, that Dukakis would find himself avenging his wife’s death. He wasn’t running for mayor of Gotham City. But by focusing on a hypothetical problem affecting one person rather than a real issue affecting the entire country—the immorality of capital punishment—the question put the governor in a bind. If he stuck to his principles, he was a robot. If he let his emotions rule, he was a hypocrite. (Dukakis chose robot. Watching with the sound off, you’d think he was discussing an infrastructure plan rather than a loved one’s grisly death.)

It says something about our politics, and the media that cover it, that we’ve largely forgotten the criticism Shaw received. It later emerged that his three co-moderators—all women—had tried to talk him out of asking such a gory and personal question. For her part, Kitty Dukakis called the moment “outrageous” and denounced it as “theater.”

Decades later, however, the media consensus appears to be that Shaw’s immoderate moderating was not just appropriate, but epic. Writing for Politico in 2007, Roger Simon called Shaw “one tough customer” and retold the story of the killer question in awed tones. CNN included the question on its 2012 list of “10 Debate Moments That Mattered.” In modern campaign reporting, where politics is often covered as a sport, journalists always look for surprise and controversy; asking about outlier cases rather than typical ones is an excellent way to create both.

Presidential candidates should expect more of these Dukakis questions than ever. For this, they can blame not just the media, but Donald Trump. This is a president who loves outliers. He appears at his happiest while discussing some gruesome act perpetrated by an immigrant, despite the fact that U.S. citizens commit violent crimes at higher rates than newcomers. And he has abandoned any pretense of moderation, either in tone or in policy. As the election draws closer, his argument is roughly this: I may be extreme, but Democrats are even worse. Reporters, not entirely unreasonably, feel a responsibility to test that theory by seeing exactly how far his would-be challengers will go.

Which brings us back to this week and a question that, while eagerly amplified by journalists, was first asked by a Harvard junior. “You’ve said that you believe that people with felony records should be allowed to vote while in prison,” the student asked Senator Bernie Sanders at a CNN town hall. “Does this mean that you would support enfranchising people like the Boston Marathon bomber?”

The three candidates who addressed the question have all proved themselves to be highly skilled campaigners. But none of them handled the moment particularly well.

Sanders enthusiastically embraced Tsarnaev’s right to vote. While voting rights in general are quite popular, opposition to Tsarnaev’s somehow united both Lindsey Graham and Cher in opposition.

Mayor Pete Buttigieg argued that some criminals should have their voting rights deprived as “punishment,” and that you should be able to vote only once you’ve paid your debt to society. It’s an argument that conveniently keeps the Boston bomber off the rolls. Less conveniently, it’s the same argument used by Florida Republicans, who this week passed a bill disenfranchising hundreds of thousands of their fellow citizens who were formerly, but are not currently, incarcerated.

Senator Kamala Harris said the issue was worth a conversation. Then, in a press conference a day later, she said that it was complicated and that she would talk to experts before making up her mind. This is the political equivalent of saying you’re in a tunnel before making static noises and hanging up the phone.

Each candidate addressed the question in a different way, but none of them managed to refocus the conversation on something they would actually have to deal with as president.

And that’s a real problem. People frequently assume that political candidates try to convince voters to agree with their answers. But just as often, in my experience, they try to convince voters to agree with their questions. I saw this sleight of hand as a junior speechwriter for President Barack Obama’s 2012 campaign. We knew that if voters asked themselves, “Am I happy with how quickly the economy has recovered?” Obama would have an uphill road to reelection. But if people asked instead, “Who would I want in charge going forward?” they would pick the incumbent. In the end, enough voters asked the right questions, and Obama won a second term.

As a president, Trump couldn’t be more different, but he faces a similar challenge as he mounts his reelection bid. If Americans are focused on health care, taxes, or climate change, he’s likely to lose. If they’re focused on something controversial but fundamentally unimportant, like, say, the democratic liberties afforded to a single particularly heinous citizen, the president has a fighting chance.

Which is why Democrats need to get better at answering Dukakis questions, and quickly. It’s fine to start by engaging the emotional content. There’s no need to be a robot. After that, however, it’s not just acceptable but necessary to get a little meta. They shouldn’t dodge the question—instead, they should evaluate it. If a candidate doesn’t think something is relevant to the job of being president, he or she should say so.

The adage in politics is “Answer the question you wish you were asked.” But perhaps a better, more intellectually honest approach is this: “Answer the question that really matters.”

In the case of voting rights, there is certainly a question that needs answering. There are 2.2 million people incarcerated in the United States, and 2.199999 million of them are not Dzhokhar Tsarnaev. The problem is not the number of Boston bombers who can vote. It’s the millions of Americans, a wildly disproportionate number of them black or brown, who cannot. In this country, mass incarceration has been turned into a tool for mass disenfranchisement. That’s the real crisis the next president will face. And how best to face it is the kind of debate worth having.



Listening to the Democratic candidates for president, you would probably not know that globalization, as it has existed for the past several decades, may soon cease to exist. Since at least the turn of the century, the close ties between the United States and China, which together constitute 40 percent of the world’s GDP, have bound the world economy together. But this deep interdependence—which is sometimes called “Chimerica”—may not survive Donald Trump. It’s not just his tariffs on Chinese goods, and China’s retaliatory tariffs on American products, which if not repealed will likely depress trade between the nations. Trump is also building a wall between China’s and America’s biggest companies. In May, his administration forced Google to stop supplying crucial software to Huawei, the world’s second-largest smartphone maker. China will likely respond by bolstering its own suppliers so it’s never at America’s mercy again.

The U.S.-China split is even influencing global travel. This week, China warned its citizens against visiting the United States, and Chinese enrollment in American universities is dropping. Trump and Xi Jinping may be leading the world into an era in which money, goods, information, and people flow less freely across national borders than they have for the past quarter century. The headline of a recent op-ed by former German Foreign Minister Joschka Fischer calls this “The End of the World as We Know It.”

How do the major Democratic presidential candidates feel about this potentially epic shift? We don’t really know. They rarely bring it up on their own. Bernie Sanders says nothing about China on his website. Neither do Elizabeth Warren, Pete Buttigieg, Beto O’Rourke, Cory Booker, or Kirsten Gillibrand. All Joe Biden says about China on his website is that it’s “rising.” On hers, Amy Klobuchar pledges to “invest in diplomacy and rebuild the State Department and modernize our military to stay one step ahead of China.” Kamala Harris’s website says the United States should “work in lockstep with our partners” to confront “China’s unfair trade practices.” That’s about as substantive as it gets.

To be fair, presidential candidates tend to talk about what voters want them to talk about. And despite Trump’s trade war, Democratic voters are most concerned about health care, education, the environment, and abortion. When the Pew Research Center asked Democrats in January which issues should be a top priority in Washington this year, trade came in 17th out of 18.

Leading media outlets aren’t doing nearly enough to jump-start the conversation. CNN, MSNBC, and Fox have all hosted town halls in which moderators and potential voters ask the presidential candidates questions. In many of them, transcripts suggest, China hasn’t come up at all. As far as I can tell, Huawei hasn’t been mentioned once.

When the candidates are forced to discuss China, you can glimpse the faint outlines of a divide between the more left-wing and more centrist contenders. In an interview on PBS last year, Sanders said he “strongly supports” tariffs against China, but thinks “Trump gets it wrong in terms of implementation.” Warren has said that “tariffs are one part of reworking our trade policy.” By contrast, Buttigieg, in his MSNBC town hall, said “a tariff is a tax” that will make Americans “all pay, on average, 800 bucks more a year, starting now.” In hers, Harris also slammed the “Trump trade tax,” which means “we are paying more for washing machines and shampoos.” The implication is that unlike Sanders and Warren, Buttigieg and Harris don’t just oppose the way Trump has imposed tariffs. They oppose tariffs in general.

But the debate the candidates should be having—and media interviewers should be nurturing—is about much more than tariffs. It’s about whether and how to alter the terms of Chinese-American interdependence. Right now, Trump’s efforts to change the relationship seem likely to break Chimerica apart and end globalization in its current form. Yet most Americans haven’t heard a clear Democratic alternative.

There are three broad arguments that Democratic hopefuls could make. The first is that Trump is right to pressure China to open its economy to U.S. corporations, but that he shouldn’t do so unilaterally. Yes, Democrats might argue: Trump is right to demand that Beijing permit American companies to do business in China without forming joint ventures with Chinese counterparts. He’s right to demand that China do a better job of protecting intellectual property so Chinese companies can’t create cheap knockoffs of American goods. Where he’s wrong is in trying to accomplish all this on his own. In Beto O’Rourke’s CNN town hall, the former Texas representative brought forth the kernel of this argument. “When in the history of this country have we ever gone to war, a military fight or a trade war, without allies?” O’Rourke asked. “Because that’s exactly what we are doing now with China.”

The implication is that the U.S. should quickly settle its trade disputes with Japan, South Korea, and Europe. If they band together, the democracies can focus instead on pushing China to accept the responsibilities that come with being the global economic power that it is. In trade matters, China still portrays itself as a developing country, a status that allows it to protect Chinese companies and impose unfavorable conditions on Western firms that want to sell to Chinese consumers. The natural forum in which to pressure Beijing would be the World Trade Organization, which the United States could empower rather than trying to cripple, as Trump has.

For Democrats, such a strategy would make intuitive sense. In economics, as in war, Democrats tend to prefer multilateral to unilateral interventions, and to support international institutions that legitimize American power. Barack Obama’s administration was thinking in these terms when it tried to create the Trans-Pacific Partnership, which it hoped would create rules for trade and investment across Asia that China felt pressured to match. Politically, the current Democratic candidates probably can’t endorse the TPP, because sentiment in the party has shifted so far against the proposed agreement. But it’s easy to imagine the more moderate Democrats—Biden, Buttigieg, Harris, and O’Rourke—pursuing a modified version of Obama’s strategy of preserving the Chimerica relationship while making it work better for American businesses.

Secondly, Democrats could make a different, more radical, argument: Opening up China’s economy to American companies and American investment isn’t the answer at all. In this view, the larger problem at the heart of globalization is that big corporations can scour the world seeking the cheapest workers with the fewest labor and environmental protections.

By this logic, Democrats shouldn’t assemble foreign partners to achieve Trump’s current trade goals, because the goals themselves are wrong. America should only seek trade agreements with strong, enforceable labor and environmental standards, and perhaps even some form of global minimum wage. The University of Rhode Island historian Erik Loomis has proposed that future trade deals create international courts that, rather than allowing corporations to sue governments for impeding investment and trade, as the TPP would have, allow citizens to sue corporations for mistreating workers or harming the environment.

The goal of this approach would be less to recalibrate the relationship between America and China—which now possesses its own “Rust Belt” as corporations shift to poorer countries with lower wages——than to recalibrate the relationship between corporations and workers. America would focus not on pushing China to better protect the intellectual property of American businesses but to allow independent labor unions so American and Chinese workers can together pressure their employers to raise wages and improve working conditions. Democrats, wrote the activist Tobita Chow in a plea to the 2020 contenders, should “recognize Chinese workers as potential comrades in a shared struggle against global corporate power.”

For anti-corporate Democrats such as Sanders and Warren, Chow’s argument might constitute a natural international extension of their domestic agenda. But this more dramatic rewriting of globalization’s rules is likely harder to achieve. Permitting more foreign investment doesn’t threaten the Chinese government’s hold on power; permitting independent labor unions could. Beijing surely remembers that Solidarity, the independent labor union led by Lech Walesa, was what helped bring down the Communist government in Poland. Sanders and Warren are not Trump-style hyper-nationalists. They don’t want to undo globalization; they want to stop corporations from defining it. But the more ambitious your goals for a trade deal, the harder that deal is to reach, which for Sanders and Warren may be an acceptable risk. If America and China can’t reach an agreement, the tariffs remain—an outcome that the two liberal senators appear more comfortable with than their more centrist opponents.

The third Democratic approach for remaking Chimerica would be, politically, the easiest. It’s to focus not on China but on America. Instead of decrying the Made in China 2025 initiative, in which Beijing subsidizes crucial emerging industries such as robotics and green energy, the MIT economist David Autor has suggested that the U.S. adopt something similar—for instance, by dramatically boosting investment in the National Science Foundation and the National Institutes of Health. Democrats could frame their openness to immigration as a way to bring in the talent necessary to compete with China. And they could propose infrastructure investments that, for instance, accelerate America’s transition to 5G. Rather than breaking up Chimerica, the United States would strengthen its competitive position within the relationship by making changes at home.

The third option isn’t incompatible with the first or second one. But so far, it’s hard to know which approach the Democratic candidates prefer, because while they are laying out proposals for expanding health-care coverage, making college cheaper, saving abortion rights, and converting to green energy, they are barely debating the U.S.-China relationship at all.

When the primary debates begin, at the end of this month, the networks must pin the Democratic candidates down. If voters go to the polls early next year knowing nothing about how the Democratic contenders envision the future of a relationship that for decades has anchored the world as we know it, those candidates and the media will both have failed.

Faith Hill contributed research to this article.



As the 2020 presidential campaign gets under way, Democrats are beginning to think about what type of foreign-policy message they need to defeat President Donald Trump. A recent conference organized by National Security Action, a progressive group run by former Obama-administration officials, unveiled an early consensus—Democrats will promise to intervene less abroad, refocus on strengthening America at home, and work with others on shared problems, such as climate change. The first two elements have been part of the core message of the four people to win the presidency over the past quarter century.

Advisers to the Democratic presidential campaigns expect intense fights over a small number of issues—such as Israel, which pits younger progressives against the party’s traditional position—but otherwise they believe that the candidates will generally agree on foreign policy, and focus instead on domestic matters. Most will make carefully crafted set-piece speeches on foreign policy, but it will not be a part of their stump speech.

There is a clear logic to the emerging consensus, but it may not be enough. The messages that worked for Bill Clinton, George W. Bush, Barack Obama, and Donald Trump are unlikely to work to dislodge Trump. If Democrats want to beat Trump on foreign policy, they need to place competition with China at the heart of their pitch to voters.  

On military intervention, Democrats could find themselves scooped by the president. He is undoubtedly reckless and militaristic, but he also seems acutely aware of the risks of large-scale military action. He recently publicly rebuked John Bolton, his national-security adviser, for pushing for military intervention in Iran, North Korea, and Venezuela. Trump’s militarism could see the United States embroiled in a war between now and the election, but there is a strong possibility that he will avoid one. Yes, the United States remains involved in Afghanistan and Syria, but Trump wants to pull out of both conflicts and may ultimately insist on it as the election looms.

The argument that Americans must pivot to the home front may fare no better. This has been Trump’s mantra for years. The results of his renegotiations of trade deals may be poor, and he has not fulfilled his promise to invest in infrastructure, but he has already made the rhetoric that the Democrats are trying to adopt his own. Moreover, he may be able to tell many voters that he’s succeeded. The present economic boom started under Obama, but it doesn’t really matter—if it extends through next November, voters will credit Trump. And, as David Gordon of the Eurasia Group observes, the states Trump won in 2016, including many that suffered during the Great Recession, are experiencing higher levels of job growth than the rest of the country.

That leaves Democrats with international cooperation as their best hope of distinguishing their foreign-policy message from Trump’s. But a recent study of public opinion by the Center for American Progress found that this will prove a tough sell:

Language from foreign policy experts about ‘fighting authoritarianism and dictatorship,’ ‘promoting democracy,’ or ‘working with allies and the international community’ uniformly fell flat with voters in our groups. Some participants questioned the idea that an international community actually exists. Democracy promotion reminded others of the 2003 Iraq War and the failures of the George W. Bush administration. When asked what the phrase ‘maintaining the liberal international order’ indicated to them, all but one of the participants in our focus groups drew a blank. Voters across educational lines simply did not understand what any of these phrases and ideas meant or implied.

The inconvenient truth for the Democratic field is that Trump’s crude foreign-policy message could resonate in 2020. He promises to remove constraints and use power freely, including against America’s friends, to extract more economic benefits. The benefits may be smaller than advertised. His approach may come at the cost of eroding America’s global influence and replacing the rules-based international order with something temporary, fragile, and transactional. He may be even more radical in his second term. Trump’s presidency may dramatically increase the risk of a national-security catastrophe—character is fate. But, until the catastrophe actually arrives, Trump is unlikely to be hurt politically. Many voters are only too pleased to have a president willing to shake things up internationally.

The Democratic candidates need to ask themselves a fundamental question: Is the minimalist foreign-policy message that has been used repeatedly since 1992 appropriate for a moment defined by political and technological upheaval around the world? Is there an opportunity for a candidate to offer a more comprehensive message about why Trump is failing abroad and how it matters to Americans in their daily lives?

As long as he avoids war and recession, Trump’s political Achilles’ heel is not his aggressiveness or ignorance, but his focus on the past, not the future. He is obsessed with the industries of the 1950s—steel, aluminum, cars, and dishwashers—and never speaks about the industries of tomorrow. He talks about the unfairness of old security commitments but never about how the United States must work with others on the challenges of the future. He never even mentions the central message of his administration’s own national-security strategy, that the United States is in a new great-power competition that supersedes terrorism and rogue states.

The problem is that, on foreign policy, many Democrats are also stuck in the past. They talk about the liberal order from the 1940s, NATO’s shared past, territorial disputes that date back decades, and an intervention debate that began in the 1990s. But voters don’t want to embrace the past or abstractions. They care how the world challenges their lives and those of their children, not just now but also in the years to come. Americans have always been motivated by threats and challenges to liberty and prosperity at home, rather than grand projects to promote democracy. This was even true of the liberal order itself—Americans rejected the project in 1945 and 1946, only turning to it as a necessary tool to confront communism.

The challenge for the Democratic candidates is to connect all the issues, domestic and foreign, into a larger narrative that relates to Americans’ daily lives, illuminates the future, and offers a path forward. The most likely way to do this is to say that the United States is losing a vitally important competition with China because the president is obsessed with the past and ignorant about the future. China is the one thing that connects all other things. It directly affects the economy, the financial system, technological innovation, values, and national security. As the Center for American Progress study showed, it is the only foreign-policy issue, other than terrorism, that voters really care about—not because they seek conflict, but because they worry about falling behind.

The United States is in a multifaceted competition with China. This is unlikely to involve military conflict, although there is a military dimension to it. The competition is technological, economic, political, diplomatic, and ideological. It is particularly complicated by the fact that the United States and China are interdependent and need to cooperate with each other even as they compete. The president styles himself as tough on China, but as Ely Ratner, director of studies at the Center for a New American Security, put it, Trump is “confrontational but not competitive.” Many of his actions are counterproductive and irresponsible. And in some areas of the competition, such as the clash between the free world and autocracy, Trump is on the wrong side.

Putting competition with China at the center of their foreign policy would allow Democrats to make the case for modernization and investment in crucial sectors, most notably in technology, which is becoming the competition’s center of gravity. The conventional wisdom is that the United States is destined to out-innovate China, because open systems beat closed systems. But what was true in the past with nuclear power, the microchip, and the internet may not apply to artificial intelligence, where access to data could give authoritarians an edge.

On 5G, the next generation of wireless-networking technology, China has shown itself to be particularly adept, successfully leveraging Huawei’s position to remove competitors from the field through subsidies and to undercut them on price. Unlike John F. Kennedy’s missile gap, the technology gap is real in key sectors. Presidents Obama and Trump were slow to recognize the problem. And now, the Trump administration is proposing to slash the budget for the very programs and agencies that make America competitive, such as the National Science Foundation and the Department of Education.

Technology is not just an industrial question. It also affects values. The way that China and other authoritarian governments are using facial recognition, surveillance, and social-credit scores to consolidate their control, and social media and artificial intelligence to interfere in democracies, raises profound questions for Americans. Voters don’t necessarily want to promote democracy, but they do want to defend it.

Trump likes to complain that America’s allies take advantage of the United States, yet he has repeatedly rejected the European Union’s offer to work together to make China play fair in the global economy, dismissing the EU as worse than China. He has demonized Germany and its chancellor, Angela Merkel. Relations with the United Kingdom are at their lowest point since the Suez crisis of 1956. Meanwhile, Trump cozies up to truly problematic allies, such as Viktor Orbán, Hungary’s wannabe strongman who champions “illiberal democracy” and flirts openly with the China option as well as with Russia. Trump hosted Orbán on Monday. The minimalist playbook, which the Democratic field has so far followed, is to ignore that visit or to tweet disapproval. A bolder approach would have been to flip the script on Trump by pointing out that Orbán is taking advantage of his alliance with America, and to question whether Hungary can remain a U.S. ally if its troublesome trajectory continues unabated.

The Trump campaign believes that China can be a winning issue in the 2020 campaign. It is already leaping on Joe Biden’s off-the-cuff remark that China “isn’t in competition with us.” But a few months ago, at the Munich Security Conference, Biden also said that China “seeks to establish itself as a hegemon and a global power player” and that the United States finds itself in “an ideological struggle … a competition of systems [and] a competition of values” with Beijing and other authoritarian powers. Bernie Sanders and Elizabeth Warren have both highlighted the risk posed by kleptocratic and autocratic regimes in their foreign-policy speeches, with Warren singling out China in particular.

But Democratic political strategists never want to talk about foreign policy, seeing it as a loser. Democratic foreign-policy experts generally agree that relations with China are becoming more difficult, but they are deeply divided about how much emphasis to place on it. Many accept the thrust of Trump’s official national-security document: that the United States finds itself in a new era of great-power competition. Their complaint is that Trump doesn’t believe a word of it, while his administration’s response is ineffective and counterproductive.

Other experts worry that the China challenge is over-cranked and in danger of spiraling out of control. That Kiron Skinner, the State Department’s director of policy planning, recently called it a clash of civilizations feeds this concern. These advisers are also keen not to break with Obama, who sought to avoid having his foreign policy defined by geopolitical competition. The skeptics are aligned with the consultants, and the result is minimalism. They hope they can tap into the competitive impulses by making a generic argument that the United States must be strong at home to be strong in the world, but without identifying the country’s main competitor, that argument loses its potency.

Yet with 22 candidates already in the race, a consensus will be hard to maintain. There is an incentive to think about new approaches that draw a stark contrast with Trump but also depart from the Obama administration. Democrats need a powerful foreign-policy message that connects with domestic politics. Competing responsibly and effectively with China is the best one they have.



President Donald Trump declared a national emergency and banned equipment made by tech firms of “foreign adversaries” from operating in the United States. The Department of Commerce followed up, listing Huawei and dozens of other Chinese firms as risks to American national security, prohibiting them from selling or buying in the U.S. market. The actions were much broader and more bare-knuckle than even China hawks had expected.

Trump’s supporters are test marketing the argument that only he could or would get tough on China. Steve Cortes, writing in RealClearPolitics, compared Trump on China to Ronald Reagan on the Soviet Union—ahead of his time in confronting its malevolence. Greg Autry wrote in Foreign Policy, “Trump’s China policy is a triumph.” The Wall Street Journal reported that CEOs have been coming around to support tariffs as “American business’s best shot at addressing those long-standing grievances.” Even The New York Times acknowledged that Trump has overturned years of failed multilateral efforts to deal with China.

Is Trump “winning” China, in contrast to his predecessors?

Previous presidents did allow China to accede to the World Trade Organization in 1999 and to receive permanent normal trade-relations status with the United States in 2000, even though China was not in full compliance with the rules. President Bill Clinton and British Prime Minister Tony Blair orchestrated China’s entry into the liberal economic order—what they termed the “rules-based order”—in the belief that a China integrated into the global economy would succumb to political openness. Western policy makers have long assumed that as people grow more prosperous, they become more demanding political consumers. Regime change by prosperity, if you will. Subsequent administrations also believed that China would become a “responsible stakeholder” once it was a member of the global club.

As Reihan Salam has argued, those decisions now look faulty. Or at least premature. The Chinese Communist Party may worry about its ability to preserve its control. Otherwise, why would it need to build a surveillance state, to put 1 million Uighurs in “reeducation camps,” to ostracize and imprison human-rights lawyers, or to “disappear” the head of Interpol? But it doesn’t appear to be anywhere near actually losing that control.

One line of argument, advanced by Cortes, among others, is that Trump was the first to understand the challenge China poses. That is, no other politician was able to recognize that a China rising without playing by the rules of the American order would present a systemic challenge. Believing this would require accepting that no other politician saw China thieving intellectual property from U.S. companies, forcing technology transfers, prejudicing state-owned companies, or manipulating its currency to mercantile advantage. But the public record proves that other leading political and economic figures understood the risks: Mitt Romney during the 2012 presidential campaign, for example, and President Barack Obama, who set up the 19-nation Trans-Pacific Partnership so that China would get access to those markets only if it played by the new rules.

What is striking about the U.S. debate on China is how little debate there actually is over whether China is a malign force in trade, development, foreign, or domestic policy. China policy would likely have hardened under any American leader because China’s actions have been so egregious that they are undeniable.

A second line of argument is that only Trump could force Chinese compliance to the rules because only he is willing to use the tactics likely to be successful. Variations on the theme include Trump as master negotiator and Trump as either purposeful or inadvertent practitioner of the madman theory of international politics. Peter Navarro, the president’s director of trade and manufacturing policy, put it like this: “The reality is, unless the president talks tough on trade and has possible concrete actions to back up that talk, these people won’t talk to us. They had no incentive to talk to us, none, because they’re winning and we’re losing.”

As Phil Levy pointed out a year ago in Forbes, though, the madman approach is productive only if the leader pivots to making reasonable demands once the counterparty comes to the table: “This has been the problem that has plagued Trump trade policy—his erratic behavior has effectively brought lots of countries to the negotiating table, but he has then presented them with equally wild demands that fail to serve U.S. interests.”

Trump is different from his predecessors when it comes to China, in part because he uses tools that are economically riskier than those that more traditional presidents would have chosen. Those tools threaten economic growth and incite stock volatility. Unlike other presidents, Trump doesn’t bother to gather allies and use international institutions such as the WTO or agreements such as the TPP, obvious advantages the United States has in any confrontation with China.

The administration’s tools include: tariffs, freedom of navigation operations in the South China Sea, opposition to Chinese companies in communications networks, study and travel restrictions on Chinese nationals suspected of spying or having links to the Chinese military. Setting aside the merit of these choices, the administration gets in its own way by failing to prioritize its efforts to contain China—pivoting back to the Middle East now, then threatening a trade war with Europe.

What strategy really is, as Eliot Cohen has argued, is a theory of victory: How will we use what means are available to us to attain our aims? Previous American presidents theorized that China would see the advantages of becoming rule-abiding. Trump theorizes that the American economy is strong enough to force Chinese submission. Those different approaches portend very different kinds of relations for the United States with China: The first would make them partners in prosperity; the second would reveal them supplicants.

But Trump contends that his approach is working, tweeting that “they are, and will be, losing.” Treasury Secretary Wilbur Ross thinks not only that the U.S. will win the trade war, but that it may result in social unrest that challenges Communist Party control in China. So we are back to regime change, but this time by threatening penury rather than luring with prosperity.



There’s no use in pretending that the White House’s announcement that it has directed former White House Counsel Don McGahn not to testify to Congress comes as a surprise.

It is only the latest salvo in the skirmish between Donald Trump’s administration and the Democratic House. The White House had already told McGahn not to supply documents to the House Judiciary Committee under subpoena. It sued to prevent the president’s accounting firm from providing documents to the House Oversight Committee. Treasury Secretary Steven Mnuchin has refused to comply with a House Ways and Means subpoena for President Trump’s tax returns. Attorney General William Barr has been held in contempt for refusing to testify to the House Judiciary Committee. Faced with Democratic investigations, the Trump team has settled on a strategy of foot-dragging and dubious legal theories.

Yet while the McGahn contretemps was predictable, it’s arguably more important than any of the other tugs of war between the House and White House. More than that of any other witness, McGahn’s testimony would deal directly with whether and how Trump obstructed justice—and it would come closest to showing what an impeachment proceeding against Trump would look like.

In support of the direction to McGahn, the administration released a legal rationale developed by the Office of Legal Counsel. It’s impossible to say whether it will hold up in court. In broad strokes, it seems like a somewhat novel assertion, and a broader one than what previous administrations have claimed. However, the test will come in a courtroom, or several, and this Supreme Court has proved sympathetic to assertions of executive power. The OLC opinion does not, as Zoe Tillman and Steve Vladeck note, actually block McGahn from testifying, or claim that the president can. Instead, it says that he isn’t legally required to do so.

But McGahn has plenty of reasons he might not want to show up. It’s hard to see how he would benefit from testifying, and whatever Democrats hope to get out of McGahn as ammo against the president, they would surely have some tough questions for McGahn as well. Testimony would probably bring unwanted flak from Trump, and it would bring unwanted attention on McGahn’s law firm, Jones Day, which does a lot of work for Republican politicians. (The Trump campaign used to be a client, but in April it hired an in-house lawyer, in what was interpreted by some as a swipe at McGahn.)

The White House also has plenty of reasons it wouldn’t want McGahn to show up, too. There’s been lots of attention given to the prospect of Barr or Special Counsel Robert Mueller testifying to the House. “Frustrated House Democrats Pin Their Hopes on Mueller,” The New York Times announced last week. What Democrats imagine they’re going to get out of either man testifying is unclear. Consider Barr’s testimony to the Senate Judiciary Committee on May 1. The attorney general occasionally made some missteps, and it was a useful forum for Senator Kamala Harris to boost her presidential campaign. It did not, however, produce any epiphanies, and no surprise—Barr, on his second tour as attorney general, knows how to deflect.

It’s been nearly two months since Mueller submitted his report, and despite Democrats saying since then that they want to hear from him, there’s still no testimony scheduled, because Mueller has not agreed to testify yet. Unlike Barr, Mueller has not dedicated himself to Trump’s devoted defense, but he’s unlikely to be all that interesting, either. Mueller had 448 pages in which to express his views, and if he wanted to accuse the president of obstruction of justice, that’s where he would have done it.

Moreover, Mueller and Barr are each at least a degree removed from the action: Mueller investigated the underlying events, and Barr summarized and redacted Mueller’s report. Each man has already made his view clear. While Mueller could speak to his disagreement with Barr over summarizing his report, that report strongly implies that Congress ought to do the deciding on obstruction, and he’s unlikely to be especially patient if it tries to bounce the decision back to him.

But McGahn was an eyewitness to, and often a participant in, the events described. Trump says that he never actually told McGahn to fire Mueller, contrary to the Mueller report. So why did McGahn think that? The best person to answer that is Don McGahn. Why did McGahn feel his job was being threatened? Barr and Mueller can only speculate, but McGahn actually knows. Why did McGahn decline to write a letter saying Trump didn’t obstruct justice? McGahn is the man to answer. With collusion receding from view and obstruction taking center stage, McGahn is more central than any possible witness except Trump.

On Monday evening, The Washington Post reported that Michael Cohen, Trump’s former personal attorney for the president, alleged to Congress that Jay Sekulow, a current personal attorney for the president, had instructed him to lie about when negotiations over a possible Trump Tower Moscow ended. That’s yet another reason Congress would want to hear directly from the former White House counsel on whether Trump tried to use a lawyer to obstruct justice.

Not only would McGahn be far more likely to provide Congress and the public with new information, but this very fact would also make the proceeding resemble an impeachment hearing—an outcome that Speaker Nancy Pelosi and Judiciary Committee Chair Jerry Nadler have sought to forestall, or at least slow. If the House moved forward on impeachment, it would want testimony from participants in the events themselves, not other people or groups who have already conducted their own investigations. Testimony from a White House counsel can be devastating to a president—just ask John Dean.

This would make McGahn’s testimony, far more than Barr’s or Mueller’s, the main event in House investigations into the Trump administration. That means that among the several fights over executive privilege between the White House and House, this one is at the top of the card.



I’ve spent the past year interviewing married or cohabiting heterosexual mothers across the United States about the distribution of child-care labor in their home. Most of them did the lion’s share of the work and were angry with their partner. Yet many of them told me they were “grateful.” Over and over again, I heard women complain that they were doing more than their partner, only to then insist that they were lucky to have any help at all.

Take Andrea, a full-time marketing professional in Portland, Maine, and the mother of an elementary-school-age child. Although she sometimes feels that her husband, Patrick, who works for a health-insurance company, is “right there with her,” Andrea says he behaves like her junior apprentice in child-rearing. (These aren’t their real names. I granted my subjects anonymity in exchange for candor.)

“We had it out the other night, and then what did he say this morning? ‘I’m so sorry I can’t help you more. I feel so guilty about that.’ He’s helping me, instead of, like, ‘We’ve got to set up the conditions for both of us to be successful.’ But still, I have so many friends whose husbands have never put their child to bed, because it’s her job because she’s the mom. When I hear things like that, I feel really grateful.”

Andrea’s misplaced gratitude is not only common, but also an impediment to the elusive goal of equity in the home.

The number of mothers in the labor force who have young children hit its peak and leveled off two decades ago. So, too, did the parenting contributions of men. For the past 20 years, research by the Bureau of Labor Statistics has consistently found that women employed outside of the home shoulder 65 percent of child-care responsibilities, and their male partners 35 percent.

Studies have also found that fathers who work long hours have wives who do more child care, while mothers who work long hours have husbands who sleep more and watch lots of television; that working mothers with preschool-age children are two and a half times as likely as fathers to get up in the middle of the night to tend to their kids; that men with babies spend twice as much weekend time engaged in leisure activity as their female partners do. Mothers remain more likely to miss work to tend to sick kids, to spend time with kids in the absence of another adult, and to maintain overall responsibility for managing the details of their children’s lives.

In 2017, the Organization for Economic Cooperation and Development called the uneven distribution of unpaid labor between men and women in the home one of the most important gender-equality issues of our time. And the problem isn’t going away; it afflicts even relatively young parents. “Millennial Men Aren’t the Dads They Thought They’d Be,” read a 2015 New York Times headline. MenCare, a fatherhood campaign working toward child-care parity in 45 nations, estimates that at the current rate of change, it will be another 75 years before women achieve gender equality in the home —a more optimistic figure than the 200 years the United Nations International Labour Organization predicted in March, on the eve of International Women’s Day.

Reports of the modern, involved father have been greatly exaggerated. As the social psychologist Bernadette Park has put it, any change “is more in ‘the culture of fatherhood’ than in actual behavior.” The so-called marriage-between-equals discourse, ever present in certain corners of the country, bears little resemblance to what really goes on in the home. Even among couples who say they’ve achieved equal partnership, studies find that their mutual decisions tend to favor the needs and goals of the husband much more than the wife.

Still, many mothers, well schooled in the importance of sugar, spice, and everything nice, resist protest. They don’t give public voice to their sense of injustice. Instead, “when a dad comes” to a mommy-and-me class, “we clap,” reported Jay Miranda, a mother and blogger in Los Angeles.

Women’s gratitude is doubtless a result of the well-known, deeply felt fact that while domestic labor isn’t equal now, it was even less equal before. The 65/35 division is certainly better than the 80/20 women lived with in the 1970s and ’80s. One family-studies professor I spoke with told me that her mom is always telling her how lucky she is: “She’s comparing my husband to my father, who did nothing, but I’m comparing him to me, and I know I do way more!” Yet she said she “hit the jackpot” when she found her husband.

Men perpetuate the notion that women should keep in mind the extremely unequal past, or perhaps other people’s extremely unequal present, and not focus on their less unequal lived experience. Laura, a New York City business owner and mother of a 4-year-old, is married to her child’s father, but told me she feels like a single parent. When she tries to address the imbalance with her husband, his standard response is “I do a lot more than other men.” Laura doesn’t disagree. Further discussion is quashed. These conversations transform her vivid anger into lukewarm appreciation.

One Oklahoma City mother, a court bailiff, broke it down for me in the starkest terms: “He thinks he should bring home a paycheck and do nothing else, but it could be worse. He doesn’t beat me. He doesn’t drink excessively.” The possibility of an ever-lower bar only highlights how nonsensical such gratitude can be.

Although appreciation goes a long way in a marriage, that doesn’t make it a positive or even a neutral force if there’s a legitimate grievance. Misplaced gratitude, by supporting a couple’s unequal status quo, can help destroy rather than maintain a romantic relationship. Women who report that they do more child care than their husbands are 45 percent less likely to describe their marriages as “very happy” than women who say responsibilities are shared. Studies in the past decade in the United Kingdom, Sweden, and the United States have all found that couples with low levels of male-partner participation in domestic chores are more likely to separate than couples in which men do more.

Social psychologists commonly distinguish between “benevolent” and “hostile” sexism. Benevolent sexism flatters women while also undermining their ambition and autonomy. Hostile sexism devalues them altogether. One study out of Germany exposed women to either benevolently sexist statements (“Women have a way of caring for others that men are not capable of”) or to hostile ones (“When women work together they often get into catfights”). Later, the women who’d read the benevolent statements were significantly less likely than the others to say they would participate in social action to rectify gender discrimination.

Gratitude is a brand of benevolent sexism, a force that repels change. To offer thanks for whatever contributions men happen to make reinforces the implicit idea that parenting is women’s work, that 65/35 is a very fine place to stop. For too long, women have paid for this imbalance with their well-being—financially, emotionally, existentially. Only once gratitude is relinquished for righteous anger will gender rules in this realm be rewritten. Then we can land somewhere different: not grateful, only glad.           



When did college students get it into their head that they should be running the university? The distressing trend of students somehow thinking that they’re the teachers began in earnest in the 1960s, a time when at least some of the grievances of campus protesters—from racism and sexism to the possibility of being sent to die in Southeast Asia—made sense.

A more noxious version of this trend, however, is now in full swing, with students demanding a say in the hiring and firing of faculty whose views they merely happen not to like. This is a dangerous development—a triple threat to free speech, to the education of future citizens, and to the value of a college education.

It is no surprise to find Camille Paglia, a professor at Philadelphia’s University of the Arts who has been outraging people across the social and political spectrum for three decades, embroiled in one of these controversies. Paglia proposed to give a talk titled “Ambiguous Images: Sexual Duality and Sexual Multiplicity in Western Art.” According to a letter released by two student activists, “a gender non-binary creative writing major” had “brought this lecture to the student body’s attention through social media and raised their concerns to Title IX and other University administration about the school giving Camille a platform.” This led to a group of students demanding that Paglia (who self-identifies as transgender) be removed from the faculty “and replaced by a queer person of color.”

So far, they’ve failed, but Paglia’s survival in Philadelphia hasn’t deterred budding activists elsewhere from mistaking themselves for presidents and provosts. In Vermont, students at Middlebury College have threatened to disband their own student government if the school does not respond to a hodgepodge of demands ranging from greater student presence in the administration to the creation of a black-studies department. Many years ago, I taught at Dartmouth College and lived in Vermont just up the road from Middlebury; just 1.1 percent of the population of Vermont, the whitest state in the nation, and 1.9 percent of Middlebury’s is black. That might make recruiting faculty for a black-studies department a challenge for any institution in the region, but students also want a two-year plan to create an LGBTQ center, hire more counselors who are “femme, of color, and/or queer,” and “provide a more robust health service for transitioning people,” proposals that are likely to be especially expensive for a small institution in rural New England.

Meanwhile, a student group at Sarah Lawrence College that calls itself the Diaspora Coalition occupied some of the school’s offices—because of course they did—and demanded that the conservative professor Samuel Abrams, the author of an October New York Times op-ed criticizing diversity-related events at the school, have his tenure reviewed by a “panel of the Diaspora Coalition and at least three faculty members of color.”

This is inimical to the entire premise of tenure and academic freedom, but the students weren’t stopping there. They also demanded that “the College must issue a statement condemning the harm that Abrams has caused to the college community, specifically queer, Black, and female students, whilst apologizing for its refusal to protect marginalized students wounded by his op-ed and the ignorant dialogue that followed.” They demanded that Abrams issue “a public apology to the broader SLC community and cease to target Black people, queer people, and women.”

I am mildly impressed by any student group outside of the United Kingdom that tries to use whilst in a statement, but beyond that, this is the kind of demand that sounds like it could have come out of China during the Cultural Revolution—if Maoists had been as obsessed with race and sexuality as they were with class.

This is not activism so much as it is preening would-be totalitarianism. If college is to become something more than a collection of trade schools on one end and a group of overpriced coffeehouses on the other, Americans have to think about how we got here and how to restore some sanity to the crucial enterprise of higher education.

First, we have to recognize a shameless dereliction of duty among faculty and administrators. Student activism can be an important part of education, but it is in the nature of students, especially among the young, to take moral differences to their natural extreme, because it is often their first excursion into the territory of an examined and conscious belief system. Faculty, both as interlocutors and mentors, should pull students back from the precipice of moral purity and work with them to acquire the skills and values that not only imbue tolerance, but provide for the rational discussion of opposing, and even hateful, views.

Instead, in the name of respect and relevance, even tenured faculty sometimes quail before the anger of people barely out of high school. Paglia has always been a notable exception here, and it is encouraging to see Swarthmore College’s president, Valerie Smith, refusing to meet with student protesters unless they end their occupation of college offices. (The students want the fraternities disbanded, which happened; they want a promise from Swarthmore that they will never come back. They’re staging an occupation not over losing, but over not winning quite enough to suit them.)

Overall, unfortunately, the typical reaction to such events is to “hear” the students and to allow them to stomp on the very traditions of rational inquiry they’re supposed to be learning while in college.

To some extent, unbridled and performative student activism is a disease of affluence. Young people who are working their way through school or who are immersed in difficult subjects have less time, and often less economic flexibility, to engage in protest.

Indeed, students at Brown University noticed the time-consuming nature of changing the world, and in 2016 demanded less schoolwork so that they could devote more effort to their “social-justice responsibilities.” As one anonymous undergraduate told the Brown school newspaper, “There are people breaking down, dropping out of classes, and failing classes because of the activism work they are taking on.” A senior with the wonderfully appropriate name of Justice Gaines told the paper, “I don’t feel okay with seeing students go through hardships without helping and organizing to make things better.”

As I wrote in a book titled The Death of Expertise, much of this, at institutions both great and humble, proceeds from a shift in the late 20th century to a kind of therapeutic model of education, which prioritizes feelings and happiness over learning. Colleges take the temperature of their students constantly, asking if they feel fulfilled, if they like their courses, and if they have any complaints. Little wonder that the students have made the short and obvious jump to the conclusion that they should be in charge.

Indulgent parenting may play a crucial role here. In an era when celebrities and plutocrats will drop nearly a half million dollars to get their children into the University of Southern California—no offense intended, Trojans—it is easy to imagine that mom and dad are not going to insist on tough love and adult advice when their children call them to complain that their grades are suffering because they were skipping class while trying to get on their professor’s post-tenure firing squad.

Changing this culture will be hard, but it starts with the confident assertion by faculty that they are there for a reason and know what they are doing. Students must be reminded that they petitioned the institution for entry, and not the other way around; they asked the university to allow them to enter into a contract in which the professors are obligated to educate them and they are obligated to fulfill the requirements that will allow those professors to recommend them to the university for graduation.

This last point is especially important. The contract is not just a bill for client services from the university’s dutiful employees. It is a promise by the students to accept instruction, rather than to give it.

“Students have obligations to teachers,” the Georgetown University professor Father James Schall wrote in the late 1980s. “I know this sounds like strange doctrine, but let it stand.” What Schall—a magisterial teacher who became a friend as I passed through my graduate education—meant was that students could emerge as peers and educated citizens only by recognizing their own responsibilities in the transcendentally important pact between students and teachers.

Schall passed away recently, much to my great sadness. And I could not help but wonder if the traditions of a university where students are required to embrace the importance—and the joys—of rigor, tolerance, commitment, self-discipline, and courageous inquiry is being buried with him.

This article is part of “The Speech Wars,” a project supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press, and the Fetzer Institute.



Is there something racist in the way the chattering classes discuss the low number of black students admitted to New York City’s most selective public high schools?

The figures are depressing indeed. This year, only seven out of 895 admits to Stuyvesant were black, as opposed to 587 Asian and 194 white kids. Only 12 out of the 803 students admitted to the Bronx High School of Science were black, and only 95 out of 1,825 admitted to Brooklyn Tech. This is all in a city in which 26 percent of public-school students are black.

Since 1971, admission to the eight most selective public schools in the city has been based solely on performance on a single test, the Specialized High School Admissions Test, or SHSAT. The naive observer of the current circumstances—say, a foreigner new to the country or an inquisitive 10-year-old—might suppose that the main question would be how New York, its parents and teachers, can help black students do better on that test.

But no—New York City Mayor Bill de Blasio wants to scrap the test, and instead admit the top performers from all middle schools. New York City Council Speaker Corey Johnson agrees, advising that a task force develop a different way of evaluating students based on some kind of feedback from parents and assorted experts. Richard Carranza, the school-system chancellor, also wants to get rid of the test, and has claimed that Asian students somehow believe they “own” admission to the top public schools. Meanwhile, the journalistic establishment seems to assume that fixing the problem will require a massive social shift. The New York Times tartly summed up that either “1) the test is flawed and not accurately capturing the best and brightest students, or 2) the test is fair, and the schools that are preparing these children are bad.”

Either ax the test or overhaul the schools, in other words. But what about the more local and pragmatic solution of helping black kids do better on the test? This position isn’t nonexistent, but it’s considered contrarian, unexpected, or even plutocratic and backwards. The cosmetics heir Ronald Lauder and former Time Warner CEO Richard Parsons have argued that the city should keep the test while fostering more gifted programs and test prep for black and Latino students, only for de Blasio to describe such opinions as follows: “The billionaire class is going all out to keep the status quo, and deprive black and Hispanic kids of their shot at the city’s specialized high schools.”

What kind of charge is that to level at Parsons, a black man who grew up working-class? And in general, why does so much of the debate over these admissions discrepancies operate according to a tacit assumption, that to discuss black kids getting better at the tests is ticklish at best and piggish at worst? There are reasons, in themselves quite well-meaning, for this mannered approach to the problem, but they don’t hold up.

Most easily dismissed is the idea that standardized tests such as the SHSAT measure nothing that would be valuable in deciding whether a child is poised to do well in a highly competitive school. For example, if the test fails to catch a significant portion of what makes a top student, perhaps focusing on too narrow a skill set, then just what additional skills will the elimination or marginalization of the test bring in? “Spunk”? We must be precise. Plus, if white and Asian kids regularly do much better in the aggregate on this test than black kids, then clearly that test is measuring something that black kids are not measuring up to. On what grounds does the city decide that this something merits no attention? And honestly, who truly believes that this something has nothing whatsoever to do with being a high-achieving student?

I sense a background suspicion among some that black kids are just not up to acing such tests on some ineradicable level. What else explains why commentators on this issue are so focused on “access” over preparation? “We must strive to make sure that every student has access to the quality education they are entitled to,” said Johnson, the council speaker, as if black students’ performance on the test were beside the point and it were impossible to imagine it ever changing. In 2012, the mother of a black Stuyvesant student told The New York Times that a co-worker, also black, said: “The exam is built to exclude blacks because it’s heavy on math, and black people can’t do math.”

However, there are plenty of black people of different mind; Richard Parsons is not alone. Jumaane Williams, New York’s public advocate, is passionately devoted to the poor black community of the city, and he is also against getting rid of the test. Plus, the idea of black kids managing that test is no pie-in-the-sky abstraction: It was a reality back in the day. In 1975, 303 out of 2,536 students at Stuyvesant were black; in 1980, 212. Many New Yorkers (including me) recall it being hardly unusual for black students to attend the elite public schools until well into the 1990s.

The issue is not how New York can create something brand new, but how the city can make things the way they were.

Other arguments often brought up in relation to black kids and tests won’t work this time. Is black kids’ problem that their parents often work too long and hard to be available to help them with homework and exams when they get home? That isn’t a useful line of argument, as a great many of the nonblack students at schools such as Stuyvesant are not affluent scions of educated white parents on the Upper West Side, but children of hard-working, working-class immigrant parents of modest education themselves. Also, black kids’ parents worked quite hard in the 1970s and 1980s as well, when the admissions discrepancies were much less severe.

Also, the issue is not that the nonblack kids have access to expensive test preparation that is unavailable to the black ones. For several years, New York City has offered free test preparation to its students, some for low-income students, some for all. The problem has been that too many black families are unaware of the service or do not take advantage of it.

Or say the test isn’t the problem, exactly—it’s the schools, or the Times’ option 2: “The test is fair, and the schools that are preparing these children are bad.” Black kids are disproportionately saddled with substandard educations in New York City. That’s a fact. Leaving aside the number of immigrant kids admitted to the top schools despite the flaws in these ailing public schools, many suppose that until the system improves, places such as Stuyvesant have a civic responsibility to admit black kids with lower test scores than those allowed to other kids. The city, that is to say, must redefine excellence according to the performance levels possible in a system distorted by systemic racism.

But admitting students unquestionably less well-prepared than today’s cohort will compromise the overall quality of the schools. Some might consider that outcome just deserts for those favored in a society riven with inequality, and perhaps even as a constructive wake-up call to them. However, we must consider that this lowered quality would apply also to the black kids newly admitted under these lowered standards; the city would admit these students into elite schools no longer as rigorous as they once were. “Greater diversity in our schools is an imperative,” Parsons has argued, “but the battle cannot be won simply by lowering standards.”

Let us address, then, a question less easily dismissed than polite discussion trains us to suppose: How can we make black kids in New York better at the SHSAT?

One approach is to more effectively spread the word in New York’s black communities about the free test-preparation classes. Many immigrant kids take test-prep courses and practice tests. There is no evidence that doing this is impossible for a critical mass of black American students in New York. Notably, I am aware of no reports that black students did ample test prep and yet still failed to be admitted to any of New York’s eight selective public schools. Rather, we hear simply of the admissions disparities, and—as mentioned above— the fact that black families often do not know the test exists, or how to learn to prepare for it.

Second, rather than assuming that this problem will only be solved by something as elusive and even quixotic as overhauling as vast and troubled a public-school system as New York’s into one where every student gets a top-quality education anytime soon, we can focus on a narrower problem: the lack of gifted-and-talented classrooms for minority students. The “anti-tracking” movement in the early 1990s — born of the philosophy that mixing children of different abilities is more effective and equitable — led to the gradual elimination of these classrooms in heavily black public schools. Today, 10 New York districts where nine in 10 students are black or Latino have either one or no gifted-and-talented program in the public elementary schools.

The decline in gifted programs may well have something to do with the dearth of black students at elite high schools. And if talented black students were once again regularly tracked into these programs, more would likely qualify for schools such as Stuyvesant. In fact, in an interview with the Times, minority students now at Stuyvesant offered that prescription.

Finally, the city should sponsor community meetings where parents of nonblack students discuss what they did to ensure that their kids got into top public schools. Surely this advice could be useful, especially given that once again, so many of these parents are as hard-working, time-crunched, and modestly educated as many of the black parents are.

It is hardly inappropriate to explore the degree to which tests such as the SHSAT actually measure scholarly potential. However, to eliminate the test now would be to do so simply because black students were underperforming on it. Whatever the good intentions behind that move, it would be antithetical to civic harmony. Nonblack parents would be permanently furious that the achievement of their children was no longer affirmed in such a measurable and celebratory way. Meanwhile, it would leave black students vulnerable to racist attacks on their intelligence, in a way that no amount of euphemisms, taboos, and questions studiously unasked would prevent. We can do better than that.

Zora Neale Hurston had useful words on issues like these: “If I say a whole system must be upset for me to win, I am saying that I cannot sit in the game, and that safer rules must be made to give me a chance. I repudiate that. If others are in there, deal me a hand and let me see what I can make of it, even though I know some in there are dealing from the bottom and cheating like hell in other ways.”

We should yank the test only after we show that black students can handle it regardless of its flaws. We can handle imperfection just like everybody else and we can prove it—as long as we can sit down and get dealt in.



During El Salvador’s “dirty war” in the 1980s, which pitted leftist guerrillas against an entrenched alliance of generals and oligarchs, the army committed atrocity upon atrocity with impunity. In one of the worst massacres in modern Latin American history, in December 1981, soldiers from an American-trained battalion slaughtered nearly 1,000 peasants—women and old men and children, some too young to walk, average age 6—in El Mozote and the surrounding villages.

After a Sisyphean struggle, justice and accountability seemed within reach when in 2017 a judge began hearing evidence against 20 former high-ranking military officers, including the former minister of defense. But now a boulder of injustice is once again about to roll over the victims. The Salvadoran assembly is considering an amnesty for crimes committed during the civil war. It is called the National Reconciliation Law, but as readers of Orwell might have guessed, it is anything but.

“This is mocking the victims,” Amadeo Sanchez, who was 8 years old at the time of the massacre, said on Tuesday in front of the parliament, where he was with other El Mozote victims to protest the law. He had survived because he’d fled into the hills with his father before the soldiers arrived in his village, he told me in an interview last year after testifying in court. “They want to favor the ones who committed the crimes,” he said about the politicians, who are scheduled to vote on the law today.

When he came out of the hills and returned to his village, Sanchez told me, he found the bodies of his mother, siblings, and neighbors, including a woman who had been shot in the head. Next to her lay her one-day-old daughter. Her throat, he said, had been cut.

On the wall, he told me, the soldiers had scrawled in blood, Un nino muerto, un guerrillero menos: “One dead child is one less guerrilla.”

The proposed law would limit the crimes for which a former combatant can be convicted. But most radically, it would remove the possibility of jail time even for those convicted of a war crime or crime against humanity. The maximum sentence would be community service of three to 10 years. Even that figure would be reduced if the defendant is over 65 years old, a category that includes the former minister of defense, José Guillermo García.

But the charges against García, which include rape, kidnapping, and murder, would have to be dismissed anyway: Only the direct perpetrators of human-rights-abuse crimes can be prosecuted under the legislation, not those who may have ordered the killings, effectively negating the legal doctrine of command responsibility.

For good measure, lest there be any doubt that the proposed law is aimed primarily at stopping the El Mozote investigation, another provision requires that all trials be held in the capital, San Salvador. The El Mozote proceeding is being held in a small courtroom in San Francisco Gotera, a gritty agricultural town that is the capital of Morazan province, where the massacre occurred.

Just as the victims have been struggling for justice, the perpetrators of the atrocities, and their supporters, have been doggedly seeking to continue the immunity they have long enjoyed.

In 1993, within weeks of a peace accord that ended the 12-year civil war, the conservative Salvadoran assembly passed a sweeping amnesty. The El Mozote investigation, which was in its initial stages, was shut down. The amnesty law was upheld by the Salvadoran Supreme Court in 2000.

The victims took their case to the Inter-American Court for Human Rights, which found no dispute as to the facts. As part of a counterinsurgency scorched-earth policy, the court said, “the Armed Forces executed all of those persons it came across: elderly adults, men, women, boys and girls, they killed animals, destroyed and burned plantations, homes, and devastated everything community-related.”

So the victims went back to the Salvadoran Supreme Court. This time the court ruled the amnesty law invalid. In 2017, the judge in Gotera hauled the defendants into his courtroom and began taking testimony from survivors and relatives of murdered families.

The American ambassador in El Salvador, Jean Manes, has endorsed the trial. “The El Mozote case is an important, positive step for rule of law and ending impunity in El Salvador,” she wrote in a cable to Washington in 2017. But she saw what was coming: “a replacement of the Amnesty law which could impact the ability to prosecute the El Mozote case and others.”

The United Nations human-rights council has called on the Salvadoran assembly to reject the proposed law. And Fabian Salvioli, the United Nations special rapporteur on the promotion of truth, justice, reparation, and guarantees of nonrecurrence, said in a statement, “I express serious concern at this attempt to open the door for a de facto amnesty and eliminate the enforcement of criminal sanctions for severe human rights and humanitarian law violations and crimes against humanity.”

In an open letter to the Salvadoran legislators, the families of four American churchwomen raped and murdered by Salvadoran soldiers in December 1980 have also registered their opposition: “In the name of our beloved Maura Clarke, Ita Ford, Jean Donovan and Dorothy Kazel, we appeal to you to reject wholeheartedly the bill calling for a second General Amnesty.”

The letter goes on, “A General Amnesty, especially in the El Mozote case, would be another denial of the humanity of those who were killed so wantonly.”

If the amnesty law passes, the immunity will continue for those who killed so wantonly.



Elizabeth Warren has been talking a lot about small business, a constituency that hasn’t figured in Democratic Party politics in a long time. The senator from Massachusetts and Democratic presidential candidate has sparred with Amazon over how the tech giant treats the businesses that rely on its platform to sell their goods. She’s unveiled a plan to put small businesses on a more equal footing by closing tax loopholes that allow “the very largest companies to pay a lower effective corporate tax rate than smaller companies.” She’s pledged to reverse consolidation in the banking industry on the grounds that the decline of local banks has “made it more difficult for small businesses and farms to get loans.”

In her speeches, Warren has linked the hopes and fears of small businesses with those of a more familiar constituency of the left. It’s time, Warren has said on the campaign trail, “to put more economic power in the hands of the American people — workers and small businesses.”

To connect these two groups today is to confound our expectations about who belongs on which side. Americans have grown accustomed to seeing small businesses as supporters of the GOP. Since the 1970s, lobbyists backed mostly by big corporations have portrayed taxes, labor unions, and government regulation as the primary threats to the success of smaller enterprises. In reality, the interests of Main Street businesses and the largest corporations are often at odds, but Democrats have done little to discourage the latter from speaking for the former.

Warren is now advancing a different theory—that big corporations’ political influence and market dominance are killing smaller rivals, and that small-business owners share interests with other victims of corporate power. (Full disclosure: Warren’s team contacted my organization for input on policy proposals. We provided feedback, as we have for other candidates.) While other Democratic presidential hopefuls have questioned the power of the tech giants, Warren’s rhetorical embrace of small business has been emphatic. She is at once bidding for votes that Democrats don’t normally seek and inviting her party to see small businesses in a new light. She’s also reviving what once was a core tenet of her party: In a democracy, a primary purpose for government is to disperse economic power.

The past three Democratic presidents—Jimmy Carter, Bill Clinton, and Barack Obama—all oversaw and indeed welcomed periods of significant economic consolidation. But before then, from the 1930s until the 1970s, Democrats recognized the threat that monopolies and other corporate behemoths posed to workers and small-business owners alike.

In accepting renomination at the 1936 Democratic convention, President Franklin D. Roosevelt decried the concentration of economic power in the hands of “new dynasties” of “economic royalists.” “There was no place among this royalty for our many thousands of small-business men and merchants who sought to make a worthy use of the American system of initiative and profit,” Roosevelt declared. “They were no more free than the worker or the farmer.”

As Democrats of this era saw it, forming a union and starting a business were two avenues toward the same ends: checking corporate power and giving ordinary people economic agency and a fair share of the returns from their labor. The career of Senator James E. Murray was a case in point. Elected in 1934 with support from Montana’s miners and timber workers, Murray spent the next 26 years championing the twin causes of labor and small business. He blocked several bills that would have made it harder for workers to unionize. He also founded and led the Senate’s Special Committee to Study Problems of American Small Business. Through a remarkable series of reports, his committee detailed how the same monopolistic corporations that menaced the rights of workers were also using their market power against their smaller competitors.

Another leading Democrat of the period was Estes Kefauver, who served in Congress from 1939 until 1963. The son of a Tennessee hardware-store owner, he was a lifelong supporter of organized labor and a fierce opponent of concentrated economic power. During a live address on ABC in 1956, Kefauver denounced President Dwight Eisenhower’s support of a bill to limit the ability of workers to strike. “It is easy to see what happens when an administration favors big business over the working man,” he said. He then turned to the plight of the nation’s independent enterprises. “Small businesses are not getting protection against the onrush of monopolistic big entrepreneurs,” Kefauver declared. His signature legislative achievement was the Celler–Kefauver Act, which vastly expanded the government’s authority to review and block mergers.

For more than four decades, Democrats governed from this vantage point. They sustained majorities in both the House and the Senate for nearly all of those years.

But then, in the 1970s, the party underwent an ideological shift. A group of young, newly elected lawmakers spurned economic populism and dismissed concerns about the power of big business as old-fashioned. This new bloc used its growing majority in Congress to marginalize the party’s long-standing anti-monopolists. It helped elect Carter, who, beginning with the airline and trucking industries, dismantled regulations that had previously constrained big business. Ronald Reagan continued this project in sweeping fashion. His Justice Department reinterpreted the nation’s antitrust laws in a way that all but gutted them.

Clinton went further still. In 1992, the Democratic Party scrubbed all references to economic concentration and antitrust from its platform. Clinton then led a successful, multiyear effort to overturn the Depression-era laws that had constrained the size and reach of banks. Obama followed in the same vein, presiding over a period of extreme consolidation that saw aggressive new forms of monopoly power emerge, uninhibited, from Silicon Valley and Seattle. While Democrats still evoke the image of small business in political speeches, it’s not a serious focus of the party’s policy making.

Meanwhile, small businesses have seen their numbers and market share plummet in one industry after another. From 2005 to 2015, the number of independent retailers fell by 85,000 and small manufacturers by 35,000. Local pharmacies, community banks, family dairy farms, and independent grocers have all been in decline. Meanwhile, starting a business has become much harder. The number of new firms launched each year has fallen by nearly two-thirds since 1980.

These trends are often dismissed as proof that larger corporations are simply better and more efficient than smaller ones, but the evidence suggests otherwise. Take local pharmacies. As they shutter their doors, we assume that they just can’t compete with national chains. But according to studies by Consumer Reports and by my organization, local pharmacies provide lower drug prices and better care. The problem is that their reimbursement rates are set by three dominant pharmacy-benefit managers, all of which also run their own competing pharmacies. Last year in Ohio, the largest of these, CVS Health, further slashed the rates it pays local pharmacies and then sent many of them letters offering to buy their struggling stores.

This kind of predatory behavior is widespread. It can be found in the hefty swipe fees Visa and Mastercard impose on independent retailers that have no alternative but to pay up, and in the loss of shelf space that local breweries face when Anheuser-Busch InBev buys or bribes their distributors. Over the past few years, I’ve talked to hundreds of small-business owners about the challenges they face. Most describe dynamics in their industry that are largely about the exercise of unconstrained market power. In 2016, my organization surveyed more than 3,000 independent businesses. By a 61 percent to 7 percent margin, they said the federal government “should more vigorously enforce antitrust laws.”

Right now, though, neither party speaks to these fears and frustrations. It’s not only that Republicans and Democrats alike are corrupted by corporate dollars and lobbyists. Both parties are ideologically captured by the very idea of bigness itself. As a result, efforts by groups such as the U.S. Chamber of Commerce to blame government—rather than monopoly power—for the troubles of small business go largely unchallenged.

While reliable data on the actual voting habits of small-business owners are hard to come by, surveys suggest that they’re only loosely attached to either party and that, like other Americans, many identify as independents. What might happen if the Democratic Party offered a different story to explain what’s happening to America’s small businesses—a story that speaks to the common cause that entrepreneurs and workers share in breaking the grip of dominant corporations?

For many voters, the idea of independent business evokes something they desperately want: the freedom, as Kefauver put it, to govern their own fate, subject to no master. Warren’s focus on small business is more than an appeal to a constituency that lacks a political home. It’s also a kind of shorthand for Americans’ deep-rooted desire to govern ourselves.



I’m an economist. I love data and evidence. I love them so much that I write books about data-based parenting. When questions arise about how to support parents at work (for example, from Alexandria Ocasio-Cortez on Twitter), my first impulse is to endorse paid parental leave. Mountains of data and evidence show that paid leave is good for children’s health, and for mothers in particular. I am more than comfortable making a data-based case for this policy.

But experience, rather than pure data, leads me to believe that what happens after paid leave is nearly as crucial—that is to say, what happens when Mom and Dad return to the office. We need to normalize the experience of parenting while working.    

For the past few weeks, I’ve been talking with parents—mostly women—about all aspects of life with little kids. (My new book, Cribsheet, focuses on using data to make parenting decisions.) One thing I heard much more than I would have liked, and more than I would have expected, was that parents feel the need to hide or minimize the evidence of their children at the office.

I should be clear that most of the parents I spoke with had good—enviable, lengthy, gender-neutral—leave policies. The issues they encountered were more subtle, more nebulous, more about climate.

Women told me that they hid their pregnancies until well into the third trimester, wearing loose-fitting clothes to avoid telling their bosses or venture-capital funders that they were expecting. Once they had kids, some told me they simply never discussed them. If they had to deal with a child-related issue, they lied about why they were leaving work.  

One woman told me she worked on a team of men, all of whom were fathers. Pregnant with her first child, she noted that none of the men ever talked about their children, and she assumed she shouldn’t either.

The general sense is that everyone should adopt the polite fiction that after the first several months of leave, the child disappears into a void from which he or she emerges for viewing and discussing only during nonworking hours.  

Reinforcing this point, women professors at my university told me that when they were more junior, they made it a point never to put pictures of their children up in their offices.

These are, however, mostly anecdotes. And I often argue in my writing that anecdotes are not enough. Thankfully at least some research exists on what you might call “secret parenting,” even if much of it is more qualitative than strictly data-based. One example is a 2014 paper in Gender, Work & Organization based on interviews with 26 mothers of small children.

The women returned again and again to the issue of secrecy: “Hiding being a mother and engaging in strategies for secrecy were ubiquitous themes in our interviews,” the authors wrote. “Many women who had gone back to work tried to conceal that they had small children or pretended that their children’s interests were of little importance to them.”  

Why would people do this? Why pretend kids are of “little importance”? When work and parenting seem at odds—because our culture tells us they’re at odds—mothers and fathers feel forced to demonstrate their commitment to one (the work side) by minimizing their concern for the other (the parenting side). They do not want their bosses to think they are anything other than 100 percent committed.  

To draw from personal experience: I was an untenured assistant professor when I had my first child, and I went back to the office for my first meeting when she was just a couple of weeks old. Yes, I did that in part because I wanted to get out of the house and see other adults. But I was also worried that if I didn’t get back to the office fast and show my face, my senior colleagues would assume I wasn’t planning to take my job seriously going forward.

Hiding your kids at work is no easy task. Even if you skip baseball games and school plays and parent-teacher conferences, your kids will sometimes get sick. Child care will fall through on occasion. Some of the women in that paper I cited above reported that they had feigned illness when their child got sick, because taking a sick day for themselves seemed acceptable, but taking one to nurse a child did not.

These pressures aren’t just bad for parents; they’re bad for employers. Inflexibility around child care is, quite simply, going to cost firms valuable workers. Most of the women in that study left the labor force. Other research has found that “the presence of children” is a main driver of the gender gap in career outcomes, even for highly educated workers, because women drop out when their employer can’t accommodate their schedule.

If a workplace doesn’t offer paid parental leave, the solution, though possibly difficult to achieve on a political level, is obvious: paid parental leave. The climate issues that lead to secret parenting are more nebulous, and thus seem more difficult to fix. But perhaps the answer is just as clear. Fight the culture that encourages secret parenting by … not parenting secretly. Eventually, your colleagues will adapt.

This change cannot come from the lowest rungs of the organization. More senior employees must take the lead. Two kids in, I’m now a tenured full professor. I am on the other side, so to speak. But my kids are still young—4 and 8—and I value seeing them every day for dinner; I do not like to travel much. Not too long ago, I would have explained away my time constraints with other obligations or been vague about them.

But I try consciously not to do that now. I tell people, “I’m sorry, I do not do meetings after 5 p.m., because of my children.” Or even, “Sorry, but today I’m leaving at 3:30 because I’ve been traveling a lot and I promised my kids I’d come home early to make cookies.” And I particularly try to say things like that around more junior colleagues, those who might wonder whether it is okay for them to have these constraints. I have pictures of my kids up everywhere, and right now I’m looking at a child’s mitten, which has been sitting on my desk since sometime in December. One glance around my office, and you’d know I’m a parent.

Nor can women, even senior women, change the tenor of their workplaces alone. Men have to do it also. Parenting is not a mom-only activity. Men also want to see their kids, to be there for dinner, for bedtime.

Once parents start acknowledging their child-care obligations openly, the need for specific changes may become apparent. For example, little kids go to sleep early. The hours between, say, 5 p.m. and 8 p.m. are really central for parents. What if they spoke up about that more? Employers might then see the benefit of making clear to parents that they needn’t fulfill their work obligations within the confines of a traditional day. Many of us would be happy to log on before our kids are up or after they are in bed. For me, a phone call at 8:15 p.m. is infinitely better than a meeting at 6 p.m. Openness about, say, sickness would also force employers to confront that even the best-laid child-care plans break down. Parents should have the flexibility to (occasionally) have a kid in their office or, better yet, be given access to emergency child care.

Put simply, mothers and fathers ought to come clean about the nature of their lives. We can’t fix problems that we pretend don’t exist; we can’t improve the lot of parents at work if we pretend we aren’t parents.



Updated at 11:42 a.m. ET on May 22, 2019.

With ideas like Medicare for All and the Green New Deal, the 2020 Democratic presidential contenders are challenging the ideological parameters that have defined American domestic policy since the Reagan era. If only they were doing so on foreign policy too.

Consider their responses to President Donald Trump’s recent escalation with Iran. Yes, one Democrat after another has called on Congress to prevent Trump from going to war. But Democrats have not frontally challenged the core assumption underlying Trump’s belligerence: that Iran is a uniquely malevolent actor in the Middle East.

Even as he criticized Trump’s recent actions, Representative Seth Moulton last week called Iran “a major threat to our national security.” In a statement emailed by her staff, Senator Kirsten Gillibrand condemned its “malign activities.” Senator Cory Booker has in the past insisted that the United States “be more vigilant than ever in fighting Iranian aggression.”

By echoing the GOP’s confrontational language, these Democrats are forgetting a crucial lesson of the Iraq War. America didn’t invade Baghdad only because people such as John Bolton, then undersecretary of state for arms control, misrepresented intelligence on weapons of mass destruction. America invaded because, under both Bill Clinton and George W. Bush, Democrats and Republicans so inflated the threat from Saddam Hussein that restoring normal economic and diplomatic relations with his regime became politically impossible. The result was a web of sanctions that no administration could lift, and a glide path to war.

Ever since the 1979 Iran hostage crisis, Americans have held an understandably negative view of the Iranian regime, a public perception that makes it easy for Trump, Bolton, and Secretary of State Mike Pompeo to describe it as the root of virtually all of the Middle East’s ills. But, in truth, Iran today is no more aggressive and malign than its key regional competitor, and America’s ally, Saudi Arabia.

Compare the two governments’ behavior across a host of domains. First, military spending. In 2017, according to the International Crisis Group, Riyadh spent roughly four times as much on defense as did Tehran. That’s nothing new. According to the Stockholm International Peace Research Institute, Iran hasn’t spent more than 3.3 percent of its GDP on defense in any year since 1989. During that period, the Saudis have spent at least 7 percent every single year. Saudi weaponry is also far better. According to a 2015 report by the Center for Strategic and International Studies, Riyadh and its Gulf allies “have acquired and are acquiring some of the most advanced and effective weapons in the world,” while “Iran has essentially been forced to live in the past, often relying on systems originally delivered at the time of the Shah, or lower grade imports, many of which reflect the technologies of the 1960s to 1980s.” Factor in Israel—the Middle East’s preeminent military power—as another counterweight to Iran, and the claim that Tehran threatens to dominate the Middle East becomes even more absurd.

A second supposed example of Iran’s uniquely aggressive behavior is its intervention in Syria. But here, again, Tehran’s behavior is no more aggressive than Riyadh’s.

The key to understanding Iran’s involvement in Syria is the Iraq-Iran War. In 1980, Saddam invaded Iran in what became one of the longest and bloodiest conflicts of the late 20th century. Roughly 1 million Iranians died. And although Saddam was clearly the aggressor, and even after he used chemical weapons, almost every major Arab country—plus the United States—backed him.

Only one Arab government took Iran’s side: Syria. It has remained Iran’s lone consistent regional ally ever since. It’s not surprising, therefore, that when protests broke out against Syrian President Bashar al-Assad’s government in 2011, Iran feared his replacement by either pro-American forces committed to regime change in Tehran or Sunni Islamists virulently hostile to Iran’s brand of Shia Islam. Like Turkey, Iran also feared if Syria’s Kurds seceded, that might embolden Kurdish separatists in their country.

None of this justifies Iran’s complicity in Assad’s murderous repression. But in Syria, Iran isn’t promoting revolution. It’s defending a brutal status quo, just as Riyadh did when it sent troops to repress protests by Bahrain’s Shia majority in 2011, or when it backed Egyptian General Abdel Fattah el-Sisi’s bloody crackdown on supporters of the Muslim Brotherhood following his 2014 coup. In Syria, it’s not the Iranians who have been promoting regime change. It’s Saudi Arabia and its Gulf allies, which have backed a host of anti-Assad rebel groups, including some linked to Jabhat al-Nusra, al-Qaeda’s local affiliate.

The third example of Iran’s supposedly destabilizing behavior is Yemen, where it has given aid and training to Houthi rebels who now control the western part of the country. But there, too, Iran is engaged in the same kind of realpolitik practiced by America’s friends. In Syria, the Saudis have tried to overthrow Iran’s ally. In Yemen, where the Houthis overthrew a Saudi ally, former President Abdrabbuh Mansur Hadi, Iran is returning the favor. Iran sees Yemen as the Saudis’ Vietnam, and as the CIA veteran Paul Pillar has explained, it’s happy to see its regional foe “bleed.”

Moreover, as the Vietnam analogy suggests, the outside power that’s wreaking the most havoc in Yemen isn’t Tehran. It’s Riyadh, which, along with the United Arab Emirates, has blockaded Yemen’s ports and bombed its people, and thus fueled the worst humanitarian crisis in the world.

The final charge against Iran is that it ranks, in the Trump administration’s oft-repeated phrase, as “the leading state sponsor of terror.” Iran certainly supports terrorist groups, including Hezbollah, Palestinian Islamic Jihad, and Hamas (which has also received backing from U.S. allies such as Qatar and Turkey). And it likely played a role in Hezbollah’s attack on the American embassy in Beirut in 1983 and an apartment complex housing U.S. Air Force personnel in Saudi Arabia in 1996.

But the problem with suggesting that Iran is uniquely supportive of terrorism is that, in recent decades, Sunni jihadist groups such as ISIS and al-Qaeda have killed far more American civilians. And those groups have received the bulk of their state support not from Iran but from Sunni-led regimes—particularly Saudi Arabia and other monarchies in the Gulf. In 2016, Americans learned that a long-classified section of the Congressional Joint Inquiry into the 9/11 attacks alleged that, “while in the United States, some of the September 11 hijackers were in contact with, and received support or assistance from, individuals who may be connected to the Saudi Government.”* Earlier this year, CNN reported that Saudi Arabia and the UAE have transferred American-made weapons to al-Qaeda fighters in Yemen.

Saudi and Emirati misdeeds don’t excuse Iran’s. But they underscore the problem with calling Iran reckless, revolutionary, imperial, or destabilizing without describing its American-backed rivals in the same way. In contrast to Trump, Bolton, and Pompeo, security professionals generally describe Iran’s foreign policy as opportunistic but cautious. A 2014 Pentagon report argued that “Iran’s military doctrine is defensive.” In 2012, the chairman of the Joint Chiefs of Staff, Martin Dempsey, called the Iranian regime a “rational actor,” an assessment echoed by Benny Gantz, then head of the Israel Defense Forces, and the former Israeli spy chief Meir Dagan.

The Democrats running for president need to say this too. They need to say it because only by challenging the Trump administration’s description of Iran as singularly irrational and menacing can Democrats justify the normalization of relations with Tehran. And without such a normalization, the prospect of war, which flared this week, will return again and again.

By calling out Iranian aggression while ruling out war, Democrats may believe they’re splitting the difference. But if they can’t describe Iran as a normal regional power jockeying with equally sharp-elbowed foes, they can’t effectively challenge the sanctions the Trump administration keeps piling on the Islamic Republic. Over time, permanent sanctions can become a formula for military conflict.

This is a key, if underappreciated, lesson of Iraq. In the 1990s, sanctions on that country devastated the Iraqi people but, as the academic research on sanctions would have predicted, they actually helped Saddam entrench his rule. Over time, as usually happens, their enforcement also began to fray. And because rapprochement with Saddam was unthinkable, the fear that his regime might eventually escape sanctions led Bill Clinton to make regime change official U.S. policy in 1998. Clinton never contemplated an all-out invasion. But the impossibility of normalization—because of the bipartisan exaggeration of the threat Saddam posed—put the U.S. and Iraq on a path to war.

That’s what the Trump administration is doing now with Iran. It hasn’t just reimposed the economic sanctions that Obama lifted. It has toughened them and imposed conditions—which include Tehran’s withdrawal from every major country in which it is competing with Riyadh—that Iran can never meet. As in Iraq, those sanctions will cause many innocent people to die. Petrified of provoking America’s wrath, foreign businesses and banks are already refusing to facilitate the sale to Iran of lifesaving medicines. But as in Iraq, the sanctions will likely fail to topple the regime. “As I witnessed during the last round of sanctions,” wrote The Washington Post’s Jason Rezaian last year, after emerging from an Iranian prison, “when people are squeezed economically, their needs and aspirations become much more about survival than about working toward change.”

Worse still, by denying Iran any of the economic benefits it was promised in the nuclear deal, the Trump administration is goading it into restarting its nuclear program, which could provide the U.S. and Israel a pretext to strike. By trying to ensure that Iran cannot export a single barrel of oil, and relying on Saudi Arabia and other Gulf countries to meet global demand, the Trump administration is goading Tehran into interfering with their exports. And last month the Trump administration designated Iran’s Revolutionary Guards Corps a terrorist organization, even after U.S. military officials warned that doing so increased the prospect of Iranian retaliation.

That’s the crucial context behind last week’s war scare: The Trump administration was responding to a provocation it helped create. As the former Bush administration national-security official Kori Schake told The New York Times, “Every single European government believes that the increased threat we’re seeing from Iran now is a reaction to the United States … They believe that the U.S. is the provocateur and they worry that the U.S. is reacting so stridently to predictable Iranian actions in order to provide a pretext for a U.S. attack on Iran.”

It’s not enough for the Democratic presidential candidates to resist this latest brush with war. It’s not even good enough for them to pledge to return to the Iran nuclear deal, because the deal won’t survive unless Iran is reintegrated into the world economy and receives the sanctions relief it was promised. Unless Democrats challenge the notion that Iran is uniquely malevolent, they won’t be able to call for a normalization of relations with the United States. And unless Democrats call for a normalization of relations, a hot war will remain an ever-present danger.

On domestic policy, Democrats have realized that some of America’s biggest problems can’t be solved unless they leave old ideological limitations behind. That’s true for foreign policy too.

* This article originally misidentified the source of a report about the 9/11 attacks.  



Joe Biden is much more popular among voters than the left’s intelligentsia anticipated, with staggering leads in every poll of Democratic presidential candidates. Why did so many journalists and Twitter pundits fail to foresee his success?

One reason, Jonathan Chait argues, is that the social democrats who support Bernie Sanders and Alexandria Ocasio-Cortez, and the conservatives who find them useful villains, shared an incentive to overstate the influence of leftists among Democrats and to understate the relative strength of moderates.

Writing on the same question, Michelle Goldberg declared, “Left-wing Twitter isn’t a microcosm of the Democratic Party. It’s just a small, noisy fraction of it.”

During a discussion I joined on Left, Right & Center, the Daily Beast columnist Keli Goff suggested another possibility. She shared that her African American family members are more enthusiastic about Biden’s candidacy than she would have guessed.

She theorized that their support wasn’t issue-based.

“To succeed in primarily nonblack spaces––you only do it when you have really good allies,” she declared. “And I think that one of the things Biden gets credit for, rightly or wrongly, is this idea of being the blue-collar white guy who helped give Obama legitimacy with some of the blue-collar, white, male voters who voted for Obama-Biden and then crossed over for Donald Trump. I think African Americans give credit for that. Especially when the Obama campaign was really struggling, not always fairly, with some of these race-baiting attacks, sending Biden out on the campaign trail to fight some of those fights made a difference.”

To those plausible factors I’d add a few theories of my own (note that they do not reflect any judgment on my part that Biden is, or is not, the most electable Democrat):

The 2020 presidential election will be just the second one in the current social-media landscape. “It is hard to exaggerate the degree to which the platform shapes the minds of professional political observers,” Chait says. “Part of Twitter’s allure to insiders is that it creates a simulacrum of the real world, complete with candidates, activists, and pundits all responding to events in real time. Because Twitter superficially resembles the outside world’s political debate—it does, after all, contain the full left-to-right spectrum—it is easy to mistake it for the real thing. But the ersatz polity of Twitter doesn’t represent the real world.”

To adequately serve its civic function, the American press has to do a better job of guarding against the distorting effects that the platform has on its coverage. Failures to foresee Biden’s popularity are, in that context, a cautionary tale.



I spent the week after the release of Special Counsel Robert Mueller’s report going through it section by section and writing a kind of diary of the endeavor. My goal was less to summarize the report than to force myself to think about each factual, legal, and analytical portion of Mueller’s discussion, which covers a huge amount of ground.

Here are five conclusions I drew from the exercise:

The president committed crimes.

There is no way around it. Attorney General William Barr’s efforts to clear President Donald Trump, both in his original letter and in his press conference the morning of the report’s release, are wholly unconvincing when you actually spend time with the document itself.

Mueller does not accuse the president of crimes. He doesn’t have to. But the facts he recounts describe criminal behavior. They describe criminal behavior even if we allow the president’s—and the attorney general’s—argument that facially valid exercises of presidential authority cannot be obstructions of justice. They do this because they describe obstructive activity that does not involve facially valid exercises of presidential power at all.

Consider only two examples. The first is the particularly ugly section concerning Trump’s efforts to get then–Attorney General Jeff Sessions to “unrecuse.”

The alleged facts are simple enough. According to Mueller, the president asked Corey Lewandowski to convey a message to Sessions. It was a request that Sessions reassert control over the special counsel’s investigation, make a speech in which he would declare that the president didn’t do anything wrong and that the special counsel’s investigation of him was “very unfair,” and restrict the special counsel’s investigation to interference in future elections. Lewandowski asked a White House staffer to deliver the message in his place; the staffer in question never did so.

A few factors are important to highlight here, all of them aggravating. Lewandowski was not a government employee, so this was not an example of the president exercising his powers to manage the executive branch. Indeed, Trump very specifically did not go through the hierarchy of the executive branch. He tried to get a private citizen to lobby the attorney general on his behalf for substantive outcomes to an investigation in which he had the deepest of personal interests. What’s more, the step he asked Lewandowski to press Sessions to take was frankly unethical. Sessions recused himself from the Russia probe because he had an actual conflict of interest in the matter. In other words, the president of the United States recruited a private citizen to procure from the attorney general of the United States behavior the attorney general was ethically barred from undertaking.

But it gets worse, because Trump did not merely seek to get Sessions to involve himself in a matter from which he was recused. Trump wanted Sessions both to limit the scope of the investigation and to declare its outcome on the merits with respect to Trump himself. This action would have quite literally and directly obstructed justice. Limiting the jurisdiction of the special counsel to future elections would have, after all, precluded the indictments Mueller later issued for Russia’s hacking and social-media operations. It would have precluded the prosecutions of Paul Manafort, Michael Cohen, Mike Flynn, George Papadopoulos, and Rick Gates, as well. Nor is there any real complexity here with respect to Trump’s intent. As Mueller reports, “Substantial evidence indicates that the President’s effort to have Sessions limit the scope of the Special Counsel’s investigation to future election interference was intended to prevent further investigative scrutiny of the President’s and his campaign’s conduct.”

As a criminal matter, this fact pattern seems to me uncomplicated: If true and provable beyond a reasonable doubt, it is unlawful obstruction of justice. Full stop.

Another example: Mueller reports that after the news broke that Trump had sought to get then–White House Counsel Don McGahn to fire the special counsel, Trump sought to get McGahn to deny the story. He also sought to get him to create an internal record denying the story. McGahn refused.

The attempt to get McGahn to write an internal memo disputing the story is the crucial fact here. The president’s conduct might otherwise be defended as a mere effort to lie to the press, but one doesn’t order the creation of false internal documents for purposes of denying a published story. So the question is, first, whether what Mueller described as Trump’s “repeated efforts to get McGahn to create a record denying that the President had directed him to remove the Special Counsel” would have “the natural tendency to constrain McGahn from testifying truthfully or to undermine his credibility” if he told the truth. The second question is whether such a corrupt outcome was specifically intended by the president.

Mueller acknowledges that there is “some evidence” that the president simply thought the story was wrong and was proceeding on his memory. But Mueller is pretty clear that the weight of evidence “cuts against that understanding,” though—as always—he stops short of making that judgment explicit. Mueller previously concluded that McGahn’s underlying story was amply supported by the evidence, while it’s hard to believe the president would simply have forgotten an effort to fire Mueller. As to the president’s intent, Mueller is pretty unabashed: “Substantial evidence indicates that in repeatedly urging McGahn to dispute that he was ordered to have the Special Counsel terminated, the President acted for the purpose of influencing McGahn’s account in order to deflect or prevent scrutiny of the President’s conduct toward the investigation.”

Assuming that one believes this could be proved beyond a reasonable doubt, imagining this fact pattern as a count in an indictment is not difficult. It is hard to imagine a plausible defense based on the idea that pressuring an employee to create false government records by way of influencing his ability to tell the truth is within the president’s constitutional authority.

If one accepts, as I do, Mueller’s general reading of the obstruction statutes as applied to official presidential action, there are many more examples. When Trump leaves office, assuming statutes of limitations have not yet run out, someone will have to make the binary assessment, which Mueller did not make, of whether they amount to prosecutable cases. As a historical matter, the report leaves me with little doubt that the president engaged in criminal obstruction of justice on a number of occasions.

The president also committed impeachable offenses. 

Crimes and impeachable offenses are not the same thing, though they are overlapping categories. Some of the most obviously impeachable offenses described in the Mueller report are likely criminal as well. Some may not be. If I were a member of Congress, I would be thinking about which portions of the report describe, in my opinion, the most unacceptable abuses of power. A few stand out to me.

The first is the circumstances of, and run-up to, the firing of former FBI Director James Comey. While this fact pattern is complicated for criminal purposes, as a matter of impeachment, it’s very simple indeed. The president of the United States, seven days after taking office, demanded loyalty from his FBI director. Shortly thereafter, he isolated Comey in order to ask that he drop a sensitive FBI investigation in which Trump had a personal interest. The president then leaned on Comey to make public statements about his own status in the investigation. And when he couldn’t get Comey to do so, he recruited the deputy attorney general to create a pretext for Comey’s removal.

While there may be viable technical defenses against a criminal charge here, there simply is no plausible way to understand this fact pattern as a good-faith exercise of presidential power. It describes a frank abuse of power: a sustained demand for a wholly self-interested investigative outcome; a willingness to disrupt a crucial institution to get that outcome, to retaliate against an official who would not deliver it, and to set the entire apparatus of the White House to lying about the reason for the action; and the recruitment of senior Justice Department officials to create a pretextual paper trail to support it. I believed this was impeachable conduct at the time. The Mueller report reinforces that belief.

Ditto the effort to get Sessions to investigate Hillary Clinton. Mueller does not disentangle this effort from the attempt to get Sessions to reassert control of the Russia investigation. Let’s do so here: Even as he was trying to get Sessions to protect him from the FBI, Trump was also trying to induce Sessions to investigate his political opponents.

This is not obstruction of justice in any criminal sense. It’s rather the opposite of obstruction of justice; it’s the initiation of injustice. So I don’t think it’s plausibly sound in terms of criminal law. But it is molten-core impeachment territory. Consider: The president of the United States was trying to induce the attorney general of the United States to initiate a criminal investigation based on no known criminal predicate against a private citizen whom he happened to dislike. This was not rhetorical. It was not a joke. And if it is not unacceptable to Congress, then no member of Congress can say he or she was not warned when some future attorney general complies with a presidential request to launch an investigation against such a member of Congress.

A third example is the president’s public dance with Paul Manafort, in which he dangled the possibility of a pardon and praised Manafort’s bravery for not “flipping,” and in which his private counsel allegedly suggested that Manafort would be taken care of. Notably, Trump got what he wanted in this case. Manafort did not end up cooperating to Mueller’s satisfaction. Indeed, Mueller concluded that Manafort had breached his plea deal by failing to cooperate and by lying to investigators. So the reality here may well be that the president’s obstructive conduct did, in fact, obstruct the investigation. The president hinted that Manafort should not “flip” and that he would take care of him—and Manafort acted in a fashion consistent with his relying on those assurances. I think this activity, assuming it can be proved, is criminal.

It is also a grotesque abuse of power for impeachment purposes. The spectacle of the president of the United States publicly and repeatedly urging witnesses not to cooperate with federal law enforcement and entertaining the notion of using his Article II powers to relieve them of criminal jeopardy or consequences if they do not cooperate is one of the most singular abuses of the entire Trump presidency. Again, one has to ask of Congress what is unacceptable in a president’s interaction with an investigation if this conduct is tolerable?

In short, the question of the prudential wisdom of impeachment politically may be a hard one for members of Congress, but the impeachability of the conduct described by Mueller is not a close call. This is heartland impeachment material—the sort of conduct the impeachment clauses were written to address.

Trump was not complicit in the Russian social-media conspiracy.

Separating the wheat from the chaff is important, so let’s do so. While Trump has a great deal to answer for, Mueller unambiguously clears him—clears in the true sense of the word—of involvement in Russian efforts to interfere in the U.S. election by means of the Internet Research Agency’s social-media campaign.

Yes, the IRA duped some Trump campaign figures into promoting the group’s material, but none of those Trump campaign figures appears to have done so deliberately. Mueller’s statement that the “investigation did not identify evidence that any U.S. persons knowingly and intentionally coordinated with the IRA’s interference operations” is a stronger one than the language he uses elsewhere to indicate that evidence is insufficient to prove something. Here he actually seems to be saying that the investigation did not produce evidence at all of knowing participation in the Russian scheme by U.S. persons. We should take that at face value.

The story the report tells is disturbing on its own terms, however. It is a story of failed immunity on the U.S. side to outside interference—and aggressive Russian exploitation of the absence of democratic antibodies to fight off such manipulation. The IRA was able to reach tens of millions of U.S. persons using its social-media accounts. It was able to trick prominent people into engaging with and promoting its dummy accounts. It was able to exploit social-media companies. And it was able to make a series of contacts with Trump campaign affiliates and to get those figures—plus Trump himself—to engage with and promote social-media content that was part of a hostile power’s covert efforts to influence the American electorate. Though not intentional or criminal on the U.S. side, this pattern shows a troubling degree of vulnerability on the part of the U.S. political system to outside influence campaigns.

The solution to this problem is not obvious. The social-media companies obviously have a role to play in better policing their platforms. But some of the solution has to come from individuals, particularly prominent individuals, who need to take more care about sharing on social media any content of uncertain provenance. That obviously includes the president and his family members and campaign staff. But the problem here is far broader than Trump. And the solution needs to be as well.

Trump’s complicity in the Russian hacking operation and his campaign’s contacts with the Russians present a more complicated picture.

No, Mueller does not appear to have developed evidence that anyone associated with the Trump campaign was involved in the hacking operation itself. And no, the investigation did not find a criminal conspiracy in the veritable blizzard of contacts between Trumpworld and the Russians. But this is an ugly story for Trump.

Here’s the key point: If there wasn’t collusion on the hacking, it sure wasn’t for lack of trying. Indeed, the Mueller report makes clear that Trump personally ordered an attempt to obtain Hillary Clinton’s emails; and people associated with the campaign pursued this believing they were dealing with Russian hackers. Trump also personally engaged in discussions about coordinating public-relations strategy around WikiLeaks releases of hacked emails. At least one person associated with the campaign was in touch directly with the Guccifer 2.0 persona—which is to say with Russian military intelligence. And Donald Trump Jr. was directly in touch with WikiLeaks—from whom he obtained a password to a hacked database. There are reasons none of these incidents amount to crimes—good reasons, in my view, in most cases, viable judgment calls in others. But the picture it all paints of the president’s conduct is anything but exonerating.

Call it Keystone Kollusion.

On July 27, 2016, Trump in a speech publicly called for Russia to release Hillary Clinton’s missing server emails: “Russia, if you’re listening, I hope you’re able to find the 30,000 emails that are missing.” The reference here was not to the hacking the GRU had done over the previous few months but to the hypothesized compromise of Clinton’s private email server some time earlier—an event that there is no particular reason to believe took place at all.

The GRU, like many Trump supporters, took Trump seriously, but not literally. “Within approximately five hours of Trump’s announcement,” Mueller writes, “GRU officers targeted for the first time Clinton’s personal office.” In other words, the GRU appears to have responded to Trump’s call for Russia to release a set of Clinton's emails the Russians likely never hacked by launching a new wave of attacks aimed at other emails.

Trump has since insisted that he was joking in that speech. But the public comments mirrored private orders. After the speech, “Trump asked individuals affiliated with his Campaign to find the deleted Clinton emails,” the report states. “Michael Flynn … recalled that Trump made this request repeatedly, and Flynn subsequently contacted multiple people in an effort to obtain the emails.”

Two of the people contacted by Flynn were Barbara Ledeen and Peter Smith. Ledeen had been working on recovering the emails for a while already, Mueller reports. Smith, only weeks after Trump’s speech, sprang into action himself on the subject. Ledeen ultimately obtained emails that proved to be not authentic. Smith, for his part, “drafted multiple emails stating or intimating that he was in contact with Russian hackers”—though Mueller notes that the investigation “did not establish that Smith was in contact with Russian hackers or that Smith, Ledeen, or other individuals in touch with the Trump Campaign ultimately obtained the deleted Clinton emails.”

In other words, Trump wasn’t above dealing with Russian hackers to get Hillary Clinton’s emails. The reason there’s no foul here, legally speaking, is only that the whole thing was a wild conspiracy theory. The idea that the missing 30,000 emails had been retrieved was never more than conjecture, after all. The idea that they would be easily retrievable from the so-called dark web was a kind of fantasy. In other words, even as a real hacking operation was going on, Trump personally, his campaign, and his campaign followers were actively attempting to collude with a fake hacking operation over fake emails.

Then there are the more-than-100 pages detailing Russian contacts and links with the Trump campaign and business. Mueller looks at these through a legal lens; he’s a prosecutor, after all, looking to answer legal questions. But I found myself reading it through a very different lens: patriotism.  

Mueller concludes, after detailing the contacts, that “the investigation established multiple links between Trump Campaign officials and individuals tied to the Russian government. Those links included Russian offers of assistance to the Campaign. In some instances, the Campaign was receptive to the offer, while in other instances the Campaign officials shied away. Ultimately, the investigation did not establish that the Campaign coordinated or conspired with the Russian government in its election-interference activities.”

It is not hard to see how he came to the conclusion that charges for conspiracy would not be plausible based on the contacts Mueller describes. For starters, a number of the individual incidents that looked deeply suspicious when they first came to light do look more innocent after investigation. These include the change in the Republican Party’s platform on Ukraine at the Republican National Convention, for example, as well as Jeff Sessions and other campaign officials’ various encounters with the omnipresent former Russian ambassador Sergey Kislyak. On these matters, Mueller does seem to have found that nothing untoward happened.

Even those incidents that don’t look innocent after investigation don’t look like criminal conspiracy either. So, for example, George Papadopoulos found out about the Russians having “dirt” on Clinton in the form of “thousands of emails,” but he does not appear to have reported this to the campaign—though he was trying to arrange a Trump-Putin meeting at the time. Even if he had reported it to the campaign, the Trump campaign’s being aware of Russian possession of hacked Clinton emails wouldn’t constitute a conspiracy—the campaign, after all, never did anything about it.

The Trump Tower meeting is one of the most damning single episodes discussed: The campaign’s senior staff took a meeting with Russian representatives who promised disparaging information on Clinton as part of the Russian government’s support of Trump. Yet even here, while the campaign showed eagerness to benefit from Russian activity, the meeting was unproductive and nothing came of it. Where exactly is the conspiracy supposed to be? I can think of a number of possible answers to this question, and Mueller entertained one related to campaign-finance violations, but I certainly can’t argue that an indictment is an obvious call.

So, too, the extended negotiations over Trump Tower Moscow. The investigation makes clear that Trump—who spent the campaign insisting he had “nothing to do with Russia”—was lying through his teeth the whole time. He was, in fact, seeking Russian presidential support for his business deal through June 2016. But it’s not illegal to have contacts with Russians, including Putin’s immediate staff, to try to build a building. And it’s not obvious how this sort of “collusion” with the Russian government could amount to coordination or conspiracy on concurrent Russian electoral interference.

At the same time, Mueller here is far more reticent than he is about the IRA operation. He does not clear the president or his campaign. There are, in my view, two major reasons for the difference between his conclusions on these matters and his conclusions about the IRA operation, for which he affirmatively finds no evidence of conspiracy. The first is the sheer volume of contacts, which is truly breathtaking. These contacts were taking place even as it was publicly revealed that the Russians had been behind the Democratic Party hacks, even as the releases of emails took place, even as the incumbent administration was publicly attributing the attacks to Russia, even as—through the transition—the outgoing administration was sanctioning Russia for those attacks. The brazen quality of meeting serially with an adversary power while it is attacking the country and lying about it constantly militates against a stronger conclusion that there is no evidence of conspiracy—at least not in the absence of solid answers to every question.

And not every question got a solid answer. The Mueller team was clearly left unsatisfied that it understood all of Carter Page’s activities while he was in Moscow in July 2016, for example. Similarly, the office reports in its discussion of the Trump Tower meeting that Donald Trump Jr. “declined to be voluntarily interviewed by the Office.” This line is followed by a redaction for grand-jury information, raising the question of whether Trump Jr. asserted his Fifth Amendment right against self-incrimination or indicated an intent to do so.

And then there’s Paul Manafort. Mueller is candid that he was unable to determine why Manafort was having campaign polling data shared with his long-time employee, Konstantin Kilimnik. Mueller was also unable to determine what to make of repeated conversations between Kilimnik—who has alleged ties to Russian intelligence—and Manafort about a Ukrainian peace plan highly favorable to Russia. And while Mueller could not find evidence of Manafort’s passing the peace plan along to other people in the campaign, he notes that the office was unable “to gain access to all of Manafort’s electronic communications” because “messages were sent using encryption applications” and that Manafort lied to the office about the peace plan. As for the polling data, “the Office could not assess what Kilimink (or others he may have given it to) did with it.” So while the office did not establish coordination in this area, it was clearly left with residual suspicions—and with unanswered questions.

In other words, on the legal side, the evidence isn’t all that close to establishing coordination in the sense that conspiracy law would recognize, either on the hacking side or with respect to the contacts. But the positive enthusiasm for engaging Russian hackers over emails, the volume of contacts, the lies, and the open questions make it impossible to say no evidence of conspiracy exists.

The really interesting question here is not legal. It is historical and political: How should we understand the relationship between Trump and Russia? Put another way, what is the story these contacts tell if it’s not one of active coordination? They surely aren’t, in the aggregate, innocent. They aren’t normal business practice for a presidential campaign. What are they?

For what it’s worth, here’s what I see in the story Mueller has told on Trump engagement with the Russians over the hacking. I see a group of people for whom partisan polarization wholly and completely defeated patriotism. I see a group of people so completely convinced Hillary Clinton was the enemy that they were willing to make common cause with an actual adversary power who was attacking their country to defeat her.

To me, it matters whether the conduct violated the law only in the pedestrian sense of determining the available remedies for it—and in guiding whether and how we might have to change our laws to prevent such conduct in the future. I don’t know the right word for this pattern of conduct. It’s not collusion, though it may involve some measure of collusion. It’s not coordination or conspiracy. But in Clinton, Democrats, and liberals, the Trump campaign saw a sufficiently irreconcilable enemy that it looked at Vladimir Putin and saw a partner. That may not be a crime, but it is a very deep betrayal.

The counterintelligence dimensions of the entire affair remain a mystery. 

Because the Mueller investigation was born out of a counterintelligence investigation, there has been an enduring impression that it had both criminal and counterintelligence elements. I have assumed this myself at times. How these two very different missions integrated within the Mueller probe has been much discussed. The Mueller report answers this question, and the answer is actually striking—and from my point of view alarming: The Mueller investigation was a criminal probe. Full stop.

It was not a counterintelligence probe. Mueller both says this directly and also describes how the counterintelligence equities were handled. Here’s how Mueller describes his investigation: “Like a U.S. Attorney’s Office, the Special Counsel’s Office considered a range of classified and unclassified information available to the FBI in the course of the Office’s Russia investigation, and the Office structured that work around evidence for possible use in prosecutions of federal crimes.” A counterintelligence investigation is not structured around evidence for possible use in prosecutions of federal crimes.

Mueller then answers the question of what happened to the counterintelligence components of the investigation: The FBI took responsibility for them. “From its inception,” Mueller writes, “the Office recognized that its investigation could identify foreign intelligence and counterintelligence information relevant to the FBI’s broader national security mission. FBI personnel who assisted the Office established procedures to identify and convey such information to the FBI.”

The special counsel’s office and the FBI Counterintelligence Division had regular meetings to facilitate this transfer of information. “For more than the past year,” Mueller goes on, “the FBI also embedded personnel at the Office who did not work on the Special Counsel’s investigation, but whose purpose was to review the results of the investigation and to send—in writing—summaries of foreign intelligence and counterintelligence information to FBIHQ and FBI Field Offices.” The report deals only, Mueller says, with “information necessary to account for the Special Counsel’s prosecution and declination decisions and to describe the investigation’s main factual results.”

In other words, the Mueller investigation was a criminal probe only. It had embedded FBI personnel sending back to the FBI material germane to the FBI’s counterintelligence mission. But Mueller does not appear to have taken on the counterintelligence investigative function himself.

This leaves me worried. After the blood-letting at the bureau that saw the entire senior leadership replaced precisely as it was engaged with counterintelligence questions involving Trumpworld and Russia, who at the bureau now is going to push such questions? The incentive structure at the FBI cannot favor senior leadership carrying the ball on this. It also cannot favor individual agents allowing themselves to get assigned to matters that would put them in the president’s cross-hairs.

So I worry about a counterintelligence gap. Mueller, the person with the independence to take this matter on, construed his role narrowly as a prosecutor and set up a one-way street for counterintelligence information to go back to the FBI. And the FBI, the entity with the mandate, has every incentive to play it cautious.

It would be the deepest of ironies if the Mueller investigation showed evidence that the president had committed crimes and had committed impeachable offenses, and if he had painted a remarkable historical portrait of the relationship between Trumpworld and the Russian government, but if at the same time, the core counterintelligence concerns that gave rise to it and that have haunted the Trump presidency from the beginning went unaddressed.



Earlier this year, President Donald Trump signed an executive order requiring colleges and universities that receive federal funds to do what they’re already required by law to do: extend free-speech protections to men and women on campus.

The executive order was a transparent exercise in politics. Its intent was to validate the collective antipathy that many Trump boosters feel toward institutions of higher learning. Its major impact, though, has been to shed light on how serious the purported censorship crisis on campus really is—or, rather, is not.

I have served for more than two decades as a university president, the past 17 years leading Columbia University. I am also a lifelong First Amendment scholar and have written books and essays to try to understand and explain why our laws and norms have evolved as they have. In both these capacities, I can attest that attitudes about the First Amendment are evolving—but not in the way President Trump thinks.

The president’s claim that the campus free-speech order was needed to defend “American values that have been under siege” ignored two essential facts. First, universities are, today, more hospitable venues for open debate than the nation as a whole. Second, not only have fierce arguments over where to draw the line on acceptable speech been a familiar occurrence in the United States for the past century, but such dialogue has also been indispensable to building a society that embraces the First Amendment. From flag burning to Holocaust denial, Americans of all ages have been grappling with basic questions about offensive speech for decades and will continue to do so for as long as the country strives for this ideal of openness and freedom of expression. Exchanges over the boundaries of campus speech should therefore be welcomed rather than reviled when they take place.

According to a 2016 Knight Foundation survey, 78 percent of college students reported they favor an open learning environment that includes offensive views. President Trump may be surprised to learn that the U.S. adult population as a whole lags well behind, with only 66 percent of adults favoring uninhibited discourse.

At Columbia and at thousands of other schools across the United States, controversial ideas are routinely expressed by speakers on both the left and the right, and have been for decades. In fact, Columbia University is something of a magnet for provocative speakers. During the 2017–18 academic year, the conservative radio talk-show host and author Dennis Prager spoke at Columbia. The Fox News legal commentator Alan Dershowitz, the 2016 Republican Party presidential candidate Herman Cain, and the immigration activist Mark Krikorian spoke too—all without incident. The conservative political commentator, author, and filmmaker Dinesh D’Souza, after his talk, remarked on the civility of the discussion he encountered in his visit to Morningside Heights. The conservative commentators Ann Coulter and Mike Cernovich also spoke freely at Columbia, as did Israeli Ambassador Danny Danon. These speakers encountered varying degrees of student protest, an essential feature of a true free-speech environment that not only welcomes but relishes contentious debate.

It’s true that, in recent years, there have been more than a few sensational reports—at places such as Middlebury, William & Mary, and UC Berkeley—of misguided demands for censorship on campus, providing a ready, if false, narrative about liberal colleges and universities retreating from the open debate they claim to champion.

Still, the surest evidence of censorship or the suppression of ideas on college campuses is the disinvitation of controversial speakers. There are more than 4,500 colleges and universities in the United States, and each year they host thousands of speakers of all political stripes. According to FIRE, a watchdog group that focuses on civil liberties in academia, only 11 speakers were disinvited from addressing college audiences in 2018. This is a minuscule fraction of the universe of speakers who express their views annually on American campuses.

Because I am of the view that one such disinvitation is one too many, I have said that I will personally introduce controversial figures who were rejected elsewhere. Nevertheless, I understand when members of our university community raise alarms that certain individuals, based on their track record, cross the line from merely controversial to offensive.

When students express concern and discomfort about speech that is hateful, racist, or noxious in other ways, they are doing nothing unreasonable or historically unprecedented. A number of other democracies take a less absolute view on this topic—yet remain democracies. Moreover, the prevailing American conception of free speech and press rights is a relatively recent development when located in the sweep of time and the history of our nation. The challenge of resolving the tensions inherent in a tolerant society is still very much with us and is likely to remain so.

While the words of the First Amendment are enduring—“Congress shall make no law … abridging the freedom of speech, or of the press”— their interpretation has been far from immutable. These rights have repeatedly been given new meaning during moments in our nation’s history characterized by intolerance, fearmongering, and censorship, when freedom of speech and the press came under attack.

The period following World War I provided the first of these moments, and it did not go well for freedom of expression. The Supreme Court, in its inaugural First Amendment ruling, exactly 100 years ago, upheld the imprisonment of the Socialist Party presidential candidate Eugene Debs for the crime of publicly expressing his support of draft resisters. Yet the Debs case, along with the companion Schenck and Frohwerk decisions, succeeded in ushering in the constitutional right of freedom of speech and the press as we currently know it.

It would then take almost a half century for the nation’s highest court to enshrine these core rights within a sustainable and resilient framework. Until the New York Times Co. v. Sullivan ruling in 1964, journalists who cast a critical light on the activities of the nation’s most powerful individuals did so at their peril. Reporters were routinely intimidated by the implied or actual threat that powerful actors would retaliate by filing libel suits. That changed when the Court established the “actual malice” standard, which holds that for press reports about public officials to be considered libel, a journalist or publisher must have made knowingly false statements or acted in reckless disregard of the truth.

Americans should not confuse a First Amendment that is codified with a First Amendment that is calcified. In landmark case after case, the First Amendment has continued to evolve as new threats to the exercise of free expression have emerged.

Today, digital communications and social media pose an array of critical challenges to free expression. Their effects on public thought and discussion and the vulnerability of these modes of communication to manipulation by actors (foreign as well as domestic) are a source of deep concern. Repeated declarations by the president that journalists are the “enemies of the people,” and the purveyors of “Fake News,” can make us feel that we are on the verge of falling into a First Amendment abyss. Pessimists variously insist that the First Amendment is “obsolete,” “dying,” or “dead.”

But such despair misreads our history and misunderstands America’s constitutional system and its proven resilience. Over the past century, periods of great insecurity and repression—from the Red Scare following World War I to the McCarthy era and beyond—ultimately gave way to the restoration of a belief in the power of reasoned debate.

These episodes are now looked back upon as provocations for redefining the contours of the First Amendment and strengthening it through the invention of new doctrines suitable for the times. We should expect the dynamic to continue, even if the process will be difficult and erratic. The final word on First Amendment disputes in America, after all, isn’t rendered on campus—or in individual newsrooms, for that matter—but within a robust legal and constitutional framework. We leave the ultimate decisions to judges who look to precedent for guidance and render new decisions about emerging topics, thus creating new precedent.

In light of the long evolution of free expression in the United States, we should be careful drawing conclusions based on a handful of sensationalist incidents on campus—incidents sometimes manufactured for their propaganda value. They shed no light on the current reality of university culture.

I sometimes agree and sometimes disagree with contemporary students’ conception of free speech and the First Amendment. Always, though, I embrace the fact that these questions are being discussed. Fifty years ago, I was on campus when students demanded access to “shocking” works of literature their parents and other adults had condemned. Fifty years later, students sensitive to expression that marginalizes and threatens may condemn those same books—albeit for entirely different reasons.

Only through such debates can the First Amendment remain vital. Struggling to decide how strong its protections should be, when speech is so offensive as to become intolerable, where to draw these lines, how to think about free speech in the context of modern communications, and how to apply First Amendment norms in our era is exactly what needs to be done—and exactly what has been done by every preceding generation for the past century.

This article is part of “The Speech Wars,” a project supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press, and the Fetzer Institute.



The writer Jon Ronson once observed that every day in the social-media era, “a new person emerges as a magnificent hero or a sickening villain. It’s all very sweeping.” In Ronson’s 2015 book, So You’ve Been Publicly Shamed, his subjects found themselves beset by angry detractors for, say, an insensitive Twitter joke or Facebook photo. They lost jobs, received threats, even pondered suicide. And they mostly retreated from view until the shame storm passed.

Today they might sue instead.

Last year, I reported on a lawsuit that a man accused of rape on the “Shitty Media Men” spreadsheet filed against the woman who had created and circulated the document.

In January, a viral video of the high-school student Nick Sandmann at a protest march in Washington, D.C., appeared to some to show him smirking at a Native American elder. That triggered a wave of inordinate social-media hate and flawed journalism. Now the young man who was at the bottom of the pile-on is suing The Washington Post for $250 million, NBC for $275 million, and CNN for $275 million.

Last month, the author Natasha Tynes tweeted a photo of a Washington, D.C., Metro employee eating on a train in violation of the transit system’s policies. Defenses of the black employee and outrage against Tynes culminated in a statement that her publisher posted to Twitter asserting that she “did something truly horrible today” as “black women face a constant barrage of this kind of inappropriate behavior directed at them and a constant policing of their bodies.” It went on to declare that it would cancel her novel.

Now Tynes is suing her publisher, Rare Bird Lit, for more than $13 million, USA Today reports, “alleging the company defamed her and breached a publishing contract amid a social media shaming.”

These cases vary in the particulars, the degree of sympathy one might feel for the plaintiffs and defendants, and the strength of the legal claims. But all involve men and women who were publicly shamed and who are now trying to recover damages. The plaintiffs are betting that they can persuade a jury to side with them rather than their public shamers. They believe their antagonists belong to an umbrage-taking minority, not a majority enforcing a social consensus.

All may lose in court anyway.

The provocateur Milo Yiannopoulos dropped a lawsuit against Simon & Schuster, failing in his efforts to recover damages after the publisher canceled his memoir, Dangerous, amid public outcry over his behavior.

The creator of the “Shitty Media Men” list may be immune from liability for entries she did not create under Section 230 of the Communications Decency Act. The egregious mistreatment of Sandmann at the hands of many does not mean that any particular media organization libeled him or caused him damages totaling hundreds of millions of dollars. And Tynes’s publisher may manage to convince the courts that its contract gives it broad license to cancel book projects involving authors who take actions that stoke moral controversy.

But another multimillion-dollar lawsuit suggests that there is an appetite among some juries for awarding big damages when the plaintiff is perceived to have been treated badly in a public shaming.

On November 9, 2016, three black students at Oberlin College made a late-afternoon trip to Gibson’s Bakery, a small, family-owned business near campus that has been serving the community at its present location since 1905. Like countless undergraduates of all races, classes, genders, and generations, they hoped to leave with alcohol but weren’t yet of age to purchase it legally.

A fake ID was produced and rejected.

In the moments that followed, Allyn Gibson, the owner’s son, would try to keep the fake ID, pursue the male student who had used it as he fled to the back of the store, chase him into the street yelling “Shoplifter!,” and detain him, even as the other students, who were women, attempted to intervene on behalf of their friend. Soon, Oberlin police arrived and arrested the three undergraduates. A police report accused them of trying to shoplift two bottles of wine. Many classmates jumped to the conclusion that they’d been mistreated and launched protests almost immediately.

“Chants of ‘No justice, no peace’ reverberated across campus from early morning into late last night as hundreds of protesters lined West College Street, calling for a boycott of Gibson’s Bakery,” the student newspaper reported. “According to a flyer distributed by protesters, this incident was far from Gibson’s first instance of alleged racial bias.”

The same article quoted a black employee of the store who dismissed racism as a motive. “If you’re caught shoplifting, you’re going to end up getting arrested,” he said. “When you steal from the store, it doesn’t matter what color you are. You can be purple, blue, green; if you steal, you get caught, you get arrested.”

It is easy to understand why some college students would reflexively side with their peers, especially early on, as conflicting eyewitness accounts spread by hearsay across the small campus. The student government passed a resolution calling for the university to “cease all support, financial and otherwise,” of the bakery, which had a long-standing contract with Oberlin’s food-services vendor.

Later, when the male student was charged with felony robbery rather than shoplifting, even as his fake ID suggested at the very least that his initial intent had been to make a purchase, many at Oberlin perceived a miscarriage of justice and wondered whether race had played a role in the charging decision. That, too, is easy to understand.

If this was merely a matter of hasty student protests going too far before all the facts emerged, the eight-figure lawsuit would not have been warranted.

But the jury heard a story in which adults at Oberlin chose to fuel the mob’s excesses while pandering to its false narrative.

That the narrative was suspect should have been obvious almost immediately. Administrators were present at early legal hearings where the male student offered to plead guilty to misdemeanor theft, a plea deal that David Gibson, the bakery’s owner, explicitly approved. (A judge rejected the deal, citing student protests at Oberlin and the bad precedent that could result from the perception of reducing the charges under pressure. One of the student defendants would later remark that he appreciated the support of his classmates even though it probably hurt his case.)

Daniel McGraw, who covered the trial for Legal Insurrection, reported on an email that Emily Crawford, who worked in the school’s communications department, sent to her bosses, who forwarded it to other administrators. “I have talked to 15 townie friends who are poc (persons of color) and they are disgusted and embarrassed by the protest,” she warned. “In their view, the kid was breaking the law, period … To them this is not a race issue at all and they do not believe the Gibsons are racist. They believe the students have picked the wrong target … I find this misdirected rage very disturbing, and it’s only going to widen the gap (between) town and gown.”

He also reported on the response from Tita Reed, the special assistant to the president for community and government relations, who reacted to the news of local sentiment, “Doesn’t change a damn thing for me.”

The Gibson family’s lawsuit, set forth in a 33-page complaint, would give locals a lot more reason for anger at Oberlin and Meredith Raimondo, the special assistant to the president for equity, diversity, and inclusion. Among its allegations were the following:

Oberlin employees were among those who distributed a boycott flyer, and they allowed it to be copied for free on school machines. It declared without evidence that the bakery was a “racist establishment with a long account of racial profiling and discrimination” and called its behavior toward the three students who broke the law there “heinous.”

Reed, Raimondo, and some Oberlin professors “raised their fists in support of the demonstration,” with some of them “shouting the defamatory statements on a bullhorn, thereby assuring that a large audience would hear their defamatory statements.”

Credit was given to students who attended the protest in lieu of classes, and administrators bought them food to support them.

After that initial round of protests, Oberlin caved to student demands to cancel all its business with the bakery. Later, an Oberlin Police Department investigation, undertaken to probe accusations of racist behavior at the bakery, found that among 40 adults arrested for shoplifting at the business in a five-year period, six were black, suggesting vigilant enforcement against people of all races.

The lawsuit goes on to allege that when David Gibson sat down with administrators to tell them about the devastating effect that defamation, boycotts, demonstrations, and refusal to do business with Gibson’s were having on his family’s store, Oberlin administrators sought to negotiate special treatment for shoplifting students in exchange for resuming relations with the bakery.

The complaint described the meeting as follows:

Gibson requested that Oberlin College immediately retract the defamatory statements and reinstate its contracts … Defendants represented that they would consider reinstating business … but only if Gibson’s Bakery would agree that “Gibson’s would not push criminal charges against first-time shoplifters” … Gibson’s Bakery already loses thousands of dollars a year due to stolen merchandise, and such losses would certainly multiply if students learned they could steal without repercussion.

Time would only further undermine the proposition that the Oberlin students were innocents victimized by a racist local business. While pleading guilty to misdemeanor theft charges in August 2017, each of the students would declare in an official statement, “I believe the employees of Gibson’s actions were not racially motivated. They were merely trying to prevent an underage sale.”

And yet, the Gibsons’ lawsuit alleged, Oberlin students giving campus tours on behalf of the college advised prospective and future students and their families not to shop at Gibson’s Bakery because it was “racist” and “assaults students.” Various hits to the business ultimately caused it to lay off multiple employees, adding to the social injustice done by the misguided student activists and the Oberlin faculty and administrators who abetted their harmful efforts.

That is not to say that everyone at Oberlin was of like mind.

Almost a year after the incident, Roger Copeland, a professor emeritus of theater and dance, wrote a letter to the student newspaper lamenting, “It is now abundantly clear that the College’s boycott of Gibson’s was disingenuous and utterly unwarranted.” He criticized then–Oberlin President Marvin Krislov and Raimondo for a “rush to judgment” and actions that amounted “to a staggering, potentially bankrupting loss” to a small family business, and concluded with this biting critique:

The facts of this case are no longer in question. And yet, a counter-narrative has taken hold, one that refuses to allow mere “facts” to get in the way. It’s embarrassing when one has to ask Oberlin students the same question one asks climate-change deniers: At what point do you accept the empirical evidence, even if that means having to embrace an “inconvenient” truth? Alas, even those who concede that the defendants violated the law, continue—stubbornly—to insist that there is “plenty of blame to go around” and that “both sides” are at fault. Really? Isn’t that what Donald Trump said about Charlottesville?

The time has come for the Dean of Students, on behalf of the College, to apologize to the Gibson family for damaging not only their livelihood but something more precious and difficult to restore—their reputation and good standing in the community.

At trial, Raimondo was revealed to have sent a text reacting to Copeland’s letter that said, “Fuck him. I’d say unleash the students if I wasn’t convinced this needs to be put behind us.” To me, the metaphor suggests administrators who calculatingly wield some control over whether students activists are aggressive or restrained.

Another striking moment at trial came when Eddie Holoway, a black man who put himself through technical college decades ago while working at Gibson’s Bakery, spoke about what he regarded as a false narrative spread about his former employer. “He was accused of being something that I know he’s not, and that’s a racist,” Holoway testified. “In my life, I have been a marginalized person, so I know what it feels like to be called something that you know you’re not. I could feel his pain. I knew where he was coming from.”

Ultimately, jurors awarded the family $11 million in compensatory damages, and—on Thursday—an additional $33 million in punitive damages. It is likely the judge will reduce that latter figure to $22 million due to an Ohio cap on such awards.

After the eight-figure victory, David Gibson told a Legal Insurrection reporter, “I just want to let people know across the country that this can happen to anyone else, but we stayed and worked together as a family and fought against this. In many ways, what we wanted from Oberlin College the jury gave to us. They said we were not racists and that the college should have said so when all this started.”

An official statement released by the college expressed sharp disagreement with the outcome, asserting that neither Oberlin nor its administrators had defamed the bakery or its owners. “Rather, the College and Dr. Raimondo worked to ensure that students’ freedom of speech was protected and that the student demonstrations were safe and lawful, and they attempted to help the plaintiffs repair any harm caused by the student protests,” the statement reads. “Colleges cannot be held liable for the independent actions of their students. Institutions of higher education are obligated to protect freedom of speech on their campuses and respect their students’ decision to peacefully exercise their First Amendment rights.”

If colleges were held responsible for the independent speech and actions of student protesters, that would indeed have a chilling effect on free speech. This lawsuit may even inspire future litigation against colleges that chills protected speech, as plaintiffs seeking a similar payday attempt to target administrators for what students do on their own. But jurors in this case did not find Oberlin liable for the independent actions of students. And I think administrators displayed the most egregious behavior in this case, given that they ought to possess more wisdom than the most zealous undergraduates.

In a 1903 law-review article, the federal judge Van Vechten Veeder posited that an era’s approach to defamation could reveal a lot about how it valued competing goods. “Since the law of defamation professes to protect personal character and public institutions from destructive attacks, without sacrificing freedom of thought and the benefit of public discussion,” he wrote, “the estimate formed of the relative importance of these objects … would be an admirable measure of each culture, liberality, and practical ability of each age.”

Our era, defined in large part by the rise of social media, is exposing us to many more instances of possibly defamatory speech, with more frequency, prompting closer examination of long-standing norms. The conditions are ripe for cultural change. And jury verdicts in the next stretch of years will both reflect and drive it.

A plaintiff’s attorney in the Gibson case has long believed that it will play a part in that process. “Sometimes attitudes and actions of powerful institutions that spawn cases like this continue until the full array of personal and economic consequences of defamation are recognized,” he told The Weekly Standard last year. “Until recent national events, some say that our society and its powerful institutions have been slow to recognize the toll extracted by defamation.”

This week, the Gibson family’s legal team cast the jury’s decision as a tool to reform undue shamings nationwide. “Why is the country watching you? Because the country agrees that what happened to the Gibsons should not happen to anyone, but could happen to everyone,” the attorney Lee Plakas argued, according to the Legal Insurrection reporter who attended the trial. “Colleges are watching us and you. Because they all know the way colleges are run will be affected, and by your decisions, they will be.”

I celebrate the happy ending for the Gibsons, but not without some trepidation about the downsides of adjudicating culture-war fights or the proper administration of America’s colleges in court, where extreme cases can mean cathartic outcomes and bad law. It would be a shame if jurors intent on vindicating the wrongly maligned wound up severely chilling protected speech too.



Here we go again: another juicy book about the White House, early leaks, a round of flat denials, shortly to be followed—in all likelihood—by a set of fevered interpretations and recriminations.

The book is Siege, by Michael Wolff. The Guardian obtained an early copy of the book, which is due out next week, and the first details suggest that it will provide fodder for days of news coverage and debate—following in the path of Wolff’s previous book, 2018’s Fire and Fury.

Yet it’s hard to imagine Siege achieving the same impact as its predecessor. In part that’s because Wolff didn’t have the same unfettered access to the White House this time, and in part that’s because of questions that were raised about his methods and results in Fire and Fury. But the bigger problem is the format. Tell-alls about Donald Trump’s administration feel increasingly obsolete. What more can we learn about a president who is already so heavily exposed?

Once upon a time, the tell-all would actually tell something new about a president. My colleague James Fallows’s 1979 Atlantic article on Jimmy Carter revealed the president’s strengths and shortcomings, including a tendency toward micromanagement that led him to personally approve requests to use the White House tennis courts. The former George W. Bush press secretary Scott McClellan’s 2008 What Happened offered just what its title promised—a full, inside account of the administration’s workings, especially in the run-up to the Iraq War. Former Defense Secretary Robert Gates revealed the extent to which domestic political considerations weighed on Barack Obama’s foreign-policy decisions. Articles and books like these offered both new detail and new interpretation that could help the public understand leaders and perhaps change public opinion about them.

At its outset, the Trump administration looked like a perfect setting for new tell-alls. It featured a president who disregarded all norms, a public that couldn’t look away, and lots of current and former staffers with axes to grind, making them the perfect sources for, or authors of, exposés. And indeed, the first year or so of the presidency was fertile. Early on, every Friday afternoon brought a contest between The New York Times and The Washington Post for the splashiest report. After that came the books, climaxing with Wolff’s entry in January 2018.

Fire and Fury sold, well, furiously, which encouraged the market for such books. In February, the Times wondered, “Is everyone in Washington writing a tell-all? It sure seems like it.” The books came from White House aides (Omarosa Manigault-Newman, Cliff Sims, Sean Spicer); career G-men settling scores (James Comey, Andrew McCabe, Preet Bharara); others in the general Trump vicinity (Chris Christie); and reporters, including the éminence grise of the White House potboiler, Bob Woodward. There are plenty more coming.

Many of these books sold well, but they shed more heat than light. At best, they offered new detail about Trump and some of the more important or interesting moments in his tenure. But they struggled to teach any larger lessons about the president, and as a result, they haven’t made much of an impact on politics.

“Beyond a considerable boost to the profit margins of Simon & Schuster,” Jeff Greenfield wrote of Woodward’s Fear in the fall, “the response in Washington from President Donald Trump’s allies, and even from his longtime critics, has been a virtual shrug.”

Don’t blame the authors—or rather, don’t blame them for this. Plenty of these tell-alls are sloppy, or self-serving, or sycophantic, and their authors can answer for that. But it’s not the writers’ fault that they aren’t reconfiguring the image of the president or his administration. Not only has Trump been exhaustively covered by the press, but he often goes through his business, including his petty feuds, his tantrums, and his changes of view on policy questions, in plain sight. That was, in fact, a core element of his preemptive defense against accusations of obstruction of justice: So many of his actions were out in the open. How could they constitute a conspiracy when they happened on Twitter? (This cuts both ways: Transparency should not confer absolution.)

Fire and Fury came under intense scrutiny even before it hit shelves, as journalists and political insiders questioned many of the specifics of Wolff’s account and critiqued his methods. These critics picked apart specific anecdotes or moments, but there was general agreement that the book’s broad-strokes portrait of Trump felt right. Axios’s Mike Allen perfectly summed up this conventional wisdom:

There are definitely parts of Michael Wolff’s “Fire and Fury” that are wrong, sloppy, or betray off-the-record confidence. But there are two things he gets absolutely right, even in the eyes of White House officials who think some of the book’s scenes are fiction: his spot-on portrait of Trump as an emotionally erratic president, and the low opinion of him among some of those serving him.

Yet anyone who was paying even casual attention to Trump’s presidency knew by January 2018 that Trump was emotionally erratic and that many of his aides held him in disdain.

The book, and many like it, largely served to flatter the preconceptions of Trump’s critics. These readers might understand that the details aren’t 100 percent accurate, but they don’t really care. For the slight majority of registered voters who already say they definitely won’t vote for Trump in 2020, it’s close enough. (There’s a different kind of book that flatters the preconceptions of Trump’s fans, but it tends to be more polemic or commentary than memoir or reportage.)

If these books tell a Trump-skeptical audience that Trump is not a conventional president, they offer the same message to a more receptive Trump-supporting audience. The president himself has embraced the idea. Responding to complaints about his tweeting in 2017, he remarked (on Twitter, of course), “My use of social media is not Presidential—it’s MODERN DAY PRESIDENTIAL.”

The notion was ridiculed, rightly, at the time. But voters seem to be coming around. A Gallup poll released Tuesday found that 40 percent of voters believe Trump “has the personality and leadership qualities a president should have,” up from just 33 percent two years ago. That still lags far behind Bush and Obama, but the size of the increase suggests that Trump has convinced some voters that what he’s doing is presidential, simply by virtue of the fact that he is the president and he is doing it.

Yet that uptick comes even as Trump’s approval/disapproval numbers remain essentially stable. Just as there are voters who disapprove of Trump and are willing to believe, or at least accept, “truthy” accounts of him, there’s another set who don’t care whether the accounts are true and continue to support him.

The balance of Siege remains to be revealed, but the first two juicy claims in The Guardian’s report help show why the tell-all genre is becoming a snooze. The paper reports that Wolff claims Trump reacted to witness-cooperation deals taken by his former fixer Michael Cohen, the Trump Organization executive Allen Weisselberg, and the tabloid publisher David Pecker by saying, “The Jews always flip.” Perhaps Trump said this and perhaps he didn’t, but it’s already well established that he has resorted to stereotypes about Jews on various occasions, and has a long history of bigoted views and comments. Whether the quote is real or not, it doesn’t convey anything new about Trump.

The Guardian also reports that Siege says Special Counsel Robert Mueller drew up an indictment against Trump for obstruction of justice but never filed it. Mueller’s spokesman says that no such document exists, and his team has proved almost entirely leak-proof, with the exception of one score-settling leak against the attorney general. Unless and until other reports corroborate this claim, it’s probably best to treat it cautiously.

It’s Mueller who may lay claim to the title of the ultimate tell-all writer of the Trump administration. When his 448-page report was released to the public, critics strained to find literary meaning and significance in it. But the value was not in the composition, but in the content. Aided—unlike any of the other authors—by subpoena power, Mueller was able to draw a more nuanced and revealing portrait of Trump and the first two years of his presidency than any other author.

Mueller’s report offered new detail, such as Trump’s meltdown over Mueller’s appointment (“This is terrible. This is the end of my presidency. I’m fucked.”) and his refusal to return a resignation letter to his attorney general, instead carrying it with him overseas. The report also offered a big-picture charge, revealing the extent and length of Trump’s attempts to obstruct justice, though Mueller stopped just short of calling it that.

Yet even the Mueller report has had little immediate effect. Trump’s approval rating has stayed stable (suggesting neither the exoneration he claimed nor the KO his critics dreamed of). Mueller did change Representative Justin Amash’s mind, though, and if House Democrats ultimately move to impeach the president, it will only cement the Mueller report’s status as the pinnacle of Trump tell-alls.

Just because the potency of tell-alls has weakened doesn’t mean the stream of books will diminish. The Associated Press revealed Tuesday that former Defense Secretary James Mattis will publish a memoir this summer. Mattis might actually have something new to say about Trump: Not only did he have significant policy differences with the president—according to Woodward, he simply discarded directives he found foolish—but he managed to last for two years in the administration by saying little to the press. But Mattis warns that he’s writing a different kind of book: “I’m old-fashioned: I don’t write about sitting Presidents, so those looking for a tell-all will be disappointed.”

No wonder Mattis has a reputation for wisdom.



Imagine a life in which all your basic needs were met, the bottom of Maslow’s hierarchy of needs forever lopped off. No concerns about college debt ruining your ability to buy a home. No worries about where meals would come from, or whether you would have enough cash to keep gas in the car. No problems paying medical bills.

Then, imagine a life in which virtually all of your needs were met. In this world, society would guarantee its members not just middle-income status, but the prospect of travel, the option of a fulfilling but nonremunerative career, time with family and friends, time spent with cats and gardens and on volunteering and road trips. Imagine that all your peers exercised regularly and watched as much Peak Television as they wanted. Imagine never retiring, because there would be no need to retire. And imagine this happening on a far greener planet.

If the former is the promise of today’s resurgent, left-tilting left, the latter is the promise of its revolutionary vanguard, its furthest flank. And it has a name, a great name: Fully Automated Luxury Communism, or FALC.

FALC is a strong brew of technological determinism, sunny utopianism, and souped-up socialism: Let the robots do all the work, and let humans enjoy the fruits of their labor in equal measure. A mainstay of science fiction and prophetic religious texts (minus the robots part), the idea has come into vogue over the past half-decade or so, both among progressive thinkers concerned about inequality and stagnation and among the internet’s meme makers, the promoters of FALC’s swervier cousin, Fully Automated Luxury Gay Space Communism.

The most ardent advocate for FALC, Aaron Bastani, a London-based media executive and writer, has written a new book on the topic. In it, he advances a curious, passionate argument, with a dire assessment of the present and a messianic vision for the future. Bastani believes that we are already living through a potentially epochal transformation of the economy, as epochal as the establishment of agriculture and the introduction of engines and electricity. Artificial intelligence, machine learning, and advanced computing might be about to eliminate the need for human labor in no small part, Bastani claims.

That could mean the continued ruination of the planet, as oligarchs throw thought conferences on yachts and the masses struggle to make rent. Or it could mean the healing of the planet and the thriving of all its inhabitants. What it might take is converting the world to solar and other renewable forms of energy, mining asteroids for raw materials, implementing Communist political systems, and guaranteeing everyone basic services. Enter utopia—a healthy world and an economy of abundance, free and accessible to all.

Bastani is certain about the viability of all of this, yet has a topsy-turvy understanding of recent history and the contemporary economy. He fails to give capitalism much credit for moving billions of lives out of poverty, for instance, and fails to recognize the preeminence of race and racism in explaining the success of President Donald Trump or Europe’s far right. He has a long argument with Francis Fukuyama, underpants-gnomes away the political difficulty of what he describes, and seems awfully sure about the potential of space mining. But the vision is compelling and the terminology is useful.

Not that the vision is a new one. John Maynard Keynes’s famous essay “Economic Possibilities for Our Grandchildren” imagines a world with far less work and far more leisure; Shulamith Firestone wrote about “cybernetic communism.” Yet the most complete picture of FALC or FALGSC might come not from radical leftists or academic economists, but from Star Trek. In that imagined universe, replicators produce physical goods and artificial intelligence takes care of services. There is no need for money, no need for work, and no problems with resource competition. People do what they want.

Living on the USS Enterprise, visiting far-flung planets, going on adventures with your friends while wearing a modular outfit and a cute pin: Now that’s Fully Automated Luxury Communism. (Where does the “Gay Space” part come from? Who knows, though here’s one answer: “Gay and space were added because of the tolerance the communist movement has on sexuality and space because space is fucking cool.”)

Maybe FALC is best understood not so much as a diagnosis of the present or a prediction of the future but as a kind of guide star. Many of the world’s richest countries already guarantee citizens their basic needs. Saving the planet by promoting a complete conversion to renewable fuels is possible and necessary. More progressive, redistributive forms of politics are becoming more popular, arguments for full-fat communism aside. And advanced, mind-bending technologies are already here.

Perhaps the most radical part of the FALC ideology is an emphasis on eliminating labor for the good of humans, rather than fearing the obsolescence of human work. Humans in rich societies could and arguably should work far less than they do, and might thrive far more if they did, FALC argues. There is no need for the world to look like Star Trek for that to become reality.



In 1926, after giving a lecture on literature, Gertrude Stein was asked, “What about the woman issue?” She replied, dryly enough to start a forest fire, “Not everything can be about everything.”

The ousting of Ronald Sullivan, the first black faculty dean to preside over a dorm at Harvard, is one of those scandals that aspires to be about everything, and in the process becomes about nothing at all. Last Friday, Sullivan lost or gave up two separate jobs: his deanship of Winthrop House, and his legal representation of the alleged rapist and potted-plant ejaculator Harvey Weinstein. Sullivan, one of the nation’s preeminent criminal-defense attorneys, had struggled to keep these jobs simultaneously while also pleasing a faction of Harvard students who detested Weinstein and held his lawyer to account for his client’s misbehavior.

I am reliably informed that the broader American public cares about as much about Harvard scandals as Harvard alumni care about scandals at Boise State. But let us count the ways this contretemps strummed chords on the country’s cultural conscience:

This is a feast of grievance, with all courses served at once, and competing to be the main. Would any of these issues individually make the Sullivan affair the subject of national news? I doubt it. And now reports suggest the affair was even less than it seemed. Last week, just before Harvard chose to fire Sullivan from his deanship, The Harvard Crimson ran a long, innuendo-driven piece that suggested that at least some of the animus toward Sullivan was due to workplace conflicts of a less zeitgeist-y nature. Some of his subordinates thought he had it in for them; some probably had grudges of their own. Sullivan cycled through managerial staff at an alarming pace, and he allegedly asked them to do personal tasks for him, such as grocery trips. These kinds of workplace problems usually get one hated but not fired.

My view is that Harvard treated Sullivan shabbily, and I agree with the reasons articulated by Randall Kennedy, former Harvard Dean Harry Lewis, and my colleague Conor Friedersdorf. But I also see the Sullivan affair as illustrative of how these episodes, which are so fraught with cultural meaning, end up contributing next to nothing to the underlying issues that everyone desperately wants them to illuminate.

Even if you grant, as I do, that anyone accused of a crime is entitled to competent defense, there is ample reason to wonder whether Sullivan’s deanship fit easily with his defense of Weinstein in particular. Lawyers exempt themselves for conflicts much less than this one. Sullivan, as an officer of Harvard, would presumably have had to represent, defend, and execute the policies of a modern university—including policies that are inconsistent with due process for accused sex criminals. (Whether these policies are wise is another matter; until he recused himself, Sullivan had to follow them, and as a residential supervisor, was likely to be involved in their implementation.) Imagine if he were arguing a major case about land use, on the side of the city of Cambridge. Would he have to resign from the chairmanship of his homeowner’s association? Probably.

But of course the Sullivan affair had to be about Weinstein’s civil rights, or about fragile or obtuse college students. Or maybe race. Everyone has a pet issue—except that the issues are not pets, cuddly friends who curl up loyally at the foot of your bed. They are obsessions, less like pets than like drug addictions, which get in the way of clear thinking and even self-interest. The Sullivan affair turned out to be complicated, but not so complicated that everyone couldn’t get his hit of the issue that energized him most.

That is why I detect a relieved sigh in the background of the convenient whispers that Sullivan might have been a less-than-ideal boss. As Harry Lewis noted, if he had really been such a bad boss, Harvard could have discovered his incompetence, and even allowed him to step down, without anyone having to know that his competence was the reason. But what immaculate grace for the university, to have reasons emerge for his termination that feed the addictions of no one in particular, and enable Harvard to say it caved neither to student activists, nor to the pervert-defender they abhor! (Sullivan, for his part, adduced a similarly bland reason for withdrawing from Weinstein’s defense: not that it was a conflict of interest, but that it was a conflict of schedules. He had classes to teach.)

The addicts make themselves vulnerable to this sort of maneuver: If you apply your issue to just any situation, you have to prepare for the situation to change, or be changed cynically, in a way that thwarts its enlistment in your cause. Similarly, as Wesley Yang pointed out, Sullivan made himself vulnerable to the addicts. If you’re a boss whose leadership brings about factionalization, the faction that hates you will enlist activists to bring you down as soon as you show weakness. Ditto about the cynicism.

The longest-serving faculty dean of a Harvard house was John H. Finley Jr., a tweedy classicist who served as master, as they were then called, of Eliot House from 1941 to 1968, during its single-sex heyday as an incubator of preppies. It is possible to feel nostalgia for aspects of university life without wishing for the restoration of the era in its morally deficient entirety. (Sullivan’s students may seem brittle, but one of Finley’s was the Unabomber, class of 1962.) Finley wrote letters of recommendation for every student under his watch—an onus no faculty dean today would be willing to undertake, and that in any case he could bear only because of the Olympian status professors then enjoyed. I doubt a faculty dean whose relationship with students was potentially adversarial would be able to do the same. Finley’s New York Times obituary quotes him as saying the purpose of Harvard was to “reduce the time [students] spent thinking about women from 80 percent to 60 percent,” and to fill the extra minutes with a little more of the Iliad, or of organic chemistry. In other words: to retreat from the distractions and complexities of social life, and to embrace the complexities of intellectual life. Quaint as this sounds to our modern ears, I wonder whether the era of the Sullivan affair, where social life is burdened with maximum complication and intellectual life is simplified for activist purposes, is any better.



The phone sits in the drink holster, next to the gear stick. I want Jack Dorsey’s dopamine hit as bad as a morning cup of coffee. But my daughters are in the back seat, so even at a red light I resist the impulse, and it passes. We’re on our way to a soccer tournament beyond exurbia. There’s no traffic, and all thoughts of politics slip from my conscious mind.

At a gas-station break, the phone emerges from the holster. A notification from The New York Times announces another synagogue shooting, this time in California. I look at my daughters in the car, with their ponytailed heads leaning against the windows. I walk into the station’s store and mindlessly buy junk food, taking my time and hoping that my fury will subside before I return to the wheel.

My daughters, who can’t see my face, have no inkling about the jolt of news. But I go silent, vacating the conversation, except for the fretful one taking place in my head. My mind turns over the memory of first learning about white supremacy, at age 7.

The bracing images arrived at my home in the form of a solicitation letter from the ACLU, an admittedly luxurious way to encounter American racial terror. The thick card, with pale-blue text, featured a black-and-white picture of a robed Klansman, an apparition sprung to life, sitting on a chair, holding a backwards American flag over his knees. My father was always matter-of-fact about evil’s existence in the world, and he explained that the Ku Klux Klan hated blacks and Jews, which meant people like us.

That week, my parents let me join them to watch a few minutes of a TV miniseries starring Muhammad Ali. The Greatest played a Union soldier who returns home to South Carolina after the Civil War. I don’t remember anything about the plot, which, according to Wikipedia, wends through the span of Reconstruction. But in the nights that followed our viewing, I would lie in bed replaying the film’s scene of a cross burning in the dark, until I would call for my mother. She would soothe me: We live in an urban fortress that the haters wouldn’t dare invade. Her words might not have survived a sociologist’s scrutiny, but they calmed my nerves.

As I remembered her promise, I thought about how I couldn’t credibly issue the same assurances to my own children. The haters had already invaded my family’s spaces. Inspired by crazed theories fomented on social media, an armed man from North Carolina drove to our favorite pizza joint—a place where the girls have gone to birthday parties and team dinners—and fired three shots, before surrendering to the police. This past weekend, a small group of white supremacists disrupted an author’s reading at Politics and Prose, our local bookstore. I watched footage of the young goons parading through the aisle where I browse recent nonfiction, shouting “This land is our land.” They were laying claim to the place where I take work breaks in the middle of the day, where my children have favorite corners for flipping through stacks of potential purchases.

Isolated paroxysms of hatred can be more easily scrubbed from worry. But the shooting in Pittsburgh was followed by the one in Poway, and prudence has dictated new precautions. After the Tree of Life massacre, my synagogue installed banks of metal detectors at every entrance. My kids pass through them on the way to Hebrew school. Communal celebrations require first emptying one’s pockets and a hand probing the tallit bag. Even in the most familiar of settings—the place where we celebrate bat mitzvahs and remember the dead—security officers must very politely assess whether we pose a threat.

Anxiety is the mind’s alert system, a mechanism guarding against the possibility that terrible things will repeat. Anxiety can linger in physical spaces long after the threat recedes, perhaps never really fading. What makes this fact so bitter is that these confines were designed for contemplation and vulnerability, and they now carry an association with harm. The mental toll of an era—of a presidency incapable of mustering opprobrium for neo-Nazis—has woven itself into the quotidian.

That night, after the long drive, we settle into a hotel room. Exhausted kids quickly fall asleep, despite the glow of my phone. I’m unable to escape the endless feed, even though I know that it will make it impossible for my own eyes to close.



As our political discourse generates derision and dissension, our time in the virtual world crowds out our time in the actual one, and trust in our institutions and one another has plummeted, local places such as markets, libraries, and coffee shops can help. A new study shows that living near community-oriented public and commercial spaces brings a host of social benefits, such as increased trust, decreased loneliness, and a stronger sense of attachment to where we live.

Americans who live in communities with a rich array of neighborhood amenities are twice as likely to talk daily with their neighbors as those whose neighborhoods have few amenities. More important, given widespread interest in the topic of loneliness in America, people living in amenity-rich communities are much less likely to feel isolated from others, regardless of whether they live in large cities, suburbs, or small towns. Fifty-five percent of Americans living in low-amenity suburbs report a high degree of social isolation, while fewer than one-third of suburbanites in amenity-dense neighborhoods report feeling so isolated.

These new findings are based on a nationally representative survey that measured how closely Americans live to six different types of public and commercial spaces: grocery stores; restaurants, bars, or coffee shops; gyms or fitness centers; movie theaters, bowling alleys, or other entertainment venues; parks or recreation centers; and community centers or libraries. By combining these spaces into a single scale, we were able to identify three distinct community types: high-, moderate-, and low-amenity neighborhoods. Americans in high-amenity communities live on average within walking distance of four of the six types of neighborhood amenities. Americans in moderate-amenity communities are on average no more than a short car trip (five to 15 minutes) away, while low-amenity residents live on average a 15-to-30-minute drive from all six types of amenities.

We found that 23 percent of Americans live in high-amenity communities, close to half (44 percent) live in moderate-amenity communities, and one-third (33 percent) live in low-amenity communities. But more notable is the effect that living near these amenities has on how we relate to our communities and to one another.

While high-amenity residents exhibit a range of more positive social behaviors and attitudes, it’s also true that these communities are geographically and demographically distinct from moderate- and low-amenity communities. High-amenity neighborhoods tend to be more urban and include a greater proportion of white non-Hispanic residents and residents with more formal years of schooling. To fully capture the independent influence of neighborhood amenities, we constructed three statistical models that controlled for these important geographic and demographic differences. The results show that even after taking account of educational background, race and ethnicity, ideology, income, age, and urbanity, people who live closer to neighborhood amenities are more trusting, are less socially isolated, and express greater satisfaction with their community.

For instance, residents in high-amenity urban neighborhoods are twice as likely to say people in their community are “very willing” to help their neighbors compared with urban dwellers in low-amenity areas. High-amenity suburban residents are three times as likely to say the same compared with those in low-amenity suburban areas. High-amenity urbanites and suburbanites are roughly twice as likely as their low-amenity counterparts to say they trust their neighbors a great deal. A similar pattern is evident when it comes to trusting co-workers.

Access to more community-oriented spaces is also associated with increased confidence in local government. Even though we are bitterly divided by politics, and confidence in federal and state governments is in decline, people in vibrant neighborhoods have a greater level of confidence in their local government than those living in amenity-poor places. Americans living closer to neighborhood restaurants, bars, parks, and libraries are nearly twice as likely as those living in places where these things are largely absent to say they trust local government (39 percent versus 22 percent). Having access to neighborhood amenities also correlates with how we think about our capacity to make a difference in politics.

Many of the things that we lament are missing from our political and social life, such as mutual concern, a sense of belonging, and helpfulness, are found in greater degrees in communities that have a sense of place, or at least enough ingredients to make a well-rounded community. Urbanists have consistently found that proximity to core community assets such as grocery stores raise property values. These new data show that proximity has an even wider range of benefits, such that it should increasingly play a role in policy deliberations.

When Tracy Stannard and her business partner reopened the defunct Broad Branch Market in a quiet corner of northwest Washington, D.C., they were not certain how the neighborhood would respond. “We decided to stock only things we like so if we couldn’t sell anything, at least we could eat the food,” says Stannard. But in no time, the market became a central part of community life, serving up hot food, coffee, and ice cream. On Thursday nights, the market hosts live music for children who are omnipresent—the local elementary school sits kitty-corner to the market.

To neighborhood residents, Broad Branch Market is much more than a place to pick up milk. And other communities need the benefits it provides—whether they receive them from libraries or parks or grocery stores. We should factor these important findings about community design into how and where we build our schools, design our local workforce systems, and build more affordable housing. Communities that blend a healthy mix of amenities, such as schools, community centers, and grocery stores, improve our social well-being in ways that our arguments over politics never will.



The fight between President Donald Trump and House Democrats over the House’s investigations of the president has escalated into what several outlets now describe as an “all-out war.” Most commentators believe that House Democrats are powerless in the face of the Trump administration’s defiance. Litigation to enforce congressional subpoenas will stall in the courts, while any attempt to remove Trump from office with impeachment will die in the Senate. Voters are losing their patience with investigations that produce no results. But if the House backs off, Trump will declare victory, and future presidents may conclude that they are immune from oversight. The options for Democrats seem bleak.

House Democrats, however, have an ace up their sleeve. Actually, a pair of aces: the power to shut down the government and the power to trigger a debt default. These options are far more potent than impeachment because the Democrats do not need the support of Republicans to use them. The problem is that the options may be too powerful: If used unwisely, they could hurt the Democrats—and the country—more than Trump. To prevail, the Democrats must play their cards shrewdly.

If they go this route, Democrats will face criticism from commentators who extol the virtues of moderation. Budgetary brinkmanship, after all, is mostly a tactic from the GOP’s playbook—one that congressional Republicans used in the Bill Clinton years and again under Barack Obama. Shouldn’t Democrats play the role of the adult in the room, rather than holding the federal government hostage for short-term advantage?

Here, though, the goal is not to win a policy dispute over health care or taxes. It’s to preserve Congress’s traditional, constitutionally sanctioned role in overseeing the executive—an essential task for countering abuse of executive power regardless of the party identification of the president. And House Democrats would be doing exactly what the Framers envisioned when they assigned to the legislature exclusive authority over borrowing and spending. For the Democrats, the only effective response to the norm-busting aggression of the Trump administration is to bust some norms themselves.

The stakes are high. The Trump team has sought to stymie 20 different congressional inquiries. The conflicts that have drawn the most attention involve subpoenas related to the Mueller report and to Trump’s tax files. But the interbranch battle is about more than any specific document or witness appearance. Without the power to compel testimony and obtain documents, Congress cannot fulfill its role in overseeing the executive.

Congress’s traditional tools to enforce its subpoenas are either symbolic or archaic. Refusing to comply with a congressional subpoena is a federal crime, but no one expects Trump’s Justice Department to prosecute Trump-administration officials for defying Democrat-controlled committees. The House can file a federal lawsuit to enforce a subpoena, but those cases can take years to resolve. In an earlier era, the House might have dispatched its sergeant-at-arms to arrest a subpoena scofflaw, but that option hasn’t been used in more than a half century.

Realistically, the House will not lock any administration official in jail anytime soon. What it can do is force federal agencies to shutter their doors on October 1, when the federal government’s fiscal year 2019 budget expires. Or the House could up the ante and refuse to raise the debt ceiling, in which case the federal government’s fiscal slack will likely run out in September or October. Unless both chambers of Congress vote to lift the debt cap, the United States will default.

Some House Democrats realize they can capitalize on these looming deadlines. Representative Adam Schiff of California suggested last month that House Democrats might tie funding for federal agencies to compliance with congressional subpoenas. A bolder move would be to add the debt ceiling to the pot. House Democrats might tell Trump: Cooperate with reasonable oversight demands, or out go the lights come autumn.

The problem, of course, is that Trump may refuse to give in to the Democrats’ threats. He will know that if the Democrats follow through, the consequences will be felt by ordinary Americans who depend upon government safety-net programs, federal workers who rely on regular paychecks, and savers who will see the value of their Treasury bonds tumble. While voters overwhelmingly faulted Trump—not congressional Democrats—for the last government shutdown, the source of the last shutdown was Trump’s insistence that Congress pay for a border wall that Trump had previously promised Mexico would fund. If they tied these bills to compliance with subpoenas, Democrats might be seen as the instigators.

However, the politics are more favorable to Democrats than they might seem at first sight. House Democrats, more so than Trump, would face significant political costs if they entered a budget showdown and then folded. Many of their members—especially from solidly blue districts—could face tough primary races if they bowed to the president. The ghost of Joe Crowley, the Queens congressman deposed by Alexandria Ocasio-Cortez in a 2018 Democratic primary, looms large. Trump, meanwhile, has the Republican Party in a stranglehold and faces no credible primary challenge. Both sides know that if Trump blinks, most of his base will forgive him.

House Democrats and the president also face different constraints from their donors. If Democrats are seen as soft on Trump, the spigot of campaign cash from contributors such as the billionaire Tom Steyer may be turned off—or start to flow against them. The last thing Republican funders want is for budget gridlock to unsettle markets. And if there is any lesson from the last shutdown, it’s that Trump will cave once an impasse inconveniences his biggest financial backers. What brought Trump to the table in January was a stoppage at LaGuardia, the airport closest to Wall Street.

And Trump—as an incumbent president—is the one whose political fortunes are most closely tied to the overall economy. If a shutdown or default slows growth, or sends the stock market into a tailspin, Trump’s biggest electoral advantage entering 2020 will be lost. While he will blame the Democrats, voters tend to blame the president for adverse economic conditions.

Finally, Democrats may get an assist from Trump, who announced last December that he was “proud to shut down the government.” His bravado helped ensure that he took the blame. This time, he has already said that “if there is going to be peace and legislation, there cannot be war and investigation,” an idea he amplified by blowing up last week’s meeting with top Democrats on infrastructure legislation. And yet he left himself room for maneuver—dodging a question last week from a reporter who asked Trump whether he would refuse to sign budget and debt bills if Congress continued its investigations.

All this offers a path forward for the Democrats. The key, for them, is to make clear that congressional oversight is an established part of the American system that Trump seeks to overthrow, and to tie themselves to this mast—insisting they have no choice but to withhold funds and authorizations until the president cooperates with the investigations. And by laying out their demands for subpoena compliance early and building support among their voters and their donors, Democrats can put themselves in a position where backing down at a late date is more politically costly than following through.

If Trump recognizes that Democrats are committed to their course of action, he may see that his options have narrowed: Comply with their subpoenas or else brace for a shutdown, or an even more devastating debt default. At that point, backroom negotiations could lead to a face-saving compromise in which Congress’s oversight powers are recognized and preserved.

It is, no doubt, a risky gamble. But the alternative—allowing the president to evade congressional oversight entirely—is even riskier. House Democrats hold the better hand in this game of constitutional poker. But they can’t win the game unless they play their best cards.



Updated at 4:47 p.m. ET on May 15, 2019.

We first met almost 30 years ago, right after the Berlin Wall came down, at a meeting of dissidents held in France’s embassy in Budapest.

President François Mitterrand had asked me to prepare a report on how France could contribute to the reconstruction of the countries of Central Europe after the lifting of the Communist yoke.

At the time, Viktor Orbán was one of the brightest figures in the victorious opposition to the Soviet order. He was the young author of a master’s thesis on the Polish Solidarity movement, which he had written while attending Oxford with the help of a grant from George Soros. He had become famous overnight following a speech he had given in Heroes’ Square in Budapest honoring Imre Nagy, the martyr of the Hungarian uprising of 1956.

And now, April 10, here he is transformed by the intervening 30 years: a pudgy satrap with the physique of a retired wrestler, Vladimir Putin without the muscles, with something sad and somber in his look—all accompanied by an odd reserve, bordering on shyness, that he did not have before. That reserve comes out as he greets my friend Gilles Hertzog, who helps me take notes, extending a tentative hand and murmuring, “Good morning, my name is Viktor Orbán. Welcome to Budapest.”

We are in the library of the former Carmelite monastery in the Buda Castle district, its walls lined with religious books, into which Orbán has just moved his offices. This I learn from Hungary’s ambassador to France, György Károly. He has traveled from Paris for the express purpose of attending our interview, which we conducted in English.

Because I am preoccupied with memories and am reluctant to ask Orbán right at the start how a former anti-totalitarian militant discovered conservatism and ultranationalism on his way to Damascus (or rather Moscow), or how the recipient of a Soros grant was able to make his former mentor public enemy No. 1 (with Soros’s caricature plastered all over the streets of the capital a while back), and because I did not wish to begin with the mystery of a true dissident who somehow relearned the Stalinist technique of retrospective reinvention of biographies (in this case, it is his own memory that he is purging), I begin benignly with a polite question, simply to buy myself a little time to let everything settle in.

“Why did you choose this monastery? Why such an austere site?”

But his response is curiously intense and sets the conversation in motion.

“Because my old offices were in the Parliament building down the hill on the other side of the Danube, and that wasn’t good from the point of view of the separation of powers.”

He would have been more truthful had he said, Because I wanted to dominate this town, which is the only part of the country that is still resisting me.

But no.

The inventor of illiberalism, the man who uses democracy to torpedo democracy, the autocrat constantly engaged in gagging the Hungarian Parliament, bringing judges to heel, and controlling the media, tells me baldly that he left his former offices out of concern for democratic processes.

I let it go.

I have no idea, at the moment, how much time he is going to give me.

I have no idea that Hungary’s free press is going to observe, the next morning, that I spent with him, in the course of an afternoon, more time than they, collectively, have spent with him in nine years of demotatorship—a term I use to mean a democratic dictatorship. So I prefer to push on.

“You have become the leader, in Europe, of the illiberal strain of demotatorship—”

The term illiberal seems to take him aback.

“Let me stop you there. Because we should agree on our terms. What is the reality? Liberalism gave rise to political correctness—that is, to a form of totalitarianism, which is the opposite of democracy. That’s why I believe that illiberalism restores true freedom, true democracy.”

This time, I feel obliged to tell him how specious I find this line of reasoning.

And I recount to him some of the infringements of the spirit of democracy that I had learned about a few hours earlier, at an NGO meeting organized for my benefit: shuttered newspapers; starving migrants; prison sentences for individuals aiding asylum seekers; the Central European University—known as George Soros University—forced to have its degrees validated in Vienna; homeless people arrested and fined; judges operating under orders; and so on.

He listens without interrupting, his mien subdued and sad looking. With one exception, which occurs when I raise the case of Gábor Iványi, a sort of people’s priest who took part in the NGO meeting and founded the Hungarian Evangelical Fellowship, a haven for the homeless and the rare migrants who have succeeded in penetrating the barbed wire of the new iron curtain that Orbán has installed on Hungary’s borders. By revoking the fellowship’s church status, the regime has choked off its funding.

“I know Iványi well,” he interrupted me. “He baptized two of my children. But it was a decision by the Parliament, which is absolutely responsible for church affairs. Moreover …”

He hesitates, seeming to search for words.

“Moreover, he called me a fascist. And that is the only thing for which I cannot forgive him.”

I push on.

“So—you are the leader, however you may define it, of the illiberal trend in Europe. Is that an accurate description? Do you accept the role?”

“Yes and no.”

Again the modest, almost fearful face, which squares badly with the idea most of us have of the big bad Orbán.

“Because of the attacks to which you’re subjected?”

He smiles.

“I don’t give a damn about the attacks,” he says. “Hungary is a special country, you know. It is the only country in Europe whose language is absolutely incomprehensible to a foreigner. And, you know, that poorly understood side suits me fine.”

“Which means what?”

“Which means that I find the mantle of leader of the movement a little heavy. Because Hungary is also a small country, don’t forget. And it has neither the ambition nor the means to assume leadership.”

He is sitting squarely in his armchair, his torso bent slightly over the little wooden table that separates us. Is he sincere? The European People’s Party recently suspended the membership of Orbán’s party, Fidesz.* Is that what has him backpedaling? Did he feel the bullet whistling by and get spooked? I press him.

“Do you mean to say that the press is wrong to characterize the upcoming European elections as an Orbán–[Emmanuel] Macron matchup?”

At this, he laughs out loud and, turning to Ambassador Károly (Károly uttered not one word during our conversation, but on several occasions, Orbán spoke to him, as if there was something about the old-school aristocrat that impressed him), scoffs:

“Orbán–Macron … Orbán–Macron …”

“You detest Macron that much?”

“Not at all. I have a good personal relationship with him. I just think he’s too intellectual for the profession we’re in.”

“So?”

“So, I already have too much on my hands with my own country, which, like all small countries, is fragile and threatened. For the match you mention, I’d prefer to see somebody else carry the torch.”

“Are you thinking of Marine Le Pen?”

Hearing this, he stiffens, and his laughter disappears.

“Absolutely not! I have nothing at all to do with Madame Le Pen. Nothing.”

“Why not?”

“Because Laurent Wauquiez warned me that she was a red line.”

“Laurent Wauquiez?”

“A friend of mine. I have a lot of friends in France, you know.”

“Such as?”

He gestures as if listing them.

“Nicolas Sarkozy, of course. Jacques Chirac, who has always greeted me very warmly. And Valéry Giscard d’Estaing, a touchstone, whom I try to see whenever I’m in Paris.”

But I come back to Le Pen.

“Do you mean to suggest that if these French friends weren’t cautioning you, you would seek an alliance with Marine Le Pen?”

His response bursts forth without any hesitation.

“No. I would not ally with her even so.”

“Once again, why not?”

“Because she’s not in power.”

It is my turn to be startled.

“When political leaders are out of power, they can say and do anything they like. They can slip out of control. I don’t want to get mixed up with any of that.”

“So who, then? If you’re not the champion, and neither is Marine Le Pen, who’s left?”

He answers without missing a beat, as if he had pondered the question at length and long ago decided on his position.

“Matteo Salvini. He leads a large country. Europe can sanction a little country like Hungary. It wouldn’t dare go after a country like Italy, with 60 million people. Moreover, Italy has a powerful voice. It is standing firm against the migrants—manning the front line.”

He utters “front line” with a hint of grandiloquence, as if the tragedy of the migrants were a war of aggression against Hungary. I ask him if he is not sounding a bit like the anti-Semites who, after the war—the real one, the one that saw the near-extermination of Europe’s Jews—remained anti-Semites, while the Jews were nearly all dead or departed.

He cuts me off.

“You can’t talk like that. I have the best relations in the world with Israel.”

“Fine. But with Jews?”

“The same. Let me tell you something. There was a time in Hungary’s history when we didn’t have enough farm labor and had to bring in Czechs, Ruthenians, Roma, and so on. So that by the middle of the 19th century, the Magyars were becoming a minority. And do you know how we settled that? Through a grand alliance between Magyars and Jews, which together made up a little more than 50 percent of the population.”

He speaks of this alliance in the manner of a captain of industry describing a shift in the majority of the board of directors. And when I ask him about the source of the Magyar strain of anti-Semitism, which was, after all, one of Europe’s deadliest, he counters with this astonishing response.

“Béla Kun.”

Kun was a Lenin ally who, in 1918, founded the short-lived Hungarian Soviet Republic.

“Yes,” he insists. “Béla Kun. The Jews played a large role—an unfortunate fact, but a fact nonetheless—in his abortive attempt at a Communist revolution. And that is what undid the fine alliance in Budapest between the Jewish and Magyar people.”

Is he aware that, by equating the terms Jew and Bolshevik, he is reprising one of the major themes of 20th-century anti-Semitic propaganda?

I tell him that one of the participants in this morning’s NGO meeting had informed me that Maria Schmidt, whom Orbán appointed to direct Hungary’s Holocaust museum, had been singing the praises of Regent Miklós Horthy, who hung around with Hitler from 1933 to 1944.

Again, he cuts me off.

“Stop right there. I, Viktor Orbán, would be the first to praise Regent Horthy. He is a part of Hungary’s history. We have him to thank for ridding us of Béla Kun.”

“Granted. But afterwards? Isn’t he also the one who, in March 1944, when the Nazis were invading Hungary, let them in and allowed them to begin deporting Jews?”

My interlocutor assumes an air of contrition. Fleetingly, a bit of the young dissident of long ago returns to his features, now heavier with age.

“Yes, that’s true. He should have left at that point.”

But I return to the question of the migrants.

“What I meant to convey to you on the subject of the migrants is that there has been, at certain times, a sort of anti-Semitism without Jews. Hungary seems to harbor anti-migrant hatred even though it’s hard to find one on the streets of Budapest.”

“Don’t kid yourself! We had migrants. In 2015. When Angela Merkel opened the doors to them. It was a flood, a tsunami.”

“You know full well that they didn’t stay.”

“That’s true. But they could come back. That’s the rule in the European Union. A migrant always has the right to return to the place where he entered the Schengen Area. And you have to understand something: Hungary has always been a land of passage; everybody, absolutely everybody, has traipsed through here. I have no desire for that to start up again.”

He concedes that the right of return is valid for only six months and that, as a result, any risk of a “reverse tsunami” is slight.

He also concedes that the former Orbán had lauded Hungary for serving as an escape route for East Germans seeking refuge in the West.

And that the Hungary of 1956, the Hungary that saw 180,000 of its own welcomed in Austria after the insurrection was put down, had benefited from the right of asylum. This point, however, he concedes only partially, clarifying that the 150,000 defeated insurgents were initially “parked in camps” by the Austrians.

At that point, he hits back hard against Merkel.

“The chancellor is very nice,” he begins. “And I understand that she has a problem with demographics and labor. But why should we Hungarians have to pay to solve her problem?”

And he hits back harder still against the migratory phenomenon in general. “Europe’s problem is Islam. And on the rise of Islam, what can I say? It is Christianity that has resisted that rise. Christianity is still resisting it. Hungary is today, as it has been, the forward post of European Christianity.”

Does he seek to distance his country from the Europe that he describes as serving the interests of Germany and living under threat of a “great replacement”?

He reacts strongly, thinking, I imagine, of the billions of euros in European structural funds that have allowed Hungary to build highways and restore the domes, bridges, and palaces that have made Budapest the Nineveh of Central Europe, nestled voluptuously on the Danube.

“Absolutely not! Because, as I told you, I am the most Christian, and thus the most European, of Europeans. Europe’s DNA is me. I am its guardian.”

“Even if the pope does not agree with you and continues to reaffirm the duty to welcome and shelter migrants?”

Silence.

For the second time, as with the suspension of Fidesz from the European Parliament, I sense that he feels anxious and unsure of himself.

“Yes, that is awkward. Especially since the pope is due to visit Budapest. But having shouldered my pilgrim’s burden, I go, several times a week, unaccompanied by journalists or anyone else, to explain my position to Catholics. Now, pay close attention to this.”

His animal side has returned quickly to the fore.

“Our partners have to realize that the Hungarians are an ancient people, free and proud, who will not be lectured to. We were occupied by the Ottomans. By the Slavs. By the Communists. We didn’t go through this so we could fall under the thumb of Brussels.”

I object that Brussels cannot be compared to an occupying army.

From there I move quickly to the two real powers that have weighed on Hungary’s history, and with whose successors he seems to find common ground.

“Are you referring to [Turkish President Recep Tayyip] Erdoğan?” he asks.

“To name one.”

“It’s complicated with Erdoğan. As it was with Silvio Berlusconi. Very few people are aware of my personal relationship with Silvio Berlusconi. Are you?”

“I don’t believe so.”

“One day in the early 1990s, I get a phone call. He’s on the other end of the line. I had never heard of him before. But he invites me to an A.C. Milan match. At the time, he was thinking about starting up Forza Italia. He wanted me to come tell him how I’d done it with Fidesz. So there I was, at 30, tutoring the future prime minister of Italy!”

“And Erdoğan?”

“There is something you have to know about Erdoğan. He’s a big soccer fan, like me. And soccer fans share a trait. They have a muscle here, in the lower back …”

He leans out of his chair a little, as if to show me his lower back.

“And that’s what Erdoğan and I did the first time we met. We touched each other’s lower back—and recognized a fellow fan.”

“Okay. But what about the Hungary that you’ve described as a small, fragile nation threatened by—”

He doubled down.

“It’s a miracle! That’s what you have to understand. Hungary is not a nation; it’s a miracle!”

“Let’s call it a miracle. Shouldn’t this miracle be all the more mistrustful of the Ottoman imperialism that is galloping back in Ankara?”

“Yes, of course. But once again, pay attention …” He gestures toward the shelves of the library in which he closets himself every Thursday. “Scholars have made a lot of progress. Especially the linguists working on the Finno-Ugric matrix from which the Turkish and Magyar languages are derived. I mean to say that our two nations have a past that is what it is, but we are also cousins.”

No serious scholar puts any stock in the hazy theory that is known in Ankara as Pan-Turanianism. But it seems to meet the needs of Viktor Orbán.

I push on.

“And Russia?”

“Russia is a big country.”

“I know.”

“It is a big country located very close to us—only Ukraine separates us.”

“I am aware of that as well.”

“I mean to imply that we must be careful. Very careful. We must support Ukraine, since it is the main bulwark between us and the Russians. At the same time, we must not provoke Putin. And that is why I oppose the European Union’s sanctions against him.”

“Even to the point of granting quasi-diplomatic status to the Russian investment bank that set up in Budapest in March?”

For the first time since the beginning of the interview, he seems on the point of losing his temper.

“First of all, it’s not a Russian bank.” He gestures as if counting on his fingers and again assumes the expression he had when listing his French friends or explaining that the alliance of Jews and Magyars had yielded a majority. “The bank to which you refer is called the International Investment Bank. Fifty-one percent of its capital is held by non-Russians. And, frankly, the Europeans, ah, the Europeans … ”

“Yes?”

“The Europeans are being incredibly hypocritical. On the one hand, they lecture us. On the other hand, I wasn’t the one, at least as far as I know, who launched the Nord Stream 2 project that puts you at the mercy of Russian gas.”

I think of what is rumored in Budapest about Orbán’s business ties with Putin and the Kremlin.

And I think of what I am going to say on a Budapest stage in a couple of hours about this real-world Luke Skywalker who may have gone over to the dark side of the Force, become the puppet of the oligarchs’ empire, and made his old friend Lőrinc Mészáros the richest man in the world in the same way Caligula made his horse a senator.

Strangely, I feel less sure of all that than I had been.

I have trouble believing that his speech about crusading Christianity masks deal-making opportunism.

I am more inclined to believe, ultimately, in an absurd form of sincerity on his part—no less sincere for being absurd.

Horthy, whom he admires, was an admiral in a country without an outlet to the sea and regent of a nation without a king.

Viktor Orbán, the would-be herald of Christian values criticized continually by the pope; the critic of a European Union that he sees more as a prison for distinctive peoples than as a source of billions in annual subsidies and aid; the sovereignist fascinated by Putin; the artisan of the renewal of the Hungarian soul whose pro-Russian stance leaves the people possessing that soul as no more than pawns in the game of the new Radetzkys who intend to carve Europe up from Moscow—yes, it may be that man is, making due allowance for differences, a new Horthy embodying a similar absurdity.

The interview is nearing its end.

He leads us out onto the terrace overlooking the Danube, inviting my cameraman to follow us.

I am reminded once again of the courageous dissident of 30 years ago.

And then, suddenly, as if reading my thoughts—or perhaps noticing for the first time the badge I am wearing from the university supported by George Soros, which he wants to shutter—he asks me if I am in contact with Soros.

I respond that I count him as a friend.

Almost timidly, he asks me how he is.

And when I, in turn, ask him, in front of the camera, if he might have a message for his former mentor, he responds not once, but twice: “I wish him good health and good luck.”

One last time I see the Oxford student who shed hot tears before Imre Nagy’s empty tomb on Heroes’ Square.

I glimpse the once-young man who, today, devotes his energy to running his rosebud over the head of his former benefactor.

And I would swear that at that instant, the man who is the enemy of Soros, of myself, and of every democrat struggling against populism, the man who killed the young person inside and is probably a lost cause as far as the truth is concerned, experiences a vision of the path he did not take and the life he did not lead.

Of course, I cannot be sure.

* This article originally stated that Orbán’s party, Fidesz, was suspended from voting in the European Parliament. In fact, it was suspended from membership in the European People’s Party. 



When Recep Erdoğan was first elected prime minister of Turkey, in 2003, he vowed to respect the country’s democratic institutions, and to vacate office if he ever lost the public’s trust. The reality of Erdoğan’s rule has been rather more bleak. Although international newspapers and magazines initially portrayed him as a democratic reformer, he systematically expanded his powers and purged opponents from top positions in the army, the civil service, and the country’s educational institutions. When former allies tried to oust him in a coup in the summer of 2016, he used the occasion to consolidate his hold over the country. Thanks to the vast emergency powers he claimed within days of the failed putsch, he was able to dismiss tens of thousands of civil servants he considered politically unreliable, and to jail some of the country’s most prominent journalists.

But even as the dictatorial nature of Erdoğan’s regime became apparent, and the freedom to criticize him more constrained, Turkey continued to hold multi-party elections, which gave the opposition some ability to compete at the ballot box. In June 2018, Erdoğan won 53 percent of the vote in an election many observers said was tainted by violent attacks on the opposition; from then on, Erdoğan styled himself president of Turkey.

This election seemed to allow Erdoğan to eat his cake and have it too: On the one hand, the control he exerted over key institutions, such as the country’s electoral commission, had limited the risk the election posed to his rule. On the other hand, the election helped to shore up his legitimacy at home and abroad. Even though observers from the OSCE to Freedom House emphasized that the election was not free and fair, international leaders including Angela Merkel and Donald Trump publicly congratulated Erdoğan on his “victory” at the polls. As Timur Kuran, a Turkish expert on authoritarian regimes, put it, Erdoğan sought to combine “the illusion of a contested election” with “a predetermined outcome.”

The tremendous power Erdoğan now holds makes it all the more remarkable that a united opposition was, last month, able to gain an unexpected set of victories in the country’s municipal elections: Exploiting anger at Turkey’s growing economic crisis, and fielding a new crop of candidates who are both charismatic and conciliatory, the opposition pulled off two highly symbolic upsets, winning control of the country’s capital, Ankara, as well as its largest city, Istanbul.

As a result, Erdoğan has, for the first time since the failed coup three years ago, faced a real trade-off: Would he allow the election results to stand, thereby acknowledging the public’s growing discontent with his rule? Or would he exploit his hold over Turkey’s institutions to have the election annulled, making it blatantly clear to anybody who cared to look that Turkey is no longer a democracy?

For much of the 20th century, the most acute threat to democracy came from the barrel of a gun. When democratic systems collapsed, it was usually because tanks commandeered by the leader of an openly antidemocratic movement rolled up in front of the country’s parliament or presidential palace. Javier Cercas vividly describes such a coup attempt in the opening pages of The Anatomy of a Moment, his account of a failed putsch against Spanish democracy in 1981:

Pistol in hand, Lieutenant Colonel of the Civil Guard Antonio Tejero calmly walks up the steps of the dais, passes behind the Secretary and stands besides the Speaker Landelino Lavilla, who looks at him incredulously. The lieutenant colonel shouts: “Nobody move!”, and a couple of spellbound seconds follow during which nothing happens and no one moves and nothing seems to be going to happen to anyone, except silence … Four nearby shouts, distinct and indisputable, then break the spell: someone shouts: “Silence!:”; someone shouts: “Nobody move!”; someone shouts, “Get down on the floor!”; someone shouts: “Everyone down on the floor!.” The chamber rushes to obey.

Because it makes for such striking theater, the kind of open attack on democracy that Cercas describes has had a long-lasting hold on the political imagination. But in the 21st century, coups have become rarer. From Russia to Venezuela, the strongmen who have destroyed democratic institutions won high office at the ballot box. Far from openly attacking democracy, they have tended to argue that they, and they alone, truly represent the people.

Granted, autocratic regimes from the German “Democratic” Republic to the “Democratic” Republic of Congo also tried to create some illusion of public legitimacy through “elections.” But whatever propagandistic purpose their ballot dramas may have served, they were far too ham-fisted to fool a domestic audience. By and large, only a single party was allowed to present itself in elections, which usually ended with 99 percent of the voting public expressing its deep devotion to the dictator.

By contrast, the new crop of authoritarian leaders is much more invested in retaining the appearance of a genuine democratic mandate. As a result, they have to engage in a more complicated political calculus: They have to give the opposition enough of a chance to compete in the elections to look credible to a significant segment of the population. But they must also capture political institutions such as electoral commissions to a sufficient extent to ensure that the people can’t actually boot them out of office.

As the recent developments in Turkey show, however, it may not be possible to sustain this equilibrium forever. Eventually, even governments that have effectively abolished the freedom of the press risk growing so unpopular that they have to resort to more blatant ways of rigging the vote.

“We are thirsty for democracy,” Ekrem İmamoğlu told a downcast crowd three weeks after being elected mayor of Istanbul. “No one can stop what the people want.”

But by the time he held his inspiring speech, İmamoğlu knew all too well that, at least for the time being, Erdoğan already had. After using his control over most of the country’s media to spread the insane conspiracy theory that a powerless opposition had somehow been able to falsify the outcome of the election, Erdoğan went on to use his control over the country’s judiciary to cancel its result. Citing supposed irregularities, the electoral commission announced on Monday that Istanbul would hold new elections in June.

The announcement marks a fundamental turning point in Turkey’s political history: It is now impossible for any reasonable observer to keep denying reality. A country whose president has the power to annul elections when he doesn’t like their outcome has clearly become a dictatorship. From now on, anybody who still insists on calling Turkey a democracy, or treating its elections as a fair barometer of public opinion, is a liar or a fool.

While the announcement dispels any remaining doubt about the current status of Turkey’s democracy, it also raises big questions about its future. In the next days, İmamoğlu will need to decide whether to boycott the repeat election in June. If he does, he’ll hand Erdoğan the power he craves. If he doesn’t, he’ll lend legitimacy to an election he likely cannot win. If it’s heads, Erdoğan wins. If it’s tails, İmamoğlu loses.

But although Erdoğan is likely to retain control of Istanbul in the short run, he too now faces a much more difficult future. Until now, large segments of the Turkish population believed his professions that he would leave office of his own accord if he ever lost the people’s trust. Even his more obviously repressive moves, such as the jailing of scores of journalists, had a slither of democratic legitimacy: In the wake of the 2016 putsch, some of Erdoğan’s supporters were willing to believe that the writers he decried as “terrorists” really were part of a dangerous plot to unseat the elected government. Now Erdoğan’s insistence that he represents the true will of the people is, even in the ears of his erstwhile supporters, likely to ring hollow.

Erdoğan’s loss of democratic legitimacy does not imply that he is about to lose power. As the long history of dictatorships demonstrates, many people are willing to support a leader who openly opposes democratic institutions—and many autocrats are able to stay in office for years or decades after they have become deeply unpopular. But it does suggest that his rule will, from now on, be based on a much more precarious foundation. With his claim to a popular mandate gone for good, Erdoğan will likely face an even more determined opposition—and need to resort to ever more naked oppression to stay in power.



However alarmist some stories about Noa Pothoven’s death might have been, one should remember that euthanasia of a minor as young as 16 for psychiatric suffering is indeed legal in the Netherlands.

Pothoven, a 17-year-old girl in that country, had struggled with depression, anorexia, and post-traumatic stress disorder, reportedly after being sexually abused at age 11 and raped at 14. She had sought permission for medical euthanasia and announced on Instagram that she intended to die. Her passing on June 3 prompted news stories around the world, their dramatic headlines an implicit rebuke of Dutch assisted-death policies.

In most countries, the debate over physician-assisted suicide has centered on adults in the final stages of incurable physical illnesses. Pothoven’s age and mental illness made her case quite different, which is why the initial English-language news stories on her death sparked such alarm. That uproar subsided when subsequent reports clarified that Pothoven’s euthanasia request had been turned down, and that she had instead died by refusing to eat and drink.

This sad outcome does not, however, show that all is well with the Dutch approach to assisted death—or that fears of a slippery slope are merely alarmist.

I have researched the Netherlands’ experience in detail and written a number of peer-reviewed papers about it. In Dutch usage, the term euthanasia legally covers cases in which medical professionals administer lethal injection and those in which doctors provide drugs that patients ingest to end their life. The Dutch system gives deference to doctors’ expertise; it respects the relationship between an individual doctor and a patient; and it recognizes that mental illness can be painful and debilitating. Yet this system illustrates how priorities that appear logical on their own terms combine, in some cases, to produce disturbing results. A respected Dutch-language medical journal recently reported that an 18-year-old had died via medically assisted suicide for psychiatric problems.

In the United States, debates about physician-assisted suicide are typically couched in terms of patient autonomy. The rationale for the landmark 2002 euthanasia law in the Netherlands, though, was that it codified a legal option for doctors, whose primary duties—to preserve life and to relieve suffering—were thought to conflict in the case of certain anguished patients. In the decades before 2002, a series of court rulings had offered legal protection for Dutch physicians who facilitated patients’ deaths.

Unlike in most other jurisdictions where medically facilitated deaths are legal, the euthanasia law in the Netherlands has no requirement that a patient be close to death. The law’s directives are few and broadly drawn. Aside from obtaining formal consent—a patient’s request must be “informed” and “voluntary and well considered”—the doctor must be “satisfied” that two conditions are met: The patient has “unbearable suffering, without prospect of improvement,” and there is “no reasonable alternative” to address it. The doctor must use the euthanasia medications properly, and she must consult an independent physician—though she is not bound by this outside consultant’s opinion. Indeed, as long as the patient is at least 16, no other person’s consent except the patient’s is mandatory. (Parents of 16- and 17-year-olds are involved in the discussion, but their permission is not required. Patients as young as 12 can seek euthanasia with parental consent. In about 10 cases since 2002, children ages 12 to 17 have received euthanasia; as far as I know, all were for physical illnesses.)

After the patient’s death, the doctors involved submit written reports, which are reviewed by one of five regional review committees consisting of a physician, a lawyer, and a bioethicist. These positions are not full-time jobs, but the five committees handle more than 6,500 cases a year. (In the United States, the per-capita equivalent would be 126,000.) Needless to say, the single physician on each committee cannot be a specialist on every disorder at issue. Over the years, only 0.18 percent of cases have been classified as “due care not met.” The doctor is virtually always right when it comes to euthanasia. Only one doctor has ever been prosecuted for violating the 2002 law.

Until about 2010, the controversial practice of psychiatric euthanasia was rare, despite being permitted since the mid-1990s. Most Dutch psychiatrists—like most other doctors and the Dutch public—disapprove of psychiatric euthanasia. Still, there has been a steady increase, with 83 cases in 2017; the per-capita equivalent in the United States would be about 1,600 cases a year. Unlike euthanasia in general, psychiatric euthanasia is predominantly given to women. Most of these cases involve the End of Life Clinic, a network of facilities affiliated with the largest Dutch euthanasia-advocacy organization. These clinics routinely handle euthanasia requests refused by other doctors. (Noa Pothoven sought euthanasia there but was refused.)

An obvious question arises: How can any physician be sure that any patient with a serious psychiatric disorder, much less an 18-year-old, meets the legal criteria for euthanasia? The short answer is that the law gives considerable weight to their professional judgment.

Compared with cases involving cancer or other terminal illnesses, the application of the eligibility criteria in psychiatric euthanasia depends much more on doctors’ opinions. Psychiatric diagnosis is not based on an objective laboratory or imaging test; generally, it is a more subjective assessment based on standard criteria agreed on by professionals in the field. Some doctors reach conclusions with which other doctors might reasonably disagree. Indeed, an otherwise healthy Dutch woman was euthanized 12 months after her husband’s death for “prolonged grief disorder”—a diagnosis listed in the International Classification of Diseases but not in the Diagnostic and Statistical Manual of Mental Disorders used by psychiatrists and psychologists around the world.

Psychiatric disorders can indeed be chronic, but their prognosis is difficult to predict for a variety of reasons. There is a paucity of relevant, large longitudinal studies. Patients may get better or worse due to psychosocial factors beyond the control of mental-health providers. Also affecting prognoses is the varying quality and availability of mental-health care—which, even in wealthy countries, patients with significant symptoms may not receive. Noa Pothoven and her family had criticized the dearth of care options available in their country for patients like her. Indeed, more than one in five Dutch patients receiving psychiatric euthanasia have not previously been hospitalized; a significant minority with personality disorders did not receive psychotherapy, the staple of treatment for such conditions. When treatments are available, doctors in the Netherlands have the discretion to judge that there are “no alternatives” if patients refuse treatment.

It is not easy to distinguish between a patient who is suicidal and a patient who qualifies for psychiatric euthanasia, because they share many key traits. In some cases, psychiatric euthanasia is simply a highly effective means of suicide, as in the case of a man who attempted suicide, was hospitalized, and then received psychiatric euthanasia.

In the end, one does not need to be a psychiatrist to appreciate how psychiatric disorders, especially when severe enough to lead to euthanasia requests, could interfere with a patient’s ability to make “voluntary and well considered” decisions—especially when that patient is a minor. The basis for concluding that any teenager with a psychiatric disorder has “no prospect of improvement” and “no alternatives” is likely to be uncertain at best.

These concerns, perhaps, are what unsettled people who jumped to conclusions about Noa Pothoven’s case this past week. Knowing how the rules are set up in the Netherlands, one can see how even a minor could be judged by some doctor as eligible for psychiatric euthanasia. But such a judgment, I believe, would be more a reflection of the priorities embedded in the Dutch law than the state of clinical science.  



After the mass shooting at Marjory Stoneman Douglas High School in Parkland, Florida, many survivors became outspoken advocates of gun control. In contrast, Kyle Kashuv became an outspoken advocate of gun rights, appearing on Fox News and speaking at events to young conservatives.

He was set to attend Harvard after a gap year. But the university rescinded its offer, Kashuv announced yesterday, citing a controversy involving racial slurs.

“A few weeks ago, I was made aware of egregious and callous comments classmates and I made privately years ago—when I was 16 years old, months before the shooting—in an attempt to be as extreme and shocking as possible,” he explained on Twitter. “I immediately apologized.” Nevertheless, he said, “former peers & political opponents began contacting Harvard urging them to rescind me.” Upon learning of the controversy, Harvard asked him to explain himself. He replied with a letter that reiterated his previous apology and noted how much he has changed since surviving the massacre with his classmates.

“The Admissions Committee has discussed at length your account of the communications about which we asked, and we appreciated your candor and your expressions or regret for sending them,” Harvard replied. “As you know the Committee takes seriously the qualities of maturity and moral character. After careful consideration the Committee voted to rescind your admission to Harvard College.”

Just like that, America found itself cleaved by another “scissor”—a controversy that seems perfectly calibrated to polarize public opinion.

Coined in the short story “Sort by Controversial,” the term was defined most succinctly by Ross Douthat in the column “The Covington Scissor.” As he put it, a scissor tears people apart “not just by generating disagreement, but by generating total incredulity that somebody could possibly disagree with your interpretation of the controversy, followed by escalating fury and paranoia and polarization, until the debate seems like a completely existential, win-or-perish fight.”

Social media are calibrated to surface these sorts of controversies. They disproportionately focus the public’s attention on that which most divides us.

In this case, the use of racial slurs violates one of the blue tribe’s biggest taboos, and the tribe’s members accurately observe that hypercompetitive Harvard routinely denies applicants for all manner of tiny shortcomings, many of which are less morally objectionable than the behavior revealed in this controversy.

Meanwhile, the red tribe, which feels that cultural elites are biased against it, can’t help but suspect that Kashuv’s skeletons wouldn’t have been unearthed and weaponized if not for his activism, and that Harvard would look past bad behavior from an already admitted student if he wasn’t a straight, white, pro-gun conservative. Its members accurately observe that almost everyone did or said something in private at 16 that doesn’t necessarily reflect on their character years later.

Rather than champion either side, I want to explore how those cleaved by this scissor might proceed in a way that doesn’t exacerbate America’s dangerously corrosive polarization. 

For example: Harvard might conserve the valuable stigma that the college and its defenders want attached to racial slurs, while still alleviating the concerns of its critics, by affirming its desire for ideological diversity among its undergraduates and pledging to replace Kashuv with an openly conservative wait-listed applicant.

“This isn’t about his politics,” it could then credibly announce.

Meanwhile, folks on the other side might recognize that their professed concern about an unforgiving culture has implications that go beyond defending, e.g., conservatives who were revealed to have used abhorrent racial slurs.

Ben Shapiro writes:

There are ex-convicts who, quite properly, have been admitted to Harvard—they earned forgiveness. There are current students who undoubtedly have said things privately that would shock the conscience. There are likely administrators who have said things when they were 16 years old that embarrass them now.

Is the new standard that if you said something on a private message board when you were 16 years old that we should deny you the possibility of a degree at a top college, so long as those who join you on that message board decide to out you?

Perhaps Shapiro could rally conservatives who agree with his assessment to demonstrate that they earnestly want a more forgiving culture, not just to defend their tribe. They could join with liberals to eliminate a strikingly unforgiving policy that harms many hundreds of college-age Americans every year: More than 1,000 students annually lose access to federal financial aid under a draconian policy that makes them ineligible after a narcotics conviction.

Should a 19-year-old lose the ability to pay for college because he was caught smoking a joint or buying magic mushrooms or taking Ecstasy into a music festival?

“Scissors” are so peculiarly divisive precisely because mass reactions on both sides are rooted in some legitimate, widely held concerns. If enough people focus on those concerns while bracketing the features that made the matter polarizing, it’s always possible to blunt the scissor’s edge—to focus on popular, common goals.



Now that it’s summer, I have a suggestion for how parents can grant their wee kiddies the magic of reading by Labor Day: Pick up Siegfried Engelmann’s Teach Your Child to Read in 100 Easy Lessons. My wife and I used it a while ago with our then-4-year-old daughter, and after a mere 20 cozy minutes a night, a little girl who on Memorial Day could recognize on paper only the words no and stop and the names of herself and her family members could, by the time the leaves turned, read simple books.

My wife and I are not unusually diligent teachers. The book worked by, quite simply, showing our daughter, bit by bit, how to sound out the words. That’s it. And yet in the education world, Engelmann’s technique is considered controversial.

Engelmann’s book, which he co-wrote with Phyllis Haddox and Elaine Bruner, was first published in the early 1980s, but it was based on work from the late 1960s. That’s when Engelmann was involved in the government-sponsored Project Follow Through, whose summary report compared nine methods for how to teach reading and tracked results on 75,000 children from kindergarten through third grade. The results, though some critics over the years have rejected them on methodological grounds, were clear: The approach that proved most effective was based on phonics—teaching children how to sound words out, letter by letter, rather than encouraging students to recognize words as single chunks, also called the whole-word system. Specifically, the most successful approach supplemented basic phonics with a tightly scripted format emphasizing repetition and student participation, often dubbed “direct instruction.” As I have previously explained for NPR, the results were especially impressive among poor children, including black ones.

At the preschool at the University of Illinois at Urbana-Champaign that Engelmann ran with the education researcher Carl Bereiter starting in 1964, phonics-based direct instruction helped even 4-year-old kids understand sounds, syllables, and rhyming, so that they entered kindergarten reading as proficiently as 8-year-olds. Nine other sites across the country had comparable results. Direct instruction has boosted student performance in a similar fashion since in Houston in the 1970s, and in Baltimore and Milwaukee in the late 1990s to early 2000s.

In 2001, students in the mostly black Richmond, Virginia, district were scoring abysmally in reading—just less than 40 percent of third-grade students passed the state reading test. Four years later, after the district switched to the direct-instruction method, 74 percent of third graders passed it. By contrast, in 2005 over in wealthy Fairfax County, where teachers scorned the phonics-based-reading instruction method (dismissing it as impersonal “drill and kill” is common), only 59 percent of the county’s black third graders taking that test passed it, despite plush school funding.

One survey found that only 15 percent of classes for elementary-school instructors offer lessons in how to teach direct instruction. Many specialists insist that kids learn to read English better using the whole-word method. The idea is that English spelling is so irregular that it’s inefficient to try to teach kids to link how letters sound to how words are written.

Among education specialists, a school of thought has grown up around the idea, espoused by the psycholinguists Ken Goodman and Frank Smith, that people don’t mentally associate letters with sounds—that real reading is a kind of elegant guesswork that relies on context. But researchers have deep-sixed that notion again and again, as Mark Seidenberg showed a few years back in his marvelous Language at the Speed of Sight.

Some educators also believe that teaching reading in the same way to all kids according to a set program is too mechanical for a diverse student body with differing skills and predilections, and that learning to read should come through “discovery” and “exploration.” This approach is often titled “balanced literacy,” in which teachers present a class with general strategies but nudge students to help one another learn to read in “reading circles” or via engaging texts on their own, with occasional check-ins from the teacher. The general expectation is that students will marvel their way into reading via assorted individual pathways. That sounds good, and kids from book-lined homes can often manage under this system, but again, Engelmann’s method has worked on kids of all backgrounds. It’s designed to.

As Seidenberg describes in his book, nationwide the phonics and whole-word camps have clashed over and over again, such that some districts use one method and some the other, with many alternating between the two. Some, of course, combine the approaches. But given Engelmann’s findings, this back-and-forth is like a pendulum swing among doctors between penicillin and bed rest. Penicillin is clinical and one-size-fits-all; bed rest allows for improvisation and feels right.

My daughter’s public-school teachers when she was 4, thoroughly excellent at what they did, nevertheless told me that the school district didn’t consider kids my daughter’s age “ready” to read. It was time for Engelmann’s book.

The process wasn’t difficult in the least; it was joyful. First came learning some sound-letter correspondences, such as the sound “ih” for i. But especially neat was watching the main jump—from p-i-g to understanding that the letters correspond to sounds that you link together into pig. Under the Engelmann method, children start by uttering the sounds in sequence—“p”, “ih,” “g”—and are then asked to “say it fast,” upon which, after some preliminary squeaks and pops, they get to “pig.”

Next, the book shows them words that rhyme: big, dig, wig. This cues them to the fact that words can differ by just one sound, which is crucial in reinforcing that the “ig” part means “ihg” and not a separate “ih” and then a “g.” The book presents letters with some shortcuts—lines over vowels to indicate the long ones, silent letters printed smaller (we called those the “stupid letters”).

What about those words with irregular spellings? The book dribbles them in slowly but steadily. Many of the most common words are irregular—said, I, have, you—and so kids get lots of practice with them in the reading passages. And so my daughter learned to read, within about the stretch on the calendar it would take to watch all of Sanford and Son at a rate of one episode a day.

Did my daughter, as the child of two hyper-literate people with doctorates, have some kind of leg up? I doubt it. Some kids pick up reading with minimal guidance as early as 3; she wasn’t one of them, nor had she given indication of any impending breakthrough. Besides, Engelmann’s book is designed for kids of average intelligence and has worked with legions of them over the decades.

Get Engelmann’s book and try it—you will watch your child discover the ability to read on your lap, via you carefully teaching her how to do it! Then pass the word on.



Two letters, two numbers.

The email to me, inviting me to dinner, began with two seemingly random letters, followed by two numbers. My assistant was the first one who read the email and was confused.

But I wasn’t. I smiled.

Once upon a time, I didn’t wear any visible rank or insignia, but if a ranger or another special operator saw those two letters and two numbers on a Velcro patch on my sleeve in the middle of the night, or heard those two letters and two numbers over a radio, he wouldn’t have needed to know me personally to know precisely who he was speaking to: an officer, for one, and an officer leading a particular unit. If a firefight started, or if the situation became confused, as situations in Iraq and Afghanistan often did, he could turn to me for guidance: What do we do now, sir?

This is the role of officers. They set the standard. George MacDonald Fraser, in his memoir of the Burma Campaign, wrote, “If you want to know how scared you’ve a right to be, look at the men around you. And if you happen to be a young subaltern, remember that they’re looking at you.”

I replied to my old commander’s email, addressing him by one letter, followed by two numbers, and signing off with the same four-character acronym with which he had ended his email.  

We met a week later for Tex-Mex in San Antonio. One hour became two, and two hours became four, as we put the world to rights.

I had left the Army in 2004. He had gone on to lead a brigade in the worst part of Baghdad during the surge of 2007. His brigade had suffered very heavy casualties. At one point, he told me, following a particularly brutal ambush in which four soldiers had been captured and executed by the enemy, he saw a young noncommissioned officer begin to roughly handle an Iraqi onlooker. In the same moment, though, his sergeant major quickly intervened, pulling the younger soldier away.

My friend didn’t give the moment another thought because the system had worked; something had almost happened, but a leader had intervened before it did. “People ask me how, in that year, we avoided any issues with units or individuals committing atrocities,” he told me. “It’s not a hard question. It was the officers and the noncommissioned officers. They held the line.”

The nation places special faith and trust in the officers and noncommissioned officers it sends into battle. Very young Americans, mostly men, but increasing numbers of women as well, are given life-and-death authority over not only the men and women they lead but also over anyone they come into contact with. I was 23 years of age, not even two years removed from a college classroom, when I was first thrown into combat and told, more or less, to kill the right people and to make sure my men did the same.

The crazy thing is that I felt very well prepared to do just that. The Army had spent years training me for that moment, and it had spent tens of thousands of dollars before that on my university and professional military education.

You hear this a lot from officers: I knew what I was getting into, and I was well prepared for what came next.

Thousands of us, then, some of us now in our 40s and 50s, have led tactical combat units in Iraq and Afghanistan. We have been one of the most isolated occupying armies in history—mostly separated, linguistically and physically, from the men and women whose countries we occupied. Thus the fact that we have done so, over a period spanning an incredible 18 years, with so few incidents of war crimes or other abuses, is remarkable and likely unprecedented in the history of war.

This is also why the very few men and women convicted of committing war crimes—such as the officer pardoned by the president last week—are viewed with such disdain by their peers. You could be forgiven for thinking that “shitbird” is the actual doctrinal term applied to such men and women, such is the frequency with which it is used to describe those who violated their ethical codes and, in cases, the law.

But large parts of the country, and especially large parts of the more reactionary elements in society, do not understand that. Fed a steady diet of 24 and action movies, they think professional military units play out like their personal fantasies: men of righteous violence, forever straining against rules and prohibitions foisted upon them by less noble, more liberal, weaker politicians who can’t understand what it takes to win.      

Since I last left the Pentagon, I have been periodically asked to talk about the war against the Islamic State. I live in Texas, and I hail from Tennessee, and I often travel through the South. The question I am asked most often, oddly but significantly, concerns the rules of engagement for our men and women overseas. Wasn’t it true—and it’s always white men of a certain age who ask me this—that our soldiers had to fight the war with one hand tied behind their back due to strict rules of engagement enforced by the White House?

I try to be patient when I get this question. On the one hand, I did often chafe at what I saw as unnecessary micromanagement from White House staffers, but on the other hand, the rules of engagement were never an issue for one simple reason: From the very start of the war against the Islamic State, all decisions regarding the rules of engagement were delegated to the senior uniformed military commander on the ground. It’s right there in the original EXORD, issued by the Pentagon.

Still, the myth persists. Portions of the public believe our men and women in uniform are unnecessarily held to unfair standards and laws, and so when a war crime is committed, it is not the fault of the officer or enlisted serviceman who committed the crime but rather the laws themselves.

But here’s what happens when the public believes such things:

First, it dishonors the thousands of men and women who successfully led combat units in Iraq and Afghanistan—often under extreme stress—without committing crimes and other atrocities. It brings those honorable men and women down to the level of the minority of men and women who chose to disgrace the flag on their shoulders.

Second, it undermines the good order and discipline that is so important to a functioning military. What message does it send, to our uniformed commanders, when civilians loudly call for the pardon of men and women who were punished for disobeying the laws and other orders their commanders ordered them to follow? What other orders, upon civilian review, are optional?

I have often argued that Americans should take more interest in their uniformed military and ask harder questions of it: How does it prioritize its use of our tax dollars? Why has it failed to achieve victory in Afghanistan? Why is there so much duplication of effort between the services, and how does interservice rivalry both help and hurt the military? The list goes on.

But if Americans aren’t going to bother to study their military, the least they can do is abstain from projecting their vengeful fever dreams upon its professionals.

You want to honor the troops? Start with that.



Last week, President Donald Trump increased tariffs on $200 billion worth of goods imported from China, the latest salvo in the administration’s months-long trade war with Beijing. On Monday, China said it would retaliate with tariffs on $60 billion worth of American products, warning that it would “never succumb to foreign pressure.”

Trump argued that additional tariffs were necessary to force concessions from the Chinese and would redound to the benefit of American manufacturers and the American economy. “Tariffs will bring in FAR MORE wealth to our Country than even a phenomenal deal of the traditional kind. Also, much easier & quicker to do,” he said in one of his numerous tweets on the subject. He added: “Tariffs will make our Country MUCH STRONGER, not weaker. Just sit back and watch!”

Oh, really? To make the case for his trade war, and to measure his administration’s success in it, Trump is relying on blatant falsehoods and misconceptions. Taking those falsehoods as truths and those misconceptions as correct—accepting Trump’s theory of trade, that is—the United States might be stronger, the deals might be phenomenal, and the trade war might be good and easy to win. But the Chinese have not yet backed down, and show no signs of doing so. In the meantime, the businesses and consumers sitting back and watching the trade war are bearing modest, but measurable costs.  

In Trump’s mind, tariffs are a potent, unilateral weapon, and protectionism is a potent, necessary economic philosophy. He argues that his tariffs are a direct tax on Beijing—a way of sapping Chinese manufacturers, raising American revenue, aiding domestic businesses, and giving Washington leverage in trade negotiations. “Tariffs are NOW being paid to the United States by China of 25% on 250 Billion Dollars worth of goods & products,” he said on Twitter. “These massive payments go directly to the Treasury of the U.S.”

This is not at all how it works; the Chinese government is no more apt to fork over billions of yuan for Trump’s tariffs than Mexico’s government is to pay for a border wall. Rather, tariffs fall on the American importers of Chinese goods, who often pass those cost increases onto American consumers. That means every time Trump raises tariffs, he risks raising costs on families and businesses.

Earlier this month, Trump argued that this dynamic did not exist. “The Tariffs paid to the USA have had little impact on product cost, mostly borne by China,” he wrote, intimating that Chinese companies have lowered their prices to remain competitive. That has not, in fact, happened. In a new paper, economists based at Princeton, Columbia, and the Federal Reserve Bank of New York write: “Although in principle the effect of higher tariffs on domestic prices could be offset by foreign exporters lowering the pre-tariff prices that they charge for these goods, we find little evidence of such an improvement in the terms of trade up to now.” The authors estimate that Trump’s tariffs were costing consumers about $1.4 billion in real income a month by the end of 2018.

Trump has promised to use the revenue that the government raises from China (remember, the government is not actually raising money from China) to help businesses harmed by the trade war. Washington will demand payments from Beijing, use the money to buy food, and pass the food on “to starving people in nations around the world!” he said. It is true that the government is planning more aid for agricultural firms hit by the trade war, and that Trump wants the U.S. Department of Agriculture to figure out some work-around. But at best, such a plan would involve taking American taxpayer dollars and using them to buy American agricultural goods to ship abroad or to bail out American farms.

Trump’s misconceptions on trade are not limited to tariffs. He continues to argue that the United States’ trade deficit with China is a sign it is getting ripped off, and that it is bleeding itself dry by engaging in commerce with the Chinese: “The United States has been losing, for many years, 600 to 800 Billion Dollars a year on Trade. With China we lose 500 Billion Dollars. Sorry, we’re not going to be doing that anymore!” There are many issues with the two countries’ economic relationship, and many ways that China does not play fair. But trade imbalances are not in and of themselves a bad thing. The United States has a trade deficit with China in large part because goods are cheaper to produce there, and Americans choose to consume huge amounts of them; the deficit is not a way of measuring capital losses in the United States.

As for tariffs bringing “FAR MORE wealth to our Country”: The trade war thus far has not caused tremendous macroeconomic damage. But it has hit certain industries and businesses very hard—dairy farms in Wisconsin, for instance—while increasing consumer prices a smidge. Economists have estimated that Trump’s trade war cost the country a sliver of GDP last year, in part by forcing businesses to rejigger their supply chains. (The pain is worst in heavily Republican counties, one analysis found.) Given Trump’s new tariffs and China’s retaliatory measures, the cost might be yet greater this year.

Not that Trump himself would admit it. In his mercantilist, protectionist understanding of the world, trade wars are good, tariffs are a way of hitting the bad guy, and whatever the United States is doing on trade, it is winning. Alas, here in the real world, Trump’s trade war means that consumer goods are about to get more expensive and certain exporting businesses are about to face a much tougher climate, all thanks to the White House.



President Donald Trump’s barbs at Germany and the European Union get the headlines, but no ally has been more tormented by him than the United Kingdom, to which he will make a state visit next week.

Over the past two and a half years, the president has interfered in the U.K.’s domestic politics. He has repeatedly undermined its national security with his comments and actions after terrorist attacks in Britain. He has bullied and humiliated the prime minister, Theresa May. He has accused British intelligence agencies of spying on him, even after he promised not to do so. Trump has taken a predatory approach in trade talks, seeking to squeeze controversial concessions out of London at a moment of weakness, even at the risk of sabotaging the prime minister’s Brexit deal. He refused to listen to the British government on vital issues of shared concern, such as Iran and climate change.

The special relationship is arguably at its lowest point since the Suez crisis of 1956, when President Dwight Eisenhower pulled the rug out from underneath Britain and France’s attempt to retake the Suez Canal. If this sounds like an exaggeration, just consider the track record.

On November 22, 2016, shortly after his election as president, Trump met with Nigel Farage in Trump Tower and tweeted:

Many people would like to see @Nigel_Farage represent Great Britain as their Ambassador to the United States. He would do a great job!

The meeting caused consternation in London, with Downing Street saying, “There is no vacancy.”

On January 26, 2017, May visited Trump in the White House and offered him a state visit to the U.K. While she was on her way home, Trump signed the ban on citizens from seven countries traveling to the United States, including those citizens who were dual nationals of the U.K. Trump did not tell May of his plans, and mass protests quickly followed in London against the ban and Trump’s visit. May called the policy “divisive and wrong.”

On March 17, 2017, the Trump administration claimed that British intelligence services eavesdropped on Trump at the request of President Barack Obama. A spokesperson for the prime minister said, “We’ve made clear to the administration that these claims are ridiculous and should be ignored. We’ve received assurances these allegations won’t be repeated.” Trump would break that promise.

On May 23, 2017, after British intelligence shared with their American colleagues the name of Salman Abedi, the man who bombed the Ariana Grande concert in Manchester, and photographs of the bomb remnants, those details were leaked to the press. The prime minister complained to the president and called the leaks unacceptable. The National Police Chiefs’ Council said that the “unauthorized disclosure of potential evidence … undermines our investigations.”

On June 3, 2017, three terrorists wielding knives killed seven people and injured dozens more. Trump tweeted, “At least 7 dead and 48 wounded in terror attack and Mayor of London says there is ‘no reason to be alarmed!’” He misconstrued the words of Sadiq Khan, who said he was appalled by and furious about the attacks, but went on to say Londoners should not worry if they encountered more police on the streets.

On September 15, 2017, Trump tweeted during an ongoing terrorist attack on the London Underground to justify his immigrant ban and to claim without any evidence that the British authorities had had the suspect “in their sights” beforehand.

In November 2017, Trump retweeted a video from the deputy leader of Britain First, a far-right group, that claimed to show a Muslim attacking a boy with crutches. The video was not what it purported to be, and the prime minister’s spokesperson issued a rare criticism of the president. Sajid Javid, now home secretary and a candidate to replace Theresa May, tweeted, “POTUS has endorsed the views of a vile, hate-filled racist organisation that hates me and people like me. He is wrong and I refuse to let it go and say nothing.”

On a visit to the U.K. in July 2018, Trump gave an interview to The Sun in which he said the prime minister had ignored his advice for dealing with Brexit and her deal would kill the prospect of a free-trade agreement with the United States. Trump also told the newspaper, “I think you are losing your culture.” The story broke as Trump and May walked into a formal dinner.

On December 31, 2018, Woody Johnson, the U.S. ambassador to the U.K., said that a U.S.-U.K. free-trade deal was unlikely if Theresa May succeeded in passing her Brexit deal. He was also withering about May personally, telling BBC Radio 4, “I’ve been all over Wales, I’ve been all over Ireland and Scotland and also England—and I am feeling that the country is in need of leadership.”

In a speech in London in April 2019, Mike Pompeo, the U.S. secretary of state, directly criticized the prime minister by comparing her unfavorably with Margaret Thatcher. Pompeo said, “Now is the exact opposite time to go wobbly. Ask yourself this: Would the Iron Lady be silent when China violates the sovereignty of nations through corruption or coercion? Would she allow China to control the internet of the future? I know it’s a sensitive topic, but we have to talk about sensitive things, as friends.” It was an extraordinary criticism to level in public, coming a month before Trump’s state visit.

On April 24, 2019, just a day after the British government confirmed the president’s state visit to the U.K., Trump tweeted:

“Former CIA analyst Larry Johnson accuses United Kingdom Intelligence of helping Obama Administration Spy on the 2016 Trump Presidential Campaign.” @OANN WOW! It is now just a question of time before the truth comes out, and when it does, it will be a beauty!

This broke the promise he made to May just more than two years prior. A spokesperson for Government Communications Headquarters, Britain’s equivalent of the National Security Agency, said in response, “As we have previously stated, the allegations that GCHQ was asked to conduct ‘wire tapping’ against the then-president elect are nonsense. They are utterly ridiculous and should be ignored.”

And then there is the policy.

John Bolton has been in regular contact with leading Brexiteers, even as they warred with the prime minister over the nature of Brexit. White House sources told Axios that Bolton “encouraged the Brexiteers to keep it up.”

Secretary of Commerce Wilbur Ross and U.S. Trade Representative Robert Lighthizer have made it clear that the U.K., if it wants a free-trade deal, will have to choose America’s regulatory framework over the European one, putting the U.K. in a position of being unable to conclude a trade deal with the EU 27, its largest trading partner. Such a deal would include provisions on chicken and access to the National Health Service that would almost certainly not make it through the House of Commons.

The Trump administration castigated the British in public for their reluctance to sever ties with the Chinese technology firm Huawei, but was very slow to present evidence that Huawei posed a security risk and to work with the British on the problem. Even those modest efforts failed spectacularly when the May government said it would move ahead with granting Huawei access to parts of the U.K. telecom network. The Brexiteers, supposedly Trump’s allies, look set to continue this policy if one of them succeeds May. For instance, Dominic Raab, a leadership contender and the former Brexit secretary, told the BBC he would abide by May’s decision.

The British also feel as if they have gotten nothing from the Trump administration on their key foreign-policy priorities, including climate change and Iran. Privately, British diplomats vent their frustration at the administration. Publicly, they have no interest in acknowledging there is a problem, solely because they have so many other problems to deal with.

The U.K. and the U.S. still have deep networks of cooperation on security and intelligence, but the lamentable state of the relationship under Trump will have lasting consequences. A no-deal Brexit, which the United States is working toward, would badly damage Britain. The administration’s failed diplomacy on Huawei dramatically increases the China challenge in Europe. Trump’s constant interference, insults, and needling of senior British officials, including May, weakens the case for the alliance within Britain and could empower Jeremy Corbyn, the U.K.’s opposition leader and a longstanding critic of the United States.

The United States needs the U.K. It will have to do more than keep the bust of Winston Churchill in the Oval Office. To preserve the alliance, it needs a very different approach. It should work with the U.K. on a trade deal that is compatible with the closest-possible relationship with the EU 27 and preserves the Good Friday Agreement with Northern Ireland. It should devise trilateral structures to preserve security cooperation across the Atlantic. It should open a strategic dialogue with the U.K. on China and listen to Britain on Iran and climate change.

None of this will happen in the foreseeable future. Instead, the situation is likely to go from bad to worse next week.



The general-election campaign is happening today. And Donald Trump is running unopposed.

Presidents who have recently won reelection seeded their victories not in the final sprint before Election Day, but by executing a two-year campaign to exploit a contentious primary on the other side, reconnect with their base of supporters, and define the election as a choice, not a referendum. I served as the national press secretary on President Barack Obama’s 2012 reelection campaign, when we used that strategy to great effect. Now I’m watching President Trump executing the same strategy that powered Obama to reelection, while the Democratic organizations that could answer him have left an open playing field in the battleground states where the election will be decided.

The Trump campaign launched at the start of 2019 and hasn’t paused for a day. It is using the candidate’s schedule, a staffed-up campaign team, and a sophisticated digital-advertising effort to reach its target voters. The campaign has spent more than $5 million on Facebook ads, with a particular focus on older voters and women, firing up the base by attacking “fake news” and promoting its message on immigration. The advertising team has gone beyond social-media campaigns, sponsoring podcasts and creating a significant paid-media presence on YouTube. In fact, Trump is outspending Democrats six to one on video ads, the primary digital-engagement tool for voters today.

Simultaneously, Trump has begun to hold rallies in battleground states across the country, dipping into media markets where he can fire up his base, such as Panama City, Florida, and battleground markets, such as Green Bay, Wisconsin. Many of these visits lead to localized polling bumps that last for weeks.

Look no further than the Trump campaign’s press secretary’s Twitter feed to watch daily footage of the campaign reconnecting with supporters and asking them to engage its networks. Trump’s campaign manager is raising general-election funds and appearing before influential audiences.

Meanwhile, neither the Democratic National Committee nor any of the major Democratic super PACs are live with any notable broadcast or digital-advertising budget in battleground states targeted toward general-election swing voters. The 23 Democratic presidential campaigns are naturally focused on proximate targets, such as winning early states and meeting the DNC’s fundraising thresholds. As a partner at Bully Pulpit Interactive, a communications and digital-marketing agency that has in the past served as an advertiser for Democratic presidential campaigns and super PACs, I follow this world closely. I’ve seen a number of campaigns begin to spend on digital advertising, but their ads are not focused on messages that will erode support for Trump. That’s not the role they are expected to play at this stage.

Democrats face the urgent necessity of countering the Trump campaign in the battleground states. The leading Democratic presidential candidates have raised less this year than they did in 2007. (In the first quarter, Senator Bernie Sanders topped out at $18.2 million, followed by Senator Kamala Harris at $12 million. In the first quarter of 2007, Hillary Clinton raised $26.1 million, and Barack Obama raised $25.7 million.) Democratic donors may be sitting on the sidelines because the field is wide and they are undecided. But if so, that also represents an opportunity. They could fund an effort that turns to the general election today even if they haven’t picked their primary horse.

There is no dearth of advertising material to air. The Chinese are importing soybeans from Russia and Brazil instead of Iowa and Ohio. Trump is steadily unwinding protections for LGBTQ Americans. Taxes have gone up on some voters who pay state income taxes after Republicans repealed the state and local tax exemption. And Democrats are again fighting to protect health-care benefits. The content writes itself.

What worries me is that I’ve implemented many aspects of the strategy that the Trump campaign has been executing. The groundwork for President Obama’s 2012 victory against Mitt Romney was laid in 2011. In November of that year, The New York Times Magazine ran a cover story called “Is Obama Toast?” declaring that Obama had a 17 percent chance of winning reelection based on the economic indicators that had been historically predictive of whether the president wins reelection.

We on the Obama campaign didn’t let those early odds intimidate us. By the spring, we had launched a major effort to reinvigorate Obama’s activists, define Romney to swing voters by highlighting his every jolt to the right, and build a data-driven field and persuasion effort. Quietly, we fed research to media outlets that would highlight Romney’s hypocrisy, providing ammunition to his Republican-primary opponents, and draw attention to the deficiencies in his record in the private sector and as governor, which would concern general-election voters. And as we tested and finessed the most effective frame for the general election, we learned that we needed to do more education about Obama’s success in turning around the economy after the financial crisis.

We, too, had studied prior playbooks. President George W. Bush used the Democratic knife fight between Dick Gephardt, Howard Dean, Wesley Clark, and John Kerry to define the field as angry and unpatriotic and to begin to conduct a persuasion campaign to the segment of voters that would decide the election. In 1995, President Bill Clinton took swift action to recover from devastating losses in the midterm elections by linking Bob Dole with the more extreme and unpopular Newt Gingrich.

While Trump’s soft poll numbers may suggest otherwise, the general-election battle won’t be easy, in large part because he’s getting a head start. The Trump campaign entertained appeals from the Russians and WikiLeaks the last time around; it’s anyone’s guess what measures he and his staff will take to win reelection. The Democratic candidates should be careful not to get caught up in a primary debate that rewards purity (No fundraisers! Attend every forum regardless of audience!) over preparing a precise plan to win the broadest set of voters in order to halt President Trump’s historic assault on Democratic—and democratic—values.

It’s not time for Democrats to despair; it’s time for us to engage. Because primary campaigns have finite resources and shorter-term needs to address before they can get to the main battle, the DNC and allied super PACs need to begin advertising now in battleground states to provide air cover for the future nominee while he or she is tied up in what will likely be a highly competitive and lengthy primary race.

Donors, including those waiting to pick their favored candidate, should invest now in a serious, year-long fill-the-gap effort that ensures that the Trump campaign’s dominance is checked as quickly as possible. And activists, as they engage in primary organizing, should also consider what steps they can take today to win next year’s election, from registering voters to persuading swing voters in battleground states.

If Democrats don’t act now, the Trump campaign will define the general election on its own terms, before we can even choose our nominee.



Updated at 10:14 a.m. ET on May 23, 2019.

Four years ago, I wrote a letter to John Walker Lindh, then–inmate number 45426-083 in the Terre Haute penitentiary, to ask for advice about jihadism, Islamic law, and the Islamic State. Lindh is the most famous jihadist America has ever produced. In December 2001, he was pulled, half-dead, from a cellar full of fellow al-Qaeda fighters in northern Afghanistan, and 10 months later he was sentenced to 20 years in U.S. prison for terror-related crimes. He is scheduled to be freed today, with three years off for good behavior, and many—including Donald Trump—have objected to his release.

The story of our correspondence is in my book The Way of the Strangers: Encounters With the Islamic State, but some details appear here for the first time.

Lindh wrote back to me promptly and courteously:

In order for me to even consider responding to your inquiry, I would require that you furnish me with books, treatises, articles, or other writings produced by leaders of the Islamic State and/or scholars affiliated with it (preferably in the original Arabic). It would not be appropriate for me to comment otherwise.

Thank you for your interest in the Islamic State.

Sincerely,

Yahya Lindh

Days later, I printed a big stack of essays, speeches, and fatwas by ISIS scholars and mailed it to Terre Haute.

Lindh’s father, Frank, a lawyer in San Francisco, told me that his son was a prisoner of conscience who, like many inmates in that section of Terre Haute, had been locked up for “political” reasons. At heart, he was a scholar, a bookworm; the government had robbed him of his freedom but would not thwart his ambition of becoming a learned Islamic thinker. Frank spoke with me from a Terre Haute Red Roof Inn in 2015, on one of his many visits with his son.

Of course, Yahya Lindh had pleaded guilty to a fairly specific and material crime: working for the Taliban, and carrying explosives while doing so. Others in Terre Haute were prisoners of conscience whose consciences had told them to, say, attempt to acquire weapons of mass destruction and blow up skyscrapers in the service of Allah. But in our short correspondence, his tone remained bookwormish. He was fastidious, even officious, in his reluctance to opine on matters that he had not studied in the original language.

The warden at Terre Haute declared my care package of ISIS propaganda contraband, and it was confiscated. (None of it directly incited violence—it was mostly about obscure points of Islamic law. But the warden had a point.) Lindh wrote back gratefully, affixing to the envelope a forever stamp honoring recipients of the Purple Heart. He couldn’t comment in any detail, he said. Maybe others could help:

Considering the attention that the Islamic State has attracted from the media, academics, researchers, and others over the past couple of years, it is striking to me how few appear to have actually visited the Islamic State to see how things really are there and to meet and interview its leaders … I would like to suggest that you visit the Islamic State yourself so that you can pose your questions directly to its officials and leaders. I am sure there are ways that that can be arranged.

I told him that sounded like a splendid idea, except for the possibility that I might be beheaded or enslaved.

I understand your concerns about being killed or enslaved, however I believe that your apprehensions are misplaced. The journalists who have been taken into custody by the authorities of the Islamic State travelled there illegally. Had they gone with the proper documentation, I am confident that the authorities of the Islamic State would have honoured their covenants, as required by Islamic law.

And then our correspondence ended with a note of self-effacement. Lindh said he was a mere “layman,” my sources were adequate to answer my questions, and his own opinions were “of no consequence.” He guided me to his “colleague” and former fellow Terre Haute inmate Ahmad Musa Jibril, a notorious ideologue now free and living in Michigan, and said that Jibril could answer further questions. Jibril was the most popular cleric among ISIS jihadis, before his accounts went dormant for legal reasons.

His more than 17 years in captivity seem, on the basis of this correspondence, to have converted Lindh from an al-Qaeda supporter to an Islamic State supporter.

According to reports, Lindh acquired an Irish passport a few years ago, and he intends to move to Ireland to proselytize once his probation ends in a few years. No one has said where he intends to live in the meantime, but one possibility is a return to Marin County, California, where he grew up in the 1990s and where his father still lives.

In 2002, George H.W. Bush, expressing his total lack of sympathy with Lindh, called him a “Marin County hot-tubber.”* (He later apologized for maligning Marin County when he had intended to malign only Lindh.) That nickname got to the heart of what irritates so many Americans about Lindh. He had everything: loving parents, wealth, a childhood in a fantasyland of pleasure and natural beauty. Before even reaching adulthood, he had rejected it all. He posed online as an aggrieved black man. After his conversion to Islam, he rejected every opportunity to live like most Muslims he met, and instead sought ever more extreme peers, first in the madrasas of Yemen, then in Pakistan, and finally in the al-Qaeda camps of Afghanistan.

As a member of al-Qaeda, he fought against the Northern Alliance, the local U.S. ally seeking to unseat the Taliban. Two American CIA operatives, Mike Spann and David Tyson, found and interrogated him at a fort in northern Afghanistan. Lindh’s fellow prisoners were hiding grenades, but Lindh said nothing during the interrogation, and in the minutes that followed, the prisoners overwhelmed and killed Spann.

The journalist Robert Young Pelton found Lindh the next day, wounded by shrapnel and hypothermic after the prison-uprising battle. “When I first met him, the thing that surprised me the most was that he didn’t want to talk to his parents,” Pelton says. He wanted martyrdom, and he said so. “Lindh seemed like a sociopath who had been working really hard to be with a group that was killing Americans and fellow Muslims.”

He was, Pelton says, an “obsessive.” And unfortunately, it appears that his obsessions have not varied. T. S. Ellis III, the federal judge who approved his probation, imposed strict rules on him, including a total ban on use of the internet and no contact with known extremists, presumably including his “colleague” Jibril. Authorities certainly know about Lindh’s continuing radicalism—not least because they have read every word of my correspondence with him.

The chances that he will leave prison and immediately start gathering bomb-making materials seem exceedingly slim to me. But the chances that Marin County will someday have an unrepentant jihadist praying in its mosques, and soaking in its (woman-free) hot tubs, seem very high. (ABC’s James Gordon Meek has reported that Lindh will initially live in Virginia, where he was sentenced.) Senators Richard Shelby and Maggie Hassan wrote to the Bureau of Prisons to ask why Lindh is out early. Their letter’s last points, though, cut to the deeper problem. What “policy, strategy, and process” do we have to ensure that a terrorist can “reintegrate into society”?

They need not wait for the bureau’s reply, because Lindh answers the question for them: No such process exists. People can change in prison, just as people can change out of prison. But the process has not been invented, outside of A Clockwork Orange, to take a bookish fiend and divert him to better books, or to less murderous hobbies. The durability of jihadist ideology remains baffling to most politicians and bureaucrats. It does not evanesce because of aerial bombing, exposure to irenic Muslim narratives, or long-term imprisonment. It sticks in the brain like chewing gum in the hair. And everything we know about the psychology of Yahya Lindh suggests that the only way to release him safely would have been to get a time machine (perhaps of the hot-tub variety) and divert him from jihadism 20 years ago, before he ever became permanently devoted to it. For now, public security demands nothing less than close observation for a very, very long time.

* This article originally misstated which president called John Walker Lindh a “Marin County hot-tubber.” It was George H. W. Bush, not George W. Bush.



It took Rudy Giuliani less than a month after the release of the Mueller report to begin colluding. In a buoyant interview with The New York Times on May 9, President Donald Trump’s personal lawyer unveiled his plans to push the incoming Ukrainian government to kick-start an inquiry that, Giuliani hoped, would be politically damaging to the former vice president turned Democratic presidential candidate Joe Biden: “We’re not meddling in an election—we’re meddling in an investigation, which we have a right to do,” Giuliani announced. The next day, President Trump told Politico that “it would be appropriate” for him to ask the Justice Department to investigate the Ukraine matter.

After a volley of criticism, Giuliani canceled his voyage to Kiev. (“They say I was meddling in an election—ridiculous—but that’s their spin,” he told the Times.) But one could be forgiven for feeling a sense of déjà vu. Giuliani’s and Trump’s behavior echoes the conduct described by Special Counsel Robert Mueller in his 448-page report on Russian interference in the 2016 election: The Trump team sought to benefit from the actions of a foreign government that harmed the opposing presidential candidate. The details are different—Ukraine rather than Russia, Biden rather than Clinton, a public announcement of an attempt to coordinate with a foreign power rather than a tacit understanding—but the broad strokes of the story remain the same.

It says a great deal that this kind of conduct from the president and his inner circle is no longer surprising. What is surprising is just how quickly Trump bounced from one scandal focused on his attempts to corrupt the functioning of independent law enforcement straight into another one. But after the Justice Department released Mueller’s account of presidential venality and misconduct, only for Congress to respond with a collective shrug, it was probably just a matter of time.

Volume II of the Mueller report—focused on attempts by the president to derail the investigation into his own conduct—is a portrait of Trump’s skewed vision of the role of state power and, particularly, of law enforcement. Again and again, he expresses his frustration that the Justice Department refuses to investigate his political rivals. He calls then–Attorney General Jeff Sessions at Sessions’s home to insist that the department begin a criminal probe into Hillary Clinton. He compares then–White House Counsel Don McGahn unfavorably to his onetime fixer Roy Cohn.

The report added new and troubling detail to this picture, but the overall sketch is familiar. As Mueller himself noted, many of Trump’s efforts to pressure Sessions into shuttering the Russia investigation took place in public; a great number of footnotes in this section of the report cited tweets from @realDonaldTrump. There is an argument—even a good one—that Trump committed an impeachable offense when he fired FBI Director James Comey in May 2017, and the publicly available evidence that would be stacked against him during any impeachment inquiry has only mounted in the years since then. But it’s one thing to see the president act out his unfitness for office on a daily basis, and another to read a special counsel’s assessment of that unfitness in what arguably amounts to an impeachment referral to Congress.

While the Mueller investigation was ongoing—the “Witch Hunt,” as the president calls it—it was a convenient target for Trump’s rage. Now that the investigation is complete, his public complaints have not ceased, but instead have focused more and more on the probe’s beginnings. Trump recently referred to a New York Times report fleshing out details of the FBI’s investigation into Trump’s foreign-policy adviser George Papadopoulos as “bigger than Watergate.” Attorney General Bill Barr has hinted darkly at wrongdoing on the bureau’s part, though the specifics of his concerns remain unclear.

The merits of Giuliani’s allegations about misconduct by Biden’s son in Ukraine are exactly as substantive as the Trump team’s concerns about misconduct by the FBI—which is to say, not substantive at all. Nevertheless, the gist of the president’s argument on Ukraine is that, as my colleague Susan Hennessey put it, “turnabout is fair play.” Responding to a tweet expressing outrage over Trump’s suggestion of opening an investigation into Biden, Senator Ted Cruz wrote on Twitter, “Irony much? … That describes the exact state of affairs w/ the Obama Admin launching investigations on Trump.”

The irony of Trump’s attitude toward federal law enforcement is that the president fears the FBI is exactly what he wants it to be: a gang of thugs operating on no higher principle than political advantage. His only problem is that they are not his thugs. “You’re telling me that Bobby and Jack [Kennedy] didn’t talk about investigations?” Mueller quotes the president as raging. “Or Obama didn’t tell Eric Holder who to investigate?” The man described in the report is someone so imprisoned in his own consciousness that he seems incapable of understanding that other people might, unlike him, go through the world as something other than scammers or bullies.

This worldview depends on ignoring the post-Watergate reforms designed to prevent the president from using the nation’s intelligence and law-enforcement capabilities as political tools. More than that, it requires pretending that those reforms never existed at all—that Trump’s corruption is not an anomaly, but only an honest recognition of what everyone who’s savvy already knew to be the case. It requires erasing the Nixon impeachment process, and the fact that the House Judiciary Committee included among the high crimes and misdemeanors committed by Richard Nixon that he “repeatedly engaged in conduct … impairing the due and proper administration of justice and the conduct of lawful inquiries.”

That article of impeachment was Congress’s way of drawing a line in the sand, establishing Nixon’s efforts to leverage state power to his own advantage as outside the scope of what is acceptable for a president to do. Today’s Congress, faced with the Mueller report, has the same prerogative.

The Democratic leadership in the House of Representatives remains resistant to impeachment, reportedly out of concern that it could buoy the president’s poll numbers going into an election year. Likewise, it argues, any impeachment would almost certainly run aground in the Republican Senate. But there is more to impeachment than a bare political calculation. It’s also a way of marking a breach, declaring that the presidency should not be what a particular president has tried to shape it into. In the case of Watergate, that statement of protest was more or less successful for decades, at least until it ran headlong into Donald Trump.

The philosopher Immanuel Kant famously argued that, even if a society were to disband entirely, “the last murderer remaining in the prison would first have to be executed … for otherwise the people can be regarded as collaborators in this public violation of justice.” Kant’s argument is, obviously, extreme. And for all Trump’s public embrace of corruption, he has not yet shot anyone on Fifth Avenue. But the point is that, when an injustice is done, we all shoulder some kind of mutual obligation to set right the imbalance in the world or otherwise become complicit in it. For Congress today to look at the conduct described in the Mueller report and decide that it does not merit impeachment is for it to acquiesce to Trump’s effort to establish his own corruption not only as the new norm, but also as the way things have always been. To put it another way, given Congress’s inaction, can you really blame Rudy Giuliani for trying his luck in Ukraine?

In thinking about impeachment these past two years, I’ve returned again and again to the work of the legal scholar Charles Black, who understood an impeachable offense to be an act “against the nation or its governmental and political processes, obviously wrong … to any person of honor.” The definition is cryptic, yet simple. It is almost innocent, this idea that there exists a community of people who could agree on what it means to be a person of honor, in the face of a president who acts as if it doesn’t mean anything at all.



In July 1987, Oliver North was living proof of what could happen when obscure government staffers exercise power on their own. North, a Marine lieutenant colonel who’d been assigned to work on Ronald Reagan’s National Security Council staff, sat upright in his olive-green uniform before a joint congressional committee. As television cameras rolled, the staffer recounted his role in the scheme to sell weapons to Iran and funnel the proceeds to Contras battling a socialist government in Nicaragua.

On paper, North and others at the NSC were supposed to support the president’s policy-making process, but Reagan staffers had cooked up their own plans and then carried them out. Amid what became known as the Iran-Contra affair, North and the rest of the NSC looked to many like, in the words of one observer, “reckless cowboys, off on their own on a wild ride.” Today conspiracy theorists would have simply called them part of a “deep state”—shadowy, unelected officials controlling government even as presidents come and go.

Like just about everyone else in the United States, I watched North’s hearing. I was 8 years old. As rain ruined a family-vacation day that July, I sat in a hotel room with my mother and siblings, captivated by the testimony of a man whose deeds, I realize now, could have besmirched the NSC’s reputation for posterity. Yet when I began research for a book on the people and power of the NSC—a project that eventually included reviewing 10,000 archival documents and almost 100 interviews with policy makers from the Reagan administration and more—I was surprised how seldom Iran-Contra came up.

There is one Washington wise man to thank for that. Brent Scowcroft, an unassuming Utahn, retired Air Force lieutenant general, and former national security adviser, has done more than anyone to shape the NSC and the way Washington makes foreign policy today. Even before North testified, Scowcroft took steps to not only save the staff but empower it. As part of the special review board that investigated Iran-Contra, and then as President George H. W. Bush’s national security adviser, Scowcroft built an NSC far more powerful than the one North had served on, despite calls by some to eradicate the staff.

Thirty years later, the institution that Scowcroft empowered serves at the pleasure of Donald Trump. The 45th president has even taken to Twitter to thank NSC staffers for their service. Coming from a president who has sharply criticized other bureaucratic entities and complained aloud about the “deep state,” Trump’s tweet is ironic proof of the NSC’s staying power.

There’s no organized deep state in Washington today, but I can understand why Americans might worry about what unelected officials do when left to their own devices. The history of the NSC is a classic demonstration of how a few serving in government can amass enormous power in the name of national security when the public can’t see what they’re up to. Since previous attempts to curtail the NSC’s purview have done the opposite, one would be forgiven for wondering if any limit is even possible.

Unsurprisingly, Americans have taken again to thinking that those in government are off again on their own wild ride. A poll last year found that three-quarters of Americans believed that unelected government and military officials secretly control policy decisions in Washington. That finding should alarm those working on the NSC. Despite their immense power, staffers operate outside the public eye. They are not subject to Senate confirmation. They do not testify before Congress. They speak to the press and public only when it is in their—and the president’s—interests. To the outside world, they are all but anonymous—a failure of democratic oversight that Congress is long overdue to fix.

The staff on which North served was created as a political, legal, and bureaucratic afterthought. Up through World War II, Senate-confirmed secretaries of Cabinet and military departments advised the president on matters of foreign policy. After the war, Congress established a formal National Security Council to better coordinate foreign policy. At first, the council itself—which included such officials as the president, the vice president, the secretaries of state and defense, and more—got all the attention due to the novelty and importance of its charge. One headline billed members as “The Men Who Guard the Nation’s Security.” But in one line of law, Congress also created a secretarial staff to keep the council productive and push its paper.

From those humble, administrative beginnings, president after president empowered the staff. Harry Truman housed it in the Executive Office Building, next to the White House. Dwight Eisenhower created the position of national security adviser. Subsequent presidents put NSC staffers in charge of the interagency process through which information gathered from across the government is put before the president. In recent decades, hundreds of staff members have helped presidents with everything from the little questions (What is the name of a foreign leader’s spouse?) to the big challenges (Should the United States go to war?).

Even when presidents occasionally sought to reduce its power, the NSC grew right back. After Reagan came into office, he downgraded the national security adviser and NSC staff, hoping instead to empower Cabinet secretaries to run foreign policy. But with Defense Secretary Caspar Weinberger and Secretary of State George Shultz in screaming matches and the Cold War presenting daily challenges, frustrated NSC staffers tried to fill the gap and “risk doing something,” as one White House official said at the time.

Few came to embody that NSC more than North. The Marine officer was first assigned to the NSC in 1981 at the age of 38, and rose to become a deputy director working on terrorism. During North’s time on the staff, the United States began secret sales of weapons to Iran, ostensibly to secure the release of hostages captured in Lebanon. Only a couple of hostages were released during the whole scheme, but North had secretly taken an additional step: Though expressly forbidden by Congress and not approved by Reagan, North began diverting funds from the arms sales to fund the Nicaraguan Contras.

When news of the Iran-Contra affair finally broke, in late 1986, the scandal was serious and sexy enough—secret missions, illegal money transfers, and rogue staffers from an unknown and mysterious entity—to become all Washington could talk about. Even more, an attempted cover-up threatened the entire Reagan presidency. After first playing down the scheme, the president took responsibility for the operations in an Oval Office address in March 1987.

Although Reagan and then–Vice President Bush avoided legal culpability, several officials were indicted. North was convicted for his efforts to cover up the affair, though the conviction was later reversed. Still, Iran-Contra, and North’s hearing, introduced the nation to the NSC staff as a group of rogue warriors manipulating policy. Individual staffers took most of the blame, but many in Washington believed that the NSC itself had, as one official later wrote, “gone off the rails.”

In the end, the political and legal drama of Iran-Contra was far less consequential than the fight to fix the National Security Council itself. In late 1986, Reagan tapped John Tower, a former Republican senator from Texas, to lead a special panel to review what had gone wrong. Also on what became known as the Tower Commission were former Secretary of State Ed Muskie and—most consequentially—Brent Scowcroft.

Compared with Tower and Muskie, both of whom had served in elected office, Scowcroft was a quintessential behind-the-scenes player. Intense, balding, and rail-thin, he had excelled as an Air Force staff officer at the Pentagon, then as deputy to National Security Adviser Henry Kissinger during Richard Nixon’s administration, and finally as a low-key and hardworking national security adviser to President Gerald Ford. In that job, as Ford’s chief of staff Dick Cheney told me, Scowcroft was “not interested in headlines for himself.”

Scowcroft recruited another low-profile insider, Stephen Hadley, a lawyer and former NSC staffer, to help on the commission. The two pored through NSC files from both the Reagan administration and previous presidencies, and they wrote much of what would become the board’s 550-page report. But more than simply exposing wrongdoing, Hadley later explained, Scowcroft was “keenly focused” on ensuring the White House’s national security adviser and NSC staff continued to hold the reins on national-security process and the policy it produced.

Amid calls to make the NSC and national security adviser answer to Congress, the commission avoided such a step and recommended no legal restrictions. Instead, the NSC was to be governed by unwritten rules—what a former White House official described as Washington “common law”—that, for instance, made verboten operations like those undertaken by North and others at the NSC. More important, the staff’s mission was redirected; staffers were to act as “honest brokers,” making sure all relevant voices were heard.

On November 23, 1988, George H. W. Bush—by then elected president—charged Scowcroft with putting this theory and his reforms into practice. At a pre-Thanksgiving press conference, Bush named Scowcroft national security adviser. The president-elect said three times that his old friend Scowcroft would serve as an “honest broker.”

Scowcroft recruited staffers from outside government, such as Richard Haass, a former congressional, Pentagon, and State Department aide with an Oxford doctorate then teaching at Harvard, and put them in the middle of a new interagency system of committees and meetings. When Cabinet-level officials or their deputies gathered for policy deliberation, either Scowcroft or his deputy, Bob Gates, chaired the sessions, and a staffer like Haass would take notes.

After Iran-Contra, such prominence caused alarm bells to go off in Washington within weeks of Bush’s inauguration. A front-page New York Times headline read, “Bush Backs Plan to Enhance Role of Security Staff.” But Scowcroft’s status and reputation smoothed concerns, and Congress gave the president’s appointee the leeway to run his own staff. In practice, the national security adviser kept the NSC staff under close watch, but not on a short leash. He encouraged staffers to develop new ideas, come to his office, and then “defend them and argue them.”

Advocating for those new ideas could prove a challenge for honest brokers. But Scowcroft and his team redefined the art of brokering as providing the president not only the views of all members of the interagency process but also their own.

Under Scowcroft’s leadership, Haass was in the room for most key discussions in the Gulf crisis, which began with Iraq’s invasion of Kuwait in August 1990. Initially Bush had told reporters, “We’re not discussing intervention.” The offhanded remark was the kind staffers regret: It suggested options had been taken off the table. In the days after, Scowcroft, Haass, and others wanted to find a way for Bush to appear more strident and buy some wiggle room for a more forceful response.

With Bush returning from Camp David one Sunday, an opportunity presented itself, and Scowcroft ordered Haass to be there to meet the president on his helicopter. When Marine One landed on the South Lawn, Bush waved Haass over. The president asked, “What’s going on?” Haass gave Bush a policy brief that he and another staffer had quickly composed and recommended a “very firm message” to the assembled press. Bush delivered a line of his own, telling the press,“This will not stand, this aggression against Kuwait.”

All of Washington took notice of Bush’s ad-lib. One reporter concluded that the president had “all but committed himself to use military force against Iraq,” and even General Colin Powell, the chairman of the Joint Chiefs of Staff, was surprised to hear about a possible “new mission” in that way. The chairman blamed Haass, the staffer standing awkwardly next to Bush during the press availability, for the manner in which the mission was delivered. According to Haass, Powell made clear that he felt the NSC staffer “had made policy on the fly” and gotten Bush to “stake out a pretty tough position … without having run this through anything like a process.”

Powell was wrong about who wrote the line, but he was right to be worried about the power of the National Security Council. While Scowcroft held staffers back from Oliver North–style mischief, the former Tower Commission member gave Haass and others the opportunity to amplify their influence on the Gulf War and more. In the years since, unknown staffers have gained enough power—through their own ambition, new presidential requests, and abdication by Cabinet secretaries or their departments—to manage America’s relationship with the world and its wars.

Regardless of party, each succeeding national security adviser—including Trump’s latest appointee, John Bolton—has sought to follow Scowcroft’s example. The NSC’s incredible power over decisions, especially in the George W. Bush, Barack Obama, and Donald Trump administrations, demonstrates how right one Iran-Contra era prediction proved to be. Shultz, Reagan’s secretary of state, said Tower’s conclusions had “offered the NSC staff an opportunity to increase its authority.” Thanks to Scowcroft, the NSC became a powerful and opinionated institution at the heart of government with little legal foundation, oversight from Congress, or exposure to the press and the American public.

Such a development is remarkable on its own terms—all the more so because the power of unknown staffers is why the Tower Commission and Scowcroft’s reforms were established in the first place. Few offer more damning judgments than Gates, who after serving as Scowcroft’s deputy became CIA director and later defense secretary, and who wrote that the staff had become “an operational body with its own policy agenda.”

The result is a change in how the United States goes to war and how Washington works. In conflict after conflict, a more powerful NSC staff has fundamentally altered the American way of war. It is now far less patient for progress and averse to risk, and more dependent on Washington’s ever-changing definition of success. The power of the NSC has also transformed how Washington works and, more often, does not work. The result today is a government that trusts less, fights more, and makes decisions much more slowly.

Scowcroft could not have predicted that his NSC would serve a president like Trump, or that a character as worrisome as Michael Flynn, who served as Trump’s first national security adviser, would even briefly oversee the NSC. But Scowcroft and others should have foreseen that such an influential and anonymous staff would worry many in the United States.

For a generation, Congress has mostly looked the other way. Driven by partisan politics, deference to commanders in chief, and lack of interest in foreign-policy oversight, members of the House and Senate have chosen not to hem in the NSC. The closest Congress has come—a limit on the number of NSC staffers in the defense authorization bill signed into law in 2016—demonstrates how little it really wanted to do. The measure, promoted by Republicans as a way of reining in Obama’s NSC, was so toothless that it would not have required any significant changes to that staff.

In any case, the real risk is not the size of the NSC staff but the unaccountable power that it represents at a time when Americans are losing trust in government and worrying about a deep state. In response, Congress should exercise more scrutiny over who works there and what they’re up to. Prospective staffers could, like presidential nominees for senior appointments at the Pentagon and the Department of State, be required to respond to background questionnaires, disclose their financial interests, and even appear before Congress. The power of the NSC has increased to the point that anonymity no longer makes sense.

From my book research, and from my time in government, I’ve learned that Oliver North—the quintessential NSC staffer gone rogue—was not a true reflection of those who work on behalf of their nation. Year after year, in good times and wartimes, remarkable men and women have shown up in Washington with a dream to serve their country, not some secret cabal of unaccountable officials. Yet amid the whispers today, some in Washington have come to treat the “deep state” label as an inside joke or a badge of honor.

The government and national-security community need to take this concern far more seriously than Scowcroft did after Iran-Contra. To ignore Americans’ concerns about rogue staffers again would be a mistake. Ultimately, few of the national-security crises the NSC works on in the White House Situation Room have ever been as dangerous to the nation than the collapsing trust in its government.



In 1838, Abraham Lincoln gave a speech on “the perpetuation of our political institutions“—better known today as the Lyceum Address. Dwelling on the threats facing the American political structure, he argued that the United States was protected from foreign invasion. “At what point, then,” Lincoln asked, “is the approach of danger to be expected?”

“I answer: If it ever reach us, it must spring up amongst us; it cannot come from abroad. If destruction be our lot, we must ourselves be its author and finisher. As a nation of freemen, we must live through all time, or die by suicide.”

The description of the United States as a “nation of freemen” three decades before emancipation was a bit of a stretch. But there is wisdom in Lincoln’s warning. It has been on my mind lately, as the country debates the question of impeachment in the wake of Special Counsel Robert Mueller’s report.

Here are the facts: The president is unsuited to his office. That should have been obvious well before the release of the special counsel’s report, but the text of the report, even with a smattering of redactions, makes his unfitness brutally clear. He shows no understanding of the responsibilities of the presidency. He delights in the abuse of his power. As Memorial Day approaches, he is reportedly planning to celebrate the holiday by pardoning, among other service members accused of war crimes, a Navy SEAL scheduled to stand trial for the murder of multiple unarmed Iraqi civilians.

To respond appropriately to Donald Trump’s behavior is to risk appearing absurd, because his own conduct is so extreme that any proportionate reaction could be deemed an overreaction. The industry of anti–anti-Trumpism is devoted to describing opposition to the president as hysterical—but an emotional excess of anger and sadness is exactly what this excessive presidency merits. What this means, in part, is that reaction to the president muted by circumstance or a desire to appear “reasonable” will always be insufficient. The only adequate response to Trump is the cry of protest. But every protest ends, even as the outrages that provoked it persist.

There is a constitutional mechanism for sounding that outrage in a more enduring way. It’s the impeachment process.

Speaker of the House Nancy Pelosi remains firmly opposed to beginning impeachment proceedings, even as multiple Democratic members of the House Judiciary Committee have called for the start of an inquiry and one Republican, Representative Justin Amash, has outright declared that the president should be impeached. Pelosi’s argument appears to be that there is no need to begin this process; that Democrats can obtain information through litigation without resorting to an impeachment inquiry; and that such an inquiry risks shoring up support for Trump as the country heads toward the next presidential election.

This is a very practical argument. But there is value to an impeachment inquiry—and to impeachment—as an act in itself, regardless of whether the Senate will convict or what the president’s supporters will think.

Pelosi and the more hardheaded Democratic strategists regard this position as overly idealistic. That’s the point.

I have returned again and again in recent weeks not just to the Lyceum Address, but also to Albert Camus’ The Rebel—the philosopher’s attempt to grapple with what it means to live morally in an absurd world. For Camus, the foundational human experience is one of outrage: a “fruitless struggle with facts,” an “incoherent pronouncement” of pain and frustration with injustice.

Camus’ reasoning can apply to an almost endless range of situations, from frustration with a corrupt political regime to rage at the inevitability of death and the silence of God. Much is absurd about the Trump administration in a colloquial sense: Consider the spectacle of a tweeting commander in chief, the most powerful man in the world spending his time insisting on falsehoods and sniping over obvious insults. But his presidency is also absurd in the philosophical sense. What better to emphasize the gap between the desire for the Constitution to mean something and the reality of the document as some words on paper than the scene of Donald J. Trump swearing an oath to “faithfully execute the Office of President of the United States, and … preserve, protect and defend the Constitution”?

The Constitution is what Camus would call a “closed universe”—a space of “coherence and unity” in an incoherent world, in which words carry weight and actions have consequences. Trump’s disrespect for the law is a reminder of how fragile that structure of meaning can be. For that reason, there is a real service in using impeachment proceedings to push back against the notion that, in the parlance of the internet, “lol nothing matters.”

Susan Hennessey and I have argued that the House of Representatives has a duty to begin an impeachment inquiry insofar as representatives swear an oath to “support and defend the Constitution” and to “well and faithfully” execute the duties of their office. Another way of saying this is that an impeachment inquiry depends on an insistence that this oath really means something—and that the president’s oath means something as well. Keith Whittington, likewise, has written that impeachment is partially a matter of “norm creation and norm reinforcement.” And Yoni Appelbaum argued that the impeachment of Andrew Johnson “drew the United States closer to living up to its ideals.”

Gerald Ford, as a member of the House of Representatives, argued in 1970 that an impeachable offense is “whatever a majority of the House of Representatives considers it to be at a given moment in history.” He was not wrong that impeachment is a political process; it is, after all, entrusted to Congress. To treat the subject as an entirely political calculation, though—as Ford did and as Pelosi appears to be doing now—is to slouch toward nihilism. Treating the words high crimes and misdemeanors as if they hold real significance, however, is a way of protesting that the world should not be as it inevitably is.

This is perhaps overly earnest. But there is a real humanity and purity of purpose in asserting earnestness against the void.

The House should take up the task of examining the president’s conduct as detailed in the Mueller report and evaluating whether it is fitting of the person who holds the nation’s highest office. It should investigate the many other instances of potentially impeachable conduct by the president, from tweets to pardons. It should debate how to understand what constitutes a “high crime and misdemeanor,” and whether relatively minor offenses can accumulate over time into something worthy of impeachment. The House should fulfill its constitutional duties and the process of constitutional interpretation, which by its nature is a declaration that the Constitution holds some significance.

Lincoln’s warning of the “approach of danger,” in context, was less about the political fracturing that would lead to the Civil War and more about the creeping acceptance of what should have been unacceptable. He decried “the increasing disregard for law which pervades the country; the growing disposition to substitute the wild and furious passions in lieu of the sober judgment of courts; and the worse than savage mobs for the executive ministers of justice.” It was this, in his mind, that pointed toward the death of the nation. The antidote he offered was “the support of the Constitution and laws.” In the absence of that, the cynical country would become vulnerable to the approach of a dictator: “Distinction will be his paramount object … and nothing left to be done in the way of building up, he would set boldly to the task of pulling down.”



We have no choice: Congress must begin an impeachment inquiry against President Donald Trump. Even if the effort to remove him comes up short in the Senate, showing a willingness to hold a lawless president accountable may be the only way to save our democracy.

I purposely have not rushed headlong into this or prejudged the outcome, as he would have done. Along with my colleagues on the House Judiciary Committee, I have carefully weighed the available evidence. Impeachment is the most extraordinary remedy the Constitution offers, and even this president deserves fairer and more impartial justice than he ever renders. Yet no other American would have been afforded—and refused—so many chances to cooperate, come clean, and do the right thing.

The president continues to betray America, putting his own interests ahead of our country’s. His statement that he would accept a foreign power’s offer of information harmful to an electoral rival, and probably not inform the FBI of such an effort, shouldn’t be shocking—because he already did it.

But for a president of the United States to say such a thing while sitting at the Resolute desk in the Oval Office is so far beyond the pale, every single American should feel violated. Trump is inviting foreigners to attack our elections, again. Our democracy is still reeling from Russia’s 2016 attack. We cannot weather another blow, particularly one that our own president encourages.

Let others debate whether impeachment proceedings are “good for Democrats” or are “playing into Trump’s hands,” or whether they “will tank the 2020 race.” As the Judiciary Committee’s only career prosecutor, I know we must put our country first and impose consequences for lawlessness.

The first half of Special Counsel Robert Mueller’s report, even in redacted form, leaves no room for debate: This president and his campaign eagerly exploited help from Russian agents, despite being aware that Russia was sabotaging our election. Mueller’s conclusion that he couldn’t prove beyond a reasonable doubt that this was a crime under current law simply means previous Congresses couldn’t imagine a candidate or president ever behaving this way—not that we can condone such behavior, or let it pass unanswered.

We cannot let Trump continue to deny that this attack happened; we cannot let him continue his cozy relations with the regime that perpetrated the attack; and we cannot let him leave us undefended against future attacks.

The second half of Mueller’s report is equally damning, examining 10 instances in which the president might have obstructed justice. Any other American who committed these acts would have been criminally charged, and reading the report, I was forced to conclude that the only reason Trump was not is because of a Justice Department policy barring indictment of a sitting president.

The next president needs to rescind that policy. But after two years of a Republican Congress unwilling to check this president’s obstruction and obfuscation, American voters gave us a House that can serve as a counterbalance on Trump’s abuses of power. Through oversight and litigation, a Democratic majority has sought to meet this responsibility. Even after the release of the redacted version of the Mueller report, though, this president has obstructed Congress by instructing witnesses not to cooperate and by invoking executive privilege where none exists. While insisting he did nothing wrong, he’s actively burying evidence.

America must know whether our president is compromised by financial ties to foreign governments. We deserve to see his tax records—to have the same level of visibility into his finances that hostile foreign actors may already enjoy. We must see the unredacted Mueller report, the full truth that Americans have demanded all along. We won’t let a serial liar and obstructer sully this office—if not for the sake of maintaining the dignity of past presidents, then certainly for the sake of ensuring no president acts this way ever again.

The rule of law, and the idea that it applies to everyone regardless of what office that person might hold, is the chief ingredient in our democracy. The accountability and transparency it provides allow for all the freedoms we hold dear; without it, America’s promise is only fulfilled for the connected and crooked.

Our democracy is worth saving, so we must begin the impeachment inquiry. A fair process will either remove a corrupt president or acquit him. He will be judged on his words and deeds, and either way, justice will be served. But inaction is no longer an option.



Two days after the bombings in Sri Lanka, the Islamic State came out and said it was behind them. It backed up its claim with video evidence that showed the attackers gathering in front of its flag to pledge allegiance to Abu Bakr al-Baghdadi, the group’s current leader. The attack had been coming for some time, and others like it are almost certainly being planned—and not just in Sri Lanka. That’s because terrorism has long been a crucial promotional tactic for ISIS. This won’t change just because the organization, which tried to build a proto-state on territory it held in Iraq and Syria, was militarily defeated earlier this year.

In the aftermath of an attack like the one in Sri Lanka last weekend, we need to ask what purpose it serves for those who claim responsibility. What’s in it for them? For ISIS, it’s quite clear: The strategic utility of terrorism has never been greater. That’s because, to navigate through its loss of land over these past few years, ISIS’s propaganda has been claiming that the group gave up on the material reality of its state long ago, having already achieved a “victory.” In this telling, its proto-state was a way to build a global platform that would ensure the movement’s future by mobilizing tens of thousands of supporters, imbuing them and their kin with its creed and its mission.

To be sure, dissenters in the organization were unconvinced of this claim, arguing that the loss of its lands, prompted by its oppression and extremism, had turned ISIS into a farce. Some have even urged a total revolt against al-Baghdadi, calling for ISIS members in Iraq, Syria, and elsewhere to rise up against him.

But these dissenters, many of whom have now fled to northwest Syria and Turkey, evidently have failed to convince ISIS’s true believers—those who buy into its propaganda hook, line, and sinker. They are the ones who really matter here, because it is they who stand to buoy the movement in the months and years to come.

For them, terror attacks such as the Sri Lanka bombings, an attempted operation in Saudi Arabia, and a border assault in the Democratic Republic of Congo last week are all evidence of ISIS’s greater victory. To the faithful, these events show that the group was as successful in expanding its reach and capabilities as its leaders claim it to have been. However, large-scale attacks are exceedingly difficult to pull off and are therefore unreliable as a way of signaling the group’s power. So ISIS has been cultivating another key “proof” of its continuing relevance: On its own organizational chart, it has been untethering its caliphate brand from Syria and Iraq.

This effort began in earnest last summer, when the group compressed its numerous wilayat (“provinces”) in Syria and Iraq into just two, wilayat al-sham and wilayat al-’iraq. It then applied the same treatment to its affiliates in Yemen and Libya. Farther-flung branches—for instance, in Somalia and Southeast Asia—were promoted to wilayat status too. This was not just some obscure lexical shift. ISIS was proactively reframing Syria and Iraq as just two of many parts of its overarching global caliphate, something that made it much easier to argue that the group would remain alive and well in the rest of the world, even if its proto-state lost all its land.

We’ve seen this strategy before. Back in 2004, the Islamic State’s predecessor, al-Qaeda in Iraq, or AQI, was militarily defeated in Fallujah—a city it had been occupying for six months alongside other insurgents. At the time, the group’s then leader, Abu Mus’ab al-Zarqawi, framed territorial defeat as a tactical setback in the short term, but a strategic victory in the long term. He asserted that Fallujah mattered most because of what the battle for the city said about AQI. It put AQI on the map, he claimed, showing it to be a viable force capable of fighting the “crusaders” head-on and globalizing its ideology. That, he said, was priceless. Sure, AQI was materially weakened, but that didn’t matter, because at the very same time it had been ideologically strengthened.

This is how ISIS is trying to get through its territorial tribulations now, and this is why we have to expect more activity from it, not less. It doesn’t really matter whether ISIS’s leaders actually believe what they are spouting. What matters is that ISIS’s true believers are buying into it. If they continue to do so, the group stands a good chance of surviving through this next, post-territorial phase of its existence.

The same message has been ringing loud and clear in its propaganda for a long time now: The proto-state in Syria and Iraq was great, but it has enabled something supposedly even greater. In Sri Lanka, we are looking at that “something even greater.”

In the coming months and years, ISIS’s core will go further underground as its units on the periphery strive to become more dangerous. The group’s thinking is that this will plug the gap left by the proto-state and give ISIS what it needs to sustain organizational and ideological inertia. It is critical that we take this into account.

It’s grim to say so, but we should expect more attempts at attacks like these more regularly for the foreseeable future. Sri Lanka was not a one-off. If anything, it was a test run.



Not long ago, I reached out to a writer I respect, and posed the uncomfortable question authors find themselves forced to ask: Would she write a blurb—the endorsement you see on the back cover—for my new book about how a person can navigate a career in the winner-take-all economy of the 21st century?

She declined. She felt strongly that this winner-take-all dynamic needs to be fought, not embraced. She argued, in essence, that I should have devoted my labors to tearing down a system in which a handful of giant companies and the highly compensated people who work at them dominate the world economy, rather than teaching people how to game it.

She has a lot of company.

Leading Democratic candidates for president have made attacking big business, and the power it wields, central to their campaigns. Republicans are on board, at least as it pertains to the power of the big tech platforms such as Facebook and Google.

And among economists, the evidence keeps building that the concentration of major industries among a handful of superstar firms might be connected to deep economic dysfunctions. When there are fewer employers in an industry, for example, they have more power to depress workers’ wages. Big dominant companies might focus more on defending what they have than on generating the kinds of innovations that drive economy-wide productivity growth. And the rise of superstar firms is likely related to the rise of superstar cities and the hollowing out of many local economies.

This is important and persuasive work—much of which I’ve written about in my day job as an economics writer at The New York Times. But in all the piling on, I fear something really important is missing from the conversation. The rise of superstar firms is rooted in fundamental technological and economic shifts that are mostly desirable. And policy changes aimed at limiting the downsides of corporate concentration—an important goal—wouldn’t restore an economy built on local, artisanal companies. They would instead leave us with a slightly larger variety of very big, technologically advanced companies dominating the corporate landscape.

The wave of trust-busting and rise of unions in the early 20th century removed some of the industrial economy’s worst downsides, but industrial capitalism boomed over the ensuing decades nonetheless. Similarly, the crucial question facing ordinary Americans, no matter how the debates over corporate power play out in the years ahead, is how to harness this reality to have fulfilling careers.

That’s what my book set out to help them do—showing how cultivating adaptability and the ability to connect different type of technical skills in team-based work is crucial to thriving in these organizations. If we want to be successful in the corporate world of the 21st century, we need to make sure we know how to work in the types of large, information-driven organizations that, one way or another, are going to remain central to the American economy.

Our careers depend on it, whether we like it or not.

Americans tend to take the advantages big companies confer for granted because they are so embedded in our daily lives. That’s because the rise of big, technologically advanced, well-managed companies that dominate their industries isn’t just a story of rapacious capitalists looking to take advantage of their workers and distort government in their favor. It’s also a story of growing abundance.

More and more industries are built off intellectual, rather than physical, capital—in ways that make the goods and services we purchase better in all kinds of ways. And it’s the scalability of these businesses that increases the quality of their offerings and reduces costs for consumers—in the process, producing a winner-takes-all economy. A software company might spend millions of dollars to develop code that can then be endlessly replicated; a moviemaker can invest a fortune to make an action movie that can then be viewed by countless people for minimal additional cost.

That pattern also applies in areas that might not seem like information industries. When you choose a bank based on whether it has a good mobile app and a wide network of automatic-teller machines, banking becomes more of a winner-take-all information industry. When Walmart’s global supply chain allows a person with a modest income nearly anywhere in America to buy a greater variety of fresh produce than people a century ago consumed in a lifetime, it entrenches retail as a winner-take-all information industry. When General Electric employs thousands of engineers to create the technology for a jet engine that saves fuel and almost never fails, it is very much part of a winner-take-all information industry.

The technology that makes those things possible demands immense investment, massive forces of specialized labor, and complex management structures to make it all work. And those markets tend to favor fewer, more dominant players. They all exhibit positive returns to scale, in which greater size makes a business more efficient rather than less. In each of these examples, the sheer scale of the biggest banks, retailers, and jet-engine manufacturers makes their products inherently more desirable than those of most upstart competitors.

Or consider the hotel business. It is a prime example of a once-fragmented industry that has become dominated by superstar firms. In 1997, the top five lodging companies in the United States controlled 43 percent of hotel rooms, according to the data and analytics company STR. By 2017 that had risen to 52 percent. Just three companies—Marriott International, Hilton Worldwide, and Choice Hotels International—have 2.6 million hotel rooms, 15 percent of the world total, and are all headquartered within a 20-minute drive of one another in the suburbs of Washington, D.C.

But when you look at the forces that have driven that consolidation, they aren’t necessarily pernicious. A hotel room is full of physical capital—the building itself, the furniture in the room. But more and more of what you’re buying when you book a hotel room is ephemeral. You want to be able to book your room on an easy-to-use mobile app, and maybe even use it to check in. You want to have confidence that the room will be clean and the mattress comfortable, even if it is a hotel you’ve never stayed in. You want to accrue loyalty points that can be used across the widest possible network of other hotels.

So the terms of competition have shifted in ways that favor a smaller number of large hotel companies and disfavor independent properties or small chains. Big global hotel companies can hire a bunch of talented software developers and product designers to build their mobile apps, then spread the benefits of that labor across thousands of properties. They can enforce quality standards across those hotels so that when you check in to, say, a Hilton Garden Inn in a strange city, you know exactly what you’re getting. And their scale allows you to accumulate points on your business trips to Cleveland that help pay for a future vacation to Bali.

Tellingly, the ownership, as opposed to management, of hotels remains widely dispersed among different types of institutions. And it is those owners of the hotel real estate who vote with their feet, concluding that the (quite high) fees the big hotel chains charge for management services are worth it compared to going independent.

It would be foolish not to acknowledge these shifts—and similar ones in nearly every other industry—in strategizing about your career. In studying how things work at many of these superstar firms for my book, I found that there are particular traits a person needs to cultivate in themselves to be successful within them.

For example, it’s important for even low- and mid-level workers to understand how their work fits into the broader corporate strategy of their organization—understanding the shifting economics of a business isn’t just for senior executives anymore.

And, relatedly, there is particular value in being a “glue person,” someone who understands how their specialty fits together with other types of technical expertise, who can ensure that teams containing people with diverse skills can work together to create something greater than the sum of its parts.

People also need to cultivate adaptability—to stretch themselves into areas that are uncomfortable rather than just doing more and more of what comes most naturally. This adaptability, I argue, is a skill that you can develop, just as you can work at becoming better at public speaking or data analysis—it just requires overcoming the natural instinct to keep doing what you’re already good at.

Fundamentally, though, you can thrive in this changing world while also accepting the critique of corporate power that economists and politicians are making, and working to fix the problems they’ve identified.

This shift of the hotel industry toward relying on intellectual capital would have had the same effects even if antitrust regulators had been more skeptical of consolidation by merger, such as Marriott’s acquisition of Starwood in 2016. It would be true even if the hotel workers’ union gained greater clout and used it to substantially increase wages for housekeepers and desk clerks. It would be true even if lobbying and campaign-finance reforms limited the ability of the big hotels to get their way in Washington or local city councils.

In thinking about the rise of winner-take-all effects in the corporate world, in other words, we need to separate the broad shifts in the economics of an industry from pernicious deployment of corporate power.

Think of the historical changes in the auto industry. On the eve of the Great Depression, there were 108 automakers in the United States, most of which are long since forgotten by history. By the 1950s, the Big Three were wildly dominant, fueled by the economies of scale of their assembly lines.

Yet we don’t remember the middle of the 20th century as a time when auto workers were exploited; to the contrary, it was a golden era in which workers without advanced education could attain a solid middle-class life.

The difference between that consolidation and the consolidation of major industries today was that the automakers had a strong counterweight to their power in the form of an equally powerful union that ensured the economic spoils that resulted from this concentration were shared with workers rather than exclusively retained by shareholders and executives.

In the late 19th and early 20th centuries, as industrialization proceeded at breakneck speed in the United States and western Europe, the downsides of the industrial age became glaringly obvious. Union leaders and other reformers strove to change the awful work conditions in many factories, and to prevent plutocrats from warping the political system. Those hard-fought battles reduced the rough edges of capitalism; it will take similar battles to do the same today.

But if you wrote a book offering advice to young people embarking on a career in that era, it wouldn’t have been, “Stay on the farm.” It would have been, “Learn how to make your skills well-suited for the industrial age—and work to make the world fairer.” And the same goes for the winner-take-all-world of the 21st century.



Normally, a scandal centered on how rich parents used bribes to win their children’s admittance into elite colleges wouldn’t play so heavily in the national news. No one much cared when Donald Trump promised large donations as his children enrolled at Penn. But the outrage over the Varsity Blues investigation perfectly illustrates what may be the most important, least understood, and underappreciated political dynamic of our era: a full-on middle-class revolt against the elites and the privileges they hoard. For all the focus on inequality and social justice, this middle-class revolt is the most important barrier standing between Democrats and the White House. They can’t afford to ignore it.

Think of what’s happened over the past decade and a half. America endured a war sold on false premises, a bailout of bankers issuing entirely toxic debt, and a massive public effort to prop up auto executives who were building cars that weren’t selling. Is it any wonder so many middle-class taxpayers resent the elites? The middle class has been forced to bail them out from their own mistakes time and time again—and yet the beneficiaries of that goodwill haven’t apologized, let alone taken responsibility. America’s middle class is Cinderella, and the nation’s elites are her evil stepsisters—only now it’s the stepsisters who get to marry the prince. It’s infuriating.

Ever since the disaster of the 2016 election, Democrats have engaged in (an often pointless) debate about whether President Trump’s supporters were drawn to him on account of economic or cultural grievances. Yes, Hillary Clinton drew more votes, but she was 1,000 times as qualified, and 10,000 times as personally appealing. She should have demolished him—but something drew many voters to Trump instead.

I’m not denying that racism (against President Barack Obama) and sexism (against Secretary Clinton) played their roles. Nostalgia surely played another. But beneath all of that was the American middle class’s belief that the Lori Loughlins and Felicity Huffmans of the world, let alone the Don Rumsfelds and Dick Fulds, aren’t asked to play by the same set of rules. The elite get all the breaks and are shown all the shortcuts. In the meantime, ordinary people are forced to pay full freight. And that’s the point. No matter how noxious he was personally—and despite the irony that he was a perfect example of elite privilege—Trump embodied the country’s desire to hit back. Justice was a long time coming.

Maybe the clearest early manifestation was the Iraq War. After 9/11, the Washington elite claimed that the country needed to neutralize Saddam Hussein’s weapons of mass destruction. Congress and the media largely went along for the ride. But $1 trillion and 5,000 lives and 16 years later, the public has been told that those WMDs had not existed after all. Yet as clear as that became, no one ever took it on the chin. No one from the Bush administration ever took responsibility. Middle-class families paid in both blood and treasure, but the people who had made the worst foreign-policy decision in U.S. history never owned their failure.

The same thing happened during the Great Recession. The nation’s banking elite had lent billions to home buyers without any realistic hope of making good on their debts. Their irresponsible lending not only precipitated a global financial meltdown, but also necessitated a bailout from the nation’s financially stressed middle-class taxpayers. Yet even after being bailed out, the nation’s banking executives never faced any real consequences. No one went to jail. They never had to repay the personal fortunes they’d made by passing out those bad loans. Once again, the middle class was called to bail out the elites who were responsible for the mess while the elites got off scot-free.

And it was the same story arc with the auto bailout. For decades, executives in Detroit had made indefensible decisions. They’d been selling less reliable cars. They’d never found a way to compete effectively with their foreign competition. They’d continually lost market share. But when the bottom fell out and they were forced to ask middle-class taxpayers for a bailout, they never took responsibility. Most of the top brass kept their jobs. And once they’d recovered, they returned to business as usual. The middle class was once again expected to foot the bailout while the execs kept on like it had never happened.

Washington wasn’t wrong to prevent a global financial meltdown. Obama was certainly right to save the domestic auto industry. But those decisions came at a real cost. After the Recovery Act had passed and the auto bailout was rolling, we had a fierce debate inside the White House about how to sequence our pushes for health care, climate change, and financial reform. As the White House chief of staff, I argued, unsuccessfully, that the American people needed the catharsis of seeing that the bankers who had gotten the country into this mess were being forced to take responsibility—that faith in government would plummet if we failed to deliver some “Old Testament justice.” Others feared that attacking Wall Street would undermine the recovery, and they won the day. Perhaps they were right on the economics. But the political implications were significant, and we’re still living with them today. The middle class believes even now that elites have license to make irresponsible decisions without paying a price.

Consider the issues the Trump White House has chosen to highlight at a moment when many of the nation’s schools are in dire need of resources and health-care costs are on the rise. Trump is focused on tariffs because there’s a widespread belief that existing trade agreements have been crafted to benefit the rich. The White House picks fights on immigration because the issue paints Democrats as champions of constituencies that aren’t following the rules. And both issues add fuel to a middle-class revolt that’s been simmering, largely unnoticed, for the better part of a decade.

Democrats have become increasingly cognizant of the anger, but too often they’ve drawn the wrong conclusions. The answer certainly isn’t socialism. Middle-class voters currently presume that elites already control the government—so why would they want to give the bureaucracy any more power? Rather, Democrats need to become the party of justice. They need to demand accountability from bad actors—and point out where Republicans would give them a pass. They don’t need to castigate entire industries, as some might recommend. But when people make decisions that affect innocent bystanders—beating the drums for an ill-conceived war, making complicated financial instruments—they should be the party standing up for middle-class interests and values.

Every time Democrats look at a problem, they think of a program. And while those programs often point the way forward, Democrats need to focus their energy on convincing the middle class that they share their values more than just their economic interests. There is more to voters than their wallets. To do that, Democrats need to prove to them that they know the difference between right and wrong, and that begins with owning the terms accountability and responsibility. Democrats need to be the ones demanding that those who fall short, no matter how privileged, be made to answer for their own decisions. Every one of us should have to live by the same moral and ethical codes. The nation’s elite shouldn’t have any special license to take the easy way out.



In the past three years, we have had two special-counsel investigations of alleged misconduct in the executive branch, and neither came to a widely accepted and lauded outcome. Robert Mueller was a formally appointed special counsel in the Russia matter; Jim Comey assumed the functional equivalent of the role in investigating and making a prosecutorial judgment in the case of Hillary Clinton’s email. Both came to their tasks highly celebrated for their independence and professional integrity. They were each believed to be especially well equipped by background and temperament to manage and resolve the most politically sensitive of assignments. By the time they had concluded their work, both came in for heavy criticism. Enchantment gave way to disillusionment.

And yet, while the results in each case left a bitter taste, Comey and Mueller went about their job in strikingly and fundamentally different ways. This suggests that, whatever may have been their missteps, blame may fall as much—or more—on the role of special counsel as it is currently structured. Despite trying multiple models, we have not gotten it quite right, dooming us to disappointment.

Consider first the differences between the Mueller and Comey cases.

Mueller was admired for being the consummate law-enforcement professional who played it by the book. Comey subscribed to a very personal moral code that required him to bend the rules, or disregard them, when required to do the right thing. In an open, swashbuckling manner alien to Mueller, Comey directly, unabashedly bypassed officials higher in the reporting chain in order to do what he thought necessary to protect public confidence in the Department of Justice. Comey also chose to make specific commitments to Congress to testify about his conclusions and to keep it apprised of case developments if any occurred. Mueller made it clear that he would prefer not to testify at all about his Russia report. If he did, he stated quite clearly, he would not depart from the text of the written, publicly released version.

Of course, Mueller was operating within specific rules for the conduct of special-counsel investigations. But Comey was hardly free of legal obligations, ethical injunctions, or the pressure of well-recognized and established norms. His choice to give the attorney general only short notice, without details, of his plan to make a public announcement of his conclusions in July 2016 did not comport with his responsibilities as director of the FBI to observe the Department of Justice’s chain of command. The department’s inspector general later found that Comey’s action was “extraordinary and insubordinate.” Comey sees his actions differently: In his book, A Higher Loyalty, he defends his “crazy idea of personally offering the American people unusual transparency, and doing it without the leadership of the Department of Justice.” The contrast with Mueller could not be starker: Mueller does not do “crazy ideas.”

Nor, in his role as de facto prosecutor, did Comey’s comments about Clinton’s carelessness in managing the security of her email systems satisfy ethical or department-policy prohibitions on commenting on the conduct of a subject or target who is not charged with a crime. The IG dismissed Comey’s justification as neither “reasonable” nor “persuasive,” but instead found that he had violated “long-standing Department and protocol.” The decision to notify Congress of the additional emails found on the Anthony Weiner laptop days before the election—a decision made in the face of the express objections of the attorney general—presented the same issues of a prosecutor marching to the beat of his own internal moral drummer.

Comey has written an entire book to justify his adherence to a higher moral calling. He explained that, because he did not “trust that the system would work,” he would have to bear special, personal, ethical responsibility to do what was right. No one would expect that sort of claim from Mueller, who has long been seen to represent what was best about the “system.”

Mueller, for his part, has been criticized for the passages in his final report that decline to “exonerate” the president, which his critics have seen as little different from Comey’s commentary about Clinton’s conduct. But there is a clear difference between the two cases. Mueller’s comments on the limits of his charge arose from a legal source that introduced, as far as he was concerned, serious complications into his legal assessment of the president’s conduct.

Mueller read Office of Legal Counsel opinions on presidential immunities to disallow a prosecutorial judgment as well as a prosecution, and after laying out the evidence of Trump’s obstructive actions, he decided to stress that nothing in his failure to reach a conclusion constituted an exoneration. It may have been an awkward move, but it remained within the realm of legal presentation—a fair distance from any Comey-like statement such as, “While I cannot find that the president committed a crime, his actions were reckless, inconsistent with the norms governing the relationship between his office and the Department of Justice and reflected poorly on his judgment.”

Mueller was averse to leaks, or to any public comment whatsoever, and when he did speak publicly about his report, it was largely with the aim of emphasizing that he would speak no more. Mueller seems likely to remain silent. Comey has gone on speaking tours, has tweeted his views about the administration, and has written a book and periodic opinion pieces for editorial pages. (And, of course, he had more to discuss by the time he left office: His conflict with President Donald Trump. Even there, Comey chose to take matters into his own hands, and, once gone from the administration, he leaked memos he’d prepared as FBI director to induce the appointment of a special counsel.)

But despite these very different approaches, by the time Comey wrapped up the Clinton investigation and Mueller signed off on his report on Russian electoral interference and presidential obstruction, they ended up at much the same place: targets of immense frustration. Comey was maligned by Democrats for inflicting political injury on Clinton, then by Republicans for what they saw as his pursuit of a lawless, underhanded vendetta against Trump; in both cases, the criticism was largely that, for reasons of misguided ethical zeal or unbounded vanity, he had ignored legal limits and crashed through norms.

Mueller’s sin was often described in very much the opposite way: as the pulling of his punches, reflected in the confusing, half-in and half-out analysis of possible obstruction of justice. The New York Times editors who had praised him as “one of the few people with the experience, stature and reputation to see the job through” when he was appointed suggested this week that “as the foremost expert on the president’s questionable doings, with expertise earned on the taxpayer’s dime,” he had proved too fearful that he would “endanger [his] own image by expressing a forthright view of those doings, even if the future of the Republic might be at stake.”

Neither the moral crusader nor the straight arrow has fared well, then, in the most recent tests of our processes for investigating high-level executive-branch wrongdoing. Of course, much of the criticism of process and performance follows closely, if it doesn’t conform exactly, to the critics’ preferred outcomes. We see this now in Democrats’ attempt to read into Mueller’s public statement a “code” for what he meant to convey to the public (Trump committed crimes) and to Congress (initiate impeachment proceedings). Republicans reject decoding and go with a crude misrepresentation of the written report: “no obstruction.” The Democrats who cheered Comey’s “crazy idea” in July 2016 thought that in October of that year, he went simply crazy, and by this no compliment was intended. Republicans embraced him on reading his first letter to Congress in October 2016, and returned to reviling him, only days later, on reading his second.

So what is to be made of our unhappy experience with these kinds of investigations?

Since Watergate, three modes of independent or special inquiry into presidential or senior-executive misconduct have produced frustration: an independent counsel, such as Ken Starr, who operates in part outside the regular system, answering in key respects to the judiciary and not to the attorney general; a senior official, such as Comey, who takes on a heroic responsibility for the failings of a flawed system; and a special counsel, such as Mueller, who works within regulations that restrict his independence of action, bind him to departmental policies and rules, and make no provision for direct communications with the public or Congress.

It is time to turn again to the question of how to structure this role to improve the prospects that it can be successfully discharged. It is not easy, especially given the inevitable politics that drive perceptions of success or failure.

But there are large questions to which we have yet to find satisfactory answers. How should a counsel be chosen, her mandate defined, and her work supervised? How should investigative independence best be balanced against mechanisms of accountability? How can the rule of law be vindicated while the public is also provided answers to legitimate issues of fitness that lie at the boundaries between legal rules and vital norms? How can Congress be fully informed of issues within its constitutional prerogative to further investigate and, as necessary, bring to a judgment on impeachment? How are individual legal and privacy rights respected without materially undermining the transparency to which the general public is entitled?

Back to the drawing board.



The presidential election is in full swing. If this were any other year, I’d be working to help reelect the Republican incumbent, hoping he would stay focused on advancing a solid free-market regulatory policy. I served on the campaign team for John McCain in 2008, on the economic-policy team of Mitt Romney in 2012, and on Donald Trump’s transition team in 2016, before I resigned over policy differences.

This year, my calculus is a bit more complicated. You see, last month I was the first former Trump staffer to call for his impeachment. I did so because I felt he was clearly implicated in up to 12 instances of obstruction of justice, impeding an investigation into foreign interference in a U.S. election. I spoke up because it was the right thing to do. I have received threats as a result, echoing Trump’s rhetoric about a coup, and targeting me as a coup plotter. I’m grateful that those threats were promptly and fully resolved by the same FBI the president now derides.

My judgment, shared by more than 700 former federal prosecutors (nearly half of whom joined the Department of Justice under a Republican president), is that Trump would have been indicted for obstruction of justice if he were an ordinary citizen, based on the contents of the Mueller report. It remains to be seen whether House Democrats will have the courage of their convictions and move forward with impeachment proceedings. There isn’t much more I can do on the impeachment front.

So now what? While I agree with many Democratic House members that Trump deserves to be impeached, I doubt we agree about much else. If next year’s Democratic Party platform is anything like the last, count me out on the overwhelming majority of it. No thanks.

On the other hand, it’s not like Trump is the reincarnation of Bill Buckley or Milton Friedman either. Quite the opposite: He’s a carnival-barking reality-television star who’d never really contemplated conservative principles until he was in his 70s.

On some important policy issues, such as trade and immigration, he is diametrically opposed to core free-market principles. On the other issues, he’s done better—for instance, he’s had success in nominating originalist judges who respect the Constitution. But how long will that last? He’s been open about his disdain for former White House Counsel Don McGahn, who was credited with channeling a conservative perspective to the president on judicial nominations.

If the Democratic Party is smart enough to nominate a moderate candidate who is respectful of Republican ideas, voters like me will have an opportunity to become an important part of the coalition that gets a candidate elected to replace Trump. And if we do, we will have a seat at the table throughout the first term.

As I consider voting for a Democratic presidential candidate for the first time in my life, I also take heart in the fact that Senate Majority Leader Mitch McConnell is likely to remain in charge of the Senate after the 2020 election. This is the part where many readers who share my criticism of Trump might grow frustrated. But I’m a Republican. Or, more to the point, I’m a libertarian who identifies more with the Republican Party than with the Democratic Party.

I do not see any inconsistency between my support both of McConnell and his Republican caucus in the Senate and of a moderate Democrat such as Vice President Joe Biden for president in 2020. I believe in the vision of the Founders, of three equal branches of government serving as checks on one another, which is limited when one party controls both the White House and the legislative branch.

McConnell would actually have more freedom to push for spending reform with a Democrat in the White House, liberated from Trump’s free-spending ways and the need to help his caucus ride his electoral coattails.

It appears that the majority of Republican primary voters remain enthralled with the cult of Trump. While I’m tempted to cast my vote on a third-party candidate or a Republican primary challenger, the history of such efforts, particularly when mounted against a sitting president, suggests that would be a complete waste.

Republican swing voters could be a formidable force in the 2020 elections, much like the “Reagan Democrats” who helped push President Reagan to victory. According to the Roper Center, only 6 percent of Republicans voted for Barack Obama in 2012, but 9 percent of Republicans voted for Obama in his historic election in 2008. I was certainly not among the Republicans voting for a Democratic candidate in either of those elections, but I might be in 2020.

I’m not the only one in that position. Polls in recent months have suggested that 8 to 12 percent of Republican voters disapprove of Trump. As the Mueller report continues to be digested by Republican voters, and its details are illuminated by continued congressional hearings, those numbers will likely continue to grow. It wouldn’t take many more defections to produce an epic defeat for the president.

Some of the Democratic Party’s primary candidates have a record of bipartisanship and of respectful dialogue with Republicans, including Biden, Mayor Pete Buttigieg and Senator Amy Klobuchar. Biden recently took a risk by extending an olive branch to Republicans, emphasizing that Trump is an obstacle to bipartisan cooperation. “The thing that will fundamentally change things is, with Donald Trump out of the White House—not a joke—you will see an epiphany occur among many of my Republican friends,” he said. I admire the character of that statement, which has done him no favors in the primary.

McConnell and Biden are old friends and have a mutual personal respect. I can appreciate those bipartisan friendships; during my time working on Capitol Hill, I have made many personal friends on the other side of the aisle. In the era of Trump, those friendships have become ever more important and challenging to maintain. I think Biden is spot-on: The post-Trump era of healing can be bipartisan if the Democrats nominate someone with bipartisan character. McConnell and a moderate Democrat in the mold of Biden could work together both to negotiate bipartisan compromises and to check the excesses of either party.

When the dust has settled in the Democratic primary, Republicans like me will be here waiting. We will be watching the candidates, and we will remember what they have said. And they might just earn our votes in the general election if they keep an open mind about us and our principled approach to policy as they navigate their party’s primary.



I was first elected to the Iowa legislature in 1978, when I was still in my late 20s. I served for seven terms in the House and another three terms in the Senate. I worked on passing nonpartisan redistricting legislation, creating REAP (a program enhancing and protecting Iowa’s natural resources), developing sentencing-reform legislation, protecting the elderly from abuse, and floor-managing one of the toughest drunk-driving laws in the nation.

While my emphasis was on bipartisan legislative undertakings, I was comfortable with my party’s priorities and felt at home in the Republican caucus. Governor Robert Ray, a Republican, was in office when I first served and was a wonderful mentor. I continue to believe that he epitomizes what is best about public service—integrity, compassion, moderation, and a spirit of rational inquiry.

But after 24 years in the legislature, I made the decision to return to Jones County to serve as a county supervisor. My four children were in or approaching their teenage years, and I felt I was needed at home. I had missed some important moments in my children’s lives—school concerts, parent-teacher conferences, sport events—and wished to make up for the time I had lost. And with college expenses on the horizon, I also needed to put more time into my law practice.

Fifteen years later, after my kids were grown and I retired from my law practice, I decided to return to the state capitol. I wasn’t quite ready for retirement and felt that I had more to contribute. What I found, however, was very different from the legislative body I had once served in.

The legislature is considerably more partisan and regimented than it used to be. I believe the increased partisanship often stands in the way of good legislation, and I’m also deeply concerned by the growing influence that big money exerts on the legislative process.

I also found a very changed Republican caucus. While I have great respect and personal regard for my Republican colleagues, I found myself more and more uncomfortable with the stance of my party on the majority of high-profile issues, such as gutting Iowa’s collective-bargaining law and politicizing our method of selecting judges. I worked for changes to improve legislation that I had concerns about, but also voted against many of these priorities.

I might have limped along—attempting to work within my caucus for what I felt was best for the people I represent—if it hadn’t been for another factor. With the 2020 presidential election looming on the horizon, I felt, as a Republican, that I needed to be able to support the standard-bearer of the party. Unfortunately, that is something I’m unable to do.

I believe that it is just a matter of time before our country pays a heavy price for President Donald Trump’s reckless spending and shortsighted financial policies; his erratic, destabilizing foreign policy; and his disdain and disregard for environmental concerns.

Furthermore, he sets a poor example for the nation and our children. He delivers personal insults, often in a crude and juvenile fashion, to those who disagree with him, and is a bully at a time when we’re attempting to discourage bullying, on- and offline.

In addition, he frequently disregards the truth and displays a willingness to ridicule or marginalize people for their appearance, ethnicity, and disability.

I believe that his actions have coarsened political discourse, contributing to unprecedented polarization and creating a breeding ground for hateful rhetoric and actions.

Some would excuse this behavior, claiming Trump is just telling it like it is—and that this is the new normal. If this is the new normal, I want no part of it. Unacceptable behavior should be called out for what it is—and Americans of all parties should insist on something far better from the man holding the highest office in the land.

All of which is to say that my decision to switch political parties has been a very difficult decision for me and has only come after considerable reflection, much prayer, and many restless nights. I had been a registered Republican for close to half a century, a Republican officeholder for 35 years, and the longest-serving Republican currently in the Iowa legislature. I am proud of many good things that the Republican Party has accomplished over the years.

I am all too aware that my decision is a disappointment to many friends and colleagues who have supported me over the years. However, the time comes when you have to be true to yourself and follow the dictates of your conscience. For me, that time is now.

I want the people I represent in Jones, Jackson, and Dubuque Counties to know that I’m still the same Andy McKean today that they knew yesterday. We still share the same basic values, are proud of our families and our communities, and want to make Iowa an even better place. I’ll continue to work for the same goals and priorities that I always have during my years in public service.

I look forward to continuing my service in the Iowa House and bringing people together to improve the quality of life for all Iowans.



“Police officers conduct approximately 29,000 arrests every day,” Chief Justice John Roberts noted in his opinion in Nieves v. Bartlett, an important First Amendment case decided last Monday. That’s roughly the population of Georgia cuffed and stuffed on an annual basis.

One might think that many arrests is too many. One might wonder about the degree to which factors such as race, immigration status, and wealth contribute to individual arrests. One might even wonder about the percentage of cases in which the power to arrest is abused.

America’s chief justice, however, worries more about the overworked police than about the people they arrest. Arresting that many folks is “a dangerous task that requires making quick decisions,” he wrote—so many people, so little time. It is thus the job of the Court “to ensure that officers may go about their work without undue apprehension of being sued.”

If that’s the appropriate aim for an Article III court, Nieves will help achieve it; the decision will make it harder to hold officers to account when they—as we all know they sometimes do—arrest citizens in retaliation for speech they don’t like. It can occur in a political-protest situation or simply during everyday dealings between police and people. Police—not all, but some—can be quick to cuff a nettlesome protester, an officious onlooker with a cellphone camera, or a mouthy suspect. The law of the First Amendment is clear: An individual should not face official retaliation for engaging in “protected speech” alone, even when that speech is unpleasant or hostile. “Retaliatory arrest” is a recognized federal cause of action.

Of course, police seldom charge anyone with “engaging in protected speech to which I object.” The charge is often something like “disorderly conduct” or “failure to obey a lawful order.” Sometimes people really are guilty of those offenses; sometimes people weren’t engaging in speech activities at all, but later claim they were. But sometimes people incur the disapproval of a cop for reasons other than those charged.

How does the law sort them out?

Arrests are supposed to be based on something called “probable cause”—which means a “reasonable ground to suspect that a person has committed or is committing a crime.” The police officer must have information at the time suggesting that possibility.

Police agencies argue that, if the officer has probable cause to arrest, the First Amendment issue should be irrelevant. That would allow a lot of First Amendment abuse. Over the years, the Supreme Court has made clear that police can arrest citizens for virtually any offense, down to driving without fastening a seat belt. Most people can’t go through a day without committing one—or more than one—crime, including crimes they haven’t heard of. What happens when a citizen claims that an officer has arrested him or her because of First Amendment speech?

Roberts joined with four other members of the Court to provide an answer: If the officer has probable cause, then his First Amendment motivation is irrelevant—unless the plaintiff presents “objective evidence that he was arrested when otherwise similarly situated individuals not engaged in the same sort of protected speech had not been.”

In other words, if you cheese off an officer by bad-mouthing the mayor (or the cop), you can be arrested if there is probable cause you did something wrong. And you can’t sue for “retaliatory arrest” unless either the arrest is for an offense such as “spitting on the sidewalk” or “affray,” which police virtually never use, or a hundred people are doing the same thing and only the ones engaged in protected speech were arrested. The burden will be on you to prove that the charge is rare—or that others were doing exactly the same thing at the same place and time and weren’t arrested. (I suspect that many courts will require proof that it really was exactly the same thing.)

After that, you have the burden to show that the “expressive activity” (speech, picketing, carrying a sign, etc.) was the real cause of the arrest. The “causation” element is hard, since you have to prove the officer’s state of mind. Officers sometimes tell you their motivation, in remarks such as “You can’t talk that way about our military.” But (surprise!) it turns out those won’t help you, because Roberts has modified his rule thus: “Because this inquiry is objective, the statements and motivations of the arresting officer are ‘irrelevant.’” Some other evidence is needed, or the case will be dismissed before trial.

Roberts is a master of the seemingly plausible distinction that in fact makes little sense. What is not “objective” about the officer’s own words? Aren’t they, in fact, the best evidence available of motivation? I suspect the thought behind this is that it’s too easy to allege that the officer said something when there’s no one around to confirm or deny. (“And then he said to me, he said, ‘There’s no one around us right now, Professor Epps, so allow me to admit that I object to your view of interpleader under Rule 22(a)(2) but in order to conceal my unconstitutional motivation, I am going to charge you with disorderly conduct instead.”) But surely that problem could be dealt with simply by requiring a plaintiff to plead something more than bare allegations.

As Justice Sonia Sotomayor pointed out in her solo dissent, arrests are usually documented in police reports, and more and more often they are recorded on video by police body cameras, news film crews, and curious onlookers. That evidence seems to me worth considering—unless the real purpose of the Roberts rule is to provide all but complete immunity to police, a result made more palatable by the kind of pseudo-plausible car-salesman patter of which Roberts is the Court’s unchallenged master.

The old legal adage claims that “hard cases make bad law.” More and more I think hard cases are good—they require both lawyers and judges to be exact about their facts and their legal theories. It is the easy case that tempts courts to sloppiness. Nieves v. Bartlett is an easy case, and the Court majority has used it to affect a lot of hard ones.

This case is easy because as the Court reviewed the facts alleged, the police officer should win. The challenged offense occurred at Alaska’s annual Arctic Man, once described by the journalist Matt White as “a weeklong, booze and fossil-fueled Sledneck Revival bookended around the world’s craziest ski race.” It’s held in a remote location northeast of Anchorage, and policed—gingerly—by a vastly outnumbered crew of state police.

During a drunken revelry at Arctic Man 2014, Sergeant Luis Nieves approached a group of merrymakers to ask them to move their beer keg. Russell Bartlett, one of the merrymakers, objected to this approach, and when Nieves tried to talk to Bartlett further, he refused to talk to the sergeant.

Bartlett had a right to do that; ordinary people do not have to talk to police if they choose not to.

Not long afterward, another trooper, Bryce Weight, was questioning other, underage celebrants about alcohol use when Bartlett approached and told Weight to leave the kids alone. By this time, it’s pretty clear that Bartlett was a bit the worse for malt beverages. He was also standing nose to nose with the lawman. Weight stiff-armed Bartlett away from his personal space—at which point Nieves came over and arrested Bartlett.

Bartlett testified later that once he was cuffed, Nieves taunted him: “Bet you wish you would have talked to me now.”

This is, as Justice Ruth Bader Ginsburg noted in a separate concurrence that is in effect a dissent, a “thin case.” There’s no additional evidence that Nieves made the admission—complete news footage of the confrontation did not survive. As Ginsburg wrote, there is “some evidence of animus … but perhaps not enough to survive summary judgment.” Had the Court majority wished to erect a heightened-evidence standard, it could have done so; instead, it came up with a rule whose nod to the First Amendment is cursory at best.

Indeed, so dismissive is the majority of the rights of citizens that Justice Neil Gorsuch declined to join, instead writing a characteristically ponderous nine-page opinion concurring in part and dissenting in part. Oddly, he situates this drunken free-for-all in the context of the struggle against a heartless administrative state rather than harried troopers in the wilderness:

History shows that governments sometimes seek to regulate our lives finely, acutely, thoroughly, and exhaustively. In our own time and place, criminal laws have grown so exuberantly and come to cover so much previously innocent conduct that almost anyone can be arrested for something. If the state could use those laws not for their intended purposes but to silence those who voice unpopular ideas, little would be left of our First Amendment liberties, and little would separate us from the tyrannies of the past or the malignant fiefdoms of our own age.

Gorsuch points out that a “probable cause is enough” rule would target only police who make completely illegal arrests. But “retaliatory arrest” suits are designed to “guard against officers who abuse their authority by making an otherwise lawful arrest for an unconstitutional reason.” The opinion suggests that probable cause should be a factual element for the jury to consider, not an almost-absolute bar to getting a case to that jury in the first place.

Sotomayor wrote a full-throated dissent. The new rule, she wrote, defies precedent. The Court already has a venerable test for First Amendment retaliation in other contexts (such as, for example, disciplinary action against dissenting government employees). It’s called the Mt. Healthy test and comes in two parts. First, can the plaintiff show that the protected speech was a “‘substantial’ or ‘motivating’” factor” in what happened to him? If so, then the burden shifts to the government to show that it would have (not, as in a test for “probable cause,” could have) taken the same action even without the protected speech. Barring the evidence of what a police officer says makes no sense, she argued, and “risks licensing even clear-cut abuses.” The result “shortchanges [the First Amendment] in the name of marginal convenience.”

Roberts’s test comes to our constitutional doctrine more or less out of thin air. The chief justice, a First Amendment tiger when the rights of rich campaign donors are at issue, clearly frets that ordinary people—protesters, let’s say randomly—will bother hardworking police. Remarkably enough, Roberts gathered five votes for his invented rule—his own plus those of Justices Stephen Breyer, Samuel Alito, Elena Kagan, and Brett Kavanaugh. The accession of Breyer and Kagan should underline an important truth about this court—that the “four liberals” shorthand disguises that two of the four are very, very moderate indeed on many issues.

This article is part of “The Speech Wars,” a project supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press, and the Fetzer Institute.



Progressives do not want Donald Trump, Mitch McConnell, or other powerful Republicans to ignore the Supreme Court when they disagree with its rulings. Doing so would upend a constitutional order that has prevailed for more than 200 years. 

Under judicial review––the courts’ ability to check the constitutional validity of laws that legislative majorities pass and executives sign––the postwar Supreme Court has repeatedly thwarted democratic majorities. It has struck down Jim Crow segregation, prohibitions on interracial marriage, laws denying the right to an abortion, laws prohibiting sodomy, and laws forbidding same-sex marriage.

Yet last week, the New York Times columnist Jamelle Bouie, anticipating a progressive majority governing alongside a conservative Supreme Court, argued that SCOTUS has always been political, that “no reform short of ending the power of judicial review will disentangle it from ordinary, partisan politics,” and that progressive leaders should mimic past presidents “who resisted the Supreme Court’s claim to ultimate interpretive authority,” so that they can advance economic policies that Chief Justice John Roberts may find unlawful.

Like Ben Shapiro, who in 2005 published a Townhall column calling for an end to judicial review, Bouie marshals populist rhetoric about “the prospect of government by justices” that ostensibly “threatens to undermine both the court and our democracy.” In his telling, a conservative court will force Americans “to conform to their particular understanding of the Constitution despite equally valid alternatives,” as if there is any way of avoiding contested constitutional outcomes.

It may, he says “shackle future majorities for decades to come.”

It is “a problem of power,” he writes, and to solve it, adding extra SCOTUS justices to dilute the conservative majority, itself a radical proposal, isn’t enough.

Calls to flout judicial review made more sense in the era of Dred Scott or the Civil Rights Act of 1875.

Today it is shortsighted and reckless, as anyone old enough to have lived through 9/11 and its aftermath ought to know. “Ending the power of judicial review would leave legislators free to do whatever they want, restrained only by their own consciences and their fear of political repercussions,” Jacob Sullum points out at Reason. “Depending on who happens to be in power, legislators might enact Bouie’s policy agenda, or they might endorse torture, approve warrantless searches, abolish the presumption of innocence, close down newspapers that criticize them, or exclude immigrants based on their race.”

It’s a problem of power––Bouie is proposing to remove a significant check on its abuse.

His talk of government by unelected judges that would shackle the majority also elides the degree to which the progressive coalition favors many judicially imposed, antimajoritarian outcomes on a wide range of policy matters.

Trying to paint the court’s conservative majority in a negative light, Bouie complains that Chief Justice Roberts “dissented in the case that legalized same-sex marriage, voted to allow the death penalty even in cases where it might cause excruciating pain and suffering, and wrote the majority opinion upholding Trump’s travel ban despite its clear roots in the president’s anti-Muslim bias.”

But Roberts grounded these opinions in democratic concerns. In the case that legalized same-sex marriage, Roberts’s dissent complained that the Supreme Court was “stealing the issue from the people,” and that the majority’s opinion used judicial review to overturn duly enacted laws in states including Michigan, Ohio, Kentucky, and Tennessee.

In the death-penalty cases, Bouie wanted the court to use judicial review to overrule state laws, prohibiting some executions regardless of the democratic will.

Americans were fairly evenly split on the travel ban—depending on the wording used in each poll. Bouie wanted the court to prohibit its implementation through judicial fiat.

The Supreme Court ought to thwart the will of democratic and legislative majorities by fiat whenever a law or an action violates the Constitution. Justices will not always interpret the Constitution correctly, of course. Judicial review has led to wrongheaded results in the past and will again in the future. But the check it imposes on the tyranny of majorities is indispensable.



Julián Castro, the former secretary of housing and urban development under President Barack Obama and former mayor of San Antonio, has put forth perhaps the most ambitious immigration and police-reform plans in the Democratic primary.

A second-generation immigrant who is widely credited with fostering an economic revival in San Antonio, Castro hopes that his progressive policy record and compelling personal story will set him apart from a large (and growing) Democratic presidential-primary field. I recently spoke with Castro about his immigration and policing plans, what Democrats should do about the Supreme Court, and whether he thinks Donald Trump has committed impeachable offenses, among other subjects.

In our exchange, Castro called for a federal database of police shootings, said that the post-9/11 shift toward treating illegal entry into the United States as a crime has “led to so many of the problems we see today,” and argued that Trump should be impeached, despite opinion polls showing that a majority of the public has yet to support that move.

A transcript of our conversation follows, edited for length and clarity.

You’ve put forth an aggressive plan for eliminating racial discrimination in policing that, among other things, states that it will “establish responsibility and accountability for officers to intervene if they witness a colleague utilizing excessive force or inappropriate conduct.” What does that mean, exactly? Are you talking about a federal law or regulation that would penalize local police officers who ignore misconduct by their colleagues?

Yeah. I’m talking about using both the carrot and the stick incentives where there are grant programs, and also legislation to ensure that if one officer witnesses another officer engaging in misconduct, that that officer—the witness—is compelled to actually report that. Because too often, those types of things go unreported.

Your plan would also require police officers to “identify themselves, issue a verbal warning, and give the suspect a reasonable amount of time before the use of force, and to only use deadly force as a last resort.” Would there be any exceptions to that, and are you concerned that that kind of approach would put the lives of police officers in danger?

Yeah, I believe that’s the best approach. I saw research not too long ago that demonstrated that police departments across the country that institute the most restrictive policies in terms of when an officer should use lethal force, both still have good rates of officer safety compared to other departments—but also have lower incidents of innocent civilians being harmed.

The Justice Department performs oversight over local police to ensure that they comply with the Constitution. But some of what you’re talking about is addressing local police policy. Is it constitutional for the federal government to dictate policy for law enforcement at that level?

The question is whether it’s constitutional for the federal government to do that. Well, the way that I approach it is, we will do everything we can under the Constitution to hold police departments and officers accountable. And where we need to use incentives [through] our federal grant process, we can use that.

So this is something that I didn’t see in the plan, but I might have missed it: Would you establish a federal database to track police-involved shootings?

You’re right—what we talked about in the plan is the decertification of officers. But I would like to see a database of officer-involved shootings, because we don’t have a database right now.

Do you think that’s important?

Of course, sure. And I don’t believe the public should have to rely on the efforts of journalists across the country, although those are noble efforts. There should be a comprehensive federal database of officer-involved shootings, of use of excessive force, and also, as I said in that plan, the decertification of police officers.

Your immigration plan would make entering the United States illegally a civil infraction. Why?

No. 1, I believe that’s more effective than what we’re doing now. What we’re doing now is a total disaster. It’s ineffective and it’s inhumane. From 1929 to about 2004, we actually used to treat someone crossing the border as a civil violation, not a criminal one. We started treating it as a criminal violation post-9/11—that’s what’s led to so many of the problems we see today. A huge backlog of immigration cases, incarceration of people, the separation of little children from their mothers. So I would actually treat it as a civil violation and create an independent immigration judiciary, and add more judges and support staff to be able to get people seeking asylum, or who are otherwise in that immigration judicial process, an answer, so people aren’t waiting in limbo for years.

When you say that criminalizing illegal entry hasn’t been effective, what do you mean by “effective”? Effective in doing what?

I think any type of way that you want to analyze that. Let’s take, for instance, Trump’s standard—his administration told us about a year ago that they’d crack down on these migrants and were cruel enough to separate these kids from their parents, that that would deter more families from coming. And the opposite has happened. More families are coming now than were coming when he instituted that policy of family separation.

I believe that treating this as a civil violation still holds people accountable, and it’ll be more effective than what we have now. It clearly hasn’t been effective. We’ve seen more people coming, and in the name of the people of the United States, migrant families have been treated very inhumanely. Which is a stain on all of us, as a country.

Does the United States need an internal immigration agency like ICE as opposed to one that guards the borders, and if so, what should it look like, and what should its priorities be?

Yeah, of course we’re always gonna have enforcement. There’s gonna be enforcement not only at the border, but also beyond the northern, southern border, and the ports. But I don’t believe it should look like ICE.

In my plan, I call for breaking up ICE and returning its enforcement functions to the Department of Justice. I’ve also called for specific changes for how enforcement in the interior would be done. For instance, right now they have the authority to, within a 100-mile radius of the border—you know, 100 miles that stretch from any point on the border—to do interior checks and enforcement, and I believe that power has been abused. And so I’ve called for curtailing that significantly.

When you say their power has been abused, what do you mean by that? Do you have examples of what you’d describe as abuses of power by ICE?

Sure—getting onto Greyhound buses and profiling people who they think look like immigrants. Harassing folks because they look a certain way. I completely disagree with that.

So you’ve been an Obama-administration official, you were the mayor of a blue city in a red state, and you’re a second-generation immigrant at a time when that issue is at the center of the American political conversation. So why do you think that you have yet to gain a lot of traction in the early polls?

We haven’t had an opportunity yet to reach a larger audience. That’s the purpose of these debates that are coming up during July, the ones beyond that, and what I’ve seen is steadily increasing support in my polling. Our fundraising has accelerated in the second quarter versus the first.

I was starting this campaign from scratch, I hadn’t run for president before, I hadn’t run for Senate, didn’t have this huge email list, which is so crucial to fundraising these days. So I’ve built this up from scratch, and now I’m getting stronger and stronger in this campaign. More people are coming to our events in Iowa and New Hampshire and the early states. We’re starting to get more media attention.

We still have about 32 weeks to go until the Iowa caucus and haven’t had a single debate yet. It’s very premature in a 23-candidate field to assess whether someone’s gonna prevail on February 3 in the Iowa caucus.

Speaking of the large field, some people have argued that candidates such as you who have a strong background in the state where they’re from should have run for Senate rather than run for president first. Did you consider that, and what made you decide to run for president instead?

I have a strong, positive vision for the future of our country. That’s where my experience is at, at the federal level as a federal executive, which the president is. So my experience directly matches the office that I’m seeking.

Democrats have, over the past few years, especially after the 2016 election, been accused of relying too heavily on what is often referred to as “identity politics.” How would you respond to that critique?

Well, that’s in the eye of the beholder. Identity politics can be sliced and diced in a million different ways. I focus on telling the truth and painting a vision of what the country can become in the future if we make the right investments together in things like health care, and education, and jobs and opportunity.

But I don’t shy away from addressing the fact that some people in different contexts are treated differently in this country. All of that goes together as far as I’m concerned. I don’t believe we need to choose between addressing economic issues and addressing issues of social or racial justice.

Speaking of economic issues, what would you say to someone who says, “You know, I’m not a huge fan of Trump, but the economy’s really strong, and he’s doing a really good job with that—so why should I vote for someone else?”

The economy’s really strong in spite of Donald Trump, not because of him. Donald Trump is like the guy who picked up the ball at the opponent’s two-yard line, because Barack Obama carried it from the two-yard line of the home team to the opponent’s two-yard line.

When Barack Obama became president, the country was losing several hundred thousand jobs a month. And we had the longest stretch of positive economic growth that this country has ever seen. So this president inherited tremendous forward momentum when it comes to the economy, and it’s not due to him that this country is doing well. In many ways, it’s in spite of him.

So you support Medicare for All, but there’s some confusion among the public about what exactly that entails. So I guess my question is, does that mean you support eliminating private insurance, or do you support allowing people to buy into Medicare?

I support everybody who wants Medicare to get Medicare, and if somebody has private insurance that they want to hold on to, I believe that’s fine as well. What I don’t believe: that anybody in our country should go without health care just because they’re poor or don’t have resources. So I agree with those who have called for major reform in our system.

Do you support eliminating the filibuster?

Yeah. If the choice comes down to universal health care or adhering to a Senate rule that is not in the Constitution and has already been violated many times, then I’m going to choose improving the lives of millions of Americans by getting a universal health-care bill.

The other great obstacle to any progressive legislation, if Donald Trump is defeated in 2020, is the Supreme Court. Do you support any changes to the Court, such as expanding the size limit, or instituting term limits, or anything like that? 

I’m intrigued by the idea of term limits. I don’t agree with expanding the size of it, because, you know … we could expect Democrats to increase the size of it to 11 in 2022, and the Republicans will come back and increase the size of it in 2032. You know, I think the more thoughtful approach would be to consider whether there should be term limits. I’m open to that.

Has Donald Trump committed impeachable offenses, and if so, what are they?

He has. As the Mueller report pointed out, there were 10 different instances where he either obstructed justice or tried to obstruct justice. And I’ve called for Congress to begin impeachment proceedings.

The question for Congress and for the American people is, Will there be any accountability here? Or is this the new normal that we want from the United States president? I don’t think this should be the new normal.

So do you think the House should impeach Trump despite the fact that, though the public seems to think he’s committed crimes, they are at the moment opposing impeachment?

Yeah, I don’t believe we should make our decisions based solely on public-opinion polls. When somebody has committed these kinds of acts … opinion polls change all the time. Someone asked me recently about the way that public-opinion polls changed as the impeachment process unfolded with President Nixon.

If the American public has the opportunity in full to digest the actual findings and the content of the Mueller report, and they have testimony on that, I’m confident that more Americans will understand the gravity of the offenses, and why they’re impeachable.

The Great Recession annihilated much of the wealth accumulated by middle- and working-class homeowners, particularly black people and Latinos. And in many ways, those communities still haven’t recovered—there was an article in USA Today about seniors being taken advantage of by private lenders. What can the next president do to address this problem?

Make big investments in housing affordability and reform our laws in regard to our approach to keeping people in their homes. We can invest in the FHA, which has been a tremendous asset for creating homeownership, particularly for African American and Latino families over the last few decades.

And we can learn the lessons in terms of the crisis, the housing crisis a decade or so ago—learn the lessons of the past, and not back off from the kind of regulation that’s gonna help ensure that those kinds of thing never happen again.

The Department of Justice under the Obama administration levied some pretty heavy fines on banks that engaged in forms of discrimination. Do you think they should have been more aggressive on the criminal side?

For which acts are you asking about?

Should the Obama Department of Justice have pursued more criminal cases against banks that broke the law, or do you think its pursuit of fines on the basis of their conduct was sufficient?

I think going forward, they could do more—that a future administration could be more stringent, even tougher on them. And Americans understand that nobody should be—just as organizations shouldn’t be immune to or outside of the law—nobody should be outside of or immune from punishment. So I do think if we had this same incident happen again, there would be executives charged.



On Tuesday, Representative Justin Amash faced his constituents for the first time since becoming the only congressional Republican to urge Donald Trump’s impeachment.

For two hours, he stood at the front of a high-school auditorium in Grand Rapids, Michigan, taking comments and questions from a divided crowd. A majority of those present joined a standing ovation after one constituent declared, “I want to salute your courage.” But some attendees insisted that President Trump is the victim of groundless persecution by his political opponents, and that their GOP congressman’s call for impeachment is a betrayal.

Amash got the best of the debates that ensued.

Several Trump supporters alleged that the FBI was guilty of abusing the process for obtaining warrants under the Foreign Intelligence Surveillance Act (FISA), and ought to be punished for spying on the Trump campaign. Why didn’t Amash seem to care about “deep state” abuses like that?

In reply, Amash accurately noted that he has been the leading champion of FISA-reform efforts in the House of Representatives, that he had introduced an amendment that would have reined in the ability of the surveillance community to spy on all Americans, and that both the Trump administration and many congressional Republicans had opposed him, fighting to expand those very powers.

“They don’t support FISA reform,” he declared. “They are not protecting your rights. They want to protect the president. But the rest of you, forget about it. The government can spy on all of you, and they don’t give one crap about it.”

But it was Amash’s comments about character and virtue that best underscored why he presents a potent challenge to Trump loyalists in the Republican Party.  “More than anyone in our government, we need the president to be ethical, to be of high moral character, and to do the right thing,” he said. “And the pattern you find in the Mueller report is someone who does not meet that standard.”

Trump’s moral deficiencies trouble many of Amash’s constituents.

“As a retired educator, a grandparent, a parent, someone who has taught in Sunday schools, I don’t know how we tell our children not to lie, that it’s wrong to lie, when it’s evident throughout the highest levels of government,” one woman said. “I don’t know how we teach our children not to bully on the playground when bullying comments are constantly coming out in the media.”

The crowd responded powerfully when Amash spoke against the example Trump was setting for children, perhaps because Amash made the version of a moral critique most likely to resonate with constitutional conservatives and libertarians. After a Trump supporter noted that the economy is strong and complained that many Americans oppose the president anyway, for example, Amash said:

Think about how well things are going with the economy and people are still so mad. Why is that? … I think it’s because of the tone we’re setting at the top. We’re not treating one another with respect. We need to bring that back. We need to treat one another with love and respect. And we don’t have that right now. If there’s one thing that I pray and hope for our country it’s that we’ll love each other and care about each other regardless of our backgrounds and differences.

This kind of division is dangerous and it destroys liberty.

I’m a big believer in liberty and the Constitution. Nobody cares about liberty in Congress more than I do. One thing you see around the world is liberty cannot survive in a system where people hate each other and where there is no virtue. You can’t have a system like that. Our Founders and Framers talked about that. You have to have people who care about virtue and you have to have love.

If you hate each other, if you disparage each other, other systems prevail … When you have people who are angry and upset at each other all the time, you’re much more likely to create a system where the government takes more control.

Later, another Trump supporter declared that the people applauding Amash for coming out for impeachment might pretend to like him, but were unlikely to vote for him in the next election. He chided Amash to wake up to that reality. Amash replied:

I represent the entire district. So it doesn’t matter to me if a person voted for me or didn’t vote for me, or donated to me or didn’t donate to me. I think I’ve been pretty clear about that. That’s not going to change my principles and who I am … I agree with you that many of the people cheering me on aren’t going to support my campaign. I don’t care. It doesn’t matter to me. This is what it means to be a bigger person. It doesn’t matter to me that some people won’t support me or are hypocritical. You have to do the right thing regardless.

Amash’s criticism of Trump may never spur an impeachment inquiry. But the nature of it forces conservative Trump voters to make a clarifying choice: To stay loyal to a president of bad character, they must attack a man of good character who votes in accordance with the principles they share.



No president of the United States has ever been prosecuted. Richard Nixon, who likely came the closest, was rescued from the threat of criminal charges by a pardon bestowed by his successor, Gerald Ford. But now, in the wake of the Mueller report’s account of potential obstruction of justice by President Donald Trump, Democratic politicians are beginning to weigh the possibility that Trump will be brought before a court.

“I want to see him in prison,” Speaker of the House Nancy Pelosi reportedly told House Democrats in a closed-door meeting earlier this month. And asked by the NPR reporter Scott Detrow whether, as president, she would support bringing an obstruction case against Trump, the Democratic presidential candidate Senator Kamala Harris answered: “I believe that [the Department of Justice] would have no choice and that they should, yes.”

Harris framed her answer in the language of justice: “Everyone should be held accountable, and the president is not above the law.” Yet her comments should be concerning to anyone who cares about maintaining the independence of law enforcement from political influence.

The idea that a presidential candidate can permissibly endorse the potential prosecution of a political opponent is itself a sign of how much damage Trump has done to that principle. Part of that damage comes from Trump’s own insistence on treating the Justice Department as a personal political tool, which eats away at the codes of behavior that have, in the past, barred politicians from making similar promises. Part of it also comes from the strain Trump has put on the constitutional system. Trump’s conduct is what has forced these questions on presidential candidates and political leaders: What, after all, do you do with a possibly criminal ex-president? What does it mean to balance accountability against the importance of preserving an apolitical system of law? How, in the wake of the Trump presidency, are Americans to understand what “justice” means?

Trump has long enjoyed calling for the prosecution of his enemies; “Lock her up!” was a favored mantra during his 2016 campaign against Hillary Clinton. He has demanded that investigations be launched into and charges be filed against Clinton and others, including former FBI Director James Comey. According to the evidence set out by Special Counsel Robert Mueller, these are not idle musings: Trump privately demanded several times that the Justice Department “look into” his opponents, at one point calling then–Attorney General Jeff Sessions at home to ask that the department investigate Clinton. When Sessions did not oblige, Trump began attacking him publicly for his failure to do so.

Harris’s statement, and to a lesser extent Pelosi’s, is a long, long way from “Lock her up!” But it is also a lot closer to that promise than anyone should be comfortable with. In a liberal democracy, the government is constrained by a network of rules, such as the presumption of innocence, that limits the deployment of power. Trump’s own efforts to use the Justice Department to go after those he dislikes have provided us with a vivid demonstration of the importance of independent law enforcement. Nothing good will come of a system in which the chief executive may direct the full force of the state against those he believes have wronged him. And nothing good will come of a political candidate running for high office on the suggestion that her administration would prosecute a particular individual. As if to emphasize the norm-breaking aspect of Harris’s statement, Trump commented in an ABC interview that “probably, if I were in her position,” he would have said the same.

The delphic language of the Mueller report forced Democratic candidates to grapple with this issue. Mueller did not reach a conclusion on whether the evidence would support a charge of obstruction of justice against Trump, because, he wrote, a Justice Department memo precluding the indictment of a sitting president barred the special counsel’s office from doing so. Yet he also noted that “a President does not have immunity after he leaves office”—and in part because of this, the office “conducted a thorough factual investigation in order to preserve the evidence.”

Mueller’s implication was that future prosecutors may be able to turn to the record preserved by the report in evaluating a possible prosecution of citizen Trump. So presidential candidates weighing how to handle hypothetical charges against Trump are, in some sense, picking up a question that Mueller left on the table. This is different from Trump’s own promise to “lock [Clinton] up” on the basis of conduct that, according to Comey, would have left “no reasonable prosecutor” able to bring a case—not to mention Trump’s insistence that Comey and others should be charged for behavior that is not criminal at all.

Harris gave the wrong answer, and Pelosi should not have said what she did. But Mueller’s invitation raises a series of issues that are not easily resolved. The question of how to handle potential criminal charges against Trump after he leaves office is actually several questions: First, should a presidential candidate weigh in on the matter? (Arguably no, as my Lawfare colleague Benjamin Wittes has written.) Second, should a future Justice Department consider bringing charges against Trump at all? It is, after all, not the president but the attorney general who would supervise the department in making that decision and evaluating the evidence—and it is the independence of that prosecutorial judgment that has come under attack during the Trump presidency.

This leads to the third question: To what extent should a future president be involved in the Justice Department process leading to that determination? And, finally, should the president let a potential prosecution go forward? In his pardon of Nixon, which precluded any indictment by the special prosecutor’s office, Ford argued that a trial of a former president would risk destroying “the tranquility to which this nation has been restored” after the bitterness of Watergate.

These are complicated issues, not least because they force, once again, a confrontation with the puzzle that Trump has repeatedly posed: While independent law enforcement is a foundation of the American constitutional system, the Justice Department is nevertheless under the direct control of the president, who has the power to intervene in an investigation or prosecution if he so chooses. So does the president exist above or outside the law? Is producing accountability possible in a system under which a sitting president may not, in the understanding of the Justice Department, be subject to prosecution by the law-enforcement apparatus he oversees?

“There is an important national interest in ensuring that no person—even the President—is above the law,” reads the 2000 Justice Department memo enshrining the principle that a sitting president may not be indicted. But the memo goes on, “Recognizing an immunity from prosecution for a sitting President would not preclude such prosecution once the President’s term is over or he is otherwise removed from office by resignation or impeachment.”

Any presidential campaign is an effort to will into existence a possible future. Usually, this imagined future is simpler than the one that will actually come into existence, and so far the Democratic candidates have largely sought to use their campaigns to imagine a post-Trump future wiped clean of the current president’s legacy. But the question of how to handle a potential prosecution of Trump zeroes in on the ugly, difficult aspects of rebuilding American democracy.

The best way to understand what America will be after Trump is to envision it as a post-conflict society in need of reconstruction—and like other post-conflict societies, there will be hard decisions to be made about how to square the need for accountability and justice with the necessity of healing, and how to balance justice with accountability when the two do not always coincide. South Africa, for example, offered immunity from prosecution to perpetrators of apartheid violence in exchange for truthful public testimony about the abuses they had committed.

In “Federalist No. 74,” Alexander Hamilton describes the pardon power as not only a manifestation of mercy but also a political tool to be used in moving a society forward after conflict: “In seasons of insurrection or rebellion, there are often critical moments, when a well-timed offer of pardon to the insurgents or rebels may restore the tranquillity of the commonwealth.” Ford pointed to this understanding of clemency in defending his pardon of Nixon before the House of Representatives.

The next president, whoever he or she may be, may not reach the same decision as Nixon’s successor, but he or she is going to need to weigh the same problems that Ford considered with care and seriousness. How can the country best hold Trump accountable for the wrongdoing described in the Mueller report and placed on display throughout his presidency? Even if criminal charges are merited, are they the best way to achieve this goal? How great is the risk that any such prosecution magnifies perceptions of law enforcement as a political tool, and so further eats away at public faith in the legitimacy of the government? Is that risk nevertheless worth running?

The hitch, of course, is that the 2020 campaign requires the country to confront these questions about what things will look like after the end of a Trump presidency while it is still very much in the midst of that presidency’s chaos. And any eventual consideration of prosecution will be inflected by how the House of Representatives chooses to play its cards: The Justice Department memo, after all, points to impeachment as a mechanism of holding a criminal president accountable, distinct from prosecution while in office.

Although Pelosi has suggested that a possible prosecution later would render moot any impeachment now, there is no reason that this should be the case. Democratic presidential candidates are considering what they might do in the future to hold Trump accountable. But the House must also ask itself what it will do right now.



Updated at 1:28 p.m. ET on June 13, 2019.

The Office of Special Counsel says that Kellyanne Conway, a senior adviser to President Donald Trump, repeatedly violated the Hatch Act and should be fired.

OSC says Conway broke the law by disparaging Democratic candidates for president, both while appearing on TV in her official capacity as an adviser to the president and on her Twitter feed. The Hatch Act prohibits most executive-branch employees from politicking. OSC, not to be confused with the office of former Special Counsel Robert Mueller, is the federal agency that polices the federal civil service.

OSC’s recommendation is important not because it is likely to result in Conway’s firing, but because it is almost certain not to. There’s no question of Conway’s guilt here: OSC doesn’t waffle about whether she broke the law, and there’s no Mueller-style legalistic parsing. The report’s conclusion is clear, as is the recommended punishment. And yet the only person who can punish Conway is the president—the very man on whose electoral behalf she broke the law, and who has made clear, as recently as Thursday, his willingness to break the law in order to win elections.

“Ms. Conway’s violations, if left unpunished, would send a message to all federal employees that they need not abide by the Hatch Act’s restrictions. Her actions thus erode the principal foundation of our democratic system—the rule of law,” OSC wrote in a letter to the president. The office identified at least 10 instances of Conway breaking the law.

But Trump has already made clear that he has no respect for the rule of law. The White House promptly dismissed the report. “The Office of Special Counsel’s unprecedented actions against Kellyanne Conway are deeply flawed and violate her constitutional rights to free speech and due process,” a statement said, complaining that OSC was “influenced by media pressure and liberal organizations” to “weaponize the Hatch Act.”

In a letter to OSC, White House Counsel Pat Cipollone argued that the process didn’t give Conway enough time to respond, that she is not subject to the Hatch Act, and that OSC’s interpretation violates Conway’s First Amendment rights. Yet this is not Conway’s first run-in with OSC, and the office noted that in the past she has declined to respond to its reports. Nor does the White House’s claim of politicization hold much water. OSC isn’t headed up by some Barack Obama–era holdover or some strident critic of the president’s in the Walter Shaub mode. Henry Kerner, who leads the office, is a Trump appointee and a former Republican staffer in Congress.

Conway is best known for the indelible, Orwellian phrase “alternative facts,” which she coined to defend the administration’s lies about crowds at President Trump’s inauguration. But she has repeatedly tangled with federal watchdogs over the law, too. In February 2017, she encouraged people to buy clothes from Ivanka Trump’s line, earning a scolding from the Office of Government Ethics. In March 2018, OSC found that she had violated the Hatch Act by both endorsing the Republican Roy Moore in a race for the U.S. Senate in Alabama and encouraging voters to oppose his Democratic rival, Doug Jones. Jones won the race.

It’s not that Conway is unaware of the rules. She’s openly thumbed her nose at them. In a May interview, when asked about overstepping the rules, she replied, “If you’re trying to silence me through the Hatch Act, it’s not going to work … Let me know when the jail sentence starts.”

Her cavalier attitude toward the law, while galling, is also probably safe. The Hatch Act is written with the understanding that the president would not want his aides flagrantly and wantonly violating the law, and only the president can fire a senior aide for violating the law. In the Trump administration, that has been revealed as a loophole, since this particular president has no inclination to punish violations that benefit him. (One of the most outspoken critics of Trump’s disrespect for laws and regulations has been the longtime Republican lawyer George Conway, who has used his Twitter feed to criticize the president. He also happens to be married to Kellyanne Conway. As of this writing, George Conway had not yet commented.)

“Ms. Conway’s persistent, notorious, and deliberate Hatch Act violations have created an unprecedented challenge to this office’s ability to enforce the Act, as we are statutorily charged,” OSC wrote. “She has willfully and openly disregarded the law in full public view.”

Conway’s behavior creates a challenge for the press, as well. Television programs have continued to invite Conway on as a guest, despite her long record of dishonesty. But, as the report documents in excruciating detail, she’s also using the access they grant to their viewers to flout the law, delivering attacks on the president’s opponents that she’s legally barred from making.

The report poses little challenge to the White House, though. Boosting Trump’s political prospects, undermining ethics watchdogs, and assailing the rule of law are all part of the same portfolio. Conway is doing precisely what her boss wants her to do.



My mother achieved real competence in Irish, and then gradually lost it. Her exertions were motivated by unrequited love, her ambitions, and even her politics. After she died, I found all these great propaganda pamphlets from the early 1980s, with titles like “Britain’s War Machine in Ireland.” All of them aimed at Irish Americans like herself. But it was hard, in the exurbs of New York with a dying mother and a growing son, to keep up the social circles that support a language. And gradually even we stopped using the ornamental bits of it.

And right now, the ornamental bits of it are almost all I have. When I’ve gone through my cycle of rebel songs, I have tried soothing this baby girl by counting in Irish. Or whispering, over and over, “Mo chroi, mo thaisce.” My heart, my treasure.

Patrick Pearse once wrote a fantasy of what Ireland might be like one century after his time. He envisioned the Ireland of 2005 as a warmer place, because the bogs had been drained. And he envisioned it as a country in which the Irish language was restored totally. Only a few schools still taught English as a second language. With the collapse of the British Empire in the 20th century— he was right about that!—the English language lost its importance. In his dream, the Irish Parliament in 2005 was debating a bill for making the study of Japanese compulsory in seaport towns in Ireland, owing to its utility as a commercial language.

The story didn’t go that way. I wrote to you earlier, Father, about the plunder of Ireland. How the English have robbed Ireland not just of its wealth, and of many of its lives, but of its sense of self. After the famine, the Irish mind awakened to the possibility of losing even the memory of itself. And it responded with a self-conscious attempt at cultural revival.

What most people say is that the Gaelic cultural revival of the late 19th and early 20th centuries produced a lot of good and some great literature in English—Yeats, Joyce, and so on. And the revival of Irish sport under the Gaelic Athletic Association was a crushing success. I know because I can listen live to the broadcast of Mayo and Dublin fighting to a draw in Gaelic football on my smartphone. But we are supposed to conclude that the language revival was doomed, and possibly destructive to have tried. In his book about the history of the Irish language, Aidan Doyle concludes, “Anybody who sets himself an impossible task is bound to fail. My contention … is that by the time the Gaelic League was founded, it was too late to reverse the language shift. If this is correct there was never a real possibility of Irish becoming a majority language in Ireland again.”

So should we all have a laugh at Pearse? Currently there are more than 400 million native English speakers in the world. Some estimates say that nearly one in five people on the planet is studying or speaking English as a second language. In many places, studying English is compulsory. The numbers for Irish are not so encouraging. I remember the day I began contemplating the current estimated number of native Irish speakers: 35,000.

A little while after I made my vow to learn Irish, my father-in-law took me to Colorado for an event commemorating the World War II company his father was in, the one that cut up through Europe from Anzio and eventually liberated Dachau. At the hotel in the morning, instead of doing a little lesson of Irish on a website I was subscribed to, I was reading The Irish Times, with the latest report on how the Gaeltacht, the various regions of Ireland where Irish is still spoken daily, was dying. By 2025, Irish will cease to be a majority language in the Gaeltacht, it said. The latest studies showed that once the percentage of Irish speakers in these areas fell below 67 percent, Irish would become a language of the old; the young would fail to develop freedom of expression in Irish and would instead form their identity and self-conception as English speakers. This is a disaster for the language for obvious reasons. The Gaeltacht is where almost all serious students of the Irish language finally finish acquiring it. The few tens of thousands of native Irish speakers today already struggle to support the compulsory learning of the hundreds of thousands of students of the language in Irish schools. And most of these students will fail to acquire it anyway. Beyond that, the Gaeltacht still has some pull as a physical and spiritual heartland of the nation, the repository of true Irishness.

Contemplating this report, I had some questions. Why the hell was I trying to learn Irish? It takes real effort to learn a language, and often a decent chunk of money too. I got up from the desk and thought about that number. Thirty-five thousand native speakers, and I spent a couple of hundred dollars on kids’ books and dictionaries, and a subscription learning website. Thirty-five thousand native speakers, and none of my actual Irish family members is counted among them. Not one of them is even in the half million or so who are categorized, generously, as competent second-language speakers of Irish. Thirty-five thousand. If I go through with this, I am a madman.

I got into a little tour van that was going to take us to the sights for that day, and I sat next to a man named Randy Palmer. He had a big, round Oklahoman accent, and his baritone voice made him sound like a Plains-state version of David Carradine. He was a member of the Kiowa nation and a veteran of the Vietnam War. Because I was thinking about languages, I asked him if he spoke the language of the Kiowa nation. He didn’t. He said that a few of the young people were interested in it. So then and there, I furtively started researching on my phone. There are only 12,000 Kiowa living. And a generous estimate is that there are just 100 speakers of the Kiowa language. None of them speak it as a mother tongue. Like most Native American languages, it had no writing system until long after most people had abandoned speaking it. The very first orthography for the language wasn’t developed until the 1920s. And talk of attempting a language revival really only started in the past five years. I have since been cheered to discover that at least one children’s book has been published in Kiowa. Instead of 35,000 Irish who have known the language from their cribs within Irish-speaking communities, the number is zero for Kiowa. All Kiowa grow up speaking English with big Plains-state accents.

That night, Palmer played a CD recording of the Kiowa Black Leggings Warrior chant for the 157th Battalion’s annual military ball. That was the Kiowa language as it exists right now, completely fossilized. And in that form it moved many young men to tears. Here was the tongue of a people, and a nation, disappearing from the face of the Earth. And when the party ended late that night, I went back to my bed in the hotel, plugged earphones into my phone, and listened to a live, morning news radio show in Irish.

You see the difference? One is purely ceremonial. The other is fit for radio broadcast and current events.

Pearse was more right to imagine Irish as a living language in this century. It is alive in a way that Kiowa isn’t. I sincerely hope one day, if my great-grandchildren have an interest in Native American languages, they can pull up a live internet radio stream in the Kiowa language. Perhaps we can program computers to produce these even if the Kiowa language revival fails among the 12,000 living Kiowa today. But Irish still survives. And it is this way because of the revivalists. When Pearse and other language activists came to the Irish language, it was heading where Kiowa is now.

The truth is that there are more people who are literate in Irish today than two centuries ago, when our best estimates are that 20,000 Irish speakers had any literacy in their mother tongue, even if more than 2 million were fluent speakers of the language. The decline of Irish happened for many reasons. It was the aim of the English government to destroy it. Sir Edmund Spenser observed, “The speech being Irish, the heart must needs be Irish.” Even in the 16th century, the Irish would use their native language to resist English rule. As the Tudors sent their ministers to rule, they found not just the Gaelic Irish, but the descendants of the Normans refusing to speak in an English language they knew, just to annoy and frustrate the will of their rulers. “Though they could speak English as well as wee, yet Commonly speake Irish among themselves, and were hardly included by our familiar Conversation to speak English with us, yea Common experience shewed and my selfe and others observed the Citizens of Watterford and Corcke having wyves that could speak English as well as wee, bitterly to chyde them when they speake English with us.”

During the time of the penal laws, Irish was the language of the most-fierce resistance to English rule. The Irish nationalists who spoke in English tended to be reformists, republicans, and modernizers, and spoke of “improvement” with language meant to appease English rulers. But Irish-language poetry teemed with Jacobite fury and dark prophecies about the English being brought low into disgrace as scholars of the Irish language retake their place at the top of society. They were close to right. Eventually the authority of the English did decline. And while I wouldn’t say Irish scholars are at the top of society, they at least get positions on TV and radio now, and the occasional column in The Irish Times.

In 1800, about half of a population of 5 million Irish people were Irish speakers. By 1851, only 23 percent of almost 7 million Irish could speak the language, but many of these were bilingual and preferred their children to speak English. From what I can tell, it is very likely that my mother’s Irish ancestors spoke Irish when they left Donegal for America.

By the mid-19th century, it was obvious that English was the language of the future. It was the language in which the state and the courts operated on Irish people. English was the language of education; Irish was banned in the national school system. It was the language in which Irishmen found opportunity and freedom in the British Empire and America.

And so Irish was kicked down from its perch. It was once a high-status language, with bards and monks guarding it. Now it was the language of the poor. Even Irish speakers, if they had the most rudimentary English, would sometimes choose never to speak Irish to their children. These parents purposely deprived their children of the intimacy of a common household language in order to give them economic opportunity.

Despite all this, by the late 19th century, some Anglo-Irish elites, like the descendants of Vikings many centuries before them, found themselves adopting the Irish language as part of their identity. One of these men was Douglas Hyde, a Protestant who saw that previous efforts at Irish national self-assertion were entirely deficient in their appreciation of culture. “Just at the moment when the Celtic race is presumably about to largely recover possession of its own country, it finds itself deprived and stript of its Celtic characteristics, cut off from its past, yet scarcely in touch with its present,” he wrote. For Hyde, as for so many others, the Irish language was a romantic endeavor. It was a way of enacting their Irishness that went some ways beyond the grubby transactionalism of liberal societies.

When the Irish compare the language revivals of Hebrew and Irish, they are tempted simply to despair of Irish ability. The similarities are hard to miss. Each language movement talked about itself as an attempt to recover their respective nation’s manhood. Each featured people who changed their names as they adopted or matured into nationalist politics. Just as Edward Thomas Kent becomes Éamonn Ceannt, Golda Meyerson becomes Golda Meir. And each of the language revivals was meant to foreshadow and undergird the building of a viable nation-state.

But paradoxically, the fact that Hebrew was a fully dead language gave the Zionists some advantages over the Irish. Hebrew had several competitor languages, all of them weaker or repulsive. A few Zionists believed that they should concede to reality, and that German would be the lingua franca of the Jewish state. Others turned to Yiddish, the language of Jewish ghettos, but which also symbolized exile and hybridity. Being a dead language, Hebrew had no baggage of failure or low social status; it was not considered a language of the poor, or of any Jewish enemy. Jews living in Palestine spoke a number of languages, and they needed a common commercial language.

By contrast, the Irish language was associated with illiteracy and backwardness. And it had one competitor: English, the most important commercial language on Earth. Irish had no special role in religion, the way Hebrew did. The Catholic Mass was in Latin. Irish Protestantism was in English.

Being human, the Irish revivalists made their own blunders along the way. There’s the story of James Joyce, who took a class on the Irish language and Irish mythology and became disgusted at the teacher’s strenuous denunciations of the English language and how he exaggerated the glories of Táin Bó Cúailnge. Joyce retreated to studying Norse mythology instead. The teacher of that Irish class was Patrick Pearse.

But even if the revival failed to make Irish the majority language of Ireland again, Irish is now a language that can be used to write news stories and academic articles, and deployed in schoolyard taunts. In the 20th century, the Irish language grew the ability even to critique its own assigned role as the treasure house of some true, and truly set apart, Gaelic pastoral ideal. Although I’m not yet sure about the accuracy, I laughed my ass off when Alan Titley translated some earthy Irish cursing as “holy fuckaroni” in his English version of Cré na Cille. Maybe some things are best to leave in Irish.

But not all. When my wife and I came to visit your home for the first time, we traveled all around Ireland. And the strangeness of Irish place-names impressed themselves on my wife. Why did so many place names have these ungainly English syllables: clon, beg, bally, kil, and carrick? You know they are Irish, do you ever think about them? Suddenly the whole country comes alive. English sometimes collapses them. The cill in Kildare is a church, the “church of the oak.” But the cuill in Kilcogy is from a forest. Clon is a meadow, and so Clonmel becomes a “meadow of honey.” Tandragee in Northern Ireland is from the Irish Tóin re Gaoith, or “backside of the wind.” When you get behind Feltrim in Dublin, you discover the “ridge of the wolves.”

More than a century ago, P. W. Joyce wrote, “This great name system, begun thousands of years ago by the first wave of population that reached our island, was continued unceasingly from age to age, till it embraced the minutest features of our country in its intricate network.” And yet, many Irish people are unaware of the way the names around them point to landmarks, and beasts, and climate. They’ve become deaf to the land.

I recently read an Irish commentator saying that every bit of money spent on the Irish language was wasted. Maybe it’s sad that languages are in Darwinian competition with one another, he sighs, but some die. Irish-speaking people died too quickly. Their literary rates failed to keep up. We entered into a commercial age, and Irish was not commercial. Irish people are happy to speak English. In fact, they speak it better than the English. So, let it go.

But the evolutionary game doesn’t always end so cleanly. Some creatures decline in one environment, but they don’t die. They adapt. And I think I caught the barest glimpse of how Irish has adapted itself and can survive lean times in the current environment.

Something like a quarter of a century passed between the time you gave me a hurl and the time I entered a hurling pitch. I experienced another 20-odd-year gap closing earlier this year. I attended a weekend immersion Irish language course in rural New York, run by Daltai na Gaeilge. When I arrived, the organizers asked if I had ever been to one of their events before.

Yes, I admitted, when I was four and five years old, with my mother. I showed a few of the older women pictures of my mother and me from that time. And they remembered us. They remembered her. I have occasionally been recognized in the street or in a bar for my disreputable career as a pamphleteer. But this was the first time in my adult life that a stranger recognized me as the son of my mother. And knew my mother because of what language she chose to speak.

I was put in a class made up mostly of children. I was made to relearn what I had known and forgotten as a toddler. We counted, and practiced saying “Hello” and “How are you?” For me, this is the hardest part of learning a language. The humiliation of being a child again. I make my living with words and I can be astonishingly vain. Learning Irish as an adult means screwing up the simplest things, like counting from a haon to a deich.

There were only a few people my age at the weekend. There was Antoin, a young teacher who grew up in West Belfast. And Megan from Boston. They knew each other from previous academic conferences on Ulster’s culture. But they accepted me, for that weekend at least, as a friend. I know this is sickening for an Irish person like yourself to read, but of course I made fast friends with the man from Belfast. How typical. How obscene. It was Irish Americans who wear their Irishness so lightly—a pin asking for a kiss—romanticizing or even financing men in the Falls Road, who wear their Irishness as a ski mask. Alas, Antoin and I couldn’t help it. We both have that thing, of having grown up outside of the Republic, in very different situations, where Irishness must be asserted. But not too loud. It is customary at Daltai na Gaeilge to prepare a “party piece,” a song, or a poem—preferably in Irish. Antoin, Megan, and I all tried to duck this for drinking and arguing about the Rising.

The night went on, and most of the party retreated for bed. But the drinks flowed on, and something started to happen to the three of us. I believe it was something around each of us that started to crack. Something like the encasing that our common culture imposes on us. I can’t speak for everyone, but I can say with some assurance that mass media were my primary teacher growing up. And it taught me and my friends how to conform with one another. It slipped under the table to me a lesson that sincerity is a kind of weakness. That it will be used against me. And that any sentiment at all, anything that could expose you to the danger of ridicule or the genuine possession of an emotion, should be double- and triple-Saran-wrapped in irony. I suppose we do this for safety somehow, as if unwrapped passion itself is so flammable, it would consume our little worlds at the instant we exposed it to open air.

I was getting drunk. And so I grabbed Antoin at one point, and quietly I sang to him a very silly song I know about Ulster, “The Old Orange Flute.” He let out big gulps of laughter and an almost maniacal smile. And this new mood descended on the room. Now, for everyone there, I was made to sing the things I sing my daughter. I tried “The Wind That Shakes the Barley.” I don’t have a voice for real work on the stage, but for a bar or night like that one, it’s pretty good. And then Megan, in a crushingly tender soprano, sang “She Moved Through the Fair.” Here it was: We revealed to everyone left, and maybe even to ourselves, that we, yes, the young ones, were romantics too.

Antoin got up and recited by the Bobby Sands poem, “The Rhythm of Time.” By the time in that poem when “the undauntable thought,” “screamed aloud by Kerry lakes, as it was knelt upon the ground,” Antoin was sobbing openly and unashamed before us. When was the last time you saw a man in his mid-20s reciting a poem in front of people he just met and croaking out the words through tears?

Yes, all these things were in English. But I believe we were there because something about the Irish language, for us, sets it apart. By the 1960s and ’70s, hopes for the complete revival of Irish had been diverted into something more humble, but with radical implications. Preserving Irish took on the character of a voluntary and local resistance to globalization and the reordering of all culture by commerce. Its preservation requires the courage to embrace an identity that could not be bought and sold. I think that is why the experience of coming together to learn this language subtly encouraged us to shed this cumbersome emotional armor, this generational pose of ironic distance from everything, even ourselves.

And to shed it means to recognize the deeper truth about my little foray into this quixotic “useless” language. The die-hard clerical Gaelic Leaguer Reverend O’Hickey complained of the failure to preserve the language: “Are the Irish people going to endure this? If so they deserve the worst that has ever been said of them. They are a people without spirit, without national self-respect, without racial pride, a poor, fibreless, degenerate, emasculated, effete race—eminently deserving of the contempt of mankind.” I know how the culture around me wants me to respond to a statement like this: with a knowing, dismissive snort. If I’m to respond to it intellectually at all, it is as an academic. “Well, O’Hickey is echoing common tropes about masculinity and nationalism and such and such.” If I am to respond the way my education would prompt me, I would say that O’Hickey is being intolerably absolutist.

What the culture insists I am not supposed to do is read those words and feel an honest conviction flooding my heart and stealing my breath. What I am not supposed to do is make vows to wake up your grandchildren each morning with “Tà an maidan ann. Múclaígí anois, a thaiscí!”

Many language learners say that they find a new personality in their second language. Already I can see that the Irish language gives me access to another part of myself, one that doesn’t feel so needful of admiration, that doesn’t couch itself in layers of irony and hide behind hand-waving verbal acts of self-creation. I’m determined to learn Irish, because it forces me to be a child and to grow up again. It allows me to become the kind of person who can utter simple convictions and mean them: I bought those Irish-language books for my daughter, because my mother bought the same books for me. I struggle to learn the Irish language, because she struggled to learn it. Because she wanted me to learn it. Because our little routine at night was for her to tell me to “dún un doras,” and we would exchange an “oíche mhaith!” before I went to bed. Because the history of being Irish is setting yourself an impossible task, then failing to do it over and over again, until one day it is accomplished. My mother tried. I will try again. This isn’t mere sentiment. The speech being Irish, the heart must needs be Irish.

It might cost a little money for me to learn a dying language, to graft it onto the tongue of the man of this house. But then the transaction stops being commercial. My children learn it freely, something Irish that is not a product or a brand that fades, but that becomes its own treasure, letting us live off the wealth it generates over a lifetime.

And I can already see the returns coming in. None of your household fits into the category of “competent speakers.” You have told me about the image of Irish speakers that you had in childhood, of women that smelled like turf fires, and men that smelled like their fishing nets. You’re no good with it, you say. But that is what everyone says. When I have tried my few words of Irish at Dublin Airport, I get the distinct sense that the people working there would rather that an American try to sneak a gun past them than a few words of Irish. They look genuinely pained or even threatened. I know that Irish people can have a genuinely complex relationship with this language that they almost understand. They want it to continue to exist, but they never use even the few words they have.

But when you and your daughters visit, and see these little children’s books lying around, you pick up these books and read them to her. All of you dare yourself to do it. My intention was that my daughter learn Irish, but through her, I’m beginning to think all of you have a chance.

This article was adapted from My Father Left Me Ireland: An American Son’s Search for Home, by Michael Brendan Dougherty.



Despite the fear and anxiety that many parents of disabled children initially have, published research shows that—with the proper support—they routinely end up satisfied with their lives and optimistic about their children’s chances for future happiness. Moreover, the lives of adults with impairments are hardly devoid of joy. One of us is able-bodied; the other was disabled by a spinal-cord injury. Because public facilities now have ramps and elevators, we are regularly able to eat out together, frequent local watering holes, and travel to a big city. The same goes for most of our wheelchair-using friends.

The political rhetoric around abortion tells a different story. Unwittingly, abortion-rights opponents are reinforcing the dangerous idea that disabilities are an unbearable burden and, in the absence of government coercion, might be snuffed out altogether.

In recent years, legislators in a number of states have debated or enacted measures that prohibit selective abortions on the basis of fetal sex, race, or disability. Some measures specifically forbid abortions prompted by the discovery that a fetus has Down syndrome. In a lengthy opinion in a case involving Indiana’s ban on selective abortion, Justice Clarence Thomas noted that, when Down syndrome is diagnosed prenatally in the United States, the pregnancy is usually terminated. Thomas claimed that abortion is being used to “achieve eugenic purposes.”

As it happens, Thomas was concurring with the Supreme Court’s decision not to rule on the Indiana law, thereby leaving intact a lower court’s ruling striking it down. But the issue will surely be back. Meanwhile, in supporting laws like the one in Indiana, a bevy of conservative pundits have echoed Thomas’s concerns and his language.

For many people, including us, the thought of aborting a fetus because of an impairment is a troubling one. But legalized abortion is not the problem to be solved. Beyond undermining women’s autonomy unfairly, bans on selective abortion also worsen the stigma against people with disabilities—while doing nothing to address the practical issues they and their families face.

Rather, what needs to be challenged is the notion that a physical or developmental disability is a tragedy. To reassure parents that they can, in fact, raise children with significant impairments, American society must to do more to emphasize that disability is a normal part of human diversity—and must provide more cultural, social, and emotional support for the families that experience it.

Unfortunately, popular depictions of disabled people in literature, film, and elsewhere make this difficult. Figures such as Shakespeare’s villainous Richard III or the rebarbative Mr. Potter from It’s a Wonderful Life have long signaled that living with an impairment must be miserable. But those who actually engage with disabled people—rather than avoiding them on the street or cordoning off their children for fear of seeming rude—will begin to create a far more complex picture.

Interacting with impaired individuals—and reading their work—will also impress upon able-bodied people that disability can offer the kinds of benefits we now attribute to other marginalized identities. An increasing number of employers are realizing the advantages of hiring individuals on the autism spectrum, for instance.

Disabilities vary widely in their severity, of course. Yet while there is no denying that certain fetal anomalies result in quick and devastating loss of life, many of the impaired bodies at the center of this most recent abortion debate are shrouded in other misconceptions. Contrary to popular perception, myriad individuals with Down syndrome live normal life spans, read, play sports, and enjoy relatively independent, happy lives. Studies have also debunked the assumption that they derail their parents’ marriages or the lives of their siblings, many of whom report that they’ve learned to be more caring and tolerant as a result of growing up with someone who’s disabled.

Even so, these families still need a broader embrace.

Let’s start by realizing that disability and reproductive rights can be mutually informative. For a woman to have a genuine choice about whether to carry a pregnancy to term, her access to safe and legal abortion must be coupled with the freedom to continue her pregnancy without fear of ruining her career, finances, or health. In our society, the physical and emotional costs of raising a disabled child far exceed those of bringing up able-bodied children. That should be as central a concern to advocates of reproductive rights as restricted access to birth control and abortion.

In some cases, existing policies can help close this disparity. The embattled Affordable Care Act, for example, prohibits various forms of discrimination by insurance companies and—at least in certain states—has allowed more families of disabled children to enroll in Medicaid. (The Donald Trump administration’s proposal to cut spending on Medicaid is already hurting disabled people.)

We also need new policies that better support the more than 16.8 million individuals who take care of disabled children in the United States. Female caregivers—few are male—are 2.5 times more likely than noncaregivers to live in poverty, and 23 percent of people who have cared for a family member for five years or more report poor health.

This wouldn’t necessarily be the case if the United States did more to educate employers about the needs of their employees with disabled kids, insisted that child-care professionals become more adept at interacting with these kids, and offered more resources for caregivers, including the ability for them to take time off. To that end, friends and local community members could educate themselves and volunteer their time to offer respite care for the impaired children in their lives, or at least make sure their families aren’t shunned. The empirical evidence is clear: The more social support that parents of children with disabilities receive, the easier it is for them to cope.

A world where disabled fetuses are brought to term is one in which mothers do not bear complete responsibility for the care of their children, and where disability itself is destigmatized. Ensuring that disabled individuals, and their families, have the assistance they need will do far more to protect disabled lives than any selective abortion ban ever could.



A few short months ago, Eric Garcetti, the mayor of Los Angeles, was giving serious consideration to running for the Democratic presidential nomination. Now he finds himself in the midst of a homelessness crisis that could doom his political future.

If you were to conjure up the ideal California politician, you could do worse than Garcetti, a Jewish Mexican American Rhodes Scholar with a gift for gab, in English and Spanish, and a winningly unpretentious style. As if channeling a young Barack Obama, the mayor is fond of invoking storied moments from the American past—the Great Depression, the Second World War, the civil-rights movement—to suggest that if previous generations were able to turn daunting challenges into historic accomplishments, then we ought to hold ourselves to the same exacting standard, a welcome alternative to the sourness and fatalism of other politicians on the left and right. But when it comes to Los Angeles’s long-running battle with homelessness, the mayor’s rhetoric looks more delusional than inspirational.   

A month after Garcetti delivered his rousing State of the City address, California released its annual homelessness count, revealing that after an encouraging 4 percent drop from 2017 to 2018, Los Angeles’s homeless population grew by 16 percent in 2019, bringing post-2011 growth up to 52 percent. These numbers would be alarming in any city, but in Los Angeles they are especially so, because the city is the epicenter of a particularly brutal style of homelessness. Seventy-five percent of the city’s homeless population is unsheltered, typhus and typhoid threaten to create a public-health emergency, and a growing number of homeless people are either the perpetrators or the victims of violent crime.

The mayor’s response has been to increase public spending on homelessness sharply, but he’s had frustratingly little to show for it. When the homelessness issue burst onto front pages a few years ago, Garcetti jumped into action with an ambitious plan to build emergency shelters in all 15 districts of the city. But as the mayor soon discovered, the issue with an “emergency” plan oriented around construction is that Los Angeles is a far cry from Bob Moses’s New York. Eighty percent of the shelters have been held up by red tape and community resistance. The short-term measures, then, must take the city’s built environment as a given.

A new sales tax boosted the city’s budget for dealing with homelessness to more than $600 million, or $20,000 per homeless person, while a bond issuance brought in $1.2 billion to go toward constructing an estimated 10,000 housing units over the next decade, all of which would be preserved for people transitioning off the street or in danger of ending up there. Los Angeles has taken about 16 percent of the funds from its recent sales-tax increase and packaged it as vouchers to offer to a share of its homeless population, allowing them to buy into the rental marketplace with the understanding that their subsidy will fade over the course of a year, shifting the burden onto the new renter.

While Los Angeles is right to want a program that moves people toward self-sufficiency—both for the sake of the homeless themselves and to protect the city’s coffers—the steep monthly increases as the vouchers fade out often outpace the low-wage, part-time work the recipients are able to find. Unsurprisingly, for an alarming share of recipients, the program is more of a one-year reprieve than the start of a new, stable life. Short of doing something serious about the underlying cost of housing in Los Angeles, a limited pool of voucher dollars will forever chase rising rents.

Before the city’s new homelessness count was released, the mayor had been touting the 20,000 people the city had moved off the street and into some form of housing. What we now know, however, is that while the Garcetti administration was helping to move 380 people off the street each week, some 480 others were joining the ranks of homeless Angelenos. Put another way, until someone does something about the city’s larger housing crisis, homelessness will be as much a part of the city’s landscape as Runyon Canyon.

Would building more housing bring an end to homelessness in L.A.? That might be too much to ask. As in most U.S. cities, a large share of the city’s homeless are thought to be mentally ill. The slice of Los Angeles’s homeless population dealing with mental illness is believed to be about 25 percent—relatively modest when compared with San Francisco, where an estimated 35 percent are struggling with mental illness, but still a substantial portion of the total.

Moreover, the city’s mild climate makes living outdoors a more viable option than in colder communities. The notorious encampments at Skid Row and in Venice Beach do not have counterparts in Manhattan, and it is safe to assume that a large number of seriously mentally ill people live in these parallel communities. Los Angeles also attracts an enormous number of homeless young adults from elsewhere in the United States and abroad. Among the 18-to-24-year-olds living on L.A.’s streets, whose numbers grew by nearly 25 percent this past year, a disproportionate share are newcomers to the city, who don’t have strong ties to the region.

These populations present knotty issues for city officials. Still, the fact that these populations are a distinct minority ought to give us hope that the majority of the city’s homeless can be reached through conventional public policy—that is, through reforms designed to increase the supply of housing, including low-cost, no-frills housing that can meet the needs of the very poor. If 10 years down the road, Los Angeles’s median rent has been pushed downward as a result of denser building, Skid Row might very well still exist as a home to people facing down hellish battles with mental illness and addiction. But at that point, the city would have the breathing room to focus on helping the hardest cases. Getting there is the hard part.

One of the ironies of this unfolding humanitarian disaster is that homelessness is a problem most pronounced in successful cities, where dynamic economies all too often meet rigidly regulated housing markets. As my Manhattan Institute colleague Stephen Eide observed in National Affairs, homelessness is not the product of poverty per se. Rather, homelessness is in no small part an artifact of being poor in a place where ferocious competition for a severely constrained supply of homes drives up rents. To offer one example of this dynamic at work, Detroit’s poverty rate is twice that of New York City’s, but because of its notably inexpensive real estate, it maintains a homelessness rate a third the size.

Los Angeles offers an example of this dynamic in extremis. In his incisive American Affairs essay on L.A.’s homelessness crisis, Jacob Siegel highlighted a study by Zillow that showed that you start to see a rising rate of homelessness once a city’s average rent reaches 22 percent of median income, and an even more rapid rate of increase once that number hits 32 percent. In Los Angeles, the average rent is 49 percent of median income. Some studies have shown that the city has as many as 600,000 people who regularly put as much as 90 percent of their monthly income toward rent. Simply put, these people need a lucky bounce to not end up homeless.  

This lucky bounce might have come from California’s state government, where ambitious fixes to the statewide housing shortage have been in play. Earlier this year, to his credit, Governor Gavin Newsom set the goal of building 3.5 million new housing units in California over the next seven years, an implicit acknowledgment that insufficient housing supply was the driving force behind the state’s ruinously high rents.

This was a controversial stance for a progressive politician whose ideological allies often prefer to blame profit-hungry landlords and absentee owners. The substance to make good on Newsom’s promise was to be found in Senate Bill 50, an ambitious proposal from Scott Wiener, a state senator from San Francisco with unimpeachable left-wing credentials. In essence, S.B. 50 would have preempted local restrictions on density within neighborhoods that are well served by public transportation or in close proximity to employment centers.

In a nod to political reality, Wiener and his allies softened some of the bill’s more controversial provisions as it made its way through the legislature. Both its supporters and detractors understood that the bill would have done a great deal to boost California’s housing stock over time. But the bill died in committee, sunk by anti-growth legislators who denounced it as a threat to local control.

When a bill to help the most vulnerable people in California fails, one can hardly blame Sacramento’s dwindling band of conservative legislators, because they are very much on the margins of the state’s political life. They can hardly muster the votes to name a park bench, let alone decide the fate of California’s housing regulations. As Michael Hendrix, also of Manhattan Institute, has observed, the real culprits are self-described progressives, such as Paul Koretz, who represents West Hollywood on the Los Angeles City Council and suggested that S.B. 50 would take his district’s neighborhoods of single-family homes and make them “look like Dubai in 10 years.” Then, from the other side of town, Damien Goodmon, the president of the Crenshaw Subway Coalition, suggested that the potential gentrification of his neighborhood amounted to a “Twenty-first century Trail of Tears.”

I sympathize with Koretz’s and Goodmon’s devotion to the built environment they know and cherish. Many of the sprawling single-family neighborhoods of Los Angeles are quite beautiful. It is hardly surprising that they’d want to fight against what they perceive to be disruptive change. The trouble is that their resistance to one form of disruptive change, as represented by the gradual replacement of single-family homes with higher-density apartment buildings that could house many more families at far lower cost, is contributing to another form of disruptive change—the transformation of large swaths of Los Angeles into unsanitary homeless encampments, where women, men, and children are forced to spend much of their waking hours fending off vermin.

And what did Garcetti have to say about S.B. 50? Though he refused to sign a Los Angeles City Council resolution denouncing the bill, the mayor didn’t come out in favor of it either, choosing instead to triangulate. In an exchange with Liam Dillon of the Los Angeles Times, Garcetti suggested that while he favored allowing the construction of duplexes and triplexes in keeping with the character of existing single-family neighborhoods, which he claimed had the potential to boost the city’s housing supply by as much as 50 percent, he felt Wiener’s bill went much too far.

It was exactly the sort of statement one would expect from a shrewd politician. By touting the virtues of duplexes and triplexes, Garcetti sounded righteous without committing himself to anything concrete enough to anger the likes of Paul Koretz. Meanwhile, L.A.’s homelessness crisis rages on.



The tech entrepreneur Ross McNutt wants to spend three years recording outdoor human movements in a major U.S. city, KMOX news radio reports. 

If that sounds too dystopian to be real, you’re behind the times. McNutt, who runs Persistent Surveillance Systems, was inspired by his stint in the Air Force tracking Iraqi insurgents. He tested mass-surveillance technology over Compton, California, in 2012. In 2016, the company flew over Baltimore, feeding information to police for months (without telling city leaders or residents) while demonstrating how the technology works to the FBI and Secret Service.

The goal is noble: to reduce violent crime.

There’s really no telling whether surveillance of this sort has already been conducted over your community as private and government entities experiment with it. If I could afford the hardware, I could legally surveil all of Los Angeles just for kicks.

And now a billionaire donor wants to help Persistent Surveillance Systems to monitor the residents of an entire high-crime municipality for an extended period of time––McNutt told KMOX that it may be Baltimore, St. Louis, or Chicago.

McNutt’s technology is straightforward: A fixed-wing plane outfitted with high-resolution video cameras circles for hours on end, recording everything in large swaths of a city. One can later “rewind” the footage, zoom in anywhere, and see exactly where a person came from before or went after perpetrating a robbery or drive-by shooting … or visiting an AA meeting, a psychiatrist’s office, a gun store, an abortion provider, a battered-women’s shelter, or an HIV clinic. On the day of a protest, participants could be tracked back to their homes.

In the timely new book Eyes in the Sky: The Secret Rise of Gorgon Stare and How It Will Watch Us All, the author Arthur Holland Michel talks with people working on this category of technology and concludes, “Someday, most major developed cities in the world will live under the unblinking gaze of some form of wide-area surveillance.”

At first, he says, the sheer amount of data will make it impossible for humans in any city to examine everything that is captured on video. But efforts are under way to use machine learning and artificial intelligence to “understand” more. “If a camera that watches a whole city is smart enough to track and understand every target simultaneously,” he writes, “it really can be said to be all-seeing.”  

The trajectory of this technology in the U.S. is still unwritten. It may depend on everything from public opinion to Fourth Amendment jurisprudence to restrictions that policy makers impose before wide-area surveillance is entrenched.

According to KMOX, McNutt plans to consult with city leaders before starting his planned three-year project somewhere. Did his company retain video of the Baltimore officials who could approve or thwart its return? I’d wonder if I were them.



When Narendra Modi led his Bharatiya Janata Party (BJP) to an outright parliamentary majority in 2014—a feat no party had been able to achieve in the previous 25 years of Indian politics—the hopes and expectations for his first term were straightforward, if lofty. Modi promised to build a “new India” that would curb corruption, spur economic growth, and advance the interests of the growing “neo–middle class” of erstwhile villagers striving to reinvent themselves as consumers.

Five years later, the BJP has secured a new electoral mandate even more impressive than the last, a testament to Modi’s unmatched political prowess. Yet it has done so despite an economic record that can be described only as underwhelming. If Modi hopes to do more than simply stay in power, if he still aspires to bring his new India to life, he’d do well to heed the advice of a small clique of economists who’ve been calling on his government to more fully embrace urbanization.

Why is it that Modi’s premiership failed to deliver robust growth? During his tenure as chief minister of Gujarat, one of India’s more prosperous and industrialized states, Modi envisioned India as a manufacturing powerhouse in the making. But that was not to be. To his credit, on his ascension to national office, Modi was clear-eyed enough to recognize that his preferred development strategy—cultivating a labor-intensive manufacturing sector that could sell its wares overseas, as China had done with such great success—was ill-suited to emerging global economic trends.

Modi and his advisers quickly came to understand that a combination of depressed demand in the mature market democracies and robust competition from other low-wage countries had essentially foreclosed the export-driven model of development, as Amy Kazmin and Lionel Barber report in the Financial Times. Instead, Modi reached for a grab bag of reforms and public investment, an approach one of his advisers described as “light many fires at once—to see if any of them would catch.” Modi’s policy mix has indeed succeeded in lighting many fires, though not all of them are burning quite as he might have wished.

It must be said that Modi has achieved some modest successes. His move to overhaul the tax code is a step in the right direction. The previous tax system vested too much power in the state and local levels, such that India’s domestic market was littered with internal trade barriers. The newly instituted VAT promises to facilitate more interstate trade and, hopefully, raise some badly needed revenue for India’s chronically under-resourced central government. In just two years, India’s tax base has increased by 50 percent.

The creation of a streamlined bankruptcy process is another long-overdue reform. An IMF report cited by the Financial Times found that under the old regime, creditors who turned to the courts to settle bankruptcy disputes could expect a process that would take four years to resolve itself and would, on average, end with them writing off three-quarters of the debts they were owed. Though far from perfect, Modi’s new bankruptcy code appears to have leveled the playing field for creditors, which should, in time, make Indian firms more attractive to investors at home and abroad.

The stimulus from these important reforms, however, has been dulled by a simultaneous liquidity contraction provoked by an ill-conceived policy of demonetization. Modi attempted to smoke out nefarious actors who were hoarding their wealth in hard-to-track cash, but instead produced a complicated and protracted financial crisis.

In November 2016, in characteristically secretive and dramatic style, Modi announced that following a 50-day grace period, the country’s high-denomination bills would be worthless. What happened next was a short-term cash crunch as people took money out from under their proverbial (and sometimes literal) mattresses and poured it into bank deposits and mutual funds. Much of this $220 billion liquidity surge found its way into the hands of shadow banks, which in turn sparked a series of financial ructions that I won’t pretend to fully understand.

On balance, though, Modi has failed to deliver on his promise of faster growth. Under his government, India’s GDP has grown at about 7 percent a year, which looks more like the growth produced by the preceding government than it does the 10 percent average growth China maintained from 1990 to 2010. Moreover, the failure to jump-start manufacturing employment has left the country with an unemployment rate of 7 percent, driven in large part by a 20 percent jobless rate for urban men under 30, a slice of the population not known for its quiescence.

Perhaps the most high-profile undertaking of the Modi government has been its war against graft and corruption. Lest voters miss the point, Modi updated his Twitter handle to include the prefix Chowkidar, or “watchman.” Here too, it is unclear that Modi’s successes outnumber his failures. During the campaign, Modi’s opponents played off his own self-branding, telling voters “chowkidar choi hai” or “the watchman is the thief.” His success at the polls notwithstanding, 42 percent of Indian voters felt as if corruption had grown worse under Modi, compared with 36 percent who thought it had improved.

Interestingly, Kazmin and Barber of the Financial Times suggest Modi’s anti-corruption fervor has deepened his country’s credit crunch. They point to the case of Jet Airways, India’s oldest private airline, which went bankrupt because no state bank was willing to extend it credit, despite the fact that these same banks had taken managing control of the company and had been shopping around for a buyer. Kazmin and Barber present the view of an anonymous businessman who thinks this curious series of decisions can be attributed to fear of prosecution: “There is a subtle difference between being anti-corruption and anti-business. If I feel I am going to be persecuted, I’m going to be very careful in how I take my investment decisions.”

Given that Modi failed to deliver rip-roaring economic growth, how do we account for Modi’s irrefutable political success? Those who attribute Modi’s success exclusively to his willingness to indulge and promote Hindu chauvinism, a sentiment not uncommon among English-language interpreters of Indian political life, miss an equally important, if more prosaic, explanation: the efficient delivery of generous welfare benefits, particularly to rural citizens.

Writing in Foreign Policy, Srinivas Thiruvadanthai of the Jerome Levy Forecasting Center argued that Modi deserved more credit for his effective administration of the welfare state, which is exceedingly important when you consider that more than 70 million Indian citizens live on less than $1.90 a day.  One particularly impactful policy provided bank accounts to 300 million previously unbanked citizens. Though the program is still in its infancy, preliminary research has shown that areas with high exposure to the program saw upticks in health-related borrowing. Separately, in an effort to cut down on pollution and improve sanitation, the government has built 81 million household toilets and provided financing for more than 60 million cylinders of Liquid Petroleum Gas, which is a much cleaner home-cooking fuel than the cheap alternatives of firewood and kerosene.

While latrine building and small-dollar banking are not the most glamorous subjects for foreign correspondents to take up, they mean an awful lot to the citizens who no longer have to relieve themselves in fields or rely exclusively on informal networks for credit. Presumably, it was these tangible, bread-and-butter outcomes that allowed Modi to fare so well in left-leaning regions—such as West Bengal, which had long been a Marxist redoubt—and, more striking still, among Muslim women.

But all the latrines in the world won’t make India an economic dynamo. To pull off that feat, Modi must persuade Indians to embrace an urban future. Reuben Abraham and Pritika Hingorani, both of India’s IDFC Institute, a small but enormously influential think tank based in Mumbai, have made a convincing case that at present India’s state governments—which are each empowered to decide what qualifies as urban—systematically underestimate the urban share of their populations. According to the Indian Census, only 31 percent of the country’s population resides in urban areas. If, however, you were to adopt Ghana’s or Lebanon’s definition for what amounts to an urban area, India is almost 50 percent urbanized.

This definitional game has consequences—classifying an area as urban completely shifts the statutory responsibilities of local governments. Urban governments must do the important work of funding fire departments, building sewage lines, and drafting building standards. India’s current policy of closing its eyes to emerging cities is helping to ensure that its cities are filthier, more chaotic, and less economically productive than they would be otherwise.

And if India’s growth strategy is going to be defined by high-value services rather than labor-intensive, low-wage manufacturing, it ought to heed the lessons of the world’s most successful postindustrial metropolises. Abraham and Shashi Verma, the chief technology officer of London’s transportation office, have argued that India should recast Mumbai, India’s financial capital, in the mold of New York or London, primarily by converting its shrinking port into a sleek new business district offering a high quality of life. Trivial though this effort might sound, the rise of Shenzhen, and the creation of Shanghai’s Pudong financial district, did a great deal to spur China’s urban development.

Ideally, Abraham and Verma’s Mumbai project would demonstrate that educated Indians needn’t move abroad to enjoy decent services or to build successful businesses. In The Other One Percent, a comprehensive analysis of the Indian-origin population of the U.S., the social scientists Sanjoy Chakravorty, Devesh Kapur, and Nirvikar Singh posit that “controlling for quality, it will take decades for India’s system of higher education to simply match the stock of India-born doctorate-degree holders in the science and technology disciplines.” Only by building attractive global cities of its own can India hope to compete with the San Franciscos and Singapores in its efforts to attract and retain intellectual and entrepreneurial talent. And in doing so, Modi might finally deliver the accelerated growth that he has promised his voters.



On May 17, 2017, Robert Mueller was appointed special counsel to oversee the Russia investigation. On May 29, 2019—a month after the release of his report on the investigation, and almost exactly two years after he was first appointed—Mueller finally spoke.

Based only on the reaction to Mueller’s appearance, you could be forgiven for assuming that he had dropped a bombshell. “Robert Mueller’s statement makes it clear: Congress has a legal and moral obligation to begin impeachment proceedings immediately,” tweeted the Democratic presidential hopeful Cory Booker. Booker’s fellow candidate Senator Kamala Harris had a similar reaction. Democratic Representative Debbie Dingell wrote, “Robert Mueller gave important context by saying ‘If we had confidence that the President did not commit a crime we would have said so.’” “This is huge,” said the CNN national-security reporter Jim Sciutto. Others pointed to Mueller’s comment that, on the basis of the Justice Department guidance against indicting a sitting president, “we concluded that we would not reach a determination … about whether the president committed a crime,” arguing that the statements definitively showed Attorney General William Barr’s previous comments on the matter to have been misleading.

The fact that this material is being treated as new when it has been available for weeks is indicative of a vast failure on the part of American institutions, which have not adequately grappled with the information conveyed in the Mueller report or presented it to the public with sufficient clarity.

For all the excitement, Mueller offered almost no substantive new information yesterday from the Justice Department podium. Mueller described a “concerted attack on our political system” by the Russian government and emphasized the existence of “multiple, systematic efforts to interfere in our election.” He reiterated that his office had not exonerated the president. He also said that “it is important that the office’s written work”—that is, the Mueller report—“speak for itself.” The (now former) special counsel’s comments were taken directly from the information already presented in the report—including the decision not to reach a conclusion about whether the evidence indicated that the president of the United States had obstructed justice.

The members of Congress and the media discussing Mueller’s comments as major news are not wrong to do so. Mueller has remained silent for two years, and his first public statement was always going to be a significant event. Likewise, the underlying information communicated in both Mueller’s remarks and the report itself is appalling—and further discussion of its meaning can only be good. The question is why it took so long to happen.

The difficulty in communicating the substance of the Mueller report began even before the report itself was released. When Barr first released his letter describing Mueller’s top-line conclusions weeks before the report itself became public, the press struggled to respond to the spin campaign mounted by the president and his allies. Some publications reported uncritically on the president’s claims of “Complete and Total EXONERATION,” though Barr’s letter stated that Mueller had not exonerated Trump. The New York Times and The Washington Post both said a “cloud” had been lifted from over the White House.

This was weeks before any members of Congress or the press had seen the actual text of the report—which differed dramatically from the relatively rosy version of events communicated by Barr. The attorney general, it soon became clear, had plucked supposedly exonerating phrases from the report while leaving out often-damning context. Barr’s summary gave the president and his allies two crucial weeks to portray the contents of the report in the most favorable light.

The report, when it arrived, was a forbidding 448 pages and dense with legal terminology. It was not user-friendly. And so, perhaps predictably, a CNN poll from early May indicated that 75 percent of Americans have not read the report at all; 24 percent said they had read some of its contents, and only 3 percent said they had reviewed the entire document. The result is that most people, lacking the time to pore through almost 450 pages of text, were dependent on the press and on political figures to communicate the significance of the document.

But the reaction to Mueller’s press conference suggests that those institutions have fallen down on the job. If the substance of Mueller’s report was widely known and understood, there would have been nothing surprising about his statements yesterday. In fact, he might not have felt the need to make a statement at all; as Ken White writes, Mueller’s tone was that of a teacher telling his students once again that they would know the answer if only they had done the reading.

The sheer lack of knowledge about the contents of the report was perhaps best communicated by Fox News’s Bret Baier, who commented after Mueller’s press conference:

This was not—as the president says time and time again—no collusion, no obstruction. It was much more nuanced than that. He said specifically they couldn’t find evidence to move forward with the crime of collusion for the investigation of the Trump campaign. He said specifically if they had found that the president did not commit a crime on obstruction, they would have said that, and then went into specific details about the DOJ policy and why they couldn’t move forward with anything else than their decision.

This is an excellent summary of what Mueller said. It’s also an excellent summary of the Mueller report itself, which has been a public document for more than a month. If Fox News viewers found any of this surprising, it’s because the network spent little time relaying those findings before now.

But the problem is not only on the Trump-friendly right. Consider Mueller’s comments on his decision not to reach a prosecution or declination decision, which were widely received as a rebuke to Barr. The special counsel’s office, Mueller said, “did not … make a determination as to whether the president did commit a crime” because “under long-standing department policy, a president cannot be charged with a federal crime while he is in office.” Barr, by contrast, said before the release of the report that Mueller “was not saying that but for the [Justice Department opinion on indicting a president] he would have found a crime.” To be sure, Mueller’s comments yesterday do “reveal” Barr’s “spin,” as MSNBC’s Nicolle Wallace put it. But so, too, did the report itself. The opening pages of Volume 2 describe in detail how Mueller read the Justice Department policy to preclude taking the steps that could lead to a decision to prosecute.

This is not the first time that the press has reported information already publicly available in the report as if it were new. After a federal court made public a handful of documents in the Michael Flynn case in mid-May, news outlets such as CNN’s wire service and Axios reported that Flynn had provided the special counsel’s office with evidence, in the form of a voicemail, of efforts by Trump’s team to persuade him not to cooperate with investigators. Yet the report already described a voicemail from Trump’s lawyers to Flynn—and even included a partial transcript.

But the institutional failures extend beyond the media. The report was difficult to digest and communicate in part because Barr chose to disseminate the entire document at once, rather than releasing the relatively brief summary language prepared by Mueller’s team for that purpose. If the attorney general had chosen to release Mueller’s summaries instead of choosing to protect the president by writing his own, perhaps Mueller’s message might have been easier for the public to understand and for the press to report.

And then there is Congress—perhaps the main target of Mueller’s entreaty to please just read the report. During his remarks, Mueller stated that, while he was precluded from bringing criminal charges against the president, the legal memo in question “says that the Constitution requires a process other than the criminal-justice system to formally accuse a sitting president of wrongdoing.” (The memorandum states that “the constitutionally specified impeachment process ensures that the immunity would not place the President ‘above the law.’”) Some members of Congress seemed to get the message: Following the press conference, both Booker and Harris released statements in support of impeachment hearings, each stating that Mueller’s comments had clarified for them that it was time for Congress to act. Others, such as House Homeland Security Committee Bennie Thompson, voiced new support for impeachment or impeachment proceedings as well.

But again, the status of the report as an impeachment referral should have been obvious the moment the document was released. Mueller wrote that “a federal criminal accusation against a sitting President would … potentially preempt constitutional processes for addressing presidential misconduct,” indicating in a footnote that he was referring to the impeachment process. Members of Congress did not need to wait for Mueller to say those words out loud before putting two and two together. The fact that some apparently did is an indication that they, too, did not take the time to engage with the document.

Two notable exceptions here are Democratic Senator (and presidential candidate) Elizabeth Warren and Republican Representative Justin Amash—both of whom have made a point of reading the entire report and publicly discussing their conclusions. Both support impeachment.

In a democratic society, it would be ideal if citizens had the time to read and debate the contents of something as politically and constitutionally significant as the Mueller report. The fact is, however, that most don’t. The press plays an indispensable role in summarizing complicated documents and explaining their significance. In a representative democracy, the people elect members of Congress in part to weigh and discuss issues that are too complicated for most to grapple with on a day-to-day basis. As part of this bargain, elected officials also receive the responsibility of guiding their constituents toward an understanding of what principles are important, and which battles are worth fighting. If the House of Representatives continues to ignore Mueller’s nudge toward an impeachment inquiry, it will be failing to take up its basic constitutional responsibility to check presidential abuses—and failing in its duty of informing the public that it should care about those abuses.



In today’s blockbuster hearings, Senate Judiciary Committee members cross-examined Attorney General William Barr on his short March 24 letter summarizing Special Counsel Robert Mueller’s probe. In that letter, Barr stated that Mueller had declined to reach a judgment on whether Donald Trump had obstructed justice. Senate Democrats seized on a letter by Mueller complaining that Barr’s short report to Congress “did not fully capture the context, nature, and substance of this office’s work and conclusions” and therefore threatened to “undermine a central purpose” of the special counsel: to ensure “full public confidence in the outcome of the investigations.”

Criticism of Barr’s summary makes much ado about nothing. Barr released the Mueller report just a few weeks later, with the crucial second volume on obstruction of justice virtually unredacted. Members of Congress and the public can reach their own judgments now on the Mueller report’s findings on obstruction. How Barr characterized Mueller’s findings makes no difference.

But fixating on who wrote and said what about someone’s characterization of someone else’s report deflects attention from the most important thing about Barr’s letter: The attorney general did not just summarize Mueller’s conclusions; he also filled the gap left by Mueller’s refusal to decide on obstruction. “The evidence developed during the Special Counsel’s investigation is not sufficient to establish that the President committed an obstruction-of-justice offense,” Barr concluded in his letter. He and Rod Rosenstein, then the deputy attorney general, reached this view “without regard to, and … not based on, the constitutional considerations that surround the indictment and criminal prosecution of a sitting president.”

Yet Barr’s decision should have come as little surprise. Last June, well before his appointment as attorney general, Barr sent an unsolicited memorandum to the Justice Department arguing that Mueller’s obstruction investigation was “fatally misconceived.” He argued that a president could not commit obstruction by exercising his constitutional powers, such as his sole authority to remove the FBI director, or even by terminating a criminal prosecution. To allow Mueller to proceed, Barr argued, “would have grave consequences far beyond the immediate confines of this case and would do lasting damage to the Presidency and to the administration of law within the Executive branch.” Barr repeated that view today: “The president does not have to sit there constitutionally and allow it to run its course,” he told senators. “The president could terminate the proceeding, and it would not be a corrupt intent, because he was being falsely accused.”

Yesterday’s hearings began to make clear that Barr thought Mueller should not have even investigated Trump for obstruction. As his report indicated, Mueller believed himself bound by a Clinton Justice Department’s 2000 ruling that “the indictment or criminal prosecution of a sitting President would impermissibly undermine the capacity of the executive branch to perform its constitutionally assigned functions.” But if the Justice Department cannot indict a sitting president, as Barr observed, Mueller should not have continued a probe that could have no fruitful end.

Barr, however, misunderstands Mueller. Mueller looked into 10 episodes, almost all of which did not involve normal obstruction such as witness intimidation or evidence tampering. Instead, Trump’s actions, such as firing James Comey, his order to remove Mueller (thankfully ignored), or another command to shut down the special counsel’s investigation (ditto), could have represented the president’s good-faith exercise of his constitutional duty to “take care that the laws be faithfully executed.”

Mueller could not find the crucial element of obstruction, which is that the president held a “corrupt” mental state to interfere with a legitimate legal proceeding. This is a delicate judgment, because some acts that appear legal can become obstruction, depending on the motive. Sending money to a witness’s family, for example, does not violate any law, unless a mob boss does it to buy the witness’s silence. Mueller could not reach a judgment that Trump had that corrupt motive without interviewing Trump directly. Here, the president’s lawyers outfoxed Mueller by refusing to make Trump available for live testimony and by barring any written questions on obstruction.

But critics wrongly challenge Barr’s and Mueller’s declination to prosecute. Instead, they should welcome it. Their decisions return the duty to curb presidential abuses of power to its constitutional seat—Congress. Mueller makes clear that he “conducted a thorough factual investigation in order to preserve the evidence when memories were fresh and documentary materials were available,” even though he could not prosecute a sitting president. Why? The reason Justice does not prosecute sitting presidents, Mueller argues, is so as not to “potentially preempt constitutional processes for addressing presidential misconduct.” The only mechanism that the Framers established to remedy presidential abuse of power remains impeachment.

Impeachment must be the only solution to Trump’s challenge to the constitutional order. The Constitution did not envision that the criminal-justice system would address abuses of presidential power. Since Watergate, we have embarked on a 40-year experiment in using the criminal law to resolve separation-of-powers disputes. If Ken Starr’s sprawling Whitewater probe had not already demonstrated it, the Mueller report should prove that the experiment has failed. The Framers vested in the president the authority to oversee all federal law enforcement. As Alexander Hamilton observed in “Federalist No. 70,” “good government” requires “energy in the executive,” and a vigorous president is “essential to the protection of the community from foreign attacks” and “the steady administration of the laws.” Because of this original design, a president can order the end of any investigation, even one into his own White House.

The creation of independent counsels was an attempt to solve this conflict of interest, but the cure was worse than the disease. A special counsel, as even Trump realized upon learning of Mueller’s appointment, could spell the end of a presidency by diverting executive power outside constitutional controls and sapping the White House of its energy. Independent counsels further have the convenient effect of relieving Congress of its own constitutional duty to constrain an abusive president.

If Congress truly believes that a president has abused his powers, it can cut off funds, block his nominees, and impede his legislative priorities. It can proceed under impeachment, which allows for the removal of a president for treason, bribery, “or other high Crimes and Misdemeanors.” As Hamilton explained in “Federalist No. 65,” this last category of offenses includes those that “proceed from the misconduct of public men, or, in other words, from the abuse or violation of some public trust. They are of a nature which may with peculiar propriety be denominated political, as they relate chiefly to injuries done immediately to the society itself.” Congress can conclude that the same conduct raised in the Mueller report justifies removal from office, even if it is not criminal.

The Framers did not want legislators to avoid the responsibility of curbing presidential abuse of power by hiding behind prosecutors or the courts. Impeachment may place that awesome duty in a body subject to political pressures and sensitive to other national demands. Nevertheless, the Constitution makes Congress alone accountable for removing a president who abuses his office. Ultimately, both Attorney General Barr and Special Counsel Mueller have done the nation a service not just by clearing the president of collusion, but by returning the question of obstruction to Congress, where it belongs.



On March 22, as I was about to wrap up a meeting with a client, I got a phone call. At first I ignored the vibrating phone, but the same number kept calling. “Aren’t you going to take that?” my client asked politely. As I reached out to take the call, the phone stopped buzzing. Then it vibrated with a short message: “Your brother was arrested.” My heart sank. I stumbled out of my meeting trying to find out what I could do to help my brother.

I believed I knew why he had been arrested. My brother Abderrahmane Weddady, 48, is a whistle-blower. Mauritanian President Mohamed Ould Abdel Aziz—or Aziz, as he is known locally—opted to silence him. The president was betting on global media and institutions to do what they have done throughout his 14-year reign: ignore Mauritania. He had gotten used to this lack of accountability. And he was facing the greatest financial scandal in the West African nation’s history.

My brother believed that he had uncovered a dangerous Ponzi scheme. Sheikh Ali Rada Al Saidy presented himself as a man with a blessing, a pious cleric of many miracles. He offered Mauritanians a tempting deal. He bought their homes at prices way above market value, my brother alleged, offering partial payment in cash and the rest as an IOU to be paid over the next one to three years. His army of representatives then moved immediately to flip the properties at deeply discounted prices—at times, as little as 50 percent of the real value—using the proceeds to pay off earlier creditors, according to my brother’s investigation.

This “blessed money fructification miracle” had been under way for four years until my brother—a construction entrepreneur—noticed that real-estate prices were tumbling fast in January 2016. He began a relentless campaign to warn the public of what he believed was an impending social and economic disaster, leveraging his popularity as a transparency and democracy activist, and his only weapon: his highly read Facebook page.

His plan was simple: to dissuade as many people as possible from falling for the swindle. He even published documents alleging that members of the president’s own family had benefited from the scheme. The scheme imploded last fall. Ever since, the victims have been demonstrating in the streets seeking payment. Rebuffed by the courts and law-enforcement agencies that refuse to investigate the fraud, they are left to fend for themselves. They are incensed that the police and the president have not held the alleged scammer accountable.

The injustice in imprisoning my brother, along with his fellow transparency advocate Cheikh Ould Jiddou, is perhaps the least of all the scheme’s consequences. My brother estimated that more than 7,000 families were affected, and that it cost more than $200 million. That would be 4 percent of Mauritania’s GDP. The social damage caused by people losing their homes, future, and dignity, though, defies efforts to assign it a price tag.

Aziz is due to hand over power in June. His exit may be welcome news to most Mauritanians. Aziz participated in a 2005 coup, then cemented his power through another coup in 2008, and his leadership of the country since then has been anything but transparent. In violation of Mauritanian law, he began his first term as president, in 2009, by disdainfully refusing to publicly disclose his wealth. In 2013, local media outlets broadcast a recording of a conversation between Aziz and an Iraqi citizen from 2006, allegedly about boxes of forged U.S. dollars. Aziz later admitted to the authenticity of the recording, claiming to having been a victim of a con artist. The World Justice Project’s 2019 “Rule of Law Index” ranks Mauritania’s government as the world’s 11th-most corrupt, and fifth worst in terms of the rule of law.

Why does the world tolerate this? Many believe that if a dictator or a strongman is willing to leave power peacefully, he ought to be encouraged, and that his past misdeeds, especially corruption, should be forgotten for the greater good of a peaceful transition. Tolerating corruption, the argument goes, is still a small price to maintain peace and order.

In March 2017, the International Monetary Fund’s Mauritania bureau sent a memo to IMF headquarters recommending that it provide information to the Mauritanian government on the dangers of Ponzi schemes, according to a source familiar with the document. If such a warning was ever issued, it does not appear to have had any effect on the government, or on the IMF’s willingness to engage with it.

There’s another reason for the world’s acquiescence. Aziz, since coming to power, has successfully branded himself as a bulwark against terrorism in the Sahel. This pose, employed by so many others since the dawn of the War on Terror, has become a costly cliché. Yemen’s Ali Abdullah Saleh is a textbook example. He received hundreds of millions of dollars in U.S. aid in the name of fighting terrorism, yet left Yemen impoverished, divided, and mired in war.

Mauritania is one of the poorest nations on Earth, and Aziz will bequeath a difficult legacy to his successor. The $200 million lost in the alleged Ponzi scheme is a pittance compared with the country’s galloping foreign debt. It has skyrocketed to $4.9 billion, a 346 percent jump from the year Aziz came to power after his second coup. Like many of his fellow strongmen, Aziz has gotten used to passing on the bill for his excesses to world donors, condemning the next generation of Mauritanians to live on handouts and donations while he and his entourage live large.

Aziz’s exit from power provides a golden opportunity for the United States to change its approach to corruption by former heads of impoverished states, creating accountability for the theft of public moneys. Mauritania presents none of the usual complications of vested interest groups or geopolitical power struggles plaguing other parts of the world. Lawmakers on Capitol Hill can authorize the Treasury Department to employ its arsenal of tools allowing it to track and identify ill-gotten fortunes. Doing so would provide a warning to the leaders of other impoverished nations, deterring them from looting their people and leaving behind failed states.

We have now nearly 19 years of evidence to show that in places such as Afghanistan and Iraq, the single most decisive factor in the failure of nation-building projects has been the inability to install good governance. Instead, many of the leaders backed by the United States turn out to be corrupt, diverting public funding meant to fix roads, provide electricity, and expand access to health care into their own pockets. But solving this problem doesn’t require armed force—it requires addressing it head-on.

Holding leaders like Aziz to account for any corruption, and seizing any ill-gotten gains, sends the message that the United States will not allow them to plunder their nations or turn them into vortexes spewing instability, extremism, and violence for the rest of the world to deal with. That message would ring loud in the ears of the world’s kleptocrats, and perhaps protect others from sharing my brother’s fate.



“There are four primary causes of injury: the ox and the pit and the crop-destroying beast and fire.” Those are the opening words of Bava Kamma, the tractate of the Mishnah—the first authoritative compendium of rabbinic Jewish law—that deals with the laws of damages. The deeper meaning of the Mishnah is that there is one primary cause of injury: people living in proximity to one another.

Human proximity puts our property at risk: A neighbor’s dog could wreck your garden, a construction project poses a public danger, a backyard fire can burn out of control. You and your stuff would be safer kept away from others.

In the early hours of Sunday, a man threw three Molotov cocktails at the synagogue in the Lakeview neighborhood of Chicago’s North Side where I serve as director of religious engagement, a member of the clergy. He did not succeed in causing any damage. When we arrived for services on Sunday morning, some noticed broken bottles but hurried along with their day. Only later did our maintenance staff notice that the bottles were surrounded by puddles of oil and charred rags. We called the police and looked through our security footage; we realized we had been attacked.

These types of attacks are becoming common: Synagogues, mosques, and black churches around the country and the world have faced violence in the past few months. It’s easy to assume that the solution is to wall ourselves off, to draw apart. If, ultimately, other people pose the greatest threat to my person and my property, perhaps I should distance myself from them.

Jewish legal sources—including the Mishnah, and the later rabbinic elaborations in the Talmud—have a lot to say about restitution for damages. Nowhere, however, does Jewish law recommend living in isolation. Community is essential to being a Jew, because community is essential to being a human. We need one another. When we live in close proximity, we will inevitably cause damage to our neighbors, whether with our words or our actions, and we lay ourselves open to being damaged in turn. But the implicit message of Bava Kamma is: The risk is worth it.

Jewish law obligates us to gather. We gather to study, we gather to pray, we gather to celebrate, and we gather to mourn. The members of my synagogue live near one another, for on Shabbat we commute to synagogue only by foot—and so in our community we are not just co-religionists but also neighbors, sharing cups of sugar, folding chairs, and playdates. At our synagogue we hold three prayer services a day: morning, afternoon, and evening. Some of our most central religious activities simply cannot be performed without the presence of others.

These gatherings make us vulnerable. On a day-to-day basis, we are perhaps more aware of how they make us vulnerable to our fellow community members. Our synagogue is a community of differences. Our congregants are diverse in age, race, sexual orientation, marital status, political affiliation, and socioeconomic situation. Being able to share community amidst such differences mean accepting and even embracing vulnerability.

And so in our synagogue, 20-year-olds sit next to 70-year-olds every week. Republicans and Democrats share pleasant conversation, perhaps agreeing on various areas of synagogue policy or learning from one another in Torah study. Families invite newcomers into their home for meals and conversation, drawn together by the warmth of Jewish hospitality modeled by the biblical Abraham. And even the most deep-seated differences can be temporarily set aside: Cubs, White Sox, and even Cardinals fans pray side by side. In a polarized world, our synagogue stands out as a model of what living around other people can be.

Under attack, we realize that there’s another type of vulnerability that we face when we gather. We are also vulnerable to outsiders. Just having a holy space at all, in this day and age, makes a community open to attacks. Our urban location makes us particularly visible. And yet, it is important for us to remember that we also benefit from that visibility. Jews who come to Chicago for conferences find hospitality in our synagogue. We have the opportunity to educate the wider Chicago population about Judaism. Our members enjoy the arts, culture, and convenience that the city offers. And we gain wonderful neighbors. Our community benefits tremendously from our location, even as it makes us vulnerable.

On Sunday evenings, I teach a short lesson in Jewish law after services. This Sunday evening, my selection was obvious. “There are four primary causes of injury: the ox and the pit and the crop-destroying beast and fire.” Our sacred space had been violated, but the Torah had something to say about it. The Torah knows that people living in proximity occasionally cause one another harm, even through fire, and the Torah tells us: It’s worth it. Stay.

And so we will defiantly continue to gather. In our synagogue, behind the stained-glass windows that the arsonist failed to break, we will come together to worship and study and grow. Together we will rise above the fear that the arsonist so desperately hoped to instill in us. Our synagogue will remain a powerful reminder that humans can and will and must gather, with all of our differences, because only in community can we live out our fullest human potentials of holiness, kindness, and service.



Late on the eve of my mother’s wedding day, in August of 1965, in Springfield, Illinois, a hoot owl on a tree outside her bedroom window called out “Who? Who?” The call echoed in the darkness of her high-ceiled room. It was a loaded question.

Earlier that day, my grandmother (Granny, we kids called her) had taken my mother (whom we call Mama) aside for a private talk. “Now Beth,” she said. “You know that Daddy and I had trouble having you.” In spite of Granny’s midwestern Methodist reserve and impermeable feminine decorum, Mama did know a little about this. When, as an unusually intense and imaginative little girl, she had begged Granny for brothers and sisters, Granny had finally explained that siblings were impossible. She and Grandpa had tried to conceive Mama for five years and sought the assistance of doctors at a Chicago hospital; it was a miracle she had been born at all. Mama would have to content herself with her cousins in Moweaqua—the children of Granny’s little sister. Effusive and highly sociable, Mama bonded with her cousins as if they were her own sisters and brother, and made near-siblings of the kids on her block, herding them to perform dog circuses and theatricals on their quiet street.

On Mama’s wedding eve, Granny anticipated that Mama would want to have a lot of children (she would end up with three—my two brothers and me), and she worried that Mama would try to start a family too soon, out of fear of fertility issues down the line. “Now, don’t you worry about having babies,” Granny told Mama. “You won’t have any trouble. The problem wasn’t with me—it was with Daddy,” she said. Then, pausing, she added emphatically: “But Daddy is your daddy!”—and, blue eyes flashing, concluded quickly, “Now, don’t you ever bring this up again.”

I was 12 when I first heard this story, in my childhood home in Indiana. Mama was by then a grown woman, of course, and though she was still cowed by Granny (who maintained her iron hold on Mama’s psyche over the phone from Illinois), she had disobeyed Granny’s prohibition, and corresponded with the hospital in Chicago where she was conceived. To her frustration, the hospital could supply no records that would clarify the circumstances of her conception. She filled me in as she sat at the kitchen table, putting the hospital’s final letter in a file folder she had whimsically labeled “Abe Horowitz.” It made sense: I had noticed that Mama looked different from her relatives, and that a lot of people thought she was Greek, Turkish, or (more rarely) Indian. But it had not occurred to me before that day to wonder why.

My mother was tall, long-legged, and slender, with gleaming blue eyes (one of her bosses said they looked like “a car with its headlights on in the daytime”), thick, dark brown hair, a tea-and-milk complexion, and a humorous, original charisma. Despite her blue eyes, Mama was darker than her parents, and didn’t look much like her cousins, aunts, or uncles, or her peers at the Methodist church or Springfield High. She certainly looked nothing like Grandpa’s side of the tree, with their snub noses, light hair, and solid builds.

When Mama’s colleagues went on business trips to New York, they always asked her to recommend a restaurant. Something about Mama made people assume she was a New Yorker—which, in Indiana code, meant Jewish. She relished that idea, and encouraged it, and would immediately name the one restaurant she’d been to, on a high-school graduation trip with her Springfield classmates. But after I found out about the Chicago hospital, I decided she might be half Syrian; my best friend in kindergarten was half Syrian and looked, I thought, like a mini-Mama. Later, in the 1990s, Mama worked in Moscow, and people on the sidewalk would stop her to ask for directions, because to their eyes, she looked Russian. But Mama liked being taken for Jewish. She was convinced that her notional genetic father was Jewish, which is why she had made up the most Jewish name she could think of for the folder on her birth research.

As she closed the Horowitz file in our kitchen that day, Mama told me her theory of her parentage. The minute she had heard Granny’s wedding-eve words, Mama had deduced that Grandpa must have been infertile. A lifetime of not quite matching her environs now made sense. She put together a chain of events in her mind that could explain her conception. Granny’s doctor, at wits’ end after five years of Granny’s persistent visits to his examination rooms, must have begged an intern to help him out with a sperm donation to “enliven” Grandpa’s batch, to get Granny off his case. In Mama’s evocation of the scene, which I listened to with rapt attention, the doctor grabbed the intern by his lab coat, and said desperately, “Abe, Abe! Help me out: This Springfield woman won’t give up, but there’s no chance her husband’s sperm will work!” This was long before the advent of IVF, so Grandpa’s sample was fortified with an addition from the notional “Abe,” and Granny was, essentially, turkey-basted. No records were kept of the procedure, or at least none survived. Nine months later, Mama was born.

My mother was always (and still is) an ace raconteur, exaggerator, and self-dramatizer, so I thought this story might or might not be true. But I wanted to believe it. Other kids have fantasies, growing up, that they are secretly high-born changelings who ended up by accident in a prosaic Muggle household. I had those fantasies about my mother. I thought she was too extraordinary to have come from our pragmatic Germanic farm stock. Nothing about the combination of Grandpa and Granny explains Mama. It wasn’t just her appearance: What was most distinct about her was her temperament—her creativity, wit, and energy.

I loved Grandpa, and so did Mama. He was a kind, generous, calm, and loving husband, father, and grandfather, steady as they come; an IRS man who got called up to World War II just after Mama was born. Luckily, Grandpa got pneumonia, so he spent the war at a desk job in Georgia, while the rest of his unit perished in the Pacific war. Nonetheless, after I found out about the Chicago hospital, I liked to daydream about who Mama’s genetic father might be; someone brilliant and unconventional, I hoped. Maybe he’d won a Nobel. The idea that she must derive from a mysterious unknown genius gene pool fascinated me. Now, armed with this story, I immediately shared it with my friends at school. I told the Jewish boys I dated that I was probably a quarter Jewish, hoping it would make them take me more seriously. (It didn’t.)

For nearly 40 years, the “Abe Horowitz” file remained closed. Then, five years ago, my little brother got Mama a 23andMe kit for Christmas. She sent off her sample, and when the results came back, she learned, to her delight, that she was half Ashkenazi (and 3 percent Neanderthal, which she joked explained her table manners). Exultant to have her long-standing conviction confirmed, she began hunting on the website for the siblings she had always yearned to have. But she found no close relatives—just third cousins, cousins twice removed, and so on—and soon she quit consulting the site.

Nonetheless, she embraced her scientifically certified new heritage with zest. She had my father nail a mezuzah next to the front door of their It’s a Wonderful Life–style Victorian house in Virginia. The next Christmas, after Santa visited to dandle the grandchildren on his knee and hand out big gifts, we had crown roast of pork … and Mama served latkes as a side, with applesauce and sour cream. After we opened the towers of family gifts around the tree, I led the grandchildren into the game room and taught them to play dreidel—on Mama’s orders, of course. Mama soon wrote a letter to a rabbi in the Shenandoah Valley, asking whether she could attend temple, but she got no response. The next time she and Papa visited me in New York, she begged me to take her to a Jewish service in New York, but I reminded her I was raised Methodist and confirmed Episcopalian, and I go to church. I’ve never been to synagogue. And so, despite the genetic evidence, our family’s Jewish link remained intangible.

Until May 13, when I received an email, via LinkedIn, while I was grading papers. The note came from a man who had taken a 23andMe DNA test early this year, and had discovered that he and my mother share the same biological father. He had a brother and a sister; that meant that Mama now had three half siblings. Mama had posted on her page that she had been artificially inseminated in Chicago in 1942, and wrote that she wished to know her father’s name, and to learn of any other family members and descendants. He had emailed her many times this spring, but she had never responded. I felt a pang. Mama got Parkinson’s some years ago; she doesn’t wrangle email well anymore. I thought, simultaneously: At last, Mama can know her siblings; and … they will never know what she was like in her glorious, extended prime; and … was she like her biological father? Her half brother, my new uncle, was trying to reach her through me, having guessed our connection online. He attached a photograph of his father.

Seeing that photograph, I felt an electric thrill, a cellular shock: There, in this man’s face, were my mother’s glowing blue eyes, dark brows, strong features; humorous, wise, indulgent expression; and olive complexion (“sallow,” his U.S. naturalization ID calls it). I emailed back immediately, sending photos; then we spoke on the phone, and I called Mama to tell her I had found her genetic father, and her half brother, and that she had another half brother and a half sister too. At 76, she finally had the siblings she had yearned for her whole life. She was overcome. Two hours later, my mother was on the phone with her half brother. She was shaking so much, she told me later, that she could hardly speak. The next week, he arranged a conference call, and all four siblings (including Mama) talked together, and me and my father too. At the end of this month, we will all meet for the first time, face-to-face.

Through my continuing correspondence with my new uncle, and through the photographs he has sent, I am learning more about the man who explains Mama: her genetic father, my third grandfather. He was born in Canada, of Russian and Romanian background, and his family moved to the United States when he was 10. His given name was Abraham, and his mother’s maiden name was Gurevitch—a variant spelling of Horowitz. So Mama’s guess in 1979 was spookily on target; although, my new uncle explained, his father changed his entire name in 1942—first, middle, and last—because of anti-Semitism. (I won’t share his name, or those of my other new relatives, to respect their privacy.)

He was an exuberant man, my new uncle wrote, tall and warm, with a booming voice like James Earl Jones’s, as good on the drums as Gene Krupa, and an avid dancer. He had paid his way through medical school by playing drums and piano in a jazz and swing band that toured the world, and after med school, he interned for two years at a hospital in Chicago. In our conference call with my mother’s half siblings, the older son told us that his father had mentioned to him once that he’d been a sperm donor in that era, but he knew no further details. It sounded as if the fantasy my mother had concocted was uncannily correct, or at least perfectly plausible.

In 1942, he was drafted to serve as an army captain and doctor in Panama and the Galápagos—like Hawkeye Pierce on M*A*S*H. Returning to peacetime America, he married and set up his medical practice. In his career, he delivered 2,500 babies—making a significant medical discovery along the way, using bone marrow to analyze blood diseases. He was also, his younger son wrote me, an amateur architect, a workaholic, and a smoker (all echoes of Mama), a “pillar of his community,” and a “bit of a visionary.” At last I could see the source of the fuse that makes my mother glow, and see that glow reflected back to me from a son who was as marked by his father’s aura as I have been by my mother’s. It must be a family thing.

“Abe” had died of a heart attack at 64, in 1973, the same year that my second brother was born—the one who would grow up to give Mama 23andMe one Christmas, enabling our belated discovery.

From the new family photographs in my inbox, I can see that Mama and my brothers and I have a lot of “Abe” in us: My mother has his coloring, eyes, brow, and expression; I have his eyes and jaw; my middle brother has his coloring and nose; my baby brother has his hairline and his hands, with distinctive, long, straight fingers. I wonder whether my new cousins will notice such details when they meet Mama, and I wonder how she will feel as she searches for a map of her unknown half in them. Her half siblings have always had the luxury of knowing for certain who their parents were and where they came from; my brothers and I have had that luxury too. Mama had only half of that knowledge. And yet, I think Granny was right, on the eve of Mama and Papa’s wedding, 54 years ago, when she insisted, “Daddy is your daddy!” Grandpa was the man who raised Mama, who supported her happily and proudly and patiently from the moment of her birth until his death in 2000, a lifetime of love and loyalty. Granny and Grandpa shaped Mama as surely as Mama and Papa shaped us, as sure as “Abe” and his wife shaped their three children.

This Father’s Day, I’m thinking about my three grandfathers. There was Grandpa Schillinger, who raised Papa to be strong and capable and honorable; there was Grandpa Hupp, Mama’s dad, whose constancy and supportiveness were a model of fatherliness; and now there’s “Abe,” formerly invisible, now emerging as an intertwined trunk in this family tree, the man who brought my mother to Granny and Grandpa, and through them, to Papa, and to us.

The man who raises you with love is your real father; but if there is a man who allowed that man to become a father, I believe he deserves a place of honor in the family tree as well. He’s the man behind the story, without whom the story could never have been born.



Back in 2007, Donald Trump sent the newly sworn-in speaker of the House, Nancy Pelosi, a letter celebrating her ascension.

“Nancy—you’re the best. Congrats. Donald,” the entertainer wrote, Politico reported in 2011. The correspondence between the two has taken a more combative tone recently, which makes the current moment all the stranger: Pelosi might be the biggest barrier between President Trump and an impeachment inquiry right now.

Pelosi has made her personal opposition to impeaching Trump clear. In March, for example, she told The Washington Post, “I’m not for impeachment … Impeachment is so divisive to the country that unless there’s something so compelling and overwhelming and bipartisan, I don’t think we should go down that path, because it divides the country. And he’s just not worth it.”

Until recently, most members of the Democratic caucus have been willing to go along with their leadership’s position. (A few backbenchers have consistently called for impeachment.) But the past few days have brought signs that that’s no longer true.

Democratic members are growing more frustrated with the Trump administration’s strategy of stonewalling House investigations. The latest move came late Monday, when the White House said it was “directing” former White House Counsel Don McGahn not to appear for testimony to the House Judiciary Committee. McGahn duly did not appear Tuesday. As I noted, McGahn’s testimony would probably come closer to a preview of an impeachment inquiry than any other witness’s appearance.

During a meeting on Monday, according to reports in Politico and the Post, several Democrats told the speaker that it was time to launch an impeachment inquiry, including Representatives David Cicilline of Rhode Island, Jamie Raskin of Maryland, and Joe Neguse of Colorado. What’s interesting about these members is they’re all members of the Democratic leadership team. Today’s leadership teams are large, and none of these representatives is majority leader or whip, but they’re also not backbenchers.

And they’re making their arguments loudly and publicly. Raskin told the Post’s Greg Sargent Tuesday:

I think that overwhelming evidence has been presented to us in the Mueller report, and outside of it too, of high crimes and misdemeanors, and we should launch an impeachment inquiry. Remember, an inquiry doesn’t prejudge the outcome. We’re not talking about articles of impeachment.

As a member of the Judiciary and Oversight committees, I do think the logic of an impeachment inquiry is pretty overwhelming at this point.

While some of these members have been on the vanguard of calling for tough action against the administration—Raskin told my colleague Russell Berman earlier this month that the House should consider arresting officials whom it holds in contempt—the open impeachment talk is a shift. This isn’t to say that in an un-whipped vote of House Democrats impeachment would win. Until it’s actually taken, that’s difficult to determine.

The pro-impeachment Democrats have their own strange ally: Representative Justin Amash, a Republican from Michigan. Over the weekend, he announced that he supported impeachment. His argument was unusual in its specificity, and he pointedly said that few of his colleagues had actually read Special Counsel Robert Mueller’s report. In fact, Amash went further than most Democrats. Even Raskin is quick to note that opening an inquiry doesn’t automatically lead to impeachment, while Amash stated flatly that Trump has committed impeachable offenses. Because Amash is a Republican, his position also means that there’s now bipartisan support for impeachment, at least in name.

Pelosi is unmoved. She and her closest allies reportedly pushed back on the restive members of the caucus during Monday’s meeting. From her perspective, none of the underlying reasons for going slow have changed. Amash may create nominal bipartisanship, but the fierce backlash he generated—Amash drew a primary challenger and was chastised not only by the president but by the House Freedom Caucus, the closest thing to his clique in Congress—shows that at least for now, his announcement is more symbolic then seismic.

Moreover, the speaker believes that Democrats are winning on their present course. On Tuesday, a federal judge incredulously rejected the Trump administration’s attempt to block the president’s accounting firm from turning over his financial records. In April, another federal judge said that a suit from House Dems alleging that Trump violated the Constitution’s emoluments clause could go forward. The White House has placed its hope on courts blocking Democrats, and so far the strategy isn’t working. Why hastily change course and embark on a risky impeachment inquiry now, when things are all breaking Democrats’ way? Impeachment will still be an option later.

This seems to be the subtext for many of Pelosi’s comments on impeachment. On face, she says she’s not in favor. But her explanations and reasons suggest a different answer: Maybe, just not yet. Both factions of Democrats insist they’re acting not out of political expedience, but principle. “This is not about politics, it’s about what’s best for the American people,” Pelosi said Monday, according to Politico. The pro-impeachers agree: Even if there aren’t more Republicans with them, and even if conviction in the Senate is sure to fail, it’s the right thing to do.

Those high-minded explanations aside, it’s also unknowable what the most politically advantageous course of action is for Democrats. The White House doesn’t know either. Trump has seethed at the idea of being impeached, but his stonewalling strategy seems almost designed to force Democrats into impeaching him. For the time being, Nancy Pelosi might be the one thing restraining them.



On Wednesday, the New York State Senate approved two important bills that could shape the legal fight over President Donald Trump’s tax returns and his pardon power, if they become law. But one of those bills—the one allowing New York State to give tax returns upon a request from Congress—also includes a word that could undermine the U.S. House of Representatives’ efforts to get Trump’s state taxes. That specific word is specific. And that word gives the House a new reason—in addition to all the ones it already possesses—to initiate a formal impeachment inquiry.

That step is already warranted by the Mueller report’s evidence that the president may have committed obstruction of justice (and by at least a preponderance of evidence, coordinated with Russia illegally). But when a court, interpreting the text of this potential new law, asks the House to identify its “specific and legitimate legislative purpose” for seeking Trump’s tax returns, impeachment is also the more specific and honest statement of the House’s purpose, and thus, more likely to prevail. In fact, a formal impeachment inquiry could be the honest legal move that saves all the House subpoenas from new conservative legal interpretations.

Section 6103(f) of the Internal Revenue Code states that “upon written request” from the chair of the House Ways and Means Committee, the Treasury secretary “shall furnish such committee with any return or return information specified in such request.” Many observers have assumed that the word shall does all the work to compel Treasury Secretary Steven Mnuchin to turn over the returns, but that bit of text must be understood in the larger context of constitutional law and precedent. Such a request, like a subpoena, must have a “legitimate” purpose.

On Monday, Mnuchin rejected the request from Ways and Means Chair Richard E. Neal to disclose the returns, saying that it “lacks a legitimate legislative purpose.” This dispute will head to the courts to evaluate whether a “legitimate legislative purpose” exists.

But meanwhile, the New York legislature is considering a second track. The bill passed by the Senate (which would still require the approval of the assembly and the signature of the governor to become law) would authorize the Department of Taxation and Finance to share state tax-return information with the relevant congressional committees as long as there is a “specific and legitimate legislative purpose.” Note that extra word, beyond what Mnuchin himself cited: specific. Perhaps New York legislators added this word as a compromise to allay the valid concerns of those worried about overbroad fishing expeditions and vague requests that might be pretexts for a partisan purpose.

That’s exactly the point. Americans should be wary of changing our laws too abruptly just to investigate Trump. When the last law is down, as Robert Bolt wrote, the devil may turn round on you, and where would you hide? Some curbs seem necessary, to guard against future abuses. The word specific can have several meanings, but some definitions of specify suggest a connection to the word clarify. A plausible reading is that the New York legislature added the word specific to eliminate pretextual or misleading explanations.

And let’s be honest. Is Neal seeking Trump’s tax returns because he is mainly interested in the IRS’s methods? To see whether Trump owes back taxes? It is far more likely that he wishes to know whether Trump has debts or financial ties that may compromise him, or whether he has links to money laundering. That would make the request part and parcel of an impeachment inquiry, whether or not the House makes that explicit.

House Democrats already had good reason to formally launch an impeachment inquiry and then connect their subpoena requests and tax requests to this proceeding. A growing chorus of conservative legal commentators is floating the argument that a request for tax returns ultimately driven by partisan politics does not clear the bar of serving a “legitimate purpose,” even if the House explicitly cites other purposes. Some legal experts are making a constitutional argument that such requests violate the separation of powers, unless the House is formally pursuing impeachment. This argument would challenge most of the House subpoenas.

Some of these claims seem to be a serious legal stretch, but that’s no reason not to take them seriously. There are at least two recent examples of novel or surprising legal claims being entertained by the courts, both from the litigation surrounding the Affordable Care Act. When parties first challenged the individual mandate as exceeding Congress’s enumerated powers, many observers laughed, but conservative commentators built up a more plausible case. The individual mandate barely survived, but it would have been on much stronger ground if Congress had been more honest in calling it a tax. Congress, though, had wanted to avoid the political risk of explicitly creating a new tax, and the Supreme Court almost made it pay a steep price for this pretext and this fear of transparency.

A few years later, the Supreme Court reviewed whether the ACA allowed the federal government to create exchanges when it used the word state. Narrow textualists would say no. But the Supreme Court ruled that the purposes of a law were relevant, not just a simple reading of a word. So, too, the federal courts could rule that the word shall is not the end of the story.

Some of these arguments are more persuasive than others. The purpose of the Constitution’s structure, and of other statutes that compel compliance with congressional subpoenas, is to prevent abuses of legislative power. Hypothetically, if a Treasury secretary knows that a request is part of a blackmail scheme or an effort to embarrass a political opponent, then the secretary would have grounds to reject the request, regardless of the word shall.

In the context of 2019, with Trump and the Republicans having dramatically shifted the federal judiciary, is it imaginable that some judges might view Neal’s request as primarily political and partisan? Is it possible that these judges would regard the current explanations from Neal about “oversight” as pretexts hiding a political purpose, and reject the requests? If Trump went to federal court to enjoin New York State from handing over his taxes, could his lawyers argue that the House had failed to specify a legitimate purpose because it offered a pretext and cowered from stating its true purpose?

Voting to authorize an impeachment inquiry would put such questions to rest. Impeachment is explicitly granted as a constitutional power, which would address the separation-of-powers concerns that conservatives have been raising.

The bottom line is that if House Democrats want a strong and legitimate legal argument for getting Trump’s tax returns from Treasury or from New York State—or getting bank records, or getting its other subpoenas to prevail in court—they need to vote to start a formal impeachment inquiry. Then they can specify a deeply legitimate reason for their request: There is a credible question as to whether the president has committed high crimes and misdemeanors. His tax records and the Trump Organization tax records may provide evidence of the motives, or perhaps even of underlying crimes, that led to his campaign’s exploitation of Russian interference in the election, and to his own efforts to obstruct justice. Such a brief would have the virtue of being honest and forthright, as well as being stronger legally. Let’s see whether the federal judges would rule that this purpose was not specific and not legitimate. If they did, then at least it would clarify—and specify—who was and was not truly legitimate.



Having apparently not bothered to read Special Counsel Robert Mueller’s report—after all, it was 448 pages, often in repetitive legalese—large sections of the political and journalistic establishment seemed shocked to learn yesterday that Mueller had pointedly not cleared President Donald Trump of the charge of obstruction of justice, and that he felt that only Congress (and not the Justice Department) could appropriately decide whether the president was involved in wrongdoing.

Poring over Mueller’s remarks for telling disclosures is mostly a fool’s errand, since they closely tracked—nearly word for word—what was in the report, which, Mueller noted, “speaks for itself.” There was, however, one place the special counsel did tip his hand, and it had little to do with Trump.

“Let me begin where the appointment order begins, and that is interference in the 2016 presidential election,” Mueller said, and he sketched out briefly what his investigation alleged: that Russian intelligence officers “launched a concerted attack on our political system,” and released information in a scheme “designed and timed to interfere with our election and to damage a presidential candidate.” Meanwhile, “a private Russian entity engaged in a social-media operation where Russian citizens posed as Americans in order to influence an election.” He added, “The matters we investigated were of paramount importance.​​”

A few minutes later, as he finished up, Mueller returned to the theme. He said it even after thanking members of his team (and, in what truly did sound like a rebuke to the president, noting, “These individuals who spent nearly two years with the special counsel’s office were of the highest integrity”). For his final public words in a decades-long life in government, he chose to say this:

I will close by reiterating the central allegation of our indictments that there were multiple, systematic efforts to interference in our election. And that allegation deserves the attention of every American. Thank you. Thank you for being here today.

In Muellerese, this closing was something akin to screaming at the nation, Are you people paying any attention to the work that my team did? The answer, for the most apart, appears to be no.

Trump says “the case is closed,” yet on interference—unlike collusion—this is emphatically not the case. Mueller delivered massive, detailed indictments on election interference, but the defendants—located in Russia—are unlikely to ever appear in American courts. Roughly three years after the first reports of hacking into computer systems at the Democratic National Committee, a few months after additional Russian interference in the 2018 elections, and with a year and a half left until the 2020 elections, there’s still no real movement by the federal government to respond.

A few bills have been introduced. House Democrats’ major statement piece at the start of the session, H.R. 1, included some provisions for election security, though no one expected the bill to make it into law. Another House bill would criminalize cooperation with foreign powers to interfere in elections; it has a few dozen Democratic co-sponsors, but no Republicans.

Realistically, it doesn’t matter what the House passes, because any such bills will die in the Senate, where Majority Leader Mitch McConnell has decided to bottle them up. During a Senate hearing earlier this month, the Democrat Dick Durbin asked whether the Rules Committee would move any election-security bills. Committee Chair Roy Blunt suggested that this would be pointless, given McConnell’s blockade.

“At this point I don’t see any likelihood that those bills would get to the floor if we mark them up,” Blunt said. “I think the majority leader is of the view that this debate reaches no conclusion.”

It’s a peculiar position. There’s not really any debate to speak of. Every investigation has come to the same conclusion: Yes, the Russians interfered, and yes, they and other foreign powers will try to do so again. Moreover, election security seems like it ought to be obvious ground for bipartisan cooperation. There will be no agreement between Democrats and Republicans on whether the Trump campaign colluded with Russia. So far, there’s no sign of agreement between Democrats and Republicans not named Justin Amash on obstruction of justice.

Election security has the potential to be different. Politicians of both parties are in danger of becoming victims of foreign interference, whether in the form of hacking or social-media campaigns. While the Russians chose Trump as their horse in 2016, that decision seems to have been more opportunistic and contingent than ideological: President Vladimir Putin hated Hillary Clinton; the Russian goal seems to have been sowing chaos, which can be done in various ways; and the Kremlin has disagreed with many of Trump’s actions.

But the nature of the 2016 interference remains the sticking point. Because Trump is so sensitive about anything that he feels would undermine the legitimacy of his victory, he refuses to grapple with it or acknowledge it, even though nearly every other official in his administration has. In April, The New York Times reported that White House Chief of Staff Mick Mulvaney has counseled staffers not to even mention election interference around Trump, because it tends to set him off.

This sometimes leads to absurd contortions. On Thursday, during a rant about the investigations into him, Trump tweeted, “Now Russia has disappeared because I had nothing to do with Russia helping me to get elected.” Later in the morning, however, Trump told reporters, “Russia didn’t help me at all. Russia, if anything, I think, helped the other side.”

Insofar as “Russia has disappeared,” it’s because Trump refuses to have a serious conversation about election interference, and because McConnell has decided to coddle the president’s sensitivities. The country remains largely unprepared for and undefended from the attacks that are certain to come.



Growing up in northern New York, a land of harsh and snowy winters, summer days were a gift to be enjoyed outdoors. The summer of 1974, however, will forever be seared in my memory as the summer we spent glued to the news. The entire country was riveted by the Watergate drama unfolding in Washington, eager to learn the truth and reclaim our government as a beacon of hope and opportunity rather than a den of corruption and opportunism.

Those of us who came of age during the Watergate era again feel the weight of that period in our history—rooted deeply in constitutional consciousness—with the issuance of the Mueller report.

In the aftermath of the 2016 election, many people were willed away from the sidelines and onto the ballot by the desire to restore faith in our democracy. Like many of my freshman colleagues in the most diverse Congress in history, I felt called to serve because I knew we had a duty to reclaim our government. We knew the American people deserved better.

Today, I serve as the vice chair of the House Judiciary Committee. As I undertake the heavy task of digesting, analyzing, and reacting to Special Counsel Robert Mueller’s report, that duty to country is front of mind. The report is incredibly dense—certainly not tweetable—and shows a presidency founded on opportunism, lacking in understanding of history or the functions of government, and devoid of respect for public service or the rule of law.

Despite what the president and his allies have claimed, this report is not the end of the story. It is a road map to guide Congress’s next steps.

The special counsel directs Congress’s attention to four areas of inquiry: obstruction of justice, coordination by the Trump campaign with the Russian government, 14 ongoing criminal investigations, and the president’s refusal to provide forthright answers to the special counsel’s questions.  

Investigating each of these four areas demanded lengthy and thorough work by the Mueller team. But with Attorney General William Barr refusing to be transparent about the totality of that work, including the underlying evidence, Congress must recover and review this evidence in order to fulfill its constitutional duties and restore the American people’s faith in both the process and the results of that process.

The evidence this report presents, preserves, and alludes to, and the misleading way the attorney general delivered it to the public, leaves many questions unanswered. That is why the committees of jurisdiction must continue to conduct oversight. Congressional hearings are not just grandstanding; they allow for serious testing of evidence—an essential part of constitutional oversight. Congress, and through it the American people, must question witnesses and review evidence, not for partisan reasons or political theatre, but to examine the harm done to our democratic institutions by this administration’s lack of transparency and integrity, and determine the consequences.

Our approach must be methodical, fair, and transparent—taking no options off the table. Our democracy has been tested before, but the serious implications of the Mueller report demand an appropriate response from Congress.

Given the stakes, we should not rush to impeachment. Impeachment is a process that cannot be undertaken for the benefit of one political party, nor should it be taken off the table out of fear of political fallout. It is the last and worst—but sometimes necessary—option, when other paths have failed.

Mueller’s statement that he believed he was legally prohibited from recommending criminal charges against a sitting president is an invitation to other government institutions to take action.

As Congress’s oversight continues, any attempts by the president to hinder investigations or run out the clock must be challenged. No one is above the law. While Mueller issued his report with the understanding that he could not charge a sitting president, that does not insulate the president from congressional inquiry or prosecution once his term is complete. Given the possibility of post-presidential indictments under this guidance, Congress or the courts may need to act to suspend or toll relevant statutes of limitations in the interests of justice. This moment in our history undoubtedly qualifies as an extreme circumstance.

Seldom do we look to the darkest days of our history for reassurance of our democracy’s strength. Memories of the summer of 1974 ground me in the seriousness of what we face as a country. Chief among my memories of that time are not those of a president’s fall from grace, but those of the courage displayed by the journalists who kept us informed, the diligence of the independent counsel and his team in their investigation, the unrattled moral compass of members of Congress as they followed the evidence, and the American people’s desire for information and vindication of their democracy.

This is not a time for easy answers and hashtag solutions, although our most tweetable founding father, Ben Franklin, told us that our Constitution created “a republic, if you can keep it.” The responsibility of safeguarding our democracy does not rest solely with Congress. It is a responsibility shared by all of the American people. It is my hope that as we separate facts from slogans, the American people demand no less than they deserve.



Too many guns.

Too little hope.

After each succeeding gun massacre, a dull fatalism grips the American mind. The victims of such massacres are counted in the thousands; the victims of individual murder, of suicide, and of heartrending accident by now are counted in the tens of thousands. Yet action to save lives is vetoed again and again by an implacable minority who see gun ownership as integral to their identity.

Political realists have surrendered: Nothing can be done. The gun always wins.

Yet the realists may themselves be falling out of date.

The National Rifle Association is in crisis. The corruption and self-dealing that have pervaded the organization have exploded into public view. Perhaps it is no surprise that a bad cause attracts bad people. What is a surprise is that those bad people have incurred serious legal risks, sustaining their financially troubled organization with transfers from its charitable foundation—more than $100 million since 2012. (Because the NRA engages in political activity, donations to the NRA are not tax deductible; donations to the charitable foundation are.) Such transfers are closely hemmed by law, and it does not seem that the NRA has been careful about the law.

The political map of the country is changing. The gun lobby used to be bipartisan. John Dingell, the legendary union Democrat from Michigan, served on the NRA’s board until 1994. An avid hunter, he earned an A+ rating from the lobby for many years. He helped lead Congress the NRA’s way against gun-safety proposals after the massacres at Columbine and Virginia Tech. But as the Democratic Party has become more urban—and as the NRA has veered ever more unmistakably toward white nationalism—the gun movement’s power has become tied ever more tightly to the Republican Party’s prospects. Those are seriously dimming. Democrats won more than 300 state legislative seats in 2018. They hold a majority of state attorney generalships. Republican-leaning women who used to accept NRA gun policy as part of the conservative coalition that held down their taxes have rebelled against the coalition in the age of Trump. Women are not only voting differently, but running for office in unprecedented numbers—and even fairly conservative women have zero use for the violent politics of the gun.

Hundreds of thousands of students have been through active-shooter drills—and their parents are angry about it. Only about one-third of U.S. parents now express confidence that their children are safe in school. The gun lobby may argue that the parents are overreacting, based on over-reading isolated incidents. That’s true, but it’s wonderfully ironic, since the case for guns is based on an even more radical misreading of data to mislead Americans into the false belief that guns in the house protect its dwellers.

The smartphone has challenged many of the gun culture’s most cherished illusions. Over Memorial Day weekend, a white Mississippi campsite manager drew a gun on a black couple who failed to properly register before picnicking with their dog. That encounter might once have been tallied by a gun-sympathetic social scientist as a “defensive gun use”—proving the need for firearms. In 2019, the couple bravely recorded the incident, exposing a belligerent jerk needlessly escalating an everyday misunderstanding.

As the political tide turns, the pro-gun cause turns to ever more aggressively anti-majoritarian methods. In 2018, the state of Oregon voted massively blue. It elected a Democratic governor, by a margin of more than six points of the vote. It returned a House with a Democratic supermajority of 38 to 22, and a Senate with a Democratic supermajority of 18 to 12. This spring, the lower house approved a cautious array of new gun-safety measures. The law required gun owners to store their guns safely and imposed liability on them if their guns were used in a crime; outlawed untraceable firearms; required hospitals to provide firearms-injury data to state authorities; and allowed gun retailers to voluntarily limit sales to customers over age 21. It did not restrict ownership of any weapon or weapon component. Unable to defeat the bill, Oregon Republicans walked out of the legislature, denying a quorum, until Democrats agreed to withdraw it. (Republicans also forced the withdrawal of a law ending nonmedical exemptions for vaccination.)

Such methods may score short-term victories. They represent a longer-term concession: Our cause is that of an extremist fringe. Meanwhile, groups such as Shannon Watts’s Moms Demand Action are winning actual election victories for women who have lost loved ones to gun violence.

On the morning after yet another terrible, preventable crime, the world looks bleak. For those in mourning, that bleakness will never end. Yet over the horizon, hope is glimmering. Those who have imposed this nightmare on the country are weakening. Those who reject the cult of the gun are rising. Tomorrow will be better.



Iran’s decision to shoot down an American RQ-4 Global Hawk surveillance drone brought the United States to the brink of military retaliation. Beyond their enormous diplomatic and geopolitical implications, these events have also heightened anxieties around the world over the role of autonomous systems. Could drones lead humans down a reckless path to war?

Not so fast, people. Yes, the situation in Iran is highly volatile and dangerous. And the very word drone conjures up fears of a Terminator-like dystopia. But the reality is both more complex and reassuring. Drones are unlikely to be the spark that lights the fires of war. We have humans for that.

I have spent six years studying and writing about drones. (Full disclosure: I am also a board member of Kratos Defense & Security Solutions, a company that makes military drones, though not any of the ones I’m about to mention). There are drones and there are drones. Talking about “drones” as a single type of weapon is akin to putting a kayak, a Coast Guard cutter, and a nuclear-armed submarine in the same analytic category. Sure, all three vessels travel through water, but the kayak is designed for recreation, the cutter is designed for search and rescue, and the submarine is designed for nuclear retaliation.

Similarly, some drones are used only for intelligence-gathering, some are used for lethal action, and some are used for both. The Global Hawk shot down by Iran was purely an intelligence asset. Think of it as the remotely piloted equivalent of a U-2 spy plane, whose sole purpose is collecting intelligence so that policy makers have a more accurate understanding of events on the ground. The Global Hawk is expensive, costing more than $100 million each. It has no ability to strike targets, and its only real defense is altitude. Its job, quite literally, is to stay above the fray—flying at 65,000 feet or higher to avoid enemy air defenses and staying aloft for more than 30 hours at a time to gather imagery and signals intelligence. Sending a Global Hawk is not a particularly provocative act, but shooting one down is more so, precisely because it poses no threat to human life. So why did Iran do it? Most likely Tehran was trying to send some nuanced signals, dialing tensions up just a notch but not too much, and letting American leaders know that Iran has better air defenses than they probably assumed.

Other drones are designed primarily or exclusively for lethal action. The Islamic State made low-tech lethal drones by purchasing rudimentary quadcopter hobbyist drones off the internet and strapping explosives onto them. ISIS flew so many of these buzzing quadcopter drone-bombs during the battle of Mosul that one American commander likened them to killer bees. American troops have a drone called the Switchblade, which fits into a backpack, weighs less than six pounds, can fly for just 10 minutes and 10 kilometers. It’s designed to be used in the field like a smart, longer-range hand grenade. Using or losing a Switchblade is unlikely to lead to states spiraling into conflict. If the Switchblades are coming out, chances are conflict has already arrived.

Then there are Predators and Reapers, which are used against suspected terrorists in Afghanistan, Yemen, and elsewhere. They combine persistent stare and precision strike. These drones can loiter over targets for hours, days, even weeks, closely monitoring developments and collecting intelligence—and then fire missiles when the time is right, with the push of a button. Importantly, these drones are nearly entirely defenseless, flying low and slow. With propeller motors, they’ve been likened to flying lawn mowers. That’s why they operate in uncontested air environments. Against a nation with reasonably good air defenses, Predators and Reapers don’t get far or achieve much. The risk of crisis escalation is somewhat higher with these drones because they inherently have two uses; from the enemy’s point of view, it’s impossible to know whether a Reaper or Predator is simply conducting surveillance or is about to strike. And where there’s uncertainty and ambiguity, miscalculation is more likely.

Yet even the shooting down of a Predator or Reaper is unlikely to lead the United States into war. Why? Because these drones are unmanned. This obvious fact has important consequences for crisis management.

Drones never come home in coffins. They do not have grieving families. There will be no Black Hawk Down moments in which video footage showing the death and desecration of American troops leads to anguished demands that the president do something. Because drones pose no risk to the warfighter, they remove a key emotional element that influences domestic politics and complicates crisis management.

While the U.S. and Iran trade barbs over whether the Global Hawk was flying in international or Iranian airspace, and the possibility of a broader military conflict looms, it’s important to remember that the most dangerous risks of crisis escalation still involve humans.



Julian Assange, the Australian national who founded WikiLeaks, was indicted Thursday for soliciting classified information from an American whistle-blower in 2010 and publishing sensitive military files as well as State Department cables.

Unlike his source, then–Army Private Chelsea Manning, who pledged to protect state secrets to get a security clearance, Assange had no obligation to the U.S. government, and appears to be in legal jeopardy for some actions that are virtually indistinguishable from journalism.

That Assange is not himself a journalist is irrelevant.

The charges set a precedent “that can be used to target all news organizations that hold the government accountable by publishing its secrets,” the ACLU warns, adding, “If the US can prosecute a foreign publisher for violating our secrecy laws, there’s nothing preventing China, or Russia, from doing the same.” The civil-liberties organization says the Assange case marks the first time in American history that criminal charges are being brought “against a publisher for the publication of truthful information” under the Espionage Act of 1917.

That law “draws no distinction between the leaker, the recipient of the leak, or the 100th person to redistribute, retransmit, or even retain the national-defense information that by that point is already in the public domain,” the law professor Stephen Vladeck has noted. And that is only one of the reasons it ranks as one of the most flagrantly authoritarian laws in U.S. history.

Our First Amendment declares, “Congress shall make no law … abridging the freedom of speech, or of the press.” But in 1917, Congress made just such a law, the Espionage Act, in part to abridge the freedom to speak out against World War I.

It did so at the urging of President Woodrow Wilson, who resegregated the federal government, screened The Birth of a Nation at the White House, and told Congress in his 1915 State of the Union address that American citizens “born under other flags but welcomed under our generous naturalization laws” were pouring “the poison of disloyalty into the very arteries of our national life,” necessitating a new law “by which we may be purged of their corrupt distempers.”

In Wilson’s telling, “such creatures of passion, disloyalty, and anarchy must be crushed out. They are not many, but they are infinitely malignant, and the hand of our power should close over them at once.” Once armed with the Espionage Act of 1917, the Wilson administration targeted two political activists, Charles Schenck and Elizabeth Baer, who mailed anti-war flyers to men facing conscription.

The flyers urged readers to peacefully refuse to comply with the draft by citing language in the Thirteenth Amendment that prohibits “involuntary servitude.” For that speech, the two were convicted by a jury of their peers.

They appealed to the Supreme Court, invoking their First Amendment rights. But war is the health of the state and the death of civil liberties; the Supreme Court chose to narrow rather than safeguard the First Amendment’s protections.

It ruled:

We admit that, in many places and in ordinary times, the defendants, in saying all that was said in the circular, would have been within their constitutional rights.

But the character of every act depends upon the circumstances in which it is done. The most stringent protection of free speech would not protect a man in falsely shouting fire in a theatre and causing a panic. It does not even protect a man from an injunction against uttering words that may have all the effect of force. The question in every case is whether the words used are used in such circumstances and are of such a nature as to create a clear and present danger that they will bring about the substantive evils that Congress has a right to prevent.

It is a question of proximity and degree.

When a nation is at war, many things that might be said in time of peace are such a hindrance to its effort that their utterance will not be endured so long as men fight, and that no Court could regard them as protected by any constitutional right.

America now seems permanently at war, with no immediate prospect that the hostilities that began in 2001, before the birth of some of today’s troops, will end. Manning’s leaks revealed serious wrongdoing in the War on Terror while also exposing legitimate secrets.

WikiLeaks published everything. The Obama administration considered indicting Assange, but decided against it. In a 2010 congressional hearing on amending the Espionage Act, Representative John Conyers declared, “Our country was founded on the belief that speech is sacrosanct … And so whatever one thinks about this controversy, it is clear that prosecuting WikiLeaks would raise the most fundamental questions about freedom of speech about who is a journalist and about what the public can know about the actions of their own government.”

Around the same time, Jack Goldsmith, who served in the Office of Legal Counsel during the Bush administration, advised that “trying to prosecute Assange under the Espionage Act would be a mistake. The prosecution could fail for any number of reasons (no legal violation, extradition impossible, First Amendment),” he wrote. “Trying but failing to put Assange in jail is worse than not trying at all. And succeeding will harm First Amendment press protections, make a martyr of Assange, and invite further chaotic Internet attacks. The best thing to do—I realize that this is politically impossible—would be to ignore Assange and fix the secrecy system so this does not happen again.”

A decade later, the Trump administration could have ignored Assange without abandoning efforts to protect state secrets. The legal scholar Geoffrey Stone has argued that “the solution is to reconcile the irreconcilable values of secrecy, on the one hand, and accountability, on the other, by guaranteeing both a strong authority of the government to prohibit leaks, and an expansive right of others to disseminate information to the public.” In Bartnicki v. Vopper, he noted, the Supreme Court ruled that it would be remarkable “to hold that an individual can constitutionally be punished merely for disseminating information because the government itself failed to deter conduct by a non-law abiding party.”

Yet a case that seeks to punish that very behavior is now upon us, needlessly threatening press freedoms. “Bringing charges against Assange for alleged hacking at least made sense,” Brian Barrett wrote at Wired. “Journalists would expect to be … prosecuted for similar. But the blast radius of an Espionage Act conviction against Assange would include every working national security journalist. Surely the Justice Department is aware of those implications. And that’s what makes its decision to go forward with the charges all the more unnerving.”

In fact, the administration’s move will detract from, rather than enhance, the very safety that state secrets are meant to secure.

“The security of the Nation is not at the ramparts alone. Security also lies in the value of our free institutions,” Judge Murray Gurfein observed in the Pentagon Papers case. “A cantankerous press, an obstinate press, an ubiquitous press, must be suffered by those in authority in order to preserve the even greater values of freedom of expression and the right of the people to know. These are troubled times. There is no greater safety valve for discontent and cynicism about the affairs of government than freedom of expression in any form.”

Or as Justice Hugo Black put it when the same case came before the Supreme Court: “The guarding of military and diplomatic secrets at the expense of informed representative government provides no real security for our Republic.” So it remains.

This article is part of “The Speech Wars,” a project supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press, and the Fetzer Institute.



When critics say that Joe Biden isn’t progressive enough, they’re mostly referring to his record and positions on policy. But the former vice president’s messaging is literally backward-looking. Biden is running a campaign of restoration—returning the United States to its rightful place before (as he sees it) the current president came onto the scene and trashed the joint.

“If we give Donald Trump eight years in the White House, he will forever and fundamentally alter the character of this nation,” Biden warned in his announcement video.

It’s not just that Biden’s message over the first few days of his campaign has been aimed straight at the #Resistance—though it has, even as other Democratic hopefuls have largely opted against head-on attacks on Trump. Biden is running on open nostalgia. He wants to take the country back, all the way to the dim and distant days of 2015 or so, when the Obama administration he served in ran the country and Trump was merely a punch line.

Appealing to nostalgia is a favorite play for Republican candidates. While Trump’s “Make America great again” slogan makes the return to an imagined past more explicit than most, backward-looking campaigns dovetail neatly with conservatism. But they’re a tougher sell in the Democratic Party. Even before the party’s recent leftward shift, Democratic candidates have tried to strike a balance between praising fundamental principles of the country and offering something new and innovative.

Every successful Democratic candidate of the past half century, as well as several unsuccessful ones, has embraced the idea of forward progress. John F. Kennedy sold voters on his youthful exuberance. Lyndon B. Johnson offered the Great Society. Jimmy Carter was an obscure evangelical governor from the South—about the furthest thing from Richard Nixon or Gerald Ford—who billed himself as an untainted reformer. Bill Clinton heralded a transformed, centrist Democratic Party. Barack Obama promised hope and change. Clinton offered perhaps the most eloquent and memorable formulation of this maneuver in his first inaugural address—a little old, a little new.

“Our democracy must be not only the envy of the world, but the engine of our own renewal,” he said. “There is nothing wrong with America that cannot be cured by what is right with America.”

These days, most Democratic politicians are just as eager for change but less likely to look kindly on the past. Taking a radical view, they are more likely to trace the problems in contemporary American society to long-standing fissures and failures in U.S. history, especially on race, class, and gender. In other words, they believe not that Trump “will forever and fundamentally alter the character of this nation,” but that he’s brought out dark characteristics present since its founding. This strain in present in Bernie Sanders, whose political hero Eugene V. Debs was making systemic critiques of American society a century ago, and it’s present whenever candidates talk about reparations, which are intended to respond to sins of racism that stretch back to even before the United States itself existed. These Democrats also bluntly reject the idea of returning to a golden age.

“I don’t think you can ever have an honest politics that revolves around the word again,” Mayor Pete Buttigieg has said. While Buttigieg was clearly taking a swipe at Trump’s slogan, his implication was also that Trump, while perhaps uniquely bad, is more a symptom and an accelerant of what ails America than a cause.

Biden, however, stands against this movement. Where his rivals tend to view Trump as a culmination, Biden sees him as an aberration.

“I believe history will look back on four years of this president and all he embraces as an aberrant moment in time,” he said in his campaign-announcement video. “But if we give Donald Trump eight years in the White House, he will forever and fundamentally alter the character of this nation—who we are—and I cannot stand by and watch that happen.”

If this is true, the trick is to just turn the clock back. Biden made the comparison with Trump explicit with a paraphrase on Good Morning America on Tuesday, promising to “make America moral again.” This restorationist rhetoric, far more than any particular policy idea, has dominated Biden’s first week on the trail.

This approach is quietly radical for the Democratic Party, and it puts Biden on a collision course with politicians like Buttigieg. Yet it would be almost impossible for Biden to do anything else. He can’t run as the youth candidate, and unlike Sanders—or Trump in 2016—he has no claim as an outsider. Biden’s experience is his greatest asset, even if it does seem jarring that the Obama years have so quickly passed into the realm of rose-tinted nostalgia. (And yet how far away those years seem.)

At this early stage, it’s not clear that voters object to Biden’s backwards glance. Biden was already leading the field before his official entry, and he’s seen a polling bump since. A CNN poll released Tuesday found that only one in four Democrats think it’s important that the nominee be an outsider, which is good news for Biden. Two in three think the nominee must represent the future of the Democratic Party—bad news for Biden. But by far the most important criterion for Democratic voters, with 92 percent ranking it extremely or very important, is the ability to beat Trump.

But appeal to nostalgia underscores Biden’s vulnerabilities, too. He has already come in for intense criticism over some of his past policy positions, particularly his opposition to busing to integrate schools, his handling of Anita Hill’s sexual-harassment allegations against now–Supreme Court Justice Clarence Thomas, and his role in the 1990s crime bill. Each of these harkens back to the long-standing flaws that other Democrats see in U.S. society. History is a Pandora’s box: Biden may want to turn attention to the narrow period from 2008 to 2016, but once you reopen the past, other unpleasant things fly out.

Biden hopes to ride his restoration argument to victory in the Democratic primary, but that would represent a surprising break with the party’s other recent nominees. Maybe Biden has cracked the code to 2020, or possibly he’ll discover that those who campaign on the past are doomed to repeat it.



Updated at 12:09 p.m. ET on June 5, 2019.

It was the kind of call a journalist dreams about. Last fall, a tipster contacted the Bucharest-based Rise Project to offer the investigative-journalism outfit a suitcase full of evidence that, the anonymous source assured, implicated a high-powered Romanian politician in a massive fraud. The reporters pounced.

In November, they published their initial findings on Rise’s Facebook page. The detailed report on an alleged scam involving Liviu Dragnea, then the president of Romania’s ruling Social Democratic Party, included photos, videos, screenshots of email exchanges, and other documents that Rise obtained through the clandestine suitcase exchange. Their report added to a swirl of allegations against Dragnea—whom Romania’s highest court ordered to prison last week in connection with a separate case—and further endangered his party’s grip on the country.

“The story went viral immediately,” recalled Raluca Radu, head of the journalism department at the University of Bucharest. Romania’s national media, which get middling to poor grades for independence, initially stayed away from the explosive revelations. The Rise report forced their hand. In countries where press freedoms are under strain, some of the most aggressive investigative journalism has been coming from small, digitally savvy start-ups such as Rise.

Which makes what happened next all the more alarming. Within days of publication, Romania’s Data Protection Authority, a regulator that previously played a small role in matters involving press complaints, stepped into the fray, ruling that the journalists had broken the country’s strict data-protection law in publishing their big scoop. The Romanian data-protection law is no authoritarian dictum designed to silence pesky journalists who fail to toe the party line. It’s based on the European Union’s General Data Protection Regulation, or GDPR, which had become the law of the land in Europe six months prior.

GDPR was the first major effort by lawmakers with any global clout to limit Silicon Valley’s ability to mine and monetize the personal data of unwitting internet users. Ironically, compliance with the complex law has arguably proved easier for cash-rich tech firms than for other companies—including bootstrapping media outlets with limited engineering know-how. Moreover, the deployment of GDPR against Rise reveals another significant downside: Broadly defined privacy laws can be creatively enforced, particularly in weak democracies, to conceal wrongdoing and take revenge on journalists who expose it in the public interest.

“We never expected this kind of attack, this kind of threat,” said Paul Radu (no relation to the journalism professor), a co-founder of the nonprofit Rise and a board member of the Global Investigative Journalism Network. “It created a huge stir. This was the first time that GDPR was used against journalists in Europe.”

In its enforcement letter, the Romanian authorities said that Rise journalists had violated GDPR in publishing the videos, photos, and documents—in essence, the private data of Romanian citizens—to support the reporters’ allegations against Dragnea. The letter directed them to turn over the identity of the tipster. It also ordered them to explain how they had obtained the information, how they stored it—this was the data-protection authority, after all—and whether they had in their possession further private details on Dragnea and his associates. The big blow was the penalty: a fine of up to 20 million euros ($22 million), the maximum that can be applied against a small publisher in a GDPR case, if the reporters failed to fully comply.

The Rise team had been subject to official intimidation before. The previous year, authorities opened an investigation into the group’s finances shortly after it had published a story alleging wrongdoing by public officials.

The GDPR order was a blatant attempt to “muzzle” the media, Paul Radu’s team shot back, and doing so under the new EU data-protection law was nothing more than a “serious misuse of the GDPR by self-interested politicians seeking to protect themselves.” The Rise team, Radu said, has about 10 people and an annual budget of perhaps 150,000 euros. It had few options but to call the government’s bluff and hope for the best.

When it went into effect last May, GDPR was hailed as the most significant data-protection law ever enacted. Casual internet users in the United States know GDPR as the law that, around this time last year, introduced a new layer of red tape to web surfing. If it seems that an annoyingly persistent pop-up window or disclaimer bar detailing how a site uses tracking cookies is following you around the web, it’s not your imagination. It’s probably GDPR. It’s more obnoxiously pervasive in Europe, where the law has serious teeth. European lawmakers pushed for the heightened digital protections because they believed that, in this age of hack attacks and unscrupulous data collection, the average user was due some added data and privacy protections that the marketplace had failed to deliver.

The law grants EU citizens the right to be informed about how their personal data are being used, the right to have any misuses rectified, the right to data erasure, the right to be forgotten (an EU favorite), and the right to data portability. Provisions restrict the ability of employers, law-enforcement agencies, and other entities to make life-changing decisions by computer algorithm. There are even limits on the collection of biometric data, an issue roiling several U.S. cities. Under GDPR, for example, no state or private entity can collect facial-recognition data without consent. And even then they cannot use it in bulk for the purpose of criminal profiling. GDPR, or at least portions of it, continue to influence the writing and rewriting of data-privacy laws from California to Japan that will ultimately transform our daily digital interactions. And if you want to do business in the EU, and access its 500 million consumers, you have no choice but to comply. The potential fines for violations are staggering.

In some cases, the law has clearly given average people more leverage against the tech giants. Uber drivers in Great Britain cited the data-protection law when threatening legal action against the ride-hailing company this spring; they wanted Uber to disclose the data it had on them, as a way to double-check that they weren’t being shortchanged.* And German authorities wielded GDPR to force Facebook to dial back its data-collection practice on Germans.

Nevertheless, the year-old law has played out somewhat differently in practice than its architects intended. Even though nearly 100,000 GDPR complaints have been filed so far, critics say enforcement is weak and sporadic in most countries. The Romanian government’s moves against Rise come despite GDPR provisions meant to protect free speech and the public’s right to know.

The Rise journalists remain in limbo. European parliamentarians in Brussels have criticized the case against the Rise Project and disputed the Romanian interpretation of GDPR enforcement. But, Rise’s Radu and various civil-society groups complain, no EU authority has formally intervened on the journalists’ behalf. The impasse has heightened fears that governments hostile to the press will weaponize GDPR and similar measures around the world.

“At first, the GDPR was seen as a gift to investigative journalists” in Romania, said Raluca Radu, the Romanian journalism professor, but now there are doubts. “If the authorities, the politicians, think they can use GDPR when other legislation cannot help them personally,” this will have a chilling effect on the media. “I mean, 20 million euros. That’s a lot!”

Yet even when vengeful officials aren’t targeting media companies under the guise of privacy, laws like GDPR still impose a burden. European small businesses with any kind of web presence grumble about the expense of adding further measures to protect the data of customers, employees, and even any visitors that happen to venture onto their websites. (A small, Rome-based NGO with no customers whatsoever had to shell out 15,000 euros to become GDPR-compliant last year. “But it’s done with,” the director told me. “We’re up to date now.”)

But ad networks and the publishers who collect revenue from them are among those most put off by the EU law. As GDPR went into effect a year ago—on May 25, 2018—hundreds of American news outlets, including the Chicago Tribune and others owned by Tribune Publishing, decided that rather than go GDPR-complaint, they would simply block anyone coming to their sites from Europe. It stands as one of the largest-ever news blackouts in the Western world, and it’s still going on a year later. For Cubs and Bears fans marooned in Europe, the data-privacy rule has made it far more difficult to get decent back-home coverage of their beloved teams. When news outlets as large and as storied as the Tribune and its corporate siblings, such as The Baltimore Sun and the New York Daily News, feel obliged to bar European visitors from their websites, it’s evidence of how ambitious data-privacy rules could reshape the news industry if they spread.

To the extent that Americans come across as more laissez-faire on electronic privacy, that may have as much to do with give-away-the-keys convenience as it does with any particular zeal for the First Amendment. But in the wake of the Cambridge Analytica–Facebook data-breach scandal and other revelations about the tech industry’s collection of users’ personal information, a patchwork of data-protection laws is cropping up. The most significant is the California Consumer Privacy Act, which was born out of a ballot initiative last year. Scheduled to go into effect next year, the act borrows elements from GDPR, such as the right to have your personal data deleted and the right to know how it’s being used. It’s viewed as a fundamental transformation—a more European one, even—in America’s policy on privacy protection.

“From a practical standpoint, the California law will become the law of the land,” predicts Joseph Jerome, a privacy-policy counsel for the Center for Democracy & Technology, a digital-rights advocacy group. For a company with an online presence, “it doesn’t make a whole lot of sense to provide [protections] just to California residents. And I think you’d have some really horrible PR messaging for those companies that don’t want to offer those rights outside of California.” (To wit, a Tribune Publishing spokeswoman said the company intends to fully comply with the California measure from day one; the company is no closer to easing its GDPR blackout, however.)

No matter how much news executives might fret about the burdens of GDPR, laws like it are steadily becoming the new global standard—not because lawmakers are pushing it, but, as Jerome notes, because consumers are. “Take back control of your personal information,” supporters of the ballot initiative urged California voters in the successful campaign.

Radu at Rise applauds such a people-first sentiment, as long as it doesn’t interfere with his job. “We work with a lot of programmers. Privacy, to us, is something that has to be upheld. It’s too important. But exposing wrongdoing is equally important,” he says. “There needs to be a balance there.” How best to strike that balance between privacy protection and free speech remains the enduring question.

* An earlier version of this article incorrectly described the status of British drivers’ dispute with Uber. They sent a pre-action legal letter, but a formal lawsuit has not been filed.

This article is part of “The Speech Wars,” a project supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press, and the Fetzer Institute.



Recounting how he met his husband via an online dating app, the Democratic presidential candidate Pete Buttigieg made light of his sexual prudence. “Possibly not the app you’re thinking of,” he quipped earlier this month before an extremely friendly audience assembled by the Gay and Lesbian Victory Fund, a clear reference to the gay hookup app Grindr. (Buttigieg met his future husband, Chasten, who has improbably emerged as the most intriguing and popular campaign spouse, on Hinge, which is more oriented to long-term relationships.) In his best-selling memoir, Shortest Way Home, Buttigieg writes, “Other than the same-sex aspect, our first date was something our parents could have recognized as typical, almost vintage.” The happy couple own a home, have two dogs, and speak frequently of their desire to have children. There is no hint that their relationship is anything other than monogamous.

Buttigieg is a model of conventional, bourgeois gay domesticity, and one who frequently quotes Christian scripture unironically. The heterosexual president whom Buttigieg hopes to defeat (and our self-proclaimed “moral majority” hypocritically supports) has been married three times, bribed a porn star to prevent her from publicizing allegations of adulterous peccadilloes, been accused by multiple women of sexual assault, bragged obscenely on tape about molesting women, joked about dating his daughter, and once boasted that avoiding STDs was his “personal Vietnam.”

That an openly gay politician can convincingly portray himself as more virtuous than a straight opponent attests to more than just the character of the current president. It shows how dramatically the country’s perception of homosexuality has changed.

For most of American history, gay people have been criminalized, pathologized, and religiously condemned; gay sexual expression was relegated to public parks, toilets, and bathhouses. Gay gathering places were routinely surveilled and raided by law enforcement; this June marks the 50th anniversary of the historic Stonewall uprising, when a group of patrons at a Greenwich Village gay bar fought back against police harassment. Even those who begrudgingly tolerated gays associated them with an inherent promiscuity unbefitting true and equal citizenship. (“Gay marriage will destroy the institution of homosexuality” went one joke.)

By embracing traditional family and sexual norms, a route made officially available to him by the Supreme Court’s 2015 Obergefell v. Hodges decision legalizing same-sex marriage, Buttigieg is radically upending popular expectations of what a gay politician can be. The South Bend, Indiana mayor has made much of the fact that he is the first Millennial to run for president. He is also the first post-Obergefell  candidate.

As Buttigieg has remarked repeatedly on the campaign trail, an earlier version of his highly qualified self (Harvard graduate, Rhodes Scholar, military veteran) would never have had a shot at the presidency. For previous generations of gay politicians, sexual orientation imposed a ceiling on their career advancement. When Representative Barney Frank of Massachusetts came out of the closet to Speaker Tip O’Neill in 1986, the plain-speaking Boston pol replied, “I’m sorry to hear it. I thought you might become the first Jewish speaker.”

In his memoir Stranger Among Friends, the gay activist David Mixner described his decades-long friendship with Bill Clinton, whose life paralleled his own. “The President and I were born three days apart. We both dreamed of serving our country,” Mixner wrote. “There was one difference. He could pursue his dreams while I felt I could not. Bill Clinton was born straight and I was born gay.” For Sean Strub, a gay activist who eventually did make a failed run for Congress in 1990, it was the very act of gay sex that instilled a sense that public office would forever be off-limits. “When I started sleeping with men, one of the most sort of salient truths that I embraced about that was that I couldn’t run for office,” he recalled in an unpublished, 1994 interview with the late New York Times reporter Dudley Clendinen.

Until very recently, a cloud of scandal and questionable sexual ethics hovered over the gay male politician, a function of society’s illegalization and stigmatization of homosexuality. Gay men are hardly more predisposed to sexual impropriety than their hetero peers, but as long as same-sex desire was driven underground, it was all but inevitable that gay men’s political careers would lurch toward some form of humiliation.

Gerry Studds, Frank’s former colleague in the Massachusetts congressional delegation, became the first congressman to publicly identify as homosexual after he was outed for having a consensual affair with a 17-year-old male page. Frank himself would later be forced to weather scandal when it emerged that he allowed a male prostitute to operate out of his apartment. Jeremy Thorpe, the former leader of the British Liberal Party and a man once tipped to be prime minister, was charged with arranging for his alleged male lover to be assassinated rather than risk exposure as a homosexual. (Thorpe was acquitted of the charges; the saga was brilliantly retold in last year’s BBC docudrama A Very English Scandal, starring Hugh Grant as the devious and cunning Thorpe.)

On the 50th anniversary of Stonewall, Buttigieg represents a long-overdue liberation from this repressive past. That he speaks of his gayness with nonchalance—as “just a fact of life, like having brown hair, and part of who I am”—has engendered critics from both the religious right and the intersectional left, each of whom has a problem with the way Buttigieg expresses his sexual orientation: The former take issue with the very fact of it, while the latter don’t consider him gay enough. For social conservatives who believe that a gay person, simply by dint of his sexual orientation, is unfit to hold the nation’s highest office, Buttigieg has the potential to change hearts and minds in much the same way Barack Obama could with respect to race. As for those who take umbrage at Buttigieg’s “assimilationist perspective,” I hate to be the one to break it that the first president from the LGBT community is likelier to be a cisgender, white gay man from a red state who looks like a middle manager at a paper company than a transgender woman of color from the Tenderloin.

The fact that a gay politician can say of a straight one, with absolute plausibility, “It is hard to look at this president’s actions and believe that they’re the actions of somebody who believes in God” is not just a sign that the religious left is successfully fighting the religious right on its own rhetorical turf. It indicates that gays are finally beginning to play on equal political ground with straights. Pete Buttigieg offers his country double relief: He has the potential to deliver us from a scandal-plagued presidency and, by doing so, transform the relationship between gay and straight America for the better.





Subscribe to Radio Atlantic: Apple Podcasts | Spotify | Stitcher | Google Play

Privacy is now the most important idea on the internet—so what exactly is it? And if we care about our privacy, why aren’t we willing to pay to keep it?
This week’s Radio Atlantic is a preview of the new season of Crazy/Genius, The Atlantic’s podcast about technology and culture. The staff writer Derek Thompson joins Isaac Dovere to discuss Season 3, which kicks off with an episode about privacy.

Subscribe to Crazy/Genius: Apple Podcasts | Spotify | Stitcher | Google Play

Listen for:

The history of privacy—how an explosion in communications technologies in the late 19th century suddenly brought people into our personal space

Why the reporter Julia Angwin thinks the best way to describe the problem isn’t privacy, but data pollution

What the costs (and solutions) are for our current system, according to Shoshana Zuboff, the author of The Age of Surveillance Capitalism



Updated at 10:51 a.m. ET on May 20, 2019.

On Friday, Representative Rashida Tlaib was attacked by President Donald Trump for a “horrible and highly insensitive statement on the Holocaust” and for having “tremendous hatred of … the Jewish people.” Trump’s off-base attack distracted from the actual problems with Tlaib’s account of the Arab-Israeli conflict, in which she deployed deliberately imprecise language, misleading her listeners about the early history of the conflict in Palestine and misrepresenting its present and possible future.

Tlaib told the hosts of the Yahoo News podcast Skullduggery that when she remembers the Holocaust, it has a “calming” effect on her to think that “it was my ancestors, Palestinians, who lost their land, and some lost their lives, their livelihood, their human dignity; their existence in some ways had been wiped out … all of it was in the name of trying to create a safe haven for Jews, post the Holocaust, post the tragedy and horrific persecution of Jews across the world at that time.” She was, she said, “humbled by the fact that it was [my Palestinian] ancestors that had to suffer for that to happen.”

But the historical reality was quite different from what Tlaib described: The Palestinians indirectly, and in some ways directly, aided in the destruction of European Jewry.

After Hitler’s accession to power in Germany in 1933, German and then Eastern European Jews sought escape and safe havens. But all the Western countries, including the United States and Britain and its dominions, closed their doors to significant Jewish immigration. Palestine emerged as the only potential safe haven. In 1932, the British allowed 9,500 Jews to immigrate to Palestine. In 1933, the number shot up to 30,000, and in 1935, it peaked at 62,000.

But from 1933 onward, Palestine’s Arabs—led by the cleric Muhammad Haj Amin al-Husseini, the grand mufti of Jerusalem—mounted a strident campaign to pressure the British, who governed Palestine, to bar all Jews from entering the country. To press home their demand, in 1936 they launched an anti-British and anti-Zionist rebellion that lasted three years. Apart from throwing out the British, the rebellion’s aim was to coerce London into halting all Jewish entry into Palestine.

Moreover, the anti-Jewish violence, which claimed the lives of hundreds of Jews and wounded many more, itself served to deter would-be emigrants from seeking to move to Palestine. British entry certificates for Jews to Palestine declined to 30,000 in 1936, 10,000 in 1937, and 15,000 in 1938. Those who couldn’t get in were left stranded in Germany, Poland, Hungary, and elsewhere. Almost all died in the Holocaust, which the Germans unleashed in 1941.

But the Palestinians’ contribution to the Holocaust was also more direct. Husseini, having fled Palestine during the revolt, helped pro-Nazi generals launch an anti-British rebellion in Iraq in 1941 (which itself engendered a large-scale pogrom against Baghdad’s Jews, the Farhoud). When that rebellion failed, he fled to Berlin, where he was given a villa and a generous monthly salary, and lived in comfort until the end of the world war. During the war, he helped recruit Muslims from the Balkans for the German army and the SS, and in radio broadcasts exhorted Middle Eastern and North African Arabs to launch jihad against the British and “kill the Jews.” (The texts of Husseini’s broadcasts appear in the historian Jeffrey Herf’s book Nazi Propaganda for the Arab World.*)

Subsequently, Husseini fled Germany and, with the Allies reluctant to trigger Arab anger by trying him for collaboration, settled down in Cairo. In 1947, he rejected the UN partition plan to settle the Palestine conflict and helped launch the first Palestinian and pan-Arab war against the Zionist enterprise. He spent his last years in Lebanon, embittered by the loss of Palestine and the pan-Arab failure to effectively support the Palestinians, and published a series of anti-Semitic articles before his death in 1974.

The most prominent Palestinian American intellectual, Edward Said, toward the end of his life enjoined the Palestinians to study the Holocaust and empathize with what had happened to the Jews, if only to properly understand the deep-seated fears and aspirations of the Israelis. It would seem that Tlaib has forsworn such an effort.

Tlaib’s podcast promulgates two basic fallacies about the more recent past and the present: first, that the Palestinian struggle is akin to the black-American struggle against white oppression and discrimination, and second, that the sole responsibility for failing to reach a two-state solution to the Palestine conflict lies with Israel.

The Zionist-Palestinian struggle has always been a political (and, lately, also a religious) struggle between two national movements over a piece of territory. Since the start of the struggle, both sides have claimed “Palestine,” the area between the Jordan River and the Mediterranean Sea, as theirs. So far, the Israeli side has prevailed. In two bouts of warfare, in 1948 and 1967, the State of Israel defeated the Arabs and gained control, in stages, over the territory between the Jordan and the Mediterranean.

Particularly in the wake of the 1967 takeover of the West Bank, East Jerusalem, and the Gaza Strip, the Israeli side has oppressed the Palestinian inhabitants and denied them various civil rights. Such is the nature of military occupation. But the struggle between the two sides—in which most Palestinians still hope for Israel’s disappearance and to take over all of Palestine—is not in essence akin to the civil-rights movement in the United States, as Tlaib would have her listeners believe. (And if the Palestinian Arabs ultimately triumph, there is no reason to believe that the equality and justice they would mete out to the minorities they would govern would be any different from that meted out to minorities governed by the neighboring Arab Muslim states.)

To this must be added one further observation: The Zionist side over the decades has repeatedly agreed to a compromise based on partitioning Palestine into two states, one for the Jews, the other for the Arabs—and, just as repeatedly, the Arab side has always rejected the two-state compromise formulas that have been proposed. So it was when the British Peel Commission proposed partition in 1937; so it was when the UN General Assembly proposed partition in November 1947; so it was when Israeli Prime Minister Ehud Barak and President Bill Clinton proposed partition (a two-state solution) in 2000; and so it was when Israeli Prime Minister Ehud Olmert proposed partition to Mahmoud Abbas, the president of the Palestinian Authority, in 2007–08. At each point in time, the Palestinian leader—Husseini, Yasser Arafat, Abbas—rejected the two-state offers and partition (as, consistently, has Hamas, the most powerful and popular of the Palestinian political factions). But Tlaib is right in saying that Israel’s current leader, Prime Minister Benjamin Netanyahu, despite occasional lip service to the two-state idea, is opposed to a compromise solution based on a real partition.

As to the future, Tlaib argues that, since Netanyahu opposes a two-state solution, what must be hoped for and reached is a one-state solution, meaning a jointly ruled binational Arab-Jewish state. A handful of Palestinian-Jewish intellectuals advocated such a solution from the 1920s to the 1940s, including Martin Buber and Judah Leib Magnes. But it failed to gain much traction among the Jews (they wanted a “Jewish state,” if only in part of Palestine) and gained no traction at all among Palestine’s Arabs (who demanded all of Palestine, not an inch for the Jews).

Today, the prospect of such a binational state emerging is even more remote: Neither people wants a binational state, especially after more than a century of mutual bloodletting and warfare. The anger and suspicions are too deep for the two peoples to live in amity intermixed in a single state—however much café-goers in London and Paris (and, apparently, Detroit) may dream about the viability of such a denouement. Any attempt to achieve such a solution, especially when coupled with the essential Palestinian demand—which Tlaib supports—to allow a mass return of refugees to the homes they lost in 1948 and 1967 (which were destroyed or are now home to Jews), would end in anarchy and a protracted bloodbath.

Tlaib may say she comes “from a place of love and equality and justice,” but these are empty words intended to rope in dupes and the ignorant. Perhaps in her prospective trip to the West Bank with the Humpty Dumpty Institute, which she announced on the podcast, she can try them out on the people who actually live in the area. We’ll see what happens.

* This article originally misidentified the book in which the texts of Muhammad Haj Amin al-Husseini’s broadcasts appear.



“A government that roams the land, tearing down monuments with religious symbolism and scrubbing away any reference to the divine,” Justice Samuel Alito warned the nation yesterday, “will strike many as aggressively hostile to religion.” Luckily, he wrote, the Supreme Court will spare the nation the spectacle of such a secular juggernaut by allowing the state of Maryland to maintain the 94-year-old, 32-foot-high “Peace Cross” on a pedestal high atop a busy intersection near Bladensburg, Maryland.

The case—American Legion v. American Humanist Association—produced a five-justice plurality for what appears to be a rather thin rule. What the Court decided is hard to discern. To understand why, read this portion of the syllabus:

ALITO, J., announced the judgment of the Court and delivered the opinion of the Court with respect to Parts I, II–B , II–C , III, and IV , in which ROBERTS, C. J., and BREYER, KAGAN, and KAVANAUGH, JJ., joined, and an opinion with respect to Parts II–A and II–D, in which ROBERTS, C. J., and BREYER and KAVANAUGH, JJ., joined. BREYER, J., filed a concurring opinion, in which KAGAN, J., joined. KAVANAUGH, J., filed a concurring opinion. KAGAN, J., filed an opinion concurring in part. THOMAS, J., filed an opinion concurring in the judgment. GORSUCH, J., filed an opinion concurring in the judgment, in which THOMAS, J., joined. GINS BURG, J., filed a dissenting opinion, in which SOTOMAYOR, J., joined.

For those scoring at home, that’s Cross 7, Humanists 2—but the seven are divided among at least four and maybe five different views of how a case like this should be decided. At a minimum, the divided lineup indicates that both the high court and the lower courts will continue to struggle with public-religion cases of all kinds.

By way of background, the Peace Cross was erected by private groups in 1925 as a memorial to the 49 citizens of Prince George’s County, Maryland, who died in World War I. The state took ownership of the site more than half a century ago and has maintained it with public funds ever since. Over the years, its location—at an intersection of the National Defense Highway that connects Washington, D.C., to Annapolis, Maryland—has become a busy suburban crossroads.

In 2012, the American Humanist Society brought a challenge to the Peace Cross on behalf of a group of its local members, non-Christians who were required to live and commute near this massive Christian symbol. The U.S. Court of Appeals for the Fourth Circuit, applying Supreme Court Establishment Clause precedent, held that the monument constituted an “establishment of religion” and was thus forbidden by the First Amendment.

The Supreme Court on Thursday reversed. One wishing to carry away a principle from the jumble of opinions would be reduced to this: If a monument has been up long enough to have taken on some other meaning than a religious one, it’s probably a bit much to ask people to pull it down (see Alito’s image of Godless-zilla rampaging across the landscape). The Latin cross in question, Alito writes, has become a symbol of sacrifice—not in general, but specifically in the context of World War I, as exemplified in the famous poem by John McCrae, which begins,

In Flanders fields, the poppies grow

Between the crosses, row on row. 

So a venerable monument like the Peace Cross can stay. If a monument is newer, then—ask again later.

The problem bedeviling the justices is the persistence of what is called the Lemon test, derived from a 1970 religious-school-subsidy case, Lemon v. Kurtzman. This test asks whether the law (1) has a “secular purpose”; (2) a “primary effect” that advances or retards religion; and (3) the effect of creating “excessive entanglement” between Church and state. Got it? It’s great except nobody really understands it and pretty much everybody hates it. Alito wants to get rid of it and permit “categories of monuments, symbols and practices with a longstanding history” so long as they follow an American tradition of “respect and tolerance for differing views, an honest endeavor to achieve inclusivity and nondiscrimination, and a recognition of the important role that religion plays in the lives of many Americans.” Sounds great except for two things: First, what does it mean? And second, this part of the opinion didn’t get five votes. Justice Elena Kagan peeled off, expressing a concern that a general rule invoking “history” is too broad.

Here is my quick assessment of the positions. Four—Alito, Chief Justice John Roberts, and Justices Stephen Breyer and Brett Kavanaugh—have had it with Lemon and wish to emphasize history. For Breyer, though, “history” mostly means how long a monument has been up: “A new memorial, erected under different circumstances, would not necessarily be permissible under this approach.” Kavanaugh, by contrast, wants to look at whether a monument is “rooted” in history and tradition—a test he suggests would allow newer (even, I suspect, brand-new) structures as well as old ones like the Peace Cross. Kagan wants to hold on to parts of Lemon and judge monuments case by case.

Justice Neil Gorsuch suggested the problem could be solved by eliminating the right of people like AHA members to sue at all. In his view, taxpayers who don’t want their tax dollars used for religious purposes should have to suck it up. Unless the government is forcing you to pray or withholding a job or benefit on religious grounds, you have no case.

Justice Clarence Thomas wrote separately to say that the Establishment Clause shouldn’t apply to the states at all. He has taken this position before; in addition, he also endorsed Gorsuch’s rules.

Finally, Justice Ruth Bader Ginsburg (joined by Justice Sonia Sotomayor) wrote an impassioned old-fashioned separationist dissent. Two thousand years of history have not wiped away the Christian symbolism of the cross, she wrote, and the majority’s suggestion that 95 years have done that to the Bladensburg cross is spurious. “An exclusively Christian symbol, the Latin cross is not emblematic of any other faith,” she wrote. Quoting an earlier dissent by retired Justice John Paul Stevens, she added, “‘Making a … Latin cross a war memorial does not make the cross secular,’ it ‘makes the war memorial sectarian.’”

As Ginsburg pointed out, there would be no need to destroy the cross—it could be moved to private land; but no matter the outcome, precisely because the symbolism is so powerful, somebody loses in each such dispute, and loses big. Breyer and Kagan seem to be striving to forge a durable center on this issue, allying with Roberts and Alito. If the effort fails, or the Court changes, Thomas, Gorsuch, and Kavanaugh seem ready to enact much more sweeping limits on the Establishment Clause.



Updated at 10:08 a.m. ET on June 2, 2019.

Democratic and Republican politicians agree on one thing about President Donald Trump’s tax returns: The Constitution determines who can see them. Democrats such as Representative David Cicilline insist that Congress needs access to fulfill its “constitutional responsibilities of oversight” and evaluate possible violations of the Constitution’s emoluments clauses. Republicans such as Representative Bradley Byrne insist that the House Ways and Means Committee’s request for the returns raises “questions of grave constitutional significance.” According to Republican Senator Chuck Grassley, the request goes beyond what the Framers of the Constitution “had in mind” when they “created Article I.”

Statements such as these illustrate something important about how the Constitution figures in public life. Elected officials from both parties appeal routinely to the nation’s foundational document. But, far from serving as a symbol of “unity and common purpose,” the Constitution has come to enable, or even exacerbate, partisan strife. In political debates such as the Trump tax tussle, it often feels as if the United States has two legal charters, one for Republicans and another for Democrats.

That’s not just an anecdotal impression. The tools of computational analysis shed light on how wide the chasm has grown.

The three of us recently examined the evolution of constitutional rhetoric on the floor of Congress from 1873 to 2016. We first identified the hundreds of thousands of remarks that referred to the Constitution. We then trained a machine-learning classifier to predict—based solely on the content of the remarks—whether Republicans or Democrats were speaking. If the algorithm finds this task hard to do, it implies that the parties are apt to talk in similar or overlapping ways. By contrast, if the algorithm performs this task with a high degree of accuracy, it implies that the parties are largely talking past each other.

The results are sobering. Since around 1980, it has become increasingly easy for an algorithm to predict whether any given constitutional remark was made by a Republican or a Democrat. It has likewise become increasingly easy to predict whether the speaker was a conservative or a liberal. By the time Trump took office, the machine was guessing right roughly 80 percent of the time, an all-time high by historic standards.

This result holds up across multiple machine-learning classifiers, multiple measures of algorithmic accuracy, and multiple criteria for what counts as a constitutional remark. Additional tests of the “disjointness” between the parties’ rhetoric point to the same conclusion: To an unprecedented extent, Republican and Democratic members of Congress no longer speak the same constitutional language.

Underlying this polarization of constitutional discourse, we further found, are competing constitutional vocabularies. Terms dating back to the ratification of the original Constitution in the late 1700s have become relatively associated with the Republican Party. For instance, today’s conservatives are more likely to use the phrase Founding Fathers and cite textual provisions such as the First, Second, and Tenth Amendments, emphasizing themes of individual liberty and the autonomy of the states.

Terms from or about the Reconstruction Amendments of 1865–70, on the other hand, have become relatively associated with the Democratic Party. Democrats are more likely to deploy the phrases civil rights and voting rights in particular, emphasizing themes of equality and federal authority. The perennial tension in constitutional law “between the values of the Founding and the values of Reconstruction,” as the law professor Kermit Roosevelt has described it, is today a highly partisan struggle.

Even more so than the fight over Trump’s tax returns, the ongoing debate over a high-profile Democratic electoral-reform bill shows how this struggle plays out. After House Democrats introduced H.R. 1 in January, Republicans insisted that the bill would “limit Americans’ First Amendment right to political speech” (Senator Mitch McConnell), encroach on “the liberties and powers of the Constitution reserved for the states and the people” (Representative Jeff Duncan), and undermine “the original intent of the Founders” (Representative Barry Loudermilk). Democrats countered that the bill would provide crucial protections for the “constitutional right to vote” (Representative Sheila Jackson Lee) and help redeem “a Constitution that was flawed” at its inception “by not recognizing the full equality of every American” (Senator Jeff Merkley).

As these remarks reflect, members of each party follow a certain constitutional script. The details change, depending on the issue. The broad interpretative themes, and ideological fault lines, stay the same.

Instead of transcending preexisting political divides, arguments framed in constitutional terms thus tend to mirror or magnify those divides. Since 1980, discourse about the Constitution has polarized at least as rapidly as discourse about other matters—on most measures, even more rapidly. Any number of legal thinkers have imagined the Constitution as supplying a kind of cultural glue that disciplines disagreement and tempers partisan passions. At least in recent decades, our findings suggest something closer to the opposite.

The two sides also rely on constitutional arguments to different degrees over time. During the 1960s and early 1970s, Democratic legislators invoked their preferred constitutional clauses and tropes far more often than Republican legislators invoked theirs. By the turn of the millennium, the situation had flipped. Of the 50 constitutional terms that were most strongly owned by one of the parties under President Barack Obama, fully three-quarters—from freedom of speech to bear arms to commander in chief—belonged to Republicans. Democrats may have dominated constitutional discourse in the Capitol at the height of the civil-rights movement, but Republicans have caught up, and then some. Although it is hard to measure the impact of such a rhetorical reversal, qualitative evidence suggests it has emboldened a variety of actors in the GOP coalition, including judges, and contributed to the growing use of hardball tactics on the right.

This confronts Democrats with a choice. One option is to accept the asymmetry and continue to emphasize nonconstitutional narratives. Yet insofar as the Constitution really is America’s civil religion, future Democrats who wish to enact transformative legislative programs may need to develop a more robust “higher law” language with which to make their case. The alternative is not just constitutional polarization, but constitutional marginalization—and the kinds of political setbacks that you don’t need a computer algorithm to track.



Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

A new study, called “The Perception Gap,” helps provide an answer. More In Common, an advocacy organization devoted to countering extremism that previously published a viral report on America’s Hidden Tribes, set out to understand how political partisans see each other. Researchers asked Democrats to guess how Republicans would answer a range of political questions—and vice versa. (The survey was conducted among a sample of 2,100 US adults the week immediately following the 2018 midterm elections.) What they found is fascinating:  Americans’ mental image of the “other side” is a caricature.

According to the Democratic caricature, most Republicans stridently oppose immigration, hold deeply prejudiced views about religious minorities, and are blind to the existence of racism or sexism. Asked to guess what share of Republicans believe that immigration can strengthen America so long as it is “properly controlled,” for example, Democrats estimated about half; actually, nearly nine in ten agreed with this sentiment.

Democrats also estimated that four in ten Republicans believe that “many Muslims are good Americans,” and that only half recognize that “racism still exists in America.” In reality, those figures were two-thirds and four in five.

Unsurprisingly, Republicans are also prone to caricature Democrats. For example, Republicans approximated that only about half of Democrats are “proud to be American” despite the country’s problems. Actually, over four in five Democrats said they are. Similarly, Republicans guessed that fewer than four in ten Democrats reject the idea of open borders. Actually, seven in ten said they do.

If the reasons for mutual hatred are rooted as much in mutual misunderstanding as in genuine differences of values, that suggests Americans’ divisions should in principle be easy to remedy. It’s all just a matter of education.

Unfortunately, the Perception Gap study suggests that neither the media nor the universities are likely to remedy Americans’ inability to hear each other: It found that the best educated and most politically interested Americans are more likely to vilify their political adversaries than their less educated, less tuned-in peers.

Americans who rarely or never follow the news are surprisingly good at estimating the views of people with whom they disagree. On average, they misjudge the preferences of political adversaries by less than ten percent. Those who follow the news most of the time, by contrast, are terrible at understanding their adversaries. On average, they believe that the share of their political adversaries who endorse extreme views is about 30 percent higher than it is in reality.

Perhaps because institutions of higher learning tend to be dominated by liberals, Republicans who have gone to college are not more likely to caricature their ideological adversaries than those who dropped out of high school. But among Democrats, education seems to make the problem much worse. Democrats who have a high school degree suffer from a greater perception gap than those who don’t. Democrats who went to college harbor greater misunderstandings than those who didn’t. And those with a postgrad degree have a way more skewed view of Republicans than anybody else.

It is deeply worrying that Americans now have so little understanding of their political adversaries. It is downright disturbing that the very institutions that ought to help us become better informed may actually be deepening our mutual incomprehension.



Special Counsel Robert Mueller wishes that you’d read his report. He’s not angry; he’s just disappointed.

When the Department of Justice announced Mueller’s press conference Wednesday morning, the media exploded in a frenzy of wild speculation. What new evidence might he reveal? Would he endorse impeachment? Would he complain about the administration’s response to his report? No, he would not. Nobody who has paid attention to Mueller’s pattern of behavior expected him to do anything of the sort. Instead, Mueller assumed the pained tones of a teacher who must read the instructions to the class again. The answers to all of our questions, he intoned repeatedly, are in his report.

Mueller characterized Wednesday’s appearance as merely an opportunity to summarize what he had done on the occasion of the formal conclusion of his investigation and his return to private life. But even if he did not explicitly set out to quell rumors and conspiracy theories, his calm recitation ought to have that effect. (Whether it will is another matter.)

Notably, Mueller undermined a scandalous book before it could even reach the shelves. This week The Guardian reported that in his forthcoming tell-all, Siege, Michael Wolff claims that Mueller’s office drafted an obstruction-of-justice indictment against President Donald Trump. Mueller, Wolff claims, wrestled with the question of whether it’s permissible to indict a sitting president. But Mueller unequivocally refuted that accusation today without even mentioning it. He repeated what he wrote in his report: He views the Department of Justice policy against indicting a sitting president as binding, and believes that was “not an option we could consider.” That’s no surprise. Federal prosecutors decide to indict and then draft the indictment, not the other way around. Wolff’s story was never credible.

Mueller elaborated that since he could not indict the president, and because there was no other mechanism for the executive branch to accuse him of a crime, it was inappropriate to offer a conclusion about whether or not Trump obstructed justice. This, too, was straight from his report. The only glimmer of a new idea today was Mueller’s comment that indicting a sitting president is unconstitutional. It was not clear whether he was simply stating the Department of Justice position or endorsing it, but for a rule-follower like Mueller, that’s a distinction without a difference.

The now ex–special counsel also disappointed anyone hoping to hear kvetching about Attorney General William Barr. We know that Mueller expressed his concerns to Barr in March about Barr’s initial summary, which Mueller suggested did not adequately capture the report’s substance. But Mueller refrained from criticizing Barr, noting that he did not question Barr’s “good faith” in how he went about the process. This was not a surprise either. Barr has sounded more and more like a Trump partisan since he released the Mueller report, but he followed the rules when he received, evaluated, minimally redacted, and eventually released it.

Wednesday’s press conference was consistent with Mueller’s image as a classic just-the-facts-ma’am G-man, a persona that frustrates anti-Trump partisans who dreamed of him as an avenging superhero. But a bit of passion shone through in two areas.

First, Mueller was adamant that his team had not exonerated the president of obstruction of justice. “If we had had confidence that the president clearly did not commit a crime, we would have said so,” he said rather sternly. Mueller also implicitly rebuked those who dismiss obstruction as a mere “process crime” unworthy of attention, saying that it “strikes at the core of the government’s effort to find the truth and hold wrongdoers accountable.” If he hoped this notion would take root in the Trump administration, it was in vain; Trump immediately claimed that Mueller found insufficient evidence of obstruction.

Second, Mueller seemed concerned that Americans have focused on what Trump did rather than on what Russia did. He described his conclusions about overt Russian interference in the 2016 elections, and closed by repeating that “there were multiple, systematic efforts to interfere in our election and that allegation deserves the attention of every American.” Mueller’s frustration is justified: Russia’s aggressive misconduct seems to have been lost in the shuffle.

Mueller is a man out of time. This is the age of alternatively factual tweets and sound bites; he’s a by-the-book throwback who expects Americans to read and absorb carefully worded 400-page reports. Has he met us? His high standards sometimes manifest as touching naïveté. “I hope and expect this to be the only time that I will speak to you in this manner,” Mueller said today, explaining that his report was his testimony and that Congress should not expect him to answer questions with any new information.

If he thinks that reprimand will deter Congress , he doesn’t grasp why Congress would summon him to testify. Our representatives don’t need the answers as much as they need to be seen on camera asking the questions. The rough beast of 2020 slouches toward us. Names can be made, primaries won and lost, and profiles elevated by those questions, whether they support Trump or condemn him. Washington is no place for a rule-follower.



In 1969, Denver began busing a small contingent of black children across town to a better-resourced white elementary school. “Every morning, we were loaded up on Bus No. 13,” Robert F. Smith told Morehouse College graduates the other weekend, before announcing that he’d pay off all their student loans.

Black parents had been complaining for years about Denver’s black schools having the oldest books and the most inexperienced teachers. But white northerners and westerners resisted busing in the 1960s and ’70s as massively as white southerners resisted the Brown v. Board of Education decision in the 1950s. Arsonists firebombed a local activist’s home and nearly one-third of Denver’s school buses in February 1970. But the terror did not stop Smith’s parents from loading him up on Bus No. 13 every day from the first to the fifth grades.

“Those five years drastically changed the trajectory of my life,” Smith concluded, comparing the successes of the black kids from his community who rode the bus with those of the kids who did not. And Smith’s life trajectory has been meteoric. He founded and led America’s best-performing private-equity firm, became the wealthiest African American, and emerged as one of the transcendent philanthropists of our time. And yet, he added, “the window closed for others just as fast as it had opened for me.”

Lost in all the shocked, critical, and jubilant responses to Smith’s historic gift to Morehouse, lost in all the serious debates about soaring student-loan debt and the role of philanthropists in solving societal ills, was the priceless gift behind Smith’s projected $40 million gift.

At Morehouse, Smith offered the gift of “Bus No. 13,” the title of his commencement address. He wanted to tell them about the community-made Americans who recognize their buses of opportunity and strive to equalize opportunity, especially for the underprivileged whom the buses often bypass.

Smith identifies as a community-made man, prominently diverging from conventional American male identity, particularly wealthy white male identity, which is built on the projection of the self-made, superior man. White men like Donald Trump ignore or downplay the role of the massive buses that carried them for most of their life. Trump claimed that his father’s role was “limited to a small loan of $1 million,” whereas The New York Times estimated that Fred Trump gave his son more than $413 million. Americans seem more apt to recite Horatio Alger lines such as “Make the most of yourself, for that is all there is of you,” and ignore Alger’s line that implored: “Make yourself necessary to somebody.”

With the United States now the most unequal nation in the Western world, I suspect that every person on the higher end of the divide had buses somewhere along the way. But do they acknowledge all the buses—the policies, initiatives, schools, mentors, networks, familial assistance, friendships, institutions, and programs that benefit certain groups or individuals more than others—that changed the trajectory of their life? Or are they more apt to claim that their personal abilities and efforts are the only driving force of their accomplishments while paradoxically resisting efforts to equalize opportunity?

If a billionaire can humble himself and declare himself community-made, then why can’t we? Then why can’t I?

Smith’s speech moved me to reflect on my many buses, and perhaps you should, too. Growing up in south-side Queens, New York, my parents bused me in a different way—not to white public schools, but to black private schools. From third to eighth grades in the 1990s, most of my private-school teachers encouraged me and challenged me. I responded in kind to this unique opportunity with high grades. But I wasn’t totally appreciative. I disliked wearing a uniform, attending chapel every week, and traveling so far from home each day. I disliked the small class sizes and yearned for anonymity. Spoiled in multiple ways, I took the opportunity for granted then, and for most of my life. I remained shamefully blind to how this bus shaped my own trajectory until a few years ago, when I started intensely self-reflecting on my history to compose my forthcoming book.

I tested into one of the best private high schools in Queens. My parents, nurturing my independence, allowed me to choose my high school. I did not get on this bus, enrolling instead at one of the lowest-performing public high schools in Queens. Why? Because my best friend was there. I know: one of the stupidest decisions of my life. My grades plummeted to near-failing as the overcrowded school environment of checked-out teachers failed students like me.

Then again, it ended up being one of the most impactful decisions of my life. When I look back, I can’t help but compare this new high school with my previous private schools, and later with the heavily resourced high school I attended after my family moved to a Virginia suburb of Washington, D.C. I can’t help but acknowledge the unequal opportunity that shaped my life.

In Virginia, my parents nudged me into International Baccalaureate courses, a bus that didn’t exist at my Queens high school. With parents and teachers pushing and challenging me, and with a black male guidance counselor taking me under his wing, my academic performance soared.

However, I hate that I was so pliable back then—low performing in the low-performing school, high performing in the high-performing schools. I refuse now to let opportunities shape my efforts. But back then, I was rather normal—opportunity often shapes one’s ability and effort. I was a rather impressionable child who needed a Bus No. 13 to be successful. And fortunately for me, I received many buses throughout my life. And now I’m community-made.

Society usually gives so much to those who have so much. In this time when bigotry and inequality threaten human society, the question for the privileged is this: How much are they going to give back before they have nothing to give back to? Why risk the lives of everyone they hold dear and wait for that next catastrophe to reduce inequality? How many privileged Americans today are going to walk in the footsteps of those atypical, privileged Americans of old who recognized they were community-made, and who started serving more than directing, started giving more than taking, and invested in the most far-reaching movements in American history for marriage equality, for civil rights, for power, for suffrage, for land, for abolition? How long until humans make sure every human has a Bus No. 13?

The equation that produces societal success seems simple: opportunity + ability + effort (+ luck). Incredible levels of opportunity can often make up for a lack of ability and effort (think of those meandering children of wealthy parents). But incredible levels of ability and effort too many times cannot make up for a lack of opportunity (think of those talented kids who aren’t being challenged and drop out of their low-performing schools. Yes, I considered dropping out of high school).

But Americans are unique in the Western world for commonly striking opportunity from the equation. Americans are more likely than people in other Western nations to believe that one’s ability and effort wholly determine one’s success. The growth of economic inequality and the decline of economic mobility have hardly affected this religious belief, according to one recent study. Perhaps indoctrinated by their parents, young upper-income whites are the most likely to believe that ability and effort rule. Older low-income people of color are the least likely, perhaps knowing firsthand how racist policies steal their opportunities and how racist ideas call them the crooks.

Smith discussed America’s dueling racial history: “the cycle of resistance to oppression, followed by favorable legislations, followed by the weakening of those laws, followed by more oppression, and more resistance, has affected and afflicted every generation.”

Today’s generation of African Americans is dealing with some unprecedented opportunities—and with the mass incarcerating of its opportunities and bodies and talents. Today’s generation is weathering the opportunity gaps that stem from the median wealth of white families ($171,000) being nearly 10 times the median wealth of black families ($17,600), according to Federal Reserve data.

For example, about 30 percent of low-income kindergartners with high test scores wind up graduating from college and securing a decent-paying entry-level job, while about 70 percent of high-income kindergartners with low test scores wind up reaching the same education and job levels, according to a new study. American education is “not a meritocracy, it is more and more an aristocracy posing as a meritocracy,” said one of the study’s authors, the Georgetown economist Anthony Carnevale.

It is hard to miss the posing when we hear about the $25 million college-admissions-fraud scheme, or when we hear that only seven black students this year were offered one of the 895 spots to New York City’s über-selective Stuyvesant High School through admissions criteria based solely on a standardized test. “A test is not racist, a test is not sexist, a test is not a homophobe; a test gives every individual an equal opportunity,” said one critic of New York’s plan to abolish the test. But how do individuals have equal opportunity to score high on a test—or in society—if they are not being prepared equally?

Too many Americans believe that success has only two parents: ability and effort. Too many people sit comfortably on the bus, imagine they are walking on a platform of equal opportunity, and shout to the walking people that something is wrong with them if they can’t keep up. Too many so-called self-made white Americans have an exaggerated sense of self instead of a sense of their exaggerated opportunities—a conceit that springs their racist ideas, as their racist ideas spring their conceit. Too many accomplished people of color dangerously believe that since they supposedly “overcame” racism, then anyone can. They believe the hype that they are extraordinary, that they are not like those ordinarily inferior people in their racial group, reinforcing the very racist ideas that oppress them. They refuse to acknowledge how they are community-made, since they believe that certain things are wrong with their community.

We must all admit our Bus No. 13, admit the opportunities that stemmed from belonging to wealthier families, from whiteness, from masculinity, from heterosexuality, from being able-bodied, from living on the coast, from being bused to better-performing schools and job sites, from that inspirational mentor choosing us and not her or him. These admissions distinguish us from the conceited “self-made” Americans and bigots reproducing inequality in word and deed. These admissions humble us before the altar of history, fusing our story of opportunities with our abilities and efforts, fusing our personal history with a larger societal history. These admissions lead to our mission of being an engine of world-shattering change.

“More than the money we make, the awards, or recognition, or titles we earn, each of us will be measured by how much we contribute to the success of the people around us,” Smith told the Morehouse graduates. “True wealth comes from contributing to the liberation of people.”

For accomplished African Americans, that means realizing we took advantage of “a fleeting glimpse of opportunity and success just before the window is slammed shut,” to use Smith’s words. For anti-racists of all races, this means assuming power and changing policy and maximizing impact to reopen windows for all. Because we can’t be community-made if we are not making the community.



What are Americans supposed to think when their leaders contradict one another on the most basic question of national security—who is the enemy? This is happening every day on the floors of the House and the Senate, in committee hearing rooms, on television news programs, and in President Donald Trump’s Twitter feed. Is Russia the enemy, or was the investigation of Russia’s interference in the 2016 election just a slow-motion attack on the president and his supporters? Are Russian fake-news troll farms stirring up resentment among the American electorate, or are mainstream-media outlets just making things up?

U.S. military commanders, national-security officials, and intelligence analysts have a definitive answer: Russia is an enemy. It is taking aggressive action right now, from cyberspace to outer space, and all around the world, against the United States and its allies. But the public has been slow to catch on, polls suggest, and Trump has given Americans little reason to believe that their president recognizes Russia’s recent actions as a threat.

All the uncertainty is part of Vladimir Putin’s plan. America’s confusion is both a product and a principal goal of a qualitatively new kind of warfare that the Kremlin is waging—a campaign that systematically targets a democratic but politically divided society whose economy, media environment, and voting systems all depend on vulnerable electronic technologies. The essence of this strategy is to attack U.S. interests just below the threshold that would prompt a military response and then, over time, to stretch that threshold further and further. The purpose of this shadow war is simple: to create what Russian General Valery Gerasimov has called “a permanent front through the entire territory of the enemy state.”

In a 2013 article bearing the innocuous title “The Value of Science Is in the Foresight,” Gerasimov, one of Russia’s top military leaders, spelled out his government’s intentions. “In the twenty-first century, we have seen a tendency toward blurring the lines between the states of war and peace,” he wrote. “Wars are no longer declared and, having begun, proceed according to an unfamiliar template.”

Today Russia is applying this “unfamiliar template” on multiple battlefields at once. During the Cold War, Moscow had few levers by which to manipulate American public opinion or meddle in American political campaigns. But the rise of social media created opportunities for troll farms, and poorly secured email systems offered a bonanza for hackers. According to the January 2017 assessment of the Office of the Director of National Intelligence, Russia interfered in 2016 to “denigrate Hillary Clinton and harm her electability” with “a clear preference for President-elect Donald Trump.” It tried to interfere in the 2018 campaign, and all evidence suggests it will do the same in 2020.

Meanwhile, Russia’s military preparations continue. In outer space, Russia has deployed weapons designed to damage or destroy U.S. satellites, the basis for a host of systems that undergird American military and economic superiority in the world. Under the waves, Russia has deployed two new classes of attack and ballistic-missile submarines that are harder to track and therefore more capable of expanding the nuclear threat right to America’s shores.

And on land, Russia has invaded and occupied territory in sovereign nations, including Ukraine and Georgia, and attempted a coup in Montenegro, threatening treaties and the rule of law that have helped keep the peace in Europe for decades.

In 2014, Russia annexed Crimea in violation of a peace agreement it had signed with Ukraine, the United States, and Europe. Months later, it then occupied large swaths of eastern Ukraine. In both cases, Moscow sent in special forces posing as something other than soldiers of the Russian Federation. The “little green men” who turned up in unmarked uniforms were supposedly helping ethnic Russians who feared for their safety in what was then part of a sovereign Ukraine, and what is still recognized as such by the United States and the West today.

In retrospect, those events should not have come as a surprise. In his article the year before, Gerasimov was remarkably specific in describing the exact tactics Russia would soon employ. “The open use of forces—often under the guise of peacekeeping and crisis regulation—is resorted to only at a certain stage, primarily for the achievement of final success in the conflict,” he wrote.

Yet for years after the end of the Cold War, leaders in the United States and other Western nations were willfully blind to Russia’s hostility. They fell victim to “mirroring,” imagining that the Russians—and the Chinese, for that matter—wanted what the U.S. wanted: for them to be drawn into the rules-based international order. But leaders of both Russia and China view that system as skewed toward the interests of the West. Perhaps not coincidentally, China is pursuing a strategy nearly identical to Russia’s, and with similar success—from stealing U.S. trade and government secrets to manufacturing territory in the disputed South China Sea to deploying offensive weapons in space. Only now, as these events unfold, are decision makers in the American public and private sectors abandoning misconceptions about the kind of relationship they might have with Moscow and Beijing.

“It took a long time to sink in,” former Defense Secretary Ashton Carter told me in an interview for my new book.

Yet even when the United States and the West have recognized Russian aggression, the penalties have proved wanting. Following Russia’s interference in the 2016 presidential election, the U.S. named and shamed the Kremlin a full month before Election Day, and later imposed a series of sanctions on Russian individuals and entities. But Russian election meddling has continued. What happened in the intervening months and years that allowed Russia to get away with one act of aggression and then lay the groundwork for another, even bolder one? By the simplest measure—did Russia then stop or soften its attacks?—the U.S. response has failed. This cycle of Russian aggression, followed by an ineffective U.S. retaliation, followed by more Russian aggression, is the shadow war in action.

The West’s handling of Russian aggression in Europe has been similarly futile. Today, despite U.S. sanctions and public condemnation, Crimea is effectively a part of Russia, and parts of eastern Ukraine remain very much under Russian control. In eastern Ukraine now, Russia may be laying the groundwork to assert more formal authority, offering passports to ethnic Russians—a step it also took before its 2008 invasion of Georgia. America’s NATO allies in eastern Europe, including the Baltic states, fear they may now be next.

Belatedly, the United States is adjusting its strategy and defenses to meet these new threats. Aboard submarines and surveillance aircraft, in National Security Agency operations centers, and on bases that make up the growing Air Force Space Command, I’ve met many of the Americans who are now on the front lines of the shadow war, doing all they can to shore up their country’s defenses. However, U.S. intelligence officials, military commanders, and lawmakers all agree that an effective response requires firm leadership from the very top.

Despite their own failures, officials from the Barack Obama and George W. Bush administrations argue that they at least directly confronted Russia over its boldest acts of aggression. Writing in The Washington Post in August, on the tenth anniversary of Russia’s invasion of Georgia, former Secretary of State Condoleezza Rice noted that the Bush administration had returned Georgian troops from Iraq to help protect Tbilisi, their country’s capital. She wrote that she had personally warned Russian Foreign Minister Sergei Lavrov against forcing out Mikheil Saakashvili, Georgia’s democratically elected president.

Officials in Obama’s administration say he twice warned Putin personally against further election interference, first in a face-to-face conversation at the G20 summit in China in September 2016 and then eight days before the election over a hotline originally designed to help prevent nuclear war.

President Trump has shown far less appetite to confront Russia. He has in fact repeatedly questioned whether Russia is an enemy at all. By accounts from within his own administration, Trump’s reluctance to confront the Russia threat is driven in part by his perception that acknowledging the 2016 interference would diminish his victory. Special Counsel Robert Mueller may have absolved Trump of an explicit conspiracy with Russia. But Trump’s continued reluctance to identify and address the Russia threat may be just as damaging to the U.S. and just as helpful to Russia—and the possibility that political intrigue will leave America paralyzed suits the architects of Russia’s shadow war just fine.



All four of my grandparents were sent to prison for their socialist convictions at some point in the 1920s or 1930s. When I was growing up in Europe, democratic countries from France to Italy were ruled by self-declared socialists. As a young activist in the Jusos, the youth organization of Germany’s Social Democratic Party, I sang along wholeheartedly when my comrades would intone “The Internationale” at the end of rallies, rounding off each rendition with a loud shout of “Long live socialism and liberty!”

Given my background, I am baffled by both the fear and the fascination that the socialist label now evokes in the United States. To someone who has grown up in a democracy that provides its citizens with universal health care and (virtually) free higher education, the idea that such policies are dangerously “socialist” is at best question-begging, and the insinuation that they somehow impinge on human liberty is simply bizarre.

But the great differences among the movements and countries that have historically called themselves socialist also makes me skeptical about leftists who think that embracing this label is enough to explain what kind of future they want. Some members of the Democratic Socialists of America, for example, simply want to emulate the rich democracies that provide their citizens with a generous welfare state. But others seek to “abolish capitalism” or sing the praises of the Venezuelan dictatorship.

Anybody who has studied the history of Europe—or, for that matter, Latin America—should know that some socialists crafted systems that left virtually no space to private enterprise and crushed the political freedoms of dissenters, while others combined government benefits with a robust market economy and the rule of law. What mattered was not whether a party or movement called itself socialist, but whether it recognized the danger of autocracy, and carefully formulated limiting principles that would stop it from going down the same path as the Soviet Union. So activists who hope to mainstream socialism in American politics must, at the very least, make clear what, exactly, they mean by the term.

This is why I was very hopeful when Senator Bernie Sanders’s campaign announced that the candidate would hold a major speech on “How Democratic Socialism Is the Only Way to Defeat Oligarchy and Authoritarianism.” After years of using the term about as imprecisely as many of his followers, I hoped that Sanders would finally set out why it holds such importance to him, what role the market would play in the socialist system he promises to build, and how he can protect his political project against the Soviet risk.

I can’t say he met my expectations.

In the most poignant passages of his speech, Sanders rightly argued that a robust welfare state need not be in tension with personal liberty. On the contrary, access to basic social and economic goods is a precondition for being able to make real choices:

Are you truly free if you are unable to go to a doctor when you are sick, or face financial bankruptcy when you leave the hospital?
Are you truly free if you cannot afford the prescription drug you need to stay alive?
Are you truly free when you spend half of your limited income on housing, and are forced to borrow money from a payday lender at 200 percent interest rates?

Are you truly free if you are 70 years old and forced to work because you lack a pension or enough money to retire?

This is a classic leftist critique of unbridled capitalism, and it retains much of the force it had back in the days of Karl Marx. Sanders made a strong case for the universal provision of affordable health care, the regulation of the financial industry, and generous old-age pensions. But he didn’t acknowledge—in this section or elsewhere—the ways in which the suppression of free markets has repeatedly fostered a different kind of oppression over the past century.

Virtually all socialist movements have claimed to embrace democracy, as Sanders did with a perfunctory reference to the Bill of Rights. What separated, say, the Sandinistas in Nicaragua, who ended up crushing political opponents, from the French Socialists, who respected the right to dissent, was in good part their attitude toward markets. Socialists who nationalized large parts of the economy, and severely restricted the functioning of the market, crushed freedom in two ways: First, they made it impossible for citizens to engage in private economic initiative. And second, they quickly started to abuse the power to take away the livelihood of political opponents.

This history makes it all the more important for Sanders to be clear on the kind of role that he envisages for the market in the society he is setting out to create. What forms of private economic initiative would be allowed? After sitting through his 40-minute speech, I was none the wiser about this basic question. Instead of clearing, Sanders’s long-standing ambiguity about the nature of the socialism for which he stands settled over me like a sea of fog.

If Sanders was coy about the details of a “socialist” economy, he was downright disdainful of the notion that a speech on socialism and authoritarianism should seriously grapple with the long history of socialist movements that have ended in dictatorship. In his view, the threat of autocracy comes exclusively from the right. Just as in the 1930s, “America and the world are once again moving towards authoritarianism.” This danger is driven by “right-wing forces of oligarchy, corporatism, nationalism, racism, and xenophobia.” The only answer that will stave off fascism is, you guessed it, “democratic socialism.”

Thus Sanders name-checked Adolf Hitler and Benito Mussolini but remained silent about Joseph Stalin and Mao Zedong. And while he rightly decried the autocratic tendencies of Russia’s Vladimir Putin, China’s Xi Jinping, Saudi Arabia’s Mohammed bin Salman, the Philippines’ Rodrigo Duterte, Brazil’s Jair Bolsonaro, and Hungary’s Viktor Orbán, he neglected to mention leftist autocrats such as Venezuela’s Nicolás Maduro, Cuba’s Raúl Castro, Nicaragua’s Daniel Ortega, Zimbabwe’s Emmerson Mnangagwa, or North Korea’s Kim Jung Un. Indeed, the only connection between socialism and autocracy that Sanders was willing to acknowledge is the one that exists in the feverish imagination of the ignorant right: He decried the “red-baiting” in which Republicans have long engaged.

The implication was obvious. Anybody who was hoping for a clear account of the differences between Sanders’s political ambitions and those of autocratic socialist regimes is a fellow traveler of Richard Nixon, Newt Gingrich, John Boehner, Donald Trump, and the Heritage Foundation.

Over the past few months, Senator Elizabeth Warren has issued a series of ambitious proposals for economic reform. Under her plans, the tax system of the United States would become a lot more redistributive. Americans would enjoy far more generous entitlements. Every resident would be guaranteed access to affordable health care. And the state would become much more active in curbing the formation of monopolies.

But Warren has argued that she is seeking to rescue, rather than bury, capitalism. (She cleverly dubbed one of her most ambitious plans the “Accountable Capitalism Act.”) And she has clearly articulated that the market has an important role to play in the country she hopes to build. In fact, many of her proposals are as much about ensuring that there is true competition in areas like tech as they are about restricting the operation of free markets.

In this regard, Warren is the heir of some of the most successful left-wing movements of the 20th century. Whether they called themselves socialists, social democrats, or progressives, figures such as Germany’s Willy Brandt, Britain’s Clement Attlee, and America’s Franklin Delano Roosevelt were clear about the benefits of markets and forthright about the dangers of left-wing authoritarianism.

Even in the United States, where the horrors of the gulags and the indiscriminate killings of Pol Pot have always felt rather remote, the most eloquent democratic socialists have taken this crucial lesson to heart. For thinkers like Michael Walzer, the label “Democratic Socialist” entailed a deep recognition that the left could be just as vulnerable to autocratic temptation as the right.

A serious speech about socialism and authoritarianism would have built on the political legacy of Brandt and the philosophical legacy of Walzer. The speech Sanders gave was not serious.



As President Donald Trump’s critics focus anew on whether he obstructed justice to thwart Special Counsel Robert Mueller’s investigation, a more flagrant abuse of presidential power is unfolding in plain sight.

For weeks, Trump has continued America’s involvement in the war in Yemen, siding with Saudi Arabia against Congress, the body that the Constitution vests with the power to declare war. The House last month approved a resolution, 247 to 175, directing the president to withdraw the U.S. from the war on Yemen. A bipartisan Senate majority had already approved the same resolution. And the American public has no appetite for a long war in Yemen.

On its own, waging war after an official call from Congress to stop doing so ought to be regarded as a violation of the Constitution that warrants impeachment.

But there’s even more to the Trump administration’s “Saudi Arabia First” foreign policy: Citing a provision in the Arms Export Control Act that allows the president to bypass the legislative approval process in an emergency, the administration is circumventing a block on arms sales to the Saudis.

“We have the constitutional duty to declare war and the responsibility to oversee arm sales that contravene our national security interests,” Democratic Senator Chris Murphy has complained. “If we don’t stand up to this abuse of authority, we will permanently box ourselves out of deciding who we should sell weapons to.”

Congress ought to eliminate the emergency provision. But the provision’s existence does not justify its invocation when there is no actual emergency. Secretary of State Mike Pompeo says the weapons are needed to deter Iran, but that hardly amounts to an immediate crisis. 

Daniel Larison notes:

The weapons that the U.S. sells to the Saudis and the UAE won’t be used to defend against a supposed Iranian threat, and they won’t be used for deterrence. We know very well that the Saudi and Emirati governments will use the weapons they obtain from the U.S. to continue waging an atrocious war against Yemen, and those weapons will very likely end up being used to kill civilians as so many other U.S.-made weapons have been. Trump is helping to fuel Saudi coalition aggression against a poor country that they have been wrecking and starving for more than four years. This will not avert a war with Iran, but it will help to keep the war on Yemen going.

Put succinctly, the Trump administration unlawfully defied Congress to extend American participation in a war in Yemen, and now it is defying America’s elected representatives again to funnel more weapons to that war’s ringleader.

It’s the legislature’s move.

Perhaps a lawsuit of the sort urged by some legal scholars who believe votes against wars cannot be constitutionally vetoed by the president would prove effective.

“I’m confident these new arms sales provides new momentum for pursuing legal action and legislation that would end U.S. involvement in the war,” Democratic Representative Ro Khanna stated on Twitter. “The lawsuit is important to uphold Congress’ constitutional War Powers & challenge President Trump’s veto of our Yemen WPR.”

But there is a more direct remedy available to Congress. So long as some of its members are invoking alleged obstruction of justice to justify impeachment proceedings, they ought to invoke abuse of the war power, too. The prospect of being removed from office is far more likely than even a successful lawsuit to deter this president and his successors from usurping the legislature’s authority.



Two times during Barack Obama’s tenure, I criticized the 60 Minutes correspondent Steve Kroft for asking softball questions when interviewing the president.

Last night, I expected Sean Hannity would fail the American public similarly in his interview with President Donald Trump. But it wouldn’t be fair to beer-guzzling amateurs playing recreational slow-pitch to compare what I saw to softball.

T-ball is closer to the mark.

At the interview’s end, Hannity said this about his approach to asking questions: “Sometimes I know when you do other interviews that people want to play gotcha. But every once in a while, I think it’s important for the American people to hear you in answer in your own words at length on some important issues.”

Let’s look at what that meant in practice.

A long stretch at the beginning of the interview was dedicated to telling Trump that he was victimized by the Obama administration, Hillary Clinton, and the FBI. Hannity asked Trump to react, prompting answers such as, “I think it’s far bigger than Watergate. I think it’s possibly the biggest scandal in political history in this country.”

Consider all the probing questions one might ask a Republican president about energy policy, or the political strengths and weaknesses of the Democratic Party.

Here is how the Fox News host teed up his guest on those subjects:

We have not just Congresswoman Ocasio-Cortez—about 100 House, Senate members at least and many of the Democratic presidential candidates for 2020 have bought into the New Green Deal. Everything is free, no oil, no gas. Comrade de Blasio has added no steel building or glass buildings in New York in five years. But importantly, airplanes are gone, combustion engines gone. How do you react if these are the policies you will be running against?

The odds that Democrats will run in 2020 on abolishing airplanes, combustion engines, and steel and glass buildings from New York City are zero. So why ask the question in that way? No journalistic impulse could justify it. Hannity teed up a straw man so big, even a child would be unlikely to swing and miss.

Trump’s reply:

It’s interesting because I just heard about this crazy deal in New York City where they want to build concrete buildings with little tiny windows. You know, I built a lot of buildings, Sean. I can tell you, the bigger the window, the better I did with it. People want big windows, and now they’re going to take them down to nothing.

Such is the quality of civic information Hannity drew out of the country’s most powerful man. Here’s Hannity a bit later, asking a worthless question insofar as it could yield only information that Trump already tells the country almost daily:

The Washington Post, The New York Times received Pulitzers for their, quote, coverage of the Russian probe. You’ve seen the coverage for two years. Russia, Russia, Russia. Trump, Trump, Trump. Collusion, collusion, collusion. The Mueller report couldn’t be clearer on the issue specifically. Do you think the news media in this country and their coverage on this owes you an apology?

Inevitably, Hannity provoked the answer, “Well, they do owe me an apology, a big one,” a position that every sentient viewer already knew and that tells Americans absolutely nothing about any of the important challenges facing the country.

A few questions did prompt Trump to speak on newsworthy subjects. “What is your full reaction to the Mueller report?” Hannity said. During follow-up questions about the Russia investigation, Trump declared, “This was an attempted coup.” Hannity neither challenged the claim nor asked Trump to justify it.

I do not object merely that Trump was interviewed by someone who shares his views on most subjects or who wants to see his campaign agenda come to fruition. Presidents ought to give some interviews to journalists who are sympathetic to the vision that they set forth. But those journalists should still hold them accountable to the public by asking tough questions about their progress, their unkept promises, and the thorny trade-offs that they inevitably confront.

That is the job.

Hannity was less a stand-in for the public than a sycophant, proving himself less adept at eliciting new information from Trump than the field on Twitter that perpetually asks, “What’s happening?” Given an opportunity to serve his audience and his country, he failed.



This month at Princeton University, hundreds of student protesters participated in a campaign to change how their institution handles cases of sexual misconduct, using a days-long sit-in to wrangle future meetings with administrators. At their invitation, I studied their 11 proposed reforms.

“We ask that the University engage in dialogue regarding the systemic issues of sexual and interpersonal violence on its campus,” they write. “We need a conversation.”

Their suggestions merit one. Constructive throughout, they combine reform proposals that could attract support from people on all sides of the Title IX debate with ideas that will divide observers depending on their views about due process. And they illustrate an underappreciated tension in the approach of today’s student activists, who simultaneously express outrage at the bad behavior of administrative bureaucracies and fight to expand their size and power.

In a reported Washington Post dispatch with a Princeton dateline, Paula Span once observed that “someone who has not spent much time on a campus lately may be startled to see the way the definition of a liberal college has changed. A generation ago, it was a school withdrawing from its students’ sexual lives, dismantling curfews and rules about who could be in whose dorm when. Now it’s a school that, often at students’ insistence, is firmly stepping back in.”

Those words were published on October 22, 1993.

As her article went on to note, the subject of sexual assault was “virtually part of the curriculum at U.S. colleges.” At Princeton, orientation included a student-performed play about date rape. The institution had just “adopted a sexual assault policy establishing disciplinary proceedings and services for victims.” Counselors were available 24 hours a day. And then the 25-year-old Princeton graduate student Katie Roiphe had recently published The Morning After: Sex, Fear, and Feminism.

Roiphe argued that an alleged “rape crisis” on American campuses was exaggerated and that feminists were producing “endless images of women as victims,” a “portrait of the delicate female” that resembled “that ’50s ideal my mother and other women of her generation fought so hard to leave behind.” Controversy surrounding her thesis ensured that Princeton was a national lightning rod in that era’s mainstream debate about sexual assault on campus.

Analysis of that era’s protests, debates, and administrative interventions might inform a question that ought to loom large in the controversies of spring 2019: Does hiring new administrators really help reduce sexual assault on campus? But memories are short at institutions that students pass through in four years.

Today’s Princeton students frame their protest as a response to a five-year-old controversy about Title IX, a law that prohibits colleges that receive federal funds from excluding, discriminating against, or denying benefits on the basis of sex. “In 2014, the Department of Education found that Princeton was not in compliance with this federal law,” the activists note. At the time, Barack Obama’s administration had adopted a new interpretation of the statute, pressuring many institutions to change how they handled claims of sexual misconduct.

“Five years later, Princeton’s Title IX system remains broken,” the manifesto asserts.

To underscore Princeton’s problems as they see them, they activists have compiled “34 stories of survivors” at the college who have been affected by what they call “the negligence of Princeton’s Title IX processes.” The system is “plagued by a lack of transparency regarding the Title IX process,” they write. Administrators “have not communicated effectively or compassionately with survivors … Outdated precedents jeopardize the fairness of the adjudication process … And Title IX panels have not adequately collected and aggregated evidence.” They seem to believe that efforts on behalf of survivors of sexual assault and against the crime itself are best focused on improving that bureaucratic system.

The first three of the student activists’ 11 reform ideas are promising:

Transparency and consistency in Title IX processes.

An external review of the implementation of Title IX at Princeton, along with a parallel and incorporated committee for student oversight.

The establishment of an opt-in restorative justice track for survivors who wish to avoid the process of Title IX proceedings.

Those on the other side of the issue, who insist that Obama-era Title IX guidelines deprive accused students of due process, agree that the system is plagued by lack of transparency, ineffective communication, outdated precedents, and failures to adequately collect and handle evidence. When the student activists say, “We need a document that educates all Princeton community members on Title IX and how it is implemented at Princeton at every step,” they’re urging a reform everyone could accept.

The call for an external audit might also attract broad support, but raises the question of who decides on the auditors, given that what counts as compliance is so contested. When I put that question to the activists, they clarified that an outsider perspective would be helpful on a range of straightforward process issues.

“Some elements of good conduct are consistent no matter who performs the review,” they wrote. “For example, does every complainant hear back about the result of their case in a timely matter, if at all? Does every complainant and respondent know what is grounds for appeal or how to register grievances?” But they listed some other questions that struck me as requiring judgments on inevitably controversial matters. “Are staff handling cases in a sensitive manner that doesn’t unnecessarily traumatize survivors?” they wrote. “Are the staff assigned to potentially guide students through the process adequately trained?”

Arguably most intriguing is their call to give students the option to seek “restorative justice” instead of filing a complaint through the Title IX bureaucracy.

They write:

At least 65 colleges and universities—including Brown University and Stanford University—have implemented some form of restorative justice programming. PRISM at Skidmore University offers opt-in restorative justice conferences, support circles, and administrative hearings for all members of the University community. A full administrative staff is dedicated to the implementation … We call for restorative interventions that establish appropriate standards of sexual conduct, reduce fear, and preserve the agency of survivors. Full-time, professional practitioners of restorative justice—trained specifically in matters of interpersonal violence—will help all parties involved develop mutual action plans, choose how, if at all, to participate in moderated dialogue, and empower rather than retraumatize survivors.

I’m in favor of more experiments in restorative justice. But keep those full-time restorative-justice administrators in mind as you read the next three suggested reforms:

The student activists want Princeton to hire a whole lot more people: the outside auditing firm, the full-time staff of restorative-justice experts, whatever constitutes a “fully-staffed” office of “intersectional violence investigation,” plus a new independent office of professional social workers. In item nine, they call for “an International Interpersonal Coordinator to be immediately hired to work as a direct resource on issues of sexual misconduct and interpersonal violence for Princeton students while they are abroad.” And in item 10, they advocate hiring more professional counselors to add diversity to their ranks, and paying students who currently volunteer their labor to help victims of assault.

On top of a pricey existing bureaucracy, that’s a lot of new expenses, I pointed out.

If all your demands were met, I asked the activists, would that be a good use of money? Ten new administrators might address any number of campus needs. What’s the case that meeting these needs is most important?

I’m not sure they granted the premise of the question. As they put it:

A better question might be that, at an institution with so many resources at its disposal, why hasn’t there already been a serious effort to address the recurring and disproportionate impact on women, people of color, LGBTQ+ students, and those who live at these intersections? We should ask why the
university wishes to expand its student body when it cannot properly support its current one.

Surely if there is time to solicit the capital to build a new building, a $65 million undertaking, there is time to find the capital to prevent interpersonal violence. This, of course, ignores the $25.9 billion endowment that can be mobilized to intervene in this crisis if the university recognized the urgency. We have the access to the money to address the campus injustices and the status of marginalized students. As the university aims to admit more students from marginalized backgrounds, Princeton must do everything in its power to ensure these students can live and learn in a safe environment without enduring cumulative and compounding violence because of their identities.

Let me push back. Princeton could spend down its endowment or raise tuition or hit up donors to fund a new Office of Suicide Prevention, an Alcohol and Drug Abuse Counseling Center, state-of-the-art accommodations for special-needs students, a new cancer-research initiative, an unprecedented effort to reduce the campus’s carbon footprint … or any number of other good things.

That does not mean there’s no case for spending money on a dramatic expansion of the Title IX administrative bureaucracy, but a case is, in fact, required––one that grapples with opportunity costs, instead of just asserting that the status quo is flawed.

In our correspondence, I asked about a hypothetical in which the activists’ suggested reforms turned out to cost $20 million a year. Could they justify that price tag? The activists were undaunted. 

For context, “during the 2017-2018 academic year,” Princeton notes of its Title IX proceedings, “there were 17 cases in which respondents were found responsible for sexual misconduct, and 16 cases in which respondents were found not responsible.” The $20 million–a-year figure would be sufficient to give all confirmed victims of sexual assault $1 million each in cash. And I’ve seen no conclusive evidence that increasing the size of Title IX bureaucracies reduces the incidence of sexual assault on campus or meaningfully diminishes the pain or trauma of victims.

I was especially struck by the activists’ question about why Princeton would want to expand when it “cannot properly support” its current student body, which is better supported than almost everyone else in planet Earth’s history. Even narrowly focusing on the issue of sexual violence against students, Princeton offers far more dedicated support to victims than is available to anyone in New Jersey who doesn’t live on the campus of a selective college. And off-campus sexual-assault rates among 18-to-22-year-olds are higher.

On those grounds alone, one could argue that spending, say, $20 million to expand the Princeton student body advances social justice more than spending on current students, a case that grows stronger in light of the full range of advantages enjoyed by those who attend an Ivy League school.

In some moments, student activism is focused on causes, such as the Freedom Rides or the anti–Vietnam War protests or the Occupy Wall Street movement, that aim to effect broad social change intended to improve life for many people far from any campus. Today student activists could demand that their wealthy institutions underwrite a battered women’s shelter, or partner with a nearby municipality to provide universal mental-health counseling for all victims of sexual assault in the community.

Of course, the activists have every right to focus more narrowly on their privileged classmates. They wish to improve the community where they live, and they’re doing more to try to improve the world, not less, than many of their peers. Still, money spent on administrative bloat is money not spent elsewhere. Whereas calls to better use existing resources are always worth studying, there must be some limit to the additional millions that one can spend on behalf of Ivy League students while still claiming to advance social justice. What is that limit?

Reform No. 7 struck me as questionable, too, but for a different reason. The student activists call for the program in gender and sexuality studies to become a new academic department, arguing that it would prove “a key step in challenging dominant paradigms of toxic masculinity, homophobia and transphobia.”

In response, I emailed, “You seem to be rooting a scholarly field in an outcome-oriented effort to advance social justice, rather than a viewpoint-neutral effort to seek truth by facilitating scholarly inquiry wherever it leads. Isn’t that a politicization of the faculty that implicitly constrains the academic freedom of those working in the proposed department?” For example, what if a scholar came to believe, “through her research, that toxic masculinity is a flawed concept?” I asked. Would that scholar’s earnest belief “or the department’s mission of ‘challenging dominant paradigms of toxic masculinity’ take precedence?”

They replied:

There is no such thing as neutral scholarly inquiry since it must be understood through the perspective of the author. A gender and sexuality studies department would examine research keeping in mind the social forces that impact gender and sexuality. To acknowledge that gender and sexuality impacts the way we move through the world is not a political statement. The paradigms we discuss are well accepted terms in the field that decades of research say play a causal role in violence. The departmentalization of Gender and Sexuality Studies will help generate research on gender and sexual violence on campus and provide intellectual frameworks to help combat those forms of violence.

But there is such a thing as an academic department that is viewpoint-neutral, affording scholars the freedom to reach a variety of conclusions that are not preordained. And I did not contest the uncontroversial statement, “Gender and sexuality impacts the way we move through the world” (something they seemed to cast as a neutral foundation for scholarly inquiry moments after asserting that there is no such thing); I asked about dissenting views on toxic masculinity.

I was as skeptical of their final demand: “We call for the University to publicly maintain its commitment to protecting survivors’ rights as outlined in current Title IX policies, in spite of proposed national rollback efforts.” In part, I was skeptical because I believe that the Obama administration’s approach to Title IX violates the due-process rights of accused students––and judges have agreed, on occasion siding with accused students in their lawsuits against universities. In 2019 so far, at least two accused students have sued Princeton alleging that their due-process rights were violated, according to the academic K. C. Johnson. In one case that settled, “Princeton aggressively fought in court to avoid implementing cross-examination,” he wrote, “or a requirement to have to turn over their training materials.”

Sexual assault is a serious problem on and off campus. In the past, I’ve argued that its incidence warrants both cultural change and experiments in innovative attempts to guard against serial predators. Today I hope student activists succeed in increasing transparency, remedying whatever failures are exposed, and experimenting with restorative justice. But 25 years after the first round of efforts to address the problem through administrators and campus-life initiatives, I don’t understand the activist faith that Title IX and associated bureaucracies can be the cornerstone of an effective solution.

Although activists are suspicious enough of Princeton’s current staff and administrators to demand more transparency, they’re also confident that the bureaucracy of the near future will share their values, or at least more reliably advance their preferred ends. Their approach is radically different from that of civil-libertarian critics of Title IX excesses, who look to rein in administrators through the courts rather than attempt to hire like-minded ones.

The student activists may have the more effective short-term approach. I predict that Princeton administrators, who’ve already agreed to an outside audit of their Title IX proceedings, will ultimately agree to more of the reforms that the students put forth, if only because college administrators are more inclined than anyone else to see the benefits of three dozen more college administrators.

So student activists should bear one last argument in mind before entering into summertime meetings with Princeton leaders. Its author is the educator Freddie deBoer, who observes that university bureaucracies, like all corporate structures, serve corporate interests, not those of the people within them–– “and so these efforts are often designed to spare the institutions from legal liability rather than protect the individuals who would be harmed by sexual harassment.”

DeBoer goes on to warn student activists that the administrators who run their universities, “no matter how convenient a recipient of their appeals, are not their friends,” and that appealing to them often results “in something like collusion between activists and administrators” rather than a more just system.

Title IX in particular can be a powerful tool for justice, he argues, but when wielded by bureaucratic functionaries, it can be abused, becoming “an instrument of power, not of the powerless.” As the law “compels the self-protective, legalistic wings of universities to grind into gear, for fear of liability and bad publicity, invocations of Title IX frequently wrest control of the process and the narrative from student activists themselves, handing it to bureaucrats.”

Princeton bureaucrats have been focused on campus sexual assault for a quarter century now. And in the telling of the student activists, they’ve yet to meet even minimal ethical and procedural standards. So why pour millions more into the same hierarchies, expanding the might, measured in total staff, of their leaders?



I have taught evolution and genetics at Williams College for about a decade. For most of that time, the only complaints I got from students were about grades. But that all changed after Donald Trump’s election as president. At that moment, political tensions were running high on our campus. And well-established scientific ideas that I’d been teaching for years suddenly met with stiff ideological resistance.

The trouble began when we discussed the notion of heritability as it applies to human intelligence. (Heritability is the degree to which offspring genetically resemble their parents; the concept can apply not only to physical traits, but also to behavioral ones.) In a classroom discussion, I noted that researchers have measured a large average difference in IQ between the inhabitants of the United States and those of my home country, Brazil. I challenged the supposed intelligence differential between Americans and Brazilians. I asked students to think about the limitations of the data, which do not control for environmental differences, and explained that the raw numbers say nothing about whether observed differences are indeed “inborn”—that is, genetic.

There is, of course, a long history of charlatans who have cited dubious “science” as proof that certain racial and ethnic groups are genetically superior to others. My approach has been to teach students how to see through those efforts, by explaining how scientists understand heritability today, and by discussing how to interpret intelligence data—and how not to.

In class, though, some students argued instead that it is impossible to measure IQ in the first place, that IQ tests were invented to ostracize minority groups, or that IQ is not heritable at all. None of these arguments is true. In fact, IQ can certainly be measured, and it has some predictive value. While the score may not reflect satisfaction in life, it does correlate with academic success. And while IQ is very highly influenced by environmental differences, it also has a substantial heritable component; about 50 percent of the variation in measured intelligence among individuals in a population is based on variation in their genes. Even so, some students, without any evidence, started to deny the existence of heritability as a biological phenomenon.

Similar biological denialism exists about nearly any observed difference between human groups, including those between males and females. Unfortunately, students push back against these phenomena not by using scientific arguments, but by employing an a priori moral commitment to equality, anti-racism, and anti-sexism. They resort to denialism to protect themselves from having to confront a worldview they reject—that certain differences between groups may be based partly on biology. This denialism manifests itself at times in classroom discussions and in emails in which students explain at length why I should not be teaching the topic.

To my surprise, some students even objected to other well-established biological concepts, such as “kin selection,” the idea that, when individuals take actions for the benefit of their offspring and siblings, they are indirectly perpetuating their own genes. Startled students, falling into what we call the “naturalistic fallacy”—the notion that what occurs in nature is good—thought I was actually endorsing Trump’s hiring of his family! Things have gone so far that, in my classes, I now feel compelled to issue a caveat: Just because a trait has evolved by natural selection does not mean that it is also morally desirable.

The duty of scientists is to study the world—including the human body and mind—as it is. Some of our students, however, are seeing only what they want to see and denying real-world phenomena that conflict with their ideology. Take, for example, the obvious biological differences between the sexes, not only in physical traits (men, on average, are clearly stronger and faster than women are), but also in aptitudes and preferences (boys generally prefer wheeled toys, and girls prefer plush toys, a preference that is also observed in baby monkeys!).

People expect an equal sex ratio across academic professions and sometimes ascribe the lack of such equality to bias. In the so-called STEM fields—science, technology, engineering, and mathematics—the relative paucity of women is frequently taken to reflect endemic sexism. While this is undoubtedly a factor, the effect of bias as opposed to other factors, such as differences in what male and female students prefer, requires detailed empirical study.

One set of data challenges the idea that bias is the only cause of sex-ratio differences in the STEM fields. The so-called gender-equality paradox involves the observation that, while women and men around the world perform equally well on standardized science tests, countries with the highest proportion of women in STEM are not the ones with the least discrimination or sexual harassment, but those with the greatest gender inequality. Where women are free to choose their own path and do not have to worry about pay, they gravitate toward the humanities. Countries such as Norway and Finland have relatively few women in STEM fields, while countries such as Algeria and Indonesia have an ample supply.

However, when one assumes that everyone is a blank slate, differences between what males and females do can be explained only by bias and harassment. The conclusion is obvious: All STEM fields are cesspools of sex discrimination. This is what happens when ideology replaces biology. It’s become taboo to even mention the possibility that men and women might have different preferences.

Sadly, students do not seem to realize that their good intentions may lead them to resist learning scientific facts, and can even harm their own goal of helping women and ethnic minorities. The existence of any genetic differences between males and females, or between different ethnic groups, does not imply that we should treat members of those groups differently. Denying reality and pretending that differences do not exist—as if this were the only possible path toward equality—is dangerous. If you believe that moral equality relies on biological equality, this makes your moral views susceptible to future research that might reveal biological inequalities. Instead, equality and equal opportunity for all should be the default position, regardless of potential biological differences.

When students at Williams or anywhere else try to protect their worldview by denying scientific evidence, it is bound to affect what professors teach and how they teach it. Campus norms proscribe any discourse that might offend women, minorities, or anyone perceived as a victim of patriarchal white societies. However, this rule, no matter how well intentioned, is harming the very people it aims to protect. The argument favoring a certain amount of self-censorship is that it is necessary to protect minority students from feeling unsafe when they hear what they see as “hate speech.” However, by not talking about science that some find unsettling, we deny students opportunities for learning and for intellectual empowerment. How well can they argue their positions effectively unless they are seeing the world as it really is?

This article is part of “The Speech Wars,” a project supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press, and the Fetzer Institute.





Subscribe to Crazy/Genius: Apple Podcasts | Spotify | Stitcher | Google Play

Rachel Cicurel, a staff attorney at the Public Defender Service for the District of Columbia, was used to being outraged by the criminal-justice system. But in 2017, she saw something that shocked her conscience.

At the time, she was representing a young defendant we’ll call “D.” (For privacy reasons, we can’t share D’s name or the nature of the offense.) As the case approached sentencing, the prosecutor agreed that probation would be a fair punishment.

But at the last minute, the parties received some troubling news: D had been deemed a “high risk” for criminal activity. The report came from something called a criminal-sentencing AI—an algorithm that uses data about a defendant to estimate his or her likelihood of committing a future crime. When prosecutors saw the report, they took probation off the table, insisting instead that D be placed in juvenile detention.

Cicurel was furious. She issued a challenge to see the underlying methodology of the report. What she found made her feel even more troubled: D’s heightened risk assessment was based on several factors that seemed racially biased, including the fact that he lived in government-subsidized housing and had expressed negative attitudes toward the police. “There are obviously plenty of reasons for a black male teenager to not like police,” she told me.

When Cicurel and her team looked more closely at the assessment technology, they discovered that it hadn’t been properly validated by any scientific group or judicial organization. Its previous review had come from an unpublished graduate-student thesis. Cicurel realized that for more than a decade, juvenile defendants in Washington, D.C., had been judged, and even committed to detention facilities, because the courts had relied on a tool whose only validation in the previous 20 years had come from a college paper.

The judge in this case threw out the test. But criminal-assessment tools like this one are being used across the country, and not every defendant is lucky enough to have a public defender like Rachel Cicurel in his or her corner.

In the latest episode of Crazy/Genius, produced by Patricia Yacob and Jesse Brenneman, we take a long look at the use of AI in the legal system. Algorithms pervade our lives. They determine the news we see and the products we buy. The presence of these tools is relatively obvious: Most people using Netflix or Amazon understand that their experience is mediated by technology. (Subscribe here.)

But algorithms also play a quiet and often devastating role in almost every element of the criminal-justice system—from policing and bail to sentencing and parole. By turning to computers, many states and cities are putting Americans’ fates in the hands of algorithms that may be nothing more than mathematical expressions of underlying bias.

Perhaps no journalist has done more to uncover this shadowy world of criminal-justice AI than Julia Angwin, a longtime investigative reporter. In 2016, Angwin and a team at ProPublica published a detailed report on COMPAS, a risk-assessment tool created by the company Equivant, then called Northpointe. (After corresponding over several emails, Equivant declined to comment for our story.)

In 2013, a Wisconsin man named Paul Zilly was facing sentencing in a courtroom in Barron County. Zilly had been convicted of stealing a lawn mower, and his lawyer agreed to a plea deal. But the judge consulted COMPAS, which had determined that Zilly was a high risk for future violent crime. “It is about as bad as it could be,” the judge said of the risk assessment, according to the ProPublica report. The judge rejected the plea deal and imposed a new sentence that would double Zilly’s time in prison.

Angwin and her team wanted to know more about the COMPAS algorithm: It seemed unfair, but was it truly biased? They got access to the COMPAS scores of 7,000 people arrested in Broward County, Florida, and compared those scores with the criminal histories of those same people over the next few years. “The score proved remarkably unreliable in forecasting violent crime,” they found. “Only 20 percent of the people predicted to commit violent crimes actually went on to do so.” They also concluded that the algorithm was twice as likely to falsely flag black defendants as future criminals as it was to falsely flag white defendants.

There’s another concern about algorithms such as COMPAS. It’s not just that they’re biased; it’s also that they’re opaque. Equivant doesn’t have to share its proprietary technology with the court. “The company that makes COMPAS has decided to seal some of the details of their algorithm, and you don’t know exactly how those scores are computed,” says Sharad Goel, a computer-science professor at Stanford University who researches criminal-sentencing tools. The result is something Kafkaesque: a jurisprudential system that doesn’t have to explain itself.

Goel dislikes COMPAS’s opacity. But he’s a cautious advocate for algorithms in the legal system, more broadly. “Everything that happens in the criminal-justice system involves a human in some way, and every time a human is involved, there’s always this potential for bias,” he told me. “We already have black boxes making decisions for us all the time, but they just happen to be sitting in black robes.”

For proof that algorithms can play a positive role, Goel points to New Jersey. In 2017, the state eliminated cash bail in almost all cases, except when judges consult a risk-assessment algorithm that determines the defendant is a high risk for future crimes. Last year, The Star-Ledger reported that violent crime had fallen more than 30 percent since 2016. To Goel, this shows that public algorithms can be part of a larger plan for states to slash incarceration and still reduce overall crime by identifying defendants who are most likely to violently recidivate.

“I don’t think we can make perfectly fair decisions,” Goel said. “But I think we can make better decisions. And that’s where these algorithms are coming into play.”

This article is part of our project “The Presence of Justice,” which is supported by a grant from the John D. and Catherine T. MacArthur Foundation’s Safety and Justice Challenge.



Late last month, the State Department rolled out new rules that require nearly all foreigners applying for U.S. visas—about 15 million people each year—to disclose the handles they’ve used over the past five years on Facebook, Twitter, Instagram, YouTube, Pinterest, Myspace, and 14 other social-media platforms. The program is unlikely to help identify people who pose a threat to the United States. It will, however, empower the U.S. government to scrape up more information than it knows what to do with. Information misconstrued by consular officers or, potentially, computer algorithms could lead to innocent people being sent into bureaucratic limbo or having their visa denied. At worst, social-media data could be used to discriminate on a large scale against particular political or religious views disfavored by Donald Trump’s administration and its successors.

The momentum to use social media to screen people coming to the United States has been mounting since December 2015, when media reports falsely claimed that Tashfeen Malik, who with her husband killed 14 people in San Bernardino, California, had pledged allegiance to ISIS in public Facebook posts. In fact, Malik had sent private messages that monitoring Facebook posts wouldn’t have caught. Nevertheless, the Department of Homeland Security launched several pilot programs to test the feasibility of such checks. In 2016, it added an optional question requesting social-media handles for travelers applying for visa-free admission to the United States. And the Trump administration has already required the disclosure of social-media handles from roughly 70,000 visa applicants “determined to warrant additional scrutiny.”

The new rule, though, vastly expands the universe of people affected. Unfortunately, the State Department has offered little detail about precisely how it will use the millions of identifiers that it is collecting. According to the department’s regulatory filings, consular officers could look at social-media accounts to round out other information about an applicant—for instance, what they glean from her interview and application papers. It’s not clear whether social-media data will be subjected to some type of automated system meant to flag particular words or identify suspicious connections between people. But Homeland Security—the State Department’s main partner in vetting visa applications—has experimented with systems that perform both tasks. Many other questions remain: What will happen to people who are flagged? Will they be notified of a post that troubles a consular officer and given a chance to respond to any concerns? How will any vetting system account for slang, cultural context, and humor? Does the State Department even have the language capacity to systematically review social-media posts?

The department says it needs social-media identifiers to determine whether visa applicants meet the standards for getting a visa, to root out fraud, and to “identify misrepresentations that disguise potential threats.” Of course, these are precisely the judgments that consular officers have already been making as part of the robust visa-vetting system that was built after the September 11 attacks. Anybody who has ever applied for a visa to the United States will attest that it involves a rigorous investigation. In addition to providing biographical and biometric information, applicants have to explain—and meticulously document—where they’re going, how they will pay for the trip, where they will stay, whom they know in the United States, and more. Before any people who need a visa board a flight for the United States, a consular officer probes their story and checks their information against databases of law-enforcement and intelligence information.

The burden is on applicants to prove that they meet the requirements for getting a visa. If they live in a country where documents are hard to come by, the U.S. government doesn’t relax the rules. If they come from a country where forgeries are common, consular officers will be even more vigilant.

Simply put, we already have “extreme vetting” that keeps out those who would do harm: From 2002 to 2016, the Cato Institute has calculated, one deadly terrorist made it through for every 379 million decisions authorizing a foreigner to enter the United States.

Since around 2014, officials have looked at social-media accounts in certain cases. But there is no evidence that such checks have added value. That’s according to the government’s own assessments on the usefulness of social-media monitoring. A February 2017 report from the Homeland Security’s Office of Inspector General found that the social-media-vetting pilot programs that it evaluated “lack[ed] criteria for measuring performance to ensure they meet their objectives.” Other internal assessments have shown that officers had difficulty using social media to detect fraud or to pinpoint public-safety or national-security concerns. These findings are in line with the objections to social-media vetting that the Brennan Center for Justice, where the two of us work, and dozens of other organizations and experts have also raised. Scaling up social-media checks will only multiply these problems.

While social-media screening isn’t a dependable way to identify threats, it can be used to discriminate. The United States, despite its foundational commitment to free speech, has a long history of excluding people not because they endanger the American public, but because government officials don’t like their views. In the past, it barred Charlie Chaplin, Gabriel García Márquez, and future Canadian Prime Minister Pierre Trudeau.

This concern is particularly acute under the Trump administration. Candidate Trump promised an “ideological screening test … [to] screen out any who have hostile attitudes toward our country or its principles.” His first homeland-security secretary, John Kelly, went even further when he told Congress, “We want to get on their social media with passwords. What do you do? What do you say? If they don’t want to cooperate, then they don’t come in.” Indeed, the State Department has cited one of the executive orders containing Trump’s Muslim ban as a legal ground for its massive expansion of social-media screening. Against this backdrop, it is difficult to take much comfort in the department’s assurance that social media “will not be used to deny visas based on … race, religion, ethnicity, national origin, political views, gender, or sexual orientation.”

Moreover, the legal basis that the State Department cites means social-media information could be shared with foreign governments. It is not hard to imagine how repressive countries with which the United States shares intelligence—for instance, Saudi Arabia—could use social-media handles to identify and target activists and protesters.

Two years ago, the Supreme Court recognized the importance of social media as “for many … the principal sources for … speaking and listening in the modern public square, and otherwise exploring the vast realms of human thought and knowledge.” But when people think the government is watching, they self-censor and avoid saying things that may be regarded as controversial. Regardless of whether a consular official or an algorithm is doing the vetting, the State Department’s policy imposes real costs to free expression and democratic engagement across the globe. At a time when these basic freedoms are under attack in many countries, the push to gather and vet what people say online sends the message that America isn’t committed to these core principles.



The rise of fake news in the American popular consciousness is one of the remarkable growth stories in recent years—a dizzying climb to make any Silicon Valley unicorn jealous. Just a few years ago, the phrase was meaningless. Today, according to a new Pew Research Center study, Americans rate it as a larger problem than racism, climate change, or terrorism.

But remarkable though that may seem, it’s not actually what’s most interesting about the study. Pew finds that Americans have deeply divergent views about fake news and different responses to it, which suggest that the emphasis on misinformation might actually run the risk of making people, especially conservatives, less well informed. More than making people believe false things, the rise of fake news is making it harder for people to see the truth.

Pew doesn’t define what it calls “made-up news,” which is a reasonable choice in the context of a poll, but matters a great deal in interpreting it. The term has come to mean different things to different people. It was coined to describe deliberately false articles created by Potemkin news sites and spread on social media. But in a deliberate effort to muddy the waters, President Donald Trump began labeling news coverage that was unfavorable to him “fake news.” (Indeed, Pew finds that Americans blame politicians and their aides, more than the press, activist groups, or foreign actors, for the problem of made-up news.) Now when Trump’s supporters refer to “fake news,” they often seem to mean mainstream news they dislike, whereas when others do so, they mean bogus information spread by fringe actors.

If Pew’s data are taken to mean that people find this latter category more dangerous than climate change, that is almost certainly an overreaction. As the political scientist Brendan Nyhan wrote in February, summarizing the state of research in the field:

Relatively few people consumed this form of content directly during the 2016 campaign, and even fewer did so before the 2018 election. Fake news consumption is concentrated among a narrow subset of Americans with the most conservative news diets. And, most notably, no credible evidence exists that exposure to fake news changed the outcome of the 2016 election.

Pew finds a significant gap between Democrats’ and Republicans’ views on the seriousness of the problem with made-up news, though:

This looks a lot like a split over the definition of fake news, rather than the actual problem. Put differently, Republicans may well be responding not to out-and-out fakery, but to bias—real or perceived—in news coverage. It would make sense that conservatives would be primed to accept the idea of widespread bias in the press after a decades-long campaign against the credibility of the mainstream press. Indeed, Republicans are about three times more likely than Democrats (58 percent versus 20 percent) to say that journalists create a lot of fake news, though they still assign more blame to both politicians and activist groups.

How do people respond when they sense fake news? Here again, the partisan splits are notable:

It’s a positive sign that people are trying to fact-check stories themselves, though it’s an open question whether they’re any good at it. (Respondents thought little of their peers’ ability to find bad information, but believe that they, like the children in Lake Wobegon, are all above average: “Survey respondents also put a good deal more faith in their own ability to recognize potentially inaccurate or misleading information than they do in the broader public’s ability to discern it.”)

Some of the other choices are more troubling. One of the biggest risks often imputed to the current media environment, in which audiences can pick and choose news outlets that agree with them, is that people will become more and more siloed, cutting themselves off from information that they don’t like or that contradicts their prior assumptions.

The Pew study suggests that fake-news panic, rather than driving people to abandon ideological outlets and the fringe, may actually be accelerating the process of polarization: It’s driving consumers to drop some outlets, to simply consume less information overall, and even to cut out social relationships.

If people stop reading a website, because it’s peddling conspiracy theories, that’s good news. If they stop consuming any coverage from mainstream outlets like CNN or The Washington Post, because they believe a story is biased, or because the president has labeled it fake news, that’s less positive. While nearly six in 10 Democrats have dropped an outlet over perceived fake news, a full 70 percent of Republicans have. A much larger portion of Republicans has also reduced their overall consumption of news. The less politically aware are also 20 percent more likely to have reduced their overall consumption of news than the more politically aware—meaning that people who were already acquiring the least information are now acquiring even less.

Fully half of respondents said they had avoided talking with someone, because they thought that person might bring made-up news and information into the conversation. The numbers are roughly equivalent across parties—48 percent of Republicans, 51 percent of Democrats. It’s another example of an action that might seem rational under certain circumstances; no one should feel obliged to listen to an Alex Jones–listening relative’s Sandy Hook trutherism or a neighbor’s Louise Mensch–derived Trump conspiracy theories. But given the relatively small actual prevalence of true fake news, this figure is probably just another sign of people siloing themselves from information that challenges their assumptions.

Nor does Pew’s study offer much reason for optimism that these problems will fade anytime soon. The public’s solutions are fraught with contradictions. More than half of respondents said that journalists bear the most responsibility for fixing the problem (53 percent, versus 20 percent for the public, 12 percent for the government, and 9 percent for tech companies), and yet eight in 10 say limitations on made-up news and information—restrictions on free speech, in other words—are needed. Moreover, almost two-thirds of people said that political divisions are a big challenge to addressing made-up news. Yet the steps that they report taking themselves seem likely to only exacerbate those political divisions.



Here in the United Kingdom, milkshakes have replaced eggs as the protest projectile of choice. Activists have poured milkshakes on right-wing candidates for the European Parliament, resulting in some heated rhetoric. The Brexit Party leader and milkshaking victim Nigel Farage, for example, characterized the fad as a sign that “civilized democracy” no longer works. Police asked a McDonald’s in Edinburgh to stop selling milkshakes; angry pundits online accused Burger King of endorsing violence because it refused to stop selling them.

This is not a new phenomenon. Political figures have long been the target of tossed foodstuffs. Australian Prime Minister Billy Hughes was egged in 1917. British Prime Minister Harold Wilson was egged in 1970. The list of political figures egged, pied, caked, or tomatoed is not short. Most have taken it with good humor. Of course, one should never throw anything at anyone; that could easily amount to assault. But the idea that these acts are “mock assassinations” that could, perhaps, lead to actual assassinations, as the commentator Sam Harris seemed to suggest, is just a bit far-fetched.

I’m not sure if anyone can claim to be an expert in this exact niche, but I’ve spent more time than most worried about stuff being poured on or thrown at politicians. From 1996 to 2002, I worked for the White House Military Office as an adviser on chemical, biological, and radiological threats; and from 2002 to 2008, I was a physical-security specialist at the U.S. Secret Service, where it was my job to directly react to physical threats to the president, the White House, and other protected persons and places. I was assigned to the Hazardous Agent Mitigation and Medical Emergency Response team for more than four years, much of that as a team leader. I was the lead specialist for detection and identification equipment for most of that time.

I was trained to deal with a wide variety of scenarios. Unknown material thrown at the president or “the Beast”—his limo—figured high in our drills and training. Stuff happened. Not every day or every week, but on occasion. Eggs. Water balloons. Shaving cream. Someone tossed a Frappuccino at our van once. We spent a lot of money on equipment and capabilities, which I should not describe in any detail. But I can say that the first priority was to rapidly assess the situation. Was the thing being thrown actually a hazard? Was it a powder or a liquid? (We had different protocols for each.) Stuff on the limo was less urgent than stuff on a body. Was the protectee’s health affected? We used both snap judgment and technology. I messed around with eggs in our lab to see what happens if you put bad things in an egg. (Spoiler: It stops looking like an egg.)

The second priority was to help the protectee return to business as usual. Move on quickly, unless he or she actually needed medical care. President George W. Bush always had a spare set of clothes in the motorcade. If we were going to faff around testing liquid on a suit, we’d do it quietly out of sight and let the show go on. We wouldn’t stop the limo to test an egg; that’s silly. We’d quietly have a look at the next stop. Methodical discretion was better than overreaction.

Most of the time, we saw food projectiles as a form of protest or a juvenile misdeed, not as a serious act of violence. For all the paranoia among some of my colleagues about hydrofluoric acid inside of eggs, I never found any. The water balloon was a water balloon. The apparent Frappuccino contained coffee, milk, and sugar when I tested it, leading me to assess that it was, in fact, a coffee drink.

Let’s not lose perspective. Acts of political protest happen. Acts of political violence happen. There is some overlap between the two. But throwing a milkshake, while fundamentally inappropriate, uncivil, and possibly criminal (depending on the jurisdiction), isn’t the same thing as throwing a brick or shooting a rifle. Criminal law has degrees of offense ranging from simple assault to attempted murder and terrorism. The law has degrees of sanction ranging from strong words from a magistrate and a token fine all the way to life imprisonment or the death penalty in some places. “Milkshakes today. Bricks tomorrow. Petrol bombs next week,” as the soccer player Joey Barton put it on Twitter, takes all of this knowledge, experience, and jurisprudence—and shreds it.

Intent is an important element in assessing such a situation. Obviously, the perpetrator’s thoughts can be inscrutable. But we can infer much intent from the physical circumstances. One cannot construe intent to injure or kill from a milkshake. One could infer intent to cause damage to a suit, possibly. But not intent to cause actual bodily harm. A cold cup of coffee likewise. But a boiling hot cup of coffee? One can infer intent to harm in such a situation.

Let’s not go turning milkshakes into boiling coffee, let alone Molotovs. Sometimes a milkshake is just a milkshake.



In the summer of 1979, conservatives within the Southern Baptist Convention gathered in Houston for their annual meeting with the goal of seizing control of the nation’s largest Protestant denomination. These conservatives claimed that theological liberalism had taken root in the denomination’s seminaries and agencies, and was taking the group down the path of heresy. Seminary professors were openly questioning the historical accuracy of some of the Bible’s miraculous stories, such as Noah’s flood. Progressive churches were embracing the ordination of women and even debating accepting LGBTQ people into the life of the Church. These “problems” could be corrected only by a disruptive overhaul of leadership.

To shift the balance of power, these conservatives implemented a strategy that was as simple as it was genius: Recruit and assemble messengers who would attend the denomination’s annual meeting and vote for a handpicked conservative for the SBC presidency. The new president would, in turn, nominate only conservatives to serve on governing boards of seminaries and agencies. And finally, once conservatives controlled a majority share of these boards, they would replace establishment liberal leaders with conservative foot soldiers.

Some 15,000 Southern Baptist messengers gathered in Houston in 1979, and after the ballots were counted, a fiery 47-year-old conservative preacher named Adrian Rogers was elected president. His unparalleled command of rhetoric and uncompromising belief in the inerrancy of scripture made him the perfect person to inaugurate the conservative revolution. Rogers received only 51 percent of the vote over several other candidates, but that was enough. His election was the toppling of the first domino, triggering a purge of left-leaning leaders and churches from the denomination. Just like that, the Southern Baptist Convention was born again.

This week, the group gathers in Birmingham, Alabama, exactly 40 years since the Southern Baptist Convention as we know it came into existence. Just like many individuals of a similar age, the denomination is experiencing a bit of a midlife crisis, defined by a lack of purpose and deep internal conflict. Our rapidly changing world has, in the words of the Baylor University historian Barry Hankins, “thrust the group into the middle of an identity crisis.” In the early days of their revolution, conservative SBC leaders united around the common goal of defeating their left-leaning brethren. But the liberals are long gone now, leaving no enemies for these “battling Baptists” to fight—except themselves.

The SBC is contracting in both membership and church attendance. It has shed a stunning 1 million members since 2003, and is on pace to lose nearly 100,000 people each year for the foreseeable future. Annual baptisms, which are of obvious importance to Baptists, have plummeted to a 70-year low. Additionally, the denomination is failing to either attract new young people or retain the ones it has. Only half of children raised Southern Baptist choose to remain Southern Baptist. Although the denomination has made attempts to curb the decline through evangelism task forces and mission efforts, such tactics aren’t working as hoped.

There is no easy explanation for this decline. You can’t merely blame secularization or chalk it up to the growing number of religiously unaffiliated people in America, because evangelicals in general have increased in number. So what gives? Underneath the numeric slippage lies a more substantive problem: cultural irrelevance. The denomination used to contribute to, or even drive, conversations on the day’s most pressing issues. At the height of the conservative takeover, the goings-on in the denomination were closely monitored by national media and regularly covered by network nightly news programs such as ABC’s Nightline. In 1985, the wildly popular daytime-TV host Phil Donahue devoted an entire show to the denomination. Now only a handful of religion journalists are paying close attention. The world has moved on.

Conservative leaders who clutched control of the group decades ago were nearly unified in their convictions and hyper-focused on their chosen mission. Today the group is fractured and endlessly consumed by infighting. It’s fought over the growing influence of Calvinism, a theological system based on the teachings of John Calvin. It’s fought over whether its Christian faith means it should care about “social justice” issues. And just recently, it’s fought over whether a woman can teach or preach in a Sunday church service. Cultivating a fresh vision for the future is difficult when you’re preoccupied with putting out fires.

In the past, the election of a Republican president would have unified a conservative group such as the SBC, infusing it with fresh energy. But Donald Trump’s election further fractured the group instead. Some prominent Southern Baptist pastors—including Robert Jeffress and Jack Graham—vocally supported Trump for his conservative positions on issues such as abortion and his promise to appoint conservative judges. But many others—such as Russell Moore, the head of the denomination’s public-policy arm—could not stomach the thrice-married, foul-mouthed, serial-lying candidate’s poor character. (Moore’s opposition so angered Graham and others that it nearly cost Moore his job.) When Vice President Mike Pence was invited to speak at last year’s annual gathering, many pastors protested.

Nothing said here will come as a surprise to most Southern Baptist leaders, particularly younger ones. They see their crisis as clearly as outsiders do. Last year, Southern Baptists elected the North Carolina pastor J. D. Greear as their president in hopes of ushering in “a new day in the SBC.” At 45 years old, Greear is one of the youngest men elected to the post, and he has asserted his desire to call off the culture war and partisan politics. He wants to promote “racial reconciliation and cultural diversity.” But as Greear concludes his first term, little seems to have changed.

Perhaps his election was a cosmetic solution to an existential problem, a change akin to a middle-aged friend purchasing a cherry-red sports car. The hum of the Corvette engine is exciting at first, but in a blink, you realize that the same person with the same problems is behind the wheel. Southern Baptists can’t simply vote their way to revival this time. They must do some deep self-examination and get their house in order.

This week in Birmingham, Southern Baptists have an opportunity to do just that. The emerging sexual-abuse crisis in the denomination should undoubtedly be the first priority. An investigation released by the Houston Chronicle in February revealed decades of sexual abuse and a pattern of repeat offenders stretching back decades and affecting hundreds of victims. New revelations continue to emerge, and Southern Baptists should expect this story to get worse, not better, for them.

Though Greear has made several proposals for seriously addressing the matter, denominational leaders are split. Some claim that Southern Baptist churches are autonomous and that the denomination has no place interfering in the matter. Others believe that sexual abuse demands a serious response, including restitution for victims. The latter have the better argument.

The Roman Catholic Church’s failure to adequately respond to its sexual-abuse scandal has had devastating effects. Donations have dropped, members’ faith in clergy has fallen, and the total number of Catholics in America has plummeted by more than 3 million since 2007 alone—more than any other religious group. Parents will avoid any space, no matter how sacred, if they question the safety of their children, and few people will donate their hard-earned money to an institution they don’t respect and trust. Southern Baptists must learn from Catholics’ mistakes and deal aggressively with this scandal in its early stages.

According to the psychoanalyst Erik Erikson, midlife marks a period of time when one must choose between “stagnation” and “generativity.” You can stay the course, retreating to a life of nostalgia, regret, and fear. The other option is to accept the new normal, stop trying to reclaim past glories, and transform to meet the needs of the moment. For Southern Baptists, a posture of generativity would require leaders to refocus on the emerging moral issues of our age.

Few issues are more relevant now than racial division. The Southern Baptist Convention, which was founded over the issue of slavery and was mostly supportive of segregation and Jim Crow laws, is still 85 percent white. It issued an apology for its racist past in 1995, but the group struggled to pass resolutions condemning white supremacy and the Confederate flag. As Greear wrote, “In theory, very few people in the American church are opposed to the idea of racial and cultural diversity. But experience would suggest that on this issue good intentions do not equal forward progress.”

When the denomination’s executive committee, which oversees the day-to-day business of the denomination, set about selecting a new leader this year, many minority leaders pressed for a person of color as a tangible marker of progress. The suggestions were disregarded, and instead the committee selected Ronnie Floyd, a white Baby Boomer from Arkansas. When a prominent black Baptist pastor criticized Trump for racist remarks in which the president called Caribbean and African nations “shithole countries,” he was largely ignored. Several prominent Southern Baptist pastors continue to serve on Trump’s religious advisory council. This kind of tone deafness by white Southern Baptist leaders sends a message to people of color that the denomination does not take their concerns seriously.

And what about the dignity and equality of women? The SBC has bombed in that department as well. Last year, troubling allegations emerged about the revered Southern Baptist leader Paige Patterson. Recordings of his sermons revealed Patterson body shaming a young woman and downplaying domestic abuse. For weeks, the Southern Baptist old guard rallied around their friend, even in the face of a petition calling for his resignation signed by thousands of Southern Baptist women. Finally, evidence emerged that Patterson had mishandled an abuse allegation at a seminary he led and he was terminated.

Recently, the wildly popular Bible teacher Beth Moore was bullied online by prominent Baptist leaders and bloggers for teaching men in a Sunday church service. Attacks on Moore grew so intense that The Washington Post reported that the issue was dominating official denominational discussions. Southern Baptist teaching holds that the office of the pastor is reserved for males, and some parishioners presumably wouldn’t support a woman preaching in their church. But what message does it send that such a petty matter sparked such furor? Given that half of Southern Baptists are women, the denomination must find ways to elevate women, affirm women’s gifts, and oppose gender-based violence and discrimination.

For some, discussions about reinventing the Southern Baptist Convention elicit fear that conservative control is slipping away. But they can no longer be avoided. If the decline continues and leaders remain unable or unwilling to make changes, America’s largest denomination won’t just be over the hill; it’ll be in the grave.



“We have won the election,” Pedro Sánchez, the leader of the Spanish Socialist Workers’ Party (PSOE), told a jubilant crowd at his party’s headquarters on Sunday night. “The future has won and the past has lost.”

Much of the campaign leading up to Spain’s third national election in four years did indeed feel like an argument over the country’s history. Sánchez presented himself as a strong advocate for a clean break with the past: If he were reelected, he vowed, he would literally exhume General Francisco Franco, the fascist dictator who ruled the country until his death in 1975, from his resting place in a massive shrine to fascist martyrs.

This pledge set up a clear contrast with Spain’s major right-wing parties. The PSOE’s traditional rival, the conservative People’s Party (PP), has at times soft-pedaled criticism of the Franco regime in an attempt to mollify his present-day admirers. Meanwhile, a new far-right party has shocked the country’s establishment by waxing nostalgic for Spain’s authoritarian past in a much more open manner; the leaders of Vox have vowed to “make Spain great again”—a rather complicated proposition in a country that was ruled by fascists less than half a century ago.

In this contest of historical visions, the left enjoyed a rare victory on Sunday. The PSOE won 29 percent of the vote, nearly twice as much as the PP. With the support of Podemos, a far-left populist movement, and a smattering of regional parties pursuing greater autonomy from Madrid, Sánchez is likely to cobble together a governing coalition—which makes him the first center-left politician in about half a decade to win a reasonably clear mandate in a major European country.

Sánchez can, then, be forgiven for overstating the significance of his victory. And yet his proclamation was at least as interesting for what it got wrong as for what it got right.

In truth, the victory of the PSOE is, at best, a qualified triumph. As recently as a decade ago, the Spanish political system had, in effect, been divided between its two major parties, which usually enjoyed a cumulative vote share of more than 80 percent. Elections often marked a peaceful transition of power between coherent ideological blocks: When the allure of the center-left faded, voters handed the baton to the center-right, and vice versa.

Over the past few years, extreme fragmentation—there are now a total of 14 political parties in Madrid’s Cortes Generales—has rendered such cohesive governments impossible. To govern, Sánchez will not only have to accommodate the populists of Podemos, who have at times fanned the flames of Euroskepticism and until recently vowed to emulate Hugo Chávez’s government in Venezuela. As important, he will also need to rely on the support of a smattering of regional parties that openly aim to break up the country.

In the best-case scenario, Sánchez will negotiate a deal that grants regions such as Catalonia and the Basque Country a little more autonomy without setting them on a path to full independence. In the worst-case scenario, which is perhaps more likely, his prospective coalition partners won’t be satisfied with anything short of a referendum on full independence, leading to a collapse of his government if Sánchez stands firm—or to Spain’s disintegration if he caves.

Moreover, far from marking a clear rejection of the fascist past, the Spanish election can just as easily be understood as a sign that the lessons of the postwar period have lost their hold over European politics. The past hasn’t lost, in other words; it’s just been forgotten.

When I spoke with leading German politicians in the fall of 2016, the refugee crisis was dominating headlines and the far-right Alternative for Germany (AfD) enjoyed double-digit support in the polls. Even so, many of my sources predicted that the AfD would fail to clear the country’s 5 percent hurdle in national elections scheduled for the spring of 2017, and quickly disintegrate even if it did. Germany, they told me, had learned the lessons of the Third Reich. A far-right party that plays with nostalgia for the Nazi past could not possibly carve out a significant place for itself in the German political landscape.

Sadly, that prediction turned out to be wide of the mark. As the polls foretold, the AfD became the country’s third-biggest party within the year; it is now represented in all of Germany’s state parliaments as well as the Bundestag. Signs of its imminent demise are conspicuous by their absence. Seventy-five years after World War II, the German taboo against far-right politics has been breached.

The rise of the AfD left Spain as the last major European country without a significant far-right presence in its politics. And though the country had never reckoned with its past as thoroughly as Germany, local political elites were just as convinced that a proudly far-right party could not gain a large national following. It turns out that they were just as wrong as their counterparts in Berlin: After a meteoric rise in regional elections, Vox gained 10 percent of the vote on Sunday, proving that it has significant national appeal. Though Vox did not “win” the elections, its ascent was the day’s most significant development—more than the PSOE’s victory—one that marks a true turning point in Spain’s, and Europe’s, attitude toward the past.

In retrospect, it is perhaps remarkable just how long a shadow World War II has cast over European politics. When I was born in 1982, the Communist system that the Soviet Union had, in the war’s immediate aftermath, imposed upon the continent’s eastern half seemed unlikely to collapse anytime soon. Meanwhile, the liberal democracies in its western half looked remarkably stable, in part because the brutal reality of totalitarianism had robbed extremists of the allure they had once enjoyed. Both systems, in their own ways, were based on an explicit rejection of the fascist politics that had led the continent on the path to perdition.

In 2000, when I turned 18, the fault lines of World War II no longer marked the continent as starkly, but the war’s lessons seemed to mark its politics even more deeply: In Central and Eastern Europe, citizens who had purchased their freedom with decades of suffering could be counted upon to guard it jealously. Meanwhile, the political culture of Western European countries—especially those, such as Germany, that bore the heaviest historical responsibility for World War II, or those, such as Spain and Portugal, that had been ruled by fascists well into the 1970s—seemed committed to moderation. The suffering of the past would, at least, ensure that the far right would never again gain a real seat at the political table.

Two decades into the 21st century, both of these assumptions have turned out to be wishful illusions. Across Central Europe, citizens have freely elected authoritarian populists. Meanwhile, countries that thought they were immune to the resurgence of the far right are finding out that the salutary effects of their violent past have started to fade.

When Sánchez said that the past had lost, he meant that his country had firmly rejected the far right. As the ascendance of Vox demonstrates, that is a dangerous piece of hubris. But in a more literal sense, Sánchez may have been more correct than he realized: After three-quarters of a century in which the legacy of World War II shaped the basic categories of the continent’s politics, its lessons are being thrown overboard.

Europe’s long 20th century is coming to an end. The past is lost—and the future is far less certain than many European politicians appear to grasp.



On March 1, 2016, Donald Trump pointed to a group of protesters at a campaign rally in Louisville, Kentucky, and said “Get ‘em out of here,” piously adding, “Don’t hurt ‘em.” Supporters assaulted the protesters as they were led out.

The protesters later sued Trump for “incitement to riot”; a panel of the Sixth Circuit dismissed the claim: “The mere tendency of speech to encourage unlawful acts” is not “sufficient reason for banning it.” Even if Trump had intended to encourage violence, the First Amendment still protected him, unless “the words used specifically advocated the use of violence, whether explicitly or implicitly.”

The decision was correct; the Supreme Court has repeatedly held that public protest, and even advocacy of violence, is protected by the First Amendment unless clearly intended to cause immediate violence. But a three-judge panel of the Fifth Circuit, in a case decided last week, seemed to see things otherwise; it made a mockery of Court precedent even as it reached back to revive an old segregation-era tactic: civil lawsuits to intimidate protesters.

On July 9, 2016, a group of Black Lives Matter activists blocked the highway in front of the Baton Rouge, Louisiana, police-department headquarters to protest the July 5 killing of Alton Sterling. Someone threw a hard object at police, injuring a Baton Rouge Police Department officer, who later reported “loss of teeth, a jaw injury, a brain injury, a head injury, lost wages, ‘and other compensable losses.’”

DeRay Mckesson, a high-profile, Baltimore-based Black Lives Matter organizer, was arrested along with more than 100 others. The anonymous officer, referred to as John Doe, sued Mckesson and the entire Black Lives Matter movement, alleging that “Mckesson did nothing to prevent the violence or to calm the crowd” and that he “incited the violence.”

Doe’s 17-page complaint portrays the Black Lives Matter movement as a violent nationwide conspiracy. But nowhere does it allege a specific word or action taken by Mckesson that led to or caused the violence in Baton Rogue. The closest it gets is: “Black Lives Matter leadership ratified all action taken during the protest. DeRay Mckesson ratified all action taken during the Baton Rogue protest.”

A federal district judge dismissed the lawsuit in September 2017. Plaintiffs can’t sue an entire social movement, the judge noted (“#BlackLivesMatter”—a hashtag—lacks the capacity to be sued,” he wrote); as for Mckesson, “The only public speech to which Plaintiff cites in his Complaint is a one-sentence statement that Mckesson allegedly made to The New York Times: ‘The police want protestors to be too afraid to protest.’” Those words, the judge wrote, “do not advocate—or make any reference to—violence of any kind.”

At that point, Doe v. Mckesson seemed like one of hundreds of nuisance lawsuits filed every year. Press coverage was desultory; the civil-liberties groups I reached out to last week had barely registered it.

A panel of the Fifth Circuit Court of Appeals held the case from late 2017 until last week, when, without allowing oral argument, the panel reinstated the lawsuit. It said that the officer, if he proves his claims, could collect damages because “Mckesson breached his duty of reasonable care in the course of organizing and leading the Baton Rouge demonstration.” Because blocking a highway is against the law, “Mckesson should have known that leading the demonstrators onto a busy highway was most nearly certain to provoke a confrontation between police and the mass of demonstrators, yet he ignored the foreseeable danger … and notwithstanding did so anyway.” Someone else threw the object; there was no evidence that Mckesson urged anyone to throw anything. Nonetheless “Mckesson’s negligent actions were the [factual] causes of Officer Doe’s injuries.”

The Fifth Circuit panel’s decision is clearly wrong under the law as it now stands. There can be no liability, civil or criminal, for speech that “incites” violence unless the defendant can be shown to have intentionally urged violence, knowing that listeners would likely respond immediately with violent behavior.

Here’s the opinion’s entire discussion of the First Amendment: “The First Amendment does not protect violence.” This, while true, is irrelevant. Mckesson isn’t accused of any violent act. He’s accused of “negligently” leading a protest at which someone else became violent.

Last I checked, “negligent protest” wasn’t really a thing in America. I could find only one reference to the idea in the case law—in a 1987 case decided by the Fifth Circuit. In that case, a family alleged that Hustler magazine had caused their son to asphyxiate himself as part of sex. “Mere negligence, therefore, cannot form the basis of liability under the incitement doctrine any more than it can under libel doctrine,” Judge Alvin Rubin wrote for a two-judge majority.

There’s a good reason for that. Imagine you want to protest a highway being built near your house. You and your neighbors organize a demonstration. Someone you don’t know throws a rock. Under the negligence rule, you become personally liable for any injuries it causes. It would take a lot of courage to organize protests in a country where that was the rule. A tort verdict, plus lawyer fees, could easily bankrupt an ordinary family.

In a statement, Alanah Odoms Hebert, the executive director of the Louisiana chapter of the ACLU, put it this way: “The principles outlined in this decision put civil disobedience at risk. If this doctrine had existed during the civil rights movement there would not have been a civil rights movement.” John Paul Schnapper-Casteras, a former appellate counsel for the NAACP Legal Defense and Educational Fund, sounded much the same note in an email to me: “The Fifth Circuit seems to embrace a broad theory of negligence to suggest that it’s plausible to impose liability upon a non-violent protestor/organizer for the violent actions of a third party. If that were the law of the land, it could be at odds with America’s long history of protesting and marching in the streets.”

These concerns aside, the Fifth Circuit twisted the meaning of that single reference to the First Amendment. “The First Amendment does not protect violence” comes from NAACP v. Claiborne Hardware, which arose in 1966 when the NAACP in Claiborne County, Mississippi, called on black people in the area to boycott white-owned stores. In a rally supporting the boycott, the civil-rights leader Charles Evers told the crowd that “if we catch any of you going in any of them racist stores, we’re gonna break your damn neck.” When, later on, someone fired through the window of a home and smashed a car windshield, local merchants filed a tort suit (like Doe’s) alleging that the NAACP was engaged in an illegal boycott and that Evers and other leaders had threatened violence to enforce it. Mississippi state courts decided that the association and its leaders were liable for the merchants’ lost profits. Appeals dragged on until 1982, when the Supreme Court ordered the case dismissed on First Amendment grounds.

The Court did use the words The First Amendment does not protect violence—but only to make clear that neither the boycott nor Evers’s speech could be the basis for a lawsuit. When “violence and … threats of violence” occur “in the context of constitutionally protected activity,” that context “imposes restraints” on what and whom tort law may punish, wrote Justice John Paul Stevens.

Thus, no leaders of the boycott could be sued unless the plaintiffs could show that they had “authorized, directed, or ratified specific tortious activity,” explicitly “incited” violence, or ordered others to carry out violent acts. That couldn’t be shown in Claiborne Hardware. 

Claiborne Hardware was one of several cases that established the robust speech protections most protesters take for granted today. When Alabama sued the NAACP to demand a list of its members, the Supreme Court sided with the NAACP in 1957. When Virginia sued the NAACP because it actively solicited plaintiffs for test cases, the Court sided with the NAACP in 1963. Then southern authorities, including police officials, filed libel suits against northern news organizations—and local civil-rights workers—who criticized southern governments in out-of-state news media. In 1965, the landmark case of New York Times v. Sullivan guaranteed the right to criticize officials without fear of massive libel judgments.

Now a panel of the Fifth Circuit has reopened the argument more or less out of a clear blue sky. One can only speculate on why these three judges—appointed by Ronald Reagan, George W. Bush, and Donald Trump—have decided that the First Amendment needs a working-over and that now is the time to do it. Certainly, the ordinary restraints of case law are slipping their moorings in the Trump era. The Fifth Circuit last year openly defied Roe v. Wade and Planned Parenthood v. Casey; the Supreme Court majority cringed in front of the administration in the “travel ban” case; Justice Clarence Thomas has recently called for the Court to overrule New York Times v. Sullivan.

The past two years have been a kind of national Walpurgisnacht, calculated to summon the worst impulses of conservative jurists. We own the courts now, an inner voice may be whispering; no need for precedent or even explanation. Doe v. Mckesson may be an anomaly, but it also may be a straw in a very chill wind.



The Iraq War of 2003 was undone by blithe assumptions, cultural ignorance, and careless planning. But compared with the accelerating drive to confront Iran, the Iraq War looks like a masterpiece of meticulous preparation.

The project of a war with Iran is so crazy, it remains incredible that Donald Trump’s administration could truly be premeditating it. But on the off, off chance that it is, here’s a word of caution from a veteran of the George W. Bush administration: Don’t do it.

I supported the Iraq War in 2003 because I believed the Bush administration’s case that Iraq was again actively seeking to acquire nuclear weapons. (A first program had been destroyed by Israeli warplanes in 1981; a second had been halted by UN inspectors after the Gulf War of 1990–91.)

Yet the goal in 2003 was bigger than denuclearization. Iraq’s Saddam Hussein was both oppressing his own subjects and menacing his neighbors. By replacing Saddam’s regime with a more humane and peaceful successor, the U.S. could set the Arab Middle East on a path to a better future—contributing to America’s own security after 9/11.

Had the U.S.-led coalition against Saddam achieved those things, the world would indeed be a better place. It is an unknowable question whether, with more resources and wiser decisions, those things could have been achieved. It is also a futile question. The American political system of 2003 was not going to provide more resources, and even in retrospect, it is difficult to identify what wiser decisions could have delivered better success in Iraq.

To paraphrase Donald Rumsfeld, you go to war with the decisions you have made, not the decisions you wish you would have made with better hindsight.

I believe that those of us who advocated the war, whether inside or outside government, carry lifelong responsibility for that advocacy. You do not disburden yourself of that responsibility by changing your mind after the fact. What matters to posterity are the things you said and did at the hour of decision. You cannot revoke the irrevocable.

I still think President Bush did right to warn the world of an “axis of evil” in his 2002 State of the Union address, a speech to which I made some modest contributions. (I tell the story in a memoir, The Right Man.) Back then, it was controversial to claim that North Korea was proliferating weapons technologies to Iran and Syria, or that Shiite Iran armed and supplied Sunni Hamas. These things are now universally known. But the step from describing the problem to acting on it was large and inadequately considered.

Inside the Bush administration, we thought we were ready to remake Iraq for the better—but we were not. We were ignorant, arrogant, and unprepared, and we unleashed human suffering that did no good for anyone: not for Americans, not for Iraqis, not for the region. Almost two decades later, the damage to America’s standing in the world from the Iraq War has still not been repaired, let alone that war’s economic and human costs to the United States and the Middle East.

The idea of repeating such a war, only on a much bigger scale, without allies, without justification, and without any plan at all for what comes next staggers and terrifies the imagination.

The Trump administration is very probably bluffing in its current menaces to Iran. President Trump dislikes foreign military interventions and has tried to withdraw American forces from Syria and Afghanistan. It seems unlikely that he would willingly launch a major war against a near-nuclear state of more than 80 million people. But bluffs do get called—and then the bluffer must rapidly make some hasty calculations. Wars of words can escalate into real wars, real fast.

If the goal of some inside the administration is to goad Iran into striking first—thus forcing Trump’s hand—that’s a ruse that risks igniting a conflict much bigger than the one with Iraq, and one even less likely to succeed.

In 2003, Vice President Dick Cheney’s now notorious promise, “We will, in fact, be greeted as liberators,” had solid basis in plausibility. Shiite Iraqis had risen in arms against Saddam Hussein’s regime after the Gulf War of 1990–91. By 2003, Iraqi Kurdistan was a more or less autonomous region, hostile to the regime. The Iraqi government was regionally isolated: friendless and feared. Its military and security forces were broken and unreliable.

Standing up a new Iraqi regime post-Saddam looked like a plausible project. A large Iraqi diaspora had formed a National Congress. Oil prices in 2003 had slumped to historic lows, promising a surge of new revenues to rebuild a post-Saddam Iraq once oil markets returned to more normal levels.

To invade Iraq, President George W. Bush asked for and got a congressional authorization to use force. He sought and received enabling resolutions from the United Nations. He built a military coalition that included not only the United Kingdom but many other allies, notably Australia, Poland, and Spain. U.S. allies who opposed the decision to use force—notably Germany and Canada—nonetheless pledged postwar assistance to a post-Saddam Iraq. Bush mobilized domestic public opinion behind him as well. More than half of Americans approved of the decision in the months leading up to the war, a number that rose to two-thirds on the eve of the conflict, and hit three-quarters the day after hostilities began. Leading Democrats in Congress—including the future presidential candidates John Kerry and Hillary Clinton—cast their vote in favor of the effort.

None of this was sufficient to bring success. But it was all a lot more than has been done to prepare for a conflict with Iran in 2019.

Trump has no legal authority of any kind to wage war against Iran—not from Congress, not from the UN. He has no allies, and has in fact imposed trade punishments on the European Union, Canada, Mexico, South Korea, and many others, above and beyond the escalating trade conflict with China. America’s most militarily capable ally, the United Kingdom, is paralyzed by the Brexit process, which Trump did everything in his power to urge forward.

The supposed provocations by Iran cited by administration sources as the reason for a U.S. response look petty, even assuming they are genuinely Iran’s doing.

Iran is a formidable state, home to a great civilization. And while the Iranian regime has acquired even more regional enemies than 2003 Iraq, its interests also converge in ways Iraq’s never did with the interests of other major powers, Russia most of all.

Iran’s theocratic state rightly inspires protest and complaint inside Iran. But there’s no evidence that Iranians would welcome military action by foreigners against their cities and military. The regime can mobilize shows of support and participation when it wants to. It rules by repression, not by terror. The regime has demonstrated global reach, sponsoring terror attacks in Europe and Argentina. U.S. officials have alleged that Iran even planned an assassination attempt against the Saudi ambassador to Washington in 2011. If the U.S. attempts surgical air strikes, Iran has proved it can retaliate against American allies. And if the Trump administration intends outright regime change, it has evidently done none of the requisite planning.

The administration has not made any public case for war. What would that case sound like, if anybody bothered to articulate it? By 2003, Iraq had spent more than a decade repeatedly cheating on the terms of the 1991 cease-fire that ended the first Gulf War. It had menaced Kuwait again in 1994, carried on forbidden military operations against the Kurds, been caught in a clandestine chemical and biological program in 1996, and evaded sanctions via a complex system of bribes and payoffs.

But in 2019, the U.S. is the international scofflaw. It ripped up a multilateral nuclear arms–control agreement with Iran. Whatever that treaty’s deficiencies, few inside the U.S.—and nobody outside it—deny that Iran complied with its terms. Iran’s behavior in Syria, Yemen, Iraq, Lebanon, and Gaza is vicious and destructive, as it has been for decades. But where’s the casus belli here? What declared-in-advance U.S. red lines has Iran tripped? Any U.S. military action will look to the world like a bolt-from-the-blue act of aggression. It will look that way for the excellent reason that it’s precisely what it would be.

In any conflict with Iran, the U.S. would find itself without allies except for Israel and the Gulf states. The Trump administration would find itself even more isolated politically at home. Most Americans do not support, trust, or respect Trump's leadership. There is no Colin Powell–like figure in this administration, no senior official who commands respect across party lines. Pitifully few people in this administration command respect even within party lines. The administration’s record of casual incompetence at minor tasks raises terrifying questions about its capacity for a gigantic undertaking like a land war against a Central Asian state.

Even as a bluff, the war talk violates the rule: Don’t threaten to do something so obviously stupid, nobody will believe that you would actually deliver on your threat. You get the worst of all worlds in that case. The threat will not frighten, because it will not be believed. That, in turn, will either push you to do the obviously stupid thing you never intended to do, or force you to walk away from your threats and expose yourself as a bullying blowhard.

If you will not do it, you should not talk about it. If you are thinking about doing it, stop. And if you are talking without thinking? The U.S. and the world have had more than enough of that from Washington, and not only since January 2017.



If grisly images stay up on Facebook or YouTube long enough, self-appointed detectives around the world sometimes use them to reconstruct a crime scene. In July 2017, a video capturing the execution of 18 people appeared on Facebook. The clip opened with a half-dozen armed men presiding over several rows of detainees. Dressed in bright-orange jumpsuits and black hoods, the captives knelt in the gravel, hands tied behind their back. They never saw what was coming. The gunmen raised their weapons and fired, and the first row of victims crumpled to the earth. The executioners repeated this act four times, following the orders of a confident young man dressed in a black cap and camouflage trousers. If you slowed the video down frame by frame, you could see that his black T-shirt bore the logo of the Al-Saiqa Brigade, an elite unit of the Libyan National Army. That was clue No. 1: This happened in Libya.

Facebook took down the bloody video, whose source has yet to be conclusively determined, shortly after it surfaced. But it existed online long enough for copies to spread to other social-networking sites. Independently, human-rights activists, prosecutors, and other internet users in multiple countries scoured the clip for clues and soon established that the killings had occurred on the outskirts of Benghazi. The ringleader, these investigators concluded, was Mahmoud Mustafa Busayf al-Werfalli, an Al-Saiqa commander. Within a month, the International Criminal Court had charged Werfalli with the murder of 33 people in seven separate incidents—from June 2016 to the July 2017 killings that landed on Facebook. In the ICC arrest warrant, prosecutors relied heavily on digital evidence collected from social-media sites.

Werfalli has thus far evaded justice. But human-rights activists still hail the case as a breakthrough for a powerful new tool: online open-source investigations. Even in no-go combat zones, war crimes and other abuses often leave behind an information trail. By piecing together information that becomes publicly accessible on social media and other sites, internet users can hold the perpetrators accountable—that is, unless algorithms developed by the tech giants expunge the evidence first.

Shortly after the Werfalli arrest warrant was issued, Hadi Al Khatib, a Syrian-born open-source investigator based in Berlin, noticed something that distressed him: User-generated videos depicting firsthand accounts from the war in Syria were vanishing from the internet by the thousands. Khatib is the founder of the Syrian Archive, a collective of activists that, since 2014, has been scouring for digital materials posted by people left behind in Syria’s war zone. The Syrian Archive’s aim is “to build a kind of visual documentation relating to human-rights violations and other crimes committed by all sides during the eight-year-old conflict,” Khatib said in an interview.

In the late summer of 2017, Khatib and his colleagues were systematically building a case against the regime of Bashar al-Assad in much the same way ICC investigators pursued Werfalli. They had amassed scores and scores of citizens’ accounts, including video and photos that purportedly showed Assad was targeting hospitals and medical clinics in bombing campaigns. “We were collecting, archiving, and geolocating evidence, doing all sorts of verification for the case,” Khatib recalled. “Then one day we noticed that all the videos that we had been going through, all of a sudden, all of them were gone.”

It wasn’t a sophisticated hack attack by pro-Assad forces that wiped out their work. It was the ruthlessly efficient work of machine-learning algorithms deployed by social networks, particularly YouTube and Facebook.

With some reluctance, technology companies in Silicon Valley have taken on the role of prosecutors, judges, and juries in decisions about which words and images should be banished from the public’s sight. Lately, tech companies have become almost as skilled at muzzling speech as they are at enabling it. This hasn’t gone unnoticed by government entities that are keen to transform social networks into listening posts. Government, in effect, is “subcontracting” social-media platforms to be its eyes and ears on all kinds of content it deems objectionable, says Fionnuala Ní Aoláin, a law professor and special rapporteur for the United Nations Human Rights Council.

But some of what governments ask tech companies to do, such as suppressing violent content, cuts against other legitimate goals, such as bringing warlords and dictators to justice. Balancing these priorities is hard enough when humans are making judgments in accordance with established legal norms. In contrast, tech giants operate largely in the dark. They are governed by opaque terms-of-service policies that, more and more, are enforced by artificial-intelligence tools developed in-house with little to no input from the public. “We don’t even know what goes into the algorithms, what kind of in-built biases and structures there are,” Ní Aoláin said in an interview.

For years, social networks relied on users to flag objectionable content, all manner of hate speech, and calls to arms that, among other things, espoused violence. But as this content continued to fill up the fringes and spill into clear sight, pressure mounted on Facebook, YouTube, Twitter, and other popular social networks to automate the cleanup. They turned to machine learning, a powerful subset of artificial intelligence that can make sense of huge amounts of data with little to no oversight from human minders.

Designed to identify and take down content posted by “extremists”—“extremists” as defined by software engineers—machine-learning software has become a potent catch-and-kill tool to keep the world’s largest social networks remarkably more sanitized places than they were just a year ago. Google and Facebook break out the numbers in their quarterly transparency reports. YouTube pulled 33 million videos off its network in 2018—roughly 90,000 a day. Of the videos removed after automated systems flagged them, 73 percent were removed so fast that no community members ever saw them. Meanwhile, Facebook removed 15 million pieces of content it deemed “terrorist propaganda” from October 2017 to September 2018. In the third quarter of 2018, machines performed 99.5 percent of Facebook’s “terrorist content” takedowns. Just 0.5 percent of the purged material was reported by users first.

Those statistics are deeply troubling to open-source investigators, who complain that the machine-learning tools are black boxes. Few people, if any, in the human-rights world know how they’re programmed. Are these AI-powered vacuum cleaners able to discern that a video from Syria, Yemen, or Libya might be a valuable piece of evidence, something someone risked his or her life to post, and therefore worth preserving? YouTube, for one, says it’s working with human-rights experts to fine-tune its take-down procedures. But deeper discussions about the technology involved are rare.

“Companies are very loath to let civil society talk directly to engineers,” says Dia Kayyali, a technology-advocacy program manager at Witness, a human-rights organization that works with Khatib and the Syrian Archive. “It’s something that I’ve pushed for. A lot.”

These concerns are being drowned out by a counterargument, this one from governments, that tech companies should clamp down harder. Authoritarian countries routinely impose social-media blackouts during national crises, as Sri Lanka did after the Easter-morning terror bombings and as Venezuela did during the May 1 uprising. But politicians in healthy democracies are pressing social networks for round-the-clock controls in an effort to protect impressionable minds from violent content that could radicalize them. If these platforms fail to comply, they could face hefty fines and even jail time for their executives. New Zealand Prime Minister Jacinda Ardern and French President Emmanuel Macron intend to up the ante at a summit next week calling on tech execs and world leaders to band together to eliminate the publication of extremist online content. After the March 15 mosque massacre in Christchurch, New Zealand, was streamed live on Facebook, countries including New Zealand, Australia, and the United Kingdom passed or proposed comprehensive new online-terror laws.

A proposed European Union law has been in the works for months. It would require technology companies to pull down harmful user-generated material—whether words or images—that “incites or solicits the commission or contribution of terrorist offenses, or promotes the participation in activities of a terrorist group.” That standard is extraordinarily broad. But if the companies don’t eliminate such posts within one hour, they face fines of up to 4 percent of global revenues.

Human-rights advocates worry about the decisions tech giants and their algorithms will make under such outside pressure. “The danger is that governments will often get the balance wrong,” argued Ní Aoláin. “But actually we have the methods and means to challenge governments when they do so. But private entities? We don’t have the legal processes. These are private companies. And the legal basis upon which they regulate their relationships with their users, whether they’re in conflict zones or not, is determined by [the company’s] terms of service. It’s neither transparent nor fair. Your recourse is quite limited.”

In July, she wrote an open letter to Facebook’s founder, Mark Zuckerberg, finding fault with how Facebook defines terrorism-related content, a key determination in what it decides to flag and take down. From what Ní Aoláin can tell, “they just came up with a definition for terrorism that bears no relationship to the global definition agreed by states, which I think is a very dangerous precedent. I made that very clear in my communications with them.”

When I asked Facebook to comment on Ní Aoláin’s complaint, a company spokesperson shared detailed minutes from a December content-standards forum. The minutes are a remarkable document, one that underscores the complexity of the judgments tech companies are being asked to make as they seek to monetize human interactions on a global scale. Is a terrorist organization one that “engages in premeditated acts of violence against persons or property,” or should the definition expand to include any non-state group that “engages in or advocates and lends substantial support” to “purposive and planned acts of violence”? “It would shock me,” one person at the meeting commented, “if in a year we don’t come back and say we need to refine this definition again.” (A company spokesperson said recently that there’s no update on the matter to announce.)

How the tech giants’ algorithms will implement these subtle standards is an open question. But a new crop of anti-terrorism bills, post-Christchurch, will thrust technology companies into an even more assertive enforcement role. Under the threat of massive fines, tech giants are likely to invest more in aggressive machine-learning content filters to suppress potentially objectionable material. All this will have a chilling effect on those who are trying to expose wrongdoing in war zones.

Khatib, at the Syrian Archive, said the rise of machine-learning algorithms has made his job far more difficult in recent months. But the push for more filters continues. (As a Brussels-based digital-rights lobbyist in a separate conversation deadpanned, “Filters are the new black, essentially.”) The EU’s online-terrorism bill, Khatib noted, sends the message that sweeping unsavory content under the rug is okay; the social-media platforms will see to it that nobody sees it. He fears the unintended consequences of such a law—that in cracking down on content that’s deemed off-limits in the West, it could have ripple effects that make life even harder for those residing in repressive societies, or worse, in war zones. Any further crackdown on what people can share online, he said, “would definitely be a gift for all authoritarian regimes. It would be a gift for Assad.”

“On the ground in Syria,” he continued, “Assad is doing everything he can to make sure the physical evidence [of potential human-rights violations] is destroyed, and the digital evidence, too. The combination of all this—the filters, the machine-learning algorithms, and new laws—will make it harder for us to document what’s happening in closed societies.” That, he fears, is what dictators want.

This article is part of “The Speech Wars,” a project supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press, and the Fetzer Institute.



The pace of legal news in the third year of the Trump administration is dizzying; sometimes it seems as if our legal system is shaking itself to pieces, like a car driven too fast too long. So you can be forgiven if you missed two news developments earlier this month: first, a decision by a federal district court in California to dismiss federal indictments against four members of the neofascist Rise Above Movement (RAM), and, second, a petition for rehearing of a decision upholding a federal civil suit in Louisiana against DeRay Mckesson, one of the organizers of the Black Lives Matter movement.

There is no universe in which both of these decisions are correct. The California judgment was right; the Louisiana decision was grievously, horribly, scandalously wrong. One can only hope that the full Fifth Circuit Court of Appeals will heed the wisdom of the California district court (and 75 years of Supreme Court precedent) and call its erring panel sharply to heel.

Let’s start with the fascists. As documented by ProPublica in 2017, RAM is a collection of white-supremacist thugs who train in violent tactics and deploy them to break up left-wing demonstrations. Members of RAM took part in the 2017 Unite the Right demonstration in Charlottesville, Virginia, at which a counter-demonstrator, Heather Heyer, was killed. They’ve also fought street battles up and down the West Coast—and those acts induced federal prosecutors in California to charge four of them with conspiring to violate the federal Anti-Riot Act. This act criminalizes traveling or using interstate commerce “with intent to incite … organize, promote, encourage, participate in, or carry on a riot,” or commit, or abet, “any act of violence in furtherance of a riot.” Violations can be punished by up to five years in prison.

The act was passed in the spring of 1968, amid public concern about uprisings in black communities and anti-war demonstrations on the streets—and in fact, all the leading cases on its constitutionality arise out of the government’s unsuccessful attempts to jail anti-war protesters after the disorders at the 1968 Democratic Convention in Chicago.

According to the federal indictment, the RAM defendants not only organized, trained, and urged others to engage in violence; they themselves committed assault against “antifa” (short for “antifascist”) demonstrators and journalists at rallies in Huntington Beach, Berkeley, and San Bernardino, California. Plenty there to hang criminal charges on.

But the First Amendment doomed this worthy attempt to use the Anti-Riot Act. District Judge Cormac J. Carney noted that the statute, on its face, violates important Supreme Court free-speech precedents. The government argued that the defendants had “incited” riot by exchanging texts and posting social-media posts before and after the protests. But, Carney wrote, “incitement” in American law has a very narrow meaning. Under a 1969 case called Brandenburg v. Ohio, “incitement” means only speech that is “directed to inciting or producing imminent lawless action and is likely to incite or produce such action.”

Three requirements: intent; imminence; and likelihood. The three are there because, for generations, American law allowed government to criminalize all speech urging people to break laws, or even to think about breaking them. Criticizing the war effort in World War I, for example, might make people want to refuse the draft—so the Supreme Court allowed the government to imprison socialist leaders such as Eugene V. Debs for “sedition.” As the civil-rights movement challenged segregation across America, states sought to use “sedition” and “incitement” laws against demonstrators; the Court in Brandenburg clarified that only the most direct and dangerous speech—“Let’s take these rocks and stone him now!,” in effect—would meet the First Amendment’s test for “incitement.”

Certainly the RAM defendants’ speech was dangerous, and harmful, and endorsed violence; but what was missing, Carney held, was the “now” element. “The Anti-Riot Act,” he wrote, “has no imminence requirement.” Some of the acts alleged in the indictment took place hours or days before any violence. Punishing speech because of later acts, Carney noted, also runs up against a venerable civil-rights era precedent called NAACP v. Claiborne Hardware, in which Mississippi sought to punish a civil-rights group because one of its leaders made “an impassioned speech, which was later followed by acts of violence.” Like the tort law at issue in Claiborne Hardware, he wrote, “the Anti-Riot Act criminalizes speech even if violence occurs weeks or months after the speech—or even if the violence never occurs.” Under a First Amendment doctrine called “substantial overbreadth,” a statute that can be used to penalize a good deal of “protected speech” is invalid in all its uses—even against speech (or acts) that could be punished under a properly drawn statute.

So the racist thugs went free. The First Amendment protects such hateful speech, not because it is harmless—it is not—but because a government that can outlaw such speech can outlaw criticism of itself. That is a fundamental principle of First Amendment law, and the Roberts Court is very careful to repeat it every time it protects the speech of corporations or the Koch brothers.

This takes us to Doe v. Mckesson, the civil suit against DeRay Mckesson decided on April 24 by a panel of the Fifth Circuit Court of Appeals. Mckesson is an African American civil-rights leader who has been prominently involved in the Black Lives Matter movement. As readers of this page know, Mckesson was at a protest in Baton Rouge where someone threw an object that injured a police officer; now the officer, proceeding under a pseudonym, wants Mckesson to pay him for his injuries, claiming that Mckesson “did nothing to calm the crowd” and “incited the violence.” A federal district court, drawing on the same case law as the California court, dismissed the case; Doe’s complaint did not, he noted, “state … how Mckesson allegedly incited violence or what orders he allegedly was giving.” Indeed, “the only public speech to which Plaintiff cites … is a one-sentence statement that Mckesson allegedly made to The New York Times: ‘The police want protestors to be too afraid to protest.’ … This statement falls far short of being ‘likely to incite lawless action,’ which Plaintiff would have to prove to hold Mckesson liable based on his public speech.”

But in April, a three-judge panel of the Fifth Circuit, without even bothering to hear oral argument, issued a surprise decision reversing the district court. The panel decided that Mckesson could be sued for the officer’s injuries—not because of his intent, but because he was careless. “Mckesson should have known that leading the demonstrators onto a busy highway was most nearly certain to provoke a confrontation between police and the mass of demonstrators, yet he ignored the foreseeable danger … and notwithstanding did so anyway,” the panel wrote.

First Amendment specialists have a term for certain kinds of legal action—“chilling effect.” A hostile jury verdict might bankrupt a defendant; anyone might hesitate to lead or even take part in a protest if a plaintiff could take away his or her house or retirement fund because of something someone else does at the event. For this reason, tort suits were used as a weapon of terror against civil-rights leaders during the 1960s. Some of them lost cars and real estate after state-court judgments—until the Supreme Court, in cases like Claiborne Hardware and New York Times v. Sullivan, made clear that the First Amendment limits tort suits as surely as criminal prosecutions.

I know I am being rather a bore about this case; but the stakes are high, and the Fifth Circuit panel’s offense is rank. The decision was not simply lawless, but insolently so. The full court of appeals has a chance to rectify this, by granting the petition for rehearing, vacating the panel opinion, and deciding the case properly.

The RAM and Mckesson cases were decided in different circuits, but there is only one Constitution, and only one set of Supreme Court case law, which both courts are sworn to apply. The only distinction I can see between the cases is one which—by the rules of mainstream public discourse—I am not supposed to mention. But I am southern by birth, raised during the death agonies of Jim Crow. I know that, in the South at large, including the three states of the Fifth Circuit, the terror of slave revolt sounds a faint nightmare tocsin in white ancestral memory. To a certain cast of the judicial imagination, speech by a DeRay Mckesson may seem to be unprotected because … something … about Mckesson may seem uniquely dangerous.

What could that “something” be?

This suggestion will produce the obligatory ceremonial outrage. Judge X, I am sure, is a doughty companion to one and all; Judge Y must certainly have a variegated circle of friends; Judge Z’s body, no doubt, utterly lacks that anatomically elusive “racist bone.”

But still: Tell me race has nothing to do with this case and I will (to quote the late Professor Charles Black of Yale on a similar topic) “exercise one of the sovereign prerogatives of philosophers—that of laughter.”



War is in the air.

President Donald Trump is still waging war in Yemen after vetoing a congressional call to end the U.S. military’s participation in that country’s civil war. He has kept U.S. forces in Afghanistan, Iraq, and Syria. And high-ranking officials in his administration are asserting their willingness to wage new wars of choice without the approval of Congress, showing disregard for the Constitution and the public’s anti-war sentiments:

Such was the context Monday when senior American officials said that “new threats by Iran against United States troops in Iraq were behind the sudden deployment of an aircraft carrier strike group and Air Force bombers to the Persian Gulf,” per The New York Times. Keeping those troops in Iraq risks wider war.

Last year, when Pompeo was tapped for secretary of state, Senator Jeff Merkley declared, “A vote for Mr. Pompeo is a vote for Trump’s War Cabinet, and for that reason, I will fiercely oppose his nomination.” Today, there are even more reasons to fear additional war-making, and, as ever, reasons to fear the ability of the commander in chief to resolve a conflict.

Nothing since World War II has damaged America more than ill-conceived wars of choice.

Yet the grassroots anti-war movement that filled the streets prior to the invasion of Iraq has all but disappeared, Congress seems content to allow Trump to defy even the explicit resolution it passed against war in Yemen, and Senator Lindsey Graham, who urged the United States into several foreign-policy debacles, is openly stating, “I don’t care about voting on the use of force.”

It is a perilous moment for the republic.



Abortion politics in 2019 is a morality play about what happens when one side has all the political power, yet feels culturally embattled. In this atmosphere, victories are not satisfying if they leave the other side with a foothold, a vestige of respectability. Cataclysmic discord lies ahead.

Abortion politics is no longer about policy wins, but about establishing dominance. This is why Governor Andrew Cuomo could not be satisfied with the passage of the Reproductive Health Act, which eliminated several restrictions on the procedure, but instead had to light up the Empire State Building pink, to declare that abortion rights were now creedal in New York. It was not just the passage of the Reproductive Health Act, but specifically the display of cultural force, that made abortion opponents feel so embattled and isolated.

This dynamic was also evident in Alabama, where the people in power hold the opposite position on abortion as their counterparts in New York and recently passed H.B. 314, a bill that virtually outlaws the procedure.

One scene from the Alabama Senate debate furnishes a quintessential example of the decline of our democracy, of the diminishment of any capacity our political process might have had to help us work through difficult issues together. During the committee markup of the bill, lawmakers passed an amendment to provide an exception for rape or incest. On May 9, as H.B. 314 was headed toward a final vote, Alabama’s Republican Lieutenant Governor Will Ainsworth broke protocol by stripping out the amendment without making a motion or acknowledging his Democratic colleagues’ requests for a roll-call vote. Democratic State Senator Bobby Singleton shouted, “There was no motion. You didn’t even make a motion!” Ainsworth simply ignored his colleague’s interjections.

Then, Democratic State Senator Vivian Figures stepped up to address Ainsworth, perhaps calculating that calm diplomacy might prove effective where righteous indignation had not. “I know you want this bill to pass, and you’re going to get your way, but at least treat us fairly and do it the right way. That’s all I ask. That’s all that women in this state ask, both Democrats and Republicans. If there has been a motion made, we should have a vote on that motion,” Figures said. Surely this display of courtesy would solicit a reciprocal response? Not in our politics today. Not when you have the gavel, and the power, and have no need for the other side. In fact, Ainsworth responded by quite literally refusing to acknowledge the existence of his Democratic colleagues, insisting that no one objected to his maneuver.

Ainsworth’s actions reflect an audacious disrespect that is now ubiquitous in our politics. The lieutenant governor, I imagine, was thinking something like: They have Hollywood. They manipulated the courts to establish abortion rights by fiat. They mock the pro-life cause, and do so with impunity. They have all the power. Except here. Except right now. They can know how it feels to be powerless for a change, like their opposition is unstoppable and they are irrelevant. Just so, Cuomo perhaps thought, They have the White House. They manipulated Senate procedures to establish a majority on the Supreme Court. They mock reproductive rights, and do so with impunity. They have all the power. Except here. Except right now. They can know how it feels to be powerless for a change, like their opposition is unstoppable and they are irrelevant.

This is where our politics has carried the abortion debate, where our so-called leaders and voters have allowed it to be carried. The abortion debate now lacks even the pretense of comity. No one seeks to reconcile rational, competing claims. Because the issue is so personal—it strikes at the very heart of what it means to be a person with life and agency—our discussions ought to remind us of our humanity and frailty. Instead, our toxic politics has taught us that to acknowledge nuance is to make ourselves vulnerable and exposed. How comfortable have we become using politics as an immoral weapon in the name of our self-assured moral cause? This is, in the most favorable light, what Ainsworth decided to do. But how moral could his cause be if he is willing to advance it in such an immoral manner?

We are not dealing with public servants here—not if the title is anything more than a euphemism. Instead, we have politicians supported by advocacy groups and moneyed interests whose goal is to attain whatever level of power is necessary to act unilaterally. This is what a representative democracy looks like when stripped of trust, respect, virtue, and sense of community.

President Donald Trump appreciates the utility of a nihilistic politics that seeks to maximize feelings of fear and embattlement rather than hope and possibility. I have argued elsewhere that it was Trump’s ability to build up a sense of embattlement among his voters, offering only himself as a pressure valve, that allowed him to win in 2016. Abortion has been central to that strategy, and as I predicted in The Atlantic in the wake of the New York bill and the Virginia controversy, abortion will play a central role in Trump’s appeal in 2020.

However, Alabama might just have solved the other side’s enthusiasm-gap problem. The 2020 candidates seem to think so; they are already moving even further left on abortion—almost all of them are promising to pursue federal legislation that would codify Roe and override state-level restrictions. Democrats are suggesting they’ll make abortion a central issue in 2020, similar to the role of the Affordable Care Act in 2018. Just as Virginia Governor Ralph Northam’s comments on children born after a failed abortion seemed to confirm anti-abortion activists’ worst fears, the Alabama bill is being used to advance progressives’ Handmaid’s Tale narrative.

Meanwhile, the majority of Americans remain somewhere between supporting abortion-on-demand and supporting a federal law that would force the victim of a rapist to carry that child to term. Though it can’t be uttered in our politics, most Americans understand both that a fetus or unborn child is more than just a “clump of cells,” and that the unborn child is uniquely situated, implicating the life of its mother in a way that is singular among human relationships.

Trump recognizes the threat the recent turn in our abortion politics poses for him. In his response to the Alabama law, Trump responded with an unusually coherent series of tweets.

He wrote:

As most people know, and for those who would like to know, I am strongly Pro-Life, with the three exceptions—Rape, Incest and protecting the Life of the mother—the same position taken by Ronald Reagan. We have come very far in the last two years with 105 wonderful new.........Federal Judges (many more to come), two great new Supreme Court Justices, the Mexico City Policy, and a whole new & positive attitude about the Right to Life. The Radical Left, with late term abortion (and worse), is imploding on this issue. We must stick together and Win.... ....for Life in 2020. If we are foolish and do not stay UNITED as one, all of our hard fought gains for Life can, and will, rapidly disappear!

Unfortunately for Trump, he might find he’s unable to contain the sense of embattlement he stoked for political gain. The thing about embattlement is that even when your side attains power, it always feels like it’s slipping away, so you fight even harder.



The story of the Chinese technology giant Huawei is, in miniature, the story of China’s extraordinary economic rise. Founded in 1987 in Shenzhen, which at the time was still an unglamorous backwater, Huawei’s early efforts centered around reselling telecom equipment imported from neighboring Hong Kong and, at the same time, working feverishly to figure out how to manufacture low-cost imitations of such equipment.

In less than a decade, Huawei went from being little more than a middleman to being one of Asia’s leading manufacturers of network technology, helped along by the support of the Chinese party-state, including the People’s Liberation Army, an early and devoted customer. Today Huawei is by one account the world’s seventh-largest tech company, and a mainstay of Shenzhen’s thriving hardware ecosystem. In recent years, the company has routinely sold more smartphones than Apple, and in 2018 it generated roughly as much revenue as Microsoft.

But that was all before Donald Trump made what could ultimately be one of the most consequential decisions of his presidency: By adding Huawei to what is known as the “entity list,” the Trump administration has cut off one of China’s most successful multinationals from the U.S. technology that it has heretofore needed to function. This is a decision that will have profound implications for the Chinese economy. Yet it will also test the United States, which has grown dependent on Chinese manufacturing prowess in building out its own network infrastructure. What happens next could forever transform the relationship between the world’s largest economies.

Trump’s decision to clip Huawei’s wings was not made lightly. It came in the face of evidence that Huawei’s growing reach poses serious security challenges to the United States and its allies. For one, Huawei has evinced a willingness to aid China’s clandestine intelligence-gathering efforts. In 2017, it came to light that Huawei-made servers in the African Union headquarters had been surreptitiously feeding classified information to a server farm in Shanghai on a nightly basis for more than five years. To date, nothing this brazen or damning has come to light in a G20 country, but there have long been concerns about Huawei’s eyebrow-raising security shortcomings. A March report from the British government suggested that despite Huawei being at the bleeding edge of 5G hardware, the security of its technology was “very, very shoddy,” a fact China hawks attribute to intentional design rather than a lack of sophistication.

To many in China, however, Trump’s blacklisting of Huawei looks rather a lot like a frontal assault on one of their country’s foremost national champions, if not an echo of the Opium Wars of the 19th century. The Chinese government has promised a forceful response that will target U.S. companies, and even individual U.S. citizens, it deems “unreliable.”

Understanding China’s vehement defense of Huawei is impossible without situating the company in China’s long-term vision for its economy. As Matthew Klein has perceptively noted in Barron’s, since the financial crisis China has moved away from its old strategy of deluging wealthy Western markets with low-cost goods. Despite China’s continued suppression of living standards, the cost of labor in China’s cities has risen as a result of a shrinking working-age population and sharp inflation in housing costs. Apple CEO Tim Cook has gone so far as to say that these pressures have moved Chinese manufacturing outside the low-wage target that multinationals such as Apple seek. This move away from being the “workplace of the world” is not a problem in itself. In fact, the “Made in China 2025” program reflects the Chinese Communist Party’s hope of aiming a new “China shock” at Silicon Valley. The issue, though, is that China’s enormous debt overhang might not allow for the seamless pivot the party is counting on.

Whereas the United States and Japan can service their debts at little cost, at least for now, debt service in China comes out to 20 percent of GDP. Given this debt burden, China was counting on its high-tech industries to win large market shares abroad and free up subsidies for the country’s struggling state-owned enterprises, which absorbed 70 percent of all new loans from 2013 to 2017.

Huawei, with its stratospheric rise, was the poster child for this approach. Yes, part of its competitive advantage still stemmed from government largesse, but the overall performance of the company more than made it a net benefit for the country. If the United States kicks off a trend of barring high-tech Chinese companies from lucrative Western markets, though, the Huawei model will be severely damaged. China would still press on with its push into high-tech sectors out of a desire to limit its own vulnerability to the type of supply-chain disruptions it is now facing, but the cost to the state would be far higher.

The purpose of “Made in China 2025” is to cultivate national champions, not create more wards of the state. Beneath all of the fawning media attention, the obstacles facing the Chinese economy are formidable. China is facing down the Japanese cocktail of high debt levels and an aging population, only it’s doing so before joining the ranks of the world’s richest countries. And unlike the government in Tokyo, the Chinese Communist Party cannot countenance a deep and lasting recession that could prove fatal to its legitimacy.

A recognition of China’s structural challenges, though, should not obscure that the United States has vulnerabilities of its own. With the exception of the dot-com decade from 1995 to 2005, the Unites States has seen lackluster productivity growth since the 1970s, which has contributed to wage stagnation and all of its associated ills. The economic wonders of 5G remain highly speculative, but unlike previous generations of wireless technology, there is reason to believe that 5G will have major cross-industry effects. To highlight a single but very promising example, when Ericsson installed its early 5G-sensor system in a factory for jet-engine blades, the defect rate was brought down by 10 percent, reducing the per blade cost by more than $4,000. Even if the 5G boosters are proved wrong, and its contributions to the economy end up being marginal, the upside is too large for the United States not to get in the race.

If blacklisting Huawei appreciably raises the cost of deploying 5G networks in the United States, American firms might find themselves at a distinct disadvantage. Over the next few years, as AT&T and Verizon build out their 5G infrastructure, swearing off Huawei means they will do so with hardware manufactured by Ericsson, a Swedish multinational, or Nokia, a Finnish one, as if to underscore the extent to which the United States has allowed its industrial know-how to atrophy. And Ericsson and Nokia hardware can be as much as 20 percent more expensive than Huawei’s offerings. When you consider this per unit premium compounded over the upper-bound estimate of 800,000 new 5G cells, the premium U.S. telecom companies will be forced to pay to guard against the threat of Chinese subversion is staggering. For smaller companies, particularly wireless providers for rural communities, the cost of moving away from Huawei could be prohibitive, unless the government steps in.

Consider the case of Nemont, as relayed by Charlie Campbell of Time. A pint-size wireless carrier operating in rural Montana, its tight margins forced it to rely on Huawei technology for its 4G hardware. Turning to a higher-cost supplier was simply not an option. Smaller players in the heartland such as Nemont would look to the federal government for relief should the Trump administration stick with the Huawei blacklist. The White House had already pledged $20 billion to expand rural broadband before the ban, a bill that may have to climb higher still.

While there’s nothing to say that either Ericsson or Nokia won’t find some cost-cutting innovations over the next few years to change this basic calculus, we should not bank on it. Instead, it would be wise to be seek out opportunities for cost-cutting and efficiency gains elsewhere in the process. At a minimum, the United States must overcome regulatory obstacles that have all but thwarted every other major effort to build out 5G infrastructure in recent years. Many of America’s larger cities and metros find themselves squeezed by soaring expenditures and cash-strapped voters who rightly resist new taxes. This has left ambitious politicians scrambling for revenue sources to paper over fiscal imbalances, even when this strategy risks deterring productive investment.

Take Portland, Oregon, where installing a 5G antenna required a $7,500 builders fee and then a recurring annual fee of somewhere between $2,500 and $3,500; or Dallas, where the right to build 5G antennae would cost you a one-time fee of $280,000. A recently announced Federal Communications Commission policy would constrain revenue-hungry local governments. Under the new guidelines, cities would be required to set their fees at however much it cost them to review the 5G-antenna application, which itself would have to be approved or declined within 90 days. It’s a policy that can’t hurt, but it won’t make the challenge of replacing Huawei’s technology all that much easier to overcome.

And so Trump has to make a decision. If he doesn’t want to cede the emerging 5G economy to a Chinese tech giant, whether out of security concerns or a larger anxiety about the loss of U.S. technological superiority, he must decide on an alternative course. One option would be to work with other market economies to reduce their collective dependence on Huawei’s low-cost networking technology. But that would require deft diplomacy—not the president’s strong suit—as America’s partners in this endeavor would need to be reassured that they have something to gain from willingly paying higher prices to fend off an amorphous Chinese challenge.

Alternatively, Trump could commit to a more ambitious strategy of rebuilding the U.S. industrial commons, and perhaps even building up U.S. national champions that can outcompete Huawei in manufacturing networking technology. In short, he could craft a “Made in the U.S.A. 2025” agenda fit to compete with “Made in China 2025.” Suffice it to say, the United States is not known for its ability to engage in this sort of long-term industrial planning, and even attempting to do so would raise hackles among free traders on the left and the right. Blacklisting Huawei is one thing. Figuring out exactly what to do next will prove to be quite another.

Regardless of the outcome of the Huawei controversy, it is yet another sign that the enmeshment of the Chinese and U.S. economies that has defined the past 20 years—the age of “Chimerica”—is coming to an end, and this will mean a painful adjustment for Chinese and Americans alike.



On Monday, the Supreme Court stymied an effort by Apple to protect its monopoly over sales of iPhone apps. Justice Brett Kavanaugh’s decision in Apple v. Pepper turned on an arcane bit of antitrust law, and it provided the first small hope that the antitrust establishment may finally turn against Big Tech. But the odds remain formidable.

The story begins during an almost unimaginably remote time in the American past—when the internet had not yet been invented, and antitrust law was still taken seriously. It was 1968, and the Supreme Court faced a dispute between Hanover Shoe, a manufacturer, and the United Shoe Machinery Corporation, from which it had leased equipment. Hanover Shoe sought damages on the grounds that United Shoe had used its monopolistic power to overcharge for the machinery.

United Shoe argued that Hanover Shoe had not been injured, because it had been able to pass on the overcharge to its own customers in the form of higher shoe prices. Those customers—that is, ordinary people who buy shoes—possessed the claim against the monopolist, not the intermediary who merely passed on the monopoly price. The Court would have none of it. The ultimate buyers—who might have spent a few extra dollars for their shoes—would not be able to afford a lawsuit. The “direct purchaser” from the manufacturer can bring an antitrust claim even if it does not suffer any damages, the Court ruled. Otherwise, monopolists would be protected from lawsuits.

However, just nine years later, the Supreme Court converted this pro-antitrust holding into an anti-antitrust rule. Illinois Brick Co. v. Illinois involved similar facts. Several manufacturers who allegedly fixed prices sold their goods to an intermediary, who sold them to customers. In Hanover Shoe, the intermediary sued the manufacturer. In Illinois Brick, the customer sued the manufacturers, skipping the intermediary. The customer argued that because the monopoly overcharge was passed on to purchasers, it was entitled to damages.

But this time, the Court ruled for the monopolists. It explained that since Hanover Shoe assigned the antitrust claim to the direct purchaser from the monopolist, there was nothing left to give the customers of the purchaser. If the customers were allowed to sue, liability might be duplicated. The Court dismissed the obvious counterargument—that damages should be shared between the customers and the intermediary according to the extent of harm. Economic theory tells us that the overcharge may sometimes be absorbed by the intermediary, sometimes passed on to customers, and sometimes shared, but that’s hard to define in practice.

Commentators pointed out that this holding made little sense. Usually the customers, not the intermediary, absorb the monopoly overcharge. The new doctrine gave the remedy to the parties least likely to be harmed and withheld it from those most likely to be harmed. And the Court turned out to have been wrong in Hanover Shoe about incentives to sue. Lawyers can organize customers to bring class-action lawsuits. Intermediaries, on the other hand, are usually terrified of monopolist suppliers, and if not, the monopolists can bribe them not to sue by giving them a share of the monopoly profits extracted from consumers.

But the Supreme Court had moved to the right by 1977, and its rightward trend would continue for years to come. The Illinois Brick rule appealed both to the neoliberalism of the time, which disapproved of antitrust liability, and to the fetish for bright-line rules found among many conservative jurists. Bright-line rules, they argued, make law more predictable by limiting the discretion of government officials, including judges—and diminishing the impact of their liberal biases.

It took the tech revolution to make the flaw in this thinking so obvious, the Court could no longer ignore it.

Apple argued that its App Store customers could not sue it because of Illinois Brick. How could this be? The customers handed over money to Apple in return for access to its apps; this seemed like the direct customer relationship that Illinois Brick had blessed. But Apple argued that Apple’s real customers were the developers, who bought from Apple access to the App Store platform by paying a 30 percent commission based on the price of the app. The customers bought their apps from the developers, not from Apple. Since they were not “direct purchasers” from Apple, they could not sue Apple—only the developers could. (Of course, the developers—whose businesses are dependent on the access to consumers that the App Store provides—had not sued Apple, and have so far shown no inclination to do so.)

The argument was not crazy; a similar argument was accepted by a court of appeals 20 years ago. The problem here, as I argued along with other antitrust scholars in an amicus brief filed in the case, was the operation of the Illinois Brick rule, a rule already poorly suited to the brick-and-mortar world that works even less well in the virtual world. A tech giant such as Apple can easily structure its distribution chain however it wants to—just by changing some lines of code and some contractual language—to evade whatever bright-line antitrust rules the Supreme Court throws at it. It shouldn’t matter to Apple whether it makes money off developers (by charging them high commissions, which they might pass on to customers) or customers (by charging them high prices, which the developers might have to offset by lowering their own prices). The labels change; the profits are the same.

Apple’s App Store—unlike a factory, warehouse, or physical store—is just code that sits on servers. Apple’s relationships with its customers and suppliers are also the product of code. This gives Apple degrees of freedom to structure its distribution chain in ways that monopolists of old never enjoyed.

While the Court made some progress in allowing victims of monopolies to obtain a remedy, the government’s decades of neglecting the antitrust violations of Big Tech leave the United States facing an enormous challenge. Indeed, not long ago many cheered tech companies for offering services for free or low prices, without realizing the strategy made sense only if the tech companies recouped their losses by obtaining monopolies.

Regulators then missed the risks of allowing tech firms to consolidate by buying their rivals. And regulators missed the novel ways in which tech companies exploited their monopoly power once they achieved it—by abusing data privacy, eroding service quality, and harassing people with ads they dislike, rather than (like old-time monopolists) simply raising prices.

And, of course, Big Tech, like the old-fashioned monopolists, has bought itself political goodwill. But the tech companies now seem to have overplayed their hand. With scandals mounting, and growing uneasiness about Facebook’s and Google’s influence on political speech—also a result of their monopoly power—a long-overdue anti-monopoly backlash has begun. If the Supreme Court seems unlikely to lead it, then the Court may, at least, not perform its usual function of standing in the way.



Political discourse has taken on a certain shade of Camus. The term existential threat is fertile of late, especially among Democratic presidential hopefuls. It has become a set term in reference to climate change, as used by Governor Jay Inslee and by Senator Elizabeth Warren, both on Twitter and in speeches, while Mayor Pete Buttigieg has used the variation existential security challenge. Former Vice President Joe Biden refers to President Donald Trump as an existential threat to the nation, and Senator Cory Booker widens the lens, applying the term to the opiate crisis, suicide rates, and even our general lack of civic unity. It isn’t only people left of center who are newly fond of the term: According to a National Rifle Association spokesman, Senator Kamala Harris is an “existential threat” to the Second Amendment.

Of course, it is perfectly logical to see climate change, the current president, and possibly other matters as existential threats. However, the nation has surely encountered quite a few dire circumstances in the past, and yet it is only lately that the specific term existential threat has been on the tip of so many tongues.

Winston Churchill’s famous speech to the House of Commons in 1940, best known for its “We shall fight them on the beaches” passage, referred to the “menace of tyranny,” but not an existential threat, despite the very real one Britain then faced in Hitler. The term existential became well entrenched in Anglophone discourse after World War II, when Martin Heidegger’s Being and Time, and especially Jean-Paul Sartre’s Being and Nothingness and Albert Camus’ works such as The Stranger, were widely read.

Crucially, though, existential threat was not regularly used in American public speeches in the late 20th century, despite how widely discussed existentialism itself was among the educated. In his speech on the Bay of Pigs, President John F. Kennedy referred to what we recognize as an existential threat, but did not call it one. Ronald Reagan referred to the Soviet Union as a threat, but not an “existential” one.

The “existential” add-on has jumped in this century specifically, first embraced in reference to terrorism after 9/11, and then again after the election of you-know-who in 2016. Google yielded about a million hits for existential threat in 2015, and 1,700,000 the year afterward, and 2,300,000 in 2017.

Existentialism is now one of the key shibboleths of being, or sounding, educated, summoning memories of how challengingly chilly and odd—yet clearly fundamental to human nature—The Stranger seemed when we were assigned it in college or an Advanced Placement class. Related to this is the sheer drama in the term, with its flavor of darkness. But precisely because threats of the past were not too often described as “existential,” the term existential threat feels not only highbrow and portentous, but novel.

In this way, the popularity of the term tracks a general trend in how any language changes over time. We seek to move, stimulate, and hold the attention of those we talk (or write) to, and this requires the constant renewal of words designed to grab the lapels and register our sincerity and passion. A modern example is the business-world habit of turning verbs into nouns, as in “a big ask” and “finding a solve.” The words request and solution have been around for a while and feel flat, a little vanilla. An “ask” sounds more lively than a “request” or a “bid,” even if it refers to the same thing, which is much of why this kind of usage has jumped the rails to more general parlance.

New developments like this often start in a subgroup and then spread, and today’s Democratic candidates can be analyzed as such a community, sharing not only a political aspiration, but even a certain wonkishness that would encourage the embrace of a term like existential.

But overall there is a chance element in these things, in which social history, powerful personalities, and sheer serendipity endlessly intertwine. It seems like it was just 10 minutes ago that one spoke of “tips,” “pointers,” and that which is “handy”—as opposed to the now viral usage of hack, as in life hack, cooking hack, and so on. Why are we now using that word so much? Because of the technology journalist Danny O’Brien’s coinage of it in 2005—but then, there are countless other terms that people in his profession use that most of us will never hear. One can no more know just why most new terms emerge than one can know why bell-bottoms became fashionable when they did or why men are now wearing their pants hemmed a bit higher above the ankle than they were a few years ago. Novelty is the constant; its direction and form are up for grabs.

After all, in 1988, many of the “Seven Dwarfs” Democratic candidates were quite comfortable with their noses in books, such as Michael Dukakis, Paul Simon, and especially Al Gore, who was memorably belittled later by George W. Bush for his fondness of none other than the existentialist tome Phenomenology of Perception. And yet no trend for using existential threat emerged among them.

Some might object that existential threat is redundant and that Reagan had it right with his preference for simply saying “threat.” Threat embodies the possibility of harm, which could be seen as potentially embodying outright negation—i.e., of existence. One might well sense damage or disempowerment as, in essence, elimination. Isn’t existential threat really just a fancy way of saying threat?

To an extent, yes, and that reflects, again, a quest to juice the word up a bit, keep it fresh. English is full of examples of our having done just that in the past, yielding what today are set phrases entailing the same kind of lily-gilding. We often call something a “damned shame,” which is not really all that “damned”—besides, isn’t something that is a shame already “damned,” technically? Rather, we say “a damned shame” as a way of saying that something was a shame with a certain air of dedication, commitment. What, precisely, is “stark” naked, as if when just naked we wear a bow tie or socks? If overwhelm means what it does, then what did whelm ever mean? The answer: It meant “to overwhelm.”

People added the over for the same reason it now feels so right to add existential to threat—it adds a sense of urgency and color to a message that otherwise might go by less noticed. To wit, speaking is never a mere recitation of things and actions and qualities decorated by some greeting conventions and a sprinkling of slang. Language is about keeping people’s attention, making it worth their while to give you their sustained attention. A language where terms like existential threat did not regularly catch on to replace earlier ways of saying the same thing would be under its own kind of existential threat, as it would no longer suit the actual needs of human exchange.



When Yale recently decided to relocate three-quarters of the books in its undergraduate library to create more study space, the students loudly protested. In a passionate op-ed in the Yale Daily News, one student accused the university librarian—who oversees 15 million books in Yale’s extensive library system—of failing to “understand the crucial relationship of books to education.” A sit-in, or rather a “browse-in,” was held in Bass Library to show the administration how college students still value the presence of books. Eventually the number of volumes that would remain was expanded, at the cost of reducing the number of proposed additional seats in a busy central location.

Little-noticed in this minor skirmish over the future of the library was a much bigger story about the changing relationship between college students and books. Buried in a slide deck about circulation statistics from Yale’s library was an unsettling fact: There has been a 64 percent decline in the number of books checked out by undergraduates from Bass Library over the past decade.

Yale’s experience is not at all unique—indeed, it is commonplace. University libraries across the country, and around the world, are seeing steady, and in many cases precipitous, declines in the use of the books on their shelves. The University of Virginia, one of our great public universities and an institution that openly shares detailed library circulation stats from the prior 20 years, is a good case study. College students at UVA checked out 238,000 books during the school year a decade ago; last year, that number had shrunk to just 60,000.

Before you tsk-tsk today’s kids for their lack of bookishness, note that the trend lines are sliding southward for graduate students and faculty members, too: down 61 percent and 46 percent, respectively, at UVA. Overall, across its entire network of libraries, UVA circulated 525,000 books during the 2007–08 school year, but last year there were only 188,000 loans—nearly 1,000 fewer books checked out a day. The Association of Research Libraries’ aggregated statistics show a steady decrease of the same proportion across its membership, even as student enrollment at these universities has grown substantially.

Maybe students aren’t checking the books out but are still consulting them regularly within the library? This also does not appear to be true. Many libraries also track such in-house uses, by tallying the books that need to be reshelved, and the trends are the same. At my library at Northeastern University, undergraduate circulations declined 50 percent from 2013 to 2017—before we decided to do our own book relocation—and our logged number of books removed from shelves but not checked out also dropped by half.

These stark statistics present a conundrum for those who care about libraries and books. At the same time that books increasingly lie dormant, library spaces themselves remain vibrant—Snell Library at Northeastern now receives well over 2 million visits a year—as retreats for focused study and dynamic collaboration, and as sites of an ever wider array of activities and forms of knowledge creation and expression, including, but also well beyond, the printed word. It should come as no surprise that library leadership, in moments of dispassionate assessment often augmented by hearing from students who have trouble finding seats during busy periods, would seek to rezone areas occupied by stacks for more individual and group work. Yet it often does come as an unwelcome surprise to many, especially those with a powerful emotional attachment to what libraries should look like and be.

What’s happening here is much more complicated than an imagined zero-sum game between the defenders of books and library futurists. The decline in the use of print books at universities relates to the kinds of books we read for scholarly pursuits rather than pure pleasure, the rise of ebooks and digital articles, and the changing environment of research. And it runs contrary to the experience of public libraries and bookstores, where print continues to thrive.

Unlike most public libraries, the libraries of colleges and universities have always been filled with an incredibly wide variety of books, including works of literature and nonfiction, but also bound scientific journals and other highly specialized periodicals, detailed reference works, and government documents—different books for different purposes. Although many of these volumes stand ready for immersive, cover-to-cover reading, others await rarer and often brief consultations, as part of a larger network of knowledge. Even many monographs, carefully and slowly written by scholars, see only very sporadic consultation, and it is not uncommon for the majority of college collections to be unused for a decade or more. This is as it should be: Research libraries exist to collect and preserve knowledge for the future as well as for the present, not to house just the latest and most popular works.

But there is a difference between preservation and access, and a significant difference, often unacknowledged, in the way we read books for research instead of pleasure. As the historian Michael O’Malley humorously summarized the nature of much scholarly reading and writing, “We learn to read books and articles quickly, under pressure, for the key points or for what we can use. But we write as if a learned gentleman of leisure sits in a paneled study, savoring every word.” Or as he more vividly described the research process, academics often approach books like “sous-chefs gutting a fish.”

With the rapidly growing number of books available online, that mode of slicing and dicing has largely become digital. Where students or faculty once pulled volumes off the shelf to scan a table of contents or index, grasp a thesis by reading an introduction, check a reference, or trace a footnote, today they consult the library’s swiftly expanding ebook collection (our library’s ebook collection has multiplied tenfold over the past decade), Google Books, or Amazon’s Look Inside. With each of these clicks, a print circulation or in-house use of a book is lost. UVA’s ebook downloads totaled 1.7 million in 2016, an order of magnitude larger than e-circulations a decade ago. Our numbers at Northeastern are almost identical, as scholars have become comfortable with the use of digital books for many purposes.

I’ve seen my own book usage change over time. When I was a graduate student studying Victorian history at Yale, the university’s towering collection in Sterling Library, next door to Bass (then called Cross Campus Library), allowed me to find and leaf through relevant books easily. Now almost all of the texts I consulted for my dissertation are available online in repositories such as HathiTrust, which stores digitized books from research libraries, many of them freely available for download since they were published before 1924, the cutoff for public-domain works. If I were doing the same scholarly project today, I would likely check out only a small subset of books that I needed to pay careful attention to, and annotate others digitally in my PDF reader.

The decline in print circulation also coincides with the increasing dominance of the article over the monograph, and the availability of most articles online. In many fields, we now have the equivalent of Spotify for research: vast databases that help scholars search millions of articles and connect them—often through highly restrictive and increasingly unsustainable subscriptions, but that is another story—instantly to digital copies. (There is also a Napster for research articles, of which we shall not speak.) Very few natural and social scientists continue to consult bound volumes of journals in their field, especially issues that are more than a few years old. UVA recorded nearly 3 million e-journal downloads in 2016, a massive and growing number that is typical of most universities.

In addition, the nature of scholarship is also changing, still with significant reading and writing, of course, but also involving the use and processing of data in a wide array of disciplines. To serve these emerging needs, Northeastern University Library has added full-time specialists in data visualization and systematic review (the process of synthesizing, statistically, exhaustive research from multiple studies), and an entire division dedicated to new forms of digital scholarship.

Our research library, like many others, has also seen a surge in group work rather than the solitary pursuit of the canonical research paper. More classes are assigning team-based projects instead of individual essays, as many urgent problems, such as climate change, call for large-scale interdisciplinary work and multiple perspectives. University libraries have correspondingly seen reservations for collaboration spaces surge. Last year, we had a record 100,000 hours of group-room bookings in our library, meaning that these spaces were occupied constantly from 8 a.m. to midnight.

At the same time—and perhaps this is one of the feel-good stories related to physical collections—there is an increasing use of archives. Many students still find the direct encounter with primary sources thrilling, and instructors and library staff have found creative ways for them to use these special collections. We have doubled our archival holdings in the past five years, focusing on Boston-related materials such as our recent acquisition of millions of photographs and negatives from The Boston Globe, and have greatly expanded our program of teaching with these artifacts.

A positive way of looking at these changes is that we are witnessing a Great Sorting within the library, a matching of different kinds of scholarly uses with the right media, formats, and locations. Books that are in high demand; or that benefit from physical manifestations, such as art books and musical scores; or that are rare or require careful, full engagement, might be better off in centralized places on campus. But multiple copies of common books, those that can be consulted quickly online or are needed only once a decade, or that are now largely replaced by digital forms, can be stored off site and made available quickly on demand, which reduces costs for libraries and also allows them to more easily share books among institutions in a network. Importantly, this also closes the gap between elite institutions such as Yale and the much larger number of colleges with more modest collections.

These trends around research collections are likely to continue. A small number of regional pools of books at a monumental scale—tens of millions of books from scores of universities working together—are already envisioned in the United States, which will ensure preservation and access for future generations and effectively act as gigantic shared libraries, or what David Prosser, the executive director of Research Libraries UK, has called “collective collections.” “Print books are historical artefacts … but some are more valuable artefacts than others,” Prosser has argued. “No library can be completely universal and decisions need to be made about what to collect and where to store material. By looking at collections collectively we can better serve the needs of readers, ensuring that what we have is well looked after (and yes, sometimes that means in ‘remote-storage’).”

Unfortunately, more troubling factors are also at work in the decline of print books within colleges. Statistics show that today’s undergraduates have read fewer books before they arrive on campus than in prior decades, and just placing students in an environment with more books is unlikely to turn that around. (The time to acquire the reading bug is much earlier than freshman year.) And while correlation does not equal causation, it is all too conspicuous that we reached Peak Book in universities just before the iPhone came out. Part of this story is undoubtedly about the proliferation of electronic devices that are consuming the attention once devoted to books.

The sharp decrease in the circulation of books also obviously coincides with the Great Recession and with the steady decline of humanities majors, as students have shifted from literature, philosophy, and history to STEM disciplines—from fields centered on the book to fields that emphasize the article.

When I tweeted about this under-discussed decline in the use of print books in universities, several respondents wondered if, regardless of circulation statistics, we should keep an ample number of books in the library for their beneficial ambience. Even if books are ignored by undergraduates, maybe just having them around will indirectly contribute to learning. If books are becoming wallpaper, they are rather nice wallpaper, surrounding students with deep learning and with some helpful sound-deadening characteristics to boot. If that helps students get into the right mind-set in a quiet, contemplative space, so be it. Maybe they will be more productive, get away from their distracting devices, and perhaps serendipitously discover a book or two along the way.

You can certainly see this theory at work in new library designs in which the number of volumes is more quietly reduced than at Yale, with books lining the walls of study spaces but not jutting out perpendicularly like the old, high-capacity stacks, so as to leave most of the floor open for tables, chairs, and spaces for group work. Perhaps that is the right approach, the right compromise, for some schools and students. Of course, you can also find students who love spaces without books, or who work better with some background noise—alas, whenever you discuss these matters, all students tend to generalize from the study space that works for themselves.

But there is another future that these statistics and our nostalgic reaction to them might produce: the research library as a Disneyland of books, with banker’s lamps and never-cracked spines providing the suggestion of, but not the true interaction with, knowledge old and new. As beautiful as those libraries appear—and I, too, find myself unconsciously responding to such surroundings, having grown up studying in them—we should beware the peril of books as glorified wallpaper. The value of books, after all, is what lies beneath their covers, as lovely as those covers may be.



When the memorial service for the former defense official Andrew W. Marshall, who recently passed away at the age of 97, was held, an eclectic throng attended. Former senior Cabinet officials, generals (the vice chairman of the Joint Chiefs of Staff gave one of the eulogies), professors, think tankers, and bureaucrats from several continents showed up. There were historians, anthropologists, economists, journalists, and political scientists. But it was not a gathering of the establishment, for these were the cranky insiders rather than the complacent wielders of authority. And all of us thought of ourselves as members of what is affectionately known as St. Andrew’s Prep.

Andy came to Washington in 1969 from the Rand Corporation to work for Henry Kissinger. His friend James Schlesinger recruited him from there to create and run the Office of Net Assessment in the Pentagon in 1973, and he retired out of that job an astounding 42 years later. In that time, he influenced not only the senior civilian and military leadership of the Pentagon (emphatically, some more than others), but generations of students of national-security affairs.

Put at its most simple, net assessment is about comparing opposing sides in actual or potential conflict. That might sound straightforward, but it is not. Intelligence agencies focus on the other—they are by culture and sometimes by bureaucratic practice allergic to studying their own side. The military engages in planning, of course, but that is not the same thing as assessment, because action is very different from analysis. Think tanks usually conduct their studies with an eye on clearly defined deliverables in well-measured times for particular clients. Universities do all kinds of analytic work, but very rarely with the kind of highly classified information that is needed.

What Andy Marshall invented (and it was his invention) was something else: a sober, multifaceted, long-range scrutiny of military balances that probed for hidden asymmetries of strategy or organizational behavior, and that took in everything—from geography to technology, order of battle to styles of command, and culture to bureaucratic routine. Many of the products were highly classified. Some were well known (such as his iconic assessment of the standoff in Central Europe during the Cold War) and some went to only one or two consumers. They gave no clear guidelines for immediate action. Indeed, the reason the Office of Net Assessment flourished was because, from a narrow bureaucratic point of view, it threatened no one. Some secretaries of defense neither understood its work nor cared about it; the clever ones, such as Schlesinger and Harold Brown, treasured it.

At any given time, fewer than a dozen bright young officers and civilians at most were at the heart of the ONA, but its intellectual ripples extended far away. Read Graham Allison’s Essence of Decision, and there in the credits you will see Andy Marshall. Look at some of the finer literature on intelligence and on military effectiveness in the interwar period and World War II, and you will see that it was sponsored by Andy Marshall. Read about how the United States sharply revised downward its estimate of the size of the Soviet economy in the mid-1980s, and you will see that it rested on work by émigré Soviet economists who had been disregarded by their more orthodox Western counterparts. Andy had contracted for, and championed, their work.

Andy was an intellectual magpie. He devoured books on early-19th-century military history (“Read Dominic Lieven’s book on how the Russians beat Napoleon; it will change your view of Russian military culture”), Chinese philosophy, and biological anthropology. To be sure, privates often think of their sergeants as apes; Andy wondered what it meant that the generals and politicians had a good deal of the primate in them, too. He wrote very little, in part because he was a perfectionist. As more than one subordinate or contractor ruefully acknowledged, you would give him something you had written, he would mumble at you and say “Do it again,” and after the third or fourth go, it was the best thing you had ever written in your life.

Andy’s was the life of the mind, devoted to the study of conflict and informed by a deep and abiding—if often pessimistic—love of the United States. He would listen to anyone who had something to say, be it a Harvard professor or a graduate student masquerading as a reserve second lieutenant. He liked the oddballs—those dissident Soviet economists, the crackbrained technologists, the impossibly insubordinate armor officers, the eccentric hedge-fund guy who was willing to help the country while trying to figure out which way the financial winds were blowing.

What those memorializing Andy remembered most, however, was his kindness. He could be tough, and on rare occasions—when someone was appallingly stupid or had behaved very badly—he could get angry, but that was rare. For the most part, he gave. He gave opportunities for scholars whose work did not quite fit within disciplinary boundaries. He gave brilliant young officers (like the four-star-general officer who eulogized him) an opportunity to sit for a couple of years getting smart. He did not mind investing in some intellectual drilling that yielded only dry holes, because he knew that that was the price of exploration. And, in a lesson to all self-important people, if he thought you might possibly have something to say, he would sit and listen to you no matter how old you were, where you went to school, or what your status was.

St. Andrew’s Prep may have some reunions (there is a foundation named after Andy), but he was the centripetal force that held it together. That is fine; he knew that nothing lasts forever, and that it was time for others to do his kind of mentoring, exploring, and inquiring about what makes the world of strategy spin. He left behind webs of friendship and connection, and an American tradition of strategic thinking that will live well beyond him.

In recent years, grim-faced or obsequious Russian and Chinese officers came to Washington seeking the mysterious secrets of the impassive brain of the Pentagon. They had pored over every reference to him (not many) in the press, and sought the hidden mysteries in his still scantier writings. They knew that he had anticipated the transformative effects of the information revolution on warfare, and wondered what he saw coming next. They would have loved to have purloined and secretly photographed the folder covered with security stamps labeled “The Really Big Secrets of Net Assessment.”

It does not exist, of course, though they will not believe it. They may never understand that his real secret was that of a roving mind and a patient intellect, married to the spirit of a masterly teacher and generous friend. If they only knew it, they would realize that the real secret to Andy Marshall’s success could begin to be found in the broad smiles and loud laughs as St. Andrew’s Prep celebrated its times with its wise mentor, the kindly, not entirely inscrutable brain of the Pentagon.



I was willing to give Bill Barr a chance. Consider me burned.

When Barr was nominated, I wrote a cautious piece for this magazine declining to give him “a character reference” and acknowledging “legitimate reasons to be concerned about [his] nomination,” but nonetheless concluding that “I suspect that he is likely as good as we’re going to get. And he might well be good enough. Because most of all, what the department needs right now is honest leadership that will insulate it from the predations of the president.”

When he wrote his first letter to Congress announcing the principal conclusions of the Mueller report, I wrote another piece saying, “For the next two weeks, let’s give Attorney General William Barr the benefit of the doubt” on the question of releasing the report in a timely and not-too-redacted fashion.

I took a lot of criticism for these pieces—particularly the second one, in which I specifically said we should evaluate Barr’s actual performance in regard to releasing the Mueller report, and thus wait for him to act, rather than denouncing him preemptively.

Barr has now acted, and we can now evaluate his actual, rather than his hypothesized, performance.

It has been catastrophic. Not in my memory has a sitting attorney general more diminished the credibility of his department on any subject. It is a kind of trope of political opposition in every administration that the attorney general—whoever he or she is—is politicizing the Justice Department and acting as a defense lawyer for the president. In this case it is true.

Barr has consistently sought to spin his department’s work in a highly political fashion, and he has done so to cast the president’s conduct in the most favorable possible light. Trump serially complained that Jeff Sessions didn’t act to “protect” him. Matthew Whitaker never had the stature or internal clout to do so effectively. In Barr, Trump has found his man.

Ironically, the redactions on the report—the matter on which I urged giving Barr the benefit of the doubt—are the one major area where his performance has been respectable. On this matter, he laid out a time frame for the release of the report. He met it. His redactions, as best as I can tell, were not unreasonable, though they were aggressive in some specific areas. To whatever extent he went overboard, Congress has a far-less-redacted version. The public, in any event, has access to a detailed account of Mueller’s conclusions. On this point, Barr did as he said he would.

Where Barr has utterly failed, by contrast, is in providing “honest leadership that insulates [the department] from the predations of the president.” I confess I am surprised by this. I have never known Barr well, but I thought better of him than that.

The core of the problem is not that Barr moved, as many people worried he would, to suppress the report; it is what he has said about it. I have spent a great deal of time with the Mueller report, about which Barr’s public statements are simply indefensible. The mischaracterizations began in his first letter. They got worse during his press conference the morning he released the document. And they grew worse still yesterday in his testimony before the Senate Judiciary Committee.

Barr did not lie in any of these statements. He did not, as some people insist, commit perjury. I haven’t found a sentence he has written or said that cannot be defended as truthful on its own terms, if only in some literal sense. But it is possible to mislead without lying. One can be dishonest before Congress without perjury. And one can convey sweeping untruths without substantial factual misstatement. This is what Barr has been doing since that first letter. And it is utterly beneath the United States Department of Justice.

The dishonesty only begins with the laughably selective quotation of Mueller’s report in Barr’s original letter, the scope of which Charlie Savage laid out in a remarkable New York Times article shortly after the full report was released. I urge people to look at Savage’s side-by-side quotations. The distortion of Mueller’s meaning across a range of areas is not subtle, and it’s not hard to understand why Mueller himself wrote to Barr saying that the attorney general’s letter “did not fully capture the context, nature, and substance of this Office’s work and conclusions.”

Barr, before the Senate yesterday, described the letter as “snitty.” Actually, it was generous. As Paul Rosenzweig summarized the situation on Lawfare, “the excerpts of the report contained in Barr’s original summary letter are at best a favorable spin on the report and at worst a rather transparent effort to mislead the public in advance of the report’s release.”

But selective quotation is actually only one of the means by which Barr is misstating Mueller’s findings. Here I want to focus on the substantive content of his mischaracterization of them—that is, not how he is doing it, but what Barr is doing.

As I read them, Barr’s public statements on the report reflect at least seven different layers of substantive misrepresentation, layers which build on one another into a dramatic rewriting of the president’s conduct—and of Mueller’s findings about the president’s conduct. It is worth unpacking and disentangling these misrepresentations, because each is mischievous on its own, but together they operate as a disinformation campaign being run by the senior leadership of the Justice Department.

The first element is Barr’s repeated conflation of that which Mueller has deemed to be not provable to the exacting standards of criminal law with that which is not true at all or for which there is no evidence. Mueller determined that the evidence “did not establish” Trump-campaign participation in a criminal conspiracy with the Russians to interfere in the 2016 presidential election. Mueller also makes clear that when his report describes that “the investigation did not establish particular facts,” this “does not mean there was no evidence of those facts.”

Yet Barr frequently talks as though Mueller found nothing of concern with respect to the underlying conduct on the part of the Trump campaign. “So that is the bottom line,” Barr said at his press conference. “After nearly two years of investigation, thousands of subpoenas, and hundreds of warrants and witness interviews, the special counsel confirmed that the Russian government sponsored efforts to illegally interfere with the 2016 presidential election but did not find that the Trump campaign or other Americans colluded in those schemes.”

Barr began his next sentence with, “After finding no underlying collusion with Russia …” Note his shift. In the first iteration, Barr is describing—accurately, if generously—that Mueller “did not find” something. By the second, however, he has pivoted to imply that Mueller found it didn’t happen. Barr vacillates in his public statements frequently from such careful, lawyerly descriptions of what Mueller did not find or establish to sweeping statements of vindication for Trump and his campaign.

The text of the Mueller report leads me to suspect that Mueller does not share Barr’s cavalier attitude toward the voluminous contacts between Russians and Trump-campaign figures and the positive enthusiasm for, and pursuit of, hacked emails on the part of the campaign. Had Mueller found no evidence of conspiracy, rather than insufficient evidence, he would have said so.

Barr’s second sleight of hand—also visible in the quotations above—is rendering the absence of a criminal-conspiracy charge as reflecting an active finding of “no collusion.” These two are very different matters. Conspiracy is a criminal charge. Collusion is a colloquial claim about history. Yet Barr, at his press conference, actually said that “there was in fact no collusion.” He used the phrase no collusion over and over. He even described it as the investigation’s “bottom line.”

In other words, Barr is not merely translating the absence of sufficient evidence for charges into a crime’s not taking place; he is translating the crime’s not taking place into an absence of misconduct in a more colloquial sense. He is also using the president’s specific talking point in doing so. This pair of mischaracterizations has the effect of transforming Trump into an innocent man falsely accused.

Barr amplifies this transformation with his third layer of misrepresentation: his adoption of Trump’s “spying” narrative, which states that there was something improper about the FBI’s scrutiny of campaign figures who had bizarre contacts with Russian-government officials or intermediaries. Barr has not specified precisely what he believes here, but yesterday’s Senate hearing was the second congressional hearing at which he implied darkly that the FBI leadership under James Comey had engaged in some kind of improper surveillance of the Trump campaign. In other words, not only is the president an innocent man falsely accused, but he’s now the victim of “spying on a political campaign”—as Barr put it a few weeks ago—by a biased cabal running the FBI.

To evaluate these allegations, we will have to await a forthcoming inspector general’s report on the matter. And Barr has promised some kind of review of his own as well. Suffice it for the present to say that I have seen no evidence to support these suggestions, which imply a kind of politically motivated “witch hunt” against Trump. Again, Barr is supporting political tweeting points of the president.

And here’s the fourth layer of misrepresentation. Barr has repeatedly insisted that our long-suffering president fully cooperated with the investigation, notwithstanding its illegitimate birth and the fact that there was nothing to any of the allegations it investigated. “The White House fully cooperated with the special counsel’s investigation, providing unfettered access to campaign and White House documents, directing senior aides to testify freely, and asserting no privilege claims,” he said at his press conference.

I suspect this would also come as a surprise to Mueller, who might point out that Trump tried to get witnesses not to cooperate—dangling pardons and seeming to threaten their families with investigation if they “flipped.” Mueller might point out that Trump tried to fire Mueller for conflicts that his own staff regarded as “silly” and “ridiculous.” Mueller might point out that Trump tried to rein in his jurisdiction, limiting him to the investigation of future electoral interference. Mueller might point out that Trump refused to sit for an interview and, even in written answers, refused to address questions concerning allegations of obstruction of justice. I say “might,” but Mueller actually did point all these things out in his report. Ignoring this reflects an astonishing conception of cooperation from the nation’s top prosecutor.

Fifth, it is on the collective back of these prior misrepresentations that Barr rests his particularly generous interpretation of intent in considering questions of obstruction. It is hard to read Mueller’s account of the president’s conduct as reflecting chiefly noncorrupt motives. But if you first adopt the fiction that the investigative subject is an innocent man falsely accused and being pursued by politically motivated FBI agents engaged in improper “spying,” and that he is nonetheless endeavoring in good faith to cooperate with his prosecutors, that does change the lens through which you look at his conduct. One might then indeed tend toward forgiving interpretations of the occasional eruption of anger.

One might then find, as Barr did in Mueller’s report, “substantial evidence … that the President was frustrated and angered by a sincere belief that the investigation was undermining his presidency, propelled by his political opponents, and fueled by illegal leaks.” And one might then find that evidence of such “non-corrupt motives weighs heavily against any allegation that the President had a corrupt intent to obstruct the investigation.” The trouble is that if you don’t first adopt these conceits, the weight of the evidence Mueller cites on intent really doesn’t push in that direction. It pushes in exactly the opposite direction.

Barr adopts, sixth, a related mode of obfuscation with respect to obstruction, which is to disaggregate all the episodes Mueller considers and view them in isolation from one another. Mueller specifically urged that the pattern of behavior was important. “Although the events we investigated involved discrete acts,” he wrote, “it is important to view the President’s pattern of conduct as a whole. That pattern sheds light on the nature of the President’s acts and the inferences that can be drawn about his intent.”

Indeed, it is very hard to look at Trump’s behavior toward the investigation over two years and not see malign intent. But isolate any specific fact pattern among the 10 Mueller describes, and you can diminish it. Look at any one in isolation, and—particularly if you have Barr’s hard-line views of presidential power—you might see a facially legitimate exercise of that power for which there is a plausible noncorrupt motive to which Mueller has indeed scrupulously nodded. If you miss the forest for the trees, you will miss the deforestation as well.

Finally, Barr conflates Mueller’s decision not to evaluate presidential obstruction with a decision on his part that the evidence is insufficient to find that Trump committed crimes. This is a very important misdirection on Barr’s part, because it allows him to imply not merely that he does not believe that the president committed crimes, but that Mueller does not, either.

Both at the press conference and in yesterday’s hearing, the attorney general insisted that Mueller had told him that it was not merely the Justice Department’s legal opinion stating that the president could not be indicted that prevented him from concluding that Trump had obstructed justice. “He made it clear that he had not made the determination that there was a crime” but for the opinion, Barr said at the press conference. The implication is that the issue was not just one of legal authority, but that the evidence wasn’t there either.

I don’t know what Mueller told Barr privately, but the report does not support this claim. Mueller lists four “considerations that guided our obstruction-of-justice investigation.” The first of them states that the Justice Department “has issued an opinion finding that ‘the indictment or criminal prosecution of a sitting President would impermissibly undermine the capacity of the executive branch to perform its constitutionally assigned functions’ in violation of ‘the constitutional separation of powers.’” Because Mueller is an officer of the Justice Department, “this Office accepted [the department’s] legal conclusion for purposes of exercising prosecutorial jurisdiction.”

The use of the word jurisdiction here is not casual. It means that Mueller believes he lacks the authority to indict the president. Because of that, he goes on to explain, he did not evaluate the evidence to render a traditional prosecutorial judgment. The report offers no support for the notion that Mueller stayed his hand on obstruction out of concern for the strength of the evidence.

The effects of these layers of mischaracterization are to rewrite the Mueller report and to recast the presidential conduct described in it. The direction of the recasting just happens to dovetail with the president’s talking points, and just happens to transmute him from a scofflaw with power into a victim of the “deep state.”

The mystery is why Barr is doing this. In an op-ed yesterday in The New York Times, Comey offered one hypothesis, writing that “amoral leaders have a way of revealing the character of those around them” and that “proximity to an amoral leader reveals something depressing. I think that’s at least part of what we’ve seen with Bill Barr and Rod Rosenstein. Accomplished people lacking inner strength can’t resist the compromises necessary to survive Mr. Trump and that adds up to something they will never recover from.”

This may be right. It may be the case that Barr knows that he’s spinning, and that he’s doing it—having had his soul eaten by Trump “in small bites,” in Comey’s poetic formulation—to preserve his position in the mad king’s court.

But we should also consider what is perhaps a scarier hypothesis: What if Barr actually believes it all? That is, what if he has sufficiently become a creature of the factual ecosystem of Trump’s support that he truly believes that the real problem here was not a president who accepted (noncriminally, of course) assistance from a hostile foreign power during his campaign, lied serially about it, and tried repeatedly to frustrate investigation of his conduct? What if Barr actually believes that closing a criminal case on these matters is the end of the historical conversation, as well as the end of the criminal conversation? What if he is actually untroubled by the substance of what Mueller reported and, like Rudy Giuliani, believes it’s okay for presidential candidates to take “dirt” from foreign governments on their rivals and okay for presidents to call up investigations of those rivals? What if he really believes that the true problem here was the investigators?

In some ways, the only thing scarier than an attorney general who would knowingly and cynically deliver the layers of misinformation Barr has been dishing is one who would do so because he’s all in on a collective delusion.



Kyle Kashuv won’t be going to Harvard next year. The young gun-rights activist and survivor of the February 14, 2018, Parkland school shooting that killed 17 of his schoolmates had his admission rescinded once Harvard learned that he had used racial slurs while editing a document shared with friends, including a reference to a black classmate as a “niggerjock.” Kashuv apologized for his past remarks, but also criticized Harvard for its own racist past, arguing that rejecting him was “deciding that someone can’t grow, especially after a life-altering event like the shooting.”

The news of Kashuv’s rescinded admission sparked anger on the right, where pundits such as Ben Shapiro accused Harvard of being “disgusting,” arguing that in “a normal world, [his apology] would have been enough.” Mainstream media outlets have been similarly enraptured with the story, which not only touches on recurring questions about redemption and forgiveness, but also fits neatly into the class concerns of the media elite. Newsrooms are more male, less diverse, and more educated than the American workforce at large, so the children of most journalists are unlikely to be the targets of racial slurs.

Young people are being more frequently deployed as advocates and symbols in American political disputes. Both right and left have their young champions, and both sides sometimes forget that, despite their presence in the public eye, these are, in fact, children. That perspective should not be lost in a haze of rage over their political advocacy. At the same time, to paraphrase James Baldwin, children may not listen to the adults in their lives, but they never fail to imitate them. Perhaps Kashuv’s remarks were just an example of a teenager pushing the limits of decency, as some teens are wont to do—or perhaps, like many of his peers, he perceives the essence of Trumpism to be something adults are loath to acknowledge. As Alex Pareene put it, “Teens, while quite good at figuring out ways to hurt people, are less skilled at plausible deniability.”

But even when children make mistakes, sometimes horrible mistakes that hurt others, that does not mean that they should be condemned to be pariahs for the rest of their lives. It also doesn’t mean that the consequences imposed on Kashuv for his remarks were disproportionate—Harvard has rescinded other offers of admission in similar circumstances, albeit with less fanfare. An apology, even a heartfelt one, does not mean one immediately gains back what was lost.

At National Review, David French argues that Kashuv’s rejection is an example of an ascendant and unforgiving cultural liberalism that is replacing the Christian forgiveness that preceded it. “I know how much a person can grow, and I know that adversity and mistakes are often the catalyst for growth,” French writes. “But woke culture has forgotten those lessons. Woke culture treats a teen like an adult and tries to crush his public reputation when his character is still in its infancy.”

French is right about the tenor of online discourse, which is largely about punishing and humiliating one’s enemies for the approval of one’s allies, a game no one who uses social media successfully avoids all the time. There is little room online for mercy, forgiveness, or respect. But that is largely a reflection of America’s culture of punishment, a culture whose mercilessness toward the young manifested itself in American law long before woke became an ironic term of derision in conservative circles. It is more correct to say that America’s punitive culture has only recently manifested itself in ways that affect the kinds of families who send their children to places like Harvard.

America asks a great deal of those children who are born into difficult circumstances, and punishes them brutally when they stumble. America asks very little of those born into lives of plenty or relative plenty, and offers them comfort when they fail. Yet the children America throws away are no less children than the ones it deems worthy of protection.

For starters, the United States currently employs a policy of systemic child abuse toward thousands of migrant children as a deterrent to illegal immigration. The Trump administration rescinded the Obama-era program that granted a temporary reprieve to undocumented immigrants brought to the United States as children, making hundreds of thousands of people subject to exile from the only country they’ve ever known, because of the actions of their parents. The current administration not only treats being in the U.S. illegally as an unforgivable crime, but also transfers culpability from parents to children. As one of the president’s favorite Fox News personalities, Brian Kilmeade, put it, “These are not our kids.”

American children are not exempt from this punitive approach. Last year, Education Secretary Betsy DeVos revoked an Obama-era initiative designed to prevent racial discrimination in school punishment. To this day, Donald Trump maintains that the Central Park Five are guilty, despite DNA evidence exonerating them. As with all of Trump’s false claims, this one has produced a cottage industry of conservative pundits defending a Trumpian falsehood by endorsing the indefensible, in this case the use of confessions coerced from teenagers.

Yet America’s love affair with draconian punishment did not begin with Trump. More than a dozen states set no floor on the age at which they can try children in criminal court as adults, and more than 100,000 children are confined in adult prisons each year. The execution of minors was held to be unconstitutional only in 2005, and life without parole for juvenile offenders was found to be unconstitutional only in 2012. Both were 5–4 decisions, made over the objections of the high court’s conservatives. In both cases, former Justice Anthony Kennedy joined the Court’s Democratic appointees, much to the chagrin of conservative legal activists.

Sometimes kids commit serious crimes—out of fear, peer pressure, avarice, or even self-defense. Sometimes they are simply the wrong color, in the wrong place, at the wrong time. Sometimes they just make mistakes. But one thing is certain: They are not adults, until the law decides that doesn’t matter.

Republicans bear a great deal of the blame, but America’s punitive culture is deeply bipartisan. It was Democratic President Bill Clinton who signed the 1994 crime bill authorizing the prosecution as adults of children as young as 13, and the current Democratic presidential front-runner, Joe Biden, who wrote it. Democrats such as Hillary Clinton seized on the racialized fear that some young Americans had become “superpredators,” remorseless killing machines who no longer needed to be treated like children. At the state and federal levels, lawmakers in both parties mobilized the punitive power of the state against children who, in their eyes, were irredeemable monsters. Adopting an unforgiving posture toward children—the “not our kids” kind of children—was part of how Democrats sought to shed the worrisome label that they were “soft on crime,” and may yet again, should the president prevail in 2020.  

The simple truth is that, for much of the American electorate, particularly those voters who rarely come into contact with the criminal-justice system, punishment is popular, and forgiveness is unpopular. The nation has been this way for decades, a global outlier in the length, conditions, and nature of the punishments it applies to both children and adults. Nor have many of those on the right demanding Harvard reverse its decision been particularly merciful to others. Gun-rights activists may be demanding forgiveness and understanding for Kashuv, but the NRA has been unrelenting in justifying the killing of black people by law enforcement, no matter how absurd the circumstances. Shapiro himself observed what would have been the 21st birthday of Trayvon Martin with a cruel joke, mocking a teenager who was stalked and killed by an adult with a firearm following a physical confrontation. Although he found Kashuv’s rejection from Harvard “disgusting,” he declared the shooting of Tamir Rice, a 12-year-old black boy with a toy gun who was killed by a police officer, “justified.” No, children should not pay for their errors by being punished for the rest of their lives, but neither should they forfeit those lives because an adult looks at them in fear.

As for Kashuv, he stands at a crossroads. He can choose a comfortable life in the public eye as a right-wing martyr to the cause of destigmatizing overt expressions of bigotry, an ideological project that has become increasingly urgent with the election of a Republican president for whom such expressions are common. Or he can reject that opportunity, reflect on his own conduct, and atone by choosing a different path. No one should spend adulthood paying for mistakes they made at 16, particularly not if they make amends.

But that ideal of charity should not begin and end with a young man denied admission to Harvard, or be offered exclusively to those children who remind the elite classes of themselves. Even a cursory glance at American law shows that some children can expect to receive only the rod, and others only the spoils. The children American society has traditionally considered “good kids” should not be the only ones who get the benefit of the doubt, or the only ones seen as worthy of mercy.



America’s relationship with China has taken a turn toward the confrontational. Tariffs are rising, rhetoric is heating up, and both sides are digging in. For all the efforts at a resolution, this current phase will likely be remembered as merely the opening skirmish in a long-term competition. The China contest now represents a key organizing principle of American foreign policy. Even a successful trade agreement would represent only the end of the beginning in a new era.

If Donald Trump and Xi Jinping strike a deal—perhaps at their planned meeting during next month’s G20 summit—it will be partial at best. Perhaps Beijing will commit to buying more American farm products, natural gas, and autos, for example, while pledging (again) not to steal intellectual property. Such a deal would resolve just a fraction of the economic disagreements dividing Washington and Beijing, and arguably not the most important ones. Larger issues—such as subsidies to Chinese state-owned enterprises, unfair investment rules, forced technology transfer, and government influence over firms like Huawei—are intrinsic to the fundamental Chinese economic model. They are largely intractable and not amenable to resolution.

An indication that this conflict is here to stay is the striking bipartisan support for President Trump’s approach. Unlike every other aspect of the president’s foreign policy—toward Iran, for instance, or North Korea, Saudi Arabia, or Russia—Washington’s Democrats and Republicans largely agree that the time for a reckoning with China has come. Democratic leaders on Capitol Hill tend to signal agreement with the president, suggest that he’s not tough enough with Beijing, or remain silent. Some quibble with Trump’s objectives (such as his fixation on reducing the trade deficit), but virtually everyone in power seems to believe that America’s tone should be sharp and tolerant of risk.

That may change, as Trump has begun using the issue to batter 2020 candidates such as Joe Biden, holding himself out as uniquely tough and clear-eyed about the challenge. But for now, most of the Democratic presidential candidates have remained quiet, taking care not to out-hawk Trump or label him overly aggressive.

Beyond the Beltway, Americans seem willing to absorb the cost of “winning” the trade war. A large proportion of the same farmers who can no longer sell soybeans to China express support for Trump’s policy on national-interest grounds. Unlike in the past, many corporate leaders privately urge an even tougher approach. With shrinking constituencies on both sides urging comity over confrontation, the bilateral relationship is exposed to the full force of direct competition.

Of course, it’s possible that the business community remains relatively silent because the costs to it, so far, are relatively modest. Once the tariffs really bite, if farmers begin to file for bankruptcy, or if the prohibitions on dealing with key Chinese companies imperil whole markets, that tone may change.

So far, the trade conflict isn’t bleeding into other areas. Xi has not, for example, sought better trade terms by dialing back cooperation on North Korea. Trump has not offered a larger weapons package to Taiwan or made moves in the South China Sea in order to gain leverage.

But contentious issues may not remain siloed forever. A key feature of Cold War politics, at least in the 1970s, was linkage—rewarding cooperation in one area by relaxing tension in another, punishing bad behavior in one domain by imposing costs elsewhere. Linkage in the U.S.-China context could turn a complex and difficult relationship into an unbounded conflict. As the stakes rise, both sides may try to gain advantage in one area by acting in another, and competition could cross domains as varied as defense, technology, diplomacy, information, and more.

Trade in theory is a win-win domain. After all, trade is the most positive-sum of all foreign-policy activities; parties enter into a transaction only if both expect to benefit. Yet as we’ve seen, even here disagreements between China and the United States are deep, and resolution remains elusive. That portends heat on harder issues such as Taiwan, military technology, the South China Sea, and human rights.

Trump and Xi may ink a deal soon, and announce it to a relieved world with great fanfare. Or not. Either way, the underlying forces that brought the two sides to this point are not going away.



Is Maggie Denang deserving of your money? How about Tomas Vargas Jr.?

Denang and Vargas are residents of Stockton, a high-poverty city on the outskirts of the Bay Area’s technology-and-wealth boom. They are also participants in a much publicized, pathbreaking project, the Stockton Economic Empowerment Demonstration, in which 130 people are receiving $500 a month for 18 months, to use however they see fit. The experiment raises the question of whether Vargas and Denang are worthy of no-strings-attached cash, or whether anyone is, or everyone is.

The program’s proponents have argued that its test subjects would be good stewards of the resources. They would use the money to improve their lives, keep the bills paid, and plan for the future—and Stockton would benefit from a little economic stimulus as they did. But the project has country-sized ambitions, not just neighborhood-sized ones. It wants to show the United States, in this age of late-capitalist excess, fear-stoking automation, polarized politics, and surging socialism, that individuals are the best judges of how to spend the resources that they have.

SEED is the brainchild of Stockton’s mayor, Michael D. Tubbs, and the Economic Security Project, a think tank and advocacy group focused on studying and promoting cash transfers in the United States. The pilot had few enrollment criteria: The recipients had to be adults in a Stockton neighborhood where the median income was at or below the city average of $46,033 a year. SEED sent letters to a randomly selected group of households meeting those criteria, and then signed up a randomly selected group of individuals who responded. In February, enrollees began receiving $500 a month, loaded onto a debit card. They were told to use the money however they wanted, with researchers studying how they fared and a group of participants agreeing to talk with the media about their lives starting this week.

Denang expressed shock at having the money fall from the sky. “I keep pinching myself,” she told me at the SEED office in Stockton. (Denang asked me not to use her full name, to help maintain her family’s privacy.) The money could not have come at a better time, she said. The native of the Northern Mariana Islands had worked as a certified nurse assistant before health issues prompted her to retire and focus on her volunteer work at a local community center. As of last year, her husband was working in seafood processing in Alaska. The pay was only $9 or $10 an hour, she told me, but with significant potential for overtime.

Then, one day in June, she did not hear from him. Three long, frightening days went by before a nurse called her to say that her husband had been medevaced to Anchorage, suffering from a kind of stroke. When she was reunited with him, she found a profoundly changed man, one still suffering today from ministrokes, paralysis, and problems with his speech and mobility.

This being the United States, the family’s medical emergency fast became an economic emergency. Denang had no income. Her husband had no income. Before SEED, the two were getting by on his $244 a month in state disability payments and her $850 a month in federal disability payments, meaning they were falling below the poverty line.

“It is a blessing,” Denang said of SEED, tearing up as she described how the $500-a-month infusion had helped them cover their bills, given them time to enroll her husband in the Social Security disability program, and let them make a plan for her to become his caregiver. She watched every single dollar, she said: When we spoke, she still had $88 left over from last month, having spent the rest on food and other necessities. She added that she and her husband had not applied for all the government benefits they likely qualified to receive.

For Vargas, the money was less of an insurance policy than a capital investment. A father and husband who works as a manager at a logistics company, Vargas told me he was using it on summer tutoring for his children, and had plans to get another degree for himself and to create investments that would spin off passive income for the family. He said that the money had also allowed him to give up some of the side gigs he took on to keep the family’s bills paid, such as fixing up cars in the evening and acting as a handyman on the weekend. “We have more family time,” he said. “I get to read bedtime stories now, and to find out what the kids did at school. The stuff that’s really important.”

Both Vargas and Denang stressed again and again, openly and subtly, how careful they were with the funds. Both had developed detailed plans for how to use the money and what to do when the payments stopped. Both stressed that they were spending only on necessities or investments. They understood, it seems to me, that there would be public scrutiny of the way people in Stockton used the money—just as there is public scrutiny of many public-benefit recipients. Vargas told me he was eager to talk to the media, to portray Stockton in a positive light and help people understand the experiment. Denang said she supported these kinds of initiatives, but worried that if everyone got this kind of money, some would spend it on things like liquor.

But what if the vast majority of people, given the chance, would be good stewards of helicopter money, like Denang and Vargas were? What if public policy were predicated on that kind of trust and lack of judgment?

SEED wants to make those what-ifs reality, showing that just giving people money would be a humane and cost-effective intervention, versus providing vouchers or food stamps or complicated tax incentives. The concept—often described as a guaranteed income, unconditional cash transfer, or universal basic income—might sound far-fetched. But it has significant cachet in the Bay Area. SEED is one of several UBI-type pilots operating in the United States, and around the world. (I wrote about many of them in my 2018 book on the subject, Give People Money.) And many Democrats are pushing for big cash policies, among them the senator and 2020 hopeful Kamala Harris.  

As it is, America’s means-tested social policies operate with very little trust, as do many of its nonprofits and charities. Many states drug-test welfare recipients. The government limits what individuals can buy with food stamps or WIC funds (no imported cheese, for instance), with a number of state legislators pushing provisions that would stop families from buying luxuries such as steak and lobster as well as junk food. But study after study has shown that cash transfers do not lead families to consume more vice goods, such as cigarettes and alcohol. As a general point, cash-transfer programs tend to increase families’ consumption of the basics, and in some cases allow them to make investments that improve their income down the road. When they get cash, people tend to act like Vargas and Denang do, in other words.

Maybe, then, the government and private donors should butt out of people’s wallets and grocery carts and pocketbooks, letting them use the money as they see fit. “As an elected official, if you can’t trust your residents or the majority of your residents to make good decisions, why would you trust them to vote for you?” Tubbs, the mayor of Stockton, told me. “You have to learn that, and also learn the limits of our own knowledge. Finances are so volatile and so personal.” When families get cash, they can put the money to their most urgent need and their own best use.

For Denang, that means groceries; for Vargas, an investment in better jobs and more education for the whole family. For each of us, something wildly different and changeable and unpredictable—something only cash, and trust, would help us find.



“There is a mysterious cycle in human events,” said Franklin Delano Roosevelt, accepting the Democratic nomination for president in Philadelphia in 1936. “To some generations much is given. Of others much is expected. This generation of Americans has a rendezvous with destiny.”

In the 20th century, many sociologists and historians flirted with the idea that generational changes could explain U.S. politics. The historians Arthur Schlesinger Sr. and Jr. wrote about “cycles of American history,” arguing that, as the generations turn, American politics rotates inexorably between liberal and conservative consensus. More recently, a new generational scheme has come into vogue. William Strauss and Neil Howe’s theory of the “fourth turning” predicts a crisis and a major political realignment every 80 to 90 years. (Strauss and Howe were briefly in the spotlight in 2016 after Steve Bannon praised their work.)

We are skeptical about cyclical theories of history. We are also aware of the slipperiness of generations as categories for political analysis. As Karl Mannheim pointed out more than 90 years ago, a generation is defined not solely by its birth years but also by the principal historical experience its members shared in their youth, whatever that might be. Nevertheless, we do believe that a generational division is growing in American politics that could prove more important than the cleavages of race and class, which are the more traditional focuses of political analysis.

Representative Alexandria Ocasio-Cortez is often described as a radical, but the data show that her views are close to the median for her generation. The Millennials and Generation Z—that is, Americans aged 18 to 38—are generations to whom little has been given, and of whom much is expected. Young Americans are burdened by student loans and credit-card debt. They face stagnant real wages and few opportunities to build a nest egg. Millennials’ early working lives were blighted by the financial crisis and the sluggish growth that followed. In later life, absent major changes in fiscal policy, they seem unlikely to enjoy the same kind of entitlements enjoyed by current retirees.

Under different circumstances, the under-39s might conceivably have been attracted to the entitlement-cutting ideas of the Republican Tea Party (especially if those ideas had been sincere). Instead, we have witnessed a shift to the political left by young voters on nearly every policy issue, economic and cultural alike.

As a liberal graduate student and a conservative professor, we rarely see eye to eye on politics. Yet we agree that the generation war is the best frame for understanding the ways that the Democratic and Republican parties are diverging. The Democrats are rapidly becoming the party of the young, specifically the Millennials (born between 1981 and 1996) and Gen Z (born after 1996). The Republicans are leaning ever more heavily on retirees, particularly the Silent Generation (born before 1945). In the middle are the Gen Xers (born between 1965 and 1980), who are slowly inching leftward, and the Baby Boomers (born between 1946 and 1964), who are slowly inching to the right.

This generation-based party realignment has profound implications for the future of American politics. The generational transition will not dramatically change the median voter in the 2020 election—or even in 2024, if turnout among young voters stays close to the historical average. Yet both parties are already feeling its effects, as the dominant age cohort in each party recognizes its newfound power to choose candidates and set the policy agenda. Drawing on opinion polls and financial data, and extrapolating historical trends, we think that young voters’ rendezvous with destiny will come in the mid to late 2020s.

Today, the older generations have a lock on political power in Washington. House Speaker Nancy Pelosi and Senate Majority Leader Mitch McConnell are members of the Silent Generation. So are Joe Biden and Bernie Sanders, who lead in nearly every poll of the 2020 Democratic primary. President Donald Trump and the median senator and representative are Boomers. Of the nine justices on the Supreme Court, two are from the Silent Generation and six are Boomers. Yet the median American is 38—a Millennial.

Over the past year, the Democratic Party’s geriatric leadership has begun to feel the ground moving beneath its feet. For decades, moderate Democrats have kept a tight grip on the party’s platform. The 2018 midterm elections were a watershed. Boomers and members of the Silent Generation still make up more than three-fifths of the party’s House members and hold all major leadership roles. But newly elected members—including 14 Millennials and 32 Gen Xers—are driving the conversation on policy, from Ocasio-Cortez’s Green New Deal to a recent resolution to withdraw support from Saudi Arabia’s war in Yemen.

The Democrats have responded by moving left. In 2013, President Barack Obama signed a bill to cut the budget deficit by slashing hundreds of billions of dollars in spending. But already in 2019, a majority of the House Democratic caucus has co-sponsored a Medicare for all bill. Even those 2020 presidential candidates characterized as moderates, such as Kamala Harris and Cory Booker, have endorsed Ocasio-Cortez’s Green New Deal, which calls for trillions of dollars of deficit-funded federal spending to transform America’s economy and its energy sector.

If Roosevelt was right, and demographics are destiny, then the Democrats are going to inherit a windfall. Ten years from now, if current population trends hold, Gen Z and Millennials together will make up a majority of the American voting-age population. Twenty years from now, by 2039, they will represent 62 percent of all eligible voters.

If the Democrats can organize these two generations into a political bloc, the consequences could be profound. Key liberal policy priorities—universal Medicare, student-loan forgiveness, immigration reform, and even some version of the Green New Deal—would stand a decent chance of becoming law. In the interim, states that are currently deep red could turn blue. A self-identifying democratic socialist could win the presidency.

By contrast, from the perspective of pure demographics, the GOP seems to be playing a losing hand. Unless Republicans can find a way to stop young voters’ slide to the left in the 2020s, the party will survive only if it can pull older voters—Boomers and the remaining members of the Silent Generation—to the right fast enough to compensate for the leftward shift of the young.

Millennials cannot be blamed for concluding that the economy is rigged against them. True, in absolute terms, Americans under 40 carry less debt than middle-aged Americans. But their debt profile is toxic. Nearly half of it comes from student loans and credit cards. In contrast, 72 percent of the debt held by Americans aged 40 to 49 is mortgage debt, which comes with tax advantages and allows debtors to build home equity as they repay their loans.

Meanwhile, the job market has turned a college education into a lose-lose choice for many young Americans. In 2016, a single year of tuition, room, and board at a private college cost 78 percent of median household income. Most American families can barely afford to send even a single child to college without loans, let alone two or three. Yet young workers without a college degree are deeply disadvantaged in the workforce, and more so all the time.

Young people then struggle to stay above water financially after they graduate. The net worth of the median Millennial household has fallen nearly 40 percent since 2007. This is not because they eat too much avocado toast; it is because student loan payments consume the income that they would otherwise save. Headline unemployment figures show that the labor market is humming. It does not feel that way for Millennials, who have never experienced a “good economy.”

It is therefore unsurprising that large majorities of young voters support economic policies that Ocasio-Cortez describes as “socialist.” According to a Harvard poll, 66 percent of Gen Z supports single-payer health care. Sixty-three percent supports making public colleges and universities tuition-free. The same share supports Ocasio-Cortez’s proposal to create a federal jobs guarantee. Many Gen Z voters are not yet in the workforce, but 47 percent support a “militant and powerful labor movement.” Millennial support for these policies is lower, but only slightly.

Younger voters are also far left of center on most other economic and social policies. They are particularly opposed to the Trump administration’s handling of immigration. Americans 35 and older are nearly evenly divided on the issue of President Trump’s border wall. Among voters under 35, this is not even a question. Nearly 80 percent oppose the wall.

Gen Z are not a trusting bunch. Students tend to believe that their college or university administration will do the right thing “always” or “most of the time.” Contrary to conventional wisdom, young Americans trust the military and law enforcement more than other institutions. But they take an extremely dim view of Trump, Congress, Wall Street, the press, and the social-media platforms where they get their news: Twitter and Facebook.

When the question is posed as an abstraction, most Gen Zers don’t trust the federal government either. But they favor big-government economic policies regardless because they believe that government is the only protection workers have against concentrated corporate power.

Philosophically, many Gen Zers and Millennials believe that government’s proper role should be as a force for social good. Among voting-age members of Gen Z, seven in 10 believe that the government “should do more to solve problems” and that it “has a responsibility to guarantee health care to all.”

Young voters are also far more willing than their elders to point to other countries as proof that the U.S. government isn’t measuring up. Gen Z voters are twice as likely to say that “there are other countries better than the U.S.” than that “America is the best country in the world.” As Ocasio-Cortez puts it: “My policies most closely resemble what we see in the U.K., in Norway, in Finland, in Sweden.”

Will Gen Z voters moderate their views after they enter the labor force? Probably not. Irving Kristol once joked that conservatives are liberals who have been “mugged by reality.” But the data don’t support this hypothesis. Most Millennials have already been mugged by reality: competing in the job market, paying taxes, and—for those 26 and older—taking responsibility for their own health care. In the process, they have lurched left, not right. On questions of political philosophy, Millennials are far closer to their juniors in Gen Z than to their elders in Gen X.

Even young Republicans have been caught up in this philosophical leftward drift. Gen Z Republicans are four times as likely as Silent Generation Republicans to believe that government should do more to solve problems. And only 60 percent of Gen Z Republicans approve of Trump’s job performance, while his approval among all Republicans hovers around 90 percent.

In short, Ocasio-Cortez is neither an aberration nor a radical. She is close to the political center of America’s younger generations.

Can the Democratic Party convert this tectonic shift into victory at the ballot box? Maybe, but not necessarily. As the party tries to harness its younger, more progressive wing, it faces three interrelated challenges.

The first challenge is the perennial problem of low youth turnout. Democrats have been working for decades to get more young Americans to vote. They have partnered with organizations such as Rock the Vote to make voting cool. They have invested heavily in social-media microtargeting and experimented with mobile apps that use peer pressure to drive up turnout. Yet they have never gotten youth-turnout rates high enough to swing a close presidential election in their favor. Since 1980, the percentage of eligible voters in their 20s who actually vote in presidential elections has held steady between 40 and 50 percent. For Americans aged 45 and up, voting rates have been far higher: between 65 and 75 percent.

History offers Democrats some reason for hope. The closer an American is to middle age, the more likely he or she is to vote. On the other hand, turnout rates are declining across the board, and it is the 30-to-44-year-old age bracket that has seen the steepest decline over the past four decades. Unless Democrats can show younger voters that their votes translate into policy change, they could find themselves trying to mobilize a generation that is permanently apathetic and politically disengaged.

The second challenge for Democrats is that most of the party’s traditional power brokers are older, and many of them consider the youngsters to be radicals, or at the very least political liabilities. House Speaker Nancy Pelosi has declined to move forward with the Green New Deal. When freshman Representative Ilhan Omar made comments about Israel policy that were widely criticized as anti-Semitic, the Democratic-controlled House voted to voice its opposition. When the Democratic Congressional Campaign Committee tried to block staffers from joining primary campaigns, Ocasio-Cortez told her followers to stop donating. These squabbles could easily lead to a rupture within the party.

The third challenge is that when young people organize, they do it in their own way and on their own terms. By The Washington Post’s count, between 1.4 and 2.3 million people attended the March for Our Lives in 2018, organized by school-shooting survivors from Parkland, Florida. Democratic candidates embraced the students’ cause and made gun control a central issue of the campaign. That may be one reason why early-voting turnout among 18-to-29-year-olds soared. But it was young people driving the agenda and the party following—not the other way around.

The best way for the Democrats to bridge these divides is to redouble the party’s focus on the issue that unites the coalition across generations: health care. In 2018, 41 percent of voters listed health care as their top issue. Three-quarters of them voted for the Democratic candidate.

However, on most other issues, the demographic trend lines are clear: By the mid 2020s, if a preponderance of young voters support an issue, the Democratic Party will probably have no choice but to make it central to the platform. Today, 43 percent of self-identified Democrats are either Gen Zers or Millennials. By 2024, by our calculations, this figure might rise to 50 percent. If the Democrats are not already the party of Alexandria Ocasio-Cortez, they will be soon.

Does all this mean that the Republican Party is doomed? Perhaps not. Even as younger voters have moved to the left, Republicans have been sustaining themselves by winning an ever-greater share of older voters. The Silent Generation moved hard to the right under Obama. In 2008, 38 percent of its members identified as Republicans. By 2016, that figure had risen to 48 percent. But the youngest members are now 75, and they will not be around forever. So Republicans are racing against the clock to pull nonaligned Boomers into the coalition. (It doesn’t hurt that Boomers now comprise fully two-thirds of the House Republican caucus.)

But how? Tax cuts are part of this strategy, but as voter reactions to the 2017 GOP tax bill showed, it’s a policy that yields diminishing political returns. A more important gambit was revealed in Trump’s State of the Union address in February, which drew a link between the disastrous regime of Nicolás Maduro in Venezuela and the emerging Democratic agenda. “We are born free, and we will stay free,” the president declared. “Tonight, we renew our resolve that America will never be a socialist country.”

As a small but growing number of prominent Democrats embrace the label “socialist”—or “democratic socialist,” as Sanders terms it—Republicans smell blood in the water. More than half of young voters may have a positive view of socialism, but sizable strong majorities of all age groups over 30 prefer capitalism. Indeed, voters over 65 feel more positively about capitalism today than in 2010, when Gallup began to ask the question. It remains to be seen whether the 2020 Democratic primary can normalize the word socialist. For now, however, it is clearly a liability for the Democrats in a national election.

Then comes the question of immigration. As we have seen, younger American voters strongly disagree with the Trump administration’s aggressive efforts to “build a wall” along the country’s southern border or limit legal immigration from Muslim-majority countries. This reflects the profound difference between the generations in terms of racial composition. Fully 85 percent of the Silent Generation is white; only 12 percent is black or Latino. Among the members of Gen Z, by contrast, only 54 percent are white, and 38 percent are black or Latino. A far larger proportion of Gen Z also identifies as mixed-race. This divide will widen further in the coming years because of immigration, birth-rate differentials, and the fact that white Americans at age 75 have a higher life expectancy than African Americans.

Negative views of immigration are based on more than just the economic argument that newcomers are lowering the wages of native-born workers or exacerbating shortages of housing or public goods. Such views have a significant cultural component, too. Needless to say, Donald Trump specializes in whipping up the anxieties of older voters about what they see as alarmingly rapid social change.

But the Republicans need to find ways of winning over aging Boomers, many of whom are squeamish about being branded as racists. That is why it makes political sense for them to broaden the culture war, making it about much more than immigration.

According to a Marist poll last December, a sizable majority of Americans under 29 want to see the country become “more politically correct.” But voters over 30 oppose the rise of political correctness by a factor of nearly 2 to 1. This is a wedge issue that Republicans will exploit with gusto.

Republicans will be happy to note that middle-aged voters are even more strongly opposed to political correctness—and all that they believe this entails—than retirees. This trend is unlikely to reverse as the Democratic Party, under the influence of the Ocasio-Cortez cohort, brings issues of cultural and social justice closer to the core of its platform. Nor will it resolve itself as these middle-aged voters’ children become teenagers and go to college, where the culture of social justice is most explicitly disseminated.

Liberals may retort that social values can change with surprising speed. Couldn’t PC culture follow the same trajectory as interracial relationships, gay marriage, and legal marijuana—once taboo, now mainstream?

Perhaps it can, but we think it probably won’t. The gay-marriage debate was about the legal status of a minority. The PC debate is about norms of expression that affect everyone. For many older voters—and not just conservatives—campus politics has become a wholly alien parallel world of safe spaces, trigger warnings, and gender-neutral pronouns. That helps explain the president’s recent executive order to cut off federal funding to colleges that fail to uphold free speech. By taking campus politics national, the GOP will try to pry centrist Boomers and older Democrats away from a party more and more driven by the values of progressive academia.

Generational conflict likely won’t swing national elections until the 2020s, depending on turnout rates and attitudinal shifts among the Boomers. In the short run, this is probably good news for the GOP, as Democrats lurch to the left on identity-based issues that turn off older voters.

Yet Trump’s strategy of single-mindedly courting members of the Silent Generation with issues such as immigration, the evils of socialism, and campus free speech is not a long-term solution for the Republican Party. The more the GOP belittles the preferences of younger voters, the more it risks forging them into a left-wing bloc.

In the 2020s, the Silent Generation will fade from the scene. This will happen at precisely the same time that history suggests younger, more left-wing voters will start to vote at higher rates. To attract more Boomers, and some Gen X men, the GOP may paint the Democrats as radical socialists and do all it can to fan the flames of the culture war. To avoid splintering along generational lines, Democrats will likely redouble their focus on health care, a rare issue that unites the party across all age groups.

In short, America’s political future will be determined by the outcome of the generation war. Can the Millennials and Gen Z organize themselves into a cross-party political bloc? If they succeed, they can dominate U.S. politics within the next 10 years, and the Democratic Party will follow them. But if Republicans can persuade enough Boomer Democrats to switch sides by effectively turning politics into a nationwide culture war, Trumpism could prove longer lived than most commentators today assume.

Will there be any areas of common ground in a political future fueled by intergenerational warfare? Not many. But one suggests itself. Even as the rising cost of Social Security and Medicare place growing pressure on the budget, neither side will have much political incentive to fight for deficit reduction. Republicans’ dreams of privatizing Social Security and trimming Medicare died forever with Paul Ryan’s retirement last year. If anything, the two parties might collaborate to expand and shore up welfare programs, ramping up the deficit in the process. The experience of Japan suggests that, so long as interest rates remain low enough and the demand for government bonds high enough, difficult fiscal decisions can be postponed for much longer and public debt accumulated to much higher levels than conventional economics led us to expect.

When FDR spoke of a new generation’s “rendezvous with destiny,” few in his audience imagined that it would take the form of another world war. Democrats who aspire to the presidency are often tempted to talk in similar, uplifting terms. Barack Obama liked to quote Martin Luther King Jr.’s remark that “the arc of the moral universe is long, but it bends toward justice,” though for Obama it became an arc of history, invariably bending his way. Few Democrats, even on the night of November 8, 2016, could conceive that the arc of history might bend toward Donald Trump.

Cyclical theories that seek to explain and predict political change in terms of generational “turns” should therefore be treated with skepticism. If, as Mannheim argued, generations are shaped by the big events of their youth, then—who knows? —a single black swan could turn today’s kids into Ocasio-Cortez’s worst nightmare: Generation T for Trump. After all, it has been asserted, to the glee of his critics, that the president’s vocabulary is that of a fourth grader. Sure, but that also means fourth graders can understand what Donald Trump says. Today’s fourth graders will be voting in 2028. Perhaps they, too, will be as “woke” as Generation Z currently is. But history teaches us not to assume that.

In 1960, Friedrich Hayek predicted in The Constitution of Liberty “that most of those who will retire at the end of the century will be dependent on the charity of the younger generation. And ultimately not morals but the fact that the young supply the police and the army will decide the issue: concentration camps for the aged unable to maintain themselves are likely to be the fate of an old generation whose income is entirely dependent on coercing the young.” It hasn’t turned out that way at all—a salutary warning that it is much easier to identify generational conflicts of interest than to anticipate correctly the political form they will take.



Defense attorneys often arouse what John Adams called a “clamor of popular suspicions and prejudices” when representing reviled clients. Just last week, the attorney Christopher Darden stopped representing a California man charged with killing the rapper Nipsey Hussle because people were so upset with his choice of client that they demanded to know his fee and threatened the safety of his children.

The vital work of criminal defense has managed to endure in spite of such attacks, thanks to a core of sober-minded citizens in each generation who know better than to pile on. They understand that to defend an accused criminal is not to defend his or her alleged crime—and that conflating the two by imposing social sanctions on attorneys would make criminal trials more like popularity contests.

Educational institutions ought to teach young adults this justice-enhancing logic. Harvard is now teaching its undergraduates how to undermine it.

Its shameful capitulation to popular passions began earlier this year when Ronald Sullivan, an African American law professor and faculty dean with a long history of freeing marginalized innocents from prison, announced that he would be working as a defense attorney for the disgraced Hollywood producer Harvey Weinstein. “Many students expressed dismay, saying that his decision to represent a person accused of abusing women disqualified Mr. Sullivan from serving in a role of support and mentorship to students,” The New York Times reported.

Sullivan was verbally abused, and the residence where his family lives was vandalized with graffiti. A survivor of sexual assault whom Sullivan helped in the past spoke out to The Boston Globe in his defense, as did many of his colleagues at Harvard Law when I contacted them for an article I wrote on the matter.

Sullivan’s colleague Jeannie Suk Gersen was especially prescient when writing in The New Yorker about the controversy:

On the same day as the vandalism, Harvard announced that, in response to “concerns about the impact of this decision on the support that students can expect to receive in the Winthrop community,” the College would undertake a “climate review,” consisting of surveys and interviews of students, after which it would “take actions, as appropriate.” The students were sent a questionnaire asking whether they find Winthrop House “sexist” or “non-sexist,” and “hostile” or “friendly,” among other things. Presumably, if Harvard learns that the “climate” requires it, Sullivan could be fired as dean.

That’s what happened on Saturday: A Harvard administrator announced that Sullivan and his wife, Stephanie Robinson, would not continue as faculty deans.

The reasons offered were vague and euphemistic.

“Over the last few weeks, students and staff have continued to communicate concerns about the climate in Winthrop House,” wrote Rakesh Khurana, dean of Harvard College. “The concerns expressed have been serious and numerous. The actions that have been taken to improve the climate have been ineffective, and the noticeable lack of faculty dean presence during critical moments has further deteriorated the climate in the House. I have concluded that the situation in the House is untenable.”

Sullivan remains a law professor.

Outsiders can’t know to what degree representing Weinstein inspired the ouster, and to what degree longtime critics of the faculty dean, such as the ones alluded to in a Harvard Crimson story attacking his performance, exploited unhappiness about Weinstein to accomplish a long-hoped-for removal.

Either way, Harvard administrators were warned about the unavoidable conflict between upholding an important civic norm––that legal representation for even the most reviled is a service to the community, not a transgression against it—and giving in to the demands of the undergraduates most aggrieved by their faculty dean’s choice of clients. And rather than infer a responsibility of the extremely privileged to uphold civic norms for the benefit of those in society who most need them, this institution, which purports to educate future leaders, chose to prioritize transient discomfort felt by its most aggrieved students.

On Twitter, an indigent-defense lawyer, James Zeigler, discussed this apparent tradeoff with a law professor, Vida B. Johnson. Here’s the core of their exchange:

Zeigler: … I don’t think Harvard is necessarily wrong for pushing Sullivan out of this post.

Johnson: You are saying then that defense attorney professors can’t be deans (and should have fewer interactions with students) because of the clients they represent? I disagree. I have a hard time accepting that race didn’t play a role here on both the student and decision-makers’ side.

Zeigler: I’m saying that in this particular situation, where a dean volunteered to take a high profile case involving allegations that directly implicate the issues he might be called to confront as dean, and students actually feel uncomfortable with this, the two jobs may be in conflict. Race may have played a role, and reports of the student response to his decision to rep Weinstein may be skewed or exaggerated. I’m not saying he couldn’t do the job.

I’m saying that protecting norms around the right to counsel, esp where someone volunteered to rep a wealthy defendant, does not justify keeping someone in a position like this if students are uncomfortable, even if that discomfort is arguably unenlightened or misplaced.

But protecting the norms around the right to counsel is orders of magnitude more important than the “unenlightened or misplaced” discomfort of some Harvard undergraduates––discomfort rooted in difficulty tolerating moral difference, not in having to report sexual assault to Sullivan, as some have erroneously suggested. In fact, Sullivan long ago appointed Linda D. M. Chavers, a resident dean, to serve as his house’s “point person” for sexual-assault issues. (Moreover, Harvard employs dozens of people to whom any student in need could report sexual misconduct.)

People outside Harvard, including up-and-coming defense lawyers and those inclined to attack them, received this message: “Harvard professor out as dean amid backlash for representing Harvey Weinstein.” (That’s from a USA Today article, but other prominent news sources ran similar headlines.) As I previously warned, Harvard’s decision may deter ambitious young lawyers from undertaking the defense of any potentially controversial client, including indigent men who stand accused of rape or sexual assault. That raises the odds of wrongful convictions, especially among the poor. Harvard grads are relatively unlikely to be affected.

In a bitter twist, all that damage appears to have been done in service of a result that may have come about anyway: On Monday, Sullivan “resigned from the legal team defending Hollywood producer Harvey Weinstein against rape and sexual assault charges before Harvard announced Saturday he would not be reappointed as a faculty dean,” the Globe reported. According to Jeannie Suk Gersen, “Sullivan’s motion to withdraw as Weinstein’s counsel states it’s bc court moved trial date from this summer, to Sept, when Sullivan has teaching obligations at Harvard Law and he can’t be in two places at once. He didn’t leave team because of student/Harvard pressure.”

This article is part of “The Speech Wars,” a project supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press, and the Fetzer Institute.



One of the stranger aspects of the Donald Trump era is the open competition for the president’s affection. From Fox Business’s Lou Dobbs saying that Trump’s presidency is “the most accomplished … in modern history” to the president forcing his Cabinet secretaries to praise him on camera to his former fixer Michael Cohen once declaring that he would “take a bullet” for his former employer, it seems like each of the president’s myrmidons is daily attempting to outdo the others in employing Soviet-style hyperbole in praise of the president.

If there’s a comfort in this spectacle, it’s in the recognition that this is performance, that it’s a schtick, and that its ubiquity is a marker of the president’s deep insecurity. It is not a projection of strength, but one of weakness. The performativity of the spectacle suggests that at least some of these people recognize they are doing a bit. Others seem to have been corrupted by their proximity to Trump. Career civil servants such as Rod Rosenstein, who swore oaths to uphold the Constitution, have somehow been reduced to shuddering with fear at the thought of being fired in a tweet, begging the president for the opportunity to ensure that the law bends to his will.

It should be clear from Wednesday’s hearing before the Senate Judiciary Committee that William Barr, the attorney general of the United States, is something else entirely. Barr is no flunky. He is a hardened ideologue who believes that the president he serves is largely above the law. Barr seems genuinely committed to defending the imperial prerogatives of the office against shortsighted liberals who would weaken the presidency in a delusional quest to remove a Republican from office. As he put it in his 2017 memo attacking the special counsel’s investigation, “crediting” the belief that the president could have committed obstruction by his official acts “would have grave consequences far beyond the immediate confines of this case and would do lasting damage to the Presidency and to the administration of law within the Executive branch.”

Barr is not protecting Trump because he thinks Trump is the most accomplished president in modern history, because he fears Trump, because the real-estate mogul has some psychological hold on him, or because he has been corrupted. Barr is defending Trump because Barr is a zealot.

In March, Barr released a letter summarizing the long-awaited conclusions of Special Counsel Robert Mueller’s inquiry into Russian interference in the 2016 election. That letter mischaracterized Mueller’s conclusion that the Trump campaign took advantage of, and benefited from, Russian interference, only quoting the part of Mueller’s report that found that Trump-campaign officials’ conduct did not amount to a prosecutable crime.

Barr also misleadingly framed Mueller’s discussion of obstruction of justice in order to reach a conclusion that Trump did not obstruct—even though Mueller all but suggested that Trump would have been indicted if the Department of Justice did not have a policy against prosecuting a sitting president. Tuesday evening, the news broke that Mueller had written a letter expressing frustration with Barr’s effort to mislead the public about the conclusions of his investigation, after watching days of credulous press coverage suggesting that the president had been exonerated.

On Wednesday, before the Senate, Barr elaborated on his decision making. Barr not only defended his decision to clear the president of obstruction despite the fact that the public watched the president fire the FBI director over the Russia investigation, dangle pardons before suspects, and intimidate witnesses, but insisted that the president could not have obstructed justice simply by shutting down the investigation, because “the president does not have to sit there constitutionally and allow it to run its course. The president could terminate the proceeding and it would not be a corrupt intent because he was being falsely accused.”

The logic here is breathtaking: The president can end an investigation on the basis that he is “falsely accused.” The entire point of an investigation is to determine culpability; if the president can end an investigation into himself or any of his allies simply by asserting his own innocence, then he is effectively above the law. Under this standard, President Richard Nixon was perfectly within his rights when he attempted to end the investigation into the break-in of Democratic headquarters at the Watergate, which implicated several of his campaign operatives and ultimately led to his resignation.

Barr has previously suggested investigating the officials involved in the Trump inquiry for wrongdoing; on Wednesday, he was evasive when Senator Kamala Harris asked whether the White House had ever asked him to prosecute anyone. Should Trump demand that his attorney general prosecute the next Democratic nominee for president, there’s little evidence that Barr would be any kind of obstacle. The attorney general is sworn to uphold the Constitution, not to act like a mob enforcer against the president’s political enemies.

Nixon famously declared in 1977, in an interview with the reporter David Frost, that “when the president does it, that means that it is not illegal.” That was not mere sophistry, but ideology, and it is an ideological strain that has run through nearly every Republican administration since Nixon.

Barr’s involvement in the Iran-Contra scandal helps illuminate his conduct today. The administration of President Ronald Reagan defied federal law by selling arms to Iran in order to fund right-wing guerrillas in Central America, a scandal that led to the appointment of an independent counsel and the convictions of several high-ranking administration officials. When George H. W. Bush took office, he pardoned six officials implicated by the investigation at Barr’s urging.

The Iran-Contra scandal itself speaks to the conception of executive power to which Barr subscribes: that a president can do whatever he wants, even if Congress bars him from doing so, particularly if he is acting in what he believes to be the interests of the country—Trump is famously incapable of distinguishing between national interests and personal ones, between loyalty to him and loyalty to the nation. As Reagan’s former national security adviser Robert McFarlane put it, Reagan “just didn’t believe that it was a legitimate authority of the Congress to say that—that he, rather than the Congress, determined how he would conduct, in this case, the support of the freedom fighters.”

This has been particularly true of the expansive conservative conception of the president’s constitutional war-making powers. If Reagan openly defied Congress and the law, the first President Bush ratified his actions by pardoning those involved in the scheme. The next Republican president, George W. Bush, covertly defied the law by building a network of secret prisons across the globe, indefinitely imprisoning those suspected of terrorism, and sanctioning warrantless surveillance of American citizens, all based on dubious legal theories that amounted to little more than Nixon’s insistence that the president is above the law. Less articulate was the former George W. Bush Justice Department official John Yoo’s response to being asked whether the president could order a child’s testicles crushed: “I think it depends on why the president thinks he needs to do that.”

This theory of executive power does not apply to Democratic presidents, who become tyrannical figures the moment they take office. But that’s for the best—even if the skepticism is partisan in origin, preventing the powers of the president from growing too vast to meaningfully constrain is in the public interest. But what is at work with Barr is something more perilous than the sort of bizarre partisan overstatement that characterizes much of the Trump-era conservative discourse.

The thing about the Trump sycophants is that, at a certain point, the praise becomes so effusive that it feels, if not quite insincere, aware of its own absurdity. If someone as committed to the president as Cohen once was can flip and tell Republicans in Congress, “I’m responsible for your silliness because I did the same thing that you’re doing now for 10 years,” it suggests that when the time comes, the pageantry can be discarded, that the grift can be abandoned once it is no longer profitable.

Barr is not Cohen. He is not doing a bit. He is not grifting. He is not performing. He is not a suck-up, or an opportunist, or a lackey. He has not been compromised or corrupted. He is an ideologue who, like many of his Republican predecessors, believes that Republican presidents can do whatever they want, regardless of what Congress, the law, or the Constitution says. And that makes him far more dangerous.



If you’re looking for a date to chisel on the gravestone of the Republican resistance to President Donald Trump, June 1, 2019, will work nicely.

That’s the day that Maryland Governor Larry Hogan told The Washington Post, “I’m not going to be a candidate for president in 2020.” The day before, former Ohio Governor John Kasich also closed the door, which was only very slightly ajar, on his own 2020 run. “There is no path right now for me. I don’t see a way to get there,” Kasich said on CNN. “Maybe somebody wants to run and make a statement, and that’s fine, but I’ve never gotten involved in a political race where I didn’t think I could win.”

Yes, former Massachusetts Governor William Weld remains in the GOP race, but no one is under any illusion that his challenge to Trump exceeds the moral and symbolic realm. (Some never-Trump dead-enders had hoped that someone like Kasich, a 2016 candidate, or even more so Hogan, a successful, popular Republican governor in a liberal state, might provide a more viable—though still doomed—challenger.) But across the landscape, a variety of signs show that Hogan’s and Kasich’s decisions are more symptoms than causes of the sputtering anti-Trump bloc within the Republican Party and conservatism.

Consider National Review, the grand old organ of the conservative movement. In 2016, in the most ambitious crossover event in right-wing-media history, the magazine published a collection of conservative writers of all stripes writing in opposition to Trump’s candidacy. The gesture was dramatic, though a little too late. Around the same time, one of National Review’s writers, David French, considered a quixotic challenge to Trump in the name of a principled conservatism. Trump’s triumph was a bitter revelation for these writers—that the GOP was not the principled, orderly Burkean party they had imagined, but rather an unruly populist groundswell.

And today? The pundits have largely accommodated themselves to the GOP as it is, rather than as they imagined it was. The National Review editor Rich Lowry, who oversaw that issue, routinely writes sympathetically or in defense of Trump. Jonah Goldberg, one of the magazine’s most stalwart anti-Trumpers, departed on Friday for a new conservative-media venture. French has become, probably unfairly, the target in an otherwise largely inscrutable internecine battle among conservative pundits about approach. Erick Erickson, who is not part of the NR crew but contributed to the never-Trump issue, earlier this year endorsed Trump for reelection and has become a vocal defender of the president.

If Trump loses his bid for reelection (and perhaps even if he wins), the 2020 Republican primary—or rather, the lack thereof—will be a mystery for future political scientists to puzzle over. How could a president who is historically unpopular, careens from crisis to crisis, and faces a serious threat of impeachment cruise to renomination without a serious challenge?

In explaining his decision not to run, Hogan cited his obligations to the voters who elected him: “I have a commitment to the 6 million people of Maryland and a lot of work to do, things we haven’t completed.” Yet he, like Kasich, also acknowledged the political reality of the situation. With the president’s approval rating among Republicans at an astronomical 90 percent (about double the general population’s approval), what’s the point in throwing yourself in front of the Trump train?

There is a moral case for doing so, which is basically Weld’s: Trump has no business being president, and so challenging him is the right thing to do, even if it’s doomed. “We need to have a bigger tent and find a way to get things done,” Hogan told the Post. “We need some civility and bipartisanship. Our politics are broken. Washington is broken. But we have a story to tell.” Yet Hogan is eschewing the simplest way to tell that story.

Yet one could also make a case for running based on, believe it or not, polling of Republican voters. Despite Trump’s strong support inside the party, 43 percent of GOP voters say they want to see a primary challenge to the president, even as 56 percent do not, according to Pew. That’s a slight increase from last fall. Pat Buchanan’s 1992 primary challenge to President George H. W. Bush shows the impact a long-shot challenge can have. (Then again, Bush entered the campaign popular overall but weakened within the GOP—a mirror image of Trump, who is more popular within his party than among the general public.)

Conservative leaders in both politics and media, having underestimated the support for a Trump-style candidate before 2016, appear to have overcorrected, thus abandoning the strong minority of Republican voters who still want an alternative and leaving this bloc without a viable candidate.

The GOP opposition to Trump has effectively vanished, at least at elite levels, yet plenty of rank-and-file Republicans and Republican-leaning independents remain who are wary of the president. That shifts the locus for any challenge outside the GOP. It could come in the person of Representative Justin Amash, the Republican from Michigan who has been courted as a Libertarian candidate in 2020, and who has recently made a splash for calling for Trump’s impeachment, or perhaps another challenger is waiting in the wings.

In the meantime, the Republican resistance is dead. In lieu of flowers, send symbolic write-ins or third-party votes to the candidate of your choice.



Pete Buttigieg’s announcement of a Supreme Court–packing plan is surprising in ways both small and large.

The surprise comes less from the specifics of the proposal than from its circumstances. Buttigieg has been conspicuously cautious about policy initiatives, so his decision to center a sweeping revamp of the high court represents an unusually bold maneuver for the South Bend, Indiana, mayor’s presidential campaign. Moreover, the rollout exemplifies how the Supreme Court, once a somewhat tangential concern for many Democrats, has moved to the center of the agenda in the Trump era.

The details of Buttigieg’s plan are interesting in an academic sense, though unlikely to really set the parameters for any rearrangement of the Court. Based on a forthcoming paper by two law professors, his plan would expand the Court from nine justices to 15, five of them Democrats, five Republicans, and five unaffiliated. NBC’s Josh Lederman explains that those last five would be chosen from federal courts by the 10 partisan justices:

They’d have to settle on the nonpolitical justices unanimously—or at least with a “strong supermajority.” The final five would serve one-year, nonrenewable terms. They’d be chosen two years in advance, to prevent nominations based on anticipated court cases, and if the 10 partisan justices couldn’t agree on the final five, the Supreme Court would be deemed to lack a quorum and couldn’t hear cases that term.

The plan seems to contain a key contradiction. It eschews the treasured pretense that the Court is above, or at least outside, politics—a pretense that, as I wrote when Justice Brett Kavanaugh was confirmed in 2018, the public seems to buy into less and less. The Buttigieg plan reifies this shift, yet it also assumes that nonpartisan, mutually agreeable judges exist.

It’s an aggressively technocratic proposal for an ideological problem, in keeping with Buttigieg’s sales pitch as a reasonable man and his past work at McKinsey. Maybe it’s no surprise that former Representative Beto O’Rourke, another handsome young man running a moderate campaign, has also expressed interest in the same general Court-packing plan.

Court packing is not quite so unprecedented as its opponents would have the public believe. (In 1866, the Senate reduced the Court from 10 justices to seven as a swipe at President Andrew Johnson, then boosted it back to nine when Ulysses Grant replaced Johnson— a maneuver that might make even current Senate Majority Leader Mitch McConnell blush.) It is, however, a curious cause for the Democratic Party to take up at the same time that it is railing against Donald Trump for his destruction of long-standing political norms.

Nonetheless, and despite the technocratic bent of the 15-justice plan, the fact that Buttigieg and O’Rourke, two cautious candidates with vague policy platforms, have aligned themselves with it shows how central the Court has become to Democratic voters. For both men, it’s a means of offering an apparently bold policy proposal that will be relatively uncontroversial among primary voters.

As recently as the 2016 election, the existing Supreme Court was not at the center of Democratic Party politics, to say nothing of Court-packing schemes. According to Pew, 62 percent of Democrats called the Court “very important” to their voting in the election—which sounds impressive, but it placed behind gun policy, Social Security, and the treatment of racial and ethnic minorities, to name a few other issues.

This was true even though the election was held as McConnell was blocking a confirmation process for Merrick Garland, President Barack Obama’s nominee to a seat on the Court. In large part, Democrats assumed that Hillary Clinton would win, and then either Garland or a new appointee of Clinton’s would join the Court. Clinton spoke about the importance of some Supreme Court decisions—calling, for example, for the reversal of the campaign-finance case Citizens United—but it wasn’t at the heart of her campaign, or of Bernie Sanders’s.

It was a different story on the Republican side of things. Donald Trump promised to nominate conservative judges to the bench, even releasing a short list of possible nominees. Speaking to conservatives who remained uncomfortable with him, Trump repeatedly reminded them of the importance of the Court, an assurance that began to seem like a taunt by the end of the campaign. But Trump was right. The Court was of such importance to these voters that they held their nose and voted for him. It has paid off for both sides: Trump has indeed named judges that conservatives love, and they have rewarded him with strong support, including from some erstwhile never Trumpers.

Democrats have taken notice. The appointment of two young, very conservative justices (Kavanaugh and Neil Gorsuch) in Trump’s first two years, and especially the messy fight over Kavanaugh’s confirmation, energized progressives. By September 2018, 81 percent of Democrats named the Court as a very important voting issue, an amazing 19 percent rise from two years earlier.

Events since then have helped cement the Court’s place in Democratic fears. A series of states have instituted strict abortion limitations that seem designed to test whether the newly conservative Court is ready to overturn Roe v. Wade, leading Democratic candidates to leap to defend abortion rights in any way possible.

Beyond that, many of the major items on Democratic wishlists are likely to be dead on arrival in the Roberts Court as currently constituted. From voting rights to campaign-finance reform and health-care overhauls to the Green New Deal, a new Democratic president faces the real prospect of a Court blowing big holes in any policy proposal even if Congress is Democratically controlled. (Just ask Obama about the Affordable Care Act.) Changes to the Court are a possible prerequisite to any other major legislation, so it stands to reason that Democratic presidential hopefuls would pursue them, and it makes sense that Democratic voters would take new interest in the Court.

Back on the right side of the aisle, some conservatives worry that by cementing a conservative majority for the foreseeable future, Republicans may risk complacency among voters. It’s unclear what would happen if the Court did overturn or substantially undermine Roe before the next election: Would the victory energize conservatives? Or would they be even more complacent, while liberals were fired up? Either way, a genuine, widespread movement among Democrats to pack the Court and eliminate that generational conservative majority could become a major motivator for the party—but it might re-enliven Republican voters’ focus on the Court, too.



When news organizations think about competition from tech companies, it’s usually in terms of the audience’s attention and advertisers’ dollars. But if Amazon has its way, a new sort of competition may be coming from a mixture of surveillance, fear, and doorbells.

Amazon is currently looking to hire someone with the title “Managing Editor, News.” But it’s not for the entire Amazon empire—it’s for the small slice of it that makes security-focused doorbells, Ring. (Amazon bought Ring last year for more than $1 billion.)

Here’s the job description:

The Managing Editor, News will work on an exciting new opportunity within Ring to manage a team of news editors who deliver breaking crime news alerts to our neighbors. This position is best suited for a candidate with experience and passion for journalism, crime reporting, and people management. Having a knack for engaging storytelling that packs a punch and a strong nose for useful content are core skills that are essential to the success of this role. The candidate should be eager to join a dynamic, new media news team that is rapidly evolving and growing week by week.

The job requires at least five years’ experience “in breaking news, crime reporting, and/or editorial operations” and three years in management. Preferred traits include “deep and nuanced knowledge of American crime trends,” “strong news judgment that allows for quick decisions in a breaking news environment,” and experience using “social media channels to gather breaking news.”

That’s right: A doorbell company wants to report crime news. It already is, actually. Several people on LinkedIn describe their jobs as “news editors” at Ring.

I hope a really thoughtful person gets that job, but I’m going to go out on a limb and say that this is a really bad idea.

Crime has declined enormously over the past 25 years, but people’s perception of how much crime there is has not. A majority of Americans have said that crime is increasing in each of the past 16 years—despite crime in each major category being significantly lower today than it used to be.

A 2016 Pew survey found that only 15 percent of Americans believed (correctly) that crime was lower in 2016 than it had been in 2008—versus 57 percent who thought it had gotten worse. (Those inaccurate beliefs are not evenly distributed politically, with conservatives, Republicans, and Trump supporters each more likely to see dangers the statistics don’t support. A couple of hours spent watching Fox News makes the approach pretty clear.)

Gallup data show that a majority of Americans have only said that crime was getting better in their community once in the past 47 years—October 2001, when presumably they had other concerns to focus on.

These mistaken beliefs are driven largely by the editorial decisions of local media—especially local TV newscasts, which are just as bloody today as they were when murder rates were twice as high. There’s a term for it: “mean world syndrome,” the phenomenon where media consumption makes people see the world as more violent and dangerous than it really is. And TV has historically been the worst offender; a body of past research has shown that people who rely on local TV most for their local news are more fearful of crime; that local TV’s crime news disproportionately shows black criminals and increases racial fears; and that the more local TV news you watch, the more fearful you get.

Those fears and mistaken beliefs are important: Consuming more local TV crime news is associated with supporting more punitive anti-crime measures, and reducing exposure to crime news can even increase presidential approval ratings.

A report from Pew last month asked people about various topics in local news and asked both whether they thought they were important or interesting and, if so, why. Did they consume news about a topic because it was important to their daily lives; because it was important, but not to their daily lives; or just because they found it interesting?

Those surveyed overwhelmingly said crime news was important. But more striking is that so many of them said it was important to their daily lives. To put that in context, the top three “important to their daily lives” topics were weather, crime, and traffic. Weather and traffic really are important to your daily life! Figuring out what to wear or which route to take to work are very useful services that local news can provide. But local TV news has convinced Americans that stories of violence are news-you-can-use at the same sort of level. (Only 9 percent said they followed local crime news because it was “interesting.”)

In recent years, a number of newspapers have decreased the emphasis they put on crime stories in their coverage. There are a number of reasons for this shift. TV is always going to have an advantage when covering day-to-day crime. There are fewer reporters to go around than there used to be. And as newspapers have retooled for digital subscriptions over page views, crime news is less important to what they’re offering readers.

(When I worked at The Dallas Morning News in the 2000s, a consultant once came through telling editors that crime news was what the audience really wanted on the web, and the paper changed its presentation accordingly to chase page views. For a while, the homepage of DallasNews.com was almost as bloody as the 10 o’clock news. But looking at the homepage as I write this—with the paper having pivoted to seeking digital subscriptions—only three of the top 17 stories are about violent crime.)

In an American Press Institute study asking new newspaper subscribers what topics they were most interested in, “crime and public safety” ranked only seventh out of 19; only 18 percent of respondents included crime news in the three topics they followed most. Meanwhile, local TV news stations, fighting for ratings in an environment of declining attention, have mostly stuck to their guns, so to speak, keeping crime news prominent.

In other words, news organizations—for better and for worse—respond to audience incentives. If they think their audiences want more crime news, they’ll probably produce more of it—and vice versa.

But news organizations have multiple and sometimes conflicting incentives that might affect how they present the local police blotter. A company that sells security-optimized doorbells has only one incentive: emphasizing that the world is a scary place, and you need to buy our products to protect you.

Ring already has an app called Neighbors that, judging by its marketing, encourages people living in bucolic suburbs with wrought iron gates to feel as if they’re in the last un-zombified neighborhood in The Walking Dead (I assume this app is where this new managing editor’s work product will be found):

The Neighbors App is the new neighborhood watch that brings your community together to help create safer neighborhoods. With real-time crime and safety alerts from your neighbors, law enforcement and the Ring team, the Neighbors App proactively keeps you in the know. Criminals target neighborhoods, not individual homes. But with real-time crime and safety alerts from your neighbors, you’ll stay one step ahead of crime.

Basically, it’s an app that makes you want to see your neighborhood the same way that this screenshot does: Suspicious Stranger Crime Crime Stranger Crime Suspicious Suspicious Crime Crime Crime Crime Suspicious Stranger Crime.

So think about this managing-editor job. Ring wants to be “covering local crime” everywhere, down to the house and neighborhood level. So one managing editor, plus however many other people are on this team, is supposed to be creating a thoughtful, nonexploitative editorial product that is sending journalistically sound “breaking news crime alerts,” in real time, all across the country. Are they really delivering news or just regular pulses of fear in push-notification form? If that’s the job, it is literally impossible to do responsibly.

I downloaded Neighbors—you can do so without owning a Ring doorbell—and plugged in my address in boring Arlington, Massachusetts, a city of 45,000 that recorded zero murders and only seven robberies last year. It decided I needed to know that someone in the uniform of a local lawn-care service had recently knocked on someone’s door instead of using the doorbell and, when no one answered, left. Also, there was a building fire two towns away, a couple of days ago.

Also, two young people, one male, one female, wearing identical T-shirts and lanyards with name badges, carrying clipboards—likely trying to get signatures for some cause or another—rang a doorbell and then walked away when no one answered. “Anyone know who they are?” the post from a Neighbors user asked, perhaps concerned about Islamic State infiltration of the Boston suburbs. “Call the police,” one helpful commenter replied. (It doesn’t take a critical race theorist to suspect that that suggestion might turn into action for people of color who dare to approach a front door.)

Now, plenty of other apps aim to turn the magical stew of unverified reports, stand-your-ground ideology, and paranoia into dollars. Citizen—an app that used to have the more-straightforward name, Vigilante—is perhaps the most well known.

But what bugs me about Ring’s approach is that it wants to bring in the credibility of journalism as a layer on top of the state of constant fear it promotes. A company that relies on people feeling unsafe to sell its products will now be able to take whatever trust professional journalism has left and put it to work toward that end. It’s like relying on the people who make antivirus software to tell you about the latest cybersecurity issues: Even when the reporting is sound, it’s still prone to exaggerating the scale of the threat and still aimed at making you so afraid that you give them money.

(A cynic—okay, me—might note that this  managing-editor job is listed under “Marketing & PR,” not editorial.)

Is it possible that real journalists can make the product better and less paranoid? Sure, it’s possible. But the reality is that “breaking crime news alerts” are not something the majority of people needs—especially if “two Greenpeace volunteers stood on my porch for 30 seconds” is the bar we’re talking about. It’s not actionable intelligence—it’s puffing a little more air into an atmosphere of fear.

News organizations’ coverage of crime is flawed in a million different ways. But at least they’re operating in a context where crime is one story out of dozens and where not all incentives point in the same direction. Even once you get past the absurdity of it all—a doorbell company writing crime news—it’s a bad direction to be going in. It says it’s selling safety, but it’s really selling fear. And it’s also a reminder that, if local news organizations go away, you might not like what fills the gaps they leave behind.

This post appears courtesy of Nieman Lab.



One of the open secrets of Donald Trump’s success in the 2016 presidential campaign was his ability to grab attention—and, accordingly, deflect it from his adversaries—by making outrageous comments. Sure, there would sometimes be backlash to things he said, but he could always deflect that with another comment. Whether this reflected a planned strategy or an intuitive feel for controlling the media remains debated, but his success was inarguable.

This pattern continued into the early days of Trump’s presidency. He would say something outrageous or surprising, markets would react with sudden swings, and the press would scramble to explain and contextualize the latest violation of longstanding norms. In February 2018, when Trump suggested that House Democrats had committed “treason” by failing to cheer during his State of the Union address, there was a frantic reaction, as observers pointed out—accurately—that this was the sort of thing that authoritarian rulers did.

By mid-May, however, when Trump tweeted his latest, similarly bogus accusation of treason, it barely registered in the news cycle:

My Campaign for President was conclusively spied on. Nothing like this has ever happened in American Politics. A really bad situation. TREASON means long jail sentences, and this was TREASON!

During his current trip to the United Kingdom, Trump already has had two similar incidents. First, he has rekindled his feud with London Mayor Sadiq Khan. In summer 2017, this was shocking; these days, it’s about as interesting as his feud with Rosie O’Donnell.

Second, promptly upon landing, he began complaining about CNN, and encouraged a boycott of its owner, AT&T. (Trump previously called for the government to block AT&T’s acquisition of the network’s parent company, but a federal judge allowed it to go forward.) The president tweeted:

I believe that if people stoped using or subscribing to @ATT, they would be forced to make big changes at @CNN, which is dying in the ratings anyway. It is so unfair with such bad, Fake News! Why wouldn’t they act. When the World watches @CNN, it gets a false picture of USA. Sad!

Before 2017, the president of the United States calling for a retaliatory boycott of an American company because of unfavorable coverage would have been unthinkable. In 2017 and 2018, it would have been a huge story. This time around, AT&T didn’t even bother to comment to CNN’s own reporter, and the company’s stock ticked up.

One reason for the collective shrug is that more than two years into Trump’s term, there’s much more substance to focus on, making his rhetorical outbursts less comparatively interesting. But Trump has also worn away the novelty of such pronouncements. The first time you wildly, baselessly accuse a political opponent of treason, it’s a horrifying break with normalcy. The umpteenth time you do it, it’s, well, the umpteenth time you’ve done it.

Trump has become the president who cried wolf. As former Special Counsel Robert Mueller’s report showed, many of Trump’s own aides have learned to disregard what he says, for better or worse. (Often better in the short term, but with bad implications in the long run.) At other times, Trump’s pronouncements have proved to be less than meets the eye, because his own aides are unprepared to implement them. Just last week, his decision to institute tariffs on Mexico to force immigration changes took many aides by surprise, according to Axios.

The public is slowly learning the same lesson, too. In addition to the anecdotal evidence that Trump’s statements carry less weight, his tweets are eliciting less engagement, fewer people are searching for him on Google, and he’s on TV less. The president has responded by tweeting more frequently, but that seems to further dilute the effect.

In some ways, this is a clearly positive development. As they say on Twitter, don’t feed the trolls. When, in July 2017, Trump tweeted a silly video of himself body-slamming a man with the CNN logo superimposed on his face, it elicited a frothy overreaction. This didn’t make CNN look good, and the fury only encouraged Trump. Many of his comments reflect the president just shooting from the hip, and if left alone they will quietly dissolve into the ether.

But it also seems possible that we’ve overcorrected. While Trump’s comments drew more pearl-clutching than was justified before, it’s at least as unwise to completely ignore them. The man is, after all, the president of the United States, and some recent examples show the power of his rhetoric.

For years has Trump asserted—while providing no evidence—wrongdoing by federal officials in the investigation into Russian interference in the 2016 campaign. While those calls were long ignored as simple tantrums, Attorney General Bill Barr earlier in May directed a U.S. attorney to investigate the probe’s origins.

That’s a direct effect: Trump asked, and Barr (eventually) answered. But less direct Trump remarks can be influential, too. When Trump made Memorial Day remarks to sailors in Japan in May, White House officials asked the Navy to keep the USS John S. McCain out of view. The destroyer is named for the late Arizona senator, who was a Navy captain, and for his father and grandfather, both of whom were admirals. The president insists he did not make the request and knew nothing of it, and that may be true. If so, however, it shows how Trump’s comments resonate. Knowing that any mention of McCain, a long-running political irritant, tends to set the president off, staffers seem to have taken a drastic measure even without Trump’s requesting it.

Other ripple effects of the president’s remarks will not be so immediately obvious. No president can oversee all aspects of the executive branch (though some have tried). Instead, he sets tone and priorities, and bureaucrats act on that guidance. A stray Trump comment about any given company may not directly launch a regulatory intervention, but federal officials will notice the president’s interest, and it will affect them, consciously or not, as they do their jobs. The Justice Department is reportedly preparing an antitrust probe into Google, as it strikes agreements with the Federal Trade Commission about scrutinizing a variety of tech giants. That’s not an obviously partisan maneuver—Senator Elizabeth Warren, a 2020 Democratic presidential candidate, praised the idea—but it’s hard to ignore that Trump has lambasted Google for supposedly suppressing conservatives, and that he has threatened the company, tweeting, “This is a very serious situation-will be addressed!”

Many of the effects of Trump’s loose talk will be even less clear and may not be felt for some time. What happens in the long term when the president accuses a lot of people of treason? We don’t know.

This unpredictability makes it difficult to calibrate the right response to Trump’s provocations. Too much, and it encourages bad behavior from the president. But if the public and the press grow inured to them, and do too little in response, they may end up dealing with the consequences for years to come.



The 2020 presidential candidates will argue strenuously about important economic questions relevant to all Americans. These include wealth and income inequality, the design of health-care insurance, systems for financing higher education, and the relative tax burdens imposed on capital and labor. Even the Green New Deal is at bottom a proposed solution to an economic problem—that of “externalities,” where market prices do not reflect the full cost of human actions, in this case the costs of burning fossil fuels on the environment and society.

Many journalists, campaign operatives, and activists lately have framed debates around these issues as a struggle between “capitalism” and “socialism.” But these words have no meaning for most voters. We are not a nation of political theorists or economists; we are ahistorical and poorly read. We can no more discuss the views of Karl Marx and their continued relevance today than we can chat about quantum mechanics with a kangaroo.

Voters need a simple organizing principle for evaluating all the economic policy proposals, arguments, and counterarguments that blossom at campaign time. In this way, they might see past some of the rhetorical tricks and misleading phrases to understand better what they really want from the political process.

I propose that voters should ask themselves a simple question: Are markets friendly? Do they exist today to serve society’s best interests, or are they currently a hostile force? If voters believe the latter—as, I’ll explain, I think they should—they ought to support candidates who back more government intervention, and vice versa.

Are markets friendly? riffs on Albert Einstein’s famous (but apparently apocryphal) observation that to him the only important question was Is the universe friendly? His question addressed our relationship to cosmic forces beyond our control; mine addresses our relationship to economic forces that seem beyond our control but that, in fact, are within our powers to alter.

My question will cause economists to choke on their cereal, because a “friendly” market is not an economic term. But it does work, I think, as a device to help organize voters’ thoughts along margins that otherwise are too abstract and too overwhelming to comprehend.

My question focuses on “markets,” not “companies” or “businesses,” because markets are where investment and production are allocated through the mechanism of prices. Companies act in markets, but they are not themselves the market. The question also ignores the useless term the economy. Most individuals care about jobs; some lucky ones care about their savings; entrepreneurs care about opportunities; and companies care about profits. “The economy,” by which pundits usually mean the gross domestic product, is just the sum of all these inputs. Policies act on these inputs, not on “the economy” as such.

A “friendly” market does not necessarily mean a kind one, but it does mean a market that is fair, open to all, efficient in allocating investment and production through the signaling mechanism of prices, and bound by rules that reflect Americans’ values. The economist’s shorthand for these requirements is that markets must be competitive and complete.

In competitive markets, no business can dictate prices to customers; all fight for survival in environments where profit margins are slim. A friendly market is not a synonym for a “business friendly” environment, where firms make fat and easy profits, but rather signifies a marketplace where businesses scrap for every little advantage.

As Adam Smith observed, businesses often are the enemies of genuinely competitive markets. A business cannot help but want to make things easy for itself, for example, by co-opting government to protect itself from market competition. Contemporary politicians eager to protect or subsidize some company or industry—for example, through tariffs—in fact have been co-opted in the same way that Smith warned about almost 250 years ago.

Abundant evidence today indicates that American markets are not as competitive as they could be. An excessively narrow interpretation of antitrust policy, for example, has led to greater concentration of market power than ever before, with the result that the remaining giants earn enormous profits beyond that which is necessary to fuel their growth.

Individual markets may be competitive, but are American markets taken as a whole complete? That is to say, can reasonable economic desires find outlet in markets open to all under fair terms of participation? If the focus is on mobile phones or table lamps, the answer obviously is yes. But what about the local labor market, or private markets for health insurance or a college education?

Health care is a good example of a market that is necessarily incomplete in the absence of government intervention. Truly private health-care markets that do not discriminate against preexisting conditions will always fail, as people delay buying insurance until they absolutely need it, and private markets that do discriminate leave millions without any insurance at all. For these reasons, every other developed country has adopted some form of government-sponsored health care to advance the welfare of its citizens. Only government can bring into the insurance pool the young and healthy as well as the old and sick. This intervention can take many different forms, but the point is that free enterprise alone cannot make this crucial service a complete market.

As another example, college education would be even more unaffordable without any public (government) institutions and financing arrangements. The underlying problem is that students can’t literally mortgage their future today to some private lender at reasonable interest rates to buy the higher education they need; government support is necessary to bridge the gap between the requirements of private lenders and students’ legally unenforceable plans for their careers.

Labor markets also are incomplete and uncompetitive, in that the negotiating power of employers is wholly disproportionate to that of employees. The result is full employment but an absence of jobs with dignity; instead, millions of Americans perform work that is just not cost-advantageous for robots to do—yet. And private markets famously fail in the absence of government intervention to reflect in prices the costs of pollution and similar externalities, as demonstrated by the accelerating pace of climate change.

If voters set aside charged and unfocused terms such as capitalism and socialism, and simply recognize that private markets are necessarily incomplete in areas that directly touch their welfare, they may then appreciate the need for greater involvement by the state in the form of public investment or insurance. Recognizing the importance of addressing otherwise incomplete markets also puts tax policy in the right context. The United States needs higher and more progressive taxes not simply to cut the rich down to size, but to fund public programs to round out markets that otherwise would be incomplete.

Too much energy is wasted on both the left and the right obsessing over tax policy in the abstract, as if the business of government were just to collect taxes and then set all those dollars on fire. It’s what government does with the money that’s important. By examining the conditions required to establish markets that are friendly to all Americans, the focus shifts to the positive side of things—those policies that would enable citizens to obtain affordable child care, health insurance, and higher education, by way of example. Genuine equality of opportunity requires these sorts of public investments. (In turn, these investments must be funded through higher taxes. The surprising result is both faster growth and more equal sharing of that growth.)

Competitive and complete markets can exist only in cooperation with government. Markets are creatures of the state, not laws of nature. Policy makers design rules that govern markets to make them work better for citizens, and thereby to offer citizens the opportunity to lead meaningful and productive lives. Pounding the table to eliminate “job-killing red tape” or claiming that everything would be great if only government got out of the way is like arguing that baseball would be better without the infield-fly rule. That rule was created to make the game work better, and the same is true of many of the rules that drive markets.

Friendly markets—markets bounded by rules and complemented by government where private markets are incomplete—advance the welfare of citizens, but will be unkind to businesses that cannot keep up in a world of fierce competition. That is unavoidable, given that in the American system there is no central command to allocate investment and production.

There’s a pervasive and pernicious myth that private markets, if left to their own devices, solve all problems. Adherents appeal to fuzzy memes such as “free enterprise” and “capitalism” to urge voters to drive government entirely out of markets. They still maintain that what’s good for General Motors (or to update, Apple) is good for America. And they see markets as largely complete and gaps as inconsequential. (After all, one can always find an example of the kid from a hardscrabble background who has graduated from Harvard, so that must prove that the market for a Harvard education is open to all.) Inequality becomes a feature, not a bug—or at worst, a necessary side effect.

America has come as close as a developed country can to instantiating that myth, and the results are obvious: a dysfunctional health-care system that costs 50 percent more as a percentage of GDP than the next most profligate country; rising market concentration and corporate profits; runaway growth in top-end inequality; job insecurity and poor job quality; and many other ills. Voters can make better political decisions, and encourage a better direction for the country, by asking whether proposed policies will lead to business-friendly markets, or instead to markets that are authentically friendly to their own values and aspirations.



I’ve been a sports fan my entire life, and for most of it, my loyalties have not been geographic. What attracts me to athletes isn’t so much the team they play for, but rather the qualities they embody: poise, discipline, courage, competitiveness; elegance, creativity, artistry. Sports at its best is a showcase for human excellence, an arena for human drama. When you witness certain athletes perform well—sometimes magically—particularly under intense pressure, you know you’re witnessing something special, and fleeting, and worth savoring. Which brings me to last Friday night, when I watched one of the most unforgettable single-game performances in NBA playoff history.

The Golden State Warriors, two-time defending champions, were leading the Houston Rockets in the best-of-seven series, three games to two. But in the second half of Game 5, Kevin Durant—the best player in the playoffs this year and one of the best scorers in NBA history—went down with a series-ending calf injury. The Warriors squeaked out a victory in Game 5, 104–99, thanks to some late-game heroics by Curry. But Game 6 was played in Houston, where the Rockets had won a dozen home games in a row—and because of the injury to Durant, the Rockets, who pushed the Warriors to a seventh game in their series last year, were heavily favored to win.

It wasn’t just Durant’s injury that made the Rockets such favorites, but also the fact that the Warriors point guard Steph Curry, a two-time Most Valuable Player award winner, was having a terrible series. His shooting percentage was dismal. He missed layups and uncontested dunks, committed sloppy turnovers, found himself in constant foul trouble, and, on top of everything else, dislocated a finger on his left (non-shooting) hand. During the first half of Friday night’s game, Curry was nearly catatonic: zero points, three fouls, and only 12 minutes of playing time. Yet the Warriors, thanks to some outstanding contributions from the bench, entered the second half tied for the lead.

Then Wardell Stephen Curry II took over.

In a performance for the ages, Curry scored 33 points in the second half, including 23 points in the fourth quarter, a tally exceeded only by Allen Iverson in the past 20 postseasons. Even more impressive is that Curry scored 16 points during the last five minutes of the game—a total it took the entire Rockets team to equal. There’s no other NBA playoff game in which a player has gone from being so awful to being so unstoppable. Curry was “a complete nonfactor in the game,” his coach, Steve Kerr, said. “And then [he] just completely took over the game on a night when everything was going wrong.” Kerr added, “If that game didn’t personify Steph Curry, I don’t know what did.”

The Warriors won, 118–113, to advance to the Western Conference finals against Portland. The Dubs’ quest for a three-peat—winning three consecutive championships in a row, and their fourth championship in five seasons—goes on.

Steph Curry is the greatest long-range shooter in NBA history. He’s also the best free-throw shooter. But he isn’t the best player in history, and he may not even be the best point guard. Yet what sets Curry apart from almost every other player, past or present—including Michael Jordan and LeBron James—is how he has revolutionized the game.

“Curry is to hoops as armed drones are to war,” Henry Abbott of ESPN The Magazine wrote in 2016. “The range. The unpredictability. The inescapability. He’s destroying defenses that don’t even know it is time to play defense. And now that we know this exists, it’s difficult to imagine the future could possibly look anything like the past.”

To understand Curry’s effect on the game, it’s helpful to know a little bit about the history of the three-point shot in professional basketball. When the three-point shot debuted in the NBA during the 1979–80 season, it was dismissed as a “gimmick.” John MacLeod, a respected coach for the Phoenix Suns, said at the time, “It may change our game at the end of the quarters, but I’m not going to set up plays for guys to bomb from 23 feet. I think that’s very boring basketball.” The Boston Celtics’ legendary coach Red Auerbach put it more bluntly: “We don’t need it. I say leave our game alone.”

At the end of that first season, teams averaged fewer than three three-point attempts a game. It wasn’t until the 1987–88 season that Danny Ainge of the Celtics became the first player to make more than 100 three-point attempts.

Then the Curry era began.

In the 2012–13 season—his third in the league—he set a record by making 272 three-point shots. In the 2015–16 season, Curry made 402—still a record. (The New York Times said at the time that the record was such an outlier, it was “the equivalent of hitting 103 home runs in a Major League Baseball season.”) He led the league in three-point shots for five consecutive seasons. Kids began to imitate Curry like kids a generation before wanted to be like Mike.

The New York Times’ Victor Mather points out, “Even in a world without Curry, the 3-point record would be tumbling.” But Curry changed things in a way no one else had. He would pull up and calmly nail game-winning shots from 37 feet, more than a dozen feet beyond the three-point arc, which once upon a time was considered a challenging shot. (You can get a sense of Curry’s preternatural shooting skills by watching one of the highlight reels that have proliferated online.) He spread the defense in ways few other players ever have, forcing other teams to change their lineup in order to guard him.

But guarding him was hardly a guarantee of stopping him. Curry is able to make shots when defenders are draped all over him, barely allowing him room to get his quick-release shot off. That was the case in the last minute-and-a-half in Game 6 against the Rockets, when Curry was guarded by P. J. Tucker, an excellent defender. But Curry dribbled behind his back (twice), crossed over several times, went to his right, and fired a three-pointer that didn’t even touch iron. It was the kill shot.

“His spurtability, his ability to get points in bunches, is the best in the world, in the history of the game,” Curry’s backcourt mate Klay Thompson said. “I knew he was going to get going. There’s nobody better to have the ball in his hands at the end of the game. [His second half] didn’t surprise me one bit. He’s our leader. He plays with great composure.” And fearlessness, in the words of Steve Kerr. “That’s what makes him who he is.”

Curry can create shots off his own dribble, but what he does better than anyone else ever has is move without the ball, using screens to get open and “creating a vacuum of defensive attention wherever he is not,” as Chris Ballard put it in Sports Illustrated. He’s perpetual motion. That is one thing that distinguishes Curry from James Harden of the Rockets, a great scorer but one who plays best in isolation, going one-on-one, which causes the rest of the team to stagnate. What makes the Warriors different from any other team is their ball movement, the extra pass, the assists. When they are hitting on all cylinders, it’s a thing of beauty. The Warriors play the game in a way purists can love.

When Sports Illustrated honored the Warriors with its 2018 Sportsperson of the Year award, the magazine said it was for myriad reasons, including “injecting joy into the game and setting fire to conventional wisdom.” And the personification of that joy is Steph Curry.

“Our universe revolves around him,” the Warriors’ general manager, Bob Myers, told Sports Illustrated. He’s “the reason for all this,” Curry’s teammate Andre Iguodala said. Another teammate, Shaun Livingston, called Curry “the soul of the team.” And Kerr put it this way: “The whole culture revolves not only [around] his talent, his unselfishness, but his joy.”

That is perhaps the most striking thing about Steph Curry—the joie de vivre he brings to the game. It’s unmatched by any professional athlete today, and equaled by only a few in history. Magic Johnson is one; Muhammad Ali was another. (Curry doesn’t possess Ali’s cruel streak, which the boxer showed toward Joe Frazier.)

You see the ebullience before tip-off, when Curry amuses himself (and delights fans) with a two-handed, 40-foot pregame tunnel heave, which he performs with the help of a 65-year-old security official. He’s known to recruit teammates to use basketballs to play volleyball, bowl, and run football plays as part of their pregame warm-up. He keeps things loose, and he keeps things fun.

On the court, Curry is demonstrative and intense, entertaining, and at times playful. He often celebrates after hitting a three-pointer, sometimes doing the shimmy, hyping up his teammates and the home crowd. Curry radiates a feeling of enchantment and childlike delight with the game, which seems like an extension of life itself. He’s a fierce competitor without hard edges.

This season has been the most grinding one for the Warriors during their half-decade-long dominance of the NBA. Tensions have flared between Durant and the star forward Draymond Green. At times, the Warriors have appeared lackadaisical, distracted, and mentally worn down. The players seem to sense that their dynastic run is winding down. At these moments, it’s been Curry who has stepped into the breach, bringing the locker room together, telling the world and his teammates, “We cannot lose the joy that we need to play with.” He doesn’t want the dance to end. Neither do I.

The Western Conference finals with Portland begin at Oracle Arena on Tuesday evening. For at least the first part of the series, the Warriors will be without Durant, the former regular-season and finals MVP who was playing as well as he ever has prior to his calf injury. Golden State seems more vulnerable than at any other point in the past few years. But in the furnace heat of the playoffs, when some players rise to the challenge and others disappear, the Warriors will happily cast their lot with their cheerful assassin, the overlooked high-school prospect who transformed the game, the best long-shooter ever to set foot on a hardwood floor.



Charles de Gaulle found the memory of D-Day so painful that he refused to participate in commemorations of the Normandy invasion during his 11 years as president of France. He did not invite heads of government to mark either the 20th anniversary in 1964 or the 25th in 1969. Old soldiers saluted; ambassadors laid wreaths.

President Dwight Eisenhower had tried to salve the French hurt in the statement he released for the 10th anniversary in 1954. The statement did not mention the United States or its armed forces. It praised by name three British commanders, three French, one Soviet—no Americans. It credited the victory to “the joint labors of cooperating nations,” and said “it depended for its success upon the skill, determination and self-sacrifice of men from several lands.” You might want to read it as a prophylactic antidote to the boast and bombast likely to fill the air today.

The experience of liberation was a complex thing for almost every country that experienced it from 1943 to 1945, but perhaps nowhere more than France. In the American imagination of 1944, France exists as a throng of cheering, welcoming faces, as women kissing GIs, as a landscape through which Allied tanks and trucks roar on their way to Germany. Depending on our mood, we romanticize the Resistance or excoriate collaborators—seldom caring to remember how ambiguously collaboration and resistance often blended together, or how often collaborators and resisters were the same people at different phases of the war or even different times of the same day.

To be liberated, first you must be defeated.

Everything about these D-Day anniversaries reminds the French of that humiliating sequence. When de Gaulle landed in Normandy for a one-day visit on June 14, he traveled back-and-forth across the English Channel in a British warship. De Gaulle’s ability to establish a provisional government depended on the permission of U.S. and British authorities—and so, ultimately, would the even more fraught question whether France would be accepted again as a major ally.

For four years, Vichy France had supplied and aided Germany. Vichy planes had bombed Gibraltar in 1940; Vichy tax collectors had extracted resources to pay the German occupiers. When Italy changed sides in 1943, it was treated as a liberated nation—but it was not accepted as a co-belligerent. France’s post-D-Day status utterly depended on British and American goodwill. For a man like de Gaulle, that dependency rankled.

De Gaulle’s famous speech of August 25, 1944, after the liberation of Paris, starkly reveals the fictions that would restore French pride.

“Paris! Paris outraged! Paris broken! Paris martyred! But Paris liberated! Liberated by itself, liberated by its people with the help of the French armies, with the support and the help of all France, of the France that fights, of the only France, of the real France, of the eternal France! … It will not even be enough that we have, with the help of our dear and admirable Allies, chased him from our home for us to consider ourselves satisfied after what has happened. We want to enter his territory as is fitting, as victors.”

France did enter Germany as a victor. French armies, supplied by the United States, subordinate to U.S. command, were stood up in 1944–45. France was allotted an occupation zone in Germany and awarded a permanent seat on the UN Security Council. (Italy was not even invited to join the United Nations until 1955.) Allied officialdom agreed to believe de Gaulle’s story that the France that fought Nazi Germany was the only real France.

But everyone understood the story was not true. The French military defeat in 1940 had torn apart social wounds dating back decades and longer. Conservative and Catholic France reinterpreted the battles of 1940 as a debacle only of the liberal and secular France that had held the upper hand since the founding of the Third Republic in 1871 and especially since the Dreyfus affair that began in 1894. When the reactionary French writer Charles Maurras was sentenced to life imprisonment for collaboration, he supposedly replied, “It’s the revenge of Dreyfus.”

Most French business leaders and civil servants collaborated out of opportunism or necessity. The Germans held hundreds of thousands of captured French soldiers as hostages for years after 1940. But more than a few leading French people, including many intellectuals and churchmen, collaborated out of a species of conviction. A French cardinal led the recruitment of French volunteers to fight alongside the Germans in Russia in 1941. “How can I, in a moment so decisive, refuse to approve the common noble enterprise directed by Germany, dedicated to liberate Russia from the bonds that have held it for the last twenty-five years, suffocating its old human and Christian traditions, to free France, Europe, and the world from the most pernicious and most sanguinary monster that mankind has ever known, to raise the peoples above their narrow interests, and to establish among them a holy fraternity revived from the time of the Christian Middle Ages?” Cardinal Alfred Baudrillart wrote, in his endorsement of the Anti-Bolshevik Legion.

The loss of the war against Germany enabled such people to launch a much more congenial culture war at home, to purge France of “liberty, equality, and fraternity,” the slogan of 1789, and establish in its place “work, family, fatherland,” the slogan of Vichy. Since 1905, France had been defined as a secular state. The Catholic Church had been reduced to one sect among others: Protestant, Jewish, even Muslim. (In 1920, the French government had subsidized the building of a grand mosque in thanks for the First World War service of Muslim troops. The great military cemetery near Verdun has a special section for Muslim soldiers, their graves angled away from the others in order to face Mecca.)

Vichy put an end to all that. The defeat of France by Germany was ideologically reinterpreted as a victory of “deep France” over a shallow liberal metropolitan veneer. Subjugation was reinterpreted by Vichy ideologues as redemption. Enmity was shifted from the occupying Germans to the liberal commercial “Anglo-Saxons.” Vichy propagandists produced cartoons in which Mickey Mouse, Donald Duck, and Popeye were depicted dropping bombs on France at the behest of Jewish masters.

Anti-Allied enmity was not difficult to stoke: Allied bombing before 1944 and Allied land forces after 1944 did more damage to French cities than the Germans had in the few weeks of combat in 1940. The port of Le Havre was bombed 132 times from 1940 to 1944. The final raids in September reduced the city center to rubble, killing 5,000, maiming and rendering homeless tens of thousands more. The modernist cityscape that replaced the former 18th- and 19th-century core remains an enduring monument to the price paid by the French people for their liberation.

Vichyite enthusiasm for anti-liberalism opened a strange fluidity in French politics during and after the war. The future leader of French socialism, François Mitterrand, began his political career on the far right of French politics and worked until 1943 as a civil servant in the Vichy government. As president after 1981, Mitterrand would raise minimum wages, cut the workweek to 39 hours, nationalize some financial institutions, and end the death penalty. He would even do what de Gaulle could never stomach: celebrate the D-Day anniversary.

It was Mitterrand who decided to invite Ronald Reagan to Normandy in 1984, where Reagan delivered one of the great speeches of his presidency. Yet Mitterrand, to the end of his career, remained friends with—and protected from prosecution for crimes against humanity—the Vichy police chief who deported tens of thousands of Jews to their death.

But the chief was not the only one protected, and Mitterrand was not the only protector. As the French journalist René Rémond quipped to Roger Cohen of The New York Times: “They all have something to hide.”

When Americans choose to remember this sad history, they do so from the privilege of an easier geography. As time has separated us from the Second World War, U.S. memories have become more triumphalist and self-aggrandizing. It is a remarkable thing to watch President Donald Trump’s preening and posing in the U.K. and France on this anniversary. France fell in 1940 in great part because the United States went AWOL from European peace and security after 1919. The U.S. was AWOL very much because of leaders who in their day espoused the same crass protectionism and isolationism—and even the same “America First” slogan—as Trump himself.

Yet Americans are not immune to the Vichy syndrome that elevates the culture war against domestic opponents over the defense of national sovereignty and independence. Nor are they immune, either, to the extremist illiberal politics that flourished under Vichy.

An exotic dispute has erupted among social-conservative writers and thinkers over the past few days. Like Gamergate of 2014, it is a dispute made even more confusing by the explanations. Ross Douthat attempted the task in The New York Times this week. Yet even Douthat’s lucid prose will leave many readers disoriented. At bottom, though, what is going on—as Douthat acknowledges in his column—is a rehabilitation of integralism, the form of Catholic reactionary politics espoused by Charles Maurras and other intellectual Vichyites. You might think this the deadest of intellectual dead ends, and so it should be, but so it is not.

The rise of Donald Trump has sparked many analogies to the politics of the 1930s. In general, this is an error. Our mentalities are not formed by vivid personal memories of the mass slaughter of 1914–18. We have experienced nothing like the Great Depression or the civil unrest that piled bodies in the streets of interwar Berlin and Paris. We are not haunted by the possibility that domestic communists might seize power and property in a revolutionary spasm. It’s never going to be 1933 again.

But the human impulses on which the fascists and communists of the 1930s battened? Those do remain with us. They have been a powerful resource to extremists of all kind in our unsettled present moment after the Great Recession of 2008–09 and amid the mass developing-world migration flows of the 2010s. Trump is their most conspicuous beneficiary, but not their only beneficiary. They trouble France; they trouble us.

This time, no D-Day is called for to defeat them—just a renewed commitment to the ideals for which D-Day was launched 75 years ago by soldiers of so many lands, including the France that has taken so long to make its entire peace with this complicated anniversary.



President Donald Trump doesn’t want conflict. Ayatollah Khamenei doesn’t want economic collapse. Yet that is where things are headed.

Put yourself in the shoes of Iran’s 80-year-old supreme leader, Ayatollah Ali Khamenei. His regime is beset by nearly 50 percent inflation, a collapsed currency, persistent labor strikes, and an irrepressible women’s-rights movement. Epic floods recently killed more than 75 people and caused nearly $3 billion in damage. A locust plague is threatening 300,000 hectares—$9 billion worth—of farming land. “Things have never been this bad” is a refrain commonly heard from Iran these days.

Beyond its borders, Iran is spending several billion dollars annually to arm and finance regional allies—including Syria’s Assad regime, Lebanese Hezbollah, Iraqi Shia militias, and the Houthis of Yemen—that offer little financial return on that investment. Direct flights between Tehran and Caracas have resumed so Iran can prop up the embattled Maduro regime.

Against this backdrop, a U.S. president whom Khamenei has described as “mentally retarded”—Donald Trump—is pursuing a relentless economic-pressure campaign seemingly intended to force either Iran’s capitulation or its collapse. First, in May 2018, Trump unilaterally pulled out of the Iran nuclear deal. In April 2019, the State Department officially designated Iran’s most powerful political and economic institution—the Islamic Revolutionary Guard Corps (IRGC)—a terrorist organization, further rendering that group an international pariah. And now Secretary of State Mike Pompeo has announced that no countries will be granted further exemptions to import Iranian oil, an attempt to choke the lifeblood of Iran’s economy.

“Everyone has a plan until they get punched in the mouth,” Mike Tyson has famously said. Khamenei’s reaction—or lack thereof—to being punched by Trump repeatedly could have important consequences for the global economy, the stability of Iran and the Middle East, and even America’s 2020 presidential election.

Rarely have an American president and his national security adviser held more divergent views than Donald Trump and John Bolton. Trump has repeatedly expressed an aversion to greater U.S. involvement (including conflict) in the Middle East, and his affinity for autocrats makes clear that he has no interest in democracy promotion or regime change in Iran. He has made numerous unreciprocated efforts to meet Iranian President Hassan Rouhani and has told aides and foreign leaders that his “maximum pressure” campaign is designed to be a prelude to diplomacy, not conflict.

Bolton, by contrast, has a long history of advocating both military strikes and regime change against Iran. Pompeo has sought to reconcile these contradictory impulses by focusing on the means—that is, by raising the pressure—rather than the endgame. “The worst fear of Bolton and Pompeo,” a senior State Department official told me, “is that the Ayatollah [Khamenei] writes Trump a letter, suggesting a get-together. They know the president would jump at such an opportunity.”

Can Khamenei overcome his pride and cynicism to try to exploit the Trump administration’s internal divides, or will he choose to escalate? An insufficient response to American bullying could cause him to lose face; an excessive response could cause him to lose his head. Khamenei essentially has three options, and all of them are fraught with risk:

Strike a Deal With Trump

The quickest way for Khamenei to halt Iran’s economic hemorrhaging would be to allow Rouhani to pursue a deal with the Trump administration. Given Trump’s weakness for flattery and disinterest in details, it’s conceivable Tehran could get an even better deal with Trump than it did with Obama.

While this outcome is plausible, it’s highly unlikely. Khamenei’s longtime distrust of the “deceitful, untrustworthy, and back-stabbing” U.S. government was vindicated after Trump pulled out of the Joint Comprehensive Plan of Action—the Iran nuclear deal—and he understandably fears that giving in to pressure may encourage Bolton and Pompeo to turn the heat up, not off. For Khamenei, subjecting 80 million Iranians to another 20 months (at least) of economic hardship may be preferable to holding his nose, swallowing his pride, and doing a deal with Trump.

Wait Trump Out

While Khamenei had vowed to “burn” the JCPOA were the United States ever to renege on its commitments, Tehran’s response to Trump’s provocations has so far been restrained. Iran has complied with the nuclear deal and has yet to react to the Trump administration’s designation of the IRGC as a terrorist group. Although one of the strategic goals of this restraint was to show the world it is the United States, not Iran, that deserves to be isolated, America’s economic might has rendered this strategy moot. “One of the strongest industrialized countries in the world has made a political decision.” Ralf Thomas, the CFO of Siemens, said last year. “As an industrial company, we have to recognize that.”

Former—and potentially future—U.S. officials have sought to reassure Iranian Foreign Minister Javad Zarif and Rouhani that Trump is a weak president unlikely to get reelected, and a Democratic president will swiftly return to the JCPOA come January 2021. Exercising such strategic patience, however, is a risky strategy for Khamenei. In addition to the possibility that Trump will get reelected, Khamenei rightfully fears that if Iran sits on its hands until January 2021, even Democrats may come to believe that the United States can eat its cake and have it too. “Why should we lift sanctions,” a former Obama-administration official asked rhetorically, “when they’ve stayed committed to the deal for four years and will use the sanctions relief to support our adversaries?”

Counter-escalate

If Khamenei believes he can’t do a deal with Trump, and he fears that waiting out Trump projects weakness, he may contemplate restarting Iran’s nuclear program, counter-escalating against U.S. interests and allies in the Middle East, or both. Iran is the only country in the world simultaneously fighting three proxy wars—against the United States, Israel, and Saudi Arabia—each of which it could further agitate. Indeed, Arab Gulf officials claim to have picked up intelligence indicating that Tehran is planning to agitate against them in the region, via proxy. Given the already turbulent state of the Middle East and Trump’s inclination to further withdraw from the region of “death and sand,” however, Tehran’s threat to destabilize is a weakening asset.

If Tehran chooses to recommence its nuclear activities, it will likely do so very deliberately—still under the guise of a civilian energy program—to avoid triggering a unified international response. Iran’s renewed nuclear activities, coupled with an absence of international resolve, would force the United States and Israel to contemplate once against the possibility of military action against Iran’s nuclear facilities. Either Iranian escalation—nuclear or regional—could undermine Trump’s desire to withdraw from the Middle East as America’s regional allies, particularly Israel and Saudi Arabia, would request a greater U.S. presence to counter an agitated Iran.

Despite the overwhelming criticism of Trump’s maximum-pressure campaign, there are already signs of its impact on Iranian thinking. Whereas last year Khamenei strictly prohibited any talks with the United States on any issues and forbade Rouhani from accepting Trump’s offer to meet “anytime and without preconditions,” Zarif now appears eager to open a channel of communication with Washington—starting with hostage negotiations—and took the unprecedented step of appearing on Fox News to directly appeal to Trump.

Yet Khamenei’s 30-year tenure as supreme leader has honed his three-dimensional chess skills, and it’s likely that he may pursue these three seemingly contradictory objectives—negotiations, strategic patience, and escalations—simultaneously. While Zarif is waving a flag of diplomacy, Khamenei will likely simultaneously authorize Qassem Soleimani, commander of the IRGC’s Quds Force, to activate Iran’s regional proxies against U.S. allies and interests in the Middle East. Whereas Washington amasses leverage with economic sanctions, one of Tehran’s few sources of leverage is its ability to sow chaos and carnage.

Just as the Iran hostage crisis ended the Carter presidency, Iran-Contra tainted the Reagan presidency, and the Iran nuclear program and deal engrossed the Obama presidency, Trump’s Iran gamble could similarly consume the duration of his first term and either boost or bust his chances of a second term. Iran, to help ensure that Trump is a one-term president, should be expected to pursue policies that could trigger regional unrest and a spike in oil prices, increasing the anxieties of American voters.

Khamenei and Trump have a mutual interest in averting conflict and cooperating, but they face a prisoner’s dilemma. As the example of both the 2015 JCPOA and the current nuclear negotiations with North Korea illustrate, the path to diplomacy is often paved with mutual threats and escalation. While the winner of the Trump-Khamenei face-off remains unclear, the biggest losers of the next two years will almost certainly be the people of Iran, as well as the inhabitants of Middle East countries where Iran wields influence.



By the tail end of the Obama administration, the culture war seemed lost. The religious right sued for détente, having been swept up in one of the most rapid cultural shifts in generations. Gone were the decades of being able to count on attacking its traditional targets for political advantage. In 2013, Chuck Cooper, the attorney defending California’s ban on same-sex marriage, begged the justices to allow same-sex-marriage opponents to lose at the ballot box rather than in court. Conservatives such as George Will and Rod Dreher griped that LGBTQ activists were “sore winners,” intent on imposing their beliefs on prostrate Christians, who, after all, had already been defeated.

The rapidity of that cultural shift, though, should not obscure the contours of the society that the religious right still aspires to preserve: a world where women have no control over whether to carry a pregnancy to term, same-sex marriage is illegal, and gays and lesbians can be arrested and incarcerated for having sex in their own homes and be barred from raising children. The religious right showed no mercy and no charity toward these groups when it had the power to impose its will, but when it lost that power, it turned to invoking the importance of religious tolerance and pluralism in a democratic society.

That was then. The tide of illiberalism sweeping over Western countries and the election of Donald Trump have since renewed hope among some on the religious right that it might revive its cultural control through the power of the state. Inspired by Viktor Orbán in Hungary and Vladimir Putin in Russia, a faction of the religious right now looks to sectarian ethno-nationalism to restore its beliefs to their rightful primacy, and to rescue a degraded and degenerate culture. All that stands in their way is democracy, and the fact that most Americans reject what they have to offer.

The past few weeks have witnessed a nasty internecine fight among religious conservatives about whether liberal democracy’s time has passed. Sohrab Ahmari, writing at First Things, attacked National Review’s David French for adhering to a traditional commitment to liberal democracy while “the overall balance of forces has tilted inexorably away from us.” Would the left have stood by liberal democracy in the face of such circumstances? In fact, the balance of forces tilted away from the left’s cultural priorities for most of my lifetime, and the left’s response was to win arguments—slowly, painfully, and at incalculable personal cost.

Many religious conservatives see antidiscrimination laws that compel owners of public accommodations to serve all customers, laws that might compel priests to break the seal of confession if they are told of child abuse, and the growing acceptance of trans people as a kind of impending apocalypse. It is no surprise that among their co-partisans, Ahmari seems to have the upper hand here; in such circles, “Crush your enemies” almost always plays better than “The other side has rights too.”

The concerns Ahmari airs are not wholly without merit: Religious conservatives are not paranoid to imagine themselves pariahs someday in the future because of their views; it was not so long ago that liberal champions such as Barack Obama and Hillary Clinton held public positions that today would be described by the left as bigotry. Nor should the left expect to win every battle with the right over matters of religious conscience; there will be moments when its opponents are correct. The same wall between Church and state that prevents the state from being dominated by the Church also bars the state from dictating the religious commitments of the Church. A law that compels Catholic priests to break the seal of confession, for example, likely runs afoul of the Free Exercise Clause of the First Amendment, despite the state’s obvious and compelling interest in preventing child abuse, and despite the Church’s abysmal record in doing so.

In spite of their disagreements, Ahmari and French are in accord about a great deal when it comes to abortion, women’s rights, and LGBTQ rights. French’s adherence to liberal democracy is a commitment to a set of rules under which these goals can be pursued in a pluralistic society: through public discourse, the courts, and the ballot box. For Ahmari and his ilk, this is insufficient. He seems to believe not only that the state should always settle such disputes in his favor, but that it should prevent cultural and political expressions he finds distasteful.

This isn’t an exaggeration. In a since-deleted tweet, Ahmari praised Alabama Public Television for refusing to air an episode of the cartoon Arthur in which the titular character’s male teacher marries another man; his attack on French was preceded by another since-deleted eruption, over Drag Queen Story Hour at a public library, in which he cried, “To hell with liberal order”; and he has since suggested the humanities should be defunded because “they may be lost to us for good.” If this is where Ahmari and his cohort are while the GOP still controls the courts, the Senate, and the presidency, imagine what they’ll be willing to countenance should they lose them.

Ahmari’s demands here outline the United States that illiberals would like to see: one that resembles Orbán’s Hungary, where rigged electoral systems ensure that political competition is minimal, the press is tightly controlled by an alliance between corporations and the state on behalf of the ruling party, national identity is defined in religious and ethnic terms, and cultural expressions are closely policed by the state to ensure compliance with that identity. It is no surprise that the vast majority of black and Latino Christians see a secular but pluralist left as more trustworthy allies than conservatives who rail against “poisonous and censorious multiculturalism,” and darkly warn of a plot to “displace American citizens.”

When Ahmari was asked, however, by Jane Coaston at Vox what his “ideal order” would look like, he said, “Working mothers wouldn’t be expected to return to work a mere eight weeks after giving birth.” This sort of obvious, coy insincerity about the actual nature of the changes they seek is one of the major reasons religious conservatives like Ahmari have lost so much ground in the public square, and why the left is inclined to view their demands for religious exceptions to be thinly veiled excuses for discrimination. The question of whether working mothers deserve more generous maternity leave does not represent a bitter split between the religious right and the secular left, nor is it given prominence in his manifesto, which focuses on crushing the left, or, as he put it, fighting “the culture war with the aim of defeating the enemy and enjoying the spoils in the form of a public square re-ordered to the common good and ultimately the Highest Good.”

Although the intraconservative critiques leveled by Ahmari and his allies sometimes take on the language of opposition to market fundamentalism, they are not truly opposed to the concentration of power and capital. These critics observe the decline in wages and community that has resulted from this concentration, and propose to do nothing at all about it other than seize that power for themselves, to be used to their ends. The illiberals see the wealthy and upper-middle classes getting married, forming families, and raising children much as they did in the 1950s, and conclude that the problem with working-class Americans is not the diminished political power relative to their bosses, but the absence of a sharp enough lash, whether from the state or from a culture that has escaped the religious right’s grasp. Gillette should be making commercials about women staying at home and fathers going off to work, not dads teaching their trans sons to shave for the first time.

This understanding also helps illuminate the right’s eruption over YouTube’s decision to demonetize (but not remove) the channel of Steven Crowder, a conservative YouTuber who called the Vox reporter Carlos Maza a “lispy queer,” among other slurs. A world in which one can refer to gay people as “lispy queers” without repercussion is one in which the illiberal right is winning the culture war, so it matters little that YouTube is no less a private business than Masterpiece Cakeshop, and has a right to define the rules for using its platform. The same sort of protests that the right decries as illiberal when deployed against right-wing speakers on college campuses are suddenly a legitimate tactic when used against Drag Queen Story Hour. The objective here, in Ahmari’s words, is to defeat “the enemy,” not adhere to principle, and that requires destigmatizing anew the kind of bigotry that was once powerful enough to sway elections.

Indeed, the illiberal faction in this debate retains Trump as its champion precisely because the president is willing to use the power of the state for sectarian ends, despite being an exemplar of the libertinism to which it is supposedly implacably opposed, a man whose major legislative accomplishment is slashing taxes on the wealthy, and whose most significant contribution to the institution of the family is destroying thousands of them on purpose. It is power that is the motivator here, and the best that could be said for these American Orbánists is that they believe that asserting an iron grip on American politics and culture would offer the greatest good for the greatest number of people. Every authoritarian movement has felt the same way.

I don’t want to overstate the significance of this dispute between French and Ahmari. They are yelling at each other in a walled garden; conservative pundits in ideological magazines have little influence over a base whose opinions are guided by the commercial incentives of Fox News and right-wing talk radio, and the partisan imperatives of the Republican Party. If they possessed such influence, Trump would not be president.

The question of whether the Republican Party would abandon liberal democracy for sectarian ethno-nationalism was decided in the 2016 primary, and all French and Ahmari are doing is arguing about it after the fact. The commercial and social incentives for conservative writers to succumb to Trumpism are vast. Some, like French, have had the integrity to stick to their stated principles. Others, like Ahmari, have already fallen. Today’s skirmishes among conservatives resemble the irregulars in 1865 shooting at one another because they had not yet heard of Robert E. Lee’s surrender at Appomattox. And the support Ahmari has drawn suggests that the conservative intelligentsia will offer less resistance to authoritarianism than it did in 2015 and 2016.

Trump is the symptom of the Republican Party’s turn toward illiberalism, not its cause; even before Trump ran for president, some Republican elites were plotting to diminish the political power of minorities and enhance those of white voters. Whatever their disagreements, the leaders of both the populist and establishment wings of the Republican Party have concluded that they cannot be allowed to lose power simply because a majority of American voters do not wish them to wield it. The president speaks of imprisoning his political rivals, and his voters cheer. He valorizes political violence, and his followers take note. His attorneys argue both that Congress cannot investigate criminality in the executive branch and that the president has the authority to end criminal investigations into himself or his allies, while ordering them against his opponents. Trump’s supporters exult in the head of state attacking private citizens who demand equal rights, then wave the banner of free speech exclusively in defense of expressions of bigotry. In the end, Trump will dictate the course of his party on these matters, and his base will do whatever he gives it license to do. Writers such as French and Ahmari cannot shape this course; they can only argue about it after the fact.

What is notable is that crisis of faith in liberalism for this faction of the religious right comes only now. It is true, as The New York Times’ Ross Douthat writes, that “liberalism has never done as well as it thinks at resolving its own crises.” Yet this faction did not abandon its faith in liberalism’s capacity to solve problems during the decades of Jim Crow. It did not cry, “To hell with the liberal order!” over mass incarceration. It did not erupt in fury over the shattering of Latino families at the border, or the Trump-made aftermath of the catastrophe in Puerto Rico. It did not question whether liberalism had failed after the first, third, fourth or 15th mass shooting at a school, or because it is typical for Americans to beg strangers on the internet for money to cover their health-care costs or after an untimely death. The state of emergency occurred when, and only when, liberal democracy ceased to guarantee victory in the culture war. The indignity of fighting for one’s rights within a democratic framework is fine for others, but it is beneath them.

Some perspective is in order. Douthat looks to the future and asks whether a society “dominated by virtual reality and eugenics and mood-stabilizing drugs, post-familial and post-religious and functionally post-human,” would “deserve the political loyalty of (let us say) a traditional Christian or Muslim, just because it still affords them some First Amendment protections? It is reasonable to say that it might not.”

Black Americans did not abandon liberal democracy because of slavery, Jim Crow, and the systematic destruction of whatever wealth they managed to accumulate; instead they took up arms in two world wars to defend it. Japanese Americans did not reject liberal democracy because of internment or the racist humiliation of Asian exclusion; they risked life and limb to preserve it. Latinos did not abandon liberal democracy because of “Operation Wetback,” or Proposition 187, or because of a man who won a presidential election on the strength of his hostility toward Latino immigrants. Gay, lesbian, and trans Americans did not abandon liberal democracy over decades of discrimination and abandonment in the face of an epidemic. This is, in part, because doing so would be tantamount to giving the state permission to destroy them, a thought so foreign to these defenders of the supposedly endangered religious right that the possibility has not even occurred to them. But it is also because of a peculiar irony of American history: The American creed has no more devoted adherents than those who have been historically denied its promises, and no more fair-weather friends than those who have taken them for granted.

Undetectable in the dispute on the right is any acknowledgment of the criticisms of liberal democracy by those who have been fighting for their fundamental rights in battles that are measured in decades and even centuries; that the social contract implicitly excluded them from the very rights white Christian men have been able to assert from the beginning. Perhaps to do so would be to acknowledge the fundamental immaturity underlying the American Orbánists’ critique: that what they describe as a crisis of liberal democracy is really just them not getting exactly what they want when they want it.



Though few citizens of the United States or Iran seek conflict, the two countries are on a dangerous trajectory that has less and less to do with the diverging interest of two nation-states. More and more, the escalation is being driven by the clashing temperaments of two cynical elderly men. Ayatollah Ali Khamenei, the 80-year-old Iranian supreme leader, has been steadfast, even monomaniacal, in opposing the United States. In contrast, the 73-year-old Donald Trump has employed a flurry of strategies—from flattering Iran to coming within minutes of military strikes—to bring Tehran to heel.  

The Oxford University philosopher Isaiah Berlin’s seminal 1953 essay, “The Hedgehog and the Fox,” offers a simple dichotomy to explain recent dynamics between the United States and Iran—or, rather, between Trump and Khamenei.

Borrowing a line from the ancient Greek poet Archilochus, Berlin divided human beings into two different categories: “The fox knows many things,” he wrote, “but the hedgehog knows one big thing.” Hedgehogs have a grand theory of the world, while foxes employ a different cunning for every circumstance. He cites Shakespeare and Aristotle as examples of foxes, while “Karl Marx was the most implacable hedgehog of them all.”

Among world leaders today, few hedgehogs are more implacable than Ayatollah Khamenei. Hedgehogs, Berlin argued, “relate everything to a single central vision … a single, universal, organizing principle in terms of which alone all that they are and say has significance.” In this spirit, Khamenei’s organizing principle throughout his 30-year rule as supreme leader has been “resistance” against America.

Rather than calming Iranian national anxieties about the prospect of war with the United States, Khamenei used the word resistance more than 65 times in a recent speech—sometimes more than once in a sentence. “Today in our region,” he said, “the common word among nations is resistance. Everyone agrees with resistance … The recent defeats that the Americans suffered in Iraq, Syria, Lebanon, Palestine and other such countries were an outcome of the resistance of Resistance groups.”

For Khamenei, “resistance” against “global arrogance”—his moniker for American imperialism— is both an ideology and a strategic doctrine. “Resistance,” he said, “unlike surrender, leads to the retreat of the enemy. When the enemy bullies you, if you take a step back, he will undoubtedly advance. The way to stop him from advancing is to resist.” Consistent with Khamenei’s philosophy, Iran has not responded to Trump’s “maximum pressure” campaign with concessions, but rather by sowing chaos in the region and threatening to restart its nuclear program.

Berlin contrasted the dogmatism of hedgehogs with foxes, who, he wrote, “pursue many ends, often unrelated and even contradictory, connected, if at all, only in some de facto way, for some psychological or physiological cause, related to no moral or aesthetic principle.” Even sympathetic observers of Donald Trump’s presidency would likely concur that he pursues contradictory ends motivated by an unknown psychological cause for no clear moral principle. But while Khamenei is the quintessential hedgehog, Trump is a variation on the prototypical fox; he does not know many things as much as he says many things.

Unlike Khamenei’s sole strategic doctrine, Trump’s Iran strategy—sometimes to the left of Glenn Greenwald, and sometimes to the right of Sean Hannity—has had the coherence of a Jackson Pollock painting. Days after angrily tweeting that “If Iran wants to fight, that will be the official end of Iran,” Trump proclaimed that Iran “has a chance to be a great country with the same leadership.” After Iran shot down a U.S. drone over the Persian Gulf this week, Trump ominously tweeted “big mistake.” Moments later, he assessed it may have just been a big misunderstanding. Hours later, he claimed to call off military strikes against Iran 10 minutes before they were to happen.

Trump’s erratic approach—provoking an escalation cycle while simultaneously making clear his aversion to conflict—only increased Tehran’s appetite for risk. As Suzanne Maloney from the Brookings Institution has pointed out, Trump is learning the same hard lesson as six U.S. presidents before him. If Tehran is willing to subject its population to economic hardship and use the entirety of its energy wealth to promulgate an antiquated ideology that advocates “Death to America” rather than “Prosperity for Iranians,” the United States has limited ability—using either engagement or coercion—to dissuade it.

Indeed, despite the imbalance of power between Tehran and Washington, Khamenei has been the one to consistently refuse Trump’s offer of dialogue, not vice versa. While many have declared this a failure of Trump’s maximum-pressure campaign, the reality is that Iran is in a much greater bind. A U.S. military strike on Iran might have been averted for now, but Iran’s deteriorating economic circumstances cannot likely be reversed absent an accommodation of the United States.

In this context, for Trump the best option is not to respond militarily to Iranian acts of aggression and sabotage, but to use them to build more robust international support, all while keeping the door of diplomacy open. While the deteriorating Iranian economy probably won’t make the regime implode, Iranian popular pressure will grow on Khamenei to justify his opposition to negotiations, and will increasingly expose him as the obstacle that stands between Iranians and a better future. Tehran already shows signs of frustration with Khamenei’s intransigence, including President Hassan Rouhani’s recent admission that he has no authority over Iran’s foreign affairs.

When and if Tehran is ready to talk, the differences between Trump and Khamenei present further obstacles. Trump prefers public pageants about broad topics; Khamenei prefers private discussions about narrow topics. Reaching a deal—or at least averting a conflict—will require Khamenei to acquire the flexibility of a fox, and Trump to adopt the strategic patience and resolve of a hedgehog. While two men with a combined age of 153 surely lack the psychological and ideological agility to change who they are, the possibility of a devastating war will encourage a little more deftness.



Is the Israeli-Palestinian conflict fundamentally about land and territory? It is certainly partly about that. But when you hear the objections and grievances of both sides, the issue of who has what part of which territory doesn’t necessarily figure all that prominently.

I recently took part in a study tour on religion and nationalism in Israel and the West Bank organized by the Philos Project. One Palestinian official whom we met told us, “I’m not going to compromise my dignity.”

The problem with what we know of the Trump administration’s “peace plan” is that it asks Palestinians to do precisely that. The entire Donald Trump approach seems to be premised on calling for unilateral surrender. It is premised on destroying the will of a people, and on hoping that despair might one day turn into acquiescence. This is the only way to interpret Trump’s senior adviser and son-in-law Jared Kushner’s insistence on prioritizing economic incentives over political progress, but this misunderstands most of what we know about human motivation.

I have a bias: I don’t tend to think that people are primarily motivated by measurable, quantifiable things. To the extent that territory becomes a seemingly insurmountable obstacle, it matters, but it matters as a proxy for other, deeper issues. As my Brookings Institution colleague Shibley Telhami put it: “To assume that the promise of economic improvement would outweigh ordinary human aspirations of a people who have painfully struggled for decades is to miss the nature of the human condition.”

Our Palestinian interlocutor’s refusal to cede his dignity wasn’t a performance; it was despair. It felt to me like an epitaph. There have been conflicts in which leaders have made compromises that may have seemed like betrayals, only for history to view them as both bold and necessary. But those conflicts are not this conflict.

The Israelis’ narrative is quite different from the Palestinians’, and on its own terms, it’s not necessarily wrong. According to this perspective, Arabs, from the founding of Israel in 1948 onward, have either longed for the Jewish state to disappear or taken action to actually make it disappear. This relates to the Israeli refrain that there is no Palestinian partner for peace; the most moderate Palestinians may accept Israel’s existence as an unfortunate fact, this argument goes, but not even they believe in Israel’s right to exist as the national homeland for the Jewish people.

In their long history together, Muslims knew Jews less as an ethnic group than as adherents of another religion, different from Islam but also like it. In The Jews of Islam, Bernard Lewis noted that when Muslims expressed negative attitudes toward Jews, they were “usually expressed in religious and social terms, very rarely in ethnic or racial terms.” In conversation, many Palestinians express discomfort with the idea that Jews are both a people and a religion, and Israeli Jews tend to view this lack of recognition as sinister and evidence of Arab irreconcilability.

Many of the early Zionists were secular, so their vision for a State of Israel did not depend on a shared religious faith. It depended, instead, on being a people. The moniker “Jewish state” itself captures this, since a Jewish state can be a secular home for Jews, whereas an “Islamic state”—to use another legalistic religion—suggests a religious mission and theological premises.

Divergent histories and narratives shape the interpretation of otherwise factual questions about what actually happened and didn’t happen at key moments. For example, Israeli politicians attack Palestinians for squandering Prime Minister Ehud Barak’s “generous offer” of 2000, and so a story of Arab and Palestinian recalcitrance builds uninterrupted, with each new rejection confirming the previous one: First, Arabs rejected the 1947 United Nations partition plan. Then Arab nations waged war against the new Israeli state. Decades later, when they finally had their chance, Palestinians rejected Barak’s offer. Then they rejected Prime Minister Ehud Olmert’s offer, and so on.

To put it mildly, Palestinians do not share this interpretation of what went wrong. They believe the offer was far from generous, coming after six years of “more Israeli settlements, less freedom of movement, and worse economic conditions,” as the senior Clinton-administration adviser Rob Malley and Hussein Agha argue in one of the definitive accounts of the 2000 Camp David negotiations. In practice, Barak, the dove, wasn’t much of a dove. As Malley and Agha write: “Behind almost all of Barak’s moves, Arafat believed he could discern the objective of either forcing him to swallow an unconscionable deal or mobilizing the world to isolate and weaken the Palestinians if they refused to yield.”

Palestinian activists tend to speak in terms of justice. An injustice was done, so it must be undone. Christopher Hitchens, in his valediction for the Palestinian American author Edward Said, wrote that his friend’s “feeling for the injustice done to Palestine was, in the best sense of this overused term, a visceral one. He simply could not reconcile himself to the dispossession of a people or to the lies and evasions that were used to cover up this offense.”

Pro-Palestinian protesters often chant the mantra of “no justice, no peace.” One former Israeli official we spoke with in Jerusalem had a different view. He said, “If we make this about justice, there will not be peace.” Too many Palestinians celebrate victimhood—fueled by a profound sense of injustice—rather than overcome it, he suggested.

But then we return to the question of dignity. No one should be asked to overcome their victimhood by giving up their dignity, the one thing even an occupier shouldn’t be able to take away. That might sound naive and impractical, especially for those who would rather Palestinians just get on with it, but that doesn’t make it any less true.

If I were advising the Palestinians, I’d tell them to reject Kushner’s offer, but they don’t need anyone to tell them what’s already painfully obvious. If someone doesn’t understand anything about the history of the Palestinians, their grievances and their narratives, then what’s the point? The outgoing French ambassador to the United States, Gérard Araud, described Kushner this way: “He is so pro-Israeli also, that he may neglect the point that if you offer the Palestinians the choice between surrendering and committing suicide, they may decide the latter. Somebody like Kushner doesn’t understand that.”

Because the two sides are so far apart and are likely to remain so for the foreseeable future, the United States—if it’s unwilling to put serious pressure on Israel or take seriously Palestinian objections—is better off disengaging from an imaginary peace process, rather than lending legitimacy to Israel’s behavior or giving the illusion of progress without the substance. Otherwise we are all just wasting time, at least until a new president attempts to fundamentally rethink America’s sometimes well-intentioned but almost always tragic role in one of the world’s most enduring conflicts.



The next time a Republican politician claims to put principle before partisanship, ask what he or she did when Representative Justin Amash came under attack.

The Michigan Republican, elected in 2010 at the height of the Tea Party wave, has always presented himself as a libertarian-leaning adherent of limited government. And he has always voted exactly as his supporters would expect, as reflected in the 100 percent lifetime score given to him by FreedomWorks.

But over the weekend, he broke with the GOP on the matter of Special Counsel Robert Mueller’s report: After studying the redacted version and related information, he declared his belief that impeaching President Donald Trump is warranted. How would Republicans react to an honest politician staying loyal to the Constitution as he understands it?

Retired Representative Joe Barton passed this test of character. “There’s no member of the Freedom Caucus more intellectually honest than he is,” he told my colleague Elaina Plott. “So my guess is that he agonized over this and felt like he couldn’t, in good conscience, not say something and still be honest to his oath of office.”

House Minority Leader Kevin McCarthy, however, did not pass the test.

“You’ve got to understand Justin Amash,” he told Fox News. “He’s been in Congress quite some time. I think he’s asked one question in all the committees that he’s been in. He votes more with Nancy Pelosi than he ever votes with me. It’s a question whether he’s even in our Republican conference as a whole.”

Those are flagrant lies.

As Jonathan Chait notes, “A very quick YouTube search turns up a number of instances of Amash asking questions in committees: here, here, here, and here.”

Matt Welch, the editor at large of the libertarian magazine Reason, puts the record straight: “He takes his job with a seriousness that has almost vanished from the legislative branch. He holds the modern day congressional record for most consecutive votes not missed, 4,289 over six-plus years, and reportedly wept when he accidentally missed one.”

As for the content of those votes, Amash has been in line with Trump’s position 91 percent of the time in the current Congress and 61 percent of the time overall, according to FiveThirtyEight. He aligns with the American Conservative Union 82 percent of the time.

But McCarthy is hardly alone in publicly disgracing himself to align with Trump on this matter.

As the libertarian Robby Soave writes at Reason, “Amash’s principled stance has already earned him a primary challenger in the form of an unabashedly pro-Trump state representative named Jim Lower, who called Amash ‘out of touch’ with voters. Turning Point USA President Charlie Kirk attacked Amash as well, smearing him as un-American in a bizarre and conspiracy-minded tweet.”

Even the other members of the House Freedom Caucus, the most freedom-loving, freedom-supporting members of Congress, have sided against one of their own to please an erratic big-government authoritarian.

Trump frequently transgresses against the stated principles of most Republican politicians. To stay loyal to him, they must either keep quiet or betray themselves. That so many choose the former is unfortunate, if commonplace. But it is shameful when they react to a colleague who does speak up by savaging him in the press.

Serving Trump is now the GOP’s priority. Principled conservatives should withhold support from the party until he is gone.



The stewards at Churchill Downs were absolutely right to disqualify Maximum Security after the talented colt drifted out at the top of the stretch and nearly wiped out the entire field in the 145th running of the Kentucky Derby. In fact, what’s striking about the reaction to the ruling is that those closest to the sport have been the least surprised by it. There are plenty of things wrong about horse racing in America, but what happened Saturday at the Kentucky Derby isn’t one of them.

It looks like there will be litigation over the result, and that’s a shame. There is no way the courts of Kentucky are going to overturn what the stewards decided on Saturday and what the Kentucky Horse Racing Commission upheld afterward. Horse racing doesn’t work that way. Great deference is given to the decisions made by track officials, and no reasonable person watching the race, and knowing what to watch for, can say the stewards made a call that was arbitrary or capricious or unsupported by evidence. Maximum Security “bore out,” to use a racing phrase (“turned right” is another way to describe it), and impeded at least two horses that had a right to their chosen “lanes” of racing. Come to think of it, an appeal challenging the ruling at the track might have had a better case if stewards hadn’t taken down Maximum Security, given what the colt did.

It doesn’t matter whether Maximum Security was “clearly the best horse in the race,” as so many commentators said in the wake of the disqualification. It doesn’t matter whether the other horses the colt interfered with likely would not have won the race if it had been run cleanly. It doesn’t matter that Maximum Security was the favorite or that Country House was one of the longest of the long shots. “Anything can happen in horse racing” is a bedrock principle of the sport. “That’s why they run the race” is another. An industry that has been besieged by bad publicity lately, much of it justified, did the right thing in this instance. It deserves praise for allowing the officials and regulators on-site to use instant replay to make the right call, even if it was an extraordinarily unpopular call, given the amount of money wagered on the favorite.

Praise today, and gratitude, even though many hard choices await industry leaders. There is pending federal legislation that would take power away from tracks and local regulators and bring it to Washington. There are continuing questions about how to better empower regulators to identify and punish trainers who cheat by giving their horses illegal drugs. There are questions about how to attract younger people to a sport whose heyday came and went generations ago. As a racehorse owner and breeder, I have written at length about many of these issues before and will do so again until meaningful reform comes.
What we shouldn’t do is conflate the sport’s safety problems, which are legitimate and serious, with what happened in the Derby. And yet that is what one reporter after another, and one media organization after another, did over the weekend after the long shot Country House was declared the winner of the big race. “The Kentucky Derby That Veered Off Course” was the headline in The Wall Street Journal, above an article arguing that the disqualification “caused a nightmare scenario that the horse-racing industry couldn’t afford.”

I don’t mean to pick on the Journal. The New York Times did it, too, calling the result “unsettling,” despite the presence of Joe Drape on its staff. There is nothing “unsettling” about getting a call right. Drape knows horse racing like few other reporters at mainstream media outlets, and the poor guy seemed to spend the entire rest of the weekend trying to explain to readers, and his colleagues, what Maximum Security did, why it is considered a foul under the rules of racing, and what stewards were supposed to do about it.

Another example of this unwarranted conflation of the outcome of the race and the sport’s institutional problems came, surprisingly, from Sally Jenkins of The Washington Post. She knows a great deal about horse racing and has an impeccable pedigree in sports journalism, and yet on Sunday she declared: “This entire sport is a foul.” She continued in the same vein:

Where, pray tell, was the discernible lane in all that muck and rain and screaming and flogging and young animal surging? Where is the “lane” in a sport beset by medication overuse and purse structures that incentivize racing horses even when they are hurt, in which the jockeys whip-beat their horses to the finish on a clearly unsafe wet surface the substance of farina?

Imagine what journalists would have written had Maximum Security gone down and taken the rest of the field with him! That didn’t happen. None of the horses in the Derby were injured. For that we should be grateful, not angry. Grateful the way Mark Casse feels this morning. He’s the trainer of War of Will, one of the horses that were bumped by Maximum Security as they turned for home. “If he goes down,” Casse said afterward, “horse racing would have been in the worst shape it’s ever been—ever … The horse-racing world should be happy that War of Will is such an athlete, because not every horse doesn’t go down there.”

The point here is one can be in favor of sweeping reform for the sport and also be impressed with the courage shown by those stewards in their moment of fame. Just imagine the pressure they felt in those frantic moments after the race. The clearest way to know that track officials at Churchill Downs did the right thing, the hard thing, the only thing they could do, given what we all saw with our own eyes? President Donald Trump, who doesn’t know a fetlock from a cannon bone, weighed in on Sunday to blame the altered result on “political correctness.” Not a big fan of the rules, our president is, and a front-runner if there ever was one.



To the six women currently running in the 2020 presidential race, I offer this advice: Study German Chancellor Angela Merkel, the world’s most successful living politician, on the basis of both achievement and longevity. Now in her 14th year as chancellor of Europe’s powerhouse, Merkel has upended the rules of the male-dominated German political culture, and transformed her country along the way.

Without fanfare, Merkel made German society friendlier to the ambitions of women. Merkel’s handpicked successor to lead the Christian Democratic Union is a woman, there are six other women in her cabinet, and women abound in her circle of advisers. Alexander Gauland, the leader of Germany’s far-right political party AfD, recently asked, “Are there no men left in the CDU?” The party still has quite a few men; they just don’t run it any longer.

How did an East German pastor’s daughter scale a mountain of resistance as a triple outsider: a woman, a scientist, and an East German? Not by waiting politely for her turn. Merkel prevailed in a world stacked against her through a combination of persistence, preparation, calculation, and a well-curbed ego. And it’s a model other women—and men—can copy.

If there is a Merkel model, the first requirement for high office is steely calculation, and, when necessary, ruthlessness. Trained as a physicist in the Communist German Democratic Republic, Merkel seized her chance at age 35, when the Berlin Wall came down in 1989. She crossed from East to West Berlin, and began her political ascent.

In the ’90s, Chancellor Helmut Kohl picked Merkel as his minister for women, then minister for the environment. Though her Ph.D. is in quantum chemistry, Merkel applied herself to the study of macho behavior as she inched her way up the German political mountain. When her colleagues dubbed her Kohl’s Madchen—the chancellor’s “little lady”—she smiled, bided her time, and struck when no one expected it. In a high-risk act of political patricide, Merkel published a front-page newspaper article stating that her party was more important than her mentor, the chancellor. She thus brashly rang down the curtain on the Kohl Era, and opened the Age of Merkel. Motivated by both personal ambition and a genuine effort to save the CDU, she succeeded on both fronts.

None of the many strutting demagogues on the world stage—Donald Trump, Vladimir Putin, Recep Tayyip Erdoğan—has managed to shake Merkel’s self-possession. Not even America’s humiliator in chief can shake a woman so well prepared for male antics. “Don’t say I never gave you anything,” Trump said to her, at a G7 conference last summer, tossing Merkel a Starburst he retrieved from his pocket. The sole reaction Merkel allowed herself was a pair of extremely raised eyebrows. When, in 2007, during a meeting at his Black Sea residence, Putin unleashed his black Labrador—knowing she was once bitten and twice shy of dogs—her face was an iron mask. “He needs to do this to prove he’s strong,” she later told her staff. Having grown up under the same totalitarian regime that produced Putin, she is aware of his KGB training. She sees anger as a wasted emotion she simply cannot afford to indulge. For drama, Merkel goes to the opera—which she does a great deal.

Another lesson from the Merkel manual is to out-prepare the man across the negotiating table. She lets men (it’s still usually men) bluster uninterrupted until they run out of steam. When her turn comes, her calm command of facts reduces their grandiloquence to its simplest components. Merkel does not counter bombast with bombast, but with deflation.

Yet another rule in the Merkel playbook is to treat high office as a job, not as an identity. She keeps talking to Putin and to Trump and the others because she sees that as her job. So insults and attacks, however personal and low, are not about her. Sometimes even Merkel has found this a tough rule to follow, as when a German politician called her “an old bird from the East.” “I can’t help where I’m from,” she said, stung by the taunt. But mostly she brushes off such insults. She treats social media’s nastiness as being about her office, not her. Moreover, she has starved the tabloids and the internet of juicy material. She does not tweet. Not a whiff of scandal has touched her two decades in public life. Neither tell-all memoirs nor leaks have seeped from her office.

When Barack Obama visited the chancellor for the last time as president in late 2016, he was startled to see the same faces he first saw eight years earlier running her office. “You guys are still all here!” he exclaimed. Her staff is loyal because she works them no harder than she works herself. “She really thinks twice,” one of her top aides told me, “before she calls us on the weekend.” Merkel devours briefing books, not people.

Merkel clearly enjoys power. Power is a way to get things done: passing minimum wage, closing Germany’s nuclear power plants after the Fukushima explosion, promoting marriage equality, keeping the EU and the U.S. united in sanctioning Russia for invading Crimea, as well as rescuing the euro in 2008. In 2015, in her typically undramatic way, she announced, “Wir schaffen das,” we can handle this, thereby allowing 1 million refugees from the wars of the Middle East a chance to restart their lives in German society. To a remarkable extent, Germany has handled it, though the AfD sits in the Bundestag as a result.

Merkel does not seem to crave the trappings of power. She has no private jets, yachts, or mansions. Her security personnel are instructed to hang way back. (I’ve observed her shop for shoes: the image of a middle-aged lady trying on footwear, betraying not a hint that this is the world’s most powerful woman buying six identical pairs of sensible black flats.) She and her scientist husband live in the same apartment, across from Berlin’s Pergamon Museum, that they’ve lived in for decades. Only his name is on the buzzer. Her modest country house in her native Brandenburg is no paparazzi magnet. And here is another remarkable feat for one of the world’s most famous people: She has ferociously fought for, and has been largely granted, the right to a private life. Her closest staff was not sure where she spent her annual August break last year. (Mostly in her country house.) So, another formula for political longevity: If you are not constantly in the public’s face, chances are people won’t tire of you quite as fast. Even in her own country, Merkel is a figure of some mystery.

Persistence is a key component of the Merkel model. Merkel refuses to give up on even bad actors. She knows when Putin lies to her. He claimed, as his military moved into Crimea, that the “little green men” were not his militia. “We have eyes, Vladimir!” an exasperated Obama exclaimed, and stopped engaging him. Merkel persisted. In a single week in February 2015, Merkel shuttled among nine cities, on two continents, in search of peace.

She’s applied the same approach to Trump. Armed with maps and charts, she patiently explained to the American president how many jobs German car manufacturers create in South Carolina, and why NATO is about shared values, not merely dues paid into an account. In her view, even if only 10 percent of her message gets through, that’s better than giving up on Berlin’s most important relationship, its historic mentor and the midwife of German democracy, the United States.

Sometimes one can only see people clearly in comparison with others. Observing British Prime Minister Theresa May’s hapless cross-Channel scurrying in search of a Brexit deal, I realized that the hyper-cautious Merkel would never have allowed herself to reach such an impasse, seemingly without allies. Equally, when the Polish prime minister canceled an international summit in Jerusalem this February, in retaliation for Israeli Prime Minister Benjamin Netanyahu’s clumsy remark regarding “innate Polish anti-Semitism,” I thought, Merkel would never indulge such public pique. She would have picked up the phone and talked it through with her Israeli counterpart. Netanyahu would then have issued a clarifying statement and the summit would have proceeded. Merkel’s entire record as chancellor illustrates that relations between nations cannot be held hostage to hubris.

Her record as chancellor is not without critics. Henry Kissinger, though her friend, accused her of recklessly endangering Germany by allowing so many refugees to enter, with so little advance planning. Indeed, her heart did seem to hold sway over her head in that instance. The fact that for the first time since the Second World War a far-right extremist party, the AfD, is present in the Bundestag is the direct result of her refugee policy and the populist reaction it provoked. (Some 400,000 of those refugees now have jobs or are in training. The jury, though, is still out on the long-term consequences of her riskiest policy by far.)

But perhaps her greatest deficit is as a communicator. She simply lacks that vital instrument of leadership: the ability to galvanize the people with a stirring message, or to fully explain why she makes certain decisions on their behalf. Angela Merkel has compensated for this lack by winning her people’s trust that she is working soberly and seriously on their behalf. Still, we are in unfamiliar and rough political waters on both sides of the Atlantic now, and it is unclear if her calm and steady-as-she-goes style is long sustainable. In a year or two, Merkel will leave the world stage seething with populist-fanned passions. Nevertheless, Merkel can serve as a model for both women and men in politics. And women, who have too few role models for political success, can look to Angela Merkel for inspiration.



Late Thursday night, The New York Times dropped an astonishing piece of news: President Donald Trump, responding to Iran shooting down an American drone, had ordered strikes against the Islamic Republic—and then decided, with planes in the air, to call them back and pull his punch.

Often, when news organizations deliver this kind of story, the president denies the claim forcefully, usually with accusations of either calumny or treason against the outlet. (He then often slips up and confirms the basic gist of the reporting.) On Friday morning, however, Trump did something different: He gleefully confirmed the story in a series of tweets. After a preamble about how terrible he believes Barack Obama’s deal to freeze Iranian nuclear proliferation was, Trump said:

On Monday they shot down an unmanned drone flying in International Waters. We were cocked & loaded to retaliate last night on 3 different sights when I asked, how many will die. 150 people, sir, was the answer from a General. 10 minutes before the strike I stopped it, not proportionate to shooting down an unmanned drone. I am in no hurry, our Military is rebuilt, new, and ready to go, by far the best in the world. Sanctions are biting & more added last night. Iran can NEVER have Nuclear Weapons, not against the USA, and not against the WORLD!

There’s no shame in calling back the strike. In fact, it’s probably the correct call. One hundred and fifty lives is a hefty price for a single drone, as Trump said. Caution is especially wise given the escalation over recent days in the Persian Gulf, which threatens to turn into outright war. The U.S. can always decide to strike after circumspect consideration, but it can’t undo a strike that has already happened. Trump doesn’t often earn credit for restraint, but he seems to have exercised it here.

Yet the story of how it happened, by Trump’s own account, is chilling. There seem to be three possibilities. One is that Trump was railroaded by advisers who are reportedly far more hawkish on Iran than he is, and only at the last minute realized what was happening, in which case he’s being ill-served by his aides. A second is that Trump was given other, more proportionate options, and estimates of the casualties each would produce, and only stopped to consider these questions as the planes were in the air—not the sign of the sort of careful, measured decision making one wants in national-security decisions.

A third is that Trump knew exactly what he was doing and it was all a big performance. That possibility is perhaps most supported by Trump’s own account and by his past history of using the military as a prop. That’s also what a source told Maggie Haberman:

A source told me 30 minutes ago that Trump was pleased with his own performance last night, loved being in command by ordering the strikes and by then ordering the stand-down. And the president just... tweeted it. https://t.co/tUPSym7inn

In this view, Trump loved the feeling of being at the controls of the war machine—an even more dramatic and exciting experience than sitting in the cab of a Mack truck on the White House grounds and pretending to drive it. Pulling back the strikes wasn’t a sign of shaky resolve—it was a stage-managed turn, allowing Trump to show his power by declining to exercise it, like an ancient king granting clemency only once the condemned was at the gallows. These are the gut-clenching-and-unclenching tactics that Trump learned in television, and he deploys them far more instinctively than he does the military.

Isn’t pulling back a sign of weakness—just the sort of wobbliness on red lines that Obama exhibited? Iran hawks in Washington will say so. But though Trump likes to talk up his strength and toughness, he has repeatedly blinked. He wanted to strike Syrian President Bashar al-Assad, per Bob Woodward, but never said another word after then–Defense Secretary James Mattis effectively suffocated it. Trump once threatened “fire and fury” against North Korea, but that has dissolved into so obliging a stance that he feels compelled to assure Kim Jong Un he’d never cultivate spies in his family. He rattled his saber against Venezuela, but now that the conflict between Nicolás Maduro and Juan Guaidó is in a stalemate, he’s lost interest. Turning back is par for the course, even if he got a lot closer to actual violence with Iran—in accordance with his escalating attempts to maintain control of the public’s attention.

Yet while avoiding a shooting war may be wise, using the military as a prop for melodrama like this is dangerous. As much fun as the adrenaline rush may be for Trump, it’s unfair to military personnel to get them hyped up for battle and then change orders at the last minute—as well as running the risk that it’s too late to pull back, like a game of chicken gone awry. To paraphrase the international-relations theorist Corey Woods, if you start brandishing weapons and making threats, you’re liable to start firing simply to maintain your credibility.

Trump has repeatedly treated the military as a prop, though. A graduate of military school, he avoided the draft for Vietnam with a series of almost certainly spurious deferments for bone spurs. “I always thought I was in the military,” he once told a biographer. “I felt like I was in the military in a true sense. Because I dealt with the people.” He loves to play general, dressing up in bomber jackets and insignia, even though it took him nearly two years to visit troops in a combat zone. He dispatched troops to the southern border in the fall of 2018 even though they couldn’t legally apprehend immigrants—a move that amounted to trying to use the U.S. Army as a political prop against Democrats ahead of the midterm elections. And Trump is planning an elaborate flyover on the National Mall for Independence Day next month.

Trump’s hesitation about striking Iran is prudent, but the way in which he arrived at the decision, and his cavalier toying with the might of the American armed forces, do not instill any faith in his thought process—or give any assurance about what might happen the next time he finds himself in a similar situation.



One must assume that the primary purpose of Special Counsel Robert Mueller’s surprise Wednesday press conference was the clarification of what he considered to be widely held misconceptions about his report. Alas, by the time Mueller had finished speaking, Americans seemed more confused than ever. Now, as before, to ask what Mueller “really meant”—and, indeed, what he “really thinks”—is to receive 100 different answers. The Mueller report, as the cliché goes, has ended up as a Rorschach test.

Americans will hear all sorts of explanations as to why this is. We will be told that it is because we are too “divided,” or because we live in a “post-truth world,” or because Attorney General William Barr is too sneaky. But none of these explanations is correct. The truth is that from the very moment the investigation was announced, it was inevitable that we would end up with a mess. Because, as usual, our political leaders abdicated their constitutional responsibilities and contrived to use the wrong tools for the job.

Having apparently learned nothing from the failure of the now-expired Independent Counsel Act, Washington D.C. settled quickly on the idea that the best way to examine whether the head of the executive branch had done something criminal was to open an investigation within … the executive branch. That this approach was absurd would have been clear in any other circumstance; can we really imagine permitting the subject of, say, a racketeering investigation to control his investigator on the understanding that any improprieties would be evaluated later? For some reason, though, when the president is involved, we tell ourselves that if we just get the right guy, everything will work out.

It didn’t. And it can’t. This is not, I must stress, because Mueller is a bad person. On the contrary: Mueller seems to be a man of integrity. Rather, it is because to ask the executive branch to investigate itself is to make demands of the American constitutional order that the American constitutional order cannot support.

There were only two possible outcomes here. The first of those outcomes was that President Donald Trump left Mueller’s investigation alone completely and did not retain even a cursory oversight role. This, clearly, was an approach that many hoped to see Trump take. I cannot count the number of times I heard it said that Mueller must be permitted to retain his “independence.” But for Trump to have done this would, in effect, to have been to create a de facto fourth branch of government that was ultimately accountable to nobody. The prosecution power is vested in the executive branch. Trump is the head of the executive branch. An investigation conducted without his superintendence would have been, by definition, illegitimate.

The other potential outcome—the one we got—was that Trump maintained the authority over his branch that the Constitution accords him, and was chastised for having done so. One does not need to believe that Trump’s conduct was irreproachable to grasp that the charges of “obstruction” on which we are all now focused were unavoidable by dint of the way the investigation was set up. Criminal obstruction, remember, hinges not on action but intent. Because he is the head of the executive branch, Trump enjoys a wide latitude to direct the Department of Justice. Determining whether he used that power for good or for ill is, ultimately, a matter of judgment—of mind reading, even. There is no detective in the world who can do that job. There is probably no detective who should.

Advocates of the Mueller investigation maintain that, as president, Trump should have behaved in a more sober way, and thereby allayed fears that he was trying to cover something up. And, indeed, as a matter of political propriety, he should have done just that. But as the Founders understood, to predicate your political system on the demand that men with power “should behave better” is to set yourself up for failure. Experience has taught us that kings do not relinquish their authority to please the chattering classes, and that self-interest and ambition cannot be quelled by chastisement or persuasion. Only a rival power center can do that.

I am talking, of course, about Congress, which is supposed to be at the center of our federal politics, but which has in recent years rendered itself depressingly otiose. Congress, lest we forget, is far and away the most powerful of the three federal branches—so powerful, in fact, that it can remove pretty much every single person within the others for reasons of its own invention. Had it done its job and led the investigation into Trump, it would have likely avoided all the intractable problems that the Mueller investigation introduced.

Because Congress is a separate branch, there would have been no conflicts of interest between the investigator and the investigatee­, and, in consequence, there would have been no muddy charges of “obstruction”; either the president would have complied or not. Rather than confusing everyone in an attempt to set up a mythical “fourth branch,” the political lines would have been clear for the public to judge—an important feature in any democratic system. And, perhaps most important of all, there would have been no restrictions on what the investigation could have legally accomplished. Had he so desired, Mueller would have been unable to bring charges without falling afoul of Office of Legal Counsel rules and raising some difficult constitutional questions (can the president arrest himself?). Congress, by contrast, is able to impeach the president for whatever reason it likes, whenever it likes, and without any need for outside permission.

We have just been through a two-year saga in which the executive branch conducted a criminal investigation into whether the executive branch was guilty of criminal conspiracy, and concluded that while there was no evidence that the executive branch was guilty of criminal conspiracy, there was some evidence that the executive branch tried to obstruct the executive branch’s investigation into an offense that didn’t happen—evidence that led a prosecutor whose job is not to pronounce guilt or innocence to publicly announce a verdict of “not exonerated.”

Ensuring that this does not happen again—and make no mistake, we will investigate another president—will be extremely difficult. Members of Congress have become accustomed to taking the back seat, and, because doing so permits them to duck difficult votes, even seem to prefer it that way. Partisanship has rotted away the harsh rivalry between the branches and replaced it with hypocrisy; now oversight is wholly contingent upon which parties run which institutions at any given point. And the public, which is generally ambivalent about politics and politicians, has decided that the only real drama worth watching is that of the White House. But that it will be hard is no reason to shirk the effort to make Congress great again. America’s system works when it is used as designed. The Mueller investigation was an attempt to perform an end run around that system. His team never had a chance. We didn’t either.



When I watched the fire consume the beautiful spire that for so long graced the roof of Notre-Dame de Paris, I was moved by the destruction, but also reminded of another partly destroyed cathedral, in a very different place, that still lies in pieces, forgotten: Notre-Dame de l’Assomption. The vaulting, overweening Haitian cathedral in downtown Port-au-Prince was brought to its knees in the earthquake of January 12, 2010. That huge seismic event killed hundreds of thousands of Haitians and also managed to knock down almost every government building and many of Haiti’s 19th- and early-20th-century Catholic churches, such as the cathedral, sending huge, heavy bells and shards of stained glass down into the city’s broad streets.

Ever since the earthquake, Haitians have imagined rebuilding this central structure of the capital. Some steps were taken early on, but as they say in Haiti: Epi? Epi anyen. “And then? And then, nothing.” Almost a decade later, I wonder whether Haiti really needs to invest in this symbol of a past era.

Unlike the French government, the Haitian government has been entirely absent from the discussion about reconstruction of the national cathedral, for many reasons. First, if someone else can be made responsible for the work and financial outlay on a project, then the Haitian government, which is usually poorer than, say, Bill Gates or Jeff Bezos, is going to let the other group do the job—in this case, the Catholic Church. Also, Haiti, infinitely more than France, has extreme and pressing problems that are far more serious than the rebuilding of some old building. Education, basic nutrition, health care, energy infrastructure, infrastructure tout court, sanitation. And, of course, security, as elections approach and gang violence escalates. Not that the Haitian government is doing anything much about those either.

Haiti doesn’t have a lot of billionaires hanging around, ready to take special charitable tax deductions by giving huge donations to rebuild the church. Nor is the Haitian cathedral a “world” building in the way that Notre-Dame de Paris had become. So when people saw Notre-Dame de l’Assomption in ruins on TV in 2010, they didn’t know what it had been before. As a piece of architecture and a monument, it had no real meaning outside Haiti; very few people outside Haiti felt it was a part of their lives as humans on the planet—unlike the cathedral in Paris, with its 13 million visitors yearly. Rightly, those who saw reports of the Haitian earthquake turned to more human-focused organizations and projects when they decided to make charitable donations.

Soon it will be a decade since the cathedral fell. Haiti’s archbishop at the time of the earthquake said that it might be 20 years or more before Haiti could put together the $30 million to $40 million necessary to rebuild the cathedral, and that he was eager for parishioners to be contributors, as they had been, to a degree, for the initial building of the church in the early days of the 20th century. But to the informed eye, Haitians in general are far more impoverished now than they were then, far more urban, far more dependent on a trickle of the faltering cash economy, so it’s hard to imagine them ponying up a percentage of their nonexistent income to rebuild the church.

Here’s one illustration of Haiti’s poverty: In Port-au-Prince, people eat spaghetti sandwiches, literally, white bread with white spaghetti in it. That’s starvation. These are not heaping, supersize American things on ciabatta with meatballs and gooey cheese and vegetables. They may, however, include ketchup. Haitians live in destitution that no one should experience. Income inequality is visible, public, and shocking. More shocking even than in Los Angeles, where I live, and where the homeless wander the streets and sleep under the freeway overpasses while … you know.

I’ve been reporting on Haiti for more than three decades, and last year the poverty seemed worse than ever, more unforgivable than ever. There are plenty of explanations for this and plenty of stakeholders, local and international, in the impoverishment of Haitians. The earthquake didn’t help, despite the optimistic chorus of outsiders, led by Bill Clinton, spewing verbiage about how Haiti would be built back better. As Graham Greene wrote so astutely in The Comedians, his 1966 novel about Haiti under François Duvalier, “It is astonishing how much money can be made out of the poorest of the poor with a little ingenuity.”

Unlike Notre-Dame de Paris, Notre-Dame de Haiti was not invented or designed by the people for whom it was built. With a small local economy, Haitians themselves rarely could dream of architecture on a grand scale (except for the Citadelle and the Sans-Souci Palace at Milot, both built with foreign help and in the days just after Haitian independence from France in 1804), and the cathedral, meant for worship of the Christian god, was not exactly in the Haitian tradition. So it wasn’t a statement of Haiti’s Haitianness—whatever that may be—as so many have argued Notre-Dame de Paris is of France’s Frenchness.

As a matter of fact, the Haitian cathedral, on which construction began in 1883—only 23 years after the Vatican deigned to recognize Haiti—was more French than Haitian. It was designed by a French architect, André Michel Ménard, who imitated many French cathedrals. The design even included late-Gothic-style rose windows of stained glass (pillaged and destroyed after the earthquake). At the time of its consecration, in 1928, the archbishop of Port-au-Prince was French, as was the rest of the Haitian hierarchy. When work on Ménard’s cathedral was completed, the building was the world’s largest structure made of reinforced concrete. No one knew what would happen to such a structure in the event of a shallow and powerful earthquake. Now we know.

Yet there was, and still is, a connection between the Haitian people and the ruined cathedral. Many Haitians were baptized there, took First Communion there, attended Sunday Mass. In the late 1980s, many parishioners who sympathized with liberation theology used the cathedral as a site for protest and for expression of popular feeling. I remember a group of young people staging a hunger strike on the altar of the cathedral.

In 1987, a hundred of them marched down the central aisle of the nave, lugging a sound system, and seven began a hunger strike. The kids, almost all 17 to 23 years old, had many demands for the Church hierarchy, foremost among them that Father Jean-Bertrand Aristide, who would later become the first freely and fairly elected president of Haiti, be allowed to remain in his parish—despite his continued preaching against the Church hierarchy and on behalf of the Haitian people and their right to a decent life. It was impressive to see a hunger strike in Haiti, where no one who can get food would ever dream of going without it for any reason.

Every day, the crowds of the curious in the cathedral grew larger. In the end, the hierarchy of the Catholic Church of Haiti was forced by this action to accede to the protesters’ demands. In a dramatic moment, the high clergy allowed Aristide, a tiny, bespectacled figure in white robes, rejected and hated by the hierarchy, to come into the vaulted sanctuary to end the hunger strike—to tumultuous applause and cheering from the thousands who packed the nave—and bring his people out of the cathedral, supposedly victorious.

The cathedral was a symbol, then, both of the dominant, French-influenced class and of the possibility for a democratic Haiti. It was also, most directly and obviously, a symbol of the power of the Catholic Church, which has been, since forever, one of the three formal pillars of Haiti’s culture and economy, the others being the government and the army. So, after the earthquake, there was at least a brief window when the Church brooded over how best to rebuild and restore this visible presence in the center of the country.

On Tuesday morning, I spoke to Segundo Cardona, the Puerto Rican architect who won a 2012 design contest for the reconstruction of the cathedral. With the Church supporting it, the competition was put together by Yves Savain, a Haitian American who was a force in Miami’s Little Haiti; the dean of the University of Miami’s School of Architecture; and the archbishop of Haiti, Guire Poulard. The jury included a Haitian architect, the editor of the magazine Faith & Form, a structural engineer, a liturgical consultant and designer from New York State, and Edwidge Danticat, the Haitian American novelist.

“The tragic fire [at Notre-Dame de Paris] brought me a lot of memories about the period in Haiti after the earthquake,” Cardona says. “I was very excited about the cathedral project, because I was very excited about church design and interested in the liturgy and the architectural relationship between the building and the liturgy.” He was eager to begin work, but the archbishop told him to be patient as he tried to promote the project.

In 2014, two years after he won the reconstruction competition, Cardona went to Port-au-Prince for the consecration of a new mini-cathedral, known as the Transitory Cathedral, which had been constructed next to the ruins of the old cathedral so Mass could continue to be said in the years before Notre-Dame’s reconstruction was finished. Cardona made the trip to show the congregation there his beautiful wooden model for the future permanent Notre-Dame. The model was stuck in customs for a while, as weird or valuable items tend to be in Haiti, but at the 11th hour, Cardona managed to get the model into the country and over to the temporary facility.

He felt his heart sink when he saw the neat, cheerful new building, where the Haitian Catholic clergy greeted him. He knew about it beforehand, of course, but it was different to see the church live. The Transitory Cathedral is a steel-frame, open-air space that seats 1,500, and its facade is modeled on a church where Emperor Faustin Soulouque, one of Haiti’s several monarchical leaders, was crowned in 1852.

The trim new church filled Cardona with foreboding. “When I saw this, I feared, and still fear, that the one we designed would never be built,” he said.

When you hear the word transitory or transitional in Haiti, you always have to wonder whether it means “final.” In any case, Guire Poulard, the archbishop who welcomed the idea of Cardona’s design, and Yves Savain, the Miami impresario who organized the competition and was so enthusiastic about reconstruction, are now both dead. Not an inch of ground has been broken, nor another penny spent beyond the $12,000 in prize money for the design contest.

The transitory space is plain and useful, and a breeze can blow through it when it’s hot out, which is most of the time, although in one of Haiti’s dramatic rainstorms or its annual hurricanes, the waters could drench it. For now, as Haiti continues to reel from the effects of an earthquake, hurricanes, and the global economy, a small space such as this one may be more fitting than a grand, soaring monument to the Catholic Church.

But if you know Haiti, you know that almost everyone from the richest person in the elite to the poorest countrywoman would like to be able to pray in a bigger place, sumptuously decorated with statues and symbols, that can accommodate all the Haitians who want to worship at their old site in something that resembles its former splendor. Just because a person is poor or of modest income doesn’t mean she wants to have poor or modest services. You should go to a Vaudou ceremony if you want to see how eager the average person is for costume, color, celebration, variety, liturgy, drama, and majesty.

Outsiders always want to convince Haitians that what Haitians want, architecturally, are modern, low-slung, open-air, eco-friendly, seismically sturdy national buildings made of indigenous Haitian materials. This was part of the gestalt of the international community in Haiti after the earthquake. But very few such buildings got built, in part because they are not, perhaps, to the taste of most Haitians, who might want something more substantial and imposing, and as good as or better than what everyone else has, and nationally important. Cardona’s new version includes seismic resistance and other changes, while keeping the grandeur of the old cathedral alive.

Never forget: first black republic, only successful slave revolution, earliest independence from the colonial power—which was France, by the way, and you could argue that Notre-Dame de Paris was built, at least during part of its years of construction and reconstruction, off the backs of slaves working for French masters. France’s wealth during the 17th and 18th centuries came in large measure from its hugely productive sugar plantations in Saint-Domingue (later Haiti). To say nothing of the approximately $21 billion (in modern dollars) that the newly independent Haiti was later forced to pay France over more than a century to avoid recolonization and pariah trade status. Maybe Haiti’s Notre-Dame de l’Assomption should get, as reparations from France, part of the millions raised for the reconstruction of Notre-Dame de Paris. If Haitians don’t have to pay to rebuild it, using money better spent elsewhere, then the cathedral, as a symbol, is probably worth rebuilding. A new cathedral isn’t all that France owes the Haitians, by any means, but it would be a beginning.



A few years ago, I was invited to my friend’s ordination to the priesthood. I was thrilled for him—a kind, holy man who’s passionate about justice—and honored to be included. But if I’m honest, I also expected to be a bit bored. Ordination liturgies can run several hours, and the rite requires some parts to be repeated for each candidate. With eight men up for ordination, I knew we’d be in it for the long haul. I imagined the experience as something akin to a graduation ceremony, where you root for the person you know and then tune out.

On the day of the liturgy, however, that repetition of the rite moved me deeply. As I watched this line of men I’d never met become priests in the Church I loved, I was struck by the beauty of this brief overlap in our lives, and by the way in which these men represented only a fraction of those ordained that year. We would all go our separate ways, changed by this experience and renewed in our desire to serve. I needed to root not just for my friend but for all of them.

With every new wave of stories of sexual abuse by priests, it can be much harder not to create a spiritual bunker containing the people I like and leaving out the rest. I have felt despair and frustration at the crisis of abuse and the failure of leadership that got us here. The Church needs healing. It needs a new way forward.

But it also needs the priesthood.

In a recent essay in The Atlantic, the author James Carroll imagines the Church without the priesthood as we know it. Some of my friends quickly dismissed the piece as a fruitless thought exercise or an irrelevant rant by an ex-priest. But while Carroll’s wrongheaded plan to rid the Church of most priests is at best overly simplistic and at worst schismatic, it is worth reading for what it reveals about the Church’s current situation.

I know plenty of Catholics who share his underlying anger over the clericalism, abuse, and misogyny present in parts of the Church. I have felt it myself. I talk to lay Catholics who feel unwelcome or unheard at their parish. They fear that priests can no longer be trusted, or that even the good ones have lost their ability to speak with any sort of moral authority. The survivors of sexual abuse have borne the worst of this pain, and the ripple effects of this scandal and cover-up continue to spread.

At its core, the problem that Carroll is grappling with has less to do with the patriarchy or the priesthood than with the unaddressed pain of the faithful. The spiritual effects of despair and disillusionment can cause people to simply shut down, to stop caring, to wash their hands of an institution. And that should worry Catholics. Because the biggest threat to the priesthood is not an internal rebellion against it. It’s that a crucial number of people will one day consider the priesthood irrelevant.

Carroll draws strong ties between clericalism—the privileges that come with the assumption that priests are superior, morally and otherwise—and the abuse of power in the Church. Bureaucratic self-interest, to be sure, is indeed an insidious force in the Church and a major cause of the sexual-abuse crisis. The solution to this, however, is not to dispense with the priests but to more widely disperse the power. Carroll and I likely agree that greater inclusion of women would be a good place to start. And the Church need not wait. Without any change to Catholic teaching, more women could serve as advisers to key Vatican offices, and more stories of women from scripture could be included in the lectionary. It is even canonically possible for laywomen to become cardinals.

A national survey sponsored by America last year showed further opportunities for growth: Six in 10 American Catholic women support the possibility of women deacons. And there is plenty of room for improvement in terms of including women at the parish level. Only 18 percent of Catholic women surveyed felt that their parish “very much” involved women in decision making. But interestingly, when asked if they felt their priest did a good job including women in decision making at the parish, 39 percent said “somewhat,” and 45 percent said “yes, definitely.” The power of personalism, perhaps.

Indeed, greater integration of the lives of the clergy and laypeople may be part of the answer to clericalism. The Church must create more opportunities for bishops, especially, to interact with the people they are meant to serve. Early Church canons frowned upon transferring bishops from location to location, according to the Boston College theologian Richard Gaillardetz. In a recent interview with America’s podcast Deliver Us, he said that as bishops have become more mobile, reassignments to larger dioceses have become nearly synonymous with career promotions.

Similarly, integrating priestly seminary studies with that of lay theology students and hiring lay professors at seminaries can also help keep future priests from becoming insular. “How can you form somebody to serve the people of God,” Gaillardetz asked, “when you systematically separate them from the very people they’re supposed to serve?”

I am a journalist at America, a Jesuit publication about faith and culture. My own workplace, one that integrates laypeople with Jesuit priests and brothers, has both unique benefits and unique challenges. (Pro: Easy to find someone to celebrate my wedding Mass and baptize my kids. Con: Need to be careful about accidentally encountering a coworker in the confessional.) But the challenges are eased, and even made fruitful, by the fact that I can be honest with my co-workers, ordained or otherwise. I harbor no illusions that priests are perfect. (The feeling is mutual.) Our shared mission requires us to explain our lives to one another.

We also have the opportunity to attend Mass weekly in our office chapel. The Mass reminds us that, whatever our differences or difficulties, at the heart of our community is the Eucharist, which inspires, empowers, and humbles us. At the risk of sounding overly pious—but it’s what the Catholic Church teaches, and what I’m afraid I actually believe—it is through the prayers said by our priests that bread and wine become the body and blood of Christ, a source of grace and peace and healing. Which is exactly what the Church needs and what so many people desire. The body of Christ also exists fully and powerfully in the people in the pews. We need both of these experiences of Christ—in the people and in the Sacrament—to move forward meaningfully as a Church.

To do away with either ignores the desires of one of the groups that Carroll posits are most likely to be ostracized by the current Church structures: Catholic women. In America’s survey, we asked women which aspects of the Catholic faith were important to their religious identity. Most women named two things: helping the poor (79 percent said “somewhat” or “very much”) and receiving the Eucharist (69 percent said “somewhat” or “very much”).

Carroll’s plan emphasizes the social-justice efforts that appeal to so many Catholics but neglects the desire of women, and Catholics more generally, to receive the real presence of the Eucharist at Mass. As the Southern Gothic Catholic fiction writer Flannery O’Connor once wrote about the Sacrament, “Well, if it’s a symbol, to hell with it.” Yet our survey showed that only 24 percent of women are going to Mass weekly or more. The structural problems of exclusion and power Carroll describes may be keeping some away. But the answer to exclusion cannot be more exclusion. The answer is to bring the priesthood and the laity closer together, not to abolish the former for the supposed benefit of the latter.

During my friend’s ordination Mass, as I joined the long line to receive the Eucharist, I was reminded of an image once described to me by another Jesuit as a way of understanding the Church. When walking up to Communion, he sometimes imagines the line stretching far in front and far behind, and he thinks of the millions of men and women who have walked this path before and all those who will follow, a chain of sincere, faithful, imperfect people. I felt grateful to be a part of that line of Catholics—ordained and laypeople alike—all walking forward in hope, spurred on by the cloud of witnesses above, rooting for us all.



Ever since Donald Trump made Twitter his preferred medium for communicating with the country, the platform has taken an outsize hold on the American imagination. Once a forum on which users could discuss the day’s news, Twitter now just as often sets the day’s agenda.

Being active on Twitter has practically become part of the job description for some of the most influential people in the country. Any politician, journalist, or CEO who does not engage with social media gives up a precious chance to shape the conversation. And any public or semipublic figure who fails to monitor what is happening on the platform risks missing attacks or accusations that can quickly find their way into the headlines of national newspapers and the chyrons of cable-news shows.

Obligation breeds habit and habit addiction. The most active Twitter users I know check the platform as soon as they wake up to see what they missed. Throughout the day, they seize on the little interstices of time they have available to them—on the way to work, or in between meetings—to follow each new development in that day’s controversies. Even in the evening, when they are settling down to dinner, they cheer attacks against their enemies, or quietly fume over the mean tweet some anonymous user sent their way. Minutes before they finally drift off to sleep, they check their notifications one last time.

It is not the mental health of Twitter addicts that most concerns me, though; it is the well-being of the nation they collectively rule. To decision makers who spend most of their days ensconced in an elite bubble, Twitter can seem like a way out, a clear window into pure public opinion. In reality, it’s an extreme distortion.

Each week seems to throw up another example of organizations capitulating to outrage mobs on social media, whether they originate on the left or the right. In the past year, CNN fired Marc Lamont Hill for controversial remarks about Israel and Disney dismissed (and then rehired) James Gunn over offensive jokes he tweeted a decade ago—in both cases due in part to anger on Twitter.

But while the best-known cases of social media influencing large institutions involve famous celebrities losing their jobs, the sway is just as strong in shaping the implicit assumptions and priorities of the country’s political class. The vast gulf between the great importance pundits ascribed to the Mueller investigation and the apparent disinterest with which most Americans have greeted its findings is Exhibit A.

Judging by the conventional wisdom on Twitter, the publication of the Mueller report should have been the defining event of the Trump presidency. If Mueller found Donald Trump guilty of obstruction of justice, the president’s approval ratings would tank. Conversely, if Mueller exonerated Trump, there would be a broad backlash against Democrats; Trump would then be well on his way to reelection in 2020.

Instead, the most anticipated news event of the year has barely left a trace in public opinion. According to Nate Silver’s FiveThirtyEight, the government shutdown, which affected the lives of millions of Americans, had a clear and immediate impact on Trump’s popularity; the Mueller report did not. In fact, 42 percent of people approved of Trump at the beginning of March, before Mueller delivered his report to Attorney General William Barr, and 42 percent approved of Trump at the beginning of April, after Barr released a summary of the report that seemed to exonerate Trump. Now that much of the report is public, the number stands at, yes, 42 percent.

According to just about every study that has been conducted on the question, Twitter is not representative in the slightest. The Pew Research Center, for example, has found that less than a quarter of Americans log on to Twitter with any regularity. And as The Atlantic’s Alexis Madrigal points out, those regular users differ from the wider population: “In the United States, Twitter users are statistically younger, wealthier, and more politically liberal than the general population.”

Politics Twitter is a bubble in itself. Among the minority of Americans who regularly use Twitter, a majority never tweet about politics. According to a 2016 study, fewer than one in five active Twitter users—which is to say about one in 20 Americans—report posting about politics “some” or “a lot” of the time.

According to a recent analysis by The New York Times, left-leaning Twitter users who regularly post about politics are richer, better educated, and less diverse than the Democratic Party as a whole. In fact, Twitter Democrats are about 50 percent more likely to have a college degree than the average Democratic voter, but only about half as likely to be African American. Among the overall Democratic electorate, less than 50 percent consider themselves liberal, as opposed to moderate or conservative. Among Democrats on Twitter, more than 70 percent do.

One study surveying the evidence for who talks about politics on Twitter, by Pablo Barberá of New York University and Gonzalo Rivero of YouGov, found that “users participating in the political discussion were mostly men, living in urban areas, and with strong ideological preferences.” Another study, by researchers at the University of Pennsylvania and the National University of Singapore, came to an even starker conclusion: “Only self-reported extremists appear to devote much of their Twitter activity to politics.”

Social scientists have known for decades that the most politically active citizens are highly unrepresentative of the population as a whole. On average, citizens are more politically engaged the more affluent, educated, and powerful they are. “The heavenly chorus” of those who write letters to their local newspaper, attend PTA meetings, or ring up their senator, the political scientist Elmer Eric Schattschneider once wrote, “sings with a strong upper-class accent.”

For that reason, key social and political institutions are always in danger of being captured by their loudest and most resourceful constituents. Small but highly ideological factions have repeatedly taken over political parties. On college campuses, radical students have had a greater influence than their more moderate classmates.

Even so, the outsize influence that small, unrepresentative groups now exert via Twitter is a particular source of concern. Until the advent of social media, decision makers were only confronted with their angriest detractors on specific occasions—at town halls, say, or on the Letters page in newspapers—for which they could mentally brace themselves. And when they faced the local teachers’ union or chamber of commerce, they were well aware that it represented a particular slice of their electorate.

Twitter is different in two key ways. Because it allows anybody to speak up, leaders of political and cultural institutions seem prone to believe that the views they encounter there are representative of the “general public.” And because so many influential people check their Twitter notifications dozens of times a day, the opinions they see there become the constant soundtrack of their life. When deciding what to think or how to act, leaders may find it harder to tune out angry professions of outrage on Twitter than the “heavenly chorus” of yore.

“When you’re on Twitter, every controversy feels like it’s at the same level of importance,” one influential Democratic strategist told me. Over time, he found it more and more difficult to tune Twitter out: “People whose perception of reality is shaped by Twitter live in a different world and a different country than those off Twitter.” (I granted the strategist anonymity in exchange for candor.)

If elected representatives treat Twitter as representative of public opinion, they will fail to be responsive to the actual views of their constituents; political journalists will obsess over scandals and debates that don’t interest most of their readers; and political campaigns may lose eminently winnable elections.

President Trump is a case in point. He has rightly intuited that a significant portion of the American population is anxious about the influx of immigrants in the country illegally. But egged on by his die-hard fans—who ensure that his tweets about immigration are especially popular, with many of them attracting more than 100,000 likes—he has embraced policies, such as separating children from their parents, that are rejected by a vast majority of Americans.

Trump’s likely Democratic opponents fare no better. They are right about the fact that most Americans would like a strong public option for their health insurance. But, encouraged by activists on Twitter, some have brushed away concerns about what Medicare for All would mean for existing insurance plans—even though polls suggest that a clear majority of Americans do not want to lose what they already have.

To win the White House in 2020, presidential candidates will need to both win over swing voters whose views diverge from those of their party’s base and mobilize like-minded supporters who rarely think (much less opine) about politics. Paying less attention to Twitter may be the key to both.

America’s political class now lives in a bubble that has been made more, rather than less, impenetrable by the technological changes of the past years. Instead of connecting America’s elites to ordinary people, Twitter has amplified the beliefs of a small band of hyper-political partisans.

The solution to this problem is a lot more straightforward and achievable than much of the hand-wringing commentary about social media would suggest: It is for political leaders—and everyone else—to keep Twitter in perspective. What’s dangerous to democracy is not the existence of a forum in which extremists can talk to, and shout at, one another—it’s the possibility that decision makers will confuse the forum for the real world, and in so doing allow extremists to shape real-world culture.

A few months ago, I started to notice just how bad an influence Twitter was having on my grasp on reality, my productivity, and my serenity. For a brief period, I considered quitting Twitter. But that didn’t seem like the right solution. For one, I like sharing my work and my views with my followers. For another, I doubted my resolve: Over the past years, I’ve seen too many writers make grandiose announcements about quitting Twitter—only to rejoin the platform a few weeks, or days, after their departure.

Instead, I opted for a more modest solution: While I still access Twitter from my desktop from time to time, I have deleted the app from my phone, and stopped it from sending any notifications to my email account. It’s faintly ridiculous just how much my quality of life has improved as a result. I now know much less about the latest controversy—but have much more time to read that book I’ve been meaning to turn to for ages. I miss out on a few good jokes or interesting links—but have started to detox from the feverish anger that reigns supreme on the hyper-political corners of the Twitterverse.

The Democratic strategist who described Twitter as a “different world” recently quit the service. And he feels the same way as I do: “Instead of retweeting pundits, I’ve started watching candidates doing speeches and town halls. It’s made me a better political strategist—not to mention a better friend, a better boyfriend, and a better human being.”

If the most influential people in the country would follow his lead, we might just wind up with a better country.



The highest priority for Democrats in 2020 is a challenger who can beat President Donald Trump. Many believe that Joe Biden is the candidate best able to do it.

They may be right.

Biden has excellent name recognition rooted in his association with a popular two-term president. And no one doubts that he has the experience to do the job. Then again, skeptics retort, the former vice president doesn’t energize democratic socialists, woke identitarians, or pundits in the liberal media. “Recent presidential elections have taught the two major parties not to settle for someone who seems electable and unthreatening to swing voters,” Michael Brendan Dougherty argues at National Review, “but to go with the candidate who excites them in the hope that excitement itself will be contagious.”

My colleague Peter Beinart has articulated a third position: that focusing on electability is folly because it is impossible to know who is most likely to win a general election. I certainly wouldn’t bet on which Democrat would most handily beat an as-yet-unknown Republican. But evaluating relative electability is a bit easier when the opponent is known. Pollsters can put the question to voters directly. And it’s possible to assess how rivals match up on specific issues.

In 2016, Hillary Clinton matched up relatively poorly against Donald Trump, which is to say that she was ill-positioned to counter some of his most glaring weaknesses as a candidate. Her support for disastrous wars in Iraq and Libya made it hard for her to exploit Trump’s lack of foreign-policy experience, for example. And a better-matched opponent could have capitalized more on Trump’s corruption in business, while Clinton was hamstrung by evidence that she was a self-dealing insider beset by ethically dubious conflicts of interest. She’d even given secret, lavishly compensated speeches to Wall Street bankers. And she couldn’t press Trump on his poor treatment of women as effectively as someone unconstrained by her husband’s history of bad behavior.  

I wrote at the time, “The Democratic nominee’s shortcomings should not blind voters to the catastrophe they’d invite by electing her cruel, undisciplined, erratic opponent.” Nevertheless, she wasn’t able to attack Trump on the aforementioned subjects as effectively as could Senator Bernie Sanders.

Biden would have some similar problems. He, too, voted in favor of the Iraq War, putting him in a weaker place than other candidates on foreign policy. As a senator representing Delaware, he fed his campaign coffers with money from credit-card companies, sold a house to a credit-card-industry executive for a suspiciously inflated sum, and had a son working in the industry as he championed a law that made it harder to discharge credit-card debt in bankruptcy.

Now it appears his vice presidency involved a similar conflict of interest.

“One of his most memorable performances came on a trip to Kiev in March 2016, when he threatened to withhold $1 billion in United States loan guarantees if Ukraine’s leaders did not dismiss the country’s top prosecutor,” The New York Times reports. “Among those who had a stake in the outcome was Hunter Biden, Mr. Biden’s younger son, who at the time was on the board of an energy company owned by a Ukrainian oligarch who had been in the sights of the fired prosecutor general.” Is he the best candidate to press Trump on the relationship between his presidency, his kids, and profiting from foreign governments?

He is not.

And while Biden treats women orders of magnitude better than does Trump, this is an era of collapsing distinctions, so Biden would likely be a less effective critic of the president than some rivals due to his role in the Anita Hill hearings and complaints that he makes some women uncomfortable when he hugs them.

Of course, there are also ways in which Biden matches up better than other candidates––for example, he polls better than most of his rivals among voters overall in a head-to-head matchup with Trump, he seems more likely than most to win over the sorts of white working-class voters Trump needs to win, and he performs extremely well among people of color, a group Democrats must win.

Given the priorities of Democratic voters, the electability question isn’t going anywhere. Orienting that conversation around polls and analysis of how different candidates compare with Trump on likely campaign issues is one way to ground analysis in something more than intuition, even if certainty will remain elusive.



Although Special Counsel Robert Mueller’s Russia probe is over, and although President Trump on Friday again described the probe as a “Witch Hunt,” the FBI is almost certain to continue its counterintelligence investigation into Russian espionage efforts related to the 2016 election. More important, they will continue to search for Americans working on behalf of the Kremlin.

The inability to establish that the Trump campaign conspired in a “tacit or express” agreement with the Russian government is not surprising. Most espionage investigations come up empty unless and until they get a lucky break. That does not mean there was no espionage activity in relation to the 2016 election. Every previous Russian political-warfare campaign was built on human spies. Russian “active measures”—propaganda, information warfare, cyberattacks, disinformation, use of forgeries, spreading conspiracies and rumors, funding extremist groups and deception operations—rely on human actors to support and inform their success. Counterintelligence professionals must doubt that Russia could have pulled off its election-interference effort without the support of spies burrowed into U.S. society or institutions.

Indeed, troubling patterns, unanswered questions, and tantalizing leads suggest that Russia relied on human sources to interfere in the 2016 election. Both the Mueller report and Intelligence Community assessments have identified a variety of Russian actors involved in the attack. They uncovered the activities of the Russian GRU, cyberhackers, and the Russian troll factory. However, one key player is missing: Russia’s premier espionage service, the SVR. Is it possible that the Russian espionage service played no role in Russia’s operation, and had no spies helping support what the Mueller report characterized as a “sweeping and systematic” attack of American institutions? The FBI would be professionally negligent if it assumed so.

Consequently, there is still much to uncover—and America’s intelligence services will work to uncover it. For example, how did the Kremlin know where to aim its disinformation effort? How did it know which communities to target, in which counties and states? One can argue that the Russians had a better sense of where to deploy their resources than did the Clinton campaign. Why did Trump and those around him consistently parrot Russian talking points? Why was the campaign so intent on disregarding expert advice on Russian issues? The Mueller report notes that while investigators couldn’t prove a conspiracy, some people nonetheless displayed conspiratorial behavior (destroying communications, engaging in a cover-up, and obstructing the work of investigators). The FBI, which has the benefit of secret intelligence, is certainly aware that it has only scratched the surface of Russian activities in 2016. Cyberhacks, troll farms, and the use of WikiLeaks are hardly cutting-edge espionage tradecraft. The Russian efforts that have been revealed to date were poorly hidden and displayed little professional elegance. Counterintelligence agencies must find it hard to believe the cupboard is already bare.

As Mueller pointed out, the Russians had a dedicated and extensive program to damage the U.S. polity. They sent numerous representatives to contact willing Trump representatives, looking for potential sources, access points to influence policy, and means to disseminate Russian talking points. Russian intelligence officers, like their American counterparts, would seek to establish as many contacts as possible and push as far as the market would bear in order to develop new sources. In the CIA, where I worked for 28 years, we used the analogy of a traffic light. A field officer pursuing a potential source would press forward slowly, assessing the target’s reaction to increasingly provocative and conspiratorial requests. As long as we received a “green light” in response, we would push the relationship further in the direction of our goal. If we hit a “yellow light,” we would reassess and try a different tack. We would stop only when we hit a firm “red light.” From the Mueller report, we now know that those around Trump were consistently flashing green.

A number of commentators have focused on the bumbling nature of those in and around the Trump campaign, concluding that their ignorance and naïveté militate against their ability to engage in a conspiracy. This is a misunderstanding of how the espionage game works. Intelligence services recruit plenty of gullible people. The responsibility for recruiting, training, exploiting, and protecting a clandestine operation lies on the side of the professional intelligence service: The spy service must translate the target’s potential willingness into a productive and secure relationship; the professional intelligence officer must slowly manipulate the relationship in an increasingly conspiratorial and secret direction, then help rationalize it for the target. The Cold War was littered with Kremlin spies the West failed to uncover in a timely manner because Western agents assumed they were too obvious, absurd, drunk, dim-witted, or low-level. Naive and ignorant people can get in too deep when manipulated by professionals.

Effective counterespionage is difficult and often unsatisfying, and takes time. Investigators are trying to uncover what a professional intelligence service is hiding, and success usually requires our own sources deep inside the enemy camp. As the saying goes, “It takes a mole to catch a mole.” Rarely can investigators and specialists develop enough evidence to uncover and indict spies without leads from overseas intelligence collectors, as the “evidence” is locked away in the files of the SVR. Unlike criminal investigations that close down when they are unable to prove that a crime has been committed, counterintelligence investigations can continue for years.

Likewise, counterintelligence professionals know that criminal prosecution is rarely the best tool for neutralizing the enemy. Even when investigators and intelligence officers are confident they’ve uncovered a spy, it is not a given that the person will be prosecuted. Hundreds of Americans spied for the Soviet Union during World War II and the Cold War, and only a small handful were ever brought to trial. The government’s methods of uncovering spies and its need to protect its sources limit its ability to produce convictions.

To some, it may seem unfair that investigators would not drop their efforts even after Mueller concluded that he could not “establish that the Trump campaign coordinated with the Russian government in its election interference.” Trump clearly thinks he’s been vindicated; he spoke to Russian President Vladimir Putin on Friday and said on Twitter that they discussed the “Russia Hoax” in their “long and very good conversation.”

Nevertheless, counterintelligence professionals realize they don’t have the whole story and will continue to work behind the scenes, slowly uncovering the activity of hostile intelligence services. From experience, they understand that failure to prove Russian espionage does not mean it didn’t happen. While the notion of “innocent until proven guilty” is something Americans take as solemn truth, to the Russian intelligence services it is just another vulnerability worth exploiting.



Over the course of a decade beginning in the mid-1980s, Donald Trump publicly presented himself as a highly successful entrepreneur even as he claimed business losses exceeding $1 billion, The New York Times reported on Tuesday. “Over all,” the newspaper explained, “Mr. Trump lost so much money that he was able to avoid paying income taxes for eight of the 10 years.”

The scoop reflects poorly on Trump, who willfully misled the public for a decade in hopes of fraudulently representing himself as a man with a Midas touch. But he could not have succeeded without the assistance of many Americans, some mercenary, others over-credulous, who helped to spread the deceit and deception, generating countless newspaper articles, magazine stories, and TV segments that misinformed the public about the publicity hound’s record in business.

New evidence of his staggering losses in that decade therefore provides an apt occasion to reflect on the media’s complicity in Trump’s brazen deceit and deception.

Tony Schwartz, the ghostwriter who penned The Art of the Deal, has already apologized for falsely portraying the huckster from Queens as “a charmingly brash entrepreneur with an unfailing knack for business,” telling The New Yorker, “I put lipstick on a pig. I feel a deep sense of remorse that I contributed to presenting Trump in a way that brought him wider attention and made him more appealing than he is.”

But Schwartz was far from alone in abetting Trump’s lies. Indeed, the television producer Mark Burnett could not have “resurrected Donald Trump as an icon of American success” with The Apprentice in the Aughts if not for portrayals of Trump as a thriving tycoon in an era when he was hemorrhaging money.

Here’s a Newsweek cover from 1987:

And a Time cover from 1989:

Neither cover image suggests a man who inherited a fortune from his father only to suffer 10-figure losses during a stretch when he passed himself off as a rainmaker. 

Back in 2011, Elspeth Reeve flagged other bygone estimates of Trump’s net worth:

In the worst cases, media outlets credulously accepted Trump’s claims. He was almost invariably covered as if he was much richer than the most careful estimates available at the time suggested.

He was rarely covered as if he were one of the biggest business failures in America, even in the era when, per the IRS data just reported by The New York Times, “year after year, Mr. Trump appears to have lost more money than nearly any other individual American taxpayer,” and Trump’s “core business losses in 1990 and 1991—more than $250 million each year—were more than double those of the nearest taxpayers in the I.R.S. information for those years.”

And no matter how many times he’d been caught being dishonest before, many treated his subsequent claims with the same presumption of legitimacy normally extended to people without a long track record of self-serving mendacity. Archives of media organizations contain countless examples.

To end their grifter-enabling complicity, America’s media institutions should now set the record straight: Each TV station, newspaper, and magazine that broadcast or published ’80s and ’90s coverage of Trump that misled its audience as to his wealth or success should revisit its claims in light of the new information unearthed by The New York Times, publishing updates and corrections. It won’t be easy at these resource-starved institutions, but they owe it to their readers.

And Random House, which published The Art of the Deal, should put out a statement clarifying that the purported author was no great deal maker at the time.

That is how institutions make themselves accountable for spreading untruths, a discipline that can’t help but influence today’s writers and editors to be more careful. Almost no one at the time could’ve anticipated how much misleading claims about Trump, of all people, would matter to the future of the world.

But it all mattered.

Let that be a lesson for today’s tabloids, gossip columnists, over-credulous or mercenary journalists, and reality-television producers. It might be tempting to salve your conscience as Tucker Carlson told GQ: “There’s this illusion … that everything is meaningful, everything important,” he said. “It’s not.” A more honorable approach, conveyed with nuance in the novel Cloud Atlas, by David Mitchell, can be distilled as follows: Strive to act as though everything matters––one never knows what will turn out to be world-changing.

For the public at large, Trump’s old tax returns are a reminder, at least for those of a certain age, of how effectively the man’s lies distorted our image of him and the degree of success that he was ostensibly enjoying in the late ’80s and early ’90s.

In truth, he was secretly flailing, piling up debt at properties that he later left bankrupt. Now he brags that he’s doing a bang-up job running America. Don’t get fooled again.



“There’s a fundamental principle of law that derives from Sherlock Holmes,” Justice Samuel Alito mused from the bench last November, “which is the dog that didn’t bark.”

Alito was referring to “The Adventure of Silver Blaze,” in which a watchdog at a stable did not bark at an intruder because, as Holmes deduced, “the midnight visitor was someone whom the dog knew well.” There are, however, other reasons that a watchdog might not bark. The dog might be asleep, or well fed and torpid, or muzzled. Or perhaps the dog might have muzzled itself.

Self-muzzling seems to be what the Supreme Court has done so far this term in the contentious area of abortion, now boiling over in the states. In February, the Court granted a temporary stay of a Louisiana abortion law that would have put five of the state’s six abortion providers out of business. But Chief Justice John Roberts, who cast the deciding vote, gave no hint of how he would vote on the law when the Court gave the case full consideration. And on Tuesday, the Court dodged the validity of an Indiana statute that required abortion clinics to dispose of an aborted fetus in much the same manner as the body of a dead person, and, second, required doctors to tell women seeking abortion that state law forbade choosing abortion “solely because of the fetus’s race, color, national origin, ancestry, sex, or diagnosis or potential diagnosis of the fetus having Down syndrome or any other disability.”

In a remarkable feat of procedural legerdemain, the Court made the issues disappear. It decided that the “fetal remains” provision could take effect because the court below had used the wrong standard to decide the issue, and continued an injunction on the “non-discrimination” law—while claiming to express no view on its validity.

The law at issue in Box v. Planned Parenthood of Indiana and Kentucky was passed in 2016 and signed by then-Governor Mike Pence, who said at the time that it would “ensure the dignified final treatment of the unborn and prohibit[] abortions that are based only on the unborn child’s sex, race, color, national origin, ancestry or disability, including Down syndrome.” Soon after, a panel of the Seventh Circuit struck down both provisions. The “non-discrimination” provision, it reasoned, contravenes 1992’s Planned Parenthood v. Casey, which held that state laws may not impose an “undue burden” on a woman’s choice. The Casey Court explained that, under that standard, abortion before viability is the pregnant woman’s decision alone; the state does not get to evaluate her reasons.

“The [non-discrimination] provisions prohibit abortions prior to viability if the abortion is sought for a particular purpose,” the Seventh Circuit panel majority wrote. Thus, they “are far greater than a substantial obstacle; they are absolute prohibitions on abortions prior to viability which the Supreme Court has clearly held cannot be imposed by the State.”

As for the “fetal remains” provision, the panel majority said, there was no need to apply the Casey standard, because the law was irrational. Until its passage, abortion clinics had been allowed to incinerate fetal remains along with other human tissue, such as organs removed during surgery. Under the new law, fetal remains, unlike cadavers, could receive “simultaneous cremation” rather than individual disposal—but they could not be removed from the facility without a “permit for the transportation and disposition of a dead human body.” The woman who obtained the abortion could also take the remains herself and dispose of them as she chose.

Indiana argued that the “fetal remains” provision embodied the state’s “moral and scientific judgment that a fetus is a human being.” But since Roe v. Wade, the panel majority noted, Supreme Court precedent has held that states cannot impose this doctrine of “fetal personhood” on women seeking abortion. “Simply put, the law does not recognize that an aborted fetus is a person,” the panel wrote.

Indiana petitioned the Supreme Court for review, arguing that:

The fetal disposition provision expands on long-established legal and cultural traditions of recognizing the dignity and humanity of the fetus. The non-discrimination provision, on the other hand, is a qualitatively new type of abortion statute that responds to new technological developments allowing women to make a choice not contemplated at the time of Roe v. Wade: the choice of which child to bear.

On Tuesday, the Court—for now — reversed the “fetal remains” decision, allowing that part of the law to take effect. A 1983 Supreme Court case had said that states do have a “legitimate interest” in “dignified disposal of human remains.” Thus, the Court reasoned, the finding of irrationality was an error. The Court implied that the “fetal remains” provision should in fact have been judged under the Casey standard.

Instead of saying anything of substance, the majority said it would wait for cases under way in other circuits that do seek to apply that standard: “Our opinion expresses no view on those challenges.” The Court also said it would not decide the “discrimination” issue, since “only the Seventh Circuit has thus far addressed this kind of law,” and the justices wanted to hear from other circuits before wading in. The opinion “expresse[d] no view on the merits” of this issue either.

In theory, the “undue burden” standard should be harder, not easier, for a “fetal remains” law to pass than the “rational basis” standard (which in essence asks only, “Is this law crazy?”). But in the past three years, the very meaning of “undue burden,” never crystalline in the first place, has become blurred beyond recognition, and no one knows what the post-Kennedy Court will do with it. Thus, as draconian abortion bans hurtle toward its inbox, the Court has managed to deal with this earlier contentious case by not really dealing with it at all.

Justice Clarence Thomas, by contrast, is always eager to share his opinion. His separate opinion is remarkably broad: It suggests that states should be able to ban—and indeed should ban—not only abortion but birth control as well.

The reason, Thomas argues, is that both birth control and abortion were embraced in the early 20th century by the eugenics movement. The most extreme form of this movement believed that government policy should be aimed at ensuring that the fittest human stock reproduced itself, while the unfit—those with congenital medical conditions, or the unintelligent, “feeble-minded,” and insane—should be put on the road to extinction by birth control, abortion, or sterilization. Some parts of the movement were solidly racist, and indeed provided inspiration for the genocidal ideology of National Socialism in Germany.

Margaret Sanger, a pioneer of birth control and a founder of Planned Parenthood, was, Thomas argued, not only a eugenicist, but a racist who aimed at limiting or even eliminating the African American population. The claim stems in part from a 1939 letter in which Sanger wrote that birth-control advocates should reach out to black ministers to explain the goals of the movement: “We do not want word to go out that we want to exterminate the Negro population, and the minister is the man who can straighten out that idea if it ever occurs to any of their more rebellious members.”

Sanger’s words, in context, seem to me pretty clearly to indicate that she was afraid that black Americans would wrongly come to believe that birth control was a white plot. Nonetheless, the pro-genocide reading has already been embraced by Secretary of Housing and Urban Development Ben Carson and the former presidential candidate Herman Cain. With Thomas’s embrace, it has now achieved a trifecta among the far-right wing of African American conservatism.

Citing Sanger in the abortion context is odd, however: Sanger was, in fact, never in favor of legal abortion; even Thomas admits, more or less under his breath, that she vocally opposed “the horrors of abortion and infanticide.” Thus, though Thomas does not say so, the genocide-related arguments he is making must apply with at least equal force to birth control itself. Thomas seems to be hinting that, once abortion is outlawed, the movement will have another objective—ending birth control as well.

Remarkably, in the 20 pages of Thomas’s opinion, not one word or phrase ever describes the choice of abortion as a decision made by a woman for reasons of her own. “There are,” he reports, “areas of New York city in which black children are more likely to be aborted than they are to be born alive—and up to eight times more likely to be aborted than white children in the same area. Whatever the reason for these disparities, they suggest that, insofar as abortion is viewed as a method of ‘family planning,’ black people do indeed ‘tak[e] the brunt of the ‘planning.’” If black women are choosing to abort, in other words, they could not be making this most personal of decisions independently; sinister unseen forces must be imposing it on them.

If there is any comfort in this decision for advocates of reproductive rights, it is that not even Thomas’s ideological soul mate, Justice Neil Gorsuch, was willing to join such a flamboyant opinion. That’s not much, but it’s all I can see. Overall, the Court is playing its abortion cards very close to the vest. If it is going to continue to be a watchdog of abortion rights, it seems likely to be a very quiet one indeed.



District of Columbia v. Heller, which recognized an individual right to possess a firearm under the Constitution, is unquestionably the most clearly incorrect decision that the Supreme Court announced during my tenure on the bench.

The text of the Second Amendment unambiguously explains its purpose: “A well regulated militia, being necessary to the security of a free State, the right of the people to keep and bear Arms, shall not be infringed.” When it was adopted, the country was concerned that the power of Congress to disarm the state militias and create a national standing army posed an intolerable threat to the sovereignty of the several states.

Throughout most of American history there was no federal objection to laws regulating the civilian use of firearms. When I joined the Supreme Court in 1975, both state and federal judges accepted the Court’s unanimous decision in United States v. Miller as having established that the Second Amendment’s protection of the right to bear arms was possessed only by members of the militia and applied only to weapons used by the militia. In that case, the Court upheld the indictment of a man who possessed a short-barreled shotgun, writing, “In the absence of any evidence that the possession or use of a ‘shotgun having a barrel of less than eighteen inches in length’ has some reasonable relationship to the preservation or efficiency of a well regulated militia, we cannot say that the Second Amendment guarantees the right to keep and bear such an instrument.”

Colonial history contains many examples of firearm regulations in urban areas that imposed obstacles to their use for protection of the home. Boston, Philadelphia, and New York—the three largest cities in America at that time—all imposed restrictions on the firing of guns in the city limits. Boston enacted a law in 1746 prohibiting the “discharge” of any gun or pistol that was later revived in 1778; Philadelphia prohibited firing a gun or setting off fireworks without a governor’s special license; and New York banned the firing of guns for three days surrounding New Year’s Day. Those and other cities also regulated the storage of gunpowder. Boston’s gunpowder law imposed a 10-pound fine on any person who took any loaded firearm into any dwelling house or barn within the town. Most, if not all, of those regulations would violate the Second Amendment as it was construed in the 5–4 decision that Justice Antonin Scalia announced in Heller on June 26, 2008.

Until Heller, the invalidity of Second Amendment–based objections to firearms regulations had been uncontroversial. The first two federal laws directly restricting the civilian use and possession of firearms—the 1927 act prohibiting mail delivery of handguns and the 1934 act prohibiting the possession of sawed-off shotguns and machine guns—were enacted over minor Second Amendment objections that were dismissed by the vast majority of legislators participating in the debates. After reviewing many of the same sources that are discussed at greater length by Scalia in his majority opinion in Heller, the Miller Court unanimously concluded that the Second Amendment did not apply to the possession of a firearm that did not have “some relationship to the preservation or efficiency of a well regulated militia.” And in 1980, in a footnote to an opinion upholding a conviction for receipt of a firearm, the Court effectively affirmed Miller, writing: “[T]he Second Amendment guarantees no right to keep and bear a firearm that does not have ‘some reasonable relationship to the preservation or efficiency of a well regulated militia.’”

So well settled was the issue that, speaking on the PBS NewsHour in 1991, the retired Chief Justice Warren Burger described the National Rifle Association’s lobbying in support of an expansive interpretation of the Second Amendment in these terms: “One of the greatest pieces of fraud, I repeat the word fraud, on the American public by special-interest groups that I have ever seen in my lifetime.”

Even if the lobbyists who oppose gun-control regulation actually do endorse the dubious proposition that the Second Amendment was intended to limit the federal power to regulate the civilian use of handguns—that Burger incorrectly accused them of “fraud”—I find it incredible that policy makers in a democratic society have failed to impose more effective regulations on the ownership and use of firearms than they have.

And even if there were some merit to the legal arguments advanced in the Heller case, all could foresee the negative consequences of the decision, which should have provided my colleagues with the justification needed to apply stare decisis to Miller. At a minimum, it should have given them greater pause before announcing such a radical change in the law that would greatly tie the hands of state and national lawmakers endeavoring to find solutions to the gun problem in America. Their twin failure—first, the misreading of the intended meaning of the Second Amendment, and second, the failure to respect settled precedent—represents the worst self-inflicted wound in the Court’s history.

It also represents my greatest disappointment as a member of the Court. After the oral argument and despite the narrow vote at our conference about the case, I continued to think it possible to persuade either Justice Anthony Kennedy or Justice Clarence Thomas to change his vote. During the drafting process, I had frequent conversations with Kennedy, as well as occasional discussions with Thomas, about historical issues, because I thought each of them had an open mind about the case. In those discussions—particularly those with Kennedy—I now realize that I failed to emphasize sufficiently the human aspects of the issue as providing unanswerable support for the stare decisis argument for affirmance. After all, Kennedy had been one of the three decisive votes that had saved Roe v. Wade from being overruled in Planned Parenthood v. Casey.

Before the argument, I had decided that stare decisis provided a correct and sufficient basis for upholding the challenged gun regulation, but I nonetheless asked my especially competent law clerk, Kate Shaw, to make a thorough study of the merits of the argument that an independent review of the historical materials would lead to the same result. I wanted that specific study to help me decide which argument to feature in my dissent, which I planned to complete and circulate before Scalia completed his opinion for the majority. Shaw convinced me that Miller had been correctly decided; accordingly, I decided to feature both arguments in my dissent, which we were able to circulate on April 28, 2008, five weeks before Scalia circulated the majority opinion on June 2, 2008. In the cover memorandum for my probable dissent, I wrote:

The enclosed memorandum explains the basis for my firm belief that the Second Amendment does not impose any limit whatsoever on the power of the federal government to regulate the non-military use or possession of firearms. I have decided to take the unusual step of circulating the initial draft of a probable dissent before [Scalia] circulates his majority because I fear the members of the majority have not yet adequately considered the unusual importance of their decision.

While I think a fair reading of history provides overwhelming support for Warren Burger’s view of the merits, even if we assume that the present majority is correct, I submit that they have not given adequate consideration to the certain impact of their proposed decision on this Court’s role in preserving the rule of law. We have profound differences over our role in areas of the law such as the Eighth Amendment and substantive due process, but I believe we all agree that there are areas of policy-making in which judges have a special obligation to let the democratic process run the show …

What has happened that could possibly justify such a massive change in the law? The text of the amendment has not changed. The history leading up to the adoption of the amendment has not changed … There has been a change in the views of some law professors, but I assume there are also some professors out there who think Congress does not have the authority to authorize a national bank, or to regulate small firms engaged in the production of goods for sale in other states, or to enact a graduated income tax. In my judgment, none of the arguments advanced by respondents or their numerous amici justify judicial entry into a quintessential area of policy-making in which there is no special need or justification for judicial supervision.

This is not a case in which either side of the policy debate can be characterized as an “insular minority” in need of special protection from the judiciary. On the contrary, there is a special risk that the action of the judiciary will be perceived as the product of policy arguments advanced by an unusually powerful political force. Because there is still time to avoid a serious and totally unnecessary self-inflicted wound, I urge each of the members of the majority to give careful consideration to the impact of this decision on the future of this institution when weighing the strength of the arguments I have set forth in what I hope will not be a dissent.

In the end, of course, beating Scalia to the punch did not change the result, but I do think it forced him to significantly revise his opinion to respond to the points I raised in my dissent. And although I failed to persuade Kennedy to change his vote, I think our talks may have contributed to his insisting on some important changes before signing on to the Court’s opinion.

That’s cold comfort. I have written in other contexts that an amendment to the Constitution to overrule Heller is desperately needed to prevent tragedies such as the massacre of 20 grammar-school children at Sandy Hook Elementary School on December 14, 2012, from ever happening again. But such tragedies have indeed happened again. In the course of writing the chapter of my memoir that discusses Heller, on October 1, 2017, a gunman fired from the 32nd floor of a hotel in Las Vegas, killing at least 58 people and injuring more than 500 more who were attending an outdoor concert. I had not yet finished the chapter when another mass shooting occurred, this one involving the death of 26 people—including three generations of a single family—at a church on November 5, 2017, in Sutherland Springs, Texas. More shootings have happened since.



Because of sex. Over the past 55 years, that single three-letter word has had momentous legal and social consequences for American life that the man who inserted it into the 1964 Civil Rights Act on a wintry Saturday morning could never have imagined. And now that the Supreme Court has agreed to decide whether that landmark law forbids employment discrimination based on sexual orientation and gender identity, the adaptive power and enduring meaning of that plain little word is about to be tested once more.

On February 8, 1964, as the House of Representatives debated passage of the bill, Howard Smith, an ardent segregationist from Virginia, rose to propose changes to four pages of Title VII, the section of the bill barring hiring and firing “because of” race, creed, religion, or color. “After the word religion, insert sex,” Smith drawled, urging his colleagues to rectify “this grave injustice … particularly in an election year.”

The result was two hours of pandemonium on the House floor, because Smith’s amendment was seen by the frantic pro–civil-rights forces as a poison pill that might put the whole bill at risk—a bill that would end Jim Crow segregation in public accommodations, help ensure voting rights for long-disenfranchised populations, and just more or less win the Civil War, only a hundred years too late. It’s a story I recounted in my book An Idea Whose Time Has Come. Hard as it may be to fathom a half century later, the notion that women deserved protection from discrimination in employment was as controversial in some quarters as the idea that racial minorities did—and, even to some liberal Democrats, much more laughable.

The Democratic chairman of the House Judiciary Committee, an inveterate male chauvinist from Brooklyn named Emanuel Celler, was livid, warning that the language was “illogical, ill-timed, and improper,” that it would be an “entering wedge” to a constitutional Equal Rights Amendment (an idea he detested), and that it would lead, as indeed it eventually did, to the overturning of state laws aimed at protecting women with special, and lighter, working conditions and hours. (In fact, such an outcome would have pleased Howard Smith, because Virginia’s textile industry depended on cheap female labor). So worried were the bill’s supporters that Edith Green, an Oregon Democrat who nearly a decade earlier had proposed a bill to require that men and women be paid equally for equal work, now stood to read a letter from the American Association of University Women opposing the Smith amendment, and adding her own view, said, “I do not believe this is the time or the place.”

But soon a bipartisan coalition of five women took up the fight in support of Smith’s proposal. Katharine St. George, a New York Republican, was biting. “I can think of nothing more logical than this amendment at this point,” she told her male colleagues. “We outlast you. We outlive you, we nag you to death …We are entitled to this little crumb of equality. The addition of the little, terrifying word s-e-x will not hurt this legislation in any way.” In the end, the House agreed, and the measure passed, 168–133, with mostly southern and Republican support, as it happened. As the final tally was announced, one woman in the gallery shouted, “We’ve won! We’ve won!” while another cried out, “We made it! God bless America!” before male doorkeepers escorted them from the room. The Senate and House gave final passage to the whole bill that summer.

Would Hubert Humphrey, Everett Dirksen, Mike Mansfield, and the other legislative lions who shepherded the 1964 Civil Rights Act ever have imagined that the law might one day be invoked to safeguard the rights of LGBTQ people, a then-unheard-of abbreviation that they might have taken for a mashed-up mix of New York subway lines? Probably not. But neither would plenty of those legislators have imagined—or been pleased—that a law that most of them saw as a color-blind expression of faith in the American creed eventually led to color-conscious remedies such as affirmative action in education and hiring. As William McCulloch of Ohio, the bill’s staunchest GOP supporter in the House, told Smith at one point in the debate, quoting the poet James Russell Lowell, a founder of this magazine:

                   New occasions teach new duties;

                   Time makes ancient good uncouth;

                   They must upward still, and onward,

                   who would keep abreast of Truth.

When Title VII was passed, just two states in the union—Hawaii and Wisconsin—had laws prohibiting sex discrimination in employment. Today, 21 states expressly prohibit discrimination against gay, lesbian, and transgender employees in the workplace, and this week, lawyers for the American Civil Liberties Union told the Los Angeles Times that most Americans assume the federal government already does too.

The language of any law has transmutative consequences that its most ardent advocates—and its most determined foes—might never envision. After the passage of the 1964 act, lawyers at the newly created Equal Employment Opportunity Commission were flummoxed by the wave of gender-discrimination complaints that they received. Members of its staff wondered what to do with these complaints, and how many resources it should devote to them, one of them told me, when everyone understood that the real point of the law was ending racial discrimination. It turns out that the real impact of the law was to address both, as a pioneering young lawyer named Ruth Bader Ginsburg would soon prove in court again and again.

Heaven only knows what the current Supreme Court will make of the cases it agreed to hear next term. In one of them, involving a gay skydiving instructor in New York who was fired after casually mentioning his sexual orientation, a lower court found that the dismissal violated Title VII’s prohibition on discrimination “because of” sex. A Michigan court reached a similar finding in the case of a transgender woman who was dismissed from her job at a funeral home after she announced her intention to transition from the male identity she had at birth. In a third case, in Georgia, a child-welfare worker who said he was gay was fired because of his orientation, and an appeals court in Atlanta ruled against him in a brief, unsigned opinion, citing a 1979 decision that had held that “discharge for homosexuality is not prohibited by Title VII.”

But gay-rights advocates have at least some reason for hope in precedent, and in the words of one of the Supreme Court’s most conservative modern-era members, Antonin Scalia, who wrote the majority opinion in a 1998 case involving a claim of sexual harassment by a male oil-platform worker who contended that other men on the rig had harassed him: “Male-on-male sexual harassment was assuredly not the principal evil Congress was concerned with. But statutory prohibitions often go beyond the principal evil to cover reasonably comparable evils, and it is ultimately the provisions of our laws rather than the principal concerns of our legislators by which we are governed.”

The legislative climate that produced the 1964 Civil Rights Act is as distant from our own day as candlelight and clipper ships. The final bill passed the Senate 73–27, with 27 Republican votes. But the debate over its passage was every bit as bitter and divisive as any contemporary argument. At the height of his fight against it, Howard Smith complained that the bill was “as full of booby traps as a dog is of fleas.” How fitting, then, that all these years later, Smith’s own little flea-bitten booby trap might just yet again produce a once-unanticipated but salutary result.



I often think of Edmund Morris, the master biographer who died this weekend at the age of 78, as the man whom Ronald Reagan, the subject of his most famous biography, drove crazy.

Reagan drove a lot of people crazy. Anyone who spent time in the faculty lounges and graduate seminars of the 1980s, as I did, can tell you all about it. You had to see it to believe it, the intensity of it, especially now that Reagan has been declawed into the kindly, unexpectedly shrewd, avuncular master of misdirection that we know from pop biographies and second-rate TV documentaries. Back then, though, the mere mention of his name could send professional eggheads, especially the ideological kind, into a scarlet fury. The dunce! Ignoramus! He’s gonna get us all killed! 

The fury was unique for its time, but I suppose we’ve all gotten used to it, after the revulsion most Republicans felt toward Barack Obama, and the revulsion everyone else felt toward Donald Trump.

Reagan didn’t drive Morris crazy in that way, even metaphorically. Before and after his years with Reagan, Morris remained soft-spoken, cerebral, amused—only mildly eccentric. And unlike the Reagan-era eggheads, or the Obama- and Trump-haters of our own day, he didn’t have an ideological bone in his body.

He was more an artist than a historian or biographer. If you can get your hand on it, take a half hour to read the first chapter of the first volume of his biography of Theodore (never Teddy) Roosevelt, in which Morris follows the new president as he makes his rounds on Inauguration Day. There, as in all his work, he gives you sights and sounds, the glow of lamplight and the clop of horses in the street, and even, in a great feat of literary imagination, the rhythm of the thoughts that pulse through the heads of his subjects. In his Reagan biography, Morris’s descriptions of the settings of Reagan’s life—from the Illinois prairie of his boyhood, woebegone and terrifying, to the crisp, carpeted, air-cooled efficiency of the White House West Wing in the 1980s—are precise, accurate, and full of meaning. They are nearly perfect.

What Morris the biographer never gave you was politics, or ideas. This is strange, to put it mildly, in a writer who became famous as a biographer of politicians. T. S. Eliot wrote of Henry James, “He had a mind so fine no idea could violate it.” Eliot meant it as a compliment. Morris, to a lesser degree, deserves the same praise. Ideas, especially political ideas, are usually blunt and cumbersome things, large and crude enough to be expressed in quick strokes and grasped by masses of people, and they preoccupy those of us whose intellectual taste seldom runs to the delicate and subtle. Morris’s taste tended in the other direction, and so did his powers of observation. He watched or imagined the interplay between souls, the effect of power on personality, the subterranean drives of emotion and belief.

His account of Roosevelt’s reaction to the death of his first wife, for example, is at once clinically detached and deeply felt, and no biographer I know of could have recreated those moments with such sensitivity. Politics, though, is another matter. In the same volume, Morris has a rounded account of the political career of Roosevelt’s rival William Jennings Bryan, and somehow scarcely mentions the debate over free silver, the issue that defined Bryan’s career. This is the difference between the historian and the artist: The historian will sit still for monetary policy.

Reagan, his wife, and his advisers were so impressed with The Rise of Theodore Roosevelt that they didn’t notice this defect—if that’s what it was—in the biographer. They were in the market for a reputable historian to write a semi-authorized biography of the sitting president. They weren’t having much luck, given that so many “reputable” historians (see above) weren’t cut out for the job. All they knew was that Morris had written admiringly of a Republican, and they’d heard rumors that the historian himself had Republican leanings. A Republican with a Pulitzer Prize! When Morris, after some back-and-forth, agreed to tail Reagan around through his second term and use the material to shape a biography as he saw fit, the Reaganites were rather proud of their catch.

The result, Dutch: A Memoir of Reagan, is a famous, a legendary, an epochal disaster. This should have been entirely predictable. No one, before Morris or after, had ever been able to penetrate Reagan’s lacquered shell of geniality. Beyond his wife, he had no intimates. Those who worked most closely with him resorted to oxymoron when describing him. Reagan, said James Baker, was “the kindest and most impersonal man” he’d ever met. Another subordinate who idolized him, Martin Anderson, called him a “warmly ruthless man.”

“People who had worked for him much of their lives,” wrote his most dutiful biographer, Lou Cannon, “suspected that there was something beneath the surface they had never seen, but they did not know what the something was.”

Morris took it on himself to find the something—it was, he felt, his duty as a biographer and (though he wouldn’t have said it aloud) an artist. After all, the only journalist who could be said to have gotten close to Reagan—through his wife, Nancy—was George Will, who had said, “On the first nine levels, Reagan is the least interesting of men. But if you postulate a tenth level, then he’s suddenly fascinating.”

Ready to be fascinated, Morris took advantage of unprecedented access to his subject. He sat as a fly on the wall during momentous White House meetings, taking notes with his Montblanc in a tiny, elegant script, and interviewed his subject for hundreds of hours as the second half of the Reagan tenure unfolded—a more consequential four years than the presidency had seen in a generation. Everyone he wanted to talk to, talked to him.

And he came up … empty. Well, not empty. Dutch is full of beautiful writing and insight about nearly everything Reagan encountered in a long and eventful life. (Reagan was 75 when Morris, then in his mid-forties, began to tag along.) But about the man himself—the lacquer never cracked, the Reagan twinkle never dimmed to reveal what, if anything, was behind it. Reagan, Morris said years later, “is the strangest man who ever lived.”

From a biographer, from an artist, this is a cry of the heart. It means: I give up! I can’t figure him out! There was no tenth level. Reagan was a purely political creature, all the way down, and to his biographer, with no ear for politics and in search of depths to plumb, he remained incomprehensible to the end.

As a way around the wall he’d been butting his head against, Morris invented a now notorious literary device. Note the word memoir in the subtitle. Instead of postulating that tenth level, he imagined himself, Edmund Morris, as a contemporary of Reagan’s, and wove himself in and out of his account of Reagan’s life, from small-town Illinois to Hollywood to the West Wing. In flashbacks, it transpires that Reagan, as a young lifeguard, had once saved young Edmund from drowning. That heroic act then becomes a metaphor for Reagan’s rescuing of the West from the swirling eddies of Communism in the Cold War.

The metaphor is strained enough. Morris never publicly worried that his fictional passages—he even invented footnotes for them!—rendered the rest of his work worthless as serious biography. The reputable historians were outraged over the squandering of priceless access and resources, and Reagan’s legions of fans seethed over what they saw as an exercise in triviality. These never bothered him either, at least not publicly. The artist won out over the biographer.

Morris entrusted a mutual friend with the privilege of reading the manuscript of Dutch as he finished it, chapter by chapter. As the final crazy pages unspooled from his fax machine late one night, my friend later told me, “I realized it had to be one of two things. Either Edmund had reached new heights of literary genius, or Reagan had driven him nuts.”

Both things could be true, of course. In the years after Dutch, Morris continued to produce work of high literary and historical merit, including dozens of essays, the final two volumes of his biography of Roosevelt, and a book-length appreciation of Beethoven. A biography of Thomas Edison, the obituaries tell us, is due this fall. The insanity was only temporary.



Mohamed Morsi’s life, especially his later life, was the product of a series of accidents. When I first met him, he was a senior but relatively obscure and not particularly important official in the Muslim Brotherhood—and one could easily imagine him staying that way. He was a loyalist, a functionary, and an enforcer. Then he became something else: Egypt’s first democratically elected president—and also the last, at least for the foreseeable future. Visionary leaders sometimes emerge during moments of crisis and transition. But just as often, ordinary men and women find themselves in the midst of historical events, both shaping them and being shaped by them.  

Morsi, who died in a Cairo courtroom Monday, was elected in 2012 and deposed in a military coup a year later. He was many, but not all, of the things his critics derided him for. He wasn’t what you would call charismatic. He was not a strategic thinker. He seemed a man particularly unsuited for the responsibility bestowed upon him. In retrospect, knowing what they know now, many in the Brotherhood—in prison, in exile, in hiding—would wish that the organization’s leadership had never opted to field a presidential candidate. But this had little to do with Morsi. Morsi wasn’t meant to be president.

The Brotherhood’s original candidate for president was the businessman Khairat al-Shater, towering in his physical presence, preternaturally confident, and perhaps overwhelmed by ambition. Some called him Egypt’s most powerful man. He was disqualified from running based on a legal technicality. Like so many other things, this, for the group, seemed to confirm that the military sought to block the Brotherhood’s rise by any means necessary. And so Morsi, derided in the Egyptian media as Shater’s “spare tire,” became the accidental candidate and then the accidental president.  

When I sat down with Morsi back in May 2010, the longtime dictator Hosni Mubarak was still in office, and the kind of uprising that could force him out seemed implausible. At that point, Morsi insisted the Brotherhood had no interest in power and even objected to the use of the word opposition to describe the group. Repression was intensifying, and political space was closing years after the brief promise of the (first) Arab Spring in 2004 and 2005. The November 2010 parliamentary elections were arguably the most fraudulent in the country’s history, reducing the Brotherhood from 88 seats to 0. Members of the Muslim Brotherhood seemed deflated but not necessarily in despair. They were playing the long game, which is what the Brotherhood always preferred to play. To be tempted by power, on the other hand, led them, and ultimately Morsi himself, into a series of missteps and miscalculations.

The campaign for president in the spring of 2012 took place in a chaotic, uncertain Egypt. Though burdened by a weak candidate, and with only two months to campaign, Brotherhood activists fanned across the country, promoting Morsi’s so-called renaissance project (which had been Shater’s “renaissance project”). In one coordinated show of strength, they held 24 simultaneous mass rallies across the country in a single day. At one rally, I asked a young Brotherhood activist if he was enthusiastic about Morsi. He smiled and then laughed.

It was easy to dismiss Morsi then, and it will be easy to dismiss him now, as a footnote in history. Buried without fanfare and under the glare of a near-totalitarian state—the most repressive in Egypt’s history—he will be easy to forget. But the brief 12 months in which he found himself in power was an unusual time for Egypt. Morsi was incompetent and polarizing, and managed to alienate nearly everyone outside the Brotherhood. Ultimately, he and the Muslim Brotherhood failed. But he was not a fascist or a new pharaoh, as his opponents liked to claim. In a previous piece for The Atlantic, a colleague and I scored Morsi’s one year in power using the Polity IV index, one of the most widely used empirical measures of autocracy and democracy, and then compared it to other cases. We concluded that “decades of transitions show that Morsi, while inept and majoritarian, was no more autocratic than a typical transitional leader and was more democratic than other leaders during societal transitions.”

But to keep the focus narrowly on Morsi, as a person or as a president, is to miss something important, and that something has become clearer to me in the five years since we wrote that piece. That year may have witnessed unprecedented polarization, fear, and uncertainty, but for that time Egypt was the freest, in relative terms, that it had been since its independence in 1952. Egyptians were shouting, protesting, striking, and hoping, both for and against Morsi. This, of course, is also what made the year frightening: the freewheeling intellectual combat, the seemingly endless sparring of ideas and individuals, but also the sheer sense of openness (and the insecurity that came with it). No other period, or even year, comes close. This was not because of Morsi, but because Egypt—with the help of millions of Egyptians—was trying to become a democracy, albeit a flawed one. And Morsi himself, also deeply flawed, was a product of that brief experiment. To remember Morsi, then, is to remember what was lost.



After the defeat of Nazi Germany, the U.S. occupation authorities carried out a series of public-opinion surveys in the American occupation zone.

One question asked whether Nazism was “a bad idea, or a good idea badly carried out.” In his history of postwar Germany, Frederick Taylor writes: “The view that Nazism had been simply and unequivocally a ‘bad idea’ was never held by more than 40 percent of respondents, and by the end of the third post-war winter that number had declined to 30 percent with double that number—60 percent—now insisting that Nazism had been a ‘good idea’ gone wrong.”

Milton Mayer, a German-speaking American journalist, lived for the year 1952 in a small town in the state of Hesse. Mayer befriended and interviewed 10 men who had taken part in the burning of the town’s synagogue. With one sole exception, he found them not only unrepentant, but strongly convinced of their own victimhood. “The other nine, decent, hard-working, ordinarily intelligent and honest men, did not know before 1933 that Nazism was evil. They did not know between 1933 and 1945 that it was evil. And they do not know it now. None of them ever knew, or now knows, Nazism as we knew and know it; and they lived under it, served it, and, indeed, made it.” And even that one exception only partially rejected Nazism. He “still believes, in part of its program and practice, ‘the democratic part.’”

This month, a united democratic Germany marks the 70th anniversary of its constitution: the Grundgesetz, or Basic Law. The lengthy document—one version of the English text runs 135 printed pages—was composed under Allied supervision in 1948 and 1949. The final text was completed May 8, 1949; approved by the British, French, and U.S. occupying authorities on May 12, 1949; and entered into effect May 23, 1949. Its first article begins, “Human dignity shall be inviolable. To respect and protect it shall be the duty of all state authority.”

In 1949, it must have seemed highly uncertain whether the new German state could possibly honor those words. Impoverished and dismembered, its cities crowded with refugees driven from their homes, its standing in the world disgraced by aggression and genocide—Germany’s most likely fate seemed rapid descent into state failure. Milton Mayer observed the unanimous conviction of his German interlocutors that never again in their lives would they live as securely and comfortably as they had under Nazi rule before the start of war in 1939.

And yet, the state flourished and the constitution endured. Over the next 70 years, Germany honored its pledge to human dignity. It atoned for its crimes, found peace with its neighbors, recovered the eastern states from communism, and consolidated an advanced liberal democracy. Germany is hardly problem-free on this milestone anniversary. Yet the once-rickety Bundesrepublik has met the test of time and success. The constitution—originally viewed as only a provisional document—has become the foundation of a united German state. How was this accomplished?

It would seem an important question. The success of the German democratic transition could offer insights to others overcoming dark chapters in their past. Yet the topic is strangely under-discussed.

Instead, scholars of Germany produce and consume a large and accumulating body of literature concerning fault and failure. The hypocrisies and limits of postwar de-Nazification are minutely examined. And it’s true: For decades after 1945, ex-Nazis held dominant roles in German medicine, law, and academia; the civil service; and even the military. (Erich von Manstein, who planned the attack through the Ardennes that smashed the French army in 1940, helped organize the new West German army after serving only four years of his 18-year sentence for war crimes in the Eastern Front.)

The culture and society of postwar Germany stand under perpetual accusation. Left-wing artists and intellectuals have arraigned the materialism, conservatism, and conformism of postwar Germany as a continuation of the kitschy culture of Nazism. Conservatives riposte by indicting the violence, anti-Semitism, and contempt for institutions of the German Far Left as a continuation of the anti-democratic ideology of Nazism. (German leftists marked the anniversary of Kristallnacht in 1969 with an attempted bombing of the rebuilt Jewish Community Center in West Berlin. German left-wing terrorists were among the hijackers of the airliner rescued by Israeli special forces at Entebbe, Uganda, in 1976.)

Problems, always problems! Germany is like a patient who has recovered from a terrible disease, and ever after monitors himself for a recurrence of the symptoms. And indeed, the symptoms are there: neo-Nazi crimes against immigrants; immigrant crimes against German Jews; far-right parties gaining seats in state legislatures; the post-communists cannibalizing the democratic left—all there, all true.

But all this occurs against the background of the amazing success of German democracy since 1949, a story so big that it can be hard to see except at a distance.

The development of German constitutionalism seems especially glacial. Americans accustomed to looking to courts to propound grand declarations about law and rights will be disappointed by the caution of German jurists. In its first important case involving the rights of dissent, in 1957, the highest German court ruled for the government and against a person who had been denied a passport for political reasons. In the 1950s, the high court upheld the criminalization of homosexuality; in the 1970s, the high court prevented the decriminalization of abortion. There was no German Justice William O. Douglas ready to convert the grand language of article 1 of the German constitution into a wide charter of judicial power.

And yet the rights of political dissenters, homosexuals, and women were protected, and strongly too. German society led the courts rather than the other way around, as so often in the United States. The constitutional idea drew its power from the complex workings of the German federal system, from the give-and-take of German parliamentary life, from a media culture that did champion dissenters and minorities, and from a public opinion that since 1949 has grown ever more self-confident and tolerant.

It’s a sobering mirror image for Americans, who have arguably over-relied on judicial guardianship even as their local government has become less democratic, their political culture more polarized, their media system more reactionary and extreme, and their public opinion more authoritarian.  

Much of the success of Germany’s democratic development depended on unique circumstances of time and place. “Economic miracles” like that which buoyed German democracy from 1950 to 1970 don’t come along every day. (If they did, we wouldn’t call them miracles.) The Cold War incubated German democracy, too. Democracy gained West Germany entry into NATO in 1955; democracy drew a sharp distinction between the freedom of western Germany and the police state in the Soviet-controlled eastern zone.

Yet there are nonunique lessons too—lessons applicable to less-extreme democratic transitions.

In his superb history of the postwar aftermath in the two divided Germanies, Jeffrey Herf attributes this insight to Konrad Adenauer, West Germany’s first chancellor: You could have democracy in post-Nazi Germany or justice in post-Nazi Germany, but not both.

So many people were implicated in Nazi crimes that comprehensive justice could never command democratic assent. The price of democratic assent was to pretend that the crimes were the work of a tiny minority, of which the majority had no idea. “Democracy had to be built on a shaky foundation of justice delayed—hence denied …” The historian Joachim Fest quoted his own father’s answer to questions about Nazi crimes: “I did not want to talk about it then and I don’t want to talk about it now.”

Yet it was not only guilt that was suppressed. It was equally impolitic to discuss German suffering during the war and aftermath. In a 1999 book, W. G. Sebald remarks upon the silence adopted by the postwar generation about the ruin of their country in 1945—not only the smashing of German cities by Allied bombing, but the expulsion of German populations from ancient homes, the mass rape of German women by Soviet soldiers: “There was a tacit agreement, equally binding on everyone, that the true state of material and moral ruin in which the country found itself was not to be described. The darkest aspects of the final act of destruction, as experienced by the great majority of the German population, remained under a kind of taboo like a shameful family secret …”

This approach seemed a profoundly corrupt bargain to many who watched it in the making. In a famous essay from 1959, the philosopher Theodor Adorno bitterly complained, “The murdered are to be cheated out of the single remaining thing that our powerlessness can offer them: remembrance.” In that same essay, Adorno wondered how committed, really, the Germans were to democracy.

Political democracy certainly is accepted in Germany in the form of what in America is called a working proposition, something that has functioned well up until now and has permitted and even promoted prosperity. But democracy has not become naturalized to the point where people truly experience it as their own and see themselves as subjects of the political process. Democracy is perceived as one system among others, as though one could choose from a menu between communism, democracy, fascism, and monarchy: but democracy is not identified with the people themselves as the expression of their political maturity. It is appraised according to its success or setbacks …

But the successes kept coming. In Exorcising Hitler, Frederick Taylor vividly describes the two decades after the war as a “sleep cure.” And when the sleeper at last awoke, jolted by the social and political convulsions of the middle 1960s, it turned out that German democracy had somehow steadied its foundations after all. After 20 years of conservative governments, the elections of 1969 at last alternated power, electing the first Social Democratic chancellor since the Weimar Republic. Justice was never fully done, but memory returned—and returned with ever more onrushing intensity.

There was no one moment of redemption, but a steady process of acknowledgment. At the commemoration of the 40th anniversary of the end of the Second World War in Europe, West German President Richard von Weizsäcker spoke of “the attempt by too many people, including those of my generation, who were young and were not involved in planning the events and carrying them out, not to take note of what was happening. There were many ways of not burdening one’s conscience, of shunning responsibility, looking away, keeping mum. When the unspeakable truth of the Holocaust then became known at the end of the war, all too many of us claimed that they had not known anything about it or even suspected anything.”

Those powerful words emerged with special force because von Weizsäcker’s father had loyally served the Hitler regime as an important diplomat—and been convicted by a Nuremberg tribunal of war crimes. The future president of a united Germany, a six-year combat veteran of the Wehrmacht, served as part of his father’s legal defense team.

“All of us, whether guilty or not,” continued von Weizsäcker’s 40th-anniversary address, “whether old or young, must accept the past. We are all affected by its consequences and liable for it. The young and old generations must and can help each other to understand why it is vital to keep alive the memories.”

Four years later, the Berlin Wall cracked open. The East German state had systematically disclaimed responsibility for Nazi crimes. In 1964, a New York Times correspondent reported with amazement:

One of the remarkable discoveries on a journey through East Germany is that virtually no one holds himself accountable in any way for the Germany of the past—or even related to it … Everything that went wrong in prewar Germany is explained as the consequence of capitalism and thus as something that could never recur in this half of the country. The injustices of Stalinist times a decade ago and more recent totalitarian acts are depicted as wholly unrelated excesses peculiar to the early years of a Communist society.

Purified by communism, the East German authorities could, guilt-free, espouse paranoid anti-Semitism, spy on their citizens, even order their soldiers to goose-step on parade.

After the state was reunited in 1990, it committed itself even more aggressively than the old West Germany to building national identity upon memory. A monument to the murdered Jews of Europe occupies the center of rebuilt Berlin. Hobble stones force their attention on pedestrians at places of memory.

But eastern Germans do not always appreciate the history lessons, especially given that they have had to rethink their past without any rerun of the economic miracle in the west a generation before.

Quite the contrary: Unification brought the West German state its very own Rust Belt, and all the troubles that attend upon post-industrialization. To gain consent from its neighbors for unification, Germany pledged itself to even tighter European integration, including a single European currency—and all the troubles that followed from that for less-competitive regions in Europe, which include the German east as well as the Mediterranean south.

Political management has become only more challenging since Angela Merkel’s 2015 decision to open Germany’s borders to 1.2 million refugees from all over the world.

Problems—more problems!

Yet here it is, the 70th anniversary of the German state, and for all those problems, the promise of article 1 of the German constitution has indeed been honored. Adenauer’s gamble—democracy first, justice later—has been vindicated. And those of us in other democracies are maybe called upon to search our own consciences.

What is our plan to rehabilitate our societies from their recent turn to authoritarianism and kleptocracy? How do we memorialize the wrongs done by our societies? How much justice can our democracies withstand?

After 70 years of self-examination, modern Germany has some lessons to teach and some wisdom to impart from its own hard experience to those perhaps excessively proud of their own imperfect past and deteriorating present.



It would have been easy to miss the stories late last week, what with a trade war in progress, a hot war with Iran threatened, and the president accusing his critics of treason.

But on Thursday, a report from the Government Accountability Office concluded that Ben Carson, the secretary of housing and urban development, broke the law in lavishly refurnishing his office. The same day, the inspector general of the Environmental Protection Agency said that former Administrator Scott Pruitt wasted nearly $124,000 of taxpayer money on excessive travel, including first-class airline tickets.

For the first year and a half of his administration, the petty corruption of Donald Trump’s aides was a leading story. During the spring and summer of 2018, there seemed to be nearly daily revelations about abuses at one department or another, from tony travel to soundproof booths. Then the issue sank from the headlines, for a variety of reasons. There were bigger stories, especially as Special Counsel Robert Mueller’s probe began producing more indictments. Pruitt was finally forced to resign, which seemed to tie a bow on the corruption thread. Besides, a certain numbness sets in after so many cases of wasted money.

But it would be a mistake to believe the problem has gone away, or that it’s safe to ignore. Pruitt is gone from the government and on to an inevitable career in lobbying, it’s true. So is Ryan Zinke, the former secretary of the interior, who was embroiled in several scandals. They were preceded out the door by Tom Price, the secretary of health and human services. Price’s relatively quick and contrite resignation from office in his own excessive-expenses scandal now seems like a quaint throwback to an earlier era, when shame applied to Cabinet members. If he’d only understood how much the ground had shifted, he might have resolved to just stay in the job and weather the storm.

That’s what Carson did. In spring 2018, it emerged that Carson had spent about $45,000 refitting his office at HUD, including four grand for new blinds, more than $8,000 for a dishwasher, and nearly $32,000 for a dining-room table. In March 2018, Congress asked the GAO to investigate the spending. The good news for Carson: The blinds were okay. The bad news: The table and dishwasher broke the law.

Such behavior might be forgivable in the case of a hardworking public servant who begged pardon. But Carson is a multimillionaire in his own right, who infamously (if with laudable self-awareness) declared himself unqualified for his post, and who blamed his wife when the spending was revealed. Carson remains in the Cabinet. Now that the federal government’s internal watchdog has concluded he broke the law, will that change? It’s unlikely. HUD seldom captures the attention of the public overall, and Trump has made clear he has little interest in it except as a forum to enact his unrelated policy priorities.

Moreover, Trump has little interest in policing this sort of bad behavior among his aides. Historically, scandalous spending of taxpayer dollars was a one-way ticket out of government. Price, a veteran elected official, was acting on this understanding when he resigned. But Pruitt’s demise came only after the drumbeat apparently became such a distraction and nuisance that Trump became unwilling to deal with it any longer. It took nearly a year.

Still in the Cabinet along with Carson is Commerce Secretary Wilbur Ross. In February, the Office of Government Ethics refused to certify Ross’s financial disclosure—a highly unusual step—because he hadn’t sold a stock that he claimed he had. Ross insisted the error was inadvertent. This would be more plausible if OGE hadn’t already had to warn Ross about inaccuracies in his disclosures, and if he hadn’t been caught lying to the press about his finances as well.

These are the most egregious cases. There’s also Interior Secretary David Bernhardt, who became the subject of an inspector general’s investigation into multiple allegations of ethics violations less than a week after being confirmed. Labor Secretary Alexander Acosta remains under scrutiny for signing off on what appears to have been a sweetheart deal with child-sex offender Jeffrey Epstein while Acosta was a U.S. attorney. Veterans Affairs Secretary Robert Wilkie did not disclose appearances to pro-Confederate groups during his confirmation process. There are reportedly Justice Department and inspector-general investigations into Zinke, who left the administration in January.

These scandals are peculiar because they mostly don’t directly involve personal enrichment—it’s not theft or embezzlement. Carson, Pruitt, and Zinke engaged in what I have labeled “conspicuous corruption,” a decision to travel and live lavishly on the public dime, in one’s own official capacity. It’s a style informed by President Trump’s ostentatious mien, and by the disregard with which the administration’s top officials seem to hold the idea of public service.

Any other president would likely have fired Cabinet officials facing the same scandals at Carson and Ross—out of simple political expediency, if not out of any moral conviction. But Trump sets the tone for his administration. He stands accused of personally profiting from his public work, especially through the Trump International Hotel in D.C., though other parts of his empire have struggled during his presidency. The shared problem is that because he has not truly separated himself from his companies, his work as president is inextricable from their ups and downs.

Ongoing violations like this remain one of the most important, and overlooked, scandals of this administration. The continued, unapologetic presence of Carson and his ilk in the Cabinet can seem like a sideshow to other, bigger issues—not least the ramifications of the Mueller report. In fact, they are connected. It’s not the sums of cash spent by these officials that matter most, though the money was not theirs to spend. If leading officials are willing to break the law and mislead the public about things as minor as interior decorating, and meet with few consequences, why would they hesitate to break the law and mislead on bigger issues?

If Ross is any example, they wouldn’t. The Commerce Department is currently embroiled in a court fight over whether the 2020 census will ask respondents whether they are U.S. citizens. Ross told Congress that he’d sought to add the question at the behest of the Justice Department, but documents revealed during the litigation contradict him.

Late in the 2016 campaign, Donald Trump began using the slogan “Drain the swamp” to represent his supposed intention to root out corruption and self-dealing in Washington. He confessed to crowds that when his advisers brought it to him, he didn’t like the slogan—it seemed “hokey”—but he decided it wasn’t hokey. He never decided he meant it, though, and the result is a Cabinet that exemplifies just what he promised to eliminate.



Former Special Counsel Robert Mueller yesterday turned up the pressure on House Democrats.
Mueller emphasized and underlined that there is strong evidence that Trump obstructed justice, and that only Congress can constitutionally decide what to do about that evidence.
Over to you, Nancy Pelosi.
Pelosi, of course, has resisted the push for impeachment hearings. But more and more national Democrats are calling for them, and after yesterday’s Mueller statement, that flow may rush into a flood. They are upholding the case advanced by Yoni Appelbaum in The Atlantic: “Only by authorizing a dedicated impeachment inquiry can the House begin to assemble disparate allegations into a coherent picture, forcing lawmakers to consider both whether specific charges are true and whether the president’s abuses of his power justify his removal.”

Yet this very coherence could—and under present conditions likely will—undo itself. Right now Trump is fighting on many fronts to suppress many investigations of many different forms of alleged wrongdoing. He must plug more holes in the dike than he has fingers. But submerge all those many stories into one big question—“remove or don’t”—and the impeachers will have to focus their energy on the most salient allegations. The battlefront will narrow, and as it narrows, the unity of the executive branch will confer a tactical advantage on even a weak presidential defense over the fissiparous offense in the House of Representatives.

Impeachment at this point is all but certain to end in Trump’s acquittal in the Senate, which is controlled by a Republican majority. The votes of two-thirds of the senators who are present are required to remove a president from office, and 67 is a number not within the present political reality. That may change, but it won’t change for reasons internal to the impeachment process. It will change only if new real-world facts materialize—either legal facts (evidence of other crimes) or political facts (a collapse in Trump’s support in the country).
A Trump facing impeachment will rally reluctant Republicans to him, with the argument, so effective for Bill Clinton in the 1990s, Even if he did something wrong, it does not merit removal from office. 

And an acquitted Trump will be an immunized Trump. Is it vexing to hear Trump’s team misrepresent Robert Mueller’s report as an “exoneration”? Imagine what they will say and do if they defeat impeachment on a party-line Senate vote. It was all fake news, a plot by the Deep State. As false and wrong as those claims will be, how will Democrats sustain the momentum to hold Trump to account after a trial and acquittal? Won’t they then have to submit to the jeers of Trump henchpersons: This issue was litigated, and it’s time to move on?
Impeachment now threatens to turn the 2020 election into a referendum on the Democrats’ methods in Congress, not Trump’s wrongdoing in the presidency, in the campaign, and in private life.
Trump accountability is not an all-or-nothing choice. It’s not now or never. The House can investigate every Trump misdeed, exposing to the light of day everything from allegations of money laundering and bank fraud to the abuse of undocumented-immigrant laborers at Trump-owned properties. It can investigate the Trump-Russia file, not as a case of criminal conspiracy, but as a national-security threat. It can fight the battle for proper Trump financial disclosure in the courts—and summon the national-security professionals who were overruled by Trump when they denied Jared Kushner a security clearance to testify before committees.

By focusing on many different issues at once rather than the singular issue of impeachment, Democrats have the chance to do three things:

Trump outrages the sense of justice. It is understandable that many yearn for urgent and decisive action to cleanse the American system. But wise action is better than urgent action, and the best decision is one that leads to success.



“Consider a building with a few broken windows,” wrote James Q. Wilson, a government professor at Harvard University, and George L. Kelling, a criminal-justice professor at Rutgers University, in a 1982 article for The Atlantic. “If the windows are not repaired, the tendency is for vandals to break a few more windows. Eventually, they may even break into the building, and if it’s unoccupied, perhaps become squatters or light fires inside.” Disorder, in other words, led to serious crime. Wilson and Kelling posed a revolutionary theory: If the original windows were repaired, the escalating string of crimes that followed might be checked before it began.

Kelling died this week; Wilson, in 2012. Their theory has been celebrated by some, including former New York City Mayor Rudy Giuliani and former NYPD Chief William Bratton, as the driving force behind a historic reduction in crime in New York City in the 1990s. It’s also been questioned by many sociologists and criminologists, and associated with controversial policing practices such as New York’s “stop and frisk” program. For years, Kelling participated in the debate his work had sparked, clarifying his and Wilson’s reasoning and criticizing some of the ways others applied it. Now, that debate will continue without him.

Kelling described their thinking while writing the original article in a 2015 essay titled “An Author’s Brief History of an Idea.” “Although we believed that police should do something about disorder,” he wrote, “at that time we were not sure what—concerned as we were about issues of justice, equity, and racism and limited by the state of police thinking of the time.” They knew that the history of policing in America was rife with abuses of African American communities, he added in a follow-up piece, including the arrests and convictions of black men for minor crimes under the Black Codes. They also knew that their theory would likely ignite controversy, and could lead to accusations of racial profiling, or worse.

“How do we insure … that the police do not become the agents of neighborhood bigotry?” they wrote. “We are not confident that there is a satisfactory answer except to hope that by their selection, training and supervision, the police will be inculcated with a clear sense of the outer limit of their discretionary authority.”

In spite of America’s long history of law-enforcement officers abusing their power and the danger of its repetition, they believed that, as they wrote in the Atlantic article, police officers should not just be “crime fighters” but should revive their historical roles maintaining order and preventing crime as well. “We must return to our long-abandoned view,” they wrote, “that the police ought to protect communities as well as individuals.” And with that training and supervision, that clear sense of limits, they believed that officers could be valuable community partners in the effort to maintain order and prevent crime.

Kelling reflected that, for him, this idea was born out of time spent with citizens in “tough areas” of American cities while serving as a consultant to the National Police Foundation in the early 1970s. Though surrounded by more serious crimes, he wrote, “poor residents” would often list “minor problems” such as “graffiti” or “youths drinking in parks” among their greatest concerns when asked. Even amid accusations that broken-window policing has “run amok” in the present day, he noted, “the demand for order remains high in minority and poor communities.”

Kelling argued that his and Wilson’s theory had been “largely misunderstood” by both critics and supporters, and misapplied by law-enforcement agencies. They had never meant it as a “high-arrest program,” and, he contended, it wasn’t; “few people go to jail” for the minor offenses the theory highlighted. A 2013 report by the Brennan Center for Justice actually found that its implementation had reduced incarceration in the state of New York. “Stop and frisk” programs were not a form of broken-window policing, he went on, though they were often associated with it, because broken-window policing focused solely on illegal, and not just suspicious, behavior. He saw the sometimes aggressive excesses of both “stop and frisk” and broken-window policing as an example of law-enforcement agencies adopting “order-maintenance policies and tactics that are not firmly grounded within a community-policing strategy.” And he argued that those excesses betrayed his and Wilson’s vision for a return of preventative policing rooted within the community itself, precisely as they themselves had worried might happen.

“A lot of sins have been committed in the name of ‘broken windows,’” Kelling reflected. But he still believed that the idea had merit, and that, if implemented correctly, it could help make communities safer. Following his death, police officers, scholars, and activists are left to grapple with that belief, and those sins. Thirty-five years after the original article was published, its legacy remains a subject of active debate—one that Kelling, despite his efforts, could never wholly settle.



It was treason.

The conservative commentator Ann Coulter said The New York Times’ reporters had done something that “could have gotten them executed.” Bill Kristol, now known as a prominent anti–Donald Trump Republican, said the Justice Department “had an obligation to consider prosecution.” The radio host Rush Limbaugh declared, “I think 80 percent of their subscribers have to be jihadists. If you look at The New York Times and the kind of stories they’re leaking and running and the information they’re getting, it’s clear that they’re trying to help the terrorists. They’re trying to help the jihadists.”

In 2006, right-wing-media figures were apoplectic over the exposure by The New York Times of a surveillance program for tracking financial transactions without warrants or subpoenas, including those of American citizens. Like the reporting that exposed the Bush administration’s warrantless-wiretapping program, its network of secret torture chambers around the world, and its use of torture on terrorism suspects, it was another example of a news story that utilized leaks of classified information to inform the American public about what its government was doing in its name.

The Bush administration did not seek to prosecute the Times over its publication of that information, despite the fact that it had embarrassed the government and exposed things it had wanted to keep secret. But if the WikiLeaks founder Julian Assange is successfully convicted under the Espionage Act for publishing information leaked by the former Army intelligence analyst Chelsea Manning, and if that conviction is upheld, then the Trump administration will have successfully laid the legal groundwork for prosecuting journalists. On Thursday, the Justice Department announced that it was charging Assange with violations of the Espionage Act for, among other things, seeking to “encourage those with access to protected information, including classified information,” to offer it for “public disclosure.” There is no sense in which that action, if criminalized, does not also apply to media outlets such as The New York Times.

The indictment alleges that Assange helped Manning decrypt a password for an Army computer to obtain classified information. But that is not the only act it is seeking to prosecute. The indictment explicitly states that Assange’s crimes include efforts to “obtain documents, writings, and notes connected with the national defense, for the purpose of obtaining information respecting the national defense” and to “willfully communicate documents relating to the national defense.” This describes, in the most basic sense, what national-security journalists do every day to ensure that the public is informed about things the government wishes to keep secret from it.

Nor does it matter whether Assange is a journalist. The First Amendment restricts the authority of the state to infringe on freedom of speech; allowing the government to determine who is and who is not a journalist is just such an infringement. Moreover, the current president of the United States attacks every journalistic outlet that does not treat him with fawning subservience as “fake news.” The line that some observers may think they are drawing between Assange and The New York Times is not one the government is obliged to draw. And as the cries of “treason” during the Bush administration show, Trump’s position on press freedom is less a divergence from conservative orthodoxy than an escalation of it. If you value democracy, you simply do not want this administration, or any administration, deciding which people are journalists and which are criminals on the basis of whether what they publish makes government officials angry.

Consider the number of stories that might be considered federal crimes under the standard set in the Assange indictment: the stories showing Trump’s former national security adviser lied about his communications with the Russian government about retaliatory sanctions for its election interference? That story about Trump’s adviser and son-in-law, Jared Kushner, seeking to use the Russian embassy to communicate with the Kremlin? The president exposing classified information to Russian officials in the Oval Office while bragging about his firing of the FBI director over the investigation into his campaign? The reports illustrating the origins of the Russia investigation in a Trump adviser’s boasts to a foreign intelligence official? Details about the Trump administration’s internal debate over going to war with Iran? All could have resulted, under the standard put forth in the Assange indictment, in the journalists who reported them being sent to prison.

That is a profoundly abridged list, and one that does not even cover the major national-security stories of past administrations—the Bush administration’s manipulation of intelligence to go to war with Iraq, the Obama administration’s escalation of the United States’ targeted-killing program. Prosecuting those who publish classified information would not only criminalize journalism; it would deprive the public of essential information it needs to make informed choices in a democracy. Such prosecutions would not end the leaking of classified information—far from it. Rather, they would simply give the government a monopoly on such information, allowing officials to selectively leak classified information to manipulate the public, with no check on their ability to do so.

The groundwork for this assault on freedom of speech was laid by prior presidents. The Espionage Act, a World War I–era law signed by President Woodrow Wilson, is a plainly unconstitutional statute that, at the time, was mainly used to repress leftist criticism of the U.S. government. Both George W. Bush and Barack Obama prosecuted leakers for speaking to the press; the Obama administration prosecuted more such cases than all prior administrations put together. But prosecuting the publishing of classified information, rather than the leaking of it, as a criminal act is a dangerous new escalation that threatens the basic freedoms necessary for democracy to function.

Assange is loathed by liberals, understandably so. During the 2016 election, his organization, WikiLeaks, published emails from the Democratic National Committee and from Hillary Clinton’s campaign chair, John Podesta, that had been hacked by the Russian government in an effort to boost Trump.

Picking unsympathetic defendants to establish bad precedents is a time-worn legal strategy. Liberals do not need to jettison their hatred of Assange for helping the Russian government sway an American election. But if the Trump administration prevails, it will establish a precedent that will allow Trump to prosecute journalists who have been diligently exposing his corruption and incompetence.

Assange’s actions helped elect an authoritarian president who seeks to use state force to destroy his political foes. Assange’s prosecution may allow that same president to use the vast power of the federal government to crush those he has dubbed the “enemy of the people.” If liberals allow their fear and anger over the 2016 election to blind them to this danger, they will be complicit in that outcome.



In the study at the ambassador’s residence of the British embassy sits a watercolor portrait of Field Marshal Bernard Law Montgomery, 1st Viscount Montgomery of Alamein.

Montgomery commanded the Allied ground forces during Operation Overlord, from the initial landings on D-Day through the Battle of Normandy, working closely with his American counterparts. His portrait might seem a tribute to smooth, amicable cooperation between the U.S. and the U.K.

Yet the actual relationship between Montgomery and General Dwight Eisenhower, the Supreme Allied Commander, was often difficult and always tumultuous. They got off to a rocky start in their first meeting in 1942, when Monty reprimanded Ike for smoking, then loudly told a colleague in the room, “Ike’s a nice chap. No soldier, though.” The tensions persisted through the next three years, on and off the battlefield. At one point, Monty’s pursuit of his own plan for Normandy led Eisenhower to seriously consider sacking him.

But he didn’t. Despite the clashes, Ike recognized Monty’s qualities as a soldier, but more important, he understood that dismissing him would have provoked a huge political backlash in Britain at a crucial moment in the war.

Ike understood that the relationship had to be steadfast, that it had to transcend personality clashes or political bumps along the way. It had to be bigger than that.

The artist who painted the watercolor of Montgomery understood this clearly. He left an inscription on the back: “To Monty, from your friend Ike. 1952.”

I’d barely unpacked my bags three and a half years ago in the beautiful Queen Anne mansion that is home to the U.K. ambassador in Washington when I was handed an article predicting the imminent demise of the partnership between the United States and Britain. I was given another such story today.

And I’m willing to bet that every one of the 23 ambassadors who unpacked their bags in the century before me had the same sort of article periodically delivered to them.

The stories always suggest that the U.K. no longer matters to the U.S., and that some other nation—Germany, or France, or whoever—is America’s new best friend.

And our response, every time, has been the same: to carry on with the day-to-day work of two countries united by shared goals, common values, and the tight ties between everyday Britons and Americans. It’s exactly what we’ve done since long before Winston Churchill coined the phrase special relationship in his Iron Curtain speech in Fulton, Missouri, in 1946.

There has not been a single time since I took office when either I or my staff hasn’t been able to secure support, counsel, or advice from one of our U.S. counterparts—from the grass roots to the top of the administration. When we’ve needed help, it’s been given. Whenever we’ve asked for a phone call with the president, it’s been given priority.

Cabinet secretaries are regularly at the British residence, and our ministers and secretaries of state visit their U.S. counterparts frequently. The president’s relationship with Prime Minister Theresa May—contrary to some reports—is also excellent. It is respectful, and on important issues, there is free, open dialogue.

Earlier this month, Secretary of State Mike Pompeo told Foreign Secretary Jeremy Hunt in London that the special relationship “doesn’t simply endure,” but “thrives.” He added later: “Our partnership allows us to protect the values we hold dear and to stand together to address the challenges of our time—China, Russia, Iran, the Middle East … We must tend to it, we must expand it, and we must not forget how special it really is.”

This isn’t politician-speak—this is what I see every day. So when I pick up these gloomy articles, it’s with a wry smile and slight exasperation that I wish the authors could see it too.

I was national security adviser for four years in the British government before coming to D.C. I knew then that U.K.-U.S. defense cooperation forms the broadest, deepest, and most advanced partnership any two countries enjoy. We’re close allies in NATO, permanent members of the UN Security Council, and leading nuclear powers—our cooperation is vital to international peace and security. We are the U.S.’s only “Day One, Night One” partner, deployed around the globe and capable of operating from the outset of high-intensity conflicts.

But working here now, I see it unfolding on the ground. Our forces are deliberately designed to operate seamlessly alongside American troops. We not only fight together, but train together. We have 1,200 British servicemen and servicewomen embedded with the U.S. armed forces, in 30 states across America. A map above my desk has dozens and dozens of tiny pins in it—their primary-colored heads create a haphazard rainbow of dots. It paints, for me, a very clear visual of decades of vital partnership.

A few months ago, I stood on the deck of the 65,000-ton aircraft carrier HMS Queen Elizabeth II—the largest warship ever built for the Royal Navy—as it came alongside the pier in New York Harbor. A few days before, it had been used for test flights of the F-35B short take-off and vertical-landing fighters created out of the U.K.-U.S.-supported Joint Strike Fighter program, which are now the backbone of Britain’s war-fighting capability. By 2021, the U.S. Marine Corps will operate its own F-35B jets in tandem with squadrons from the Royal Navy and the Royal Air Force. And soon the next generation of Columbia and Dreadnought nuclear submarines, which we are building together, will be on patrol in the seas below, underpinning NATO’s collective deterrence.

In its social-media posts, the British Army uses the hashtag #sidebyside. It’s a phrase that was originally used in Churchill’s address to Congress in 1943—“We will wage that war side by side with you … while there is breath in our bodies and while blood flows in our veins”—and neatly summarizes the reciprocal relationship we still enjoy today.

And we were never more grateful for that than on one quiet day in the historic market city of Salisbury in Southwest England when Russian agents used a nerve agent, for the first time in Europe since the Second World War, to attack a man and his daughter.

The country was in shock. In the hours and days that followed, our embassy team and I personally lobbied colleagues in the White House and the State Department for a strong American response—knowing that the U.S. decision would set the standard for Europe and the rest of the world.

And the U.S. delivered. A total of 60 Russian diplomats were expelled from the U.S. Europe then expelled another 60, delivering a blow to the Russian intelligence machine. It’s just one of the countless examples of how the U.S.-U.K. relationship is built not on misty-eyed nostalgia, but on practical, unwavering partnership.

That partnership is also built on global diplomatic influence. The U.K. has one of the largest diplomatic footprints of any country, with embassies and missions around the world. This reach is hugely valuable—and the Americans recognize this. The U.S. has no diplomatic presence in Pyongyang or Tehran. We have had ambassadors and teams in North Korea since the early 2000s and in Iran since 1821. The United States relies on us to be its eyes and ears in places where it has none.

The constant engagement between our Foreign and Commonwealth Office and the U.S. State Department fills my days and weeks in a way that nothing else does.

A British colleague of mine at our embassy in Washington recently told me a story. Her son died suddenly, at age 13, while she and her husband—a British Army colonel—were stationed at Fort Leavenworth in Kansas. He was teaching American (and international) officers national-security and defense policy.

In the unimaginable horror of dealing with all that entailed—the shock, the emotion, the administration, the bureaucracy, the shielding of her two other boys—she found a handwritten note on their doorstep:

“Your loss is our loss. History brought us together—our friendship and our enduring alliance is what will keep us together. Therefore, when we serve together, we grieve together.”

The American woman who had fixed the note on top of a warm meatloaf was not someone my colleague knew particularly well—she worked in a store on the base—but her grandfather had served in World War II. As he was taken to a field hospital in France, he dealt with his unimaginable horror, but with a British corporal by his side. That corporal took the name of the dying man’s mother, and some months later wrote a moving letter to her, paying tribute to her son.

The lady in the store at Fort Leavenworth still had that letter. It was what had moved her to walk along the Missouri River as the sun rose on that August morning to give comfort to the grieving family.

These are the moments I think about when I read another commentary on the special relationship written from a desk in a faraway city.

One of the most important things I’ve learned in my three years here is that we share so much more than relations between diplomats, politicians, and heads of state. The special relationship is about people. Americans and Britons share not only values, but also language, culture, movies, music, and an unwavering belief about what is right and wrong.

It’s a relationship that starts with the personal and reaches the powerful—and that’s why it will always survive.

When the somber, silent procession of former President George H. W. Bush’s funeral passed by our embassy on its way to the National Cathedral just before Christmas, former President George W. Bush leaned across from his far-side seat in one of the cars and saluted the members of the British military who had formed an impromptu honor guard outside the residence gates.

After the long, winding cortege moved slowly up Massachusetts Avenue, one of the D.C. police officers who had been lining the route turned to a member of our staff. “I honestly don’t think there’s a president who wouldn’t have reacted that way,” he told her. “Who could drive by here, look past Churchill’s statue, through those gates, and not think about everything that’s been done by both of us together?”



On December 1, 1862—a month before he issued the Emancipation Proclamation—President Abraham Lincoln wrote to Congress. He was not yet the Great Emancipator. Instead, he proposed to become the Great Compensator.

Lincoln proposed a Thirteenth Amendment to the U.S. Constitution: the most expansive and expensive slavery-reparations plan ever put forth by a U.S. president. “Every State wherein slavery now exists shall abolish the same therein at any time or times before” January 1, 1900, and slaveholders “shall receive compensation from the United States” for emancipating the enslaved.

Lincoln stressed to his fellow citizens that “we cannot escape history.” Pursuing gradual emancipation, and compensating the enslavers for their lost labor and wealth—and not the enslaved for their lost labor and wealth—would repair a broken America once and for all. “Other means may succeed,” he said in closing; “this could not fail.”

Indeed, Lincoln’s proposal did not fail to escape history. His politically expedient plan made and portended history, projecting a middle ground for Americans to stand between permanent slavery and inequality, and immediate emancipation and equality.

Today, many Americans who oppose reparations, including a slight majority of Democrats, stand on this middle ground. These Americans self-identify as “not racist,” but do nothing in the face of the racial wealth gap that grows as white people are compensated by past and present racist policies. Or they support small-scale solutions that barely keep up with this growth. Or they support class-based solutions that are bound to partially fail in solving this class- and race-based problem. Or they oppose reparations because they’ve consumed the racist idea that black people will waste the “handouts,” that the reparations bill will be too expensive, or that black America is not too big to fail.

Americans who prefer gradual approaches that do not radically disrupt inequality and who label their approaches “plain, peaceful, generous, just,” to use Lincoln’s words, carelessly ignore or understate the complex, violent, stingy, and unjust damage wrought by inequality. These Americans care more about responding to political expediency than about the emergency of inequality, care more about repairing alienated white Americans than about repairing pillaged black coffers, and claim to be horrified by slavery and “not racist” but end up, knowingly or unknowingly, compensating the white beneficiaries of slavery and racism.

These Americans claim they oppose racism and reparations. They support the drive for economic equality between the races at the same time they are pumping the brakes on the only foreseeable policy that can dramatically close the growing racial wealth gap. Only an expansive and expensive compensation policy for the descendants of the enslaved and relegated of the scale Lincoln proposed for the enslavers and subsidized could prevent the racial wealth gap from compounding and being passed onto another generation.

The reparations debate returned to Capitol Hill this week for the first time in more than a decade. Ta-Nehisi Coates and Danny Glover testified on Wednesday in a hearing before the House Subcommittee on the Constitution, Civil Rights, and Civil Liberties. Is this hearing, and the fact that some Democratic presidential candidates are endorsing reparations, the beginning of the reckoning? Is the United States finally beginning to acknowledge the economic damage that state-sanctioned racist policies have wrought since slavery? Is the United States finally beginning the process of eradicating those policies and repairing their damage?

For every $100 of wealth that white families hold, black families hold just $5. One in four black households has zero or negative wealth, in contrast to one in 10 white households. White households make up 96 percent of the top 1 percent, while black households constitute 2 percent of that highest wealth bracket.

The racial wealth gap will not repair itself. And it is growing.

From 1983 to 2013, the wealth of the median black household declined 75 percent as the wealth of the median white household increased 14 percent. By 2020, black people are projected to lose an additional 18 percent of wealth, and white households will own 86 times as much wealth as their black counterparts. By 2053, the median black household is projected to flatline at $0. Generally speaking, black people are facing economic death.

State-sanctioned racist policies, which have opened, sustained, and broadened the racial wealth gap, have often been ironically framed as reparative for white people. Wealthy-white victimhood has been the creed of racist history since long before Donald Trump vowed to repair America’s greatness from the tyranny of the first black president. The Founding Fathers identified only themselves as the victims of tyranny. Slaveholders cast themselves as under siege by abolitionists, runaways, and especially revolting captives. Confederates fought the so-called War of Northern Aggression. Whites described civil- and voting-rights bills and judgments as “made to operate in favor of the colored and against the white race,” to quote President Andrew Johnson’s reasoning for vetoing the first Civil Rights Act in 1866. Klansmen and lynchers said they were fighting against black debauchery. Whites complained they were subjected to affirmative action, welfare queens, the Central Park Five, reverse discrimination, race cards, and roving and ravishing migrants and immigrants.

Throughout this alternative history, white people were collectively accumulating, compounding, and passing down wealth from selling black bodies; exploiting no-wage or low-wage black labor; stealing black assets, from the days of whitecapping to the foreclosure era; seizing opportunities, such as the New Deal or GI Bill, that were denied to black people; utilizing family wealth to start businesses; owning government-subsidized homes in government-subsidized white suburbs or gentrified neighborhoods; and cashing in on Reagan-, Bush-, and Trump-era tax cuts for the already wealthy.

Racist policies have historically compensated people for their whiteness and extracted wealth from people because of their blackness. But Americans occupying the middle ground do not attack these policies like they attack reparations. They support (what they don’t call) reparations for white people at the same time they oppose reparations for black people.

When the so-called not-racists express their opposition to reparations, I do not quarrel with them over their reasoning. I do not point out the history of white compensation to repair damages that hardly existed. I do not point out their middle ground. I ask a simple question: How does the United States close the growing racial wealth gap without reparations?

Nearly all Americans claim to be not-racist, but the so-called not-racists are usually not up to supporting a policy that can create racial equity.

Reparations is not my litmus test for presidential candidates. But it is a litmus test for whether a person is being a racist or anti-racist when it comes to one of the most damaging racial inequities of our time, of all American time—the racial wealth gap. To oppose reparations is to be racist. To support reparations is to be anti-racist. The middle ground is racist ground. It is occupied by people passively doing nothing in the face of racial inequity, or actively supporting policies that reproduce racial inequity. The anti-racist approach requires standing up for the policies, like reparations, that can create racial equity.

Take Lincoln’s compensation plan in 1862. He considered it a “compromise among friends.” Opposition to his planned Emancipation Proclamation had been mounting like casualties from the Civil War. In the November 1862 midterm elections, Democrats gained 34 seats in the U.S. House of Representatives shouting at Republicans like Lincoln: We are warring for reunion with our Southern brethren, not for emancipation. Lincoln shuddered and related. In the summer of 1862, he had publicly declared: “My paramount object in this struggle is to save the Union, and is not either to save or to destroy slavery.”

Lincoln’s reparations plan went nowhere. He signed the Emancipation Proclamation as scheduled, on January 1, 1863, as “a necessary war measure” to save the Union. But when slavery reemerged in another form after the Civil War, when former slaveholders received a different manner of compensation from Jim Crow, when a civil war had to be fought each time black people proclaimed they should be the ones receiving reparations, it renewed the questions Lincoln answered with his plans to compensate the slaveholders. These questions still divide Americans today. Who is being damaged? Who is being compensated and repaired?

The slaveholder still—or will it finally be the enslaved?



The crazed pursuit of college admissions helps no one thrive. And while the Varsity Blues admissions scandal shines a light on families that break the rules, it’s time to consider the unhappiness of families that play by them. While competition for seats may be inevitable, students scramble to do ever more to get into college—and give away more of their childhood to do so. This competition might seem a problem only for middle class and wealthy families. But students of modest means suffer most when applying to college becomes an endless list of tasks requiring time and other resources.

As the CEO of the College Board, I see this arms race up close. We administer the SAT, a test that helps admissions officers assess the reading, writing, and math skills of students across the country and around the world. We also administer the Advanced Placement program, which helps students earn credit for college-level work they do while in high school. We know these tools to be useful, but we also see how they can contribute to the arms race. The College Board can and will do more to limit the excesses—more on that below—but there is more at stake than which tests kids take or don’t take.

The statistic that should worry us most is this one: According to a 2014 study by Gallup and Purdue University, only 3 percent of students have the kind of transformative experience in college that fosters personal success and happiness. Three percent. Even as the pressure of college admissions haunts students throughout their adolescence, whispering premature anxiety into questions of what to learn and how to spend time, the admissions process as we know it often misses the heart of the matter: What kind of education is really worth investing in? What is it that students should be doing, not just to get into college, but to succeed there and live a good life after they graduate?

Having listened to hundreds of admissions officers, school counselors, parents, and students, and after reflecting on my own experience, I believe there is a healthier model to prepare young people to excel. There are durable ways to invest in children that will help them thrive in college and beyond. As the Varsity Blues scandal works its way through the legal system, the broader question is whether there’s a productive path out of the current admissions madness—a way to fill students not with anxiety, but with a deeper devotion to learning.

In the Gallup-Purdue study, the type of college that students attended affected their sense of well-being after graduation more than what they experienced at whichever institution they chose. The 3 percent of students whose lives changed for the better—who, according to Gallup, had the types of experiences that “strongly relate to great jobs and great lives afterward”—had three features in common: a great teacher and mentor, intensive engagement in activities outside class, and in-depth study and application of ideas.

These three shared features are all about intensity—not just participation in college life, but active engagement. They require students to move beyond merely doing something and toward becoming devoted to something. They require a depth of commitment that will serve students well throughout their lives. And yet nearly nothing in the admissions process tells students that these are the keys to their success.

1. Find great teachers.

At the College Board, we regularly convene first-generation students on the threshold of college to help them plan their future. These students have been remarkably resourceful in navigating their path to college, yet they have much less to say about how they will succeed once there. I have asked hundreds of high-school students what choices they will make in college that will most shape their success. Students talk about which major they will choose, who their friends will be, or which clubs they’ll join. They never say that their most important decision will be who their professors are. In general, students are extremely passive about seeking out great teaching.

Outside of family, though, no single factor comes close to the impact of a great teacher on students’ success. Former U.S. Education Secretary John King describes how a New York City public-school teacher effectively saved his life after he lost his mother and father. He says that as a young African American and Puerto Rican man from Brooklyn in a family in crisis, he might well have ended up “shot or in prison” but for great teaching.

Even for students who confront far fewer challenges, seeking out and finding the right teachers pays enormous rewards. In my high school in New York City, there was a tough and engaging teacher named Mrs. Grist. I asked whether I could take her government class, and I went on to study psychology with her as well. Mrs. Grist was among the most forbidding people I had ever met, yet she made the subjects she taught intense and urgent. I was stunned when she asked me whether I needed a recommendation for college. Her offer gave me a confidence in my step, as if her hand were behind me.

Mrs. Grist’s approach to teaching helped transform my college life as well. I arrived at college disoriented by large lectures and huge reading lists. I knew I was a slower, more deliberate reader. I could be intimidated by racing through books I did not understand. I was not self-sufficient to do my best work on my own and needed a great teacher to inspire me.

So rather than accepting the typical first-year roster of large introductory courses, I began a hunt. I used those first days of the semester, before schedules were set in stone, to find classes where I felt at home. I will never forget how much I relaxed when I walked into a small philosophy class that taught only one book. Instead of racing through a book a week in a big survey course, I immersed myself in the world of Plato’s Republic with a gifted teacher, Professor Ferrari. Rather than dazzling us with his expertise, he asked questions as if he, too, were reading the book for the first time.

In effect, I was attending a very different college from that of so many of my classmates. They carried around piles of books that they might at best skim before class; I was kept up at night by the handful of old books on my shelf. They were more engaged in what was going on outside class, and studied in binges for midterms and finals; I read my few pages, often with a sense of defeat, but there were moments when the centuries separating the authors and me would melt away. I worked daily for my teachers—looking forward to the next conversation, usually in class, sometimes in office hours, where I seldom saw another classmate. All these students who had fought so hard to pry open the doors of college didn’t know to knock on their teachers’ doors.

Finding great teachers and insisting on learning from them is a form of resistance. You must push the rules and the system. One of the most misleading things we say in education is that a good school will “give you an excellent education.” A great education is never given—it is taken. The ancient myth of Prometheus is more honest; the gods do not give Prometheus the flame—he steals it.

2. Pick an activity (or maybe two).

Religious tradition testifies that immersion changes lives. Research agrees; the College Board reviewed dozens of studies to find the factors that most predict success. After grades and test scores, the factor that most predicts college success is follow-through—that is, students’ sustained effort and growth in one or two extracurricular activities while in high school. Students who devote themselves to an activity are more likely to succeed later in areas such as campus leadership and independent accomplishment.

Devotion to one or two activities—not several—advances you. Competition to get into college has metastasized into a race where more is better. We have sacrificed the productive ideal of nurturing excellence in one thing for the mad rush to submit a résumé of too many things.

The typical application for college today has eight to 10 spaces for students’ activities outside class, and parents and students have become convinced that the more spaces filled, the better. Long lists cultivate busy mediocrity rather than sustained excellence. To get into college or to earn scholarships, it is much more effective to be very good at a small set of things than to check off a long list.

MIT recently revised its application to include only four spaces for extracurricular activities, and admissions officials there are evaluating whether they can move to three. Brilliantly, the school also removed the space for students to put any activities from ninth grade on their application. From MIT’s point of view, ninth grade is a safe harbor—a year to change your mind, to try different things without regard to your track record.

MIT is not alone. “Not only at Maryland, but broadly across the admissions community we’re more interested in the few things students are devoted to over a sustained period of time rather than a long list,” says Barbara Gill, associate vice president of enrollment management at the University of Maryland.

Time is one of the great inequalities in our society. The Harvard researcher Richard Weissbourd is right to demand that college applications honor the work some students do to support their families. For lower-income students, it is defeating to ask them for a long list of activities outside class. We need to do all we can to ensure that they have the time, resources, and space to pursue passions in-depth outside class—but also not penalize them if work and family obligations get in the way.

In wealthier communities, the scramble for credentials often leads to premature professionalism and intensive regimentation. These artificial structures we invent to fill applications hinder the development of genuine interest and commitment. Young people become less authors of their own fate than soldiers enacting the battle plans of their parents.

Personally, I was lucky. In high school, I began debating and found that I loved it. (My parents didn’t share my enthusiasm—after debate practice, I was too argumentative—but they left me to it.) I didn’t have much else going on outside class, so I could fill my time researching evidence and practicing for the next fight. But I wonder how today’s overscheduled students find time to explore any one extracurricular—whether it’s a sport, a musical instrument, or anything else worth doing—in any depth. The key challenge for our young people is not to master more activities, but to learn that mastery requires doing one thing at a time.

3. Learn to love ideas, even when it hurts.

The luckiest people in life develop enduring fascinations and spend time honing their skills and learning new ones. They experience regularly the internal satisfaction that arises from encountering new ideas. With its focus on external measures of success, such as grades and test scores, the college-admissions scramble does little to communicate the importance of growth and exploration. For young people to be happy in college—and to excel there and the rest of their lives—they need to open themselves to new subjects and ideas that can captivate and motivate them. That process necessarily includes doing things they might not immediately like.

Most of the time, we misunderstand how students learn to love a subject. Listen to parents talk: My child loves math. My child loves to read. When parents say this, they mean their child enjoys something and is good at it. It sounds harmless and encouraging, but it excludes the possibility that children might someday find meaning in ideas and subjects that do not come easy to them. Difficulty can be the starting point of love, rather than a signal to abandon the subject matter entirely. To say I hate math is to say that you retreated too quickly. The question is not whether you like or excel at a subject from the outset, but whether the subject is lovely and worth knowing. Loving to learn requires that you move beyond your initial distaste to discover a subject’s power.

Particularly destructive for aspiring college students is the myth of the “numbers person” or the “word lover,” ignoring the fact that we all have minds and hearts capable of both. (Feeling at home in both domains also makes tests such as the SAT and ACT much easier.) If you don’t at first like math, seek out a better teacher, practice harder, find a connection to something else that interests you. The paradox of loving to learn is that it requires managing pain.

Being a good learner does not require that you keep doing everything without any regard to whether you enjoy it; pleasure must emerge as an essential dimension to those areas to which we devote ourselves. But even when you are engaged with a subject you love, it too can be difficult and forbidding at times. Yet even when you love something at first and are drawn to it, devotion sustains you when it becomes difficult and forbidding. We know that people love to read when they are first defeated by a book, and then reread it to see what they missed.

We need to dispense with platitudes such as “Learning is fun,” and instead admit that learning is often painful. A real love of ideas begins when students stop doing only what they are good at and realize that through practice they can discover new worlds of understanding and joy.

Even without federal indictments of parents who sought an unfair advantage, it’s clear that the American college-admissions system has created unproductive anxiety among families while doing little to foster the kind of devotion to learning that makes an education meaningful. All of us who are involved in this system—including the College Board—should reconsider what we can do to stop the madness.

Advanced Placement can help students discover and pursue a passion, but not if too many courses suffocate their time. Some students cram their schedules with AP courses to burnish their applications. While data show that taking up to five AP classes over the course of high school helps students succeed in college, there is no evidence that more than that is better. We therefore recently announced that taking more than five AP courses should provide no advantage in admissions. Students can take more AP if they want, but not to get into college.

And we need a far humbler view of the SAT. When the SAT began, it was an aptitude measure designed to gauge intellectual potential. We revised the exam in 2014, and the era of trying to measure aptitude is finally over. The new SAT assesses nothing tricky or mysterious: a focused set of reading, writing, and math skills students learn in school and use widely in college. The new SAT does not tell students or anyone else how smart students are, or how capable they are of learning new things. It only says something about whether students have yet attained the reading, writing, and math skills they will use to gain knowledge in college or career training; it makes no statement about what they are capable of learning.

We need to change the culture around exams such as the SAT. They should never be more than one factor in an admissions decision. Low scores should never be a veto on a student’s life. Students should have confidence that if they practice their math and reading skills, they will improve, which is exactly what we are seeing when students practice for free on Khan Academy. Students should take an exam once and, if they don’t like their scores, practice and take the test once more. If they still don’t like their scores, we should offer many other ways for them to show their strengths to admissions officers.

Let’s fashion a new invitation to higher education. We must invite families to invest in durable excellence rather than fragile perfectionism. Students should sacrifice far less for the sake of getting into college and do much more to thrive within and beyond it.



JUBA, South Sudan—Virtually everything in South Sudan appears rigged in favor of the few. It begins with the economy, with so much oil revenue and so little to show for it. The capital, Juba, has few paved streets and scant signs of development or even basic infrastructure. There is wealth, but unseen, lost to graft, misused to build private armies and buy off potential rivals.

The war, too, belongs to the elites. They are not doing the fighting, and they are not its victims. But they provoke it, manipulating ethnic tensions to mobilize their respective constituents and seek control of land and resources. They are good at sparing their own manpower: Armed groups typically don’t do battle with other armed groups, but instead steal from, rape, and kill ordinary, defenseless civilians. Even peace itself has tended to be the preserve of those at the top. Rather than negotiate on behalf of their constituents, strongmen strike transactional deals to preserve their personal power.

At least peace—or the absence of war—can bring benefits to a broader community. That much became clear after President Salva Kiir and his former vice president but also main rival, Riek Machar, reached a cease-fire deal last September. Their recent decision to extend the deadline to form a transitional unity government rather than pronounce the collapse of their agreement was, for that reason, welcome news. But it also was a clear indication of how tenuous the truce is, and how far off a lasting peace still remains.

The cease-fire agreement between Kiir and Machar suffered from many common defects. It lacks a credible outside guarantor. It didn’t address any of the deeper roots of the conflict. It was a power-sharing affair (Kiir would retain the presidency, while Machar was promised a return to power as vice president) reached between two men who have wrought such damage to their country and who want to exercise power, not share it. It excluded other important armed groups, which, having been shut out of the deal, have had an incentive to grow their ranks while waiting for a slice of the cake. It involves a complex effort to reunify the two men’s armed groups that, because it encourages the sides to inflate the size of their forces, is more likely to be used to recruit new fighters than to demobilize existing ones.

Still, the deal ushered in the first sustained end of hostilities between the two antagonists since the 2013 outbreak of a vicious civil war that killed up to 400,000 people, a mere two years after South Sudan was born amid local and international exuberance. For a people that has experienced unthinkable brutality for decades, first during the war for independence from Sudan and then during the war within the new breakaway country, the reprieve from violence is priceless.

By now, though, the two armies were to have assembled, screened, and trained their respective armed forces. They were to have turned them into a unified national army and formed a unity government. They were to have resolved disputes over the number and boundaries of South Sudan’s states. As of now, none of this has been achieved. The period since the signing has been wasted.

The question on people’s minds in Juba is whether the cease-fire can last. Judging by how little has been accomplished in the eight months since the signing, the obvious answer would be: no. Judging by the ease with which the parties agreed to extend the deadline to carry out their commitments from May to November, however, the answer would be: maybe.

Neither side seems in a hurry to resume fighting at this point, and both saw advantages in gaining time. For Kiir, the calculus was straightforward. He is in control, both of the government and (mostly) on the ground, so the status quo suits him well. Why rush toward implementing a deal that will require dividing power that is now his alone? Why relinquish any control over armed forces he presently commands? The original request for an extension came from Machar, not Kiir, and the president dragged his feet for a while before acquiescing in what he described as a goodwill gesture. But few were fooled, and in private conversations senior officials in Kiir’s government don’t bother to conceal it: A postponement served them well this time, and it may serve them well the time after that.

Machar’s calculations were more complex but led him to the same conclusion. Returning now meant returning in a position of comparative weakness; his forces have largely demobilized, the balance of power clearly favors his foe, and he fears further defections from his remaining forces should he come back to the capital without adequate concessions from him. Machar’s gamble when he signed the deal appears to have been that he would have time to embark on a recruitment spree, attract new fighters, stack his forces with loyalists from ethnic or clan networks, and build up strength in case of renewed warfare. The opposition offered a preview of this pattern following an earlier accord in 2015, with fateful results: It mobilized fighters from areas previously unaffected by conflict, thus expanding the war’s boundaries as soon as it resumed. Yet, over the past eight months, Machar made few advances in this regard. He has been struggling to get his fighters, many of whom have deserted and now live in refugee camps or other East African capitals, to return.

To achieve his goal, he would have had to have money to pay, feed, and otherwise take care of new recruits. External donors refused to foot the bill, for good reason: The parties intended to create a 300,000-strong joint security force, a significant expansion of what presently exists, most of whose members would have to be freshly recruited, at a cost of more than $200 million. South Sudan needs fewer men with guns, not more. Unable to rebuild his forces, Machar had little option but to seek an extension of the deadline. At a minimum, it gives him a chance for a do-over.

The question remains: How to make the halt in fighting endure? Pressure from outside powers—African nations, but also the United States and Europe—has its part to play. Faced with a credible threat of sanctions targeting their personal economic interests, Kiir and Machar might think twice before dragging their people back down the road of confrontation. But without some advance toward bringing Machar back into the government, and some combination of demobilizing and integrating the two rival armed forces, the risk of a resumption of violence will grow over time. Already, in private conversations, Machar’s aides promise war will reignite if no progress is made in implementing the deal. It could be bluster, of course—but it might not be.

Perhaps the smartest step that could be taken now would be to focus on immediate, realistic steps. Machar’s demands regarding broader reform of the military and integration of his own disparate armed forces may be in line with the agreement he signed. But they won’t happen, or won’t happen anytime soon. Nor is he being sensible in his insistence that he return only after thousands of his fighters are deployed to Juba; twice in the recent past, in 2013 and 2016, a major eruption of violence was triggered by a confrontation between Kiir’s and Machar’s bodyguards. A potential alternative solution would be for an external, third-party force to provide protection for Machar, allow him to return safely and with dignity intact, assume the vice presidency, and—by keeping the process afloat—lend more time and space for the peace deal to progress without holding it hostage to wider security reforms. We suggested such an idea in conversations with the two leaders. Neither jumped at it, but neither shut the door completely. By South Sudanese standards, that counts as hope.

On the plane ride out of Juba, a woman told her story. Half of her family members had been killed; the other half were scattered across the globe. Her mother had been exiled twice, once because of the war with the North, the second time because of South Sudan’s internecine fighting. As a member of the Dinka, the country’s largest ethnic group, she had been kidnapped and tortured by Machar’s predominantly Nuer forces. One Nuer threatened to kill her; another ultimately saved her life. That summed it up for her daughter: The war essentially was engineered and stage-managed from the top. Why, she asked, was the world spending so much time and effort cajoling and trying to persuade Kiir and Machar even as they were busy agitating their constituents for the next battle, rather than focusing on the ordinary people, for whom such ethnic differences hardly matter?

She had a point. Assuming Machar can be persuaded to return, assuming he and Kiir can form a unity government, assuming the process of demobilization and reforming the armed forces can begin, and assuming the cease-fire holds—assuming all that, none of the underlying sources of conflict will have been addressed. The result would be a precarious status quo between one side that feels comfortably entrenched in its current dominant position and another that feels too weak today to take a gamble. It hardly would mean that either side has given up on the goal of eradicating its foe, that memories of brutal ethnic killings have dissipated, or that the brittle equilibrium can persist for long. But it’s far better than the likeliest alternative today—a return to warfare.

For now, South Sudan’s most meaningful ray of hope may lie in its cloudy skies. The six-month rainy season is when fighting is hardest. As we prepared to depart Juba, a powerful rainstorm signaled that it was just around the corner.



It was Megan Rapinoe’s goal in the 79th minute that really seemed to tick people off. Rapinoe, the vivacious U.S. women’s national soccer team forward with pink hair, ran with outstretched arms, spun around a couple times, then slid to the ground and kicked her right heel high in the air several times.

A whole lot of people were big mad at Rapinoe, whose goal made it 9–0 over Thailand, a team the U.S. thoroughly dominated in its opening World Cup match on Tuesday. The Americans eventually won 13–0. But, rather than being praised for setting a World Cup record for scoring the most goals in the tournament’s history and securing the largest margin of victory ever, the win turned into a debate about sportsmanship.

Instead of Team USA being celebrated for what its players achieved, the victory became an opportunity to lecture these women on how to behave. That lecture is all the more galling given that, in March, the team filed a gender-discrimination lawsuit against the U.S. Soccer Federation. The women are fighting, in the courts, for equal pay and respect—and, on the field, for the right to pummel their opponents and express themselves in a way that men often do.

“Either way, people are going to say something,” the former women’s national-team forward Sydney Leroux Dwyer told me in a text message. Dwyer won the World Cup with Team USA in 2015. “You celebrate, you’re rubbing it in their faces,” she wrote. “You don’t, and you’re entitled or cocky.”

True to form, many commentators who saw the U.S.-Thailand game chided the Americans for gloating. Jim Toth, a radio host for the Canada sports network TSN, tweeted: “I’m not opposed to the number of goals. I am disgusted by the celebrations after 8 though.”

Former national-team member Hope Solo, who was the U.S. goalkeeper for 16 years and won a World Cup with the team in 2015, wrote in a guest column for The Guardian: “You do want the game to be celebrated and you do want to see players having fun, but at the same time I thought some of the celebrations were a little overboard.”

The ESPN soccer analyst Taylor Twellman also weighed in on Twitter: “0.0 problem with the score line as this [is] THE tournament BUT celebrating goals (like #9) leaves a sour taste in my mouth like many of you. Curious to see if anyone apologizes for this postgame.”

Well, no one apologized. Nor should anyone have. It isn’t the U.S. national team’s job to spare Thailand from humiliation—especially when, in this phase of the tournament, the differential between goals scored and goals allowed can determine whether a team advances. Considering that Alex Morgan tied a tournament record with five goals, and Morgan’s teammates Sam Mewis and Rose Lavelle each scored the first World Cup goals of their careers, this team had every right to celebrate as it wanted.

“You spend your entire life trying to get to a World Cup,” Dwyer wrote, “and you get there and you’re supposed to tone it down and make people more comfortable?”

Female athletes are often judged differently than male athletes when it comes to expressing emotions on the field of play—whether it’s in exuberance or anger. In 1999, Brandi Chastain hit a penalty kick in the World Cup Final that not only sealed the tournament for Team USA, but led to the most iconic moment in U.S. women’s soccer history. After making the kick, Chastain infamously whipped off her jersey and celebrated in her sports bra. Some considered Chastain’s celebration to be in poor taste, even though there were countless examples of bare-chested male soccer players in the same victory pose.

The behavior police don’t just stick to soccer. If the tennis star Serena Williams is visibly upset with her performance, she isn’t perceived as being competitive, but moody. Earlier this month, the men’s player Dominic Thiem said Williams had a “bad personality,” because he was told to leave the main interview room at the French Open to accommodate Williams, who was in a rush to leave after suffering a surprising loss to Sofia Kenin in the third round.

It’s doubtful Thiem would have said the same about Roger Federer.

Last year, Williams was subjected to a mountain of criticism for calling the chair umpire Carlos Ramos a “thief” during the U.S. Open’s women’s final. Ramos made the unprecedented decision to levy a game penalty against Williams for verbal abuse. In all, he penalized Williams three times during the match.

Meanwhile, men’s players often have testy exchanges with officials without being penalized on the spot. Andy Murray kicked a ball toward an umpire’s head at the 2016 Cincinnati Masters in Ohio, and all the umpire did was glare and move out of the way. Federer, who said Williams “went too far” by calling the umpire a “thief,” blew up at an umpire at the 2009 U.S. Open: “Don’t tell me when to be quiet, okay? When I want to talk, I’ll talk,” he said. “Don’t fucking tell me the rules,” he added.  

Federer was fined $1,500 for swearing at an official. Instead of clucking at Federer’s poor sportsmanship, a story in The Telegraph characterized the outburst as a competitive turning point. That same U.S. Open, Williams received a $10,000 fine for berating a line judge.

When men curse and yell at officials, they’re just showing how much they care about the game. Imagine if a woman behaved as Mario Vilella Martínez did at an ATP Challenger event earlier this week.

The shameful part is that how the U.S. women’s soccer team celebrated on the field will cause more of a stir than whether the players are paid fairly. Despite having won three World Cup titles, earned four Olympic gold medals, and generated millions of dollars more in revenue than the men in 2015, the women sometimes earn 38 percent of what the men earn per game.

In fact, the 13 goals the women scored were more than the men have tallied in every World Cup appearance since 2006 combined. So if anyone deserved to celebrate on their own terms, it’s these women.



As I check out of a hotel, various excuses race through my head for not tipping the housekeeper. I’m in a big rush. I don’t have cash. Will the maid who folded my clothes get the money? Why can’t I just add a gratuity to the credit-card bill and expense it?

About 70 percent of hotel guests go through the same mental exercise and end up not leaving a tip. A waiter would have to spit in your soup, and you would have to see him do it, to stiff him. Housekeepers are stiffed every day. I’ve heard every reason why guests treat hotel workers so differently than other service workers, but I’ve not heard a good one.

I have more than a passing interest in the subject. For 10 years, my grandmother, Nellie O’Connor McCreary, was a maid at the Hotel Washington, now the W Hotel. If you lean over the railing of its rooftop bar after a drink or two, you’d swear you could see the Oval Office.

She would never see that bar, and I would never have seen below stairs, if it weren’t for living with her in a two-bedroom bungalow during summers when I was interning in Washington, D.C. It was a perfect situation: I didn’t always get along with my mother, and she didn’t always get along with her daughter, but we got along perfectly well with each other. Besides that, the room was free. So were the stories.

One in particular left an enduring impression. At one of our weekly dinners after work at Reeve’s Bakery near the hotel, my grandmother pulled out some crisp 10s, a tip she’d received after a week’s stay from Clare Boothe Luce, the author, ambassador, and congresswoman, and a regular guest until she moved to the Watergate when it was a building, not a metaphor, in the mid-1970s.

The feminist author of The Women treated my grandmother, a fellow Catholic and a Roosevelt admirer, like an Irish maid from central casting climbing the housekeeping ladder rather than someone making beds for minimum wage. Despite the misconception, and Luce’s admiration for Nixon, they got along.

Luce was opposed to freeloaders and thought others should tip like her. She had an idea: have each maid leave a note on a nice card next to the mint on the pillow, hoping the stay had been pleasant, and wait for the tips to pour in. Luce then jotted down a note Nellie should deliver to management, co-signed by her “colleagues,” asking for a line to be added to the bill for a gratuity, like the one that exists for waiters.

The comparison to waiters was apt; they earn a mean annual wage of about $30,000, and housekeepers, about $25,000. To make her point, the patrician playwright reenacted her daily encounter with room service. The floor waiter (usually a he) rolls a breakfast cart into the room, removes the silver dome, and then dawdles while your poached eggs congeal—unfolding the napkin with a flourish, taking the paper hat off the orange juice, refolding the napkin—to give you time to add a gratuity on top of the automatic one of 18 percent.

He then goes off, leaving behind a mess. On the same principle that no one washes a rented car, few guests clean up after eating. So the housekeeper (it’s usually a she) will stack up the dishes, put the cart in the hallway, clean up the toast crumbs, and then proceed to the rest of her work of stripping the beds, picking up the supernumerary pillows on the floor, wiping the butter stains off the remote, and leaving the bathroom, now with coffee spills, gleaming. Not to begrudge waiters their tips, but why does he get two lines on the bill and the housekeeper gets none?

My grandmother’s reenactment of the reenactment didn’t mean she would do anything about it. You might as well have asked her to scale the Washington Monument and write an essay about it. But her admiration for Luce was less a response to her grand plan than to the attention paid. The hotel job wasn’t necessarily a step down from her prior employment, but it was a world apart from working as a nurse’s aide for 20 years at St. Elizabeth’s, a federal psychiatric hospital overlooking the city.  She became invisible, interacting primarily with a mop. There was no one to pull up for a dance, no one to get to sit down, no one much at all. The first rule of Housekeeping for Dummies is, Do not speak to a guest unless spoken to first.  

It would take decades before someone else would look at a housekeeper and see a wrong to be righted. Maria Shriver, the founder of A Woman’s Nation, wasn’t inspired by a family member scouring bathtubs but by the sight of housekeepers—mostly minority, many immigrants—working like borrowed mules with an 80-mile or more commute in the several hotels she stayed in after separating from Arnold Schwarzenegger in 2014. There were no Cinderella stories where a maid on the eighth floor was invited to train for a job on the first. It’s a job where a girl could use a tip.

The former first lady of California got a meeting with Arne Sorenson, the CEO of Marriott, the largest hotel chain in the world, and persuaded him to promote tipping with a catchy Hollywood name, “The Envelope Please.” Marriott placed packets in 160,000 rooms with space for the housekeeper to write a message next to the hotel’s about how “our caring attendant’s hard work is many times overlooked.”

The effort could be filed under No good deed goes unpunished, a phrase, incidentally, perhaps coined by the playwright Luce. Instead of money, the envelopes were stuffed with notes asking why a multibillion-dollar corporation didn’t pay its help a living wage, memorialized in this Fortune headline: “Marriott to Hotel Guests: Please Pay Our Maids for Us.”

That’s why the second-largest chain would barely touch the subject. The Hilton spokesman Nigel Glennie told me that the Marriott experience was the first thing he was warned about when he joined the company. “The custom and practice of tipping is very local,” he said, “and with Hiltons in 113 countries and territories” there would be no way to standardize it. But, he added, “there’s nothing stopping you or me from leaving a gratuity beside the bed.”

But there is something stopping people, and the hospitality industry knows it. Why else do hotels already have a line for waiters and, at their resort properties, have some added one for housekeeping?

Props to Marriott for effort, but now, like other hotels, it’s going in the opposite direction. The industry has launched a program purporting to save the environment; it has the perhaps not wholly incidental benefit of allowing hotels to slash their spending on housekeeping, their largest labor cost. First, they enticed guests to save the environment with a “green” option, whereby guests could opt to not have their sheets laundered every day. With guests softened up, hotels shifted to a purely self-serving marketing gambit, still with “green” in its name, offering reward points or other perks for giving up housekeeping altogether. It cost the industry virtually nothing. Housekeepers, though, wound up with an estimated 350 fewer full-time jobs, 700,000 fewer hours, and rooms left untended for as long as three days to shovel out.

Enter Unite Here, the largest hospitality-workers union in the country. It hopes for tips and respect for all of its 270,000 workers but gave up counting on that, or a living wage, in 2018. With the motto “One job should be enough,” workers embarked on the largest multi-city strike in history, walking out of 23 properties in eight cities, from the St. Francis in San Francisco to the Ritz-Carlton in Boston.

It was a big risk for the union: It’s always harder to keep workers without a paycheck striking than it is for management filling in for them to make beds badly. One of the tropes that keeps maids down is that we all can do housework, we just don’t want to.

In a matter of weeks, Marriott offered varied settlements, on average about $4 an hour over four years, as well as more full-time jobs with predictable shifts. For a moment, housekeeping gained a priceless degree of public visibility and appreciation, by way of wet towels, funky smells, angry guests, and canceled conventions. It is the industry’s lowest-paid employees who, one day at a time, make a hotel a home.

In 1980, my grandmother retired for a second time, moving to a house in Pennsylvania near my parents. Positions reversed, she visited me (and her great-granddaughter) and only asked that I keep her stocked with the right colors of thread for her project to embroider 50 state flowers on 50 pillowcases, along with Murphy’s Oil Soap and a box for donations to Goodwill. A week and my house looked like Marie Kondo had come for a stay.

When she died in 1985, she left a box in her chest of drawers with postcards from Luce and the letter she composed. My grandmother left me with an appreciation for a well-ordered house, a family who kills at Jeopardy when the category is state trivia, and so much more.

When I checked out of the Sheraton in March, I left a 10, as my grandmother said to do, on the counter in the bathroom and not under the pillow like a piece of wedding cake where it can get lost. I might stiff a waiter if he spit in my soup, but never a maid, no matter that voice in my head as I check out. That’s for management to do. To Nellie and her colleagues: Thank you for your service.  



Late in May, the Louvre closed. The museum’s workers walked out, arguing that overcrowding at the home of the Mona Lisa and the Venus de Milo had made the place dangerous and unmanageable. “The Louvre suffocates,” the workers’ union said in a statement written in French, citing the “total inadequacy” of the museum’s facilities to manage the high volume of visitors.

Half a world away, a conga line of mountaineers waited to approach the summit of Mount Everest, queued up on a knife’s-edge ridge, looking as if they had chosen to hit the DMV at lunchtime. A photograph of the pileup went viral; nearly a dozen climbers died, with guides and survivors arguing that overcrowding at the world’s highest peak was a primary cause, if not the only one.

Such incidents are not isolated. Crowds of Instagrammers caused a public-safety debacle during a California poppy super bloom. An “extreme environmental crisis” fomented a “summer of action” against visitors to the Spanish island of Mallorca. Barcelona and Venice and Reykjavik and Dubrovnik, inundated. Beaches in Thailand and Mexico and the Philippines, destroyed. Natural wonders from the Sierra Nevadas to the Andes, jeopardized. Religious sites from Cambodia to India to Rome, damaged.

This phenomenon is known as overtourism, and like breakfast margaritas on an all-inclusive cruise, it is suddenly everywhere. A confluence of macroeconomic factors and changing business trends have led more tourists crowding to popular destinations. That has led to environmental degradation, dangerous conditions, and the immiseration and pricing-out of locals in many places. And it has cities around the world asking one question: Is there anything to be done about being too popular?

Locals have, of course, complained about tourists since time immemorial, and the masses have disrespected, thronged, and vandalized wonders natural and fabricated for as long as they have been visiting them. But tourism as we know it was a much more limited affair until recent decades. Through the early 19th century, travel for personal fulfillment was the provenance of “wealthy nobles and educated professionals” only, people for whom it was a “demonstrative expression of their social class, which communicated power, status, money and leisure,” as one history of tourism notes. It was only in the 1840s that commercialized mass tourism developed, growing as the middle class grew.

If tourism is a capitalist phenomenon, overtourism is its demented late-capitalist cousin: selfie-stick deaths, all-you-can-eat ships docking at historic ports, stag nights that end in property crimes, the live-streaming of the ruination of fragile natural habitats, et cetera. There are just too many people thronging popular destinations—30 million visitors a year to Barcelona, population 1.6 million; 20 million visitors to Venice, population 50,000. La Rambla and the Piazza San Marco fit only so many people, and the summertime now seems like a test to find out just how many that is.

The root cause of this surge in tourism is macroeconomic. The middle class is global now, and tens of millions of people have acquired the means to travel over the past few decades. China is responsible for much of this growth, with the number of overseas trips made by its citizens rising from 10.5 million in 2000 to an estimated 156 million last year. But it is not solely responsible. International-tourist arrivals around the world have gone from a little less than 70 million as of 1960 to 1.4 billion today: Mass tourism, again, is a very new thing and a very big thing.

Business trends have also contributed to turning paradise to paradise lost. Cruise vacations are vastly more popular than they once were, with the diesel-belching vessels disgorging thousands of passengers at a time onto port towns. Supercheap airlines using satellite airports have dramatically cut the cost of hopscotching around Europe, the Americas, and Asia, encouraging travelers to take 1 billion flights on budget airlines every year. And platforms such as Airbnb have increased the supply of rentable rooms in cities from Rio to Delhi, reducing search friction for travelers, boosting cities’ carrying capacity, and bumping up rents for existing residents—an estimated 4 percent in Barcelona, for instance.

Social media are at work, too, with apps such as Instagram leading tourists to pitch over cliffs and clog vital roadways in search of the perfect pic, and sites such as Yelp and TripAdvisor making restaurants, museums, and beaches discoverable and thus ruinable. Overtourism itself is a media phenomenon as much as it is anything else. The word catapulted into common use in 2017, with wall-to-wall coverage of the problems in Venice, Bali, and elsewhere helping to drive the global backlash against tourists as well as the backlash to the backlash.

As for the backlash to the backlash: Some concerns about overtourism seem enormously overblown, and many local complaints about visitors are shot through with classism and racism. The majority of tourist destinations have no problem with the number of visitors they receive—would it even be possible for Orlando or Vegas to be over-touristed, logistically or spiritually? Travelers and their foreign direct investment remain a vital lifeblood for tiny Italian towns and big American parks and thousands of places in between. And while many sites are inarguably overcrowded, very few cities and towns are; the problem is mostly one of beaches and blocks and buildings, not of neighborhoods or regions.

There’s too much of a good thing in some of these spots, and mayors and city councils are doing their part to take it away. A number of places have implemented or expanded or proposed tourist taxes, among them Amsterdam, Bali, Edinburgh, Ireland, Rome, and Venice. These levies on hotels and day trips both reduce the number of visitors to a given place and provide it with revenue to improve infrastructure and defray the damage that tourists inevitably cause. Governments are also rolling out regulations, such as bans on tour buses in Rome and gating-and-ticketing in Barcelona. Those kinds of measures stand to become more important in the coming years, as the global middle class gets bigger, social media more ubiquitous, and travel cheaper.

These phenomena inevitably mean more complaints from locals, and more damage and lines and selfies and bad behavior. But they also mean more cross-cultural exposure, more investment, more global connection, more democratization of travel, and perhaps more awe and wonder. Even overtourism has its upsides.



President Donald Trump despises “fake news.” The Washington Post, The New York Times—these are “enemies of the people.” He has urged the Federal Communications Commission and the Federal Election Commission to force Saturday Night Live off the air to punish the comedy show for making jokes about him.

What he likes are independent and honest voices who say things such as: Vaccines cause autism. President Barack Obama’s birth certificate is a “carefully crafted fake.” Democratic Party insiders organized the murder of a staffer to cover up their nefarious plan to blame Russia for the hack of their emails. Sharia police are enforcing sharia law in Minneapolis. The Sandy Hook massacre never happened; the dead children were paid actors. (These are all false claims.)

After Facebook on Friday banned far-right figures and organizations from their platform, including the site Infowars, the president threatened to “monitor” social-media sites in retaliation. Through much of the late evening of May 3 and early morning of May 4, the president used his Twitter feed to champion the people who earn a large living spreading false reports. He hailed them as conservative thinkers whose free-speech rights have been abridged by social-media platforms.

One thing at least will follow from the president’s Twitter campaign: It will become even more difficult than before for the shamefaced remains of what used to be mainstream conservatism to separate themselves from these grifters, racists, and liars. According to the president, they are now martyrs, saying things that deserve to be heard. There have been times in the past few years—especially during the hoax to shift blame from the Russians for hacking the Democratic National Committee—that Fox News and Infowars blurred into each other. Those days will now return.

Yet even as the president engrafts conspiracists and racists onto mainstream conservatism, it’s worth wondering: Why is he starting this fight? What does he hope to accomplish? In the past, when presidents publicly criticized major corporations by name, they got results.

In April 1962, President John F. Kennedy criticized, at a White House press conference, “a tiny handful of steel executives whose pursuit of power and profit exceeds their sense of public responsibility.” Kennedy was angry about steel-price increases that he regarded as inflationary. He spoke even more harshly in private, calling the executives “bastards” and “sons of bitches.” Within 48 hours, the price increases had been rescinded.

In June 2010, a ruptured deepwater rig spilled millions of barrels of oil into the Gulf of Mexico. President Obama described the spill as the “worst environmental disaster the United States has ever faced.” He vowed that the owner of the rig, BP, would pay for whatever damage had been done; $20 billion was ultimately collected from the oil company.

But what happens if Facebook … just ignores the president? Facebook—long the premier channel for distributing hoaxes, scams, and Russian propaganda—seems to have made a business decision to clean up its act. Or at least begin to clean up its act. Perhaps presidential pressure will change Facebook’s mind. Or perhaps Facebook will calculate: Trump’s agitation will be forgotten by tomorrow. He’ll move on to the next thing. He’s just venting. He never follows up.

One observer of social media speculates that Trump hopes to deter Facebook from enforcing its rules against him and his 2020 campaign. In that case, wouldn’t Trump fight on the strongest ground, not the weakest? Identifying “my team” with some of the worst characters on the internet seems a prelude not to a hard fight, but to an embarrassing retreat.

Instead of preparing for a trial of strength against a corporation that a president should easily win, he has joined his personal brand to a gaggle of shady characters in an outburst likely to be forgotten in a day or two. Or, at least, forgotten by him.

But other and more determined actors are “monitoring”—and monitoring more attentively and persistently than the president himself. Trump’s Twitter rampage coincided with a North Korean missile test. For months, Trump has been touting the suspension of North Korean missile testing as proof that his concessions to that dictatorship delivered results. By resuming the testing, the North Koreans were administering a calculated humiliation to Trump, gambling that they can extract more from a president who talks tough in international relations, but acts weak. Now Facebook has set him a test of strength at home.

Trump has staked the prestige of the presidency on a gang of bad actors with shady histories who use social media to profit from deceit and the inflaming of racial and religious hatred. They are his supporters, after all, and he does not have so many to lose. But now Trump needs a win. North Korea is watching, and so are even more serious world actors.

The Washington Post reported that foreign governments have learned to shrug off Trump’s bluster and tough-guy talk. “He has shown us that what’s black at 9 a.m. can be gray at 3 p.m. and white at 7 p.m.,” said a Mexican diplomat of the president’s revolving pronouncements.

Past presidents spoke. Trump just … talks. Trump’s racist, conspiracist con-artist friends may be about to learn that sad difference firsthand too.

This article is part of “The Speech Wars,” a project supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press, and the Fetzer Institute.



One common knock on President Donald Trump is that he is chronically dishonest. Another is that he is a fickle leader who cannot or will not focus on any particular topic for any extended period of time.

Both are true. But when it comes to border security, neither of these critiques really applies. Trump’s announcement of escalating tariffs on all goods from Mexico until illegal immigration stops is a desperate move. The sources of that desperation, though, are his determination to keep his promise to secure the border and the fact that despite trying constantly to make good on his vow, more than two years into his presidency, he still can’t figure out how.

Trump, as I’ve noted, has been remarkably consistent on border security, going back to his June 2015 campaign announcement, which prefigured the current situation: More Mexicans are now leaving the United States than entering, but people continue to stream north from farther south.

“It’s coming from more than Mexico,” Trump said. “It’s coming from all over South and Latin America, and it’s coming probably—probably—from the Middle East. But we don’t know. Because we have no protection and we have no competence, we don’t know what’s happening. And it’s got to stop, and it’s got to stop fast.”

The solution, Trump said, was simple. All it would take was a little common sense, and getting the right person in place. If only there were a president who was willing to be tough on immigration and implement the obvious policies, illegal immigration could be stopped. For more than two years since becoming president, Trump has tried to prove that he was right. He has instituted a long string of policy ideas that he thinks will prevent migrants from entering the United States, and each has—for its own reasons—failed.

The first big idea was one that Trump unveiled in that campaign launch. “I would build a great wall, and nobody builds walls better than me, believe me. And I’ll build them very inexpensively. I will build a great, great wall on our southern border,” he said. “And I will have Mexico pay for that wall.”

Predictably, Mexico did not agree to pay for the wall. Trump then said he’d try to force it to do so through a remittance tax, taking a cut of all money that Mexicans in the United States sent back home, but he eventually stopped talking about that—it was unclear that it would raise enough money, or that it would be workable or legal. Having effectively conceded that Mexico wouldn’t pay for the wall, Trump then tried to get Congress to do so.

Nearly as predictably, Congress did not agree to pay for the wall either. When Republicans controlled both houses of Congress, GOP leaders were reluctant to cough up the cash. Trump, for reasons that remain unclear, decided not to push them on it. Then came the 2018 midterms and the Democratic takeover of the House. He decided to get tough only then, forcing a government shutdown for more than a month, from December 2018 to January 2019.

Trump eventually blinked. Then he announced plans to pay for wall construction by reprogramming already allocated funds under a national-emergency declaration. While some of those moves seem straightforward, others are of questionable legality and tied up in litigation. And even if Trump were to succeed in court, these measures would pay for only a small portion of the wall. Ultimately, he will need Congress.

With wall construction on ice, Trump has tried a variety of other measures to stem the flow of migrants across the southern border. He dispatched thousands of troops to the border, but under the U.S. laws the president invoked, the military can’t enforce immigration laws, so instead service members went to the border, assisted with some construction, and then sat around bored and hot for a few weeks before being withdrawn.

The law has, in fact, proved a powerful constraint on Trump’s border plans. The administration infamously decided to separate children from parents arriving at the border, but was pounded by both public opinion and the courts; meanwhile, there’s little evidence that the move had the intended deterrent effect. Trump has attempted to reshape asylum laws in a variety of ways, though those efforts, too, have been caught up in court, since the president can’t unilaterally change asylum laws passed by Congress. Trump reportedly told border agents to block asylum seekers, contrary to the law, and promised that if they were prosecuted, he would pardon them. (No one seems to have followed this advice.) Trump has also threatened to close crossings, but has been talked out of it by aides.

Now comes Trump’s latest move, the 5 percent tariff, which could rise over time if Mexico doesn’t comply. It’s a more modest version of an earlier threat to levy a 25 percent tariff on all Mexican goods, but it has still created chaos. U.S. companies are scrambling to figure out how to deal with the tariff, Republican lawmakers are critical, and Mexico is responding with anger and defiance.

The revolving door of policy ideas, many of them obviously flawed, betrays Trump’s frantic desire to follow through on his immigration rhetoric. But the issue is not as straightforward as he promised on the campaign trail. He told the nation that securing the border would be simple, but he was ignorant of both the challenges at the border and the legal constraints any president would face in achieving that goal. He has discovered too late that immigration is actually a challenging problem. He insisted that all that was needed was a president committed to solving the situation, but he has discovered that the president of the United States doesn’t have the unilateral power he imagined. He has hired and fired new border officials—he has now nominated his third secretary of homeland security, and has replaced a long list of lower-ranking officers—but that hasn’t solved the situation either.

There is the chance that the tariff (or some other trick) will actually succeed, but the prospects seem dim. Agreeing to Trump’s demands would likely be politically untenable for Mexican President Andrés Manuel López Obrador. Even if it were not, it’s unclear how much ability López Obrador has to stop illegal immigration through Mexico. After all, the American experience shows that border security is not so easy—especially without resorting to violence or inhumane tactics. It’s not even clear what would count as success in Trump’s view; his declaration says that Mexico must “dramatically reduce or eliminate the number of illegal aliens crossing its territory into the United States,” without naming quantitative targets.

There are, in fact, probably ways to secure the border, but they are not simple or obvious. Instead of Trump issuing ultimatums to Congress or Mexico, they would require him to negotiate. He could attempt to pass a comprehensive immigration bill through Congress that would overhaul the system while also getting him money for a border wall. (Senate Minority Leader Chuck Schumer has floated such a deal before.) Or Trump could work out a deal with López Obrador.

But Trump would have to give something up to get what he wants. He tends to see every discussion as zero-sum, and he is a terrible negotiator. Instead, Trump continues to search for a simple, magical solution that will allow him to keep his promise—even with none in sight.



Ralph Waldo Emerson once famously said that “a foolish consistency is the hobgoblin of little minds.” If so, then as a lawyer committed to the rule of law, I confess to having a little mind, though I like to think my consistency is not foolish.

Earlier this week, I signed a letter (along with a growing number—now more than 600—of other former federal prosecutors) expressing the view that the facts recounted in Special Counsel Robert Mueller’s report to Attorney General William Barr were in many cases (the letter lists three) sufficient to have warranted criminal charges against President Donald Trump for obstruction of justice. For me, the question was one of intellectual consistency. Having held President Bill Clinton to this standard 20 years ago, I could not, in good conscience, decline to apply the same standard to President Trump.

Call it, if you will, the Betty Currie test.

Currie was Clinton’s personal secretary. (For The West Wing fans, she was his Mrs. Landingham.) And Clinton, of course, was suspected of having had a sexual relationship with one of his interns, Monica Lewinsky.

On the day after he first became aware that his relationship with Lewinsky was under scrutiny, Clinton called Currie into work (it was a Sunday). And when she arrived, he said to her, “There are several things you may want to know,” and then proceeded to make several statements, in the form of “questions” to Currie. Referring to Lewinsky, Clinton said:

Viewing this evidence, Independent Counsel Ken Starr (for whom I then worked) told Congress that there was “substantial and credible” information that the president had endeavored to obstruct justice by attempting to influence the testimony of Currie. Though the president testified that his interaction with Currie was an attempt to refresh his own memory, we had no problem concluding that his explanation was not plausible. We concluded that the most reasonable inference was that he was attempting to enlist Currie to testify falsely about the true nature of his relationship with Lewinsky.

This vignette from the investigation of Clinton illuminates my conclusions today and is instructive for a number of reasons.

First, some, such as Barr, have argued that the obstruction case against Trump is weak because there was no underlying criminal behavior. If, they argue, there was no criminal conspiracy in the contacts between the Trump campaign and Russians, then there is no obstruction in covering up the noncrime.

While it is true that the absence of an underlying crime makes proving a corrupt motive harder for a prosecutor, it is absolutely clear under the law that one can obstruct justice out of other motives, such as fear of embarrassment or political condemnation.

And that’s exactly what happened with Clinton—his underlying actions involved a sexual relationship with an intern that was, by itself, exceedingly unsavory, but it wasn’t criminal. I was of the view then, and remain of the view now, that this should not matter. Quite the contrary: Respect for the rule of law means respect for, and adherence to, the processes of law. It means not lying and not suborning others to lie for you. And that obligation falls, in my judgment, even more strongly on the president, who takes an oath to uphold the law.

And so, if Clinton should have been held to account for trying to get Currie to lie for him about Lewinsky, then, by the same logic, Trump must be held to account for (to take but one example from the Mueller report) asking his White House counsel, Don McGahn, to lie for him about Trump’s intent to fire Mueller. It doesn’t matter that Trump was asking McGahn to lie because of his political fears, and it doesn’t matter that the ultimate issue of Russian electoral interference never matured into a criminal charge against the Trump campaign.

Second, the comparison is telling in another way. Say what you will about the investigation of Russia’s connection to the Trump campaign; there can be no doubt at all—none whatsoever—that the possibility of Russian interference in our election system is a matter of grave significance to our democratic institutions. Far more so than, say, the president’s sexual activities. I never accepted the argument that “lying about sex” isn’t a crime—but even if I did, I would not accept the argument that “lying about an investigation of Russian electoral interference” isn’t a crime. If only for comparative reasons, anyone who supported obstruction charges in the Clinton era must acknowledge the greater salience of the issues at the core of this Trump-era investigation.

Finally, the Clinton story also tells us that another of Trump’s defenses is likewise meritless. Some have said that his effort to obstruct justice isn’t criminal, because he didn’t succeed. McGahn, for example, refused to create a false record and refused to lie for him.

But again, the same is equally true of the Clinton investigation. We know that Clinton tried to persuade Currie to lie because, ultimately, Currie told us that story in her personal testimony. The fact that she didn’t follow his lead (at least not fully) does not excuse the effort. And today we know about the effort to suborn McGahn’s false testimony because McGahn has told us of it. If Clinton’s lack of success was no defense, then Trump’s should not be either.

I could go on. In the end, though, the comparison to Clinton’s investigation and impeachment does Trump no favors. If you continue to think that Clinton was derelict in his actions, violative of his oath of office, and deserving of condemnation for his criminal activity, as I do, you can say no less about Trump.

Perhaps that consistency means I have a “little mind.” I prefer to think that I have the courage of my convictions, and I’m honored to join others who have served the American public in saying what I think. President Clinton failed the Betty Currie test; so has President Trump.



During the 2016 campaign, Hillary Clinton often warned that Donald Trump would do to the United States what he had done to his businesses.

She was thinking of his record of debt, failure, and bankruptcy—about which The New York Times offered grim new details this week.

But there is an even more disturbing way that Clinton’s warnings are being fulfilled. North Korea has resumed missile testing, disregarding both Trump’s wooing and his threats of “fire and fury.” It has taken the U.S. president’s measure—and found him weak and empty.

The Times story of the tax returns showed how stock markets did just the same thing in the 1980s. From 1986 to 1989, Trump earned $67.3 million from short-term stock speculation. His method? He would acquire a substantial position in a company, then boast of his takeover intentions. Trump’s words would drive the stock price up. He would then sell at a profit.

The trick worked as long as Trump’s credibility lasted. Which was not long.

In September 1989, Trump tried that familiar trick once too often. He bought a large stake in American Airlines, talked takeover—and was jeered:

“I’m very skeptical of everything this man does,” Andrew Geller, then an airline analyst at Provident National Bank in Philadelphia, told The Associated Press.

Mr. Trump was rebuffed, and the stock price fell sharply. Though at the time his losses were reported to be modest, the new tax return figures show that in 1990, the year he sold his American Airlines stake, Mr. Trump lost $34.9 million on short-term trades, wiping out half his gains from the previous four years.

In the 1980s, Trump was burning through his own money. As president, he’s playing with the wealth and lives of nations. That greater responsibility has not in any way improved his behavior. Greater power has also only temporarily restored his credit. The North Koreans see through him on missile testing. Now the Chinese seem to be doing the same on his trade threats. Trump’s current round of trade threats is failing to elicit trade concessions.

U.S. stock markets slumped Tuesday. Markets had been expecting a trade agreement this week, and were taken by surprise by a suddenly harder Chinese line. A new round of U.S. tariffs is scheduled to go into effect Friday unless a deal is reached. China balked at U.S. proposals, and Trump returned to Twitter for another round of threats. But those threats also revealed Trump’s fears. He wanted to score a domestic political point off his freer-trade Democratic rivals. But he showed international leaders how worried he is that trade disputes might cost him reelection:

The reason for the China pullback & attempted renegotiation of the Trade Deal is the sincere HOPE that they will be able to “negotiate” with Joe Biden or one of the very weak Democrats, and thereby continue to ripoff the United States (($500 Billion a year)) for years to come ….

The big question in a trade dispute is which side can stand more pain. At the same time as Trump has threatened China, he has pleaded with the Federal Reserve to cut interest rates. The Chinese have noted the juxtaposition. The Wall Street Journal quoted an analyst at a Chinese government-backed think tank: “Why would you be constantly asking the Fed to lower rates if your economy is not turning weak?”

The world is absorbing the lesson that Wall Street learned in the 1980s. Trump has only one negotiating move: Take an aggressive position, try to deceive others and maybe yourself about your own strength, issue threats you cannot fulfill, and then retreat amid losses if the bluff is called.

But whereas once those losses were denominated in the millions, today they rise to the hundreds of billions. Where once he troubled only those investors credulous enough to take seriously his tycoon image, today he troubles the peace of the world.



To former Vice President Joe Biden’s benefit, electability has become the unofficial buzzword of the 2020 presidential campaign.

Although it’s still early, most polls show Biden as the clear front-runner among Democrats. A CNN/Des Moines Register/Mediacom poll was just the latest to give him a solid lead. Among Iowa’s likely Democratic caucus-goers, 24 percent named Biden their first choice for president—a significant lead in a fractured field that has more than 20 candidates.

Biden’s early strength isn’t particularly surprising. He’s an experienced politician. And his service alongside former President Barack Obama has given him a priceless advantage. On Saturday, to celebrate “Best Friends Day,” Biden even tweeted a picture of bracelets entwining his first name and Obama’s—a not-so subtle reminder that the former vice president was a fixture of the good old days.

Nevertheless, Biden’s elevation to front-runner is a testament to how much President Donald Trump has shaken the faith of those who believe the White House could better reflect what America looked like.

This is perhaps Trump’s most crucial victory yet: successfully persuading Democrats—especially African American voters—not just to lower the bar, but to abandon the idea that inclusion and bold ideas matter more than appeasing the patriarchy.

More than likely, the Democratic nominee for president won’t be the person with the best and most progressive ideas, or the person most capable of galvanizing a fractured country. The nominee just has to beat Trump, even if the cost of that victory is reinforcing the idea that only an older white man is capable of getting this country back on track.

In a recent piece explaining Joe Biden’s early polling success, David Mark, a writer for NBC News’s digital site Think, wrote: “For starters, there’s Biden’s demographic edge in the primaries. Biden, 76 and white, broadly fits the profile of the Democratic electorate that will select the nominee.”

But older white Democrats aren’t the only ones who are bullish on the former vice president. In a Quinnipiac poll conducted in late April, 61 percent of nonwhite Democrats said Biden had the best chance of beating Trump.

Already many Democrats are cutting Biden much more slack than they’re giving other candidates. There is, for example, a double standard in how some African Americans judge the presidential candidate Kamala Harris—who was an Oakland prosecutor before becoming a U.S. senator from California—far more harshly than they judge Biden.

Harris has been criticized repeatedly by African Americans for her record as a prosecutor; many accused her of aiding a system that has disproportionately punished and targeted black people. There was even a hashtag created on Twitter, #KamalaHarrisIsACop, that her detractors employed to point out her failure to protect African Americans in the criminal-justice system.

Even though Biden wrote the 1994 crime bill whose mandatory-minimum sentencing rules sent many black men to prison, the former vice president’s support among African Americans remains significantly stronger than that of both black presidential candidates in the field—Harris and Senator Cory Booker of New Jersey. A poll released by BlackPAC last month showed that 72 percent of African Americans view Biden favorably, compared with 49 percent for Harris and 47 percent for Booker.

Remarkably, the negative energy directed toward Harris for serving as a prosecutor has not been aimed at Biden, who said recently that, although the “three strikes” provisions of the 1994 law were a mistake, the bill “had a lot of other good things.” While the explosion of mass incarceration was already in progress before the crime bill was signed, the legislation was still devastating for black and brown people. According to the U.S. Bureau of Justice Statistics, the black incarceration rate rose from 1,200 per 100,000 in 1985 to 2,450 per 100,000 in 2000. For black men in 2000, the rate was 3,457 per 100,000.

For many African Americans, who understandably feel particularly vulnerable in Trump’s administration, prioritizing a defeat of Trump over progress is a means of survival. Biden’s treatment of Anita Hill, questions about his handsy behavior with women, his opposition to marijuana legalization, the accusations of plagiarism, his flip-flop on supporting the Hyde Amendment, which bans the use of federal funds for abortion services—none of it has weakened Biden’s position.

Unfortunately, the lesson even Democrats have learned from Trump’s election is that certain voters are willing to tolerate anything if they believe in a candidate. Especially if that candidate is an older white man.



On March 24, Attorney General William Barr released a summary of the findings of Special Counsel Robert Mueller’s report that stressed positive news for President Donald Trump. The redacted text of the report would not be released until April 18, more than four weeks later.

Over those four weeks, Trump and his supporters made the most of their one-sided information advantage. They blared “No collusion! No obstruction!” They dismissed the connections between the Trump campaign and Russia as a “hoax.” They demanded punishment of those in government and media who had investigated and reported on those connections.

In retrospect, that was not a very smart thing to do.

The smart play would have been to pocket the legal win—no more indictments—and then try to rise above the controversy. The president could have given a speech analogous to the one President Ronald Reagan gave after being absolved of direct personal responsibility for Iran-Contra: Acknowledge mistakes, apologize for them, vow that lessons would be learned. Condemn the Russian interference in 2016, and vow to harden future U.S. elections against any repeat. Meet critics more than halfway, move forward, try to consign the controversy to the past.

But that is not the Trump way. The Trump way is to escalate, always.

Over the four weeks between the Barr letter and the release of the redacted Mueller report, Trump kept insisting that the Mueller report said more than it did. It said, in effect: We didn’t find sufficient evidence to charge your campaign with conspiracy, and our internal Department of Justice policies forbid us from charging you with obstruction. He wanted it to say: You did nothing wrong. He wanted it to say: Actually, Donald, you were the real victim here—and Hillary Clinton the true criminal conspirator.”

Trump has tried to close that gap by lying about it—and by demanding that other people lie, too. When they don’t and won’t, Trump gets angry. And when Trump gets angry, he takes to Twitter.

Trump got extra angry Sunday night. Uncheered by Mother’s Day, the president launched into a sequence of rage tweets that included the line: “The FBI has no leadership.” Trump has fired one FBI director, James Comey, for looking into the Russia matter. He fired an acting director, Andrew McCabe, for the same apparent reason. Apparently, he is now gunning for the present director, Chris Wray.

Why is Trump angry? Trump disjointedly tweeted over linked messages: “The Director is protecting the same gang…..that tried to……..overthrow the President through an illegal coup. (Recommended by previous DOJ) @TomFitton @JudicialWatch”

Trump wants the FBI to endorse his own theory of victimhood—and it won’t. Worse, the FBI was embedded in the Mueller investigation. The FBI received, and still holds, whatever information the investigation gathered about Russia’s interference in the 2016 election, including potential answers to the all-important question: Why? Why was Vladimir Putin so eager to help Trump into the presidency? Why did Russia care so much, and run such risks for him?

The answer may be indicated in an underappreciated pair of sentences on page 76 of Volume II of the Mueller report: “As described in Volume I, the evidence uncovered in the investigation did not establish that the President or those close to him were involved in the charged Russian computer-hacking or active-measure conspiracies, or that the President otherwise had any unlawful relationship with any Russian official. But the evidence does indicate that a thorough FBI investigation would uncover facts about the campaign and the President personally that the President could have understood to be crimes or that would give rise to personal or political concerns.”

So long as the FBI remains in independent hands, the president will remain gripped by those concerns.

What Trump means by leadership is compliance. He wants an FBI director who serves him personally the way Attorney General Barr has served him personally. So long as the FBI retains its integrity, Trump feels unsafe. He cannot close the case, because he keeps hearing scratching sounds from inside. He cannot move on, because he keeps looking back in fear. His next move? He’s already telegraphing it: another attack on the independence of law enforcement.

Trump today welcomed Hungarian Prime Minister Viktor Orbán to the White House. I keep thinking on this trip of the shrewd insight offered by a Budapest observer when I visited Hungary in 2016: “The benefit of controlling a modern state is less the power to persecute the innocent, more the power to protect the guilty.” Trump holds that power, and he is determined to wield it.



How many times can Donald Trump announce his 2020 campaign? At least five, by my count.

The president is traveling to Orlando, Florida, today for what news outlets are calling a rally to “officially” or “formally” launch his reelection bid. It’s hard to know what those adverbs mean. Not only is today not the first time Trump has said he was starting his campaign, but he never really stopped campaigning in the first place.

If anything was official, it came on January 20, 2017, when, within hours of his inauguration, Trump filed documents with the Federal Election Commission to run for reelection. By then, he’d already told The Washington Post about his slogan for the reelection campaign: “Keep America Great.”

Just 29 days later, Trump threw the first rally of his reelection campaign. It’s probably not a coincidence that that rally was also in the crucial swing state of Florida—in Melbourne, about an hour from Orlando. There’s nothing all that unusual about a president hosting a rally; what was unusual was that Trump was advertising and paying for the event through his campaign, a decision that perplexed campaign-law experts I spoke with at the time. Some presidents have opted to separate events that are baldly political from those that are more presidential, but Trump doesn’t bother with that. (See, for example, his attacks on Speaker Nancy Pelosi in front of graves at Normandy, or his swipes at Joe Biden while in Japan.)

The president continued to host sporadic campaign-style rallies over the next year. Then, in March 2018, while House Republicans were scrambling to hold back a Democratic wave, Trump decided to pitch in for the effort by … announcing his new slogan for the 2020 race. Only it was the same slogan he’d previewed to the Post in January 2017. (This did not prevent the media from dutifully reporting he had unveiled a new slogan.)

Two months later, in May 2018, Trump once again presented the slogan as a brand-new reveal. “By the way, this is the first, for Indiana,” he said. “Our new slogan for 2020. You know what it is? ‘Keep America Great.’ Because we’re doing so well that in another two years, when we start the heavy campaign, ‘Make America Great Again’ wouldn’t work out too well.” Reporters once again gave him credit for novelty. Six months later, Trump’s allies were whomped at the polls. Meanwhile, his reelection campaign has rolled on, with Orlando its latest stop.

When Trump went to Florida in February 2017, I identified the rally as an example of the “permanent campaign”—a notion dating to the 1980s and since ensconced, in which officeholders maintain some of the methods and tactics of the campaign while remaining in office, from rallies to poll testing. It’s a staple for every president now. Bill Clinton, the president most associated with the permanent campaign, had the earliest “official” launch in recent memory, according to NPR—but Trump will edge him by three days.

But labeling Trump’s rally a part of the permanent campaign turned out not to be prescient so much as an egregious understatement. The point of a campaign launch used to be to signal that the period of governing—of passing legislation and enacting policy—was largely wrapping up, and that the focus would shift back to electoral politics. In the permanent-campaign paradigm, a president would run a policy track and a politics track in parallel.

Trump has fully unified them. He can’t turn back to campaigning from governing, because he never really bothered to start governing in the first place. With the exception of cutting taxes and especially building a wall on the Mexican border, he’s never shown much interest in learning how the levers of power work or in using them. Whereas Barack Obama held rallies in early 2009 to support the passage of his health-care bill, Trump held rallies in early 2017 for the purpose of being reelected nearly four years later.

The problem with skating from crisis to crisis with few accomplishments to show for it is that eventually the public becomes fatigued. There are signs of growing public boredom with Trump. A newsy, blockbuster interview with George Stephanopoulos this past weekend drew disappointing ratings. The New York Times publisher A. G. Sulzberger has noted declining reader interest in political news. The president’s outlandish remarks generally make a smaller splash than they once did. He seems to have tried to compensate for that by tweeting more, but the result is something like inflation in a market flooded with currency: Every tweet is less valuable.

As the incumbent, Trump enjoys advantages he did not in 2016, but his most important political tool remains his ability to control the discourse. With other methods losing some potency, repeated campaign launches—aided by obligingly credulous coverage—are one way to generate attention. If today’s event draws enough coverage, maybe he’ll officially launch his campaign a few more times. But sooner or later, campaign launches will have to give way to new methods of attracting attention, which are likely to be less decorous than elaborate campaign rallies.



For the second time in two weeks, President Donald Trump interrupted a busy schedule of trashing Joe Biden to say nice things about the North Korean dictator Kim Jong Un.

But Trump’s decision, during remarks in Japan in May, to side with Kim over Biden was a brazen but unsurprising violation of the tradition that “politics ends at the water’s edge,” whereas his comments today were far more baffling.

Two accounts, a new book by the Washington Post reporter Anna Fifield and a Wall Street Journal story, report that Kim’s brother Kim Jong Nam was a CIA informant. Kim Jong Nam was killed in a shocking chemical-weapons attack in the Kuala Lumpur airport in February 2017. Trump was asked about the revelation as he left the White House for a trip to Iowa, and his answer was jarring.

“I see that, and I just received a beautiful letter from Kim Jong Un,” Trump said. “I think the relationship is very well, but I appreciated the letter. I saw the information about the CIA with regard to his brother or half brother, and I would tell him that would not happen under my auspices. I wouldn’t let that happen under my auspices. I just received a beautiful letter from Kim Jong Un.”

The first surprising thing here is that Trump gave no sign of having been aware of the story prior to the Journal report. He did not, however, dispute its accuracy. Given how personally involved the president has been in negotiations with North Korea, if the report is indeed accurate, it is hard to imagine he would have been in the dark. Perhaps Trump is simply playing dumb, though he doesn’t typically have much of a poker face.

American officials often avoid discussing sensitive stories like this with the press, and one reason for that caution became clear as Trump continued. The context of his remarks makes clear that what Trump “wouldn’t let … happen” is not Kim Jong Nam’s killing, but his cultivation as an American asset. Trump has said that former President Barack Obama described North Korea as the nation’s greatest foreign-policy challenge, and Trump has taken that cue, making it a major priority. By saying he wouldn’t allow American intelligence to cultivate an asset so close to Kim, he’s saying he wouldn’t use spying to better understand the country’s biggest overseas challenge.

Put another way, he’s ruling out having the best information possible headed into high-stakes negotiations. Tying one hand behind your back like this makes sense only if you have a messianic belief in your own negotiating prowess—which Trump does, despite the collapse of the most recent round of talks.

It might be a moot point, however, because by responding this way, Trump is sending a clear message to any would-be informants: The United States doesn’t have your back. Why would any other North Korean take the risk of ending up like Kim Jong Nam? If Fifield and the Journal are right, Kim Jong Nam’s assassination wasn’t just Kim killing his brother and rival; it wasn’t even just North Korea using chemical weapons in a foreign country. It was North Korea killing an American intelligence asset in the early days of the Trump administration, a test of the new president’s resolve.

Trump’s nonchalance is especially strange given that the United States expelled 60 Russian diplomats in 2018 in retaliation for Russia’s poisoning of Sergei Skripal and his daughter in Britain. Yet when an alleged American informant is killed, his response is not to warn North Korea not to act that way again, but to rush to assure North Korea that he won’t let such spying happen again.

The guiding principle of Trump’s interactions with Kim has been to try to flatter Kim’s ego and play the good cop, while allowing other members of his administration to take the hard line. Arguably, that paid off in getting Kim to negotiate, even though no deal has been struck. But it also risks letting Kim get away with heinous acts, because the risk of offending him is that negotiations will break off. Moreover, this incident shows it works both ways: Kim grasps the importance of flattering Trump, as with the “beautiful” letter he sent the president. A beautiful letter here, a beautiful letter there, and pretty soon the president of the United States is apologizing to you after a report that you killed an American informant.



Last week, the prime minister of New Zealand and president of France presented the Christchurch Call—a pledge to “eliminate terrorist and violent extremist content online.” Eighteen countries and all major tech companies signed up, but Donald Trump’s administration issued a statement declining to join them. Critics of the administration imputed the darkest of motives: It must oppose the pledge because it wants to make the world safe for violent extremists, perhaps especially the right-wing zealots who applauded the massacre of 51 people in Christchurch, New Zealand, itself two months ago.

You can read the Christchurch Call here. I defy you to find anything objectionable about it. It does not vilify particular religious or political beliefs; it mentions freedom of expression multiple times; it recognizes that terrorists will not disappear just because their Facebook accounts do or because their parents find out that they’ve been up to no good. Even the White House noted that “we support [its] overall goals,” and declined to say why the United States did not sign on. The office that issued the statement, the Office of Science and Technology Policy, referred me to the National Security Council, which did not offer any defense either.

So let me offer a defense for them.

The United States shares many values with France and New Zealand, but a common understanding of “freedom of expression” is not among them. And in their handling of terror threats, both countries have resorted to actions that are antithetical to the American understanding of the value of freedom of expression and would be flagrantly illegal under U.S. law. The Christchurch Call was written with deliberate, strategic vagueness, so that an expression like freedom of expression can be taken to mean whatever a signatory wishes it to mean. But that vagueness poses risks, and if there is any chance that signing on would make the U.S. seem to endorse a French or Kiwi version of free expression, we should stay away.

New Zealand has an Office of the Chief Censor. Take a look at his website; he often goes by his first name, which is Dave. Dave has the godlike ability to declare certain material “objectionable,” thereby making it illegal to produce, distribute, or watch—and he did just that after the murders in Christchurch. He classified as objectionable the live-video footage (an Islamic State–style commando raid against unarmed Muslims at prayer) and the killer’s manifesto, “The Great Replacement.” To read the manifesto for what he considers a “legitimate” reason—say, you are an academic who studies killers, or a journalist writing a story—you have to apply to Dave for permission and pay him NZ$102.20 (about U.S.$66) for his verdict.

France criminalizes not only the downloading of terror propaganda but the mere utterance of statements of approval for terror, which can land you in prison for seven years. Indeed, you need not even mention a terror attack: to say something nice about Osama bin Laden (“an epic beard”; “volleyball prodigy”) is, in the law, equal to saying something nice about terror. Penalties for these speech crimes grow if the speech is on the internet. In addition to imprisonment, a judge can make you pay 100,000 euros (about $112,000). Hundreds are convicted of this crime in France every year, according to Human Rights Watch, and 6 percent of those prosecuted are under the age of 14.

In the United States, you can watch terrorist videos, read their manifestos, and glorify their attacks all you like. The only price you will pay is total ostracism from the company of decent people. The protection guaranteed by the First Amendment, even in these days of hostility toward journalists by the Trump administration, extends comfortably over all of these sordid pastimes. In this near-absolute protection, the United States stands alone among nations—and given the constant calls, both internationally and domestically, to cut that freedom back, any suggestion that the United States should waver would be a sad concession.

This protection extends to the U.S. corporations that joined France and New Zealand in signing the Christchurch Call. Google, Facebook, Microsoft, and others also enjoy the absolute right to kick off any users they please, for almost any reason. It extends, too, to those corporations’ users and shareholders, who can say what they please about the corporations and stop surrendering their time and data to them if their sites become havens for the politically or religiously monstrous.

The best argument I have heard against the administration’s decision is from Farah Pandith, who worked for George W. Bush and Barack Obama and just published a book, How We Win, about countering violent extremism. “There are so many ways we have developed to push against terrorism—far more than criminalization of [extremist content],” she told me. “Being at the table for these conversations allow us to mold them as they go forward. By declaring that we’re not going to be there at all, we’ve blown any chance we’ve had.”

But the real value of the Christchurch Call was not government participation anyway. Governments already have programs to discourage terrorism, the most prominent of which is killing or capturing terrorists. The value was, instead, the participation of the social-media companies, whose policies’ influence online is at least as great as that of most governments. Anyone who watched the rise of ISIS five years ago will confirm that in those days, you could post just about anything, and major media companies would take weeks or longer to remove terrorist propaganda.

Now the life of an ISIS video is measured in fractions of a second. The companies have developed tools to identify and remove terror content—and they have done so not because of criminal prosecution in the United States, but because letting that content stand would have a devastating effect on their brand. I can’t find ISIS propaganda anymore, except in private groups on a platform called Telegram—and a big part of the activity on those groups is devoted to nothing more than telling members where to go if the group they’re in gets shut down, much to their (and let’s face it, my) annoyance. We’re making progress, and Dave has little to do with it.

This article is part of “The Speech Wars,” a project supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press, and the Fetzer Institute.



“Suppose a president were to announce that he would in no circumstances appoint any Roman Catholic to office and were rigorously to stick to this plan,” Charles L. Black Jr. wondered in his 1974 book Impeachment: A Handbook. “Suppose a president were to announce and follow a policy of granting full pardons, in advance of indictment or trial, to all federal agents or police who killed anybody in line of duty, in the District of Columbia, whatever the circumstances and however unnecessary the killing?”
In the throes of Watergate, the Yale professor pondered the question: Must a president commit an indictable offense to be impeached? Black imagined a range of noncrimes that might justify removing a president from office. The two I quoted are the climax of a series of increasing ominousness.
But even Black’s inventive mind did not foresee what we all just saw on ABC: the president confessing in advance that he would accept stolen information from a hostile foreign intelligence agency if it were to help his presidential campaign.

“There’s nothing wrong with listening,” he told George Stephanopoulos. “If somebody called from a country, Norway, ‘We have information on your opponent,’ I think I’d want to hear it.”
This confession carries heavy implications, starting with the question of whether Donald Trump Jr. lied to Congress when he denied telling his father in advance about the famous June 2016 Trump Tower meeting, in which he believed that a representative of the Russian government would be offering dirt on the Hillary Clinton campaign.
Special Counsel Robert Mueller’s report found that the Donald Trump campaign desperately wished to collude with Russian intelligence—but concluded that there was insufficient evidence to prove beyond a reasonable doubt that anyone in the campaign had actually done so. But after three years and the special counsel’s investigation? Trump acknowledges that he would do it all again, if given the chance.
Will he be given the chance, whether by Russia or China or Saudi Arabia or Abu Dhabi or Israel or Pakistan—or, for that matter, any number of foreign non-state actors, legitimate or criminal, with intelligence-gathering capabilities?
Yoni Appelbaum argued in an important cover story for The Atlantic in favor of opening an impeachment inquiry into the president. I worried some weeks later on this site about the political and institutional risks of proceeding down that path. But Trump himself gets a vote; Trump himself forces the hands even of those who might wish to restrain the hands. He is such an institution-wrecker—his instincts are so lawless—that he may simply refuse to allow Congress not to impeach him.

Confessing a willingness to collaborate with foreign spies against his domestic political opponents is a hand-forcing move. The risks of proceeding are still there. But the risks of not proceeding? Trump just forced us all to confront them in the most aggressively public possible way.



President Donald Trump can only escalate. He cannot help it.
On Thursday night, he spread from his own presidential account a video of the speaker of the House, edited to splice together moments when she stumbled over her words, in an apparent effort to deceive people into thinking her drunk or ill. In 2016, Trump’s Russian supporters performed this service for him with faked videos of Hillary Clinton. Now he seems to have decided that if you want a dirty-tricks campaign done right, you must do it yourself.
At the same time, he has put the declassification powers of the presidency to work as part of a larger campaign of cover-up.
Trump directed his attorney general to declassify documents in an effort to depict Trump’s campaign as a victim of improper surveillance in 2016. Trump tweeted that the attorney general had “requested” these powers. That may even be true. But Trump has been demanding such an investigation of U.S. intelligence agencies since long before William Barr got the top law-enforcement job. Barr is compliant and complicit, but the idea is all Trump’s.

The declassification process will be selective, of course, in service to a predetermined narrative. Meanwhile, Trump’s lawyers are fiercely battling in court to suppress congressional subpoenas for the financial documents that would cast light on Trump’s pre-2016 finances.
Who will trust or credit in any way the integrity of a Barr-led investigation? The intelligence agencies found evidence that alarmed them enough about the campaign’s Russia connections to justify a request for warrants. A federal court reviewed that evidence and authorized and reauthorized the warrants. Will that evidence be declassified?

Barr mischaracterized the content of Special Counsel Robert Mueller’s report in his letter summarizing its conclusions. He set aside Mueller’s reluctance to interpret the evidence of obstruction of justice, instead taking the decision upon himself—and decided in his boss’s favor. He held his peace as the president used his bully pulpit to falsely claim over more than a month that a report nobody else was allowed to see absolved him of wrongdoing, when the report did no such thing. And now Barr is tasked to declassify documents as he thinks fit to support conclusions already whistled up by Trump?

Trump will be acting as his own Julian Assange, releasing U.S. secrets to advance his agenda.

If Trump’s claims had any basis in reality, he would convene an independent commission of respected fact finders. Instead, he has relied on supporters willing to do his bidding—first Devin Nunes, now William Barr. The mission he has assigned them: Fight to suppress documents properly subpoenaed by Congress to answer important public questions, then pick and choose U.S. national secrets to defame career professionals who sought to protect the integrity of the nation’s elections against foreign adversaries who manipulated those elections in Trump’s favor.
Where’s the cover-up? This is the cover-up, as the White House and the office of the attorney general collude to conceal what the public deserves to know.



President Donald Trump has repeatedly said that his administration is the “most transparent in history,” and that it has “cooperated totally” with Special Counsel Robert Mueller’s investigation, or words to that effect. But the truth is quite the opposite. No prior administration has pushed the envelope of the law to deflect outside scrutiny to the same degree as this one. In a recent letter from the White House to the chairman of the House Judiciary Committee, the president, in effect, rejected the entire notion of congressional oversight as illegitimately political: “Congressional investigations are intended to obtain information to aid in evaluating potential legislation, not to harass political opponents or to pursue an unauthorized ‘do-over’ of exhaustive law enforcement investigations conducted by the Department of Justice.”

By contrast, prior presidents understood that respect for the rule of law means, in the end, complying with the law, no matter what the cost. That was true even of those under investigation, such as President Bill Clinton. And I should know—I was a member of the team led by Independent Counsel Ken Starr that investigated him.

Clinton was far from a willing participant in his own investigation. He resisted in multiple ways. But he was constrained by an appreciation for the rule of law, even as he was trying to evade its consequences.

Consider, by way of example and comparison, Clinton’s use of executive privilege—a privilege that Trump has also invoked in recent days to frustrate the House’s effort to get the unredacted version of the Mueller report. Just what is executive privilege, and why do we have it?

Broadly speaking, the idea behind executive privilege is that we want the advice that senior officials give the president—which often involves matters of national security and domestic prosperity, and is of crucial importance to the nation—to be candid and complete. It hardly seems plausible that a president could do his or her job and fulfill constitutional obligations without the candid advice of senior advisers. Protecting the confidentiality of these conversations may foster more open communication and lead, in the end, to better results.

And so, executive privilege extends not just to the legal advice that the president receives but, at least in theory, to all of the many communications that take place within the executive branch that are intended to develop policy for the benefit of the president. As the Supreme Court said in United States v. Nixon while reviewing President Richard Nixon’s claim of privilege, there is a “valid need for protection of communications between high government officials and those who advise and assist them in the performance of their manifold duties.”

But it is abundantly clear that executive privilege (in all of its forms) is not absolute. That’s why Nixon ultimately lost his effort to prevent disclosure of the tapes he had made of conversations in the White House. Nixon asserted that the confidential nature of the conversations made all of them privileged against disclosure. The Court, however, rejected Nixon’s extreme reading that he had an absolute power to withhold the tapes:

To read the Article II powers of the President as providing an absolute privilege as against a subpoena essential to enforcement of criminal statutes on no more than a generalized claim of the public interest in confidentiality of nonmilitary and nondiplomatic discussions would upset the constitutional balance of “a workable government” and gravely impair the role of the courts under Article III.

And, one might add, it might also impair the role of Congress under Article I—as reflected in today’s debates between the president and the House of Representatives.

In effect, the Court created a balancing test: The more significant the investigative interest, the greater the likelihood that privilege will yield. In Nixon, a criminal investigation was seen as a high-value investigative interest. Today a congressional inquiry into presidential misconduct would be as well.

Perhaps more importantly, a privilege like executive privilege is designed to serve the public good. When a president uses the privilege to help himself and conceal his own misconduct, he is abusing his power.

Starr said as much in his report to Congress. He argued that there was “substantial and credible information” that Clinton’s repeated and unlawful invocation of executive privilege was inconsistent with his duty to faithfully execute the laws of the United States and constituted potential grounds for impeachment. Starr was echoing the history of Watergate. In 1974, when the House Judiciary Committee drafted articles of impeachment for the House to consider, the third article adopted recommended impeachment on the grounds that the president had refused to comply with lawful subpoenas from Congress, in part through the wrongful invocation of executive privilege. Starr’s report to Congress argued that Clinton had acted similarly, albeit with respect to a criminal investigation rather than a congressional one.

The Starr Report recounts a history that also echoes recent events. It recalls Clinton’s promise on public TV that he would “cooperate fully” with the investigation into his contacts with Monica Lewinsky. In 1994, Lloyd Cutler, then the White House counsel, issued a directive that the Clinton administration not invoke executive privilege in cases involving allegations of personal wrongdoing.

In the end, however, those promises were unavailing. During the course of the Lewinsky investigation, Clinton invoked the presidential-communications version of executive privilege and the governmental attorney-client version of the privilege with respect to five witnesses: Bruce Lindsey, Cheryl Mills, Nancy Hernreich, Sidney Blumenthal, and Lanny Breuer.

He withdrew one claim before litigation and lost the remaining claims in a ruling by the district court. The breadth of the claims of executive privilege was, in some cases, striking. For example, Mills (who was at the time a deputy White House counsel) not only claimed privilege over internal communications with the president and other senior staff but also asserted that her communications with the president’s private lawyers (who, of course, are not part of the executive branch) were protected by the presidential privilege.

Even more ambitiously (if that is the proper word), Clinton attempted to create a new form of executive privilege. He authorized the assertion of a “protective function” privilege that would have permitted Secret Service agents to refuse to testify before a grand jury as to their observations of behavior that was the subject of a criminal investigation. The reasoning was (echoing the confidentiality argument that undergirds executive privilege) that if agents could be called to testify, then a president would push the agents away, increasing his personal risk.

The courts had little trouble concluding that Secret Service agents had no such privilege. As one district judge wrote:

In the end, the policy arguments advanced by the Secret Service are not strong enough to overcome the grand jury’s substantial interest in obtaining evidence of crimes or to cause this court to create a new testimonial privilege. Given this and the absence of legal support for the asserted privilege, this court will not establish a protective function privilege [against giving testimony].

The effort to create a sort of loyal Praetorian Guard was, thus, unavailing.

In short, the Clinton experience teaches us that the invocation of executive privilege can be the refuge of a president who is concealing misconduct. It is frequently asserted in an overbroad manner as a way of thwarting or delaying an inquiry. Perhaps we can all agree that, when used in that manner, the invocation is both ill-founded legally and contrary to basic principles of the rule of law that demand the accountability of the president for his or her actions.

Today we face a situation with many echoes from that earlier time. Trump, like Clinton before him, has sought to erect executive privilege and other claims of immunity from inquiry as a barrier to oversight of his own conduct. Three overarching considerations make clear that the president’s wholesale invocation of privilege is, in a number of ways, more severe and extreme than that of Clinton before him.

First, Trump’s actions do not occur in a vacuum, nor is the public required to ignore the context in which they arise. The president has publicly declared his intent to resist all congressional inquiries through a variety of means. By one count, he is currently defying as many as 20 different efforts to examine his conduct. Not all of these involve executive privilege. And perhaps some of these invocations of privilege and refusals to assist congressional investigation are well justified. But the pattern of resistance is such that we should evaluate the president’s actions against that background and, rightly, conclude that much of the president’s resistance is undertaken in bad faith in an attempt to avoid, or at a minimum delay, scrutiny of his conduct.

Clinton, by contrast, struggle though he might have done to avoid scrutiny of his personal conduct, never went to the same extremes as Trump. Clinton never sued private citizens to try to stop them from responding to congressional subpoenas. Clinton never refused to release his tax returns. Unlike Trump, Clinton eventually testified to Starr (albeit very reluctantly) because he knew he had to. And none of his family ever invoked the Fifth Amendment privilege against self-incrimination.

Second, Attorney General William Barr’s formal determination that the president has not committed any crimes and his public exoneration of Trump from any criminal wrongdoing have the effect of reducing, if not eliminating, much of the executive interest in the confidentiality of law-enforcement information that Trump continues to try to conceal. As the Office of Legal Counsel has noted:

Once an investigation has been closed without further prosecution, many of the considerations previously discussed lose some of their force. Access by Congress to details of closed investigations does not pose as substantial a risk that Congress will be a partner in the investigation and prosecution or will otherwise seek to influence the outcome of the prosecution; likewise, if no prosecution will result, concerns about the effects of undue pretrial publicity on a jury would disappear.

And so, the attorney general’s decision to close the criminal investigation of the president further weakens the executive claim of privilege.

Finally, on policy grounds, it is abundantly clear that however weak Clinton’s invocation of the privilege was (and I think it was not well founded), it was systematically stronger than that of President Trump today. To begin with, however ill-founded the claims might have been, Clinton’s privilege invocation was related to core presidential communications between him and his immediate advisers—a type of claim that merits a higher degree of protection. By contrast, Trump’s invocation has wandered much further afield, to include the protection of law-enforcement information and even the personal privacy of nonexecutive individuals.

More importantly, Clinton’s invocation was related to his own personal conduct with an intern. Those were events that, while significant, were of little systematic import to the nation, and thus, arguably, of less importance to Congress. By contrast, the investigation of Russian interference in our elections that is at the bottom of the special counsel’s investigation is a crucial matter for the nation, and so Congress has greater justification for inquiring into the matter.

In short, Clinton’s efforts to resist a review of his actions—efforts which were, in my judgment, properly rejected—were on a stronger footing than Trump’s efforts to evade congressional oversight today.

One anecdote from the investigation of Clinton’s assignation with Lewinsky shows how, even in his most desperate moments, Clinton understood that norms of lawful behavior applied to himself. One of his close advisers, Paul Begala, recently told me that even Clinton, whose efforts to avoid responsibility for his actions were, at times, almost laughable in their extremity, understood that in the end, the rule of law must prevail.

You may consider Begala’s characterization as somewhat self-serving, but the evidence from the denouement of the investigation, in the summer of 1998, supports his claim. The Starr investigation had been circling Clinton for months. Toward the end the investigation, Starr got a dress from Lewinsky that she had saved—and he wanted a DNA sample from Clinton to match to stains on the dress.

And so it came to pass, in a rather remarkable turn of events, that Clinton sat still one evening while the White House physician drew his blood, in the presence of an FBI agent and a prosecutor from Starr’s office. Imagine how that must have looked and felt from Clinton’s perspective—his very own blood being taken. And Clinton must have understood—he simply must have—that the blood would prove the connection to Lewinsky, in effect condemning him from his own body. And yet he sat there and did it. He didn’t refuse—and Begala says he never considered it—even though, from his perspective, it may well have meant the end of his presidency.

Clinton gave his blood. Not willingly, but he gave it nonetheless. Why? We can’t ever know for sure, but in some sense, it must have reflected a commitment to following the rules, even when they hurt.

In the meantime, don’t accept the argument that “Trump is cooperative.” Call me when he gives blood.



“I’m actually a very honest guy,” Donald Trump told George Stephanopoulos in an interview aired Monday. And while that claim holds no water in general, Trump was jarringly honest on one topic: his willingness to welcome foreign interference in the 2020 election.

“It’s not an interference, they have information—I think I’d take it,” Trump said. “If I thought there was something wrong, I’d go maybe to the FBI—if I thought there was something wrong. But when somebody comes up with oppo research, right, they come up with oppo research, ‘Oh let’s call the FBI.’ The FBI doesn’t have enough agents to take care of it.”

There are several plausible ways to interpret this. One, as my colleague David Frum shows, is as an astonishing confession. Another, laid out by my colleague Peter Nicholas, is that Trump has completely failed to learn the lessons of the 2016 campaign.

Trump’s declaration, though, is neither especially surprising nor especially irrational. While the president has paid hefty political penalties for his behavior during the 2016 election, and while his latest comments will only stoke the fervor for impeachment among Democrats, the fact remains that the Trump campaign profited from foreign interference in 2016. It did not rebuff explicit offers of assistance from Russia, and capitalized on the roundabout assistance Russia’s release of hacked material provided. Whatever collateral damage Trump has received since the election, Russia’s interference helped him pull off a shocking upset victory in November 2016, and he’s so far escaped serious personal consequences for exploiting that aid.

It’s no surprise, then, that Trump would not foreswear a tactic that worked for him then. Rather, every indication is that the president’s electoral behavior will be worse in 2020, and there will be fewer constraints on him.

First, as the interview with Stephanopoulos showed, Trump is effectively already actively soliciting foreign assistance in 2020. In the 2016 race, he was a long-shot candidate, and Russia took a serious risk by aggressively helping him. That bet paid off with Trump’s win, and the divisions in America that have followed; the repercussions for Russia have been relatively minor, and the president himself refuses to blame the Kremlin.

Trump openly telling Stephanopoulos he’d look at help and not report it to the FBI is as good as a request for bids. Where before many foreigners viewed him as an uncouth businessman with no chance at the Oval Office, Trump is now the president of the United States, and he’s offering a simple way to curry favor with him. He’s also promising he won’t take any concerns to law enforcement.

This morning, as the backlash to his comments gathered force, Trump argued that his comments had been misconstrued. “I meet and talk to ‘foreign governments’ every day,” he tweeted. “I just met with the Queen of England (U.K.), the Prince of Wales, the P.M. of the United Kingdom, the P.M. of Ireland, the President of France and the President of Poland. We talked about ‘Everything!’ Should I immediately call the FBI about these calls and meetings?”

That’s a red herring. Trump is either unable to tell the difference between diplomatic conversations in his capacity as head of government and electoral interference by the intelligence agencies of a hostile foreign power, or he is unwilling to do so. This fits with a pattern of Trump conflating the national interest with his own personal interests.

There’s no need to deal in hypotheticals: Not only would Trump hear out foreign countries offering aid, he’s arguably already doing so. In May, The Washington Post reported, the Trump lawyer Rudy Giuliani—who has been seeking to dig up damaging information about the Biden family—met in New York with a former Ukrainian diplomat who has made unsubstantiated allegations against the Democratic National Committee. Sub in Donald Trump Jr. for Giuliani and Russia for Ukraine, and it’s a rerun of the notorious June 2016 Trump Tower meeting. The Trump campaign is returning to the same playbook. Giuliani also planned a trip to Ukraine, before canceling it over objections from the State Department, according to the Post.

And Trump can now run that playbook without as much fear of repercussion. The president’s understanding of the FBI is peculiar. He reacted strongly when Stephanopoulos asked him about the agency, offering a mob-style revulsion to snitching: “I don’t think in my whole life I’ve ever called the FBI. In my whole life. You don’t call the FBI.” This disdainful attitude toward federal law enforcement is especially strange given that Trump is now the nation’s top law-enforcement officer. (It’s also bizarre given that in 1981, Trump offered to “fully cooperate” with the bureau.)

In other ways, however, Trump is happy to flex his power over the executive branch. After years of demanding it, Trump now has an attorney general who has launched an investigation into the origin of the probe into Russian interference in the 2016 election. Trump has also given Barr wide latitude to declassify intelligence, and the Justice Department is seeking to question officials at the CIA. Trump has also repeatedly personally attacked Peter Strzok and Lisa Page, FBI officials involved in that investigation. The effect of the president’s rhetoric and the investigation will be to put any federal law-enforcement or intelligence officials who might dare to object to or probe foreign interference in 2020 on notice. At best, they would face the risk of being called in front of an inquisition; at worst, the president might be airing their personal lives on his Twitter feed.

The major remaining constraint on foreign interference now is that any foreign actor might worry about helping Trump only to see him lose—and alienating an incoming administration in the process.

Trump’s comments to Stephanopoulos underscore what ought to be obvious by now. The president isn’t interested in a fair election, and he’s not interested in legality. He’s only interested in winning. If that requires foreign interference, so be it.



In an address last week, President Donald Trump offered an immigration proposal that, in his words, “establishes a new legal immigration system that protects American wages, promotes American values, and attracts the best and brightest from all around the world.” As just about every news outlet that’s covered it has made clear, the proposal is very unlikely to make its way through Congress. But that is hardly surprising. Short of a no-strings-attached mass amnesty, it is difficult to envision Democrats in the House endorsing any legislative proposal from the Trump White House on an issue that has proved so divisive, and so richly resonant to left-of-center activists and donors.

But Trump’s proposal actually gets the framework right for a new approach to immigration policy. Rather than reducing the number of green cards the U.S. grants every year, Trump is now calling for rebalancing admissions to ensure that a higher proportion of new immigrants are poised to achieve labor-market success. Trump has been inching away from steep reductions in legal immigration for some time. If congressional Democrats took this proposal seriously, they could push the administration to follow through on the logic of this plan, adding provisions that would make it both more politically viable and more effective. And for congressional Republicans, the plan offers a chance to turn a divisive issue for their coalition into a unifying one.

I’ve advocated for something like this approach in these pages on a number of occasions, and it is a centerpiece of my recent book. And so I’ve been struck by the Trump proposal’s reception. In short, the vagueness of the proposal has allowed the president’s critics to paint it in the darkest possible light, which is, of course, to be expected. But it is easy to see how a more refined proposal would prove broadly popular among conservatives and moderates, which is why the Trump White House would be wise to stay the course.

The political case for moving from reduction to rebalancing is strong, even if it’s not a position that will satisfy immigration maximalists who see the notion of a more skills-based system as an affront, a group that appears to be overrepresented among the journalists who have been covering Trump’s proposal. Consider that a 37 percent plurality of U.S. adults wants to keep legal admissions at their current levels, while 68 percent are opposed to increasing them, proportions that would be higher still among voting adults. Moreover, there is considerable evidence to the effect that most Americans would favor prioritizing educated, English-speaking immigrants employed in high-wage occupations over those who are more likely to find themselves in need of a helping hand. Again, this might irk immigration maximalists, but that doesn’t make it any less true.     

Many observers see rebalancing without reduction as a nonstarter, not least out of an expectation that it would alienate the GOP’s restrictionist wing. No doubt there are Republicans who insist that reducing legal-immigration levels is essential, but support for their position has been falling among GOP voters in recent years, from 43 percent in 2006 to 33 percent in 2018, and it has fallen even more sharply among voters at large. Trump’s proposal is therefore best understood as a clear-eyed recognition that the classic restrictionist position is incapable of commanding even a narrow majority, certainly for now.

Then there is the fact that the immigration status quo has a number of quirks that are awfully unattractive from the perspective of many intending immigrants and naturalized citizens hoping to be reunited with their families. In 2017, 46 percent of the 1.1 million people granted lawful permanent-resident status were the spouses, minor children, and parents of U.S. citizens. This group always comprises the lion’s share of permanent visas, because there is no limit on the number of green cards issued to intending immigrants who are considered the immediate relatives of U.S. citizens. Notably, Trump’s proposal appears to leave this category untouched.

An additional 21 percent of green cards were given to so-called family-preference immigrants, who might be the adult siblings of U.S. citizens or the relatives of lawful permanent residents who have yet to naturalize, categories that are subject to maddeningly complicated per-country caps and other numerical limits. Taken together, 67 percent of all permanent visas fell into one of the family-sponsored categories. As for the rest, 13 percent of green cards were granted to refugees and asylum seekers, 12 percent to employment-based immigrants, and 5 percent to winners of the diversity visa lottery.

Among family-preference immigrants, it makes a big difference if you’re petitioning from a country with a large pool of potential green-card holders—including Mexico, the Philippines, India, Vietnam, and China—than one with a small pool, such as Switzerland or Tuvalu. Petitioners from high-pool countries are always bumping up against per-country caps, and so they’re often subject to long waitlists. Because the employment-based categories are so tightly constrained, an intending immigrant waiting for a family-preference visa doesn’t generally have the option of, say, mastering the English language and acquiring valuable skills to improve her chances of gaining admission. Indeed, she’d be better off persuading a U.S. citizen to marry her than to acquire skills that would help ensure she’d be able to thrive in America’s labor market. Needless to say, these incentives are perverse, and the insistence that our current approach to family-based immigration ought to be treated as sacrosanct is nothing short of bizarre.

At the same time, it is also true that Americans value family reunification as a core principle of immigration policy, and they’re wary of proposals that deprecate its importance. With that in mind, I’d suggest modifying, or rather clarifying, Trump’s immigration proposal so that its merit-based system would take family ties into account. Drawing on the Canadian experience, petitioners could be granted points for having an extended-family member who is already a citizen or lawful permanent resident of the U.S., but this wouldn’t be the be-all and end-all. Having a U.S. citizen sibling could give you a boost, but you could move up the queue by gaining valuable skills, or by securing a remunerative job offer from a U.S. employer for whom you’ve been working remotely.

This approach would prove enormously valuable to petitioners from high-pool countries, who are badly disadvantaged by the current system, and it might win over naturalized citizens from such countries, many of whom are frustrated by the decades-long waitlists they’re forced to endure to reunite with loved ones, and who’d welcome a system that would reward their relatives for speaking fluent English. On its own, the case for skills-based immigration risks sounding arid and abstract. While an increased emphasis on skills might stimulate human-capital investment among intending immigrants living overseas, which would benefit them and their neighbors whether or not they manage to settle in the U.S., we tend to neglect the welfare of people we can’t see. Emphasizing that a blended points system of the kind I’ve sketched out would help Filipino Americans and Mexican Americans reunite with loved ones willing to put in a bit of effort would make for a more vivid pitch, and it has the added benefit of being entirely true.

And there is another opportunity the Trump administration could seize: It could draw a more explicit and direct connection between immigration policy and human-capital policy. For example, the U.S. Department of Labor devotes a share of the revenue generated by application fees for the H-1B temporary work visa to fund apprenticeships for U.S. workers, a program with obvious appeal to an administration that often touts its “Hire American” agenda. Revamping the H-1B program by allocating its visas by auction rather than by lottery, as recently proposed by Alessandra Casella and Adam Cox, could improve the program itself by making sure H-1B visas are granted to the most valuable foreign workers and could generate a large increase in revenue, which could then finance the expansion of apprenticeships and other initiatives designed to develop the potential of U.S. workers, perhaps with a particular focus on struggling regions.

Do I expect the Trump White House to pursue the president’s immigration proposal, and to make it more attractive to a larger number of Americans, including naturalized citizens? I’m sorry to say that I’m skeptical. The Trump administration is divided between those who adamantly favor deep reductions in legal immigration and those who back a large-scale expansion of low-skill guest-worker visas, and so the middle ground of rebalancing without reduction is always at risk of being squeezed out. But that is not to say that other ambitious Republicans, and indeed Democrats, couldn’t pick up the baton.



Do you remember the little woven finger traps you sometimes got as a kid, as a party favor or a reward at a fair? You could comfortably stick your fingers in, but if you tried to pull them out, the weave would tighten and you’d be stuck. Only by maneuvering gently, and not pulling too hard, could you extract yourself.

President Donald Trump finds himself in a sort of impeachment finger trap right now. He isn’t certain to be impeached—but every step he’s taking to try to squirm out of it seems to tighten the bind he’s in.

Consider the president’s tantrum on Wednesday. After inviting Speaker Nancy Pelosi and Senate Minority Leader Chuck Schumer to the White House for a meeting on infrastructure, Trump stomped out of the meeting, supposedly because Pelosi had earlier accused him of participating in a cover-up. (The accusation is unrebuttably true.) Trump insists he did not throw a fit—“I was purposely very polite and calm, much as I was minutes later with the press in the Rose Garden. Can be easily proven.”—but one can’t calmly blow off a meeting. It defeats the point.

Trump has many things to be upset about. His feint on infrastructure came to nothing: Pelosi and Schumer were happy to go along with his plan, but he couldn’t rally Republican support for it. His former spokeswoman Hope Hicks has just been subpoenaed by the House Judiciary Committee. And his strategy of stonewalling Congress in the face of Democratic investigations is unraveling quickly. There never seemed to be much hope that it would block the probes altogether; instead, the goal appeared to be to bog down the process and run out the clock before the 2020 election.

On Wednesday, however, a federal judge in New York ruled against Trump’s effort to block a subpoena from House Democrats of his financial records from Deutsche Bank and Capital One. That came a day after another federal judge rejected his bid to keep his accounting firm, Mazars USA, from turning over documents; that judge refused to stay his order pending appeal, and seemed incredulous at the administration’s arguments. NBC News reports that two other banks, TD and Wells Fargo, have already handed over documents. The process is moving much faster than Trump had hoped. Instead of eating up months, his refusals to comply have barely eaten up weeks.

So Trump is suggesting he won’t work with Democrats on anything until they drop their investigations. “It is not possible for them to investigate and legislate at the same time,” he tweeted. But being able to do both oversight and lawmaking is precisely how Congress is structured, and as veterans of any previous administration can attest, plenty can get done while Congress is investigating a White House.

There is also no chance Democrats are going to drop their investigations, and that’s where the finger trap comes in. By and large, the House Democratic caucus has been wary of impeachment. Even after Special Counsel Robert Mueller’s report all but accused the president of obstruction of justice and suggested that Congress ought to act, most members were content to follow Pelosi’s slow approach and to avoid open calls for impeachment.

More recently, however, that has changed—and the spark has been the White House instructing former aides like Don McGahn to neither produce documents nor testify in response to subpoenas. It’s one thing to fire the FBI director to kill an investigation, pressure aides to lie, and try to fire the special counsel—you might very well get away with only harsh words for that—but start stepping on Congress’s prerogatives, and its members start to get very angry very fast. Specifically, they start to demand impeachment inquiries.

If Trump were to follow through on his threat to not do anything with Congress until House Democrats drop their investigations, things could get even dicier. Within the next few months, the debt ceiling will need to increase and the government will need to be funded. Democrats might have been tempted to hold those bills hostage, just as Republicans have done in the past—but now Trump has given them an opportunity to pass an increase and a spending bill and dare the president to call their bluff. A senior government official told CNBC that the debt ceiling and funding are not subject to Trump’s ultimatum, but the president has demonstrated again and again that only he can speak for himself. And if he doesn’t act, and the U.S. defaults or shuts down? It could be fodder for another article of impeachment.

Thus far, Pelosi has been the brake on the members of her caucus most eager to impeach, but Trump’s erratic behavior is backing her into an ever-more-untenable situation. On Wednesday, she said, “I pray for the president of the United States. And I pray for the United States of America.” Later on Wednesday, she said, “In plain sight, this president is obstructing justice and is engaged in a cover-up. And that could be an impeachable offense.” On Thursday, she said that she was concerned for Trump’s well-being and said he was conducting an “assault on the Constitution of the United States.” But Pelosi continues to say she doesn’t support impeachment, and reportedly told Democratic lawmakers, “He wants to be impeached, so he can be exonerated by the Senate.”

With each comment like this, Pelosi’s balancing act becomes more challenging. Even if it is true that the odds of conviction in the Senate following an impeachment are very long, it’s difficult to tell your members and your constituents that the president is attacking the Constitution and has committed impeachable acts, and then decline to even launch an impeachment inquiry. There’s an analogy with the Republican rhetoric about Barack Obama: Once GOP voters were convinced that Obama was a tyrant, everything the Republican Congress did short of acting that way started to look like a betrayal, and incumbents paid a price for that in their primary elections.

While Pelosi’s explicit position is against impeachment, her implicit position, I have argued, is actually not yet. Trump’s response to the investigations is making yet closer for her and for the rest of the Democrats. His fingers are in the trap, and he’s pulling furiously, but the trap is just getting tighter.



Like many writers I know, I’ve had a passion for words for almost as long as I can remember. I’ve admired those who use words well, who have shaped my imagination and given voice to things I wanted to express but didn’t feel like I adequately could. That is why they have to be protected against assault and degradation.

At an early age I recognized their power to convey deep emotions and longings, knowledge and understanding, hopes and fears. “Words can be polluted even more dramatically and drastically than rivers and land and sea,” one of my favorite writers, Malcolm Muggeridge, once wrote. “Their misuse is our undoing.”

Eventually, we all come to understand that words are the means by which we teach and inspire, defend truth, and seek justice. (Those of us of the Christian faith don’t consider it an accident that the first sentence in the Gospel of John is, “In the beginning was the Word, and the Word was with God, and the Word was God.”) So words have extraordinary power—in our daily lives most of all, but in politics as well.

Democracy requires that we honor the culture of words. The very idea of democracy is based on the hope that fellow citizens can reason together and find a system for adjudicating differences and solving problems—all of which assumes there is a shared commitment to the integrity of our public words. If you believe words can ennoble, you must also believe they can debase. If they can elevate the human spirit, they can also pull it down. And when words are weaponized by our political leaders and used to paint all opponents as inherently evil, stupid, or weak, then democracy’s foundations are put in peril. Which brings us to the dismal, demoralizing Donald Trump era.

The debasement of words has reached a zenith with the coming of America’s 45th president, who dominates discourse in this country in ways perhaps no other president ever has. And if we hope to repair the damage that’s been done, we need to understand what it is about Trump’s misuse of words that is pernicious and dangerous.

The least problematic part is the sheer banality of Donald Trump’s words. During his presidency, Trump has uttered no beautiful and memorable phrases. His inaugural address, which is a speech normally meant to inspire the citizenry, is remembered, if at all, for the phrase American carnage and Trump’s description of a dystopian nation, broken and shattered. More worrisome is that many of Trump’s utterances are an incoherent word salad. If you read the transcript of many of his interviews and extemporaneous speeches, you often find that Trump is not only unable to lay out a coherent argument; at times he’s unable to string together sentences that parse.

But that’s hardly the worst of Trump’s misuses of words. When it comes to dealing with those who oppose him, he consistently uses words to demean, belittle, bully, or dehumanize. He has mocked former prisoners of war, the disabled, and the appearance of women. He has perpetuated conspiracy theories. He has attacked Gold Star parents and widows. And he has engaged in racially tinged attacks. The number of his targets is inexhaustible because Trump’s brutishness is inexhaustible.

Many other presidents have been viewed as divisive figures, but none have taken as much delight as Trump in provoking acrimony, malice, and bitterness for their own sake; in turning Americans against one another in order to turn them against one another. He seems to find psychic satisfaction in doing so.

The banality and weaponization of Trump’s words are bad enough, but the greatest cause for concern is his nonstop, dawn-to-midnight assault on facts, truth, reality. That places Trump in a sinister category all his own.  

Many politicians are guilty of not telling the full truth of events. A significant number shade the truth from time to time. A few fall into the category of consistent, outright liars. But only very few—and only the most dangerous—are committed to destroying the very idea of truth itself. That is what we have in Donald Trump, along with many of his aides and courtiers. We saw it at the dawn of the Trump presidency, when he insisted—and sent out his press secretary to insist—that the crowd size at his inauguration was larger than that of Barack Obama’s, despite photographic evidence to the contrary. And that behavior has continued virtually every day since.

According to The Washington Post, Trump has made more than 10,000 false or misleading claims as president, roughly 12 a day. The Trump presidency is notable for the number and velocity of his falsehoods and misleading statements. They have been made in speeches and tweets, on matters significant and trivial, about others and about himself—and he virtually never apologizes or issues corrections. He says what he wants, when he wants, regardless of the reality of things.

In a 2018 speech to the Veterans of Foreign Wars, Trump said, “And just remember: What you’re seeing and what you’re reading is not what’s happening.” In other words, who are you going to believe—me or your lyin’ eyes?

“The man lies all the time,” writes Thomas Wells, an attorney Trump once hired. In Bob Woodward’s book Fear, Trump’s former personal lawyer John Dowd describes the president as “a f******” liar,” telling Trump he would end up in an “orange jump suit” if he testified to Special Counsel Robert Mueller. And the former White House aide Anthony Scaramucci, when asked whether he considers Trump a liar, admitted, “Okay, well we both know that he’s telling lies. So if you want me to say he’s a liar, I’m happy to say he’s a liar.” (In a later interview Scaramucci put it this way: “He’s an intentional liar. It’s very different from just being a liar-liar.”)

Trump is not simply a serial liar; he is attempting to murder the very idea of truth, which is even worse. “The point of modern propaganda isn’t only to misinform or push an agenda,” according to the Russian dissident and former world chess champion Garry Kasparov. “It is to exhaust your critical thinking, to annihilate truth.”

This is an urgent matter, and it makes this a dangerous moment because without truth and a common factual basis for our national life, a free society cannot operate. And right now, for a significant number of Americans—including many people on the right who long defended the concept of objective truth and repeatedly rang the alarm bell about the rise of relativism—truth is viewed as relative rather than objective, malleable rather than solid; as instrumental, as a means to an end, as a weapon in our intense political war. A depressingly large number of Trump supporters—again, many of whom have for years agreed with the conservative political philosopher Allan Bloom that relativism was impoverishing our souls—now seem to relish this “post-truth” political moment.

Friedrich Nietzsche coined a term, perspectivism, to describe the idea that there is no objective truth; we all get to make up our own reality, our own script, our own set of facts, and everything is conditioned to what one’s own perspective is. We saw this illustrated in the 2016 campaign, when Newt Gingrich insisted during a morning-show interview on defending Trump’s claim that crime rates were soaring. When the host, CNN’s Alisyn Camerota, cited FBI data to support her claim that we are safer and crime is down, Gingrich responded, “No. That’s your view.”

When Camerota countered that this wasn’t simply a subjective matter and once again cited FBI crime statistics, Gingrich responded, “As a political candidate, I’ll go with how people feel, and I’ll let you go with the theoreticians.” In other words, facts be damned; my feelings will create my own reality. (By the way, those who assemble crime statistics are not “theoreticians.” They are documenting empirical data.)  

Destroy the foundation of factual truth, and lies will be normalized. This is what the Czech dissident (and later president) Václav Havel described in the late 1970s when he wrote about his fellow citizens making their own inner peace with a regime built on hypocrisy and falsehoods. They were “living within the lie.” In such a situation life becomes farcical, demoralizing, a theater of the absurd. It is soul-destroying.

The United States is still quite a long way from the situation Havel found himself in. But to keep it that way—to keep civic vandalism from spreading—we all have a role to play, including calling out lies, including the lies of Trump, in every way we can.

The most obvious thing Americans can do is to vote for men and women who prize integrity and are, in the main, truth-tellers. It doesn’t seem too much to ask that we not vote for those who are chronically dishonest and corrupt. Americans can also end their financial support for parties that are aiding and abetting compulsive liars.

There are also plenty of ways constituents can exert pressure on their members of Congress to speak out and act against those who are duplicitous and disgracing the profession of politics. Congress has a lot of tools in its kit, from censure to holding hearings to blocking nominations and legislation to impeachment. But those efforts will only happen if public pressure is applied. If it is, politicians will respond. People who are a corrupting influence have been voted into office; they can be voted out of office.

The United States government needs to step up our efforts to stop the misinformation and disinformation campaigns by foreign powers who are influencing our elections, including learning from countries like Ukraine, which has experienced this and taken steps to defend itself. We know that social-media platforms such as Facebook, Google, Reddit, and Tumblr were weaponized over the past several years; they need to be held accountable and need to be fixed, including regulating these industries if they can’t correct themselves and end this wild-west show.

The American press has to redouble its effort to get its facts right and resist jumping to premature conclusion. “Our facts need to be squeaky clean and uncorrupted,” in the words of CNN’s Jake Tapper, who is an exemplary journalist.

Each of us can refuse to become complicit in lies. We can refuse to defend them, refuse to believe them, and refuse to spread them, including lies that might help our political causes. We can also venture outside of our ideological silos, listen to other sources of information, and take into account other perspectives. (Think about how often we listen not to understand but in order to refute.) All of us can do better to remind ourselves that the main point of gathering information isn’t to reaffirm the views we already hold; it’s to better ascertain the truth.

Beyond that, we can all do better to model truthfulness, temperance, decency, and integrity in our daily lives, among our family, friends, and colleagues. One person acting alone can’t change much; a lot of people acting together create a civic and political culture.

The temptation is to think that if we simply flip the right policy switches, if we implement the right laws, we will put an end to this disorienting “post-truth” era. But there is no set of policies we can pull off the shelf to deal with our present political malady. Ultimately what will be decisive is whether enough Americans commit (or recommit) themselves to defend truth and fight falsity. That has to happen in our individual lives and in how we manifest that commitment in the political realm. There’s no getting around the fact that much of what needs to be done lies in the realm of attitudes, in shaping our sensibilities in a way that respects truth and aligns with the reality of things. As Havel put it:

In its most original and broadest sense, living within the truth covers a vast territory whose outer limits are vague and difficult to map, a territory full of modest expressions of human volition, the vast majority of which will remain anonymous and whose political impact will probably never be felt or described any more concretely than simply as part of a social climate or mood. Most of these expressions remain elementary revolts against manipulation: you simply straighten your backbone and live in greater dignity as an individual.

We cannot give up on the belief that human beings are rational and reasonable, that evidence and logic matter, and that persuasion is possible. The human condition is such that things are rarely all of one and none of the other, and certainly in this case, the pendulum swings from moments of collective trust and calm reason to collective mistrust, emotivism, and rancor.

A lot of different factors—internal and external, domestic and international, economic and social—influence a nation’s political and civic culture. And we all know, deep in our bones, that political leadership and rhetoric do, too. We need to stand with women and men in public life who believe, as Abraham Lincoln did, that words can be instruments of reason and justice, repair and reconciliation, enlightenment and truth. Who are willing to challenge not just their adversaries but their allies, not just the other political tribe but their own. And who are willing to make a compelling case for truth, deliberative democracy, and persuasion.

Ours is a remarkable republic, if we can keep it.



On June 13, 2018, Special Counsel Robert Mueller charged 12 officers of the GRU, the Russian intelligence agency, with committing “large-scale cyber operations to interfere with the 2016 U.S. presidential election.” Three days later, President Donald Trump met with Russian President Vladimir Putin in Helsinki, Finland. Speaking at a press conference beside Putin, Trump absolved Russia of any hacking.

“He just said it’s not Russia. I will say this: I don’t see any reason why it would be,” Trump said. “So I have great confidence in my intelligence people, but I will tell you that President Putin was extremely strong and powerful in his denial today. And what he did is an incredible offer. He offered to have the people working on the case come and work with their investigators, with respect to the 12 people. I think that’s an incredible offer.”

The remarks forced Trump’s approval rating, politicians’ pretenses, and jaws to drop. Republicans who’d been reluctant to criticize the president were horrified to see him taking the Kremlin’s word over that of his own aides and the U.S. intelligence community.

Trump repeated the sin in an hour-long phone call with Putin on Friday. Two weeks after Mueller’s report laid out even more detail about the dimensions of Russian interference in the election, Trump didn’t bother to condemn Putin or complain about the interference. He didn’t even bring it up. But don’t expect this reprise to elicit the same reaction as Helsinki. Whereas Trump’s refusal to defend U.S. elections against foreign interference was once shocking, it’s now become expected.

In brief remarks during a visit with the Slovakian prime minister, reporters asked Trump about the call. Had he discussed Russian meddling with Putin?

Trump: He sort of smiled when he said something to the effect that it started off as a mountain and it ended up being a mouse. But he knew that, because you knew there was no collusion whatsoever. So that is pretty much what it was—

Reporter: Did you tell him not to meddle in the next election?

Trump: Excuse me. I’m talking. I’m answering this question. You are very rude. So we had a good conversation about many different things. Okay.

Reporter: Did you tell him not to meddle in the next election?

Trump: We didn’t discuss that. Really, we didn’t discuss it. We discussed five or six things.

It’s not hard to believe that he didn’t discuss it, since the president has repeatedly shown great hesitation in discussing the hacking—or “the Russian hoax,” as he called it Friday.

The problem is not that Trump is willing to speak to Putin. It’s important and useful for the United States to maintain diplomatic channels even with adversaries, and working with Russia can serve U.S. purposes in Syria, Venezuela, and elsewhere. “Getting along with Russia and China is a good thing; it is not a bad thing. And getting along with countries … it is a good thing, and we want to have good relationships with every country,” Trump said.

All well and good. The problem is that Trump is unwilling to simultaneously hold Russia to account for its brazen interference in the election. No one in government other than Trump denies the Russian attack. During Attorney General William Barr’s testimony to the Senate Judiciary Committee this week, he, Democrats, and Republicans all agreed on the attacks and the serious threat to American elections—a consensus that was all the more impressive since there was practically nothing else on which all three parties agreed.

One reason Trump can’t bring up the hacks is that he is a terrible negotiator. Because he is bad at one-on-one discussions and eager for Putin’s approval, he is unable to discuss other issues with Putin while also holding a firm line on election interference.

Another is that he has fiercely resisted any suggestion that his electoral victory was the fruit of anything other than his own genius. Whenever the subject of Russia’s interference—its social-media campaigns, its hacking and dissemination of private emails—has surfaced, Trump has responded angrily, as if acknowledging what Russia did would call into question the legitimacy of his victory. (And not without reason; many Democrats believe that it does.)

The other big reason for Trump’s silence is that he remains incapable of separating himself from Putin for the purposes of the investigation. Trump insists that the Mueller report found “No Collusion—No Obstruction”—in fact, it made neither of those conclusions—but cannot make the distinction that even as the special counsel’s probe did not charge him with any crimes or find a criminal conspiracy by his campaign, it unequivocally did conclude that there was Russian interference. It is as though Trump believes that because he was (supposedly) vindicated, everyone else was also vindicated.

Trump’s failure to bring up the interference is also terribly hypocritical. During an interview with Fox News on Thursday, he criticized former President Barack Obama for not doing more to push back on Russia during the election. “He could have called out the troops and he could have said, ‘Let’s look at this very closely.’ He did absolutely nothing, because he thought that ‘Crooked Hillary’ was going to win the election,” Trump said then. On Friday, Trump spoke to Putin and, by his own account, did absolutely nothing.

It’s Helsinki all over again. In this case, at least, Trump didn’t offer to allow Russian intelligence agents to take part in the investigation, or to submit a former American diplomat to Russian interrogation, and he didn’t do it while standing next to Putin on a dais. But in substance, Trump’s call essentially reprised his earlier performance. He still refuses to acknowledge Russian interference or do anything else about it—even though there’s now even more evidence to back it up.

Yet as Julian Sanchez, a senior fellow at the Cato Institute, notes, Trump’s denial of reality seems to be working for him politically. In July 2018, right after the GRU indictment and the Helsinki summit, about half of Republicans said Russia had interfered in the election. By February, that was down to a quarter. Why should Trump acknowledge reality and do the hard work of pushing back on Putin when it’s easier to just convince his supporters of a fiction?



A magnificent fresco adorns the main pavilion of the royal palace in the Iranian city of Isfahan, depicting the 16th-century Battle of Chaldiran, fought between the Turkish-Ottoman and Persian-Safavid empires. The fresco appears to show the Persian army victorious, having crushed its Turkish adversary. The truth is that Chaldiran marked a decisive victory for the Ottomans, who went on to annex eastern Anatolia and northern Iraq. But what the self-serving historical distortion suggests is not shame of defeat but pride in the heroic valor with which the Iranians resisted a foe that outnumbered them and, unlike them, possessed heavy artillery. Donald Trump’s administration, which has made bringing Iranians to their knees the cornerstone of its Mideast policy half a millennium later, should draw a lesson from the battle and the way the Persians digested defeat.

It has been one year since President Trump reneged on the 2015 nuclear deal that rolled back Iran’s nuclear activities and placed them under the most rigorous international inspection regime ever implemented anywhere. Then came one of the most draconian sanctions regimes ever imposed by Washington on any adversary. So far, the U.S. Treasury has blacklisted nearly 1,000 Iranian entities and individuals, targeting nearly all sectors of Iran’s economy.

There can be little doubt that the administration’s “maximum pressure” policy is inflicting considerable economic harm on Iran. Economic growth that followed the lifting of sanctions in 2016 has given way to an inflationary recession. The Iranian currency has lost two-thirds of its value, as oil exports have dropped by more than half and will likely fall further still. Although food and medicine are exempt from sanctions, lack of access to the global financial system is giving rise to a humanitarian crisis. Some families have not been able to eat meat for months and are suffering from shortages of specialized medicine.

To date, however, there is no sign that either Iran’s regional policies are shifting or its leaders are willing to come back to the negotiating table and submit to the Trump administration’s demands. Nor is there any hint that economic hardship has triggered popular unrest of a magnitude that would threaten the regime’s survival. In the absence of any visible shift in Tehran’s political calculus, Washington is presenting the sanctions’ impact by no metric other than their quantity and severity.

There appears to be a belief among U.S. policy makers, almost congealed into doctrine, that Iran will cave to nothing less than massive pressure, a point it clearly has not reached. With U.S. elections at the end of next year, the administration is therefore responding to Iran’s refusal to concede defeat by doubling down, and it’s going about it in a hurry. It has resorted to the unprecedented steps of designating a state entity, Iran’s Islamic Revolutionary Guard Corps, a “foreign terrorist organization,” and of trying to push Iran’s oil exports to zero almost overnight.

This policy is unlikely to succeed for three main reasons.

First and most important: The one thing Tehran would find more intolerable than the crushing impact of sanctions is raising the white flag because of them. Convinced that Trump’s national-security team is bent on toppling the Islamic Republic, the Iranian leadership views economic sanctions as just one in a range of measures designed to destabilize it. Its counterstrategy can be summed up in two words: Resist and survive. The mere act of survival would constitute victory, however pyrrhic.

Tehran believes it has history on its side. Neither besiegement nor prolonged economic suffering is new to Iran’s rulers or its people. They have previously witnessed nearly half of the country’s oil revenue evaporate during the Iran-Iraq War in the 1980s, again during the Asian financial crisis in 1997, and a third time as a result of the European oil embargo and U.S. sanctions in 2012. They know how to get around sanctions and keep state and society afloat.

Second, Tehran feels compelled to prove to U.S. policy makers the bankruptcy of their belief that severe pressure can force Tehran to yield. Iran may have sued for compromise when it faced potential existential threats in the past, but strategic gain outweighed the cost each time. In 1988, Ayatollah Ruhollah Khomeini reluctantly declared that he would “drink from the poison chalice,” agreeing to a cease-fire with Iraq. But when the guns fell silent, after having suffered hundreds of thousands of casualties, Iran had managed to consolidate the young republic’s rule without losing an inch of territory. A similar logic applied in 2003, when after the U.S. invasion of Iraq and, separately, the exposure of Iran’s secret nuclear activities, Tehran pushed the pause button on the nuclear program, lest it become the next target for regime change, and proposed a grand bargain to Washington. Nothing came of what was essentially an invitation to dialogue, in part because the Bush administration’s Iraq adventure proved a strategic disaster.

And third, if past is prologue, Iran will not negotiate with Washington unless it knows it has a relatively strong hand. As Supreme Leader Ali Khamenei put it, when Iran entered into serious (but then still secret) negotiations with the United States in 2012, it had accumulated significant leverage, in the form of thousands of nuclear centrifuges, tons of low-enriched uranium, bunkered uranium-enrichment facilities, and a nearly completed heavy-water reactor.

President Barack Obama took two additional steps that persuaded Iran to talk and ultimately reach a deal: He took regime change off the table and openly declared that Iran, in principle, would be allowed to enrich uranium on its own soil. So if coercive diplomacy was a factor in bringing Iran to the table, it was not the only, and perhaps not even the principal, one. Iran had built up leverage that it could trade against the lifting of sanctions, and it was offered a realistic way forward. Today the Iranian leadership sees nothing of the sort. That is why it rolled back some of its commitments this week and issued an ultimatum to the deal’s remaining parties that either they step up to salvage the deal or it would step aside from its commitments.

These factors suggest that whatever the benefits, great risks are built into Trump’s maximum-pressure campaign. For one thing, it increases the threat of a nuclear escalation: If Iran reneges on its obligations under the nuclear deal, the United States and Israel will respond by targeting Iran’s resurgent nuclear program, and Iran might direct its allies in the region to target Western assets and personnel.

But even without such a nightmare scenario, the Trump administration’s approach is self-defeating in the long term. The sanctions will reduce Iran’s pro-Western middle class to tatters at a time when the country stands in front of a major transition to a post-1979 leadership. Regime hard-liners, meanwhile, stand to benefit financially from sanctions through their control of the black market and politically through their control of a repressive apparatus to put down dissent. The net effect is a country with its economy in ruins but its regime intact—a political victory snatched from the jaws of economic defeat.

Sanctions, the U.S. travel ban, and a lack of sensitivity to Iranians’ sense of dignity could combine to harden the perception that U.S. policy is indiscriminate and implacable. This is a formula for perpetuating enmity between the two countries for another generation.

Trump and his closest advisers may discover that history will not bend to their will. Rather than trying to achieve the unattainable goal of Iran’s surrender, they should act to prevent another costly U.S. war of choice. This would require stepping back from maximalist demands, and using sanctions as a scalpel, not a chainsaw. In practice, that would mean lifting sanctions gradually and conditionally. The question is whether Trump can find his way out of the escalating confrontation, toward win-win negotiations.



I do not normally watch Tucker Carlson’s Fox News show, but when the fate of the Earth is at stake, I make an exception. On Friday night, after an extraordinary week of brinkmanship in the Persian Gulf, Carlson delivered a seven-minute philippic against John Bolton, President Trump’s national security adviser. Bolton is the most bellicose in the West Wing of the White House, and according to reports, he has advocated military action against Iran in retaliation for the attacks on oil tankers and the downing of a $130 million U.S. drone in the Strait of Hormuz. Trump says he called off a military strike with an hour to go—reportedly on the private advice of Carlson.

On his show, Carlson described Bolton as “a bureaucratic tapeworm. Try as you might, you can’t expel him.” (Bolton served in three Republican administrations before Trump but was out of government from 2006 until his appointment to head the National Security Council last year.) He and other neoconservatives had beguiled previous presidents of both parties into invading and destabilizing stable countries such as Syria, Libya, and Iraq. They are parasites, Carlson said, and Bolton would “live forever in the bowels of the federal agencies, periodically reemerging to cause pain and suffering but never suffering himself.”

Carlson is wrong about tapeworms, which usually get expelled after a single dose of praziquantel, and do damage only before emerging, not after. Is he also wrong about Bolton? I profiled Bolton for the magazine in April and found the accusation that he is a neoconservative wrong. Bolton isn’t that sentimental. He served with neoconservatives in the second Bush administration, but unlike them he harbored few illusions about America’s ability to bring democracy to the Muslim world by means of cruise missiles and U.S. Marines. Instead he agrees with Trump: America must be made great again, and the rest of the planet can go to hell if it tries to stand in our way. Trump bombed ISIS indiscriminately, but he happily befriends tyrants if they join Team America. Bolton is no different. His closest friends among the Iranian opposition belong to the Mujahedin-e Khalq, a cultlike religious group that was still a State Department–designated foreign terrorist organization when he spoke at one of its rallies in Paris. The group hates the Iranian government, though.

So what justifies Carlson’s wrath? It’s true that Bolton’s answer to most questions is war or the threat of war—and against Iran in particular, he has advocated bombing campaigns, even (or especially) when other Americans are exploring normal relations. When Bolton served the Bush administration as the State Department’s subcomandante for arms control, he nitpicked every international agreement relating to Iranian and North Korean nuclear programs, and in so doing he forced colleagues to acknowledge that both countries had violated their agreements. Whether improved agreements or aerial bombing would have improved their compliance is another issue. Bolton’s view has been consistent: Don’t make a deal until you’ve shown your enemy that his alternative is annihilation. And if you make a deal, accept no violations, and keep the bombers fueled in case you find any. Carlson is a dove, and he says threats of annihilation are “demented ... Normal people don’t talk like that.”

These are baffling times: With only minor modification one could imagine an identical rant against Bolton from, say, Chris Hayes at MSNBC. (Hayes would, I suspect, have refrained from calling neoconservatives or any other humans tapeworms.) Trump’s account of his decision to call off the sorties focuses on the deaths of Iranians. “How many people will be killed?” Trump asked his generals. When the answer (“150, Sir”) came back, he reacted with very un-Boltonian sentimentality, noting that the plane Iran shot down was just a machine, and the Iranians are humans—“every one of them someone with a family,” Carlson said the next day. I find this one of the more endearing things Trump or Carlson has ever said.

But as a matter of international relations, rapid fluctuation  between policies is disastrous. It gives adversaries a wedge.

In my profile of Bolton, I quoted a North Korean official who in 2003 called Bolton “human scum,” a “bloodsucker,” and “a beastly man bereft of reason.” Irritating America’s enemies was no liability in the Bush administration. But the North Koreans responded to Bolton’s methods by trying to go over his head, since they had reason to believe his president was, like most humans, more of a softie. The North Koreans’ invective ended by noting that George W. Bush seemed, by contrast, a nice guy, and that in the future they intended to deal with him, rather than with the subhuman parasite he had designated as his envoy.

If the national security adviser has no heart, and the president has no brain, their adversaries will play their respective deficits off each other, appealing to the heart when the brain says no. Bush and Bolton were at least in general agreement, and the North Koreans’ hope of splitting them was just that—a hope. Presidents have disagreed with their national security advisers before. Now, however, the split is real and visible. National security advisers have, in the past, had confidence that their presidents would at least approach international security issues consistently, so that threats bore the proper menace, and enemies could not respond by waiting around for the boss to change his mind. Bolton never changes his mind, but Trump changes his mind constantly, so who cares?

The Iranian strategy is, as Mike Doran notes, to convince the president that his government is captured and controlled by maniacs, who are whispering bloodthirsty advice to him from within the White House. (Given the Iranians’ fondness for anti-Semitic rhetoric, it should be noted that “neoconservatives” is often code for “Jewish.” Bolton isn’t Jewish, but Carlson named Bolton’s “old friend” Bill Kristol, a Jew, as if the former Weekly Standard editor headed the cabal that was influencing him.) Whatever Bolton’s faults—and they are considerable—he is one of the only senior national-security officials to have worked on this sort of crisis before, and to wedge him away from the president is to increase the chaos in an already wild administration. Carlson even repeated, on the air and apropos of nothing, a statement of Persian cultural supremacy: “Iran is a sophisticated country,” he said, and its cities “not at all like Riyadh or Dubai,” the seats of Gulf power friendly to Trump and unfriendly to Tehran. I like the poetry of Hafez and Rumi as much as the next person, but it is nonetheless startling to hear Iranian propaganda repeated on Fox News.

When Bolton was appointed, his political allies and enemies all agreed that he was a rarity in the Trump administration: a bureaucrat who knew the bureaucracy and could make it follow his commands. He has spent much of the past year denying that he has the powers attributed to him. “I am the national security adviser,” he told me, “not the national security decider.” In the end, Bolton wields only the power the president allows him. And once it becomes known that the president favors the advice not of his government but of his favorite television host, Americans (and foreign powers) might conclude that  we have no government at all. Bolton’s immediate prior employment, before joining the administration, was as a pundit on Fox News. Now that Fox’s star host has savaged him, and his president apparently agrees that he is a parasite, I suspect Bolton is thinking about drafting a letter of resignation and a fresh C.V., all at once.



Why have national Democrats and not national Republicans fallen under the tyranny of the 70-somethings? It seems so contrary to common expectation. Democrats are, as they often remind us, the party of progress and the future. The question seems to rival those enduring, unanswerable mysteries such as “What happens when you die?” and “Why did Mick Taylor quit the Rolling Stones?”

People in their mid-to-late 70s are thick on the ground nowadays, while in an earlier era, of course, you’d have been more likely to find them under it. This is especially true in the urban centers of the Northeast and mid-Atlantic, according to a recent survey of census data by the Associated Press–NORC Center for Public Affairs Research. In particular, the Washington, D.C., area is a leader in “senior labor force participation,” by which the researchers mean the region is loaded with people who have passed the age of retirement yet somehow neglected to retire.

Look no further than the Democratic caucus on Capitol Hill. For whatever reason—perhaps they’re more easily bored by government work, or perhaps they’re more eager to cash in on government work—Republicans have less of a 70-something problem. House Republicans are relatively youthful, in chronology if not in disposition: They are led by a trio ages 54, 53, and 52. Indeed, the only 70-something among the GOP leadership on the Hill is the 77-year-old Mitch McConnell (I’m omitting the constitutional office of president pro tempore of the Senate, now occupied by the Republican Chuck Grassley, who is 85 but doesn’t look a day over 86.)

Going down the ranks, the public-affairs software firm Quorum reckoned that the average age of the Democratic House leadership is 72, fully 24 years more than the average of the Republican House leadership. Infamously, the three leading Democrats in the House are 79, 78, and 79, for a staggering combined age of 236, making the Democratic leadership team older, in aggregate, than the Constitution itself.

The party’s congressional gerontocracy has now inevitably bled into the field of presidential candidates. The front-runner, Joe Biden, is 76. Second place, according to most polls, belongs to Bernie Sanders, who’s a year older than Biden. They hope to replace the oldest man ever to be elected president. He’s younger than both of them. If either Biden or Sanders gets to the White House and then wins a second term, we will be governed by a man in his early 80s, nearly two decades older than Franklin D. Roosevelt was when, having won his fourth term, he pegged out from overwork. Needless to say, Sanders and Biden are each much spryer than FDR. Imagine Dick Van Dyke from Mary Poppins Returns clicking his heels in the Oval Office.

To be sure, anyone who criticizes our gerontocracy must insert a “to be sure” paragraph right about now, praising the gumption and resilience of our oldsters, marveling at their energy and their bottomless reservoirs of wisdom. Stipulated! Nancy Pelosi, Steny Hoyer, Biden, and Sanders—and especially the McDonald’s-loving 72-year-old incumbent—are walking testaments to the advances made by geriatric medicine since the 1950s, when they were teenagers. The idea that with length of days comes wisdom is a commonplace of our patrimony, from Aristotle and Job to Shakespeare and Austen. And all the flattering things we are required to say about old age and the people caught up in it do serve as a much-needed counterbalance to our culture’s childish obsession with youth.

But this traditional picture of old age as the repository of wisdom comes with certain complications. Gerontocracy is rule by people who insist on turning the peak of their career into a plateau. Aristotle and the others acknowledged that it carries hidden and insidious effects, and reveals unflattering qualities in the gerontocrats themselves. We can see this most obviously in the effect it has had on the Democratic Party generationally. There is a huge gap between where the energy and creativity of the party lie, with a group of dynamic activists and House members in their 30s and even their 20s (thank you, Alexandria Ocasio-Cortez), and the ruling class of 70-somethings layered far above like a crumbling porte cochere.

In the farm system that trains and seasons the leaders of tomorrow—assuming tomorrow ever comes—that gap signifies a lost generation. One day, presumably, power within the party will pass, and when it does, if present trends continue, it will leapfrog from seniors born around the time of V-J Day to people who can barely remember 9/11. More likely than not, members of Generation X will never get their turn—an entire cohort condemned to the fate of Prince Charles. After the indignities that Boomers inflicted on Generation X, from disco to postmodern literary theory, this scarcely seems fair.

The situation pushes some Gen Xers to take extreme measures. The far-fetched presidential campaigns of backbenchers such as Tim Ryan and Seth Moulton are best understood as cries for help, as ambitious young politicians try to free themselves from the professional bottleneck created by unbudgeable leadership.

Some 70-somethings are easier to forgive than others. Pelosi and her team are simply aging in place, clinging to a version of the jobs they’ve held for a decade or more; inertia could be as much to blame for their refusal to move along as an unslakable thirst for power and attention. There’s less to forgive in the actions of Biden and Sanders. Three years ago, both were given the chance to leave the field gracefully. But they. Will. Not. Go. Away.

Sanders, holding political positions virtually identical to those of his rivals, offered a less plausible case for his candidacy than Biden did. Biden’s case, which you could strain to make if you were willing to risk a herniated disk, was ideological: He filled a slot that no one else would fill. He was carrying the pragmatic liberalism of an earlier time into a scrum of leftish contenders who believe that pragmatism is for chumps.

That case was dashed last week with Biden’s head-snapping reversal of his 40-year support of the Hyde Amendment, which bars the use of federal funds to pay for abortion. Far from serving as an alternative to the radicalism of one segment of his party, Biden showed that he is willing to be its slave—if that’s what it takes to win approval for his dream of apotheosis. Such groveling is unlovely enough in people in the robust prime of life; it is doubly so in old people, who, by virtue of their age and experience, are supposed to know their own mind.

The only cure for the desire to be president, a wise politician once said, is embalming fluid. Let’s stipulate to that, too. We all need purpose and meaning in life. The trick for old folks is to adjust their search for purpose and meaning as they follow nature’s course and give way to their juniors. The avenues to self-fulfillment that were open to them as younger men and women are now the rightful territory of a newer generation, and dignity requires them to find other paths of service and satisfaction.

I can easily imagine a host of dignified futures for our 70-something presidential candidates, far from New Hampshire and Iowa. Sanders could work as a tour guide in Nicaragua or a docent on fundraising cruises for The New York Review of Books. Biden, for his part, could take on the once-popular, now-neglected role of “elder statesman,” happy to serve when called to a blue-ribbon panel or as a special envoy to trouble spots here and there, to offer advice when his advice is sought, and otherwise to lead a life of recreation, reading, and contemplation. No one will think less of either of them.

Instead, they have chosen the way of vanity and self-indulgence, to the detriment of the political cause they say they want to advance. Sanders and Biden have made themselves the equivalent of the old dude cruising the pool at Club Med in his sagging Speedo, capped teeth gleaming, knobby shoulders and fallen pecs bronzed and shiny with tanning oil, gold chains twinkling through the chest hair. I’m not saying one of them won’t succeed in his quest—though I have my doubts about both—but in a saner world, it would be obvious that the quest itself is unseemly. They do no credit to their peers with their refusal to acknowledge their natural and inevitable station in life. And they do no favors to the younger people—from Pete Buttigieg, age 37; to Kamala Harris, age 54; and even to Elizabeth Warren, age 69—who are eager, as they are entitled to be, to take their shot.



Over the past few weeks, the parts of the world still dependent on fossil fuels—which is to say, all of them—have anxiously watched tensions rise in the Strait of Hormuz, the narrow channel between the oil-rich Persian Gulf and the deepwater shipping channels of the Indian Ocean.

Television broadcasts show images of U.S. naval vessels escorting oil tankers through the strait, ensuring that oil and gas reach their markets. And on the one hand, this is entirely appropriate and encouraging: The purpose of a navy, after all, is to safeguard the movement of friendly armies and commerce—and to deny one’s enemies the ability to do the same.   

On the other hand, the fact that U.S. naval vessels are escorting commercial ships in and out of the Persian Gulf is also an indictment of a U.S. policy initiative that has spanned at least six U.S. presidential administrations and has, until very recently, garnered bipartisan support in Congress: Our efforts to build military capacity among our partners in the Gulf.

The current crisis in the region offers an opportunity to assess not only the scale and efficacy of our efforts but also how we might tailor them to fit our strategic needs as much as those of our partners. Because it is not clear to me that what we’ve been doing over the past three decades has served U.S. interests.

Recently, of course, representatives and senators from both sides of the aisle have begun to question arms sales in the Gulf—to our Saudi and Emirati partners, in particular. Appalled by the loss of civilian life in Yemen and—in the case of Lindsey Graham, among others—pushed over the edge by the killing of the Saudi journalist Jamal Khashoggi, they have taken steps to prevent the administration from providing certain weapons to our traditional partners. The administration has responded by invoking a national-security emergency to continue doing just that, citing the threat posed by Iran.

I’m largely agnostic about the roles that the legislative and executive branches play in arms sales. I have more to say, though, about the strategic utility of the arms sales themselves. From 2015 to 2017, I served as the deputy assistant secretary of defense for the Middle East, which meant I had oversight of security-cooperation programs, including foreign-military sales, in the region. And during an earlier stint at the Pentagon, between 2012 and 2013, I led a project that examined, on a country-by-country basis, what actual stand-alone military capabilities our partners in the region had developed since U.S. security-cooperation efforts had really picked up, in the aftermath of the Gulf War.

That project was spurred by a persistent fantasy among think-tank types of a certain generation: What if we could build an “Arab NATO” in the Gulf? What if we could build a military coalition among our Gulf partners to constrain Iran in the same way we built a Western European military coalition to constrain Russia during the Cold War? 

It’s easy to see why some people advanced this idea. First, they were often among the same people who had argued for removing the most effective actual constraint on the ambitions of the Islamic Republic of Iran: Saddam Hussein’s Iraq. Second, despite in many cases serving as architects of, or cheerleaders for, America’s greatest blunder in the post–Cold War era, they retained enough strategic sense to realize that keeping tens of thousands of U.S. service members in the Gulf didn’t make a lot of sense in a century in which China would challenge the United States for hegemony in the Pacific.

Indeed, by the time I left the Pentagon in January 2017, we had roughly 35,000 troops in the Gulf alone, and these troops were mostly housed in semipermanent bases. I used to review the annual construction plans submitted by U.S. Central Command and marvel at all the concrete we were pouring into a region that we all knew, in our heads if not our hearts, should matter less to us in the coming century.   

I hope the Saudi-led embargo of Qatar and the self-defeating fracturing of the Gulf Cooperation Council has finally pounded a wooden stake into the heart of the Arab NATO vampire, and that future Pentagon desk officers will not be as tormented as I was. What did we learn, though? Well, a few things. I’ll give you the bad news first, which isn’t entirely bad. And then I’ll give you the good news, which isn’t entirely good. (Sorry, this is the Middle East—you need to get used to such ambiguities.)   

First, let me be impolite but clear: Despite spending billions of dollars on military hardware, our Gulf partners do not have very good militaries. They sport large collections of weapons and equipment—some shiny, some rusted—but not real capabilities. That’s why I raise my eyebrows when administration officials cite the threat posed by Iran as a reason to keep arming these partners over the objections of Congress: In an actual war with Iran, we would likely not ask our Gulf partners to do much more than stay out of the way. We do not, for the most part, trust their ability to participate in what would be a very stressful, very challenging, and highly kinetic conflict.

The war in Yemen has been a humanitarian nightmare, but it has also been illuminating from the perspective of defense policy. We can finally see what our various regional partners—the Saudis, the Kuwaitis, the Bahrainis, the Emiratis—can and cannot do. The result has not, for the most part, been pretty.

When I was at the Pentagon in my last job, we determined that the majority of civilian deaths in Yemen were not caused by crimes of malice but by crimes of incompetence: The Saudi-led coalition’s air force simply could not plan and execute an independent air campaign that either accomplished its strategic objectives or, failing to do that, at least minimized civilian casualties. The Saudis realized this, early in the campaign, and they begged us for more help, which we were reluctant to give, because we didn’t want to own any more of their war in Yemen than we already did—especially when we had a fight against the Islamic State on our hands and needed all available resources to defeat it.

Compounding these failures is the fact that our Gulf partners have largely invested in those areas where they cannot match the United States, and not in those areas for which the United States could actually use partner capacity. They have spent a lot of money building very expensive air forces, for example, that largely cannot do what their leaders need them to do. But these countries—whose economies depend on their ability to move oil and gas to the market by sea—haven’t spent much money at all on naval forces that can patrol their sea lanes, or minesweepers that can reopen those same sea lanes through either the Strait of Hormuz or the Bab el-Mandeb.

That’s why you are more likely to see a U.S. naval vessel escorting an oil tanker through the Strait of Hormuz than you are to see a Gulf naval vessel. As a U.S. military officer wryly lamented to me on a visit to one Gulf country, “Out of the three services here, sir, the navy ranks fourth in terms of priority.”

But ground forces don’t fare much better. Like naval surface warfare, ground combat and the things one has to do to be good at it are not sexy. You need to be physically fit (which involves running a lot), spend a lot of time on the rifle range (which involves sweating a lot), and rehearse battle drills and other collective tasks ad nauseam (which involve both running and sweating a lot).

I once spent five months doing all that with a light-infantry platoon in the heat of the Kuwaiti desert and … well, it’s not always fun. The sun sucks, the sand sucks, and you’re trying to keep a bunch of teenagers focused in 100-degree heat. I get it. Getting shot by the enemy, though, is less fun, and along the border with Yemen, Saudi ground forces in particular have proved largely incapable of closing with and engaging the enemy—which is the entire point of possessing ground-maneuver forces.

The failure of Saudi and allied ground forces has contributed to their overreliance on air forces, which have spent most of the past few decades practicing air-to-air combat (which they’re still not very good at, if we’re not grading on a curve) and were largely unprepared for what they were asked to do over Yemen—as lots of Yemeni civilians sadly discovered.

The silver lining to all this bad news is that none of our Gulf partners looks ready to challenge Israel’s qualitative military edge anytime soon, individually or collectively, and we retain some leverage over our partners so long as they remain reliant on us for their collective defense.

The good news, meanwhile, is that some of our partners in the region—not many, but some—have developed real and formidable military capabilities. Our Emirati partners, for example, are able to conduct truly independent military operations, and their air forces and special forces are capable of operating alongside ours. They have done so, in fact, over the past decade—including in Afghanistan.

Indeed, one of the things that’s missing from the spate of recent articles bemoaning the influence of the United Arab Emirates in Washington is the real value proposition that the Emiratis bring to the table. The reason U.S. military officers, especially, fall in love with their Emirati counterparts is because the Emirati crown prince, Mohamed bin Zayed, has invested in actual capabilities and has military forces the Americans can treat as peers.

Of course, the danger of helping your partners create independent military capabilities is that, if you succeed, you’ve helped your partners create independent military capabilities. They may use their newfound capabilities—from Yemen to Libya—in support of strategic aims that diverge from your own. (In Yemen, our Emirati friends have discovered something that we ourselves were reminded of in Iraq and Afghanistan: Operational excellence alone is often not enough to realize strategic victory.)

So why does the current administration fight so hard to keep arming our partners in the Gulf? I don’t think it’s as simple as the need to support the U.S. military industrial base, though that is a concern I’m sure it has. Some U.S. strategists genuinely fear that if we do not arm our partners, our Russian or Chinese rivals will. They can’t cite that fear to justify the “emergency” that allows us to continue arming the Saudis and Emiratis over congressional objections, because it’s more of a strategic concern, but based on my conversations with U.S., Saudi, and Emirati officials, it’s a major driver of American policy.

I’m just not sure that is a good-enough reason. Russia and China cannot, in the near term, rival the numbers of personnel we have deployed in the region. None of our partners is going to call the Chinese military to save them from the Iranian navy. So we should probably stop being so scared of the Russian or Chinese bogeymen, no matter how much our partners might publicly flirt with our rivals. One of the reasons they do that, after all, is because their strategic interests diverge from ours: We want to rebalance our resources toward future security challenges, while they want to keep as many of our forces tied down in their region as possible.

Going forward, we can afford to focus on building our allies’ capacity only when we expect to reap a direct benefit. Especially following large recent sales of aircraft to Saudi Arabia (F-15s), Kuwait (F-18s), and Qatar (F-15s), we’ve probably sold enough advanced fighter aircraft to the region. The Saudis and others will claim they now need F-35s and F-22s to deter Iran, but there is no evidence to suggest that Iran has been in any way deterred by the fourth-generation fighters, so I’m not sure why fifth-generation fighter aircraft would suddenly cause Qasem Soleimani & Co. to change their behavior.   

We need to help our allies build capabilities that will allow the United States to do less, and that largely means building up naval forces and integrated air and missile defenses—another rare bright spot in U.S. capacity-building efforts (at least until the Gulf militaries all stopped talking to Qatar, home to the largest U.S. air base in the region). You want to sell weapons to the Gulf? Fine. But sell them some frigates and air defenses.

That’s not going to be easy for two reasons: First, unlike Egypt or Lebanon or Israel, the Gulf militaries are not the beneficiaries of U.S. largesse in the form of foreign military financing, a mechanism whereby we give countries funds to spend on U.S. weapons and training. The Gulf states have their own dollars that they can spend as they like, and they don’t have to spend those dollars on U.S. weapons. If we don’t sell them a certain weapon system, they can buy a similar one elsewhere. But they do so at their own risk. If you buy a bunch of Chinese drones and allow Chinese engineers to walk around your air bases, it will not be long before those U.S. aircraft and U.S. military personnel find another base. And our Gulf partners don’t want that. They like keeping us close.

Second, our Gulf partners have been masterful at scaring the wits out of successive U.S. administrations, by suggesting they fear we will abandon them. Condoleezza Rice, for example, came back from a meeting with the late King Abdullah of Saudi Arabia in the second term of the George W. Bush administration, alarmed by the king’s worry the United States was leaving the region—this at a time in which we had 150,000 troops in Iraq alone. That fear helped spark what has now been a decade-long push to sell more U.S. weapons to our Gulf partners, increasing interoperability and thus deepening the bilateral ties between our respective militaries.

But our Gulf partners will always claim we are abandoning the region; even permanently relocating the XVIII Airborne Corps to Kuwait would not change that. They did it during the Bush administration, they did it during the Obama administration, and I bet they are doing it today, during the Trump administration. That fear is grounded in a clear-eyed view of our presence in the region. They can see it makes little sense—not in our current numbers. They know, in their hearts, that we have bigger priorities elsewhere.

If only our hearts knew the same.



What is the point of a university press? Should it be expected to support itself? These questions are at the heart of a debate triggered by the Stanford University provost Persis Drell, who indicated in April that the school would impose massive funding cuts on Stanford University Press (SUP). The university appeared poised to completely or almost completely eliminate the press’s $1.7 million annual subsidy, a sum essential to SUP’s continued operations. After sustained pushback from the academic community, Drell sent a message to the faculty promising to “make one-time funds available to the Press,” with the possibility of giving it “incremental funds” in future years, combined with potential opportunities to raise funds from philanthropists, thereby creating a “sustainable” funding model. Nonetheless, the long-term future of the press remains in doubt. SUP probably cannot keep up its operations without significant university funding on top of the $5 million annual income it generates from publications.

The controversy reflects broader concerns about the future of academic presses. If one of the nation’s wealthiest and most prestigious universities is apparently willing to gut its highly respected press, that does not bode well for other academic publishers. And if academic publishing goes into decline, that in turn could impede the production and distribution of new knowledge—a prospect that should concern even the many people who do not read, much less write, academic books.

According to Peter Berkery of the Association of University Presses, some 80 percent of university presses receive subsidies from their affiliated institutions, which on average account for roughly 15 percent of their total budget. Without that additional funding, the presses would have to significantly curtail their operations, and some might even have to shut down. While some university presses engage in wasteful spending, the fundamental reason why most require subsidies is that they are not intended to make a profit. This point brings us back to my first question: What is the point of a university press? Its main task, quite simply, is to publish works that expand our knowledge. Such books do not necessarily attract a large readership. A book that makes a major contribution to science, art, or history might attract a readership limited to a few specialists. Sometimes, specialists are the only people who can even understand it. But the advances in knowledge that such books facilitate can greatly benefit society. A better understanding of history, law, economics, or political science can improve the quality of public policy. Advances in scientific knowledge can lead to improvement in many fields. Many such advances in knowledge are “public goods” that benefit people who cannot be induced to pay for them. As a result, conventional for-profit enterprises may underproduce them.

Academic publishers are not indifferent to profit. I have published books with several academic presses, including Stanford (the publisher of my book Democracy and Political Ignorance: Why Smaller Government Is Smarter). Every contract negotiation I have had involved discussion of potential markets for the book. After Democracy and Political Ignorance sold thousands of copies and attracted considerable attention, publishers took a more favorable view of my later book proposals. But we should not expect university presses to publish books only likely to make a profit.

Granted, university presses publish a fair number of books that produce neither profits nor valuable contributions to knowledge. But predicting which books will make a notable intellectual breakthrough is often even more difficult than predicting which ones will make a profit. In many disciplines, scholars have significant disagreements about methodology and objectives. Publishers need to consider a wide range of works to reflect the field’s diversity. When divergent methodologies conflict, at least one of them might well be an intellectual dead end.

A minority of academic publishers do manage to self-finance. Some, such as Harvard University Press, have large independent endowments, separate from those of their university. University of Chicago Press (the publisher of my book The Grasping Hand) has a successful book-distribution business that helps finance its other projects. Oxford University Press (with which I have a forthcoming book) has a large backlist of books that appeal to general-interest readers. A few university presses manage to make large profits publishing academic journals, which in turn finance their book publishing. But these strategies are unlikely to work for most university presses. Few can develop the donor bases needed to build up large endowments. Similarly, few can publish academic journals that sell more than a small number of copies.

None of this suggests that higher education is free of wasteful spending. Far from it. But university presses are only a tiny fraction of total university expenditures. Stanford’s annual $1.7 million grant to SUP is a mere 0.03 percent of the university’s $6.3 billion annual budget. And the admittedly risky investments these publishers make often result in valuable works that would not have been produced otherwise. Universities would do better to cut back on academic bureaucracy, which has massively grown in recent years, with costs that far outstrip expenditures on academic presses.

When I previously wrote in defense of SUP, some readers wondered why I, a libertarian, would criticize the decision of a private institution and urge it to continue funding a money-losing enterprise. I cannot claim to be a completely detached observer. But libertarianism is a political theory that favors voluntary cooperation over state coercion, not a theory that holds that the only worthwhile enterprises are those that make a profit. Still less does it claim that private institutions never make mistakes. Such errors are especially common in the nonprofit world, where the value of output is hard to measure.

Academic presses published pathbreaking books by leading libertarian thinkers, including F. A. Hayek and Milton Friedman, at a time when other publishers were reluctant to print them. Without those crucial early publications, libertarian ideas might not have achieved their current prominence. The same is true for many other schools of thought that challenge dominant intellectual orthodoxies.

Whether libertarian or not, we all have an interest in promoting the development and diffusion of knowledge. Despite their flaws, university presses make a valuable contribution to that enterprise.



The key word in Joe Biden’s announcement video is aberrant. If Donald Trump serves only one term, Biden declares, “I believe history will look back on four years of this president and all he embraces as an aberrant moment in time.”

Before Trump, the former vice president implies, a moral consensus reigned. America, he declares, “is an idea”—an idea that “everyone is treated with dignity,” and that “gives hate no safe harbor” and “instills in every person in this country the belief that no matter where you start, there’s nothing you can’t achieve if you work at it.” That, Biden explains, is “what we believe”—or at least we did, before Trump came along.

That’s a fundamentally different message from the one being peddled by Biden’s key competitors, who see Trump not as a historical aberration but as the outcome of a long historical decline. Bernie Sanders and Elizabeth Warren both depict Trump as a manifestation of the class war that the ultrarich have been waging since the Ronald Reagan era; in their telling, this war created the economic insecurity that made working-class whites susceptible to Trump’s racist scapegoating, and Trump is escalating the conflict by handing over the government to corporate and financial interests. Pete Buttigieg, meanwhile, attributes Trump’s rise to America’s long-standing failure to meet the challenges of globalization, a failure that has left Americans susceptible to “the myth that we can stop the clock and turn it back” to an era before automation and outsourcing.

Biden, by contrast, describes Trump not as the consequence of long-festering American ills, but as the antithesis of long-standing American ideals. He starts the video by noting that Charlottesville, Virginia, is the home of Thomas Jefferson, who authored the words All men are created equal. Americans “haven’t always lived up to these ideals,” Biden acknowledges. “But we have never before walked away from them.” Until Trump.

Biden’s distinction—between not “living up to ideals” and “walking away from them”—is meaningless. America “walked away” from the ideals of human equality at its founding, when it enforced slavery, ethnically cleansed Native Americans, and denied women the vote. Since then, America has oscillated between eras such as Reconstruction, from 1865 to 1876, when it moved closer to equality under the law, and eras such as Redemption, when whites reestablished racial supremacy in the years that followed. As Ta-Nehisi Coates and Adam Serwer have argued, America is experiencing an era like Redemption again today.

In every era, there are different versions of the American idea, some more inclusive and some more exclusive. Discouraging nonwhites from voting—as Trump is doing now—is as deeply American an idea as demanding that they gain access to the ballot. Opposing immigration by people of alien races and faiths is as American as welcoming them.

It’s not surprising that Biden, of all the Democratic contenders, would come closest to a Democratic version of “Make America great again.” He served in the Senate from 1973 until he became vice president in 2009. He has to defend the pre-Trump era. If he described Trump the way Sanders and Warren do—as the product of a decades-long, bipartisan descent into oligarchy—he’d be condemning himself.

Biden’s problem is that while most Democrats like Barack Obama personally, the party has lurched left since he left office, and many of its activists now take a dim view of policies that Democrats once deemed mainstream. Thus, if Biden had entered the presidential race with a standard biographical video describing his many accomplishments in public life (something his website actually offers), he would have immediately prompted a debate about all the positions he once took—on crime, financial deregulation, Anita Hill, and the Iraq War—that Democrats now scorn.

Biden evades that problem in his announcement video, but at a cost. He bathes the past in a warm glow without defending it substantively. And in so doing, he offers a deeply unconvincing historical narrative in which Trump lands upon the American political scene from outer space.

In his announcement speech, Buttigieg warned against romanticizing “a bygone era that was never as great as advertised to begin with.” Although that comment was meant as a dig at Trump, Biden has reason to worry. If his announcement video is a sign of things to come, it could be an effective line against him, too.



President Donald Trump is reportedly planning to mark Memorial Day by pardoning several American military members accused or convicted of war crimes. If he does so, it would undermine our military-justice system, weaken good order and discipline in the ranks, erode trust with our allies and partners, and sanction the worst inclinations of our adversaries.

During my three decades in the Marine Corps, as an enlisted marine and officer, on active duty and in the Reserves, I received endless training. Some was devised to instill discipline and inculcate high standards of conduct. Other training stressed the importance of ethics and adherence to laws and regulations. Some of the training was scenario-based, to demonstrate that choices weren’t always easy or clear, particularly in combat. We were taught to “choose the hard right over the easy wrong.”

Over the course of my three deployments involving combat and peacekeeping duties, I was fortunate never to have been required to fire my weapon to take a life. I did not have to make a split-second decision to kill another human being. But I was trained to do so—taught not just marksmanship, but also practical decision making and the laws of war. We operated with weapons of war, but we were expected to be judicious in their use.

Everyone serving in the U.S. military, from privates to generals, is expected to adhere to the highest standards of conduct, on the battlefield and off. Some do go astray, in matters both minor and major, but the military-justice system exists to hold them accountable for their actions.

The Uniform Code of Military Justice (UCMJ) dates to 1950 and serves as the foundation for military law. Its stated purpose is “to promote justice, to assist in maintaining good order and discipline in the armed forces [and] to promote efficiency and effectiveness in the military establishment.” Pardoning those who have been accused or convicted of serious crimes would undermine the military-justice system.

Those who serve this country in uniform, who are entrusted to operate and carry weapons and are trained and authorized to use deadly force, must adhere to the highest standards of discipline and conduct, and strictly follow the lawful orders they are given. Those who fail in their duties and responsibilities must be held accountable for their decisions and actions. They are accorded due process through the UCMJ and military-justice system, and held accountable by men and women who also serve in the profession of arms.

In civilian courts, a “jury of your peers” might include accountants, electricians, teachers, factory workers, and the self-employed. In the military system, the jury in a court-martial proceeding is composed of fellow service members, members of the same challenging profession, with similar training and experiences. Those convicted by a military judge, or members of a court-martial panel, have truly been judged by a jury of their peers.

Pardoning military war criminals is a departure from our values, and sanctions the mistreatment of combatants without national accountability.

Those convicted of committing crimes that violate the law of war, who used their weapons to wantonly harm innocents or those under their care—the wounded, the sick, prisoners, or detainees—violated their oaths and the sacred trust placed in them. Pardoning them sends a signal to the entire force as well as to our allies and adversaries that the U.S. military can’t be trusted to live up to its values and obligations. This erosion of trust exposes those who volunteer to serve in our armed forces, today and into the future, to greater risk.

If the governments of those countries in which U.S. service members operate do not believe that our military-justice system will hold accountable those convicted of wrongdoing while on their soil, they will increasingly seek to arrest, imprison, and try those service members in their own courts. That is an outcome we cannot accept, and the commander in chief should not take actions that would cause those governments to consider such steps.

Lieutenant Commander John McCain was shot down over North Vietnam in October 1967. In addition to the broken bones suffered in his ejection from his stricken aircraft, he had his shoulder broken by a rifle butt and his foot bayoneted. During his nearly five and a half years as a prisoner of war, he was beaten, tortured, and given little medical care for his injuries. His treatment at the hands of his captors violated the Geneva Conventions and international law governing humanitarian treatment during war or armed conflict. The torture of McCain as a POW is what happens to Americans when other nations depart from accountability for norms of conduct during armed conflict.

Today McCain lies at rest at the United States Naval Academy. He and the other veterans in cemeteries around the world, who have worn the cloth of our nation and upheld its highest values, should be remembered this Memorial Day—a day for commemorating our fallen heroes and their families. Pardons for those who violated the law and their oaths dishonor those who have kept their honor clean and those who have given their last full measure of devotion.



A year after abandoning the Iran nuclear agreement, President Donald Trump is doubling down on a risky and an ill-fated “maximum pressure” campaign. He’s tried to brand this strategy as a kind of coercive diplomacy, purportedly aimed at an elusive “better deal.” But so far, his strategy is all coercion and no diplomacy. His aggressive escalation of sanctions, the blustery rhetoric of his senior officials, and his administration’s lack of direct engagement with Tehran betray a fundamentally different goal: the capitulation or implosion of the Iranian regime.

Painful experience has shown that neither of those objectives is realistic. In the meantime, two sets of risks loom large.

The first is the risk of a violent collision, whether intended or unintended. In the past week, we’ve seen the U.S. announce the dispatch of an aircraft carrier and B-52 bombers in response to perceived Iranian threats against American personnel in the region. We’ve also seen reported attacks on shipping and oil infrastructure around the Persian Gulf. With American forces and Iranian proxies in tight quarters across Iraq, Syria, and the Gulf, and no direct communications between Washington and Tehran, either side could misjudge or misinterpret the other’s moves.

Trump’s hawkish advisers and the hard-liners in Tehran could easily become mutual enablers in pushing a crisis up the escalatory ladder. The idea that the conflict is inevitable can produce momentum of its own, as can the sort of hubris that led to a disastrous war in Iraq in 2003. And should Iran abandon the deal altogether, the odds of conflict will grow larger still.

An escalating conflict brings with it an increased risk of significant collateral damage. Fissures between the U.S. and our European allies are widening as a result of our withdrawal from the nuclear deal with Iran, our subsequent pressure campaign, and our erratic saber-rattling. We’re also eroding the long-term utility of economic sanctions with our reckless unilateralism. Even our closest partners have begun to talk publicly about reducing exposure to the American financial system as a hedge against U.S. economic pressure.

We’ve seen coercive diplomacy succeed with Iran—this is not how it works.

We’re the two negotiators who led the secret bilateral talks with the Iranians that paved the way for the interim and comprehensive nuclear deals between Iran and the so-called P5+1, the five permanent members of the UN Security Council and Germany. The United States built broad international pressure to bring Tehran to the table—the political leverage of an international community united in its determination to prevent Iran from developing a nuclear weapon; the military leverage of a credible threat of force; and the economic leverage of sanctions that ultimately produced a 50 percent drop in Iran’s oil exports and in the value of its currency.

That pressure was necessary but not sufficient, because pressure is not an end in itself. It was coupled with a realistic aim—a sharply constrained, tightly limited, and closely monitored civilian nuclear program—and a willingness to engage directly with the Iranians, not through empty summitry but over many months of arduous negotiations.

Now, after more than a year of coercion, with no capitulation or implosion in sight, and no shortage of risks on the horizon, it’s time to take diplomacy seriously again. That means going beyond the repetition of terms the other side won’t ever accept. The best way forward for the Trump administration is to signal privately that its maximalist demands are not carved in stone and pursue a more realistic agenda on nuclear issues. That starts with working to extend the nuclear deal’s timelines, and recognizing that further sanctions relief will be necessary to encourage Iranian acceptance; it means talking quietly about securing the release of Americans detained in brutal Iranian prisons; it means probing for possible understandings on Iran’s ballistic-missile programs; and it means encouraging dialogue on the wars in Afghanistan and Yemen, where Iran will be a player in any eventual settlement.

Contacts with the Iranians are not a reward for bad behavior, and we should have no illusions that they will engage productively on all our concerns. But diplomacy is the best way to test intentions and define the realm of the possible, repair the damage our unilateral turn has inflicted on our international partnerships, and invest in more effective coercion if and when it’s needed to focus minds in Tehran.

Coercive diplomacy—when both elements of the approach are carefully synchronized—can deliver. On the other hand, coercion without diplomacy can lead to huge blunders in the Middle East. We’ve seen that before. A lot is at stake over the coming months. Given the impulses and track record of this administration, it’s hard to be optimistic, and easy to see more trouble ahead.



President Donald Trump last Tuesday lamented on Twitter that “in the ‘old days’ if you were President and you had a good economy, you were basically immune from criticism.” The next day, he complained that Congress members “only want to continue the Witch Hunt, which I have already won.” In an interview with The Washington Post, Trump said, “There is no reason to go any further, and especially in Congress where it’s very partisan—obviously very partisan … I don’t want people testifying to a party, because that is what they’re doing if they do this.” Meanwhile, Trump has filed a lawsuit to avoid handing over his tax returns to the House.

Trump’s defiance of Congress is outrageous and dangerous. It also exposes Republicans’ hypocrisy. There is a world of difference between how Republicans viewed oversight when Barack Obama was president and their support of Trump’s obstruction. I know, because for five years I worked for Republicans on the House Oversight and Reform Committee.

In a 1957 Supreme Court ruling, Chief Justice Earl Warren wrote, “The power of Congress to conduct investigations is inherent in the legislative process. That power is broad … It comprehends probes into departments of the federal government to expose corruption, inefficiency, or waste.”

During my time on Oversight, the chief justice’s words were often cited as justification for our vigorous supervision of the Obama administration. Led by Representative Darrell Issa, my former boss, Republicans issued more than 100 subpoenas, held Attorney General Eric Holder in contempt of Congress, created a select committee to investigate Secretary of State Hillary Clinton’s handling of the Benghazi crisis, and filed a lawsuit in federal court challenging President Obama’s use of executive privilege.

In 2011, we sent a letter to Secretary Clinton that stated: “The Committee on Oversight and Government Reform is the principal oversight committee of the House of Representatives and may at ‘any time’ investigate ‘any matter’ as set forth in House Rule X.”

Also in 2011, when we suspected an effort to intimidate a witness called to testify at a hearing, Issa sent a letter warning the Obama administration that the “inappropriate effort to intimidate” and “discourage” someone from testifying before Congress was “an unlawful attempt to interfere with a Congressional inquiry.”

Yet when Treasury Secretary Steven Mnuchin last week ignored a deadline to produce Trump’s tax returns, House Republicans refused to speak out against this blatant disregard for legislative authority.

And Republicans did nothing when the White House last week instructed an administration official to ignore a subpoena and not testify at a hearing regarding White House security-clearance procedures.

Contrast that with the time an IRS official refused to answer questions from Oversight Republicans—they held that official in contempt of Congress. During the contempt proceeding, Representative Jim Jordan, now the ranking Republican on the Oversight Committee, justified his vote in favor of contempt by saying, “The only remedy we have to get to the truth is to use every tool at our disposal” to get that official to “testify and answer the questions. That is the only remedy we have. The only route to the truth is through the House of Representatives.”

President Trump and Republicans complain about the pace of oversight; Trump declared on Twitter on Wednesday that “there has NEVER been a President who has been more transparent.” But the simple truth is that this White House is more obstructionist than the Obama White House, or any other White House, and Republicans are enabling this behavior.

During the two years that Trump’s presidency overlapped with the Republican majority in the House, Republicans issued a total of zero subpoenas to the Trump administration. To date, Trump has refused to cooperate with subpoenas issued by congressional Democrats.

Trump’s desire to shield his tax returns may provoke a constitutional standoff with Congress. He wants to slow the pace of oversight as much as possible, which means a long and tedious legal battle that will likely be decided by the Supreme Court. Trump is betting that the American people simply do not care whether or not he cooperates with congressional investigations. He’s betting that they do not have the attention span to follow a long court battle about constitutional authority. Trump believes that his stranglehold on the GOP is so tight that his flagrant disregard for checks and balances won’t matter to the Republican base or Republican elected officials.

He might be right.

The entire point of having separate but equal branches of government was to create protections against the kind of tyranny and absolute rule that was common in Europe. If Trump can simply ignore Congress and act unilaterally without consequence, then he is America’s first dictator.

This fight is bigger than one hearing or one investigation or one subpoena. It is a struggle to preserve the foundation of our republic. Republicans won’t rise to the challenge. Which means it’s up to Democrats to keep Trump in check, and to support the Constitution. They have to learn to confront Trump as aggressively as we confronted Obama.



What do a Christian overnight camp, abstinence-only sex education, and pro-marriage advertisements all have in common? They’ve all been funded with money that used to provide cash assistance to low-income families.

In the United States, the federal Temporary Assistance for Needy Families program—often known simply as “welfare”—is administered by the 50 states, which have considerable leeway in how to spend the money. The choices states make are unmistakably correlated with race. The higher the proportion of African Americans in a state, the more likely officials are to try to change the way poor families run their lives, rather than simply help them with basic expenses.

Many know TANF as the nation’s primary cash assistance program for low-income families. But depending on which state you live in, TANF may provide barely any cash assistance at all.

In a new study published in the journal Socio-Economic Review, I find that a state with a higher share of black families is less likely to allocate TANF funds toward the provision of cash assistance, but more likely to allocate TANF funds toward efforts to “encourage the formation of two-parent families” and “reduce the incidence of out-of-wedlock pregnancies.” The stated assumption behind these initiatives is that strengthening the family unit has greater long-term benefits than simply giving money to needy people.

In practice, though, the diversion of TANF funds away from cash support and toward programs meant to influence family formation has likely exacerbated racial differences in poverty. A clear pattern emerges: A black family in poverty is more likely than a white family to be offered advice via a “Healthy Marriage Initiative” in place of direct cash support.

These racial inequities in states’ use of TANF funds turn out to have important consequences for racial differences in child poverty. I find, for example, that closing the racial differences in states’ use of TANF funds would narrow the black-white child-poverty gap by up to 15 percent.

Arkansas’s experience epitomizes these findings. The state has a large African American population and no shortage of poverty. Yet in 2017, Arkansas spent only 4 percent of its total TANF budget on cash assistance. Instead, the state allocated two-thirds of the budget for the “formation of two-parent families” and the “reduction of out-of-wedlock pregnancies.”

But Arkansas is hardly alone in spending less on cash support. From the introduction of TANF, in 1997, to 2017, total spending on cash assistance across all states declined from $14 billion a year to $7 billion. (In constant dollars, the amount of money spent on cash assistance has fallen by two-thirds.) While cash support has waned, however, states’ TANF budgets haven’t changed: The federal government provides states the same chunk of money each year to run their TANF programs. Thus, every dollar that a state does not spend on cash assistance should generally be spent on another program or service that, at least in theory, will support low-income families.

So where is the money? In Mississippi, a state that spends comparatively little on cash support, TANF funds have been used to finance an abstinence-only sex-education curriculum that “teaches the social, psychological, and physical effects of engaging in sexual activities.” Officials in Louisiana, where only 4 percent of poor families with children receive cash support, redirect TANF funds toward an Alternatives to Abortion program that discourages low-income families from terminating pregnancies. Southern states aren’t the only ones using the money for moral uplift. In Maine, children were bused off to a TANF-funded Christian summer camp. In Connecticut, TANF money was diverted toward compulsive-gambler assistance.

To be sure, not all of the excess TANF funds are spent on summer camps and sex ed. Many states use the resources to fund child-care programs, earnings subsidies for the working poor, and other efforts to promote or incentivize employment. Some states, such as Georgia, have spent the largest chunk of their TANF funds on child-welfare services and foster-care support. Both are worthy purposes, but other states pay for these services out of general revenues rather than TANF funds.

Meanwhile, fewer and fewer families in need are receiving direct cash support—an essential resource for reducing levels of child poverty.

To understand why a state’s racial composition is the strongest predictor of how it allocates TANF resources, consider that academic research has shown time and time again that many Americans tend to view black families as lazy, unworthy of help, and receiving “more than they deserve” from the state. Whether researchers are exploring Why Americans Hate Welfare, as Martin Gilens did in his 1999 book, or asking “Why Doesn’t the U.S. Have a European Welfare State?,” as Alberto Alesina and colleagues asked in 2001, the answer nearly always begins and ends with evidence of racialized perceptions of the beneficiaries of social assistance. These perceptions have crept into many policy-making decisions, including those relating to TANF. Indeed, my results show that—unlike race—the share of single mothers in the state, a state’s wealth, or which political party has control of its legislature explains little of the variance in states’ cash-assistance spending.

Removing the racial inequities in states’ TANF allocations would mark a large step in reducing racial differences in child poverty. For context, the estimated 15 percent reduction in the black-white child-poverty gap is comparable to the effect of moving all children from single-mother households into two-parent households (while keeping all other characteristics of the households as is).

This is not to say that single motherhood is unimportant—more children growing up in two-parent households would surely be a good thing. But if a state’s purported goal is to reduce the number of its residents living in poverty, offering cash support coupled with employment incentives is likely to be more effective than sex-education courses or ad campaigns “promoting the value of healthy marriage.”

TANF is not the only social program in the U.S. that stratifies low-income families based on state boundaries and skin color. In Jamila Michener’s new book, “Fragmented Democracy: Medicaid, Federalism, and Unequal Politics,” the Cornell political scientist depicts in vivid detail how state differences in Medicaid policies “tether health policy even more deeply to race and poverty.”

Most concretely, Michener points out that eight of the 11 states with the largest share of the nation’s black population are among those that have failed to implement Medicaid expansion. Even among Medicaid beneficiaries, access to dental treatment, hearing or vision support, and end-of-life services vary by state. If a person eligible for Medicaid “got sick in the wrong state during the wrong year,” Michener writes, “the consequences of policy fragmentation could be life altering.”

Other examples of “policy fragmentation” abound. Today, roughly half of the 50 states offer a supplement to the federal earned-income tax credit, but the average black family is less likely than the average white family to live in one of those states. States vary in levels of minimum wage, paid-leave policies, and investments in early-childhood education, but again, regional and racial inequities are large. And perhaps most damaging, states have long varied with respect to their criminal-justice policies. In 11 states, at least one in 20 black men is incarcerated. Ironically, the states most likely to chide black women for raising children alone—and to promote marriage as the key to poverty reduction—tend to be the same states that incarcerate the largest share of black men. Including the incarcerated population in our estimates of poverty in the U.S. would only widen racial divides.

“Federalism,” as Michener poignantly writes, “is a primary channel through which the geography of opportunity is shaped in America.” The question of in which state a low-income family lives is associated more and more with how well that family is able to live. And more often than not, low-income families of color tend to find themselves living within the borders of a more punitive state.

We often perceive policy makers as defenders of economic opportunity, and social policy as a set of tools to alleviate inequalities. But as Michener’s work shows, and as the data on TANF suggest, state governments often function as a source of inequality rather than its cure. Instead of narrowing gaps between the advantaged and disadvantaged, social policy can, when deployed unevenly across the country, act to deepen them instead.



A story commonly told these days on both the left and the right says that American Christians, and especially evangelicals, are solidly behind President Donald Trump. The real story is far more complex, and has led many Christians to some fairly serious soul-searching, and others to ask hard questions about whether we even know what an “evangelical” is. Among Christians, as among so many other Americans, one of the chief effects of the rise of Trump has been to widen some fault lines and expose others that we didn’t even know existed. It is at least possible that some good will come from this exposure.

You can see some of these fault lines opening up in a recent controversy that has greatly occupied many journalists, scholars, and ordinary people who care about the relations between Christianity and conservatism. The controversy began when Sohrab Ahmari, the op-ed editor of the New York Post, tweeted, “There’s no polite, David French-ian third way around the cultural civil war”—referring to the lawyer, former soldier, and senior writer of National Review who has often made the case that Christians in the public arena need to practice civility. Ahmari then expanded that tweet into a full-scale attack on French, and since then, the conservative world has been fairly obsessed with adjudicating the dispute.

It’s important to note that Ahmari sees the differences between him and French as rooted, ultimately, in their different Christian traditions: Catholicism for Ahmari—who recently published a memoir of his conversion—and evangelical Protestantism. But whether this is indeed the heart of the matter, the dispute so far hasn’t fallen out that way. Some Catholics are with French, some Protestants with Ahmari. And in any case, I’m more interested in the ways this dispute illuminates questions that all Christians involved in public life need to reckon with than in choosing sides. How Christians choose to reckon with these questions will have consequences for all Americans, whether religious or not.

In brief, Ahmari’s critique of French is that he is too nice a guy for the harsh times we live in, and he is too nice because he has too much belief in what political philosophers call “liberal proceduralism.” That’s the idea that all Americans can flourish, more or less, in a political environment in which we don’t agree on the prime ends of culture or of human life more generally, but do agree to follow the same set of political and rhetorical rules—the same “procedures.” To this idea, Ahmari responds:

But conservative Christians can’t afford these luxuries. Progressives understand that culture war means discrediting their opponents and weakening or destroying their institutions. Conservatives should approach the culture war with a similar realism. Civility and decency are secondary values. They regulate compliance with an established order and orthodoxy. We should seek to use these values to enforce our order and our orthodoxy, not pretend that they could ever be neutral. To recognize that enmity is real is its own kind of moral duty.

In Ahmari’s view—and it’s a view I largely share—liberal proceduralism has become a fiction. Today’s secular left has no intention of playing fair, and if Christians and conservatives—if people who follow “David French–ism”—insist on playing by the discarded rules, they’re just setting themselves to be played for suckers. Ahmari thus echoes a great American who wasn’t willing to be suckered. I refer to Bugs Bunny, who on more than one occasion intoned, “Of course, you realize this means war.”

For me, a Christian who is also sort of conservative, this is not a merely academic dispute. But I think that the argument to this point has not been fruitful, and that, I believe, has happened because of a lack of clarity on one key point. That point can be clarified if you look at an earlier moment in the history of First Things, the magazine in which Ahmari’s critique of French appeared.

In 1995, when I wrote regularly for First Things, the editor in chief, Father Richard John Neuhaus, gave me an interesting bit of news: The prominent literary critic and theorist Stanley Fish, who was then thought of as a disturber of the intellectual peace and certainly not as a religious person, had submitted an essay to First Things, a self-described “journal of religion and public life.” Neuhaus wanted to know whether I thought he should publish it. Indeed, I did. (He probably asked many people, but I don’t know anyone else’s answer.) He decided to run it, but to include a lengthy response. I pleaded with him to allow me to write that response, but he did it himself.

Why did Fish’s essay need a response? In large part because it made this argument:

If you persuade liberalism that its dismissive marginalizing of religious discourse is a violation of its own chief principle, all you will gain is the right to sit down at liberalism’s table where before you were denied an invitation; but it will still be liberalism’s table that you are sitting at, and the etiquette of the conversation will still be hers. That is, someone will now turn and ask, “Well, what does religion have to say about this question?” And when, as often will be the case, religion’s answer is doctrinaire (what else could it be?), the moderator (a title deeply revealing) will nod politely and turn to someone who is presumed to be more reasonable. To put the matter baldly, a person of religious conviction should not want to enter the marketplace of ideas but to shut it down, at least insofar as it presumes to determine matters that he believes have been determined by God and faith. The religious person should not seek an accommodation with liberalism; he should seek to rout it from the field, to extirpate it, root and branch.

This is Sohrab Ahmari’s argument, 23 years avant la lettre.

Neuhaus began his response by quoting a part of the passage I just quoted and then setting out to refute it—though not with a whole heart, because Neuhaus realized that one variety of liberalism is indeed programmatically opposed to religion. That variety contends that confidence in metaphysical claims—especially claims about what human beings are, and are for—is always dangerous because those claims are just not true. But Neuhaus saw that there was another kind of liberalism that is programmatically modest about what a whole society can claim to be true—and that kind of liberalism, he thought, was useful.

Thus, in his essay, he cites the great American Jesuit theologian John Courtney Murray:

John Courtney Murray said that pluralism is written into the script of history, and I would add that it seems God did the writing. By pluralism, I mean a world in which people live by significantly different accounts of reality, including moral and religious reality, and must learn to live together.

Neuhaus thought not only that Good Liberalism is compatible with Christianity, but also that Christians, if they are properly mature, are among the best-suited to live in such an environment: “The Christian understanding of reason, faith, and how the world is created to be is the best guard against the totalitarianism, whether liberal or religious, that is invited by a monistic view of reality … This gives the Christian confidence that he can enter into conversation with the non-Christian … The Christian therefore tries in various ways to enter into the reason and language of non-Christians in order to help reorder them to truth.”

This sounds like a variety of French-ism: a commitment to conversation, to civility, to gentle persuasion. (As the apostle Paul said, “I have become all things to all people, that I might by all means save some.”) But would Neuhaus, who died in 2009, still take this line if he were alive today? Or would he, like Ahmari, have concluded by now that Good Liberalism has been fully eclipsed by Bad? I cannot be sure, of course, but I am inclined to believe that he would have a lot of sympathy for the substance of Ahmari’s argument. That is, I suspect that Neuhaus would have drawn closer to the position articulated by Fish all those years ago.

But there is one more point to be explored here, and it involves not substantive political philosophy, but rather rhetorical style. If you are centrally a political conservative and you also happen to be a Christian, then perhaps you may set aside certain Christian commandments in order to achieve your primary ends. But if you are centrally a Christian and secondarily a political conservative, then you have certain obligations that you cannot ignore.

Among those is to be truthful about your political opponents, something that I do not believe Ahmari achieved in his article: Many of the beliefs that he attributes to French are simply made up from whole cloth, as French has explained, and his crude mockery of “Pastor French” recalls another figure who substitutes demeaning nicknames for argument. An American president might declare a national emergency and set aside American and international law, but a Christian cannot in the same way set aside divine commandments, even if he thinks, as Ahmari does—and, for that matter, as I do—that there is a “present crisis facing religious conservatives.”

Ahmari thinks that “civility and decency are secondary values,” but even if that is true, they remain values, and Ahmari is not warranted in discarding them so flagrantly. Yet I am not sure that that statement is true. And here again, Neuhaus’s response to Fish is relevant: “The Second Vatican Council’s declaration on religious freedom is titled Dignitatis Humanae. Respect for the dignity of the other person created in the image of God requires that we not silence or exclude him but try to persuade him.” Even when people are wrong, he says, “we must put up with them or tolerate them or, much better, respect and love them”—not because that is a politically effective strategy, which it may or may not be, but because we are so instructed by God.

This respect and love require a commitment to conversation, and “conversation requires civility”—even when people do not reciprocate that civility. After all, it is Jesus himself who tells us that when we are struck on one cheek, we should turn the other toward our attacker. Civility should not be our religion, but “there are religiously imperative reasons for being civil that do not entail turning civility into a religion.”

Even if Ahmari and others now associated with First Things are right to say that the old-fashioned commitment to liberal proceduralism is a “dead consensus”—even if we Christians are facing a genuine crisis—charity, and the civility and decency that accompany charity and have so consistently been manifested by “Pastor French,” are what we are commanded to do. And charity begins at home.



The fight for control of information from the Russia investigation is heading into uncharted legal territory. The House Judiciary Committee has voted to hold Attorney General William Barr in contempt of Congress for his refusal to provide the committee with the full, unredacted version of Special Counsel Robert Mueller’s report. Earlier this month, House Intelligence Chairman Adam Schiff publicly signaled his intention to impose fines on the federal officials who refuse to comply with congressional subpoenas. “We’re looking through the history and studying the law to make sure we’re on solid ground,” the California Democrat said, revealing that he and his staff are aware that the move would be unorthodox and unconventional. Under these circumstances, the trepidations of the Democratic leadership are understandable. Yet the important thing is: Fining Barr would be legal—even if enforcing the fine could itself prove tricky.

The legal framework governing situations such as this is seldom used and little known. As it happens, I studied it for a forthcoming law-review article. Although the Constitution does not expressly provide Congress with investigatory power, it is a logical extension of the power to legislate.

Much as the president needs to be able to hire people to execute the nation’s laws, the House and Senate need to be able to collect information to make those laws in the first place. In the 1927 case McGrain v. Daugherty, the Supreme Court stated that a “legislative body cannot legislate wisely or effectively in the absence of information.” Despite the highest court’s imprimatur, Congress’s requests for information during investigations have not always been met with cooperation from the executive branch. When informal requests for information are disregarded, Congress exercises a power usually reserved only for the courts: It issues a formal subpoena. As with a subpoena issued by a court, the person receiving the subpoena is on notice that further refusal to disclose the requested information will open the door to punishment.

The first step is to hold the individual “in contempt.” This serves as Congress’s formal expression that an individual has disobeyed the body’s orders, thereby obstructing its information gathering. But much like being held in contempt of court, the decision would lack genuine force if those who defied Congress faced no consequences. To pressure such people, lawmakers have traditionally resorted to three different strategies: inherent contempt, criminal contempt, and civil contempt.

The oldest approach, and now the most draconian, is to arrest and detain the contemner—that is, the person being held in contempt. This is known as “inherent contempt” power, whereby the sergeant at arms of Congress treats the person in contempt in the same way that a sheriff or bailiff in a courtroom would treat someone disturbing the court proceedings. Despite the Supreme Court’s decision affirming Congress’s power to arrest and detain those held in contempt, and the apocryphal story about an empty dungeon underneath the Capitol dome, Congress has not exercised this option since 1934. It has instead mainly relied on transferring the contempt proceedings to the courts, leaving a judge to decide the appropriate punishment for criminal or civil contempt.

The criminal-contempt statute, passed in 1857, makes it a federal crime to defy congressional subpoenas. Congress has the option of asking the Justice Department to sue anyone held in contempt for violating this federal law. If Congress succeeds in obtaining a favorable judgment, the judge can order the contemner to be jailed or fined. But, not surprisingly, if the individual held in contempt is an executive-branch official, Justice will likely refuse to sue him or her—as it has in every case involving a federal official in the past 10 years.

Alternatively, either the House or the Senate can authorize some of its members to bring a civil-contempt case, circumventing the need to rely on the Justice Department. This option too has its own shortcomings. First, courts are hesitant to entertain disputes that involve a tug-of-war between two branches of the government. Second, litigating the matter in courts can be time-consuming in practice, so it’s not helpful when Congress’s main concern is expediting access to information. In the past, similar cases have dragged out in the courts for long enough that the requesting Congress and the incumbent administration’s terms both expired before reaching a resolution.

Neither of these options helps Congress get the information it wants in a timely way; both options require cooperation from one or two of the other branches. The increasing sense of frustration with these strategies has shifted the attention to creative ideas for punishing those in contempt. One such idea is to impose fines on noncompliant federal officials.

Fining federal officials circumvents the need to rely on the two other branches. It’s also more politically palatable than arrest and detention. Still, the question of whether Congress has the power to use its contempt power in such a manner has been murky, given that it has never been used before. Article I, Section 9, of the Constitution (known as the “bill of attainder” clause) prohibits legislative acts that single out one individual for punishment. When Congress has previously tried to withhold the salary of executive officials as an indirect way of removing them from office, courts have nullified such attempts as infringements on the president’s constitutional power to remove officers.

Even so, there are solid reasons to believe that Congress does indeed possess this power. The Supreme Court has consistently likened Congress’s contempt power to that of the courts. And since judges routinely issue fines to those held in contempt of court instead of jailing them, Congress too should be allowed to exercise the same power without violating judicial precedent. Second, although imposing fines on federal officials with the indirect motive of removing them from office can be unconstitutional, using the same means to achieve a different goal—namely, the disclosure of information to protect congressional investigations—is a different story. Congress has the power of the purse. Refusal to comply with its normal investigative proceedings will impose additional costs on congressional committees, and a fine aimed at recouping those costs can be justified under Congress’s prerogative to protect against the waste of federal resources.

If Congress has the power to directly fine contemners without going to court first, the procedure it should use remains unclear. One possible strategy is to borrow the legal procedures used by Congress in disciplining its own members. In the past, Congress has directly fined its own members at the conclusion of disciplinary investigations by either asking the Treasury Department to withhold a certain amount from their salary or asking the member to write a check directly to Treasury. In some cases, the fine that was assessed was commensurate with the cost of the ethical investigation.

The contemner or Treasury might well refuse to comply with these requests. If the contemner—Barr, for instance—is directly asked to provide a check and refuses, Congress’s only recourse would be to resort to the courts again, but this time with the much stronger claim that the contemner has misappropriated federal money, a serious crime on its own. Alternatively, Congress can ask the Department of the Treasury to withhold the contemner’s salary. Treasury has extensive control over the administration of the budget, and the department might well push back against Congress, much as the Justice Department does when it declines to pursue criminal action. Yet the case for executive discretion to ignore Congress’s demands will be much weaker. Justice enjoys the right to exercise discretion on whether to prosecute a criminal case, but Treasury’s refusal to follow congressional demands over the management of federal money will not have a clear nexus to any constitutional right that would counterbalance the power of the purse.

It remains to be seen how far Democratic leadership will venture down this unexplored path. But a new precedent could come into play again quickly. The House Ways and Means Committee has issued a subpoena for President Donald Trump’s tax returns. On Friday, Treasury Secretary Steve Mnuchin refused to comply.



Earlier this year, Elizabeth Warren, Kamala Harris, Pete Buttigieg, and other Democratic presidential aspirants began speaking positively about reparations, in contrast to Barack Obama and Hillary Clinton, who opposed the policy.

Just 26 percent of voters favor reparations in polls.

In the telling of The New York Times, this shift is due to the fact that “grass-roots organizers and many liberal voters of all races are now pushing elected officials to go further on policies of racial equality, regardless of any political calculations.” While that is likely a factor, I suspect something else is going on too: When average Americans hear reparations, they still think of “the idea that some form of compensatory payment needs to be made to the American descendants of slaves,” to quote from the definition of the term on Wikipedia.

But among some influential Democratic constituencies—educated, left-of-center Brooklyn, for example—reparations is understood differently, as illustrated by a roundtable on the subject broadcast last month by a Brooklyn TV station. It’s worth watching, regardless of whether you love or hate the idea of reparations, because it clarifies the degree to which Americans discussing the subject can talk past one another or mistake how much disagreement actually exists, fueling everything from mild confusion to needless polarization.





“Give me your working definition of reparations,” the moderator, Brian Vines, began.

Chief Dwaine Perry of the Ramapough-Lunaape Nation kicked things off.

“Perhaps the most important thing that reparations can do is present history and knowledge as it really occurred, not as a paradigm to abuse and manipulate,” he said. “Reparation, I think, has to start with the integrity of true history.”

The columnist Noah Millman spoke next.

For him, reparations means “an attempt to reconcile with the past between communities where one has suffered at the hands of the other,” he said. “Whether that is in the form of monetary or whatever, it is an intra-communal agreement, effectively, that what we are doing now is settling a long-standing grievance.”

L. Joy Williams, the president of the NAACP’s Brooklyn chapter, began by affirming that reparations should begin with truth-telling about American history. “We’re still uncovering stories and places of what harm was done, and that is part of reparations,” she said. “Following that is how do we repair … How do we repay?” That need not always take the form of a check, she emphasized. And lastly, there’s a “commitment” to never repeat the injustice again.

Later, she clarified that the state needn’t be the primary actor. “If you’re relying on American government to come and chart out a process for reparations, we’ll be waiting for 400 more damn years for that to happen,” she said. “The overall process we’re talking about starts with telling the truth … That can come from professors researching. That can come from elected officials uncovering documents. That can come from a Ta-Nehisi Coates writing … That doesn’t have to happen from the government, and I don’t think it should.”

The Reverend Mark Thompson, a member of the National Coalition of Blacks for Reparations in America, rooted his definition in repair and government assistance:

For many of us, reparations means spiritual repair, cultural repair, repair through the means of education, health, economics, society, all of those things together. So it’s obviously more than individual checks, but helping to build institutions so that at least African Americans can catch up with white Americans.

White Americans had help through the Homestead Act—which didn’t include us—housing loans, FHA, that helped build the suburbs. Social Security did not include us … So there were all these helping hands. And we, as African Americans, not to exclude the indigenous people, none of us can catch up because some others got a head start … We have to talk about slavery’s vestiges because as soon as slavery was over, we had the Jim Crow era … And now we live in an era where we have modern-day lynchings by law enforcement, a racist criminal-justice system … the toll grows higher and higher.

Coleman Hughes, the freelance opinion journalist and Columbia University undergraduate, asserted that reparations is “something of a misnomer because the wrongs of history are generally too deep to actually be completely compensated.” What reparations should mean, he said, is “a full-hearted recognition that a wrong was committed, that something happened that should not have happened––and more than that, it’s an apology that feels more sincere because you’re attaching something tangible to it, because words are very cheap.”

And the Columbia University professor Katherine Franke, the author of a book on reparations, called them “a tool and an opportunity for us to recover a kind of history … but to not relegate it only to history, but make it part of our national memory.” After the Civil War, America should have given recently enslaved people “the material resources to be free and full citizens,” she argued. “We also needed to use those resources to recognize the terror, the rape, the family separation, the humiliation of being enslaved. So reparations are backward-looking in terms of recognizing the fundamental soul-killing nature of slavery, but forward-looking in terms of creating the very possibility for people to be free.”

Among these six, “reparations” always involves a truthful reckoning with history. Beyond that, it might refer to a government-run program to repair historic injustice or to specifically nongovernmental probes into historic injustices, to a onetime attempt to settle a communal grievance or an open-ended process of discovery, repair, and compensation with no foreseeable conclusion. And it might or might not involve direct payment to descendants of slaves.

When it comes to reparations as most Americans understand the term, I’m a skeptic for reasons I explain in “The Benefits of Redressing Racism With Race Neutral Remedies” and “Why Bernie Sanders Is Right to Oppose Reparations.” But if asked in that Brooklyn auditorium whether I favored reparations, I’d have required a three-minute sidebar defining terms before I felt able to answer.

Under some definitions, I’d have said yes; under others, no.

For growing parts of the left, “Do you support reparations?” is not necessarily a question about the wisdom, justice, or feasibility of compensation given to descendants of slaves. A person might reject cutting checks on any one of those grounds and nevertheless affirm that, yes, she does support reparations, understanding herself to be saying, “I recognize the historic injustices done to blacks in the American slave trade and Jim Crow, and favor affirmative steps to repair them.”

I certainly favor historical scholarship and an unsparingly accurate account of the injustices done to indigenous people and African Americans. I favor attempts “to reconcile with the past between communities where one has suffered at the hands of the other.” I favor “a full-hearted recognition that a wrong was committed, that something happened that should not have happened,” as well as a commitment to never repeat the injustice. I certainly agree that our historical reckoning must encompass Jim Crow, not just slavery. I want every American to enjoy the opportunity to be a free and full citizen. And I favor settling long-standing grievances between groups where that is possible.

So do I support reparations—even though I also believe that redressing recent ills, like redlining, should compensate anyone directly victimized, not just African Americans, and that the neediest among us, regardless of race, have a greater claim to common resources than a wealthy descendant of enslaved people?

Definitional murkiness doesn’t matter much in a Brooklyn auditorium, a small community where participants can explore nuances in conversation.

But it does matter in the context of a presidential campaign in which candidates must convey their beliefs and intentions to hundreds of millions of Americans. And the complications go beyond simply defining reparations in different ways, to the way candidates will choose to express themselves. Take two possible formulations:

Those formulations are substantively identical. They could manifest as identical policies. But they are arguably symbolically different. For some on the left, a primary candidate who uses formulation A is superior to one who uses B, even though that candidate will likely face a tougher time with voters in a general election while delivering exactly the same policy measures if ultimately elected.

The roundtable discussion touched on the issue of rhetorical framing. Millman, the columnist, told Williams, the NAACP chapter president:

It sounds to me––and forgive me if I’m wrong––that we have a little bit of disagreement about what the word should mean. You have a very expansive conception of what reparations is, particularly that it is an open-ended process, because there’s always going to be more to learn … that reparations is a way of thinking about social justice generally that focuses on the sources within society that caused the situation that we see today … the harms that have continued down into the present either in terms of continuing to happen or continuing to have ripple effects from things that were done in the past. I’m curious, if that’s what you’re saying, why you think from a political perspective that’s the right way to frame things, in terms of getting what you want accomplished?

In reply, Williams made a strong case against reparations as a onetime event. Cutting a check “doesn’t address a criminal-justice system … doesn’t address housing policy that’s still on the books to this day … doesn’t address all of those connections.”

If criminal-justice reform, housing reform, and many other policies poll much better than 26 percent, why bundle them together under the umbrella of reparations?

Hughes, the Columbia student, raised the question a different way:

I fear that we’re talking around the main issue … When people hear reparations, which is this very controversial topic, I don’t think they’re thinking, Oh, they mean criminal-justice reform. Oh, they mean repairing society. What they’re thinking, and what the public meaning right now in America is, is programs or benefits or a check or a deeper program that is allocated to descendants of slaves and not to other people. And I think that’s the crucial variable that makes it, for most people who hear that term, controversial.

He added that he doesn’t think Americans who say they’re against reparations think of themselves as opposing criminal-justice reform or against ending structural racism. “I fear,” he said, “that we’re talking around the most controversial part.”

Thompson disagreed, retorting, “I think what happens is, a lot of these talking heads, people on television, don’t know anything about reparations.” While that may be true, it doesn’t change the fact that six highly informed commentators at a reparations event in Brooklyn had different understandings of the word—different not only from the general public, but also from one another.

Williams responded to the challenge by arguing that it is not marginalized people’s job to convince society of their rights and humanity:

Whether it’s reparations or any kind of work on behalf of marginalized people, there has to be some kind of PR thing that has to happen to make people be more accepting of your humanity and your dignity and the rights you deserve being in this country. I always call BS on that. I don’t need to make you feel better about what I’m rightfully entitled to. So there’s a different kind of organizing model, negotiating from a position of power. I’m not going to ask for anything that you’re giving me out of charity. I’m fighting for something that I deserve and that I am owed … I’m asking for the money and land and support and resources that marginalized people––I’m not interested, even as a strategist, in trying to massage people’s ego or package it differently in order to get what a human deserves in terms of rights and responsibilities.

But I don’t think eschewing the term reparations is mere PR. As Perry put it at one point in the roundtable:

I think a missing element in all of this is that we need to have or somehow come to a decisive understanding and focus of where we’re going. Otherwise it’s going to become an intellectual exercise … It’s going to ebb and flow, and before long, no one’s even going to know what you’re talking about. So I think, maybe, perhaps not this forum at this moment, but we do need to convene, sit down, and say what are we talking about.

Count me as a proponent of rhetorical clarity, too, and a skeptic of those who employ the term in ways that the vast majority of listeners are unlikely to understand.

That clarity is lacking right now. So if you hear the word, take caution before reacting. Even if you’ve always opposed reparations, understand that you may well support many of the things that some of your fellow Americans actually propose. And if you favor reparations, understand that some of what you deem imperative may be perfectly fine with some of the people who insist they disagree with you.

Imprecision is getting in the way of a healthy debate.



Of the many challenges facing anyone trying to understand Donald Trump’s presidency is the fact that it is maddeningly nonlinear, lurching several times each day between policy objectives that may be dictated by a Fox News anchor, a friend from Mar-a-Lago, or the prime minister of Norway. This was especially true in the first six months of his administration, when the chief political strategist Steve Bannon was at the height of his influence, while Reince Priebus wielded the chief of staff’s potentially awesome authority with all the gravitas of a substitute teacher.

Then, in the summer of 2017, Priebus was fired and Bannon pushed none-too-gently toward the door. Under Priebus’s replacement, John Kelly, the Trump presidency on some days seemed almost normal. Kelly and his staff put strict controls on the flow of information into the Oval Office while also ending the open-door policy that Priebus had been powerless to curb.

When Kelly left in December 2018, chaos, which had been held in abeyance for at least some of the previous months, returned in full force. One of the unending debates of the Trump presidency is whether Trump intentionally creates this chaos or is somehow helpless against it, against the very disorder he causes daily, if not hourly.

The question of intentionality is impossible for anyone but Trump to answer, and he would surely answer it by claiming that he has had a plan all along. That would be a typically Trumpian boast. That aside, however, it is undeniable that the exhausting storms that mark political life in Washington obscure the ruthlessly effective work happening across the federal government.

That should explain why, when I spoke with Bannon for my book on Trump’s Cabinet, he said he thought “Reince did a terrific job,” adding, “People said it was too loosey-goosey. Well, but that’s kind of Trump’s style. You have to let Trump be Trump.” Trump at his Trumpiest was Trump sitting at the Resolute desk, happily signing executive orders: to impose the “Muslim ban,” end the Trans-Pacific Partnership, accelerate work on the Dakota Access Pipeline. It was Trump tweeting about no collusion, trolling the media and the Resistance with every ungrammatical missive.

“It was brutal,” Bannon remembered. “Every day was a knife fight.”

Maybe it didn’t have to be so brutal, and maybe the knives didn’t have to come out every morning. The mere appearance of battle, whether with congressional Democrats, Wall Street free-marketeers, or most of Europe, has often been enough to distract journalists and the rest of America from what has been fomenting just beneath the surface.

The diversionary maneuver has been so effective because Trump remains an object of intense public fascination. If nothing else, Trump is an effective distraction from Trumpism, which is to say a kind of raw modern Republicanism that has shed the last vestiges of its eastern-establishment roots. The more Trump acts like Trump, the more it seems to the rest of us that his administration is about to collapse into a heap of faux-golden shards, the more the Trump administration actually gets done.

Just so, the news on February 14, 2017, was largely focused on Trump’s fleeting National Security Adviser Michael Flynn and the improper contacts he’d had with the Russian ambassador during the presidential transition, as well as on whether Trump had tried to stop FBI Director James Comey from investigating Flynn.

That same day, Trump and the Republican Congress rolled back a Barack Obama–era rule that required energy companies to disclose payments they received from foreign governments. They did so quietly—though hardly in secret—using the Congressional Review Act, the brainchild of Newt Gingrich. Passed in 1996, the law gives Congress 60 days to review any new rules. If it does not like the rule, Congress can vote to nullify it. Congress attempted to use the CRA against Obama on five separate occasions, but he leaned on his presidential veto powers to block each of these efforts. The CRA was not used at all under Bill Clinton, and only once under George W. Bush (to cancel a workplace-ergonomics program that Clinton implemented).

Republicans were not reluctant to use the CRA against Obama’s regulatory legacy. Longtime conservative operators who’d joined the administration coordinated with leaders in the House and Senate on which rules to roll back. Trump was thoroughly on board, remembered the White House official involved in the effort. “I love it,” the president said. “Show me which ones we’re talking about.”

In Trump’s first several months in office, Republicans used the CRA more than a dozen times. They repealed a rule that prevented internet companies from selling individuals’ data without their explicit consent. They undid the Stream Protection Rule, which was intended to keep surface mines from polluting waterways with the potential toxic products of their activities. They killed a mandate that employers report workplace injuries. And they made it easier to hunt bears in Alaska. Now you can shoot them from helicopters again.

The press did cover these developments, but with nothing like the ardor devoted to Trump’s supposed cupidity, his inability to grasp the gravity of his office, his fawning over Russian President Vladimir Putin and other dictators. These reports portrayed an administration without captain and lacking rudder, adrift on seas. This was thrilling stuff. It was also enormously convenient to the Trump administration. News reports of dysfunction “were our greatest advantage,” explained a former White House official. (I granted him and other subjects anonymity in exchange for candor.)

He cast the distractions as an actual strategy at work. Bush-era conservative operatives now fill the middle ranks of the executive branch, including deputy Chief of Staff Joe W. Hagin and deputy Interior Secretary David Bernhardt. They seem to collectively understand that if they can keep the craft from crashing, they can steer it where they please, and that far more attention will be devoted to the turbulence than the destination.

Law limited Trump’s authority to use the CRA. But nothing limited his administration from continuing to cause a “shit show,” as one West Wing veteran put it. By the summer of 2017, Trump’s Cabinet was in place (his first full Cabinet meeting was almost exactly two years ago). Many of his departmental chiefs exacerbated the appearance of chaos with their predilection for private jets, lavish security arrangements, and other trappings of power.

Scott Pruitt, the former head of the Environmental Protection Agency, was the most baroquely corrupt of Trump’s Cabinet members, with close to 20 investigations into his behavior by the time he left office, in the summer of 2018. Ryan Zinke, former secretary of the interior, was close behind, with nearly as many investigations to his name when he offered his resignation, at the end of that same year. Secretary of Commerce Wilbur Ross allegedly lied about his wealth; Secretary of Transportation Elaine Chao allegedly lied about her investments. Secretary of State Mike Pompeo allegedly pressured the State Department to rent him a historic Potomac Hill mansion.

These incidents, too, caused outrage, starting in the fall of 2017, when the grotesque travel expenses of former Health and Human Services Secretary Tom Price came to light. Yet even as Pruitt faced questions about why he wanted a used mattress from the Trump International Hotel—the question remains without an answer—his deputies dismantled protections for American waterways. Industrial chemicals that had been deemed carcinogens were suddenly deemed safe. Coal companies came back into favor. Pollutants were made great again.

The story has been repeated across the federal bureaucracy. The Department of Interior practically gave away hundreds of thousands of acres of open land across the West, leasing it to energy companies for pennies on the dollar. But what do we remember about Zinke’s tenure? His crude “konichiwa” comment at a congressional hearing. His challenge coins and department flag. His bizarre tiff with a Capitol Hill neighbor bothered by Zinke’s idling SUV.

What kind of person doesn’t want to read about a Cabinet secretary engaging in a parking row with a private citizen? Or about Trump wandering the West Wing in his bathrobe? The most dismaying thing about the “shit show” is how effectively it works, with Trump as the star of an enthralling drama whose most consequential developments are always taking place backstage.





Subscribe to Crazy/Genius: Apple Podcasts | Spotify | Stitcher | Google Play

In the past few decades, digital pornography has been blamed for—well, pick a noun and add the word sex. It’s been named as a culprit for both sex addiction and sex abstinence. It’s been blamed for poor sex education, rampant sexual violence, and rising sexual dysfunction. Pornography is practically the Swiss Army knife of social calamity.

In the latest episode of Crazy/Genius, produced by Jesse Brenneman and Patricia Yacob, we investigate the internet’s original bogeyman and ask what, if anything, can be said about the effect of digital pornography on our lives after 20 years of online smut. (Subscribe here.)

“I think there’s no way that we could look at the dramatic increase in availability of porn and dismiss the idea that porn might play a role in the sex recession,” says Kate Julian, the Atlantic senior editor who wrote last year’s cover story on why young straight people seem to be having less sex around the world. “We are watching porn. Surely that is affecting us in some way. How?”

It’s a good question—but a surprisingly difficult one to answer.

The academic literature on pornography is not like that of climate change or gravity, where practically all researchers agree on the big picture. Instead, there is a broad group of academics and advocates who are deeply split on whether pornography amounts to a public-health crisis, or whether it’s an often harmless outlet and a common scapegoat for dissatisfied couples.

“The problem with beginning any sentence with ‘Porn is’ is you know right from the start that a person is about to generalize about all sexually explicit media, and that’s really a mistake,” says Emily Rothman, a professor at the Boston University School of Public Health. Rothman says porn use can be compulsive, but so can television. She says porn use might have contributed to the sharp rise in erectile-dysfunction treatment. But there’s also rising anxiety, rising obesity, and, most obviously, the proliferation of ED medication. In the past decade, Viagra has spent millions of dollars telling millions of American men to “ask your doctor” about the drug; presumably, a few of them did.

The truth, she argues, is that porn is like food. Much of it is harmless. And some of it is bad. But some of it is simply good. Younger people who are lesbian, gay, bisexual, or transgender, growing up in a small town without friends who share their sexual orientation, might discover in pornography a window into their own experience—and the message that there is nothing wrong with their feelings. “They might see pornography almost like a safe space,” Rothman says. “It can be inspiring and really helpful.”

Still, every academic I spoke with agreed that porn is generally a poor, and even harmful, alternative to sex education.

“When I look at a cooking show, I know not only my own eating habits but I know everybody’s eating habits,” says Marty Klein, a well-known sex therapist in Palo Alto. “I have ways of calibrating what I see on the mass media when it comes to food. When it comes to sex, most people never ever ever get to watch one other person having sex.” But with digital pornography, young people discover a trove of tantalizing content that’s been utterly decontextualized from any real person’s sexual experience. “Porn is not meant to be sex education,” he says. But for many young people, it is—and that’s especially problematic if the porn is violent.

Just as extremism on social-media platforms often spills over into the physical world, dreadful sex ed can lead to dreadful early sexual experiences. “In my own study that I did years ago, there were girls who said because their boyfriend had seen something in pornography, they were then forced or coerced to do that thing,” Rothman says. “And they were unhappy about it.” Porn critics such as Mary Anne Layden, a psychotherapist at the University of Pennsylvania, say this can have two parallel effects: more sexual violence for some, and a withdrawal from sexual experiences by others.

Everybody I spoke with noted that porn can offer vulnerable consumers an infinite buffet of false, decontextualized, and potentially harmful ideas about the world. If that sounds familiar, it’s because that’s precisely the claim against the dangers of extremist and falsely conspiratorial content on today’s social-media platforms.

In both cases, there are top-down solutions and bottom-up solutions. This summer, the U.K. government will institute a novel “proof of age” technology across porn sites to prevent underage consumption. Meanwhile, some sexologists are experimenting with showing porn openly in public-school classrooms, acknowledging that if it is going to be sex ed anyway, it might as well be taught. Both strategies have their parallels in the broader attempt to make the internet safe for the world, as social-media companies ban extremists from their sites, while other groups debate whether digital literacy can be taught in elementary school.

It’s ironic that porn has come to represent the broader challenge of life online. People used to say smut tainted the web. But the dangers of porn turned out to be the dangers of the whole internet. Once the internet’s great shame, porn grew up to become a synecdoche of life online.



When I was a teenager, in the 1990s, I spent my summer breaks herding sheep from sunrise to sunset. My daily routine was nearly always the same. I released the sheep from the barn, steered them along the village’s main road, grabbed a watermelon from a shop to add to my packed lunch, and turned to the desert. Once I left the populated section of the village, I directed the few dozen animals along the desert cliffs to the open fields at the mouth of a little valley.

My family had two lines of business at the time, farming and livestock trading, so we did relatively well. We owned some 1,000 livestock and had an orchard of about 900 pomegranate trees that was leased annually to merchants from Aleppo, who arrived at harvest time to ship the produce from several orchards in the area to their city. Along with my eight siblings, I helped in farming and herding not only over the summer but on weekends and holidays throughout the year. I didn’t venture outside my home village until 1996, after finishing my ninth-grade exams. At that point I went to the city of Albu Kamal to study in the area’s sole high school.

My village, Ash Sha’fa, lies on the eastern bank of the Euphrates River, in the province of Deir Ezzor in eastern Syria. The Iraqi border, mostly a sand berm eroded by desert winds, is only a short drive from the village. Most of Deir Ezzor’s population descends from one main Arab Sunni tribe, the Egaidat, to which my family belongs. Like most tribes in the Middle East, the Egaidat has members in Iraq and the Persian Gulf.

This eastern region, commonly referred to in Syria as the Remote Provinces, is distinctly tribal, rural, and marginalized. In the 1990s, life there was generally simple and uneventful: The state’s presence was minimal, and villagers sustained themselves through farming and remittances from relatives working in the Persian Gulf. Even in retrospect, nothing in those days indicated that my home province would become the main transit hub for jihadists moving from Syria into Iraq after the 2003 invasion, or the site of the Islamic State’s final battle as a caliphate.

As someone who studies the Islamic State for a living, I still struggle to connect images from my past with the reality of today. They are simply two different worlds.

A little over a month after ISIS seized Ash Sha’fa, one of my siblings sent me a picture of our father. I froze at the sight of him with a gray beard. He used to be clean-shaven. But he, like other men living under the caliphate, was forced to wear a beard as a sign of his adherence to the religious principles of his jihadist rulers. This was five years ago, by which point I was already studying ISIS’s every move as a journalist in Abu Dhabi; the photograph made me feel the group’s terrors and daily humiliations in a new way.

In the context of the Syrian conflict, my family’s plight was not extreme; nor did my immediate family produce active participants in the many-sided war. But their story still provides a window into the country’s tragedy, and into how a society can be radically transformed in a matter of years.

When the Syrian conflict started, fighting and bombardments in the village were minimal, as clashes tended to be concentrated in the urban centers. But schools closed, as did many nearby hospitals. And the economic situation deteriorated rapidly. When ISIS swept through eastern Syria and western Iraq in June 2014, the ragtag militias that used to operate in Deir Ezzor vanished and were replaced by ISIS representatives who acted like a state security force.

ISIS militants seized properties belonging to the government or to individuals they deemed apostates. They constructed bases in those facilities. ISIS then widened its writ dramatically. Unlike the regime before the war, ISIS was highly visible. It micromanaged the areas under its control, down to family feuds that had once been resolved through tribal codes.

Before the uprising, my village did not even have a police station, and official paperwork had to be submitted in adjacent cities. ISIS, however, established centers for hisbah (the religious police) and tribal outreach in every village. Its fighters patrolled the areas, and a traveler from my village to the main city would encounter several checkpoints along the way, instead of just one, as was previously the case, at the bridge linking the eastern and western banks of the Euphrates, near Albu Kamal.

People became careful about what they said even around close family members. This extreme caution had not been the norm previously, even under jihadist groups such as al-Qaeda’s Jabhat al-Nusra, which used to control much of Deir Ezzor.

The Islamic State’s security apparatus in the village was headed by a Bahraini of Syrian descent in his 20s. He and other members presented themselves to the locals as liberators who were committed to enforcing Sharia. Men were not only required to grow their beard but also to attend prayers at the mosque, and women to wear full face cover. Smoking and selling cigarettes were banned, and violations of Sharia rules, from eating during Ramadan to engaging in adultery, were punished in the public square with lashings or executions. The public square was also used to display the bodies of people the militants had killed.

My family was afraid, but only in August 2014, about two months after ISIS seized the village, did they realize the extent of their danger. During that month, ISIS committed several atrocities against civilians, including the enslavement of Yazidis in Iraq. Then came the massacre of the Shaytat clan.

The Shaytat, part of the Egaidat tribe, lived just a few villages away. ISIS declared them ta’ifa mumtani’a, a religious label for Muslims who refuse to comply with Sharia, and killed at least 700 of them. Some survivors, mostly old men, women, and children, fled to Ash Sha’fa, where my family heard tell of what had happened. Tribal mediators eventually convinced the ISIS leader Abu Bakr al-Baghdadi to grant clemency to the displaced, but ISIS had made clear its ruthlessness.

My brother Hussain told me that people lived in constant terror under the organization. “You have to ensure you don’t make any mistakes and don’t get near them. Only then you’ll be okay,” he said. For those who were previously involved with the anti-government and non-jihadist Free Syrian Army, the risks were higher. They were considered potential threats, and ISIS would summon them for repentance and interrogation frequently in the early months.

A civilian exodus out of ISIS areas started as early as 2015 as the caliphate’s notorious security apparatus became dominant over the clerical and civilian structures. Indeed, that was the year Hussain managed to leave our family village, along with his wife and children. Several other members of the family followed in 2016. In response to the departures, ISIS imposed a strict prohibition on civilians leaving the “land of Islam” for the “land of infidels” without written approval. A person leaving the area for medical reasons had to name a guarantor living in the caliphate to ensure that he or she returned. ISIS increased its presence at key exits, cracked down on drivers who smuggled civilians, and finally laid minefields around smuggling routes. Nevertheless, departures accelerated, not only because of the group’s brutality, but because of Russian bombardments and the destruction of infrastructure by the U.S.-led coalition.

After ISIS lost Mosul, Raqqa, and Anbar in 2017, fighters poured down to the group’s last strongholds, in the Euphrates River valley. ISIS militants would swiftly take over houses as soon as their owners vacated them—“like rats,” as one resident put it. Notwithstanding the danger, some locals chose to stay to safeguard their property, in anticipation of the possibility that after the war, dispersed family members might return. Their homes, in many cases, were all they had left. My father, my sisters, my uncles, and my cousins were among those who chose to remain, despite the risks. (My mother left in 2017, for medical reasons.)

For the most part, my family avoided confrontations with ISIS, but one of my cousins, Usamah, wasn’t so lucky. In December of 2018, he was riding his motorbike when he accidentally kicked up sand and pebbles near where ISIS members were standing. They stopped him and accused him of trying to hurt them. They searched his house and found a camera and a gun. Such materials were prohibited, so Usamah was taken into custody.

The militants at first assured Usamah’s family that he was undergoing a routine interrogation and that he would meet with a judge. But soon thereafter the militants said they no longer knew his whereabouts; another branch of ISIS, the general-security intelligence apparatus, had taken him. As was usual when civilians were found with banned items such as cameras, ISIS suspected he was working as an informant for the U.S.-backed coalition. The group had previously executed civilians in our village on the basis of such accusations, and Usamah’s family feared the worst.

About a month later, in January 2019, a shell struck my parents’ home, seriously injuring my father. Finally, he agreed to leave along with my sisters; my holdout uncles decided it was time to go with their children, as well, though reluctantly since Usamah was still missing. Although most of my family reached territory held by the Syrian Democratic Forces and were then escorted to a camp for civilians who’d escaped ISIS, the journey proved too much for my father and he turned back along with one relative.

On returning to the house, my father found two Iraqi members of ISIS scavenging the car he had left behind. He tried to stop them but gave up when they accused him—correctly— of attempting to smuggle himself out of the caliphate. He understood that if he persisted, they would report him or perhaps kill him. He stayed in the house for some days before, in a second attempt, he and my other family members managed to get out of ISIS-held territory and reach one of the liberated villages of the Shaytat clan.

My father was taken for medical treatment, while my sisters, my uncles, and my cousins waited in the camp for civilians. Soon after that, in late January, my village was liberated, and news emerged that prisoners had been handed over to the Syrian Democratic Forces. My cousin Usamah was among them, alive and as well as could be expected.

ISIS maintained its governance structures in eastern Syria—and its determination to enforce its version of Islamic law—long after it was obvious that the group could not prevail. The caliphate finally collapsed completely on March 23, 2019, four years and eight months after Baghdadi declared it from Mosul. For my family, one chapter ended and a new one began.

My parents and siblings live far from the village where I grew up, in a city held by the Syrian regime. They do not know whether they will ever return home, or whether they would recognize the village as their home. Our livestock is gone, our orchard’s fate is unknown, and the desert where I used to herd sheep is now a no-go zone because ISIS militants laid mines there. Such misfortunes are shared by and, indeed, affect the whole village. My father used to employ at least three people and offer support to other families, especially in high-demand times such as Ramadan and winter. Today he depends on pocket money sent by his children living abroad and cannot help others.

Widen the aperture, and the picture is even more dire. ISIS has left behind social friction caused by five years of divide-and-rule tactics, evident in current threats of revenge by clans such as the Shaytat against locals who cooperated with ISIS. It is impossible to tell how many people were indoctrinated by the Islamic State’s ideology.

But the ISIS takeover of my community was not inevitable, nor obvious in the slightest. Rural areas are socially conservative and governed by tribal norms but are not dogmatically religious. A strictly religious person might even be described in his rural community as darweesh or a simpleton. From Fallujah to rural Aleppo, the areas that ISIS controlled had historically been strongholds of Sufism, the antithesis of the jihadist movements that came to dominate the region after the U.S. invasion of Iraq.

The Islamic State operated in war-torn Syria for more than a year before its spectacular rise in 2014, but it had no grassroots support in Deir Ezzor. Instead, it had to snatch the province by force from other rebel groups before it was able to co-opt some portions of the population.

Nevertheless, the past five years have transformed the area and created a new reality—of societal and economic collapse, a power vacuum, and radicalization—that nobody has a plan to address. I worry that the people of my village, ripped apart by war, might eventually become amenable to an extremist ideology they were previously strong enough to reject. The contrast is stark between the simple world I lived in as a young man and the complicated one that my father left behind only a few months ago. The contrast might be starker still in the coming years.



I watched the five stages of grief spread across the internet from east to west, like the sunset. James Holzhauer, the Jeopardy phenom and reigning 32-game champion, had finally lost.

“NOOOOO! Please tell me this isn’t true! #JeopardyJames”

“Very obvious he lost on purpose.”

“I am legit depressed right now.”

In an increasingly uncertain world, we get attached to our Jeopardy champions. In 2004, to mark the 20th anniversary of Alex Trebek’s modern syndicated Jeopardy, the quiz show announced a change to its long-standing contestant policy. Instead of booting returning champions off the show after five wins, it would allow players to keep going indefinitely, until they lost. I was the first real beneficiary of the policy, having auditioned for Jeopardy months before the new rule was announced, but not getting called up until a few months after it was official. That accident of timing, it turned out, changed my life (and paid for my house).

The Jeopardy producers may have envisioned the end of the five-day limit as a minor anniversary gimmick, but it ended up fundamentally changing a show that almost never changes. The rule change cannily anticipated the social-media era, delivering us a world where a vast community of viewers now often cares passionately about who is winning on Jeopardy. No longer is the show an endless parade of identical midwestern librarians and Beltway lawyers. Now many are personalities, with fans and haters. On any given night, a Jeopardy contestant can go viral by winning big, or giving a funny wrong answer, or sassing Alex Trebek during his or her mini-interview, or mugging for the camera.

And a few, of course, become national news. I’ve spent 15 years expecting the young gunslinger who would arise and put together a long streak like mine, but no one, not even me, could have predicted James Holzhauer. He was an experienced sports bettor with no qualms about going all in on Daily Double wagers. He was a Jeopardy disciple who had spent years studying the show, practicing his buzzer technique, and devising a strategy to sew up games early by playing the board from the bottom up. And most important, he seemed to know everything.

Suddenly, no Jeopardy record was safe; it was as if the show’s laws of mathematics had been repealed. The old one-day cash record was $77,000; Holzhauer was averaging that every night. Days would go by without him giving a single incorrect response. He won $131,127 in a single game, and even came within a whisker of beating my total-winnings record in a fraction of the time.

Now that Jeopardy champions can stick around indefinitely, they have time to build up a powerful home-field advantage on the set, and even a bit of mystique. Jeopardy tapes five shows back to back in a single afternoon, and so I would meet a new busload of 10 to 12 eager hopefuls on the morning of every taping day. Then they’d be told, “Ken is our 45-day champion and has won $1.4 million,” and I could see their faces fall. Before even sitting down in the makeup chair, they’d given up.

But no streak lasts forever. Until Holzhauer lost in Monday night’s game, he had seemed invulnerable. It was rare for anyone to even make a run at him. But he was defeated, fair and square, by Emma Boettcher of the University of Chicago—that’s right, a midwestern librarian. Boettcher was no civilian. She was a longtime Jeopardy nut who had even written her master’s thesis about predicting the difficulty of the show’s clues. Unflustered by Holzhauer’s stat line, she played a near-perfect game. She found both Daily Doubles in the Double Jeopardy round and did what too many of his challengers had been reluctant to do: bet big. As a result, she rolled into Final Jeopardy with a decisive lead over the best Jeopardy player of our era.

That’s what people don’t understand about Jeopardy dominance: It’s so fragile. You get only one loss, and it’s Russian roulette: Any given night could be the game with your name on it. You could play a dominant game, but still catch a bad break or two—a missed Final Jeopardy, a Daily Double found by someone else. I think there were about a dozen games in my streak where my win hinged on a single question. Incredibly, they all went my way. Until the 13th game, when one didn’t.

In the Before Times, an elite Jeopardy player such as Holzhauer would have been a mild curiosity for five days. Now these champs can be bona fide celebrities. Speaking from experience, I can tell you that Jeopardy mini-fame is a fun little adventure, but it has its downsides. Viral Jeopardy contestants get hounded by online trolls (the women in particular have to wade through some awful sludge). They get fan mail and hate mail from stans and stalkers and nuts and the incarcerated. Worst of all, they are batted around by pundits in endless, pointless hot takes about What Their Streak Means. (Not this article, of course. This one is good.)

This treatment exasperates me. These aren’t celebrities; they didn’t sign up for this! They’re normal folks, just trying to earn a little money on their favorite quiz show. It’s not their fault that they kept winning for a few weeks. If they played well, they don’t care whether you think they have a weird laugh or cute glasses or whatever. They’re not here to entertain you.

But there was something beautiful, I think, in the James Holzhauer news cycle. For two months, one of the most irresistible news stories in America was about Jeopardy, a 55-year-old media property. It seemed so wholesome and old-timey, a story that Snapchatting teens and their grandparents were all following at once. It brought back good memories of 2004 for me, but it also reminded me of a time before the cultural landscape balkanized into a thousand niches, before middlebrow America went away, before politics and everything else dumbed down.

For a little while, we just wanted to watch someone blow our minds by knowing stuff.



In the conference room Nancy Pelosi once used as Democratic minority leader, she displayed only one item on the walls. She positioned it strategically, just behind and above her seat at the head of a long mahogany table that could accommodate about 30 people. Anyone sitting at the table couldn’t avoid seeing it, and it stared back at them.

It was a portrait of Abraham Lincoln, on the floor of the House, during the single term he served in Congress from 1847 to 1849. Lincoln cradles a book and has a wry look in his eyes.

When House Democrats convened in the room to hash out strategies on policy and politics, Pelosi would point to the portrait and remind them of a Lincoln quote: “Public sentiment is everything.” That instruction guides her today on the matter of impeachment. But it’s easily misunderstood.

For Pelosi, public sentiment doesn’t mean following public opinion, but strategically shaping it so that it’s more receptive to a strategic goal. It’s not just laying the groundwork; it’s fertilizing it. That takes message discipline, unity, and patience—all of which will be necessary as pressure to impeach President Donald Trump continues to build.

Pelosi executed a strategy to shape public sentiment immediately after President George W. Bush’s reelection in 2004, when Republicans expanded their majority by three seats. Bush was pushing for a politically risky overhaul of Social Security. Members of her caucus and outside advocacy groups pressured Pelosi to propose alternative policies. But Pelosi knew that once Democrats offered a solution, they would give Republicans something to attack rather than defend. For nearly two years, Republicans watched their favorability ratings fall, dragged down by a spate of scandals and the unpopular war in Iraq. Only a few months before the midterm election, Pelosi and the House Democratic Caucus rolled out “6 for ’06,” the legislative priorities they would pass if in the majority. Naturally, Republicans took an offensive posture, but by then it was too late. Public sentiment had ripened for a Democratic legislative agenda, the party gained 32 seats in the House, and Pelosi became speaker. Then she mobilized her majority to pass those very priorities. Two years later, in 2008, the electorate rewarded Democrats with an even larger majority. Timing was everything.

On a more mundane level, I caught Pelosi’s ire when I forgot the Lincoln mantra. It was May 2003, only two years into my 16-year tenure representing a fairly competitive district on Long Island, New York. When Republicans offered a new package of tax cuts skewed to the wealthiest, I indicated to the Democratic whip’s office that I was undecided. A few days before the vote, Pelosi hunted me down on the House floor and asked why I couldn’t oppose the measure. When I told her that many of my constituents favored it, she looked me squarely in the eye and said, “Well, educate them.”

Pelosi’s sensitivity to public sentiment requires her to keep tabs on three fronts.

The first is the Democratic caucus. She constantly monitors and measures the mood of her colleagues. She rotates through her office the House Democratic leadership, a wider leadership group called the Steering and Policy Committee, the chairs of various legislative committees, and the leaders and members of dozens of disparate caucuses (the Congressional Black Caucus and the conservative Blue Dogs, the Congressional Hispanic Caucus and the Congressional Asian Pacific American Caucus, the Congressional Progressive Caucus and the moderate New Democratic Caucus). Then she goes to ground, conferring with members one-on-one. Not everyone knows what everyone else is thinking. She and Majority Leader Steny Hoyer do. It’s how they shape consensus.

Pelosi tells her caucus, “Our diversity is our strength; our unity is our power.”

The second is the congressional electorate, which determines which party controls the House. Sure, Pelosi has institutional responsibilities. Yes, she must reflect the progressive values and priorities of the Democratic Party. But she also has a responsibility to keep Democrats in the majority, so that they can fight effectively for those values and priorities. She’s got to win elections.

An impeachment inquiry that results in Trump’s acquittal in the Senate may jeopardize the 31 Democrats in districts where Trump beat Hillary Clinton in 2016. If Democrats lose 18 seats in 2020, they return to the minority just in time for Republicans to try to use gerrymandering to keep them there for a decade. Many Democratic members from those districts tell me that public sentiment, particularly among vitally needed swing voters, is currently against impeachment. Even Republicans recall how the failed impeachment of President Bill Clinton backfired: In 1998, Democrats gained seats in Congress, a rare occurrence for a president’s party in a midterm election.

The third is the presidency. When Barack Obama was president, Pelosi made sure that decisions by House Democrats were calibrated to avoid friction with the White House. Today, Pelosi makes sure that decisions by House Democrats won’t fortify Trump in battleground states including Wisconsin, Pennsylvania, Florida, Michigan, and others. “Trump is goading us to impeach him,” Pelosi recently told an audience in New York. “That’s what he’s doing. Every single day, he’s just, like, taunting, taunting, taunting. Because he knows it would be very divisive in the country, but he doesn’t really care. He just wants to solidify his base.” If Pelosi and Trump agree on anything, it may be this formula: At this moment in time, impeaching Trump minus convicting Trump equals reelecting Trump.

But “this moment in time” does not mean “all moments in time.” Pelosi, remember, believes it’s possible to shape public sentiment. That’s why she’s unleashed her committee chairs to fully exercise their oversight responsibilities by investigating every facet of potentially impeachable offenses: Jerry Nadler of the Judiciary Committee, Adam Schiff on Intel, Maxine Waters on Financial Services, Elijah Cummings on Oversight and Reform. They may find a smoking gun—incontrovertible evidence that crystallizes public support for impeachment and maximizes pressure on House Republican incumbents in moderate districts. Then Pelosi will have achieved her goal: a broader public consensus for impeachment and stronger, if not necessarily overwhelming, bipartisan support.

Progressives worry that if Democrats avoid impeachment with this president, they will set a bad precedent. Just how bad must things get? Fair enough. But for Democrats there’s a worse outcome: a premature impeachment that acquits and helps result in the reelection of Trump with a loyal Republican majority in Congress, an expanded Republican majority in state legislatures, and a permanently hyper-conservative judiciary.

That would fracture and set back the country more than at any time since Lincoln. Which is why that portrait was on that wall.



In my long career as an academic jack-of-all-trades, I sometimes teach law students Jurisprudence—that is, Philosophy of Law. The course begins with the question “What is law?” and its corollary, “What is lawlessness?”

The latter comes in two flavors. The first is anarchy—Hobbes’s “war of all against all,” a Mad Max moonscape in which only stealth and brute force provide even a semblance of safety. Such situations existed for millennia and, though relatively rare, exist in remote parts of the globe today.

But there is an authoritarian lawlessness that is far more common in the 21st century, and next time I teach the course, I will have the most precise example of this second version I have ever seen: the dispute over 26 U.S. Code § 6103(f)(1), which reads: “Upon written request from the chairman of the Committee on Ways and Means of the House of Representatives, the chairman of the Committee on Finance of the Senate, or the chairman of the Joint Committee on Taxation, the Secretary [of the Treasury] shall furnish such committee with any return or return information specified in such request,” subject only to a requirement that the return be considered in closed session.

Served with a proper demand by Representative Richard Neal, the Ways and Means Committee chair, Treasury Secretary Steven Mnuchin responded, “I have determined that the Committee’s request lacks a legitimate legislative purpose,” and that he therefore would not comply.

Let’s begin at the beginning: To paraphrase Joe Pesci in My Cousin Vinny, Section 6103 is what we lawyers call a “statute.” It was adopted by Congress as part of the Tax Reform Act of 1976. The final Senate vote on the bill was 81–1; in the House, it was 405–2. It was signed by President Gerald Ford (for those scoring at home, a Republican). Under the United States Constitution, Article VI, Section 2, it, like all statutes, is “the supreme law of the land.” It contains no provision requiring a “legislative purpose” at all. That’s not an oversight. Congress isn’t always legislating. It has other functions; one of them is to investigate officials and even private citizens, which has been part of Congress’s mission since its 1790 inquiry into the financier Robert Morris’s management of federal revenue during the Revolution.

I can’t find any mention of “legislative purpose” in the statute’s legislative history; the Senate report notes only that congressional committees “would continue to have access to returns and return information.” Nor is “legislative purpose” mentioned in the two Office of Legal Counsel opinions I have found that deal with disclosure of returns to congressional committees. “While Congress was concerned about the citizens’ right to privacy, it was also concerned about the Government’s need for the tax information, and was very much aware of its own needs,” an opinion stated in 1977. “The legislative reports, in addressing this issue, simply state that the committees will have access to tax information ‘upon written request of their respective chairmen.’”

Finally, the text contains no provision empowering the secretary of the Treasury to determine whether such a request is “legitimate.” It says “shall furnish.” The lawful response is, “Here they are.” The lawless answer is, “I personally don’t think you have a good reason to ask.” A private citizen who gave such an answer to a lawful order would be headed for jail.

Mnuchin’s defiance is of a piece with the administration’s utterly unprecedented claim that “executive privilege” permits it to refuse to provide documents or testimony whenever it suits the president. Though not mentioned in the Constitution, executive privilege over the years has evolved to protect a few classes of information—military and law-enforcement secrets, for example, specific advice provided by officials directly to the president, and certain internal deliberations over policy.

But except in those limited cases, the executive is expected to provide information at the request of Congress and the courts. Sometimes these disputes require negotiation to reach a balance between what Congress seeks and what the president feels able to reveal. Since the George Washington administration, the most common result has been compromise; though sometimes the fight turns ugly, as former officials such as Attorney General Eric Holder and White House Counsel Harriet Miers found out when different Congresses held them in contempt for defying subpoenas.

No president I know of has asserted a blanket power to reject any request that doesn’t suit him—until Donald Trump. No president I know of has rejected requests on the grounds that the committee requesting is controlled by Democrats—until Donald Trump. The ongoing battle between this administration and the House committees is not, at heart, a legal dispute at all; it is an assertion by a president that the law and the Constitution are simply irrelevant when they conflict with his will.

The administration’s contempt for statutes is not limited to its disputes with Congress. Statute 8 U.S.C. § 1158(a) states: “Any alien who is physically present in the United States or who arrives in the United States (whether or not at a designated port of arrival and including an alien who is brought to the United States after having been indicted in international or United States waters), irrespective of such alien’s status, may apply for asylum … ” Critics often rightly criticize congressional draftsmanship as unclear—but this particular provision isn’t. “Any alien … whether or not at a designated port of arrival.”

And yet the Trump administration’s new asylum regulations say that any alien not at a port of entry may not receive asylum. Congress said “may apply”; Trump said “may not.”

This is the climate of law in 2019. If a president obstructs justice, it’s not illegal—because, you see, he doesn’t like being investigated. If Congress refuses to appropriate funds for a border wall, build it anyway. If the Posse Comitatus Act forbids use of the military in immigration enforcement, urge soldiers to shoot migrants anyway. If the Administrative Procedure Act requires a notice-and-comment procedure before changing regulations, skip the procedure and announce it anyway. If a racist sheriff gets caught harassing Latinos, pardon him. Urge police to beat suspects; urge crowds to shoot immigrants. If a federal trial court rules against a Trump business, attack the judge as “Mexican”; if a federal judge rules against the “travel ban,” attack the “so-called judge.” If a Court of Appeals agrees about the travel ban, threaten to abolish it. If another judge halts the asylum rules, call him an “Obama judge.” If the chief justice mildly protests that the judiciary is independent, tell him he’s wrong.

The Trump administration aspires to be the first of the post-legal era. It lives by a principle enunciated 2,000 years ago by the Roman jurist Ulpian and relied upon by tyrants ever since: Quod principi placuit, legis habet vigorem. What pleases the prince has the force of law.

The formal precursor to the age of post-legality was the post-norm era. This began in 2016 with the decision by Senate Majority Leader Mitch McConnell to block the Senate from considering President Barack Obama’s nomination of Merrick Garland for a vacancy on the Supreme Court. Learned commentators rushed to explain that because the Constitution didn’t say in so many words “The Senate has to act on a presidential nomination,” the Senate had no duty to do anything at all. The Washington Post fact guru Glenn Kessler said that since the Republican majority “can in effect do what it wants—unless it becomes politically uncomfortable,” McConnell’s critics had no leg to stand on. “No duty [to consider a nomination] can be found in text, history, or practice,” proclaimed the conservative oracle Josh Blackman.

The fact is, the duty to vote up or down on presidential nominations was a constitutional norm, an unwritten practice forged over decades. Today, with the eager assistance of the legal right, that norm sleeps with the fishes. After the Garland victory, the new administration and its Senate allies revoked other norms—such as Congress’s oversight role and the executive branch’s duty to respond to it. The prince decides what Congress may consider and what it may not.

Without norms, the Constitution is toothless. The Constitution doesn’t, for example, say that Congress must create an Army and a Navy—or appropriate any funds for any purpose at all; it doesn’t say that the Supreme Court has to decide on the constitutionality of laws, or even hear cases at all; it doesn’t say that there must be a Justice Department or that it must prosecute federal crime or that attorneys general need to follow the law or that judicial nominees must support Brown v. Board of Education. The Constitution doesn’t say that officials have to tell the truth to the public. All those things are norms, and without them, the system will harden into autocracy with alarming speed.

A decade or so ago, I spent part of a summer advising a Chinese news magazine about American law. As I was preparing to leave Beijing, I had a farewell dinner with one of the magazine’s young reporters. More or less out of the blue, she asked me for the meaning of the phrase “rule of law.”

I answered that “rule of law” meant that both the government and the people existed within a binding legal framework, and that both respected the decisions of legislatures and courts even when they disagreed with them.

She seemed taken aback by my answer. “‘Rule of law’ means that law binds the sovereign?” she asked. I said yes.

After a long minute, she said, “That would never work in China.”

At that time, many outsiders were hopeful that China would evolve toward democracy. Ten years on, it has not. China has a constitution; it has laws; it has lawyers and courts galore. But none of these things bind the government of Xi Jinping—whether it is kidnaping Hong Kong bookstore owners or penning Uighurs in concentration camps. “Rule of law” in China means the rulers command and the people obey. The “justice system” exists, more and more, only to effectuate those commands and demand that obedience.

The United States could find itself in a similar place much sooner than its people would like to think.



Robert Mueller has advised Americans to go back and actually read his report if we want to understand what happened in 2016. “We chose those words carefully, and the work speaks for itself,” he said on Wednesday morning, speaking publicly for the first time since his appointment.

But the words of the report are damning.
“The Russian government interfered in the 2016 presidential election in sweeping and systematic fashion,” Mueller wrote. This help “favored presidential candidate Donald J. Trump and disparaged presidential candidate Hillary Clinton.”
The Trump campaign “expected it would benefit electorally from information stolen and released through Russian efforts,” and it “welcomed” this help.
There is insufficient evidence to accuse the Trump campaign of criminal conspiracy with its Russian benefactors. However, “the social media campaign and the GRU hacking operations coincided with a series of contacts between Trump Campaign officials and individuals with ties to the Russian government.”

These contacts were covered up by a series of lies, both to the special counsel and to Congress. Lying by the Trump campaign successfully obscured much of what happened in 2016. The special counsel in some cases “was not able to corroborate witness statements through comparison to contemporaneous communications or fully question witnesses about statements that appeared inconsistent with other known facts.” In particular, the investigation never did determine what happened to proprietary Trump-campaign polling data shared with the Russians.
Within hours of the appointment of a special counsel to investigate 2016 events, Trump began defaming him. Trump had already fired the FBI director who investigated these events. His first order to fire the special counsel appointed in the director’s place was issued on June 17, 2017, a month after Mueller’s appointment. That order would be followed by many more. Trump directed his staff to lie about these orders.
Over and above his efforts to fire the special counsel, “the President engaged in a second phase of conduct, involving public attacks on the investigation, non-public efforts to control it, and efforts in both public and private to encourage witnesses not to cooperate with the investigation.”
The subversion of the investigation was brazen. “Many of the President’s acts directed at witnesses, including discouragement of cooperation with the government and suggestions of possible future pardons, occurred in public view.”

Obstruction of justice, though, need not be clandestine to count as a crime. What matters is intent—and that must be judged by Congress, not a special counsel subordinate to the Department of Justice and bound by its rule that a president cannot be indicted.
The full report is rich with details. But that’s the essence. A foreign power interfered in the U.S. election to help the Trump campaign. The Trump campaign welcomed the help and repeatedly lied about it. The lying successfully obscured some questions the investigation sought to answer; in the end, it found insufficient evidence to charge a broader conspiracy. President Trump, in public and in private, worked to stop the investigation.
Those are the facts. What are the remedies? Mueller underscored at his press statement: He did not exonerate the president. Under the Department of Justice rules he was subject to, he lacked the power to act.
Meanwhile, the Trump administration refuses to take steps to secure the next presidential election against the interference that swayed the last. The question of why Russia so strongly wished to help Trump remains as mysterious as ever. In particular, if you wish to understand the breadth and depth of Trump’s Russian business connections before he declared for president in 2015, Mueller’s report will not help you.
Mueller says he can do no more. The rest, Congress, is up to you.



Mercurial bosses in dysfunctional offices sometimes give orders that their employees just ignore—even when that dysfunctional office is the highest in the country. According to Robert Mueller’s recent report, Donald Trump tried to get his staff to impede the special counsel’s investigation, but figures such as Don McGahn and Rod Rosenstein protected the president—and themselves—by quietly letting those orders slide.

In better-run offices, employees defy their superiors overtly. Back in the early 1980s, when Joanna Hoffman was in charge of marketing for Apple’s nascent Macintosh computer system, her boss, Steve Jobs, was a demanding, tantrum-throwing perfectionist. According to his biographer, Walter Isaacson, every year from 1981 on, the team developing the Mac gave an award to the person who could best stand up to Jobs. The first winner was Hoffman.

At one point, Isaacson wrote, she found out that Jobs had adjusted her marketing projections “in a way she found totally reality-distorting.” As she marched toward his office, she told his assistant, “I’m going to take a knife and stab it into his heart.” The company’s counsel overheard her and rushed out to stop her. “But,” she told Isaacson, “Steve heard me out and backed down.” The next year, she won the award again.

In the traditional workplace hierarchy, CEOs are used to getting their way, and open defiance could endanger a worker’s job. The literature of human-resources management abounds with articles such as “How to Write Up an Employee for Insubordination” and “Getting Compliance When Employees Simply Do Not Want To.” Tips to employees on how to fend off unwise, unethical, or even illegal demands from above are harder to come by.

A product of the business world, Trump couldn’t abide the notion that his underlings would question him—even after Mueller noted that, in slow-rolling his demands, they’d limited his exposure to obstruction-of-justice charges. “Nobody disobeys my orders,” Trump insisted.

The best bosses, however, recognize that defiant employees are sometimes right and that, even when they’re not, their disagreement is useful. In 1985, when Jobs was fired from Apple and started NeXT, Hoffman went with him. Some firms, as a matter of policy, urge employees to speak up. McKinsey, the management-consulting firm, insists that employees have an “obligation to dissent.”

Workplaces function better, business ethicists point out, when they make room for a certain amount of defiance. “I think you always have to make independent judgments about orders that come down to you,” Charlan Nemeth, a psychology professor at the University of California at Berkeley, said in an email. Nemeth, the author of the 2018 book In Defense of Troublemakers, added, “People who speak up are often those most loyal to the organization.”

You’d be hard-pressed to find a psychologist or organizational-culture expert who endorses the idea of blowing off your boss’s commands and hoping she won’t notice. And in the face of real wrongdoing, outright defiance is a clear moral mandate. This is why we make movies lionizing whistle-blowers, and why protections for them are enshrined into law. In military courts, the refusal to carry out an unlawful order is protected. Indeed, it isn’t defined as insubordination at all.

Most of the time, though, the modern workplace can be a difficult venue for conspicuous displays of individual conscience. Activities that are protected by law—for example, union organizing—are often strongly discouraged in reality. Even under the most genial of bosses, office politics usually favor collegiality and compliance over overt confrontation. Some corporate boards, Nemeth notes in her book, even include “team player” clauses in their contracts, discouraging members from disagreeing. Ultimately, what constitutes insubordination is in the eye of the person who can fire you for it.

Even when the boss isn’t fudging numbers or trying to subvert a federal investigation, organizations are worse off when employees defer too much to those in charge. Entrepreneurial history is littered with examples of executive autocracy, from Henry Ford to Abe Rosenthal of The New York Times. It’s also littered with examples of when that style failed. The “cult of the CEO” that took hold in the 1980s and ’90s flattered top executives into equating their companies’ best interest with their own self-aggrandizement. The hardest-charging corporate chieftains may get their comeuppance quickly—for instance, Albert “Chainsaw Al” Dunlap’s infamous stewardship of Sunbeam in the 1990s resulted in his firing amid an accounting scandal after just 23 months—but not before doing great harm to the companies they lead. Sunbeam declared bankruptcy a few years later.

Especially in such environments, disagreement helps everyone make better decisions. “The beauty of the results of our decades of studies is that, even if you are wrong, your dissent stimulates others to think in more open, more divergent, and better ways,” Nemeth said. “They consider more information and alternatives, more cons as well as pros of a position, and in general the team will make better decisions.”

Other studies suggest that employees will perform better when given moral autonomy than when they’re just expected to obey. In 2018, the Harvard Business School behavioral scientist Francesca Gino and her colleagues conducted an experiment: They posed difficult ethical challenges in which there appeared to be no good solution. They then asked some participants what they should do and others what they could do. The “could” group generated more creative solutions, Gino said via email. Gino, the author of the 2018 book Rebel Talent: Why It Pays to Break the Rules at Work and in Life, also cited research indicating that when we experience conflict, we generate more original solutions to problems than when we are in a more cooperative mood.

In other words, confronting the boss is fundamentally helpful. Even when an employer’s order crosses no ethical boundaries, Gino said in a subsequent message, “it could still mean carrying out a process that could be better if employees asked questions rather than simply accepting blindly what they have been asked to do.”

That’s why Joanna Hoffman rejected Steve Jobs’s fanciful marketing projections. She survived because Jobs was, at least sometimes, willing to admit when he was wrong and his subordinates were right.

Good leaders understand how important that capacity is. “Put simply,” the author and entrepreneur Bill Taylor wrote in Harvard Business Review, “you can’t be an effective leader in business, politics, or society unless you encourage those around you to speak their minds, to bring attention to hypocrisy and misbehavior, and to be as direct and strong-willed in their evaluations of you as you are in your strategies and plans for them.”

That kind of humility is in short supply among many CEOs (including, he’s suggested, the head of the country). Taylor pointed to the work of the retired MIT management professor Edgar Schein, who warned, “Deep down, many of us believe that if you are not winning, you are losing.” Sound familiar?

Whether those people who directly disobeyed, blew off, or just creatively interpreted Donald Trump’s orders did the right thing remains to be seen. After all, they were the ones who stood between him and a much stronger case for criminal wrongdoing. What’s undeniable is that, in government and the business world alike, insubordination has its uses—not the least of which might be protecting the powerful from themselves.

This article is part of “The Speech Wars,” a project supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press, and the Fetzer Institute.



The sheer scale of the European elections, coupled with the huge differences among the parties that were on the ballot from Sweden to Greece, makes it possible to find evidence for just about any story about the results. Perhaps because the rise of far-right populism has, three years after the surprise victory of Brexit and the shock election of Donald Trump, come to look rather old hat, many publications have opted for a more refreshing narrative: What we saw on Sunday, they say, was a populist wave that ended “in a ripple,” or, more simply, “the populist surge that wasn’t.”

This narrative points to some important facts. Far-right populists had a disappointing night in a number of big countries, including Germany and Spain. Their advance slowed or went into reverse in a few smaller countries where they once looked as though they could pose a real threat, including Denmark and the Netherlands. And though their overall ranks have swelled, they are in no position to take down the European Union anytime soon.

At the same time, these facts only add up to an optimistic takeaway if one’s baseline for populist success is unmitigated triumph. The real story here is that right-wing populists are still growing—and have already established themselves as a fixture on the political stage.

When the far-right Freedom Party joined the Austrian government as a junior coalition partner in 1999, the shocking news of its ascent dominated European headlines for months on end. Statesmen across the continent vowed that they would never treat extremists as legitimate leaders of European nations. The member states of the EU unanimously imposed diplomatic sanctions on Austria.

There were good reasons to hope that the populists’ success in Austria would remain a strange aberration. In that year’s elections for the European Parliament, far-right extremists failed to break into the double digits in any other country; nowhere did they win an outright majority.

Twenty years later, it is painfully obvious that the events in Austria were a harbinger of things to come. Movements that are every bit as extreme as the Freedom Party are now in government across large chunks of Europe, from Hungary to Italy. In Sunday’s elections, they posted their best results in the history of the European Parliament, entrenching themselves as a major presence in virtually every country across the length and breadth of Europe, and claiming the top spot in some of its most influential states.

In France, Marine Le Pen’s National Rally beat Emmanuel Macron’s En Marche. In the United Kingdom, Nigel Farage’s newly founded Brexit Party took a significantly greater share of the vote than Labour and the Conservative Party combined. In Poland, the far-right Law and Justice bested a broad alliance of moderate politicians. And in Hungary, where Viktor Orbán has already amassed so much power that the country’s election results should be interpreted with a healthy dose of skepticism, his Fidesz party once again crushed the opposition.

The results in Italy were especially striking. By engaging in ever more extreme demagoguery against immigrants, Matteo Salvini has transformed the Northern League, a small separatist party fighting for northern independence, into the dominant force in national politics. When he entered government last year, his party was the junior coalition partner to the Five Stars, a populist movement with roots in the political left. Now he has eclipsed his rivals, winning six times as many votes as he did five years ago, and twice as many as he did last year. In the process, he has cemented his position as the likely next prime minister—and radically transformed Italy’s political geography.

For 100 years, Tuscany was one of the most reliable strongholds for Italy’s left. In the bitter years of Benito Mussolini, brave anti-fascist partisans used to find refuge in the woods that cover the nearby mountain. When democracy returned to Italy, local peasants and tradesmen voted for mayors who proudly belonged to the Italian Communist Party. Even when the parties that had shaped the postwar period disintegrated amid a giant corruption scandal in the early 1990s and Silvio Berlusconi rose to power, most Tuscans dutifully transferred their allegiance to the center-left Democratic Party.

Throughout this period, far-right parties such as the Northern League had little support in the region. As recently as 2014, it barely scratched 3 percent of the vote in the province of Grosseto.

But this century-old tradition has now come to an abrupt end. In Arcidosso, where I have spent a part of every summer for the past dozen years, the Northern League took 39 percent of the vote in Sunday’s European elections. In Castel del Piano, a beautiful hilltop town I can see out of my kitchen window, it surged to 41 percent. In Seggiano, a picturesque village I look at from my garden, it got 48 percent.

The cumulative impact of these right-wing-populist victories in Tuscany, in Italy as a whole, and throughout Europe is evident in the overall composition of the European Parliament. While the center-right European People’s Party (EPP) has long enjoyed the loudest voice in Brussels, its influence will now be rivaled by the far right. If you add up the different factions of right-wing populists, they now outnumber the EPP. If this is what it looks like when the populist wave crests, then I suppose we’ve all become used to living underwater.

It’s tempting to imagine that some of the progressive parties that are now in the ascendant across Europe might be able to stem the right-wing tide. As they have shed the radicalism of their founding period, the Greens have, for example, become ever more popular in Germany. Five years ago, they took 11 percent of the vote, finishing third. This time around, they doubled their share of the vote, comfortably taking second place. For the first time in history, they have beaten Germany’s Social Democrats in a nationwide election. And Germany’s Greens are part of a wider trend: Their sister parties also posted significant gains in France, Portugal, and the United Kingdom. Meanwhile, liberal parties, which tend to pursue more pro-market policies but have similar views on many social issues, performed strongly in Britain, Spain, the Netherlands, and parts of Scandinavia.

But while they have proved very powerful in urban centers and among the highly educated, these parties struggle elsewhere. Young students in Berlin and London feel seen by Germany’s Greens and Britain’s Liberal Democrats. But a huge cultural and economic gulf separates these parties from the older workers in Wolverhampton, the middle-aged electricians in Gelsenkirchen, and the young shop assistants in Arcidosso who once favored traditional left-wing parties. Despite the success of the Greens, the left across Europe now captures a smaller share of the vote than it did five years ago. (In 2014, the three left-wing factions in the European Parliament held 293 seats between them; now their share has shrunk to 260.)

Thinking of those hills and valleys of Tuscany I love so deeply, and of the locals who have always been so kind and welcoming to me and my friends, I cannot help but hope that they will soon come to regret their support for Salvini’s demagoguery. But I also fear that none of the parties that are currently on the political menu in Italy, or in other parts of Europe, is doing very much to lure them back.

Traditional parties have disappointed too many people, too many times. The Greens and the liberals speak a different language, directed at a different audience. For now, only Salvini directly addresses the disenchanted voters of the Monte Amiata. Unless that changes, he may be able to count on their support for many years to come.



Is the president a king? The question may sound absurd, but you’d be surprised: A great many lawyers, politicians, judges, and policy experts think the U.S. Constitution builds from exactly that starting point. Their argument relies on the first sentence of Article II, which gives the president “the executive power.” That phrase, they claim, was originally understood as a generic reference to monarchical authority. This means, they say, that the American president must have been given all the prerogatives of a British king, except where the Constitution specifies otherwise. The foreign-relations scholar Philip Trimble states their conclusion plainly: “Unless the [Article II] Vesting Clause is meaningless, it incorporates the unallocated parts of Royal Prerogative.”

The repercussions of this claim ripple across the face of constitutional law. During Senate hearings on legislating an end to the Iraq War, Brad Berenson, who had served as one of President George W. Bush’s top lawyers, told the Senate that the executive-power clause conveys “a vast reserve of implied authority to do whatever may be necessary in executing the laws and governing the nation.” When the Bush administration wanted to defy statutory restrictions on dragnet surveillance, the Justice Department relied on the clause in advising that Congress “cannot restrict the President’s ability to engage in warrantless searches that protect the national security.” And Justice Clarence Thomas put the clause front and center in concluding that “those who ratified the Constitution understood the ‘executive Power’ vested by Article II to include those foreign affairs powers not otherwise allocated in the Constitution.”

These aren’t selective examples. Pick a random recent controversy about presidential power, and you’re almost certain to find the president-as-king claim woven into the debates. During the George W. Bush administration, the argument was used to defend the torture of prisoners, the evasion of habeas corpus, and the claim of authority to invade Afghanistan and Iraq without congressional authorization. During the Obama administration, the argument surfaced in debates about the administration’s defiance of a statute recognizing Jerusalem as the capital of Israel and about the use of force against Libya. And supporters of the Trump administration have supercharged the claim, advocating a breathtaking theory of indefeasible imperial prerogative in areas ranging from the Russia investigation and workaday congressional oversight to immigration law and the bombing of Syria.

After years of research into an enormous array of colonial, revolutionary, and founding-era sources, I’m here to tell you that—as a historical matter—this president-as-king claim is utterly and totally wrong. I’ve reviewed more than a thousand publications from the 17th and 18th centuries for each instance of the word root exec-, and have read most of those texts from cover to cover with the topic of presidential power squarely in mind. I’ve read every discussion of executive power and presidential authority that appears in the gigantic compilation of archival materials known as the Documentary History of the Ratification of the United States Constitution. And with the help of a team of research assistants, I’m most of the way through flyspecking the full records of the Continental Congress—including committee reports, floor debates, and delegate correspondence—with the same question in mind.

All this work has left me with both the confidence to share this conclusion and the sense of obligation to do so as bluntly as possible. It’s just not a close call: The historical record categorically refutes the idea that the American revolutionaries gave their new president an unspecified array of royal prerogatives. To the contrary, the presidency that leaps off the pages of the Founders’ debates, diaries, speeches, letters, poems, and essays was an instrument of the law of the land, subject to the law of the land, and both morally and legally obliged to obey the law of the land.

If you had the same third-grade history class I did, you might think this all goes without saying. But in the realm of constitutional law, these findings represent a tectonic shift.

For more than two centuries, jurists and statesmen have intoned that “ours is a government of limited powers.” That proposition is the foundational principle of federal power. The Constitution did not grant Congress open-ended authority to regulate in the public interest. Instead, the Founders wrote a laundry list of highly specific legislative authorities. This enumeration strategy, the Supreme Court has explained, is why courts must carefully consider the national government’s legislative limits: “If no enumerated power authorizes Congress to pass a certain law, that law may not be enacted.” From this starting point comes the endless constitutional sparring over the scope of the powers to regulate commerce, to tax, to spend, and to enter into treaties—just to name a few. Almost everyone agrees that unless legislators can point to an affirmative grant of constitutional authority, Congress simply can’t act.

A funny thing happens, though, when it comes to the presidency. Suddenly you see hand-waving that would be laughed out of the room just about anywhere else. Here’s Justice Robert Jackson on executive power, in 1952:

A judge, like an executive adviser, may be surprised at the poverty of really useful and unambiguous authority applicable to concrete problems of executive power as they actually present themselves. Just what our forefathers did envision must be divined from materials almost as enigmatic as the dreams Joseph was called upon to interpret for Pharaoh.

This is one of the most celebrated opinions in constitutional history. Is Jackson seriously advising us to approach problems of presidential power by meditating on curtsying wheat and overweight cows?

The answer is obviously no. But such sorcerous gesticulations are motivated by an inconvenient fact: The constitutional text doesn’t actually authorize the president to do very much. It enumerates the veto, appointments, and pardon powers. It grants the president “the executive power” and the office of commander in chief. It authorizes the president to receive foreign ambassadors, demand reports from his subordinates, and deliver a State of the Union address. But aside from a few miscellaneous process authorities, that’s just about it.

The way president-as-king theorists see it, this fact is more than just inconvenient; it’s downright dangerous. Can we imagine a country, they ask, whose president doesn’t have the authority to conduct diplomacy, recognize foreign governments, terminate treaties, acquire territory, fire officers and employees, or announce national policy? Is it conceivable, they wonder, that our national charter would fail to include an escape hatch—“In case of emergency, break this law”—for any legal requirement that interferes with our national security? For president-as-king theorists, to ask these questions is to answer them. And so they claim that the first three words of Article II—“the executive power”—vest all the authorities I’ve just described and more.

As a historical matter, my research shows that this claim is dead wrong. “The executive power” granted at the American founding was conceptually, legally, and semantically incapable of conveying a reservoir of royal authority. The real meaning of executive power was something almost embarrassingly simple: the power to execute the law. Overwhelming evidence for this point pervades both the Founders’ debates and the legal and political theory on which their discussions drew.

Listen to how Gouverneur Morris framed the problem for his fellow delegates in Philadelphia. The central challenge of constitutional governance, he said, was to safely distribute each of “the three powers” that everyone knew so well: “one … the power of making[,] another of executing, and a third of judging, the laws.” Under this tripartite system, the function of executive power was both straightforward and indispensable—to implement instructions issued by a valid exercise of legislative power. In a famous 1774 Election Day sermon, Gad Hitchcock stated the consequence plainly: “The executive power is strictly no other than the legislative carried forward, and of course, controllable by it.” These weren’t idiosyncratic views. The catechistic statement of three interlocking powers served as a universal grammar for debating constitutional governance. As one exasperated British reviewer said of the relentless trinitarianism in John Adams’s 1787 constitutional treatise, “Upon this point, like Lord Chesterfield with the Graces, Dr. Adams dwells for ever.”

And so the historical Constitution just wasn’t that complicated. It defined the president’s fundamental role as the servant of legislative will. It gave the president a conditional veto to check Congress’s exercise of that will in any particular case. And it vested a smattering of other authorities where Article II specifically said so. But that was it. The very “doctrine of prerogative” and such “other peculiar properties of the royal character,” one Virginia newspaper explained, were conceptually “incompatible with the view of these states when they are settling the form of a republican government.” The defining fact of the Constitution’s separation of powers was the structural minimalism of its presidency: Because the president’s powers were “so clearly defined,” a South Carolina Federalist concluded, they “never can be dangerous.”

Did this leave gaps in the constitutional system as ratified in 1789? Of course it did! But the Founders weren’t idiots. They knew that no legal text can anticipate every possible eventuality, so they made specific provision for Congress to decide how to fill any gaps in the system. The constitutional text on this point could scarcely be more explicit: The national legislature is expressly authorized to make “all Laws which shall be necessary and proper for carrying into Execution” any of the “Powers vested by this Constitution in the Government of the United States.” The first Congress took up that invitation and ran with it, just like its successors have ever since—conveying those powers to the executive branch by statute that the constantly evolving democratic process deems necessary for the president to have.

It’s not like this vision of the presidency leads to weakness or irresolution. Under the modern administrative state, a vast statutory framework authorizes a spectacular range of presidential authorities. But as a matter of the original constitutional understanding, all such powers are subject to legislative revision. And that’s what the Founders expected. You can advocate originalism in constitutional interpretation. You can support the imperial presidency. But you can’t do both at the same time.



Accidents are part of life. So are catastrophes. Two of Boeing’s new 737 Max 8 jetliners, arguably the most modern of modern aircraft, crashed in the space of less than five months. A cathedral whose construction started in the 12th century burned before our eyes, despite explicit fire-safety procedures and the presence of an on-site firefighter and a security agent. If Notre-Dame stood for so many centuries, why did safeguards unavailable to prior generations fail? How did modernizing the venerable Boeing 737 result in two horrific crashes, even as, on average, air travel is safer than ever before?

These are questions for investigators and committees. They are also fodder for accident theorists. Take Charles Perrow, a sociologist who published an account of accidents occurring in human-machine systems in 1984. Now something of a cult classic, Normal Accidents made a case for the obvious: Accidents happen. What he meant is that they must happen. Worse, according to Perrow, a humbling cautionary tale lurks in complicated systems: Our very attempts to stave off disaster by introducing safety systems ultimately increase the overall complexity of the systems, ensuring that some unpredictable outcome will rear its ugly head no matter what. Complicated human-machine systems might surprise us with outcomes more favorable than we have any reason to expect. They also might shock us with catastrophe.

When disaster strikes, past experience has conditioned the public to assume that hardware upgrades or software patches will solve the underlying problem. This indomitable faith in technology is hard to challenge—what else solves complicated problems? But sometimes our attempts to banish accidents make things worse.

In his 2014 book, To Save Everything, Click Here, the author Evgeny Morozov argues that “technological solutionism”—leaving the answer up to Silicon Valley—causes us to neglect other ways of addressing problems. In The Glass Cage, published the same year, Nicholas Carr points warily to “deskilling,” which occurs when the skills of human operators working a job begin to erode, as automation makes such capacities unnecessary. On average, automation is safer than error-prone humans, so a typical response to deskilling is “So what?”

The specter of airline pilots losing their manual flying skills—or being stripped of the ability to use them—brings to mind the tragedy of the Boeing 737 Max crashes. Investigators reviewing the crashes, which killed 157 people in Indonesia and 189 in Ethiopia, have zeroed in on a software problem in the maneuvering-characteristics augmentation system, or MCAS. MCAS is necessary for the Max, unlike its older brother, the 737-800, because the former sports a redesign that fits larger engines under the wings. The engine on the Max sits farther forward, creating a vulnerability to stalling from steeper climb rates on takeoff. MCAS simply pushes the nose down—and in the process, it transfers control away from the pilots. Pushing the nose down helps when averting a stall, but too much nose-down has fatal consequences.

The 737 Max crashes had other interconnected causes. In Boeing’s case, they reach all the way to financial and corporate zeal in competing with its rival Airbus, financial incentives to save money on expensive fuel, and so on. At any rate, a fix for MCAS is now under way. Everyone learned from the mistake, even as the human cost cannot be rolled back or fixed.

What makes the Boeing disaster so frustrating is the relative obviousness of the problem in retrospect. Psychologists and economists have a term for this; it’s called “hindsight bias,” the tendency to see causes of prior events as obvious and predictable, even when the world had no clue leading up to them. Without the benefit of hindsight, the complex causal sequences leading to catastrophe are sometimes impossible to foresee. But in light of recent tragedy, theorists such as Perrow would have us try harder anyway. Trade-offs in engineering decisions necessitate an eternal vigilance against the unforeseen. If some accidents are a tangle of unpredictability, we’d better spend more time thinking through our designs and decisions—and factoring in the risks that arise from complexity itself.

Perhaps the centuries-old Notre-Dame is an unlikely candidate for complicated human-machine technology, but it too may qualify. The building was equipped with fire alarms, but, according to an account in a French newspaper picked up by English-language outlets, a computer bug located the fire in the wrong place. In deciding which precautions to incorporate into a fire-safety system, building custodians take calculated risks: Automatic sprinklers, tripped accidentally or unnecessarily, could ruin paintings and other precious art.

Perrow argued in Normal Accidents that two conditions must hold for there to be significant threats in technology designs that turn safety systems against themselves: One, the systems must be complex. Two, the parts or subsystems in the design must be “tightly coupled”—that is, interdependent in such a way that a failure in one can cascade through the others to a global failure. Today most of our day-to-day life is spent interacting with such systems. They’re everywhere.

When Germanwings Flight 9525 flew directly into the side of a mountain in the French Alps, killing all on board, investigators discovered that one cause was the safety system itself, put in place in aircraft after the 9/11 attacks. The Germanwings captain, leaving the cockpit for the bathroom, was locked out by the co-pilot, Andreas Lubitz, who then set the autopilot to descend into a mountain, killing all 144 passengers and six crew on board. Like perhaps the Boeing 737 Max tragedy, and even Notre-Dame, the accident seems predictable in hindsight. It also shows the sad wisdom of Perrow’s decades-old warning. On Flight 9525, the cockpit door was reinforced with steel rods, preventing a terrorist break-in, but making it impossible for the captain to break in as well. When Lubitz failed to respond to the distraught captain’s pleas to open the door, the captain attempted to use his door code to reenter. Unfortunately, the code could be overridden from the cockpit (presumably as further defense against entry), which is precisely what happened. It was Lubitz only in the cockpit—suicidal, as we now know—for the remainder of the tragic flight. It’s tempting to call this a case of human will (and it was), but the system put in place to prevent pernicious human will enabled it.

The increasing complexity of modern human-machine systems means that, depressingly, unforeseen failures are typically large-scale and catastrophic. The collapse of the real-estate market in 2008 could not have happened without derivatives designed not to amplify financial risk, but to help traders control it. Boeing would never have put the 737 Max’s engines where it did, but for the possibility of anti-stall software making the design “safe.”

In response to these risks, we play the averages. Overall, air travel is safer today than in, say, the 1980s. Centuries-old cathedrals don’t burn, on average, and planes don’t crash. Stock markets don’t, either. On average, things usually work. But our recent sadness forces a reminder that future catastrophes require more attention to the bizarre and (paradoxically) to the unforeseen. Our thinking about accidents and tragedies has to evolve, like the systems we design. Perhaps we are capable of outsmarting complexity more often. Sometimes, though, our recognition of what we’ve done will still come too late.



Last week, a pediatrician sent me an email with a link to a paper she just published with several co-authors. “I thought you might like this!” The paper discusses baby formula, and the pediatrician figured I would find it interesting—which I did—because I’m an economist who writes about child care. As many new parents may (or may not) know, official guidelines suggest that parents boil water before mixing in powdered formula, then cool it before giving it to the baby. As the authors note, the rules call for a lengthy process with 12 distinct steps: “Twelve steps to be performed by sleep-deprived parents, often with other children to care for, up to 8 times per day.”

The 12 steps are meant to forestall bacterial contamination. The authors argue, however, that the risk of contamination in the United States is minimal—smaller than the risk that exhausted parents will seriously scald themselves or a child with hot water. They note that there are four to six cases of this particular bacterial infection reported to the Centers for Disease Control per year, whereas some 300 children are brought to the emergency room each day in the U.S. for burns from hot water (obviously these are mostly not a result of formula preparation). “Currently,” the authors conclude, “our recommendations may be doing more harm than good.”

Walking to work, I told my husband (also an economist) about the formula controversy. “Yeah,” he said. “Just another unfunded parenting mandate.”

“Unfunded mandate” refers to situations where the federal government requires states to do something, but doesn’t provide them with the money. Unfunded mandates create complications; money to pay for the mandated programs must come from somewhere, usually from other programs. This term from the world of governance is a good lens through which to understand modern parenting, which comes with a lot of rules (a lot of mandates) but not a lot of help (funding).

In pregnancy: Don’t eat this list of foods, drink this list of beverages. Sleep on your side. Don’t go skiing or engage in contact sports. Gain exactly 25 to 35 pounds. And then the baby arrives: Breastfeed exclusively until six months, continue to a year. Give them allergens as soon as you can. And, yes, if you have to use formula, mix it with boiling water.

But resources are finite. There are only 24 hours in a day. If you spend an extra hour boiling water to mix formula, that hour isn’t spent doing something else. It might be impossible to do everything that the medical and child-care establishments (Big Baby?) tell you to do as a new parent. And yet by framing each recommendation as an imperative, Big Baby provides little guidance for how to choose among them when you are constrained.

In the U.S., for example, official safe-sleep guidelines decree that parents not sleep in the same bed with their babies (commonly called co-sleeping), out of concern about higher rates of sudden infant death syndrome and suffocation. The policy message against co-sleeping is very clear, and very dire; when my daughter was born there was a brief controversy around a set of anti-co-sleeping advertisements, which equated bed sharing with allowing your infant to sleep next to a kitchen knife.

When I wrote my recent book, Cribsheet, I spent a lot of time with the data on co-sleeping. And I ultimately came to agree with the official guideline, in the sense that I believe the evidence shows a higher risk of infant mortality when parents share their bed with their infant. But the story’s not as simple as Big Baby would have you believe.

Co-sleeping is especially dangerous when accompanied by parental smoking, heavy drinking, or pillows and fluffy covers on the bed. In a safe sleep environment there is still a risk, but it is fairly small compared with other risks people take regularly (such as driving their children in a car). Seeing these risks for what they are, some parents might decide that co-sleeping (as safely as possible) is what works for their family.

The typical argument against framing risk in this way goes like so: Assuming there is a risk, even a very small one, we should tell people to avoid it. By informing parents that the risk is small, we normalize this behavior, making it seem okay. The same argument applies to the formula-mixing example at the start of this piece: Sure, the risk of bacteria is small, but it’s not zero, so why not tell parents to just boil the water?

But some infants simply will not sleep on their own. Despite parental best efforts at swaddling, white noise, rocking, tiptoeing out of the room, etc., some three-week-old babies will always wake up within a few minutes of being put down alone. In this situation, what’s a parent to do? Remember that Big Baby also tells parents that sleep is incredibly important for the developing brain (which it is). And consider that if baby’s not sleeping, Mom and Dad aren’t sleeping, and if Mom and Dad aren’t sleeping, they’re probably stressed—and perhaps clumsy with that boiling water.

It is easy to say, “Do the safest thing, it’s only a few months, it ends,” but where do people get the resources to survive these few months? When parents set out to do everything by the book, too often they ultimately muddle through, making choices at random. They co-sleep by accident: They try to stay awake and end up snoozing with the baby on a sofa (much more dangerous). Or  parents try to split the night between them and then both drive to work the next day exhausted.

If parents understood that the risks of co-sleeping (in a safe sleep environment) are small, more of them might do it—just like if they understood that the risks of using room-temperature water for formula are small, they might do it. The simple fact that resources are limited means the alternative might be worse.

The upside of mandates—either in parenting or in policy—is that they are clear. Telling parents that you “must not” co-sleep and you “must” breastfeed could produce slightly better outcomes overall if everyone were able to follow instructions to a T. But in a world of constraints, parents might not be able to do everything they are told. If they lack accurate information on the actual benefits and risks of each behavior, they also lack the ability to make optimal choices under those constraints.

Here’s an example from pregnancy. Women are told not to drink too much coffee, and not to smoke cigarettes. Many might conclude that the risks are similar; some might feel that they can really only give up one, and choose to break the coffee habit. (You have to find the money for that unfunded program somewhere … ) But the risks of copious coffee drinking are extremely small relative to the risks of smoking during pregnancy. Knowing this information might lead to a different choice. Similarly, if parents disregard mandates derived from small risks (such as the imperative to boil water for formula) and find that nothing harmful happens, they might feel emboldened to disregard mandates derived from large risks—such as the imperative to vaccinate children.

Communicating risks accurately is a challenge. But it is one that advice-givers such as the American Academy of Pediatrics need to meet. Let’s end unfunded parenting mandates and replace them with evidence-based advice about risks. We can start by saving a few parents from scalding themselves.



“We fight with the values that we represent; we don’t adopt those of our enemy.” This is what I told the marines standing in a loose semicircle around me on our forward operating base outside Karmah, Iraq, one day in December 2008. “If we lose sight of that, we’ve got nothing left.” I meant every word. For many of us, making sense of the war in Iraq was becoming harder, but we needed to believe that we were fighting for something. Most could articulate a version of that argument themselves during squad-level discussions back in Hawaii, but now it was hard to tell what impact my words were having. I watched the familiar faces as I spoke. Some nodded, others looked at the ground, shifting their feet on the gravel or gazing back impassively, their expressions a reflection of the gray skies and drizzling rain.

The day before, the same faces had watched, blanched with shock, as the battalion sergeant major and I removed the remains of the 19-year-old Thomas J. Reilly from the Humvee in which he had died. In a war in which death was customarily delivered remotely by roadside bombs, T.J.’s killing had been an unusually personal one. As his Humvee passed through Karmah’s darkened streets, someone standing just feet away threw an RKG-3 anti-tank grenade—an unusually sophisticated weapon for that war—sending a shaped charge of molten steel through the roof of the vehicle, killing T.J. and wounding the other three members of his fire team. I was nearby when the incident happened and arrived on the scene within minutes. One look at the faces around the wrecked Humvee told me that what lay inside would be bad. It was. That image remained in my memory, the way the shadow of an object seen in the bright sun lingers on your retina when you close your eyes.

To almost everyone in Charlie Company, T.J. had been a familiar figure—an irrepressibly good-humored marine well liked by his platoon-mates, most of whom had been together since boot camp. From London, Kentucky, he had been brought up by his mother, Georgina, to whom he was dutiful in a way that few teenagers are. He called and wrote regularly, trying to reassure her that things weren’t as bad in Iraq as the news made it appear. His hobby was cooking. Impervious to the ribbing it inspired from his squad-mates, he had plans after the Marine Corps to become a chef. Now he was on his way back to his mother in a casket marked “remains unviewable,” and we were leaving on an operation to find his killers. A “cordon and search,” I called it—but it was really to get Charlie Company back on the streets, giving them the catharsis of purposeful action, rather than leaving them sitting on base to brood.

I harbored little hope of finding clues that might lead us to the men who had killed T.J. The city of Karmah was a dark place, its sullen population and unlit streets redolent with menace. A succession of Marine battalions had been badly mauled there over the years with little to show in return. The commander of the battalion that had preceded us, a close friend of mine, had died in a suicide-bomb attack days before our turnover. His unit, which had poured hundreds of thousands of dollars into various projects around the city, left angry and bitter, convinced that a prominent local sheikh, a recipient of much U.S. largesse, was behind the attack.

I was aware that the marines of Charlie Company would want revenge for T.J.’s death—and among young men trained for violent confrontation, such a desire can find explosive outlet unless resolutely curbed. Your moral resolve sags under the experience of combat in a place like Iraq: fatigue from lack of sleep and the enervating effort of lugging body armor, weapons, and equipment in breathless heat; persistent exposure to a culture in which, at least to our eyes, the locals seemed to show casual cruelty to others of different tribes and denominations, and that, to us, appeared to exalt brutality; and the frontal-lobe numbing effect of fear, grief, and white-hot anger. I had experienced that anger myself—despite having two decades on my marines, and degrees in philosophy and law—and I wasn’t foolish enough to assume that my talk to them that morning would make a difference.

Nevertheless, I wasn’t concerned. I knew that the leaders closer to them than myself, their sergeants and lieutenants—though still reeling from the loss themselves—would restrain their subordinates from venting their anger on the local population. That may sound like reckless faith, but we had prepared for moments like this, and I knew that I could trust them. And all of us understood the consequences of failing to do the right thing—for our unit, for our cause, and for ourselves.

Memories of Karmah came back to me three weeks ago, when President Donald Trump granted a pardon to Michael Behenna, a former Army lieutenant convicted of the murder of an Iraqi prisoner in 2008.

“We know we have a president who is very sympathetic to the very difficult situation that soldiers, sailors, and marines were put in during the Iraq and Afghanistan wars,” John Richter, the lawyer who defended Behenna in court, told The Washington Post. Since then, The New York Times and others have reported that, around Memorial Day, the president intends to pardon other servicemen accused or convicted of war crimes. Among the names that have been floated are Naval Special Warfare Operator Chief Eddie Gallagher and Green Beret Major Mathew Golsteyn, both of whom have been charged with murder and are pending trial. Golsteyn stands accused of murdering a detainee, while Gallagher faces allegations that he shot civilians and stabbed a prisoner to death. The president’s comments came against a backdrop of sympathetic media coverage of both men, and amid appeals by politicians on their behalf.

Behenna, Golsteyn, and Gallagher held leadership positions within elite units and were all described in the media as being highly decorated heroes. The public seems uneasy to see such Americans in the dock.

They are men of proven character, runs the subtext. If they did lose their way, it was because of what they went through, because of what they did for their country. And when you’re fighting a vicious enemy, sometimes the rules just don’t make sense. It’s a superficially beguiling message, but one that undermines rather than supports the sacrifice of those who serve. As a combat veteran myself, I watch these developments with deep unease.

If the men in question had been junior soldiers, I might feel differently. But when the military gives you responsibility, it comes with the understanding that you can’t abandon it by blaming the stressors of combat. Because it’s in combat when your subordinates depend on you the most—when fear, fatigue, and anger threaten to take them off path, and when, lacking firm guidance, they are likely to blunder down a dangerous path. Among the squad leaders whom I sent into Karmah that day were a number who had earlier served with me as junior marines in the Battle of Fallujah, during a four-month period in which the same battalion had seen 45 marines killed, with another 250 wounded. None of them used that fact as an excuse to abuse prisoners or the local population—then or afterward. That doing so was forbidden was just understood.

Just over 40 years before I addressed my marines in Karmah, another Charlie Company reacted very differently to the impact of fear and loss. On March 16, 1968, in the Vietnamese village of My Lai, U.S. soldiers killed between 347 and 504 unarmed Vietnamese civilians and raped approximately 20 women and girls, some as young as 10 years old. In an article published in The New York Times on the 50th anniversary of the incident, Christopher J. Levesque illustrated that until that point, there was nothing remarkable about Company C, 1st Battalion 20th Infantry. Demographically, the soldiers who composed the company were an average representation of the U.S. Army, even slightly better educated than the norm in terms of high-school-graduation rates. They came from homes across America, cities and small towns and remote rural areas.

And what emerged in subsequent media interviews with these young soldiers was their absolute ordinariness.The only thing exceptional about them was their leadership, or rather, its absence. Charlie Company’s commander, Captain Ernest Medina, was a singularly unpleasant individual who, according to subsequent testimony, was in the habit of beating detainees during interrogation. The platoon that did most of the killing was headed by Second Lieutenant William Calley, who reportedly killed an unarmed farmer in front of the platoon several days before the massacre. Calley was the only person convicted of any crime, serving three and a half years under house arrest after President Richard Nixon intervened to keep him out of prison.

When I was a lieutenant at the Basic School for Marine officers, the story of the My Lai massacre was required reading, and the lesson was clear: Nothing absolves a leader from upholding the law of war. That lesson may now appear blurred by the passage of time and the implicit belief that such a thing couldn’t possibly happen again. Today’s all-volunteer force may be better educated than its draftee predecessor, but the alchemy of combat without firm direction remains as morally destructive as ever.

In 2006, in the Iraqi town of Mahmudiya, a group of soldiers from the 101st Airborne Division gang-raped a 14-year-old Iraqi girl before killing her, her 6-year-old sister, and both her parents. It’s a story made all the more shocking because these weren’t reluctant draftees but well-trained volunteers belonging to a storied unit with proud traditions. In Black Hearts: One Platoon’s Descent Into Madness in Iraq’s Triangle of Death, the author Jim Frederick recounts the story of how 1st Platoon, Bravo Company slid into a state of collective sociopathy. In the book’s foreword, Frederick notes a marked contrast in behavior between 1st Platoon and its two sister platoons within the same company, “who labored under exactly the same conditions but who had come home with far fewer losses and their sense of brotherhood and accomplishments more or less intact.” The difference, Frederick concludes, was leadership: The other two platoon commanders were uncompromising when it came to adherence to the rules of war.

In November 2005, after losing one of their comrades to an IED, a squad of marines was involved in the unlawful killing of 24 Iraqi civilians in the town of Haditha. When the news broke, I overheard my boss, a Marine colonel, assure his wife, “Well, of course they didn’t do it.” Part of me envied his cheerful naïveté, but I had witnessed firsthand the corrosive effect that sustained exposure to violence and fear can have on previously held moral convictions. I knew that under the right circumstances, almost anyone is capable of committing a war crime. Those circumstances had come together for me on a fire-swept street in Fallujah, when I found myself balling my fists as two detainees were led past the bodies of the two marines whom I had just seen them kill. I wanted those Iraqis dead. I learned then firsthand how combat can make good people do bad things, which is exactly why it’s so important to reinforce the message that it’s not okay to do so.

In the aftermath of Haditha, the commander of the unit involved was relieved of his duties. A year later, I listened with a group of fellow battalion commanders as then–Lieutenant General James Mattis explained to us why he had made that decision. “As a leader, you can’t be a gray man,” Mattis said. “Those of you who are introverts need to change or find another profession, because if you aren’t aggressive about establishing ethical standards, someone else will fill that vacuum. Our Marine hymn reminds us to keep our honor clean. And the consequences of failing to do so, for our cause and for the young men and women involved, will be profound and irreversible.” It might never have occurred to Mattis to remind us that leaders themselves shouldn’t commit war crimes; surely they knew.

I wrote his words down at the time, and in the years since have been reminded often of their truth. When a leader, through his actions or inaction, grants his subordinates unrestricted license to kill, he neglects his responsibility for their welfare and undermines the cause for which they are risking their lives. Moral injury can be every bit as disabling as physical or other, psychological wounds.

And the “all’s fair in war” argument backfires when a civilian population seeks revenge against an occupying army that treats it with ruthless disdain. Being subjected to brutality tends to strengthen a person’s resolve and nurture a desire for revenge. The killings of civilians in Mahmudiya and Haditha were widely covered by the Arab media and became a rallying cry for our enemies.

It’s now been more than a decade since Lance Corporal T.J. Reilly was killed in Iraq. I think about him often, and the many others I have known who fought honorably and died for their country. Memorial Day is meant to be the day when America honors their sacrifice—not an opportunity to excuse those whose actions sully the cause for which they died.



Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

The truth is more complex, but still appalling. The sheer effrontery of the government’s argument may be explained, but not excused, by its long backstory.

The government’s “safe and sanitary” argument did not arise from a new case generated by Trump-administration policies. It arose in 1985, during the Reagan administration, when a 15-year-old Salvadoran child named Jenny Lisette Flores was detained after entering the United States illegally, hoping to escape her country’s vicious civil war. Flores spent two months at a facility in California, confined with adult strangers in poor conditions and strip-searched regularly. In July 1985, she and three other minors brought a class action against what was then called the Immigration and Naturalization Service, challenging its policies for the care and confinement of minors.

In 1997, after a dozen years of litigation, the parties settled the lawsuit in what became known as the “Flores Agreement.” The Flores Agreement requires, among other things, that the government hold minors in facilities that are “safe and sanitary” and that they be released from confinement without delay whenever possible.

Over the years, lawyers acting on behalf of minors protected by the Flores Agreement have filed numerous motions asking judges to enforce it, claiming that the government has fallen short of its obligations. They filed the motion now at issue in 2016, during the Obama administration, arguing that ICE (Immigration and Customs Enforcement) and CBP (Customs and Border Protection) were violating the Flores Agreement by, among other things, confining minors in facilities that are not “safe and sanitary.”

United States District Judge Dolly Gee, who considered hundreds of declarations from minors and their parents, ultimately ruled that CBP was violating the Flores Agreement. In 2017, during the Trump administration, she found that CBP failed to provide adequate food and water to minors, that it did not maintain the facilities at adequate temperatures, and that it deprived the minors of sleep by confining them on concrete floors under bright lights. Gee also found that CBP’s obligation to provide “safe and sanitary” conditions included providing soap, dry towels, showers, toothbrushes, and dry clothes. Gee ultimately ordered CBP to appoint a monitor to bring its facilities into compliance with the Flores Agreement.

Gee’s order put the government in a technical legal bind. When a federal judge appoints an official to monitor compliance with an already existing injunction or agreement like the Flores Agreement, the government cannot immediately appeal. Such a measure is considered an “interlocutory” order—an intermediate one that does not generate a final decision suitable for appellate review. The government can only appeal if the judge modifies the prior injunction or order.

So that’s what the United States argued. In its appeal to the Ninth Circuit, the United States—through Fabian and the other attorneys of the Office of Immigration Litigation—claimed that Gee had altered the deal. They argued that by ruling that “safe and sanitary conditions” specifically required things like dry clothes and toothbrushes and showers and not sleeping on concrete under bright lights, Gee changed the Flores Agreement and “substantially altered the legal relations of the parties by reading new requirements into the Agreement.” That was the premise of their assertion that they could appeal, after all.

It was this sequence of events that brought Fabian before three judges of the United States Court of Appeals for the Ninth Circuit last week to make her startling argument. The panel—which included Judge A. Wallace Tashima, who as a child in World War II was confined to an internment camp with other Japanese Americans—was perhaps not an ideal forum. The judges were openly hostile, incredulous that the government would argue that a facility is “safe and sanitary” even if the minors confined there have no soap, toothbrushes, or dark places to sleep. “I find that inconceivable that the government would say that that is safe and sanitary,” said Judge William Fletcher, in a representative comment. The judges ultimately suggested that the United States should consider whether it wanted to maintain the appeal—a signal that litigants ignore at their grave peril.

The United States’s loathsome argument—that it is “safe and sanitary” to confine children without soap, toothbrushes, dry clothes, and on concrete under bright lights—is morally indefensible. It’s also a spectacularly foolish argument to raise in the famously liberal Ninth Circuit, where the United States should have expected exactly the reception that it got. And even though the litigation began under the Obama administration, it was the Trump administration that elected to bring this appeal and ask the court to bless these inhumane conditions as “safe and sanitary.” That’s an extremely aggressive legal argument, and one that suggests that the disturbing conditions being reported at confinement centers are intentional, not a sign of mere neglect.

It is right and fit to condemn the Trump administration for its argument and its treatment of children. But it’s wrong to think the problem can be cured with a presidential election. Trump will depart; the problem will not depart with him. This administration is merely the latest one to subject immigrant children to abusive conditions. It’s been 35 years since Jenny Flores was strip-searched in an adult facility. Before Sarah Fabian defended concrete floors and bright lights for President Donald Trump, she defended putting kids in solitary confinement for President Barack Obama.

The fault lies not with any one administration or politician, but with the culture: the ICE and CBP culture that encourages the abuse, the culture of the legal apologists who defend it, and our culture—a largely indifferent America that hasn’t done a damn thing about it. This stain on America’s soul will not wash out with an election cycle. It will only change when Americans demand that the government treat the least of us as both the law and our values require—and firmly maintain that demand no matter how we feel about the party in power.



With a new video, the Islamic State’s long-elusive leader, Abu Bakr al-Baghdadi, has reemerged. His message was simple: ISIS’s self-declared caliphate in Iraq and Syria has fallen, but the global community forged by ISIS lives on. That makes his video something of a rebuttal to President Donald Trump’s December claim that ISIS was “defeated.”

The first question to ask about the video is: Why release it? Baghdadi has been, for almost five years, a ghost, not seen publicly since July 2014, when ISIS released a video that showed him speaking at the al-Nuri Mosque in Mosul, Iraq. For the world’s most wanted man, any link to the outside world is a vulnerability, a possible vector for intelligence agencies and militaries to find and eliminate him. Breaking a half decade of silence carries the risk of death. Baghdadi, however, evidently concluded that being seen and heard from right now outweighed that risk. And that’s surely because ISIS faces dangers as an organization that are more significant than the ones Baghdadi does as an individual.

What ISIS did that was new and different was declare a caliphate and actually establish one on real, physical territory. That was the heart of how Baghdadi distinguished ISIS from its predecessor organization, al-Qaeda; and that was the core of ISIS’s call to arms, which ultimately yielded thousands of foreign fighters and scores of deadly attacks worldwide. ISIS also created something other terrorist groups had only dreamed of cultivating: a sense of virtual community to which those who otherwise felt adrift and detached from their real communities were drawn. That’s part of why those who attacked their own communities in ISIS’s name shouldn’t be dubbed “lone wolves.” ISIS’s astonishing achievement was in making these vulnerable souls feel not alone, and instead like part of something bigger than themselves, no matter how far away.

Now the territorial manifestation of ISIS’s self-declared caliphate—the animating force behind that entire global community—is gone, thanks to years of work by a wide-ranging coalition and incredible sacrifices by military, diplomatic, intelligence-community, law-enforcement, and other professionals from across that coalition. Yet the global community ISIS forged is very much still in place. Indeed, ISIS has networks across the globe, and draws on those networks and the group’s prodigious output online to make a case to its followers that the fight is far from over—instead, it’s just entered a new phase.

That’s where Baghdadi’s reemergence fits in. The case for a post-caliphate ISIS is not an easy one for ISIS to make, given how heavily the group has emphasized its territorial control. So Baghdadi concluded that he’d surface and risk everything to present the argument himself. He eulogized those lost in the fight for Iraqi and Syrian territory. Then he pivoted to exulting in recent ISIS-linked attacks elsewhere, such as in Sri Lanka. Through it all, his message was: We’re still here, and we’re still fighting—and killing.

The last time we saw Baghdadi on video, he was essentially celebrating ISIS’s birth. This week, he was touting its rebirth, or at least trying to sell it.

What does the video mean for counterterrorism policy? First, it’s a reminder that the eradication of territorial control in Iraq and Syria doesn’t amount to the defeat of ISIS. Degrading the group’s networks globally will require a continued careful calibration of direct military force, intelligence sharing, arrests and prosecutions, training and equipping of partners, and other counterterrorism tools such as efforts to thwart the radicalization process.

Second, Baghdadi’s reaffirmation of ISIS as a global community means that the internet will remain a central battle space for the group. This fact requires, in turn, continued and indeed accelerated efforts by tech companies to remove and—better still—prevent terrorist content from being uploaded and shared. Governments should also do more to share with those companies what they know about the latest terrorist online tactics, trends, and trajectories, so as to empower the companies to police their own platforms more aggressively and more effectively.

Third, Baghdadi’s reemergence means that Americans and others must understand what’s ahead in ISIS’s evolution. Trump’s premature declaration of ISIS’s defeat invites precisely the wrong expectations—that there will be no more ISIS-linked attacks—and, in turn, precisely the wrong reactions to those attacks when they do occur: not reactions but overreactions, untethered to the actual needs of figuring out what went wrong and how to prevent more bloodshed. In the face of terrorism—whether jihadist, white supremacist, or some other brand—what’s needed from the public is resilience, and what’s needed from government leaders is reassurance.

Baghdadi’s video was meant to sustain the sense that there’s still something for ISIS’s global community to belong to. It should also serve as an unintended reminder that there’s a far stronger global community that has, for years, rejected ISIS’s toxic call to violence and collaborated to address the threat posed by the group.



So far, the conversation about the upcoming Boston Red Sox visit to Donald Trump’s White House has centered around the people of color who are skipping the event. The manager Alex Cora, a critic of the Trump administration’s inexcusable treatment of Puerto Rico amid the devastation of Hurricane Maria in 2017, cited his home island’s continuing troubles as his reason for opting out.

“Unfortunately, we are still struggling, still fighting,” Cora said in a statement. “Some people still lack basic necessities, others remain without electricity and many homes and schools are in pretty bad shape almost a year and a half after Hurricane Maria struck. I’ve used my voice on many occasions so that Puerto Ricans are not forgotten, and my absence is no different. As such, at this moment, I don’t feel comfortable celebrating in the White House.”

The majority of the Hispanic and African American players on the Red Sox—including the pitcher David Price and the 2018 American League MVP, Mookie Betts—have also declined to attend. Not all have explained their reasons, but the Mexican-born relief pitcher Hector Velázquez has been honest. “I made the choice not to go because, as we know, the president has said a lot of stuff about Mexico,” he told MassLive. “And I have a lot of people in Mexico that are fans of me, that follow me. And I’m from there. So I would rather not offend anyone over there.”

Black and Hispanic players and coaches are expected to justify their reasons for not going to Trump’s White House. But the real question is: Why have so many of the white players on the Red Sox chosen not to support their black and brown teammates?

As my colleague Yoni Appelbaum wrote in June, the history of sports teams visiting the White House began in 1865, when Union soldiers played baseball on the White House grounds to pay homage to a game they loved and to send a unifying message to a country torn apart by the Civil War.

But President Andrew Johnson wasn’t really on board with a message of togetherness. Around that time, The Cincinnati Enquirer quoted Johnson as telling the governor of Missouri, “This is a country for white men, and by God, so long as I am president, it shall be a government for white men.”

That divisive proclamation 154 years ago turned out to be a self-fulfilling prophecy. Johnson wanted a government where certain people felt excluded. Under Trump, Johnson’s wish came true.

Trump hasn’t made his views as overt as Johnson did, but the current president’s actions, policies, and treatment of marginalized citizens reveal a lot about his underlying attitudes. As such, Trump turned the tradition of championship teams visiting the White House into an uncomfortable experience for athletes of color—who are often asked to cast aside their identity for the comfort of their white teammates, owners, coaches, and fans.

Plenty of commentators have argued that these White House visits should be apolitical and devoid of drama. But under Trump’s administration, that simply isn’t possible.

Recently, Trump hosted the NCAA champion Baylor women’s-basketball team at the White House, making the Bears the first women’s championship team Trump has held a private ceremony for since he became president. That the Baylor coach, Kim Mulkey, had publicly campaigned for an invitation to the White House helped bring about the visit. Trump has shown that he can be petulant about extending invites to championship teams if his overture won’t be warmly received. After the Golden State Warriors won the NBA championship in 2017, Trump rescinded his invitation to them on Twitter because several players had been critical of the president, and many of them made it known that they had no interest in attending a White House reception.

When photos of Baylor’s visit circulated on social media, the internet had its fun making note of how some of the players didn’t look thrilled to be there. As of now, no one outside the team knows if Mulkey ever considered how some of her players might feel about being in the presence of someone who has insulted not just people of color, but also women—and women athletes in particular.

When South Carolina won the NCAA women’s-basketball championship in 2017, the Gamecocks didn’t receive an invitation to visit Trump for months. The lateness “speaks volumes,” the coach Dawn Staley says. When the invite finally came, the team declined. Did Trump’s snub register with Mulkey, the Baylor coach? Did Mulkey consider the things that Stephen Moore, Trump’s now-withdrawn pick for the Federal Reserve Board, wrote mocking women’s participation in sports?

Through Baylor’s sports-information department, Mulkey declined to comment about the team’s trip to the White House. However, she told the Associated Press last month that going to the White House is “not a political issue for me.”

But what if it’s a personal issue for her players? If Mulkey didn’t at least have an honest dialogue with her team about the trip to the White House, then she is guilty of exhibiting privilege and an alarming lack of awareness.

Not every red-state coach expects players to grimace their way through an appearance with Trump. To his credit, the Clemson football coach, Dabo Swinney, reportedly never pressured any players on his team to visit the White House in January after the Tigers beat Alabama for their second national title in the past three years. Forty-five members of the team chose not to go.

Plenty of athletes opted not to go to the White House when Barack Obama was president, but that felt different. Those choices appeared to be rooted in athletes’ convictions about certain topics—rather than in any deeper judgments about the character of the sitting president. In 2012, the Boston Bruins goaltender Tim Thomas backed out of the White House reception because, as he argued in a statement at the time, the “federal government has grown out of control, threatening the rights, liberties, and property of the people.” In 2013, the Baltimore Ravens offensive lineman Matt Birk, a devout Catholic, chose not to go to the White House because of a speech Obama had made at Planned Parenthood.

Context matters. And the truth is that Trump’s hateful rhetoric and policies aren’t so easily forgotten. Forcing people—including championship athletes—to disregard how hurtful his actions can be is disrespectful to those he has hurt.

Alex Cora can’t laugh and shake hands with the president knowing that 3,000 people in Puerto Rico—a U.S. territory—perished as a result of Hurricane Maria. And it’s not just that the government’s response to the devastation was inadequate. Trump also lied about the island’s death toll, and in a tweet the president called Puerto Rico’s leaders “grossly incompetent” and said they only want to “take from USA,” which implied that Puerto Rico wasn’t part of his country. In the same vein, a senior administration official told The Washington Post that Trump “doesn’t want another single dollar going to the island.” That’s not policy, that’s pettiness—and it shows contempt and condescension toward the people of Puerto Rico.

Trump’s bigoted and obtuse rhetoric about immigrants, “Mexican countries,” and their citizens is also well known, so expecting Hector Velázquez to smile politely in a team photo with Trump in the Oval Office is an indignity he shouldn’t have to suffer.

In team sports, the concept of putting team before self is preached ad nauseam. Solidarity is supposed to be paramount, but clearly in this situation that solidarity doesn’t run both ways. If you’re one of the athletes of color on a team, how can you not wonder how your white teammates feel about people like you? That thought appeared to cross David Price’s mind Monday.

I just feel like more than 38k should see this tweet... https://t.co/BtbK0DNPQc

Later, when pressed on the matter by The Boston Globe, Price said he was only amplifying “an insensitive tweet that needs to be seen by more people.” But, in fact, that “insensitive” message only pointed out an obvious pattern.

So instead of focusing on why Cora and other Red Sox figures won’t be at the White House, ask their teammates why they’re comfortable being with a president who marginalizes and harms the communities to which their fellow players belong.



Joshua Wheeler became famous as the first American soldier to die in the fight against the Islamic State—ISIS. But there’s more to his story than most people know.

Wheeler grew up in a poor, troubled family in rural eastern Oklahoma, the oldest of five kids. After high school, he faced the same choice as most of his fellow graduates: He could look for work in the oil business, or he could join the military. Josh chose the Army. In 1997, two years after he’d enlisted, he joined the elite Rangers and later was assigned to Army Special Operations Command, based at Fort Bragg, North Carolina.

In October 2015, Master Sergeant Joshua Wheeler was stationed in Iraq. At that point, U.S. forces were no longer doing all the fighting in that troubled part of the world. Instead, they were engaged in training and support of local forces battling against the militants of ISIS. One day, the Kurdish commandos Wheeler was working with received a tip: A nearby compound controlled by ISIS contained some 70 local hostages, held prisoner for cooperating with Iraqi government officials. Now it appeared that the execution of those hostages was imminent—in fact, aerial photos showed a newly dug mass grave near the compound, waiting for their bodies.

On October 22, the Kurdish commandos swung into action, supported by their U.S. special-operations partners. They launched a helicopter raid on the compound, determined to rescue the hostages. Wheeler and a team of 10 to 20 U.S. fighters went along to provide intelligence and communications support. But the raid went wrong. An effort by the commandos to blast a hole in the compound’s outer wall failed. Gunfire immediately broke out. It was obvious that the commandos were in trouble.

Wheeler and his men did what American fighters do—they ran toward the sound of the guns. When the battle ended, the hostages had been freed. A few of the Iraqi commandos were injured. Only one rescuer died in the operation—Joshua Wheeler.

Days later, my wife, Stephanie, and I met with Wheeler’s wife, Ashley, at Dover Air Force Base. We welcomed her husband’s remains after they came down the cargo ramp of a C-17, and the three of us spoke together briefly. Ashley was an extraordinary person, filled with love and admiration for her husband. It was a marriage that had made her life whole, she said.

As usual, Stephanie and I then prepared to depart the base, giving Ashley some time and space to handle the difficult moment in her own way. But before we could leave, an officer sought me out. “Mrs. Wheeler would like another moment with you, sir,” he said.

I returned, and found Ashley as composed and dignified as ever. There was no bitterness in her voice. But she did have one question to ask the secretary of defense who had signed her husband’s orders—the same question many in the press were also asking: “Did he die in combat?”

I was saddened—and angered—that she even had to ask that question. But I understood all too well why she was asking.

The strategy we were pursuing in Iraq and Syria to destroy ISIS was to enable and support local forces rather than substitute for them. The strategy was the right one. But the administration’s plan to enable local forces had led to a game of “gotcha” with some reporters. Several tried to trip up administration spokespeople into making misstatements about exactly what our forces were doing in the Middle East.

I was put off by the very idea of playing such verbal games. “Of course Josh died in combat,” I told Ashley Wheeler. And when I spoke to the press about the incident on October 28, I repeated those words: “Of course he died in combat.”

War has to be spoken about bluntly, especially when leaders are talking with the troops or their families. Accordingly, I used honest language—words like war and combat—whenever it was appropriate, and ignored the “suggested edits” from the White House staff substituting other, less forthright words.

I followed the same principle when addressing the troops. Thus, shortly after we completed the coalition military-campaign plan of 2015 against ISIS (the same plan that two U.S presidents stuck with), I traveled to Fort Campbell, Kentucky. That’s where the 101st Airborne was preparing to deploy to Baghdad—the first unit to begin putting the new plan into action. I wanted to give them a clear notion of what their mission was. To accomplish that, I made sure to do two things.

First, I told the troops how proud I was of them, how proud their country was of them, and how proud they should be of themselves. I said they were doing “the noblest thing you can do with your life—protecting America and making a better world for our children.” I told them they were part of “the finest fighting force the world has ever known,” a phrase I used in practically every speech I made, mainly because I believed it to my bones.

Second, I told the troops precisely what we were asking them to do—what the strategy was and why it was the right one. I told them how it would fit into history. I explained how we needed to destroy the fact of an Islamic State based on its evil ideology in order to destroy the idea itself. And I would explain that they were working hand in hand with local forces rather than on their own—which would be frustrating at times—because we wanted our victory to be planted firmly in local conditions and culture, and therefore lasting.

Strategy and history are big ideas to these young people, many not yet out of their teens. But if my words were clear and direct, they could remember the words, they could repeat them to their mom or dad, and hopefully they could recall them proudly for years to come. In a democracy, every man and woman who dons a uniform in the service of the country should share that personal understanding of and commitment to the cause for which they fight. That’s a basic reason it is an important part of the SecDef’s job in command to talk plainly and comprehensively about war, especially to those waging it.

Sometimes talking honestly about war means recognizing the consequences of the decisions we must make at the Pentagon, as I had to do when meeting the families of the fallen at Dover Air Force.

It was usually only 24 or 48 hours since the family members were notified. They were dazed with fatigue and grief. Entire extended families would often be gathered in the spacious room furnished with sofas and armchairs—sometimes 10 or more people altogether.

My wife and I would have a short, private word with each person there, but we would focus first on the spouse, parents, and children. I told them that I understood I could not truly know what they felt, and that I could not give them what they wanted most, which was their loved one back. I had read carefully about each service member in advance, and I briefly stated the importance of the mission they had been conducting and the reason for it. I wanted them to hear these things in my own words. I told them it wouldn’t mean much to them to hear these words on this day, but perhaps sometime in the years to come it would.

Every family took it their own way. Occasionally a flash of anger would erupt, a mother or father glowering and exploding in words like, “When is this shit going to end?”

Dover, of course, is where the sense of loss is at its most raw. No less profound is the sense of grief one experiences on a visit to a cemetery where the fallen have been laid to rest. But there the feeling of grief is almost exceeded by the deep sense of respect and gratitude for the sacrifice made by the dead and by those who loved them.

Arlington Cemetery, right down the road from the Pentagon, has a section devoted to the fallen from the post-9/11 wars. Stephanie and I made a point of stopping there before I came into the Pentagon to begin my first day as secretary of defense. As the snow fell, we walked among the headstones, reading names, noting dates, and stopping to put a hand on specific stones with special meaning to us.

Many long days later, on my last day as SecDef, I made the same journey, visiting the same gravesites and many more. It seemed a fitting way to end my work as the steward of America’s fighting forces.

I think a lot about those twin journeys, and about the men and women—known to me and unknown—whose remains are honored at Arlington. In a very real sense, their story sums up for me the central mission of any secretary of defense. He or she must never forget the fact that the lives of millions of people—military and civilian, at home and abroad—are affected by every decision made in the halls of the Pentagon.



President Donald Trump has defied a congressional subpoena and refused to deliver his tax returns as the law requires. The headlines say that the decision is Secretary of the Treasury Steven Mnuchin’s, but that, of course, is a fiction. Mnuchin’s statement insists that he acted on the advice of the Department of Justice. But the law and the precedents are clear: Congressional subpoenas must be complied with, and neither the president nor the courts have any authority to judge which subpoenas “serve a legitimate legislative purpose” and which do not. Congress is its own judge in these matters, as the Supreme Court affirmed in 1975 in the classic case on the topic.

Most analysts explain Trump’s actions as a play for time. He may ultimately lose—but if that ultimately can be postponed past November 2020, a late loss may serve as the next best thing to a win.

But here’s a reason to wonder whether the calendar serves Trump quite as well as most analysts assume. What is Trump hiding in those returns? Your guess is as good as anyone’s. The secret could be mild: He’s not as wealthy as he likes to boast. The secret could be embarrassing, but not illegal: He personally hugely benefited from special favors in the recent tax cut. The secret could raise national-security concerns. Or the secret could even point to a lifelong career of financial fraud.

The longer the fight over the returns continues—especially if Trump loses in the lower courts but appeals and appeals again—the more likely it is that Americans will assume the worst.

Trump already suffers from a wide and deep public-opinion disbelief in his integrity. In September, Gallup asked respondents to rate Trump’s ethics compared with those of other presidents. Sixty-eight percent regarded him as less ethical than Ronald Reagan; 58 percent as less ethical than Barack Obama; and 52 percent as less ethical than Bill Clinton.

Trump even suffers in comparison to Richard Nixon: 43 percent rate Trump as less ethical than Nixon, while only 37 percent rate him higher.

Quinnipiac University produced even more troubling results in March. Sixty-five percent told pollsters that they regard Trump as dishonest, the worst honesty number yet recorded by any survey. Sixty-four percent of Americans believe that Trump committed crimes before becoming president.

It’s often assumed that Trump has a solid 40 percent base. But that’s not true on ethics matters. Ethics surveys reveal a split between strong supporters and softer supporters.

When the Pew Research Center asked in January whether Trump was separating his business interests from his official duties, only 28 percent expressed strong confidence that he was doing so. Another 13 percent described themselves as “somewhat” confident. While 66 percent of conservative Republicans expressed strong confidence in Trump’s integrity, only 39 percent of self-described moderate Republicans did so.

It’s unrealistic to imagine a split within the GOP over these issues, but it’s easy to imagine a continued melting away of Trump’s support on questions of ethics. Nearly two-thirds of Americans now agree that Trump should release his tax returns, again according to Pew.

Polls will not bend Trump on an issue as seemingly existential to him as keeping his tax returns concealed. But the issue of the tax returns may bend Trump’s polls.

Over the next weeks, Trump will be fighting multiple financial-disclosure fights. He has intervened to stop Deutsche Bank from complying with a congressional subpoena of his bank records. He threatens to fight to prevent Special Counsel Robert Mueller from testifying about Trump’s Russia connections. He’s already lost the first round of the emoluments-clause lawsuit filed by the state of Maryland and the District of Columbia.

As Trump fights to conceal his financial records, loses, appeals, and loses again, it becomes progressively more plausible to Republicans that those records conceal damaging revelations about serious wrongdoing. Trump is ultimately fighting to prove he’s not a crook. He can postpone delivering the records that would prove the matter one way or another. But as he fights to postpone the inevitable, he risks convincing voters that they do not need a subpoena to read his guilt.



Donald Trump is finding religion. Or at least, religion is finding its way into his remarks and his campaign’s rhetoric to an unprecedented extent.

On Thursday, the president celebrated the National Day of Prayer at the White House, and he said the Almighty had helped him persevere through the ordeal of Special Counsel Robert Mueller’s investigation.

“People say, ‘How do you get through that whole stuff? How do you get through those witch hunts and everything else?’” Trump said, turning to Vice President Pence. “And you know what we do, Mike? We just do it, right? And we think about God.”

In a variation on his claims about a “war on Christmas,” Trump also claimed that Americans are referring to the Divine more frequently.

“One of the things that Mike and I were discussing just a little while ago—people are so proud to be using that beautiful word, God, and they’re using the word God again, and they’re not hiding from it,” he said. “They’re not being told to take it down, and they’re not saying we can’t honor God. In God we trust. So important.”

The Day of Prayer is an annual venue to talk about faith, but it’s not the only time religion has come up lately. Trump’s 2020 campaign manager, Brad Parscale, tweeted this after a rally in Green Bay, Wisconsin, on Saturday:

Loved watching the crowd fill up for the 547th Rally in Green Bay. There has never been and probably never will be a movement like this again. Only God could deliver such a savior to our nation and only God could allow me to help. God bless America! pic.twitter.com/PBata3mB14

That’s the sort of invocation of God that tends to send liberals into fainting fits, but which strikes many evangelicals as a fairly unremarkable expression of faith.

Finally, Trump has been speaking repeatedly (and dishonestly) about late-term abortion during campaign appearances.

By this point it’s banal to note the mismatch between Trump—the coarse, libertine sexual harasser—and the American evangelical movement. It’s a marriage of convenience: Trump gets support he needs, and evangelicals get a champion of their causes, even if that champion is not especially Christlike in his bearing.

But Trump’s statement that he leaned on God during the Mueller probe is notable because it’s practically unheard of for Trump to speak of God in a personal way like that. (Compare that with his remarks at least year’s event, which feature nothing similar.)

Whether Trump’s God talk is sincere is not for me to say, though it’s hard to imagine it is. Trump has demonstrated his lack of interest in personal devotion many times: He appears never to have regularly attended a church in his adult life—the Presbyterian congregation he named as his home church during the 2016 campaign said he was not an active member—and he has rarely attended services, other than on Christmas and Easter, since becoming president. He infamously referred to “2 Corinthians” at Liberty University in January 2016. He said he’s never sought forgiveness from God. If Trump had experienced some sort of religious epiphany since then, it’s doubtful he would have kept it quiet, given the political advantage he’d reap and given how poorly he keeps anything quiet.

But for political purposes, Trump’s sincerity is beside the point. It’s enough that he is speaking about religion so much. One way God appears to be helping Trump through the ordeal of the Mueller investigation is that, by invoking the Almighty’s name with greater frequency, Trump is managing to retain the support of many voters who might otherwise be disturbed by the special counsel’s findings.

Ironically, even as Trump talks about God more—and claims that more Americans are proudly using God’s name—the general trend is the reverse. The number of Americans who say they have no religious affiliation continues to rise. Ramping up religious appeals, however, meshes with Trump’s demonstrated political strategy of appealing to a base that represents a minority of the electorate and hoping that it can push him across the finish line, just as it did in 2016.

The same week as this flurry of religious talk, Trump and Pence also appeared at the NRA’s annual convention. Guns, religion—it evokes a notorious gaffe by Barack Obama during the 2008 campaign. Referring to “small towns in Pennsylvania” during a fundraiser in San Francisco, Obama said:

They fell through the Clinton administration, and the Bush administration, and each successive administration has said that somehow these communities are gonna regenerate and they have not. And it’s not surprising then they get bitter, they cling to guns or religion or antipathy to people who aren’t like them or anti-immigrant sentiment or anti-trade sentiment as a way to explain their frustrations.

This was a classic Kinsley gaffe—when a politician accidentally tells the truth. Obama’s comments were damaging to his own prospects with these voters, but from today’s vantage point, they uncannily predict the Trump campaign, which was focused on immigration, xenophobia and anti-Muslim sentiment, religion, protectionism, and the Second Amendment.

Perhaps it’s no coincidence that Trump is talking about God and speaking to the NRA just as his allies signal nervousness about his prospects of winning the state of Pennsylvania again in 2020—in other words, the same electorate to which Obama referred in 2008. Voters can cling to guns and religion, but politicians can, too.



Updated at 1:25 p.m. ET on May 2, 2019.

Thursday morning, despite an increasing chorus of skeptics among Senate Republicans, Stephen Moore insisted that he was still on the verge of being formally nominated to the Federal Reserve’s Board of Governors.

“I’m all in,” he told Bloomberg reporters.

The White House, however, was not. Within a couple of hours, President Donald Trump had pulled the plug. “Steve Moore, a great pro-growth economist and a truly fine person, has decided to withdraw from the Fed process,” he tweeted. “I’ve asked Steve to work with me toward future economic growth in our Country.”

Moore follows Herman Cain, whom Trump said he would nominate to the Fed but who withdrew after extensive criticism, especially over past accusations of sexual harassment. In Moore’s case, the crucial flaws were a long record of economic illiteracy and offensive remarks, especially about women.

Moore’s abortive nomination was at once inexplicable and utterly predictable. How did a candidate with few qualifications and a damaging paper trail get nominated for an important position in the Trump administration? Presumably the same way all the other previous candidates with few qualifications or a damaging paper trail did: They were on TV a lot, they had nice things to say about the president, and that was good enough for him. More than two years into his presidency, and despite a long record of failed or aborted nominations, Trump remains remarkably uninterested in vetting the people he wants to put in top posts.

If you’ve paid attention to conservative media over the past couple of decades, Moore has been a familiar figure, as a persistent if not especially heavyweight proponent of supply-side economics. Moore advised Cain on his infamous “9-9-9” tax plan during his 2012 presidential run, then advised Trump in 2016. He consulted on Trump’s 2017 tax cuts and co-wrote a book called Trumponomics.

Moore was a peculiar pick for the Fed in part because his expertise, such as it is, is fiscal policy. Moore is ignorant of monetary policy, which is what the Fed oversees. That’s not my assessment—it’s Moore’s. When Trump announced his plan to nominate Moore, the would-be governor told Bloomberg that he didn’t know what the central bank or its board did.

“I’m kind of new to this game, frankly, so I’m going to be on a steep learning curve myself about how the Fed operates, how the Federal Reserve makes its decisions,” he said. “It’s hard for me to say even what my role will be there, assuming I get confirmed.”

His record backs this up. As the Washington Post columnist Catherine Rampell has noted, Moore claimed that there was deflation when there wasn’t, and insisted that the nation was on the verge of hyperinflation when in fact there was deflation. Moore has supported the gold standard (though he insists that he hasn’t, despite video evidence). Matt O’Brien rounds up other problems with Moore’s economic positions. Moore also called on Trump to fire Fed Chair Jerome Powell, which would have, at the very least, made for some awkward small talk at Moore’s first meeting.

Somewhat perversely, Moore’s views and comments on other topics are what finished his chances. His economic views are more relevant to the job he would have actually held, but whereas most people don’t have a sophisticated understanding of interest rates, most people either are or know a woman—and Moore has some peculiar views about women, both related and unrelated to the economy.

CNN’s KFile has been at the forefront of uncovering Moore’s past comments. Basketball has been a frequent trigger for these views. Referring to his wife in a 2001 column, Moore wrote, “When Allison and I got married the hoops ground rules were already well established: She’s not allowed to talk to me during the NCAA tournament.”

The next year, he recycled the idea: “Ah, March, the greatest month of the year. This is the season where I return to bachelorhood, lock myself into the TV room and tell my wife that I’ll see her sometime in April. Oh, and by the way, keep those three crying kids out of my hair for the next three weeks.”

Moore complained about women refereeing games, with a reference to the notoriously violent and abusive Indiana University coach Bob Knight:

How outrageous is this? This year they allowed a woman ref a men’s NCAA game. Liberals celebrate this breakthrough as a triumph for gender equity. The NCAA has been touting this as example of how progressive they are. I see it as an obscenity. Is there no area in life where men can take vacation from women? What’s next? Women invited to bachelor parties? Women in combat? (Oh yeah, they’ve done that already.) Why can’t women ref the women’s games and men the men’s games.
I can’t wait to see the first lady ref have a run in with Bobby Knight.

He did offer one exception to his suggestion of banning women from sports, citing a prominent broadcaster:

Women are permitted to participate, if and only if, they look like Bonnie Bernstein. The fact that Bonnie knows nothing about basketball is entirely irrelevant … Bonnie Bernstein should wear a halter top.

In an email to CNN, Moore explained these columns by saying, “This was a spoof. I have a sense of humor.” To his credit, he didn’t say it was a good sense of humor.

In another column, Moore wrote in the third person about “Steve” buying a cherry-red Camaro convertible, despite his “22-year-old college intern” telling him that the car “screams midlife crisis.” Moore then told a very real anecdote that absolutely happened:

On more than one occasion Steve has been cruising around town with the top down and a gorgeous 20-something blond has pulled up beside him: he looks longingly at her, she gives him a “come hither look,” and then the mood is spoiled when she sees David drooling in the baby seat and then Justin and Will start making weird faces at her. She sticks her finger in her mouth and zooms off and Steve is left screaming at the kids: “How many times do I have to tell you tyrants to stay out of sight when I’m hitting on girls?” And then Will, with a puzzled look on his face says, “But daddy, we already have a mommy.” And then Steve says, “Yes, but imagine, just for a moment, how nice it would be if you had a much younger mommy.”

In the same column, he wrote, “Will someone out there please help us get Allison a job? It’s not so much that we need her income, but that when she sits at home idly day after day she becomes a compulsive shopper.”

Moore’s wife filed for divorce in 2010, claiming that he had committed adultery and subjected her to “emotional and psychological abuse.” She later sued him to collect on tens of thousands of dollars in alimony and child support that he owed her.

Appearing on ABC’s This Week on Sunday, Moore apologized for some of his past remarks. “But I do think we should get back to the issue of whether I’m qualified to be on the Federal Reserve Board, whether I have the, you know, economic expertise,” he said. “I’ll debate anybody on economics … Let’s make this about the economy.”

But many of Moore’s views about women have directly connected to economics. Complaining about his then-wife’s votes for Democrats in the 2000 election, he griped, “Women are sooo malleable! No wonder there’s a gender gap.”

For Moore, however, the gender gap in pay is a feature, not a bug. In 2000, he said on C-SPAN, “It’s not a good thing that black women are making more than black men today. In fact, you know, the male needs to be the breadwinner of the family.” In 2014, he waxed concerned about rising women’s wages. “What are the implications of a society in which women earn more than men?” Moore wrote. “We don’t really know, but it could be disruptive to family stability. If men aren’t the breadwinners, will women regard them as economically expendable?”

He reiterated the point on Tuesday. “Look, I want everybody’s wages to rise, of course. But, you know, people are talking about women’s earnings—they’ve risen,” he said on CNBC. “The problem, actually, has been the steady decline in male earnings, and I think we should pay attention to that, because I think that has very negative consequences for the economy and for society.”

While Moore feared women’s wages rising too high, he was eager to put a different segment of the population to work: children. “I’m a radical on this,” he said in 2000. “I’d get rid of a lot of these child-labor laws. I want people starting to work at 11, 12.”

In addition to his complaints about black women’s wages rising too high, Moore has made other dubious comments on race. In 2017, on CNN, he delivered a twin bill of bad Civil War history, claiming that “Robert E. Lee hated slavery” (untrue) and that “the Civil War was about the South having its own rights” (true only insofar as the right that Confederate states were concerned about was the right to own slaves).

After Trump’s victory in November 2016, Moore joked (apparently quoting a cartoon) that the president-elect’s first act would be to kick a black family (i.e., the Obamas) out of public housing. His attempt to explain that joke to Margaret Hoover is recommended only to those with a high tolerance for cringing.

Faced with the avalanche of embarrassing past quotes, Moore compared the media coverage to efforts to sink the nomination of Supreme Court Justice Brett Kavanaugh.

“They’re pulling a Kavanaugh against me,” he said.

The claim is absurd. Kavanaugh was accused of sexual assault by several women and denied it. But neither Moore nor anyone else disputes that he wrote and said the things that he’s being criticized for writing and saying. The idea that reading the things Moore published represents a conspiracy may say a lot about the publications for which Moore wrote, but it doesn’t make for a very effective defense.

Indeed, while Senate Republicans rallied to Kavanaugh’s defense, they were chilly on Moore. Senator Joni Ernst of Iowa said it was “very unlikely that I would support that person,” adding, “Look at his writings! I’m not enthused. I’m a woman.”

Senate Majority Whip John Thune of South Dakota offered an ominous forecast to The Washington Post on Wednesday. “I think there will be probably some more information about that nomination in the next day or so,” Thune said. “I think he’s gotten enough feedback from the people up here that his nomination is in trouble.”

Thune, it turned out, had a better sense of what was coming than Moore did. In general, GOP senators have been most successful at killing controversial nominations they don’t like by stifling them early in the process. Once Trump actually makes a nomination, senators are loath to vote against an appointee.

The White House said Monday that it was reviewing Moore’s writings. Conducting such a review before the president announced plans to nominate Moore would have been wise. But the Trump administration has repeatedly declined to vet candidates ahead of time.

Yet despite the back-to-back failures of Cain and Moore, it seems likely that the pattern will repeat again. Trump announced his intent to nominate both men but then went weeks without a formal nomination, which suggests that the president is getting out ahead of the official process. Trump will continue to see people on TV whose feisty demeanor and staunch defenses of his leadership he likes, and he’ll keep nominating them for jobs—no matter how unqualified they are, or how much of a liability their past statements make them. It’s certainly easier and more fun than plodding through years of Stephen Moore’s “humor” columns.





Subscribe to Crazy/Genius: Apple Podcasts | Spotify | Stitcher | Google Play

If you have a hard time understanding the meaning of privacy and the scale of digital surveillance in the modern age—and let’s face it, who doesn’t?—consider a toy named Cayla.

Cayla is a doll with long hair, a tiny denim jacket, and little pink shoes. She also comes with a microphone, a Bluetooth app, and built-in voice-recognition technology. My Friend Cayla, as the product is called, can introduce herself and suggest fun activities. The label on her box reads “She has millions of things to say!” And she does. But who is she talking to?

Could it be the CIA? Several years ago, consumer groups discovered that when somebody asks Cayla a question, the dialogue is stored on a server owned by Nuance Communications. That firm sold “voice biometric data” to the military and intelligence agencies. After discovering the privacy concerns surrounding My Friend Cayla in 2017, the German government banned the doll. (It is still available for purchase in the United States.)

This story isn’t unique, says Shoshana Zuboff, the author of The Age of Surveillance Capitalism. It is just another example of how invisible “supply chains” create marketplaces out of behavioral data. A chunk of dialogue from a child’s playtime travels to a server. The data are shared with a third party, which can sell them to yet another organization. Neither the child nor the parents will ever fully know where the data are going, or for what purposes.

Does that mean little girls and boys are doing implicit labor for national intelligence agencies? Zuboff rejected that framing. “There is an important distinction to be made between labor and raw material,” she says. These children are not working. They are merely living, and their lives are being strip-mined for data, as an elephant might be harvested for its ivory.

“What are we in this equation?” Zuboff asks. “We are not the ivory. We are not what is poached. We are the carcass that is left behind.”

How the hell did we create this world? And what, if anything, can we do to get out of it? That’s the central question in the latest episode of Crazy/Genius, The Atlantic’s technology podcast, produced by Jesse Brenneman and Patricia Yacob. The episode kicks off Season 3: Unbreak the Internet. (Subscribe here.)

Privacy was scarcely an issue in the United States until the late 19th century, which saw an explosion in communication technology—such as the telegraph, the telephone, and cheap cameras. Instant photos and wired communications brought tech into our personal space, and rapid urbanization brought other people into our personal space. It was an age of nascent paranoia, as people feared that once-private interactions were open to nosy neighbors. Americans didn’t realize they valued privacy until modernity made it nearly impossible to be alone.

In the mid-1900s, Americans’ privacy fears shifted from the local to the national level. As the federal government marshaled technology to expand its powers, the public feared wiretapping, McCarthyism, and the atmosphere of surveillance that George Orwell described well enough to make his surname a useful adjective. Not all these fears were rational. In the 1940s, two bus riders in Washington, D.C., sued the local government for piping in Muzak on the bus’s loudspeakers, claiming that it infringed on their right to be left alone. Shockingly, the case made it all the way to the Supreme Court; less shockingly, they lost. But the lawsuit serves as a cartoonish reminder of that age’s very real anxieties: The public so feared the overreach of government that some considered soft jazz on public transit a constitutional infringement.

In the 19th century, privacy was about protection from people. In the 20th century, it was about protection from government. In the 21st century, it’s about protection from a new class of corporate giants that Zuboff calls “surveillance capitalists.” Companies such as Google, Facebook, and Amazon have amassed combined valuations in the trillions of dollars by building empires of omniscience. These firms know our deepest fears, our best friends, and our favorite toilet paper. Armed with such godlike powers, they can … well, what can they do? We’re not exactly sure.

“I think privacy is the wrong way to describe the issue we face in a world of pervasive unregulated data collection,” says Julia Angwin, a longtime investigative reporter. She prefers another term: data pollution.

“I’ve long felt that the issue we call privacy is very similar to the issue we call environmentalism,” she says. “It’s pervasive. It’s invisible. Attribution is hard. Even if you get cancer, you don’t know if it’s from that chemical plant down the road. Living in a world where all of your data is collected and swept up in these dragnets all the time and will be used against you in a way that you will probably never be able to trace and you will never know about it feels like that same type of collective harm.”

The metaphor—privacy infringement as environmental calamity—perfectly fits the most famous privacy breakdown of the past five years. In 2016, Cambridge Analytica, a political-consulting firm working with the Trump campaign, invited Facebook users to fill out a personality quiz. Then they took the data from that quiz to build psychological profiles of voters, whom they targeted with Facebook ads. These ads were designed to energize Donald Trump supporters and discourage Hillary Clinton voters.

“You could make an argument: Oh, these people’s quiz data was taken, and then they were vulnerable to all this propaganda!” Angwin says. “But if you talk to those particular people, they’re probably fine with how they voted. The harm was not individual. The harm was to our understanding of fair elections.”

Cambridge Analytica’s “consulting” work was not like an individual wiretap, or an individual eavesdrop. It was like a climate-related superstorm—a collective and diffuse crisis, caused by innumerable data emissions, which struck at the existential heart of the country. Surveillance is the climate change of the internet.

Democracy requires the informed participation of adult citizens. Surveillance capitalism demands the uninformed half-consent of consumers pressing “Okay!” on privacy disclosures they cannot possibly read or understand. These companies harvest behavior for their own ends, or share it with companies we haven’t heard of, for purposes we can’t imagine, and yet promise: You have nothing to worry about!

But American democracy, and other collective institutions vulnerable to mass surveillance, will surely weather more “extreme data events” in the near future.





Subscribe to Crazy/Genius: Apple Podcasts | Spotify | Stitcher | Google Play

In the early 1970s, the psychologist David G. Myers conducted a famous experiment on the power of groups. He divided several hundred undergraduates into two camps based on their attitudes toward feminism, creating a conservative cluster and a liberal one. Then he left them all alone to talk. When the groups disbanded, the liberal students had become much more liberal, and the conservative students had veered sharply right.

Today this effect is known as group polarization, and unlike other pseudo-phenomena in the field of psychology, it’s been ratified by several additional studies. Spending long amounts of time with people who agree with you doesn’t just lead to groupthink, these researchers have found; it can also lead to the gradual silencing of dissent and the elevation of, and consensus around, the most virulent opinions. If you want to make people more extreme, you don’t have to threaten them or brainwash them. Just plop them in a like-minded group, and human nature will do the rest.

What does this have to do with the internet? Approximately everything. Social networks such as Facebook and Twitter are many things at once—a modern railroad crossed with a modern telephone network, mixed with a modern phone book, on top of a modern Borgesian library. Above all, social media are a mechanism for allowing people to find like-minded individuals and to form groups with them. To a technologist such as Mark Zuckerberg, this characteristic seemed to promise a new age of transnational peace and moderation (not to mention: profit). But to a social psychologist, it sounded like a machine for injecting public discourse with ideological steroids.

The social psychologists were right.

The latest episode of Crazy/Genius, produced by Patricia Yacob and Jesse Brenneman, analyzes the recent wave of internet-inspired violence—from Charlottesville to Christchurch—and asks why the web became such a fecund landscape for extremism. Hate is an ancient offline phenomenon. But something about the design of our social-media platforms—and perhaps something inherent to the internet itself—has amplified the worst angels of our nature. (Subscribe here.)

The psychological roots of online hatred have three levels. At the bottom, there is group polarization and the natural tendency of moderate people to become extremist versions of themselves when they interact with like-minded peers. At the next level, there is what you might call Viral Screaming Syndrome—the natural tendency of web content to veer toward high-arousal emotions, such as outrage and paranoia, to attract attention and promote social sharing. “Video is really expensive to make, and reported video is really, really expensive to make,” says the Atlantic staff writer Alexis Madrigal. “You know what’s not expensive to make? A bunch of random, paranoid opinions to cut through the noise.”

Finally, the largest social-media networks have built algorithms that exacerbate both group polarization and the Viral Screaming Effect. For example, YouTube executives knew that extreme and misleading videos were racking up tens of millions of views, but the company’s executives declined to intervene, because they were “focused on increasing viewing time and other measures of engagement,” according to a Bloomberg report in April.

“The No. 1 thing, though, that happens when you look into the failings of the various platforms, YouTube and Facebook specifically, is you see this kind of fractal irresponsibility,” Madrigal says. “They were launching in countries where they literally would have no idea what people were saying. And now they’re being asked to defend elections, they’re being asked to, like, understand deeply the social dynamics of every place in which they are.”

If you think the chief driver of online extremism is algorithmic, then your preferred solutions are likely to be algorithmic tweaks. That’s not enough. After all, the internet’s failures exist only because of the natural tendencies of group behavior. To fix social media’s problems, you have to address them at the level of the group.

For Whitney Phillips, an assistant professor of communication and rhetoric at Syracuse University, the ecosystem of online hate speech resembles a biomass pyramid—with apex predators, such as Alex Jones, at the top, and the rest of us playing the role of worms and fungi at the bottom. “The reason that Alex Jones and other abusers and bigots have that platform is because other people engage with them,” Phillips says. “These messages are able to spread way further and way more quickly than they ever would have been able to do on their own because we share them.” The virus of hateful extremism grows because so many people share it—even if they’re just trying to point out how terrible it is.

This might seem like a catch-22: Ignore the bigots and become a bystander, or criticize them publicly and become their amplifier and accomplice. “The issue is generations old,” Phillips says. “If you go back and look at the first-wave Klan in the 1860s and ’70s, they used the news media and boasted to reporters about how many more followers they would get because of their story.”

Fighting extremism requires a pyramid-shaped strategy. At the top, it requires that social-media companies take stronger steps to ban the predators and monitor hate speech, as they’ve already begun to do. But the rest of us, the understory of the biomass pyramid, can do better too. If we understand the psychological origins of online extremism, we can play an equally important role in limiting the spread of the most hateful ideas.

Today’s internet users have the broadcast power once reserved for journalists, but journalistic power comes with journalistic responsibilities. Phillips says internet users ought to act more like a responsible press. One way is for users to ask themselves a simple question before pressing the share button: “What does the sharing of this content achieve? Does it merely make my social network a more extreme, chaotic, and frothily outraged claque, or does it add context and understanding to the world?” Some extremism deserves public condemnation. But sometimes it’s best to resist offering hateful speech the oxygen of amplification.



Chris Wallace’s question for Secretary of State Mike Pompeo wasn’t complicated, or at least it shouldn’t have been. “Is accepting oppo research from a foreign government right or wrong?” the Fox News Sunday host asked.

Yet it had the nation’s top diplomat sputtering. “Chris, you asked me not to call any of your questions today ridiculous. You came really close right there. President Trump has been very clear,” Pompeo said. “He clarified his remarks later.”

Of course, had Donald Trump been very clear the first time he had addressed the subject, the president wouldn’t have needed to clarify anything later on. Trump’s answers have been a confusing mess; he even contradicted himself in a long interview with George Stephanopoulos last week:

Okay, let’s put yourself in a position: You’re a congressman; somebody comes up and says, ‘Hey, I have information on your opponent.’ Do you call the FBI? I’ll tell you what: I’ve seen a lot of things over my life. I don’t think in my whole life I’ve ever called the FBI. In my whole life. You don’t call the FBI.

When Stephanopoulos noted that FBI Director Christopher Wray, whom Trump selected in 2017, had said a campaign should call the FBI, Trump replied, “The FBI director is wrong. Because, frankly, it doesn’t happen like that in life.”

A few moments later, Trump offered a different answer. “I think maybe you do both. I think you might want to listen,” he said, though he added, “If I thought there was something wrong, I’d go maybe to the FBI. If I thought there was something wrong.” He half-reversed course immediately, saying this sort of thing happens so frequently and that the feds can’t handle it: “The FBI doesn’t have enough agents to take care of it. But you go and talk honestly to congressmen, they all do it; they always have. And that’s the way it is. It’s called oppo research.”

On Friday, Trump called in to Fox & Friends, where, as a birthday present, the hosts allowed him to offer yet another answer in an attempt to clean up the mess he’d created with Stephanopoulos.

“You have to look at it, because if you don’t look at it, you’re not going to know if it’s bad,” Trump said. “How are you going to know if it’s bad? But of course you give it to the FBI or report it to the attorney general or somebody like that. But of course you do that.”

The president added, “You couldn’t have that happen with our country. And everybody understands that,” conveniently glossing over the fact that this is not a hypothetical: People with connections to the Russian government offered damaging information to Trump’s own campaign in 2016, and his campaign didn’t report it to the FBI.

To sum up: Trump wouldn’t call the FBI; he would look at the info and also call the FBI; the FBI wouldn’t be interested; and of course he’d call the FBI. No wonder Wallace was confused by Trump’s answers.

During the 2016 campaign, Trump’s supporters often praised him for his blunt speech—for “telling it like it is,” even if the way he did that was unsavory or gauche. His straight talk, against the purported mush-mouth of Hillary Clinton, set him apart. In fact, Trump is even less direct than many politicians, with a habit of offering every possible answer so that his actual views are opaque. Trump’s defenders have asked that the media take him “seriously, not literally,” but his panoply of answers makes it impossible to do either.

On a few core issues, Trump is clear. Immigration? He’s against it. Tariffs? He likes ’em. Iran? Bad hombres. But on many other issues, the president doesn’t have strong impulses, nor does he have much interest in sifting through evidence and doing the homework.

Instead, he’s just looking for the right answer. But what makes an answer the right one often depends on the setting. Sometimes it’s the one that will quiet a political firestorm. Sometimes it’s the one that will incite one. Sometimes it’s what will please his interviewer, or piss her off. Sometimes it’s whatever the crowd wants to hear. He’s constantly reading the room, and if he gets it wrong, he’ll happily try something else.

One vivid example of this came during the presidential campaign, when Trump was asked about abortion. Trump has taken multiple positions on abortion over the course of his life, ranging from calling himself “very pro-choice” in 1999 to making opposition to late-term abortions a staple of his more recent speeches. He was not well versed in the prevailing (though not unanimous) pro-life view that while abortion should be illegal, women who get abortions should not be punished. Asked whether women should be prosecuted for abortions, Trump told Chris Matthews, “The answer is that there has to be some form of punishment,” adding that “people in certain parts of the Republican Party and conservative Republicans would say, ‘Yes, they should be punished.’”

In fact, most pro-life Republicans reacted with horror. The next day, the Trump campaign issued a clarification—Washingtonese for flip-flop—to say what he had really meant was that doctors who perform abortions should be punished. What does Trump really believe on the topic? Who knows? Maybe nothing.

But he does believe unvaryingly in the importance of gaining attention. He told The New York Times editorial board that he used “Build the wall” chants at campaign rallies whenever the crowd started to seem bored. Toward the end of his campaign, his advisers tried to persuade him to use a new slogan, “Drain the swamp.” Trump hated it—he thought it was corny. But when he saw that crowds responded, he was happy to embrace it.

There are other reasons Trump may give multiple, conflicting answers. That approach often confers a measure of plausible deniability. On foreign interference, he told the Fox & Friends crew, “I actually said at the beginning—I think I said I’d do both.”

And it allows him to offer various talking points—sometimes points that contradict one another—simultaneously. The president demonstrated this over the weekend, when he claimed that a news report was both a treasonous betrayal of national security and false, even though logically it could only be a threat if it were true. It’s not that Trump can’t see the contradictions, but rather that they don’t matter. He’s committed to the idea that the press fabricates stories and also to the idea that the attacks on him are treason, and he’ll try both and see what sticks.

Other politicians have their own variations on this tendency to pander. Bill Clinton took full advantage of polling to allow him to tell the populace what it wanted to hear. Barack Obama offered a studied vagueness that allowed him to be all things to all people, or at least many things to many people. Trump’s say-everything approach is just a typically Trumpian, maximalist twist on the same idea. When pressed on the plain contradictions, the president’s aides and minions typically fall back on the same don’t-believe-your-lying-eyes defense that Pompeo did: “The president has been very clear.”

The rub is that there’s not always a “right” answer, as the foreign-interference question demonstrates. If Trump says that going to the FBI is the right thing to do, he’s both implicitly condemning his son’s and son-in-law’s behavior and also slamming the door shut on his own solicitation of foreign help in 2020. If he says he wouldn’t go to the FBI, he gets pilloried and contradicted by his own top officials. He can try to say “Maybe,” but that’s actually an answer that gives the worst of both worlds. As a result, he’s been caught in a loop, cycling through the same set of defenses since summer 2017: There was no collusion. Actually, collusion is normal. Everyone does collusion. There was no collusion.

No matter how many times he tries, Trump can’t find the right answer. What about that isn’t clear?



President Donald Trump reversed himself, calling off the attack against Iran already under way to retaliate against the destruction of a U.S. drone operating in international airspace. Having warned, “If Iran wants to fight, that will be the official end of Iran,” but then balking when his bluff was called, Trump has now shown himself just as willing as President Barack Obama was to make empty threats that damage American credibility.

Trump has actually done much worse than Obama did with his “red line” comment, since Obama didn’t commence operations only to then send a panicked message through an emissary assuring Iran’s leaders that he wanted negotiations instead, or publicly downplay the nature of the threat. Trump did both of these things, after providing with Congress “very strong and compelling evidence” that Iran had sabotaged two tankers in international waters. And he contradicted public, factual reports made by the military command.

The architect of this successful Iranian policy is the head of the Quds Force, Qassem Soleimani. As Michael Weiss describes him, Soleimani “is seen as the one man who outsmarted three U.S. presidents, using their own myopic policies to his farsighted advantage, starting with the invasion of Iraq, continuing onto the failure to confront Assad, and culminating in the fixation on ISIS as the sole security challenge in the neighborhood.”

Soleimani must be incredulous over his victory. In the past several weeks, Iran has attacked two tankers in the Gulf of Oman; fired missiles six times at U.S. bases in Iraq; helped Houthi rebels in Yemen fire rockets at Saudi civilian airports, injuring 23 civilians; and now caused a major disruption to commerce by proving that the skies over the gulf are unsafe for passage.

It’s difficult to determine whether Iran accurately anticipated that Trump would prove unwilling to use military force in retaliation (a power move) or lashed out because the Trump administration’s “maximum pressure” sanctions are domestically destabilizing the regime (an outgrowth of weakness).

The Beirut-based journalist Alex Rowell argues that “the Iranians are very astute readers of the region, and also understand Washington better, frankly, than many Washington pundits.” But it doesn’t take carefully calibrated sensibilities to bet that a president who balked on his threats against North Korea, who obviously wants to disengage from the wars the U.S. is fighting, who has left unchecked Iran’s use of Hezbollah and other proxy forces to save the regime of Bashar al-Assad in Syria, and who, in the midst of a crisis over tanker attacks, claimed, “We just don’t want them to have nuclear weapons,” wouldn’t risk a war with Iran.

The president’s reprehensible behavior makes it virtually impossible for him to bring the country together, convince it that war is necessary, and, on the basis of that support, persuade America’s allies to join the fight. The president has mostly surrounded himself—with the notable exception of Director of National Intelligence Dan Coats—with people who, either by personality or because of the provisional nature of their Cabinet appointments, are disinclined to disagree with him.

In foreign policy, and Iran policy in particular, chaos rules. There appears to be no interagency process to vet alternative approaches or include the talent from departments in deliberations on policy. National Security Adviser John Bolton doesn’t serve either as an impartial adjudicator of the interagency or as an enforcer of the president’s views; instead, he advances his own strident policies, which the president publicly rebuts. The White House is populated by figures either unwilling to restrain the president’s erratic impulses or incapable of doing so. Max Boot is surely right that the most we can expect of this dysfunctional administration is “for Trump to veer, as he has with North Korea, from irresponsible saber-rattling to oleaginous appeasement.”

To be clear, Iran was destabilizing the region before the Trump administration, and the nuclear agreement did not attenuate Iran’s behavior. In fact, after the agreement was signed, Iran ramped up threats against freedom of navigation in the Strait of Hormuz, boosted efforts to use Shia militia as anti-American proxies in Iraq and as support for the Assad regime in Syria, and kept arming Houthi rebels in Yemen. Obama’s decision not to enforce his red line in Syria emboldened Iran further. But the lurching back and forth between “maximum pressure” policies and panicky pleas for negotiation is devastating to our ability to deter Iran. And not just Iran—America’s adversaries everywhere will detect the pattern of tough talk coupled with agitated appeals for negotiation.

The problem with the Trump administration’s policy on Iran isn’t that it won’t go to war. It’s that it keeps constructing policies that require the use of military force to achieve objectives, when the president has repeatedly made clear he’s unwilling to take that step. The administration points a gun, but won’t pull the trigger, and that will encourage other adversaries to challenge America in other theaters.



One of the most interesting legal phenomena of the Trump administration has been the increased use of—and public focus on—previously obscure federal statutes that delegate surprisingly broad power to the president. From using the National Emergencies Act to build his border wall and the Federal Vacancies Reform Act to control the upper echelons of the executive branch, to using the Trade Expansion Act to raise tariffs against Canada in the dubious name of “national security,” President Donald Trump has pursued an array of actions that at once seem to be both within the letter of these laws and an indictment of the open-endedness of their statutory delegations.

If The Daily Caller is correct, the latest addition to this list may soon be the Insurrection Act—which the president plans to use “to remove illegal immigrants from the United States,” the outlet reported yesterday. If the president does actually call out the U.S. military to help deport undocumented immigrants, that could be the most clearly lawful—and most historically indefensible—example of this phenomenon that we’ve seen to date.

The “Insurrection Act” is an umbrella term for a series of statutes that date all the way back to the Founding, and through which Congress has exercised its authority under Article I, Section 8, Clause 15 of the Constitution “to provide for calling forth the Militia to execute the Laws of the Union, suppress Insurrections and repel Invasions.” The Constitution’s drafters understood that there would be circumstances in which local authorities were inadequate to protect the populace and enforce the laws, and so went out of their way not only to identify three circumstances in which troops could be used, but also to give the power to delimit those circumstances to Congress, not the president.

As Justice Robert H. Jackson would write in his celebrated concurring opinion in the Steel Seizure case, during the Truman administration, the Constitution’s limitation on domestic use of the military to three sets of emergencies, “written at a time when the militia rather than a standing army was contemplated as the military weapon of the Republic, underscores the Constitution’s policy that Congress, not the Executive, should control utilization of the war power as an instrument of domestic policy.”

At first, Congress was both thoughtful and careful in how it delegated such crisis power to the president. A 1792 statute required a federal judge to sign off on the president’s determination that the militia needed to be called forth, and also imposed strict time limits on how long the president could use the militia (and which states’ militias he could use for different purposes). President George Washington hewed closely to those mandates in suppressing the 1794 Whiskey Rebellion—the first true domestic security crisis the country faced under the Constitution.

But Congress took the wrong lessons away from this early experience. In 1795, it removed some of the most important checks on the use of the militia for domestic emergencies. And far more significantly, in 1807, a one-sentence statute enacted on the very last day of the Ninth Congress (and signed into law, more than a little ironically, by President Thomas Jefferson) provided that the president could use federal regulars—the standing army of which the Founders had feared—in most of the circumstances in which resort to the militia had already been authorized.

Numerous statutory tweaks followed, but the structural features remained the same. Under the Insurrection Act as it stands today:

Whenever the President considers that unlawful obstructions, combinations, or assemblages, or rebellion against the authority of the United States, make it impracticable to enforce the laws of the United States in any State by the ordinary course of judicial proceedings, he may call into Federal service such of the militia of any State, and use such of the armed forces, as he considers necessary to enforce those laws or to suppress the rebellion.

In other words, if the president determines that ordinary law enforcement is inadequate to enforce federal law, he can deploy the military to assist. And although Congress in the Posse Comitatus Act of 1878 generally prohibited use of the federal military for domestic law enforcement, the Insurrection Act was always understood as the principal exception to that general rule.

As documented in a comprehensive three-volume history by the U.S. Army’s Center for Military History, the Insurrection Act has therefore been used repeatedly throughout American history to help quell civil unrest—especially before the rise of well-trained (and increasingly well-equipped) modern local police forces. In virtually every case, the act was used in circumstances in which there was no serious dispute that local authorities were inadequate to the task at hand, and where domestic deployment of federal troops was seen as a means of restoring civil and civilian order, not subverting it.

But alongside the increasing capabilities of local law enforcement to handle domestic disorder has come increasing political opposition to domestic use of the military for the same purposes—as not only unnecessary, but also perhaps even coercive. It was politics more than any legal concerns that led President George W. Bush to decline to invoke the act to help restore order in Louisiana after Hurricane Katrina. Politics is also a big part of why we’re now in the longest period in American history without a domestic deployment of U.S. troops under the Insurrection Act; it’s been 27 years since President George H. W. Bush sent federal troops to Los Angeles to help restore order after the Rodney King riots. It’s not just that local authorities today can handle most law-enforcement crises; it’s that calling in federal troops (as opposed to the state National Guard) had, at least until now, come to be seen as crossing a constitutional Rubicon—a measure that should be saved for truly existential crises when there is no dispute over the need for federal military intervention.

Lawsuits will certainly challenge Trump’s invocation of the Insurrection Act to assist in immigration enforcement—a purpose for which it’s never previously been used. But the text of the statute would seem to be on the president’s side—underscoring just how broad the power is that Congress has delegated to the president, and just how much we have historically relied on political checks, rather than legal constraints, to circumscribe the president’s authority. As partisan tribalism has increasingly come to mark virtually every policy debate in Washington, those political checks have proved increasingly ineffective.

The obvious lesson here, as with the National Emergencies Act, the Federal Vacancies Reform Act, the Trade Expansion Act, and others, is that Congress ought to put less faith into these political checks, and more teeth into substantive statutory limits on the president’s authorities. In the case of the Insurrection Act, some of us have been arguing as much for years. But that can’t—and won’t—happen until members of this (or any) president’s own party, and not just his opponents, privilege the separation of powers over the separation of parties.



Almost a decade ago, as a young graduate student in theology, I lived for a year in the rectory of a Catholic parish.

Like many other parishes in Boston faced with an ever-worsening clergy shortage, St. Mary of the Angels did not have a priest in residence. Rather than allowing the creaky 19th-century Victorian estate house that doubled as the church’s gathering space to stand empty, the parish made the decision to open the doors to laypeople.

I moved into the parish house and into an anomalous existence: I was a 24-year-old woman living in a Catholic church. In exchange for my bedroom above the office, I helped clean the church on Saturday mornings and set out the coffee and donuts—a veritable second Eucharist—after Mass on Sundays, dutifully cutting the pastries into quarters in an attempt to feed as many people as possible on the parish’s nonexistent budget. I compiled the church bulletin and taught fifth-grade catechesis and performed a litany of other odd jobs and pastoral tasks. In return, I was given a rare gift: the chance to experience the life of a parish from the inside out.

St. Mary’s was unique in two respects. First, it was profoundly diverse. Built in 1906 to serve the Irish and German working class in Boston’s Roxbury neighborhood, it had, for decades, sustained a vibrant community of African American, Afro-Caribbean, Latino, Southeast Asian, and Euro-American parishioners. A significant portion was first-generation immigrants. Even more striking were the ties of friendship that united members across boundaries of race and culture.

Second, laypeople were the heartbeat of parish leadership. People weren’t just involved. They were empowered. In some ways, they had to be. There was no full-time pastor, and no money to pay a large staff. But the tradition of collaboration was born of more than necessity. After Vatican II, St. Mary’s established an interracial parish council of laypeople who put forth a bold agenda for change at the once isolated, struggling church. In 1969, they transferred the church’s financial accounts to Boston’s only black-owned bank in an act of solidarity with the neighborhood’s growing African American community. Collaborative leadership among the parish’s laypeople, religious sisters, priests, and neighbors intensified in the 1970s and ’80s, when St. Mary’s became the epicenter of community peace-building against a rising tide of youth gang violence. In 2004, when the Archdiocese of Boston targeted more than 80 churches for closure or consolidation, St. Mary’s was one of only a few to successfully protest its shuttering. Parishioners organized a community campaign to convince the chancery that the parish was too vital to the stability of the neighborhood to close.

St. Mary’s was a parish that, as the Jesuits like to say, ruined me for life. It ruined me for clericalism, for racism, for xenophobia. Most of all, it convinced me that when it comes to building humble, accountable, inclusive Catholic communities, another world is indeed possible—not in a small, self-selecting alternative community of like-minded individuals, or in the kingdom of God, but in an ordinary city parish here and now.

I thought of St. Mary’s as I read James Carroll’s provocative cover story in the June issue of The Atlantic. The piece is a kind of lament, an excoriation of the Catholic Church’s capitulation to clericalism. In theological terms, clericalism—the elevation of ordained persons over the laity—is not only an unintended consequence of history, but also a social sin, an idolization of power perpetuated by a constellation of social structures and cultural practices.

The most difficult part of transforming structures of sin is imagining what our institutions would look like without them. But like other social sins—racism, nationalism, sexism—the subject is not the same as its distortion. The solution to racism, for example, is not to abolish human difference but (among other things) to transform the laws and practices and false narratives that uphold white supremacy. Similarly, the solution to clericalism need not be, and indeed should not be, to abolish the priesthood. Rather, it is the more painstaking work of transforming the ecclesial structures that engender and sustain this diseased understanding of clerical supremacy.

Carroll and I are emphatically of one mind about the harm that clericalism has caused the People of God. There is room for the kind of creative, grassroots dissent that he seeks. Such communities of resistance already exist, indeed have always existed within the Church, and in numbers more vast and forms more diverse than most Catholics realize.

But if we truly want to reform the Church on a global scale—that is, if we are genuinely interested in saying “never again” to the catastrophe of sexual violence and secrecy that has emerged and reemerged throughout the history of this institution—then what is needed is a perhaps more sober and less triumphant grappling with the way institutional change actually takes place.

There is a saying, popular in intentional communities, that goes, “Everybody wants a revolution, but nobody wants to do the dishes.” The year I spent keeping the lights on in that Roxbury parish house taught me to do the dishes, literally and metaphorically. In certain ways, St. Mary of the Angels looked a lot like the vision of a lay-led church Carroll wants to help us glimpse. Indeed, the parish was, among many other things, a sort of refuge for Boston Catholics who found themselves hanging on to their faith by a thread in the wake of the 2002 abuse crisis. And yet what I learned from the community’s longtime leaders is that changing the culture of power in a 2,000-year-old institution means resisting the urge to burn the whole rotten thing to the ground and instead sticking around and going to meetings and participating in the often infuriatingly slow work of change.

This is why I winced when I read Carroll’s suggestion that clericalism will finally meet its end when laypeople simply decide to be “Catholics on our own terms.” Who, I wondered, in a Church of 1 billion people, is “our”? What can come of such an approach, ultimately, is merely another sort of Benedict option. In the original sense of the term, traditionalists bind together to keep the faith. In Carroll’s version, it’s the reformers who circle their wagons. But the result is the same: a smaller, purer Church of Good People.

At St. Mary’s, by contrast, a culture of inclusive collaboration gradually took root as laypeople and priests joined together to leverage the Church’s institutional power on behalf of the most marginalized members of the local community. Over time, they developed structures and practices to ensure that, no matter who the pastor happened to be, the laity would retain a guiding voice in the parish’s mission.

This local example is instructive for the entire Church. If undoing clericalism means transforming the structures that uphold it, then where might the Church begin? I will suggest one possibility. Currently, beyond the purely advisory role of parish and diocesan councils, laypeople hold no formal role in the authority structure of the Church. This must change. Giving laypeople a powerful voice at every level of Church governance would be a consequential first step in building an ecclesial culture of justice, transparency, and humility.

The Church, as Carroll emphasizes, is the People of God. But this notion wasn’t an invention of Vatican II. The term has its origins in Hebrew scripture, where it is used to invoke God’s covenantal bond with the people of Israel and thus to underscore the fundamentally communal shape of holiness. To call the Church holy, then, as Christians of many denominations do each Sunday when we recite the Nicene Creed, is to contend that whatever is good and beautiful about the Church—indeed, whatever is not beyond redemption—is a function of this communion with God and among people, living and dead, near and far.

The greatest challenge of picking up the pieces of the Church will come in repairing that broken communion. By the grace of God, it might also be the greatest gift.



