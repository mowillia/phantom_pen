On Monday, another admissions scandal injected a new dose of disillusionment into the already disillusioned world of elite education. This time the revelations concern not higher education, but Stuyvesant High and New York City’s other elite public high schools. Of the 895 current eighth graders who secured a spot in next year's Stuyvesant freshman class, just seven identify as African American.

Every year, reports show abysmally low numbers of black or Latino students at all eight of the city’s elite specialized high schools whose admissions rely solely on a standardized exam. City officials including Mayor Bill de Blasio have led an ongoing, multifaceted effort to solve the problem through recruitment initiatives and a summer enrichment program designed to shepherd low-income youth into the rigorous institutions, but enrollment numbers remain disappointing.

De Blasio and his relatively new schools chancellor, Richard Carranza, last year proposed a plan that would set aside a percentage of specialized-school seats to disadvantaged students who participate in the summer enrichment course but who score just below the cutoff on the entrance exam. It’s hard to say how it will play out, however, because of a lawsuit spearheaded by a cadre of largely Chinese American activists that accuses the city of racial discrimination. The complaint alleges that the plan, if implemented, would reduce the proportion of Asian American students who attend these schools, depriving highly qualified, disadvantaged kids of the opportunity to live up to their potential. The issue of diversity at NYC's elite schools is full of disagreement over the merits of the current system, the sources of the disparities, and what effective solutions might be—but it is also full of misunderstandings. Accurately describing the problem requires dispelling several myths.



As is the case at most elite colleges in the United States, Asian American students are substantially overrepresented at most of the elite public high schools in New York City. Roughly three in four students currently enrolled at Stuyvesant High School identify as Asian American, for example, dramatically eclipsing all other racial groups; their African American and Latino peers account for an almost nonexistent slice of the school’s population. What’s especially striking is how acutely the racial distributions at elite institutions such as Stuyvesant or Harvard University clash with their surrounding communities—even when considering the soaring numbers of Asian Americans across the country. In 2017, 22 percent of Harvard’s admitted class identified as Asian American, compared with 5 percent of the country at large; in New York City, residents who are identified with this racial group make up a larger but still modest 15 percent of residents.

A pending lawsuit accusing Harvard’s admissions process of discriminating against Asian American students has created a national platform for a network of predominantly Chinese American activists who are against affirmative action, many of whom are also involved in the suit against the specialized high schools. With the allegation that race-conscious admissions practices are hurting a minority group they were designed to serve, the group has gained traction among the mainstream public. But polling data and court filings indicate that many if not most Asian Americans support race-conscious admissions policies.

Yet this opposition to affirmative-action policies in college and high-school admissions is often portrayed by activists, politicians, and the media as a social-justice battle endorsed by or on behalf of all Asian Americans, rather than a niche faction. This portrayal treats Asian Americans as a monolith, and feeds into stereotypes that they are the "model minority." Notably, surveying Americans of Asian descent, a 2012 Pew poll found that just one in five respondents most often describe themselves as “Asian American” or “Asian”; a majority, meanwhile, said they typically reference themselves using their country of origin—”Mongolian American,” for example, or “Pakistani.”

The population referred to sweepingly as “Asian American” comprises more than 30 nationalities and ethnic groups: from Chinese and Cambodian to Burmese and Bangladeshi. The immigration experiences, political ideologies, and amounts of social capital are just as diverse—both among the various groups and within them. For instance, Chinese Americans whose ancestors immigrated to the U.S. in the 1800s as manual laborers tend to have very different stories and values than Chinese Americans who immigrated to the country in the 1980s and ’90s to fill white-collar jobs. These nuances help explain why some Asian American groups boast superlative levels of educational attainment while others amount to some of the country’s lowest performers. Close to three-fourths of Indian Americans ages 25 or older had a bachelor’s degree in 2015, according to Pew data; meanwhile, the same was true for fewer than one in 10 of their Bhutanese American counterparts.

New York City—which in the past few decades has witnessed a rising share of majority-Asian neighborhoods, whose residents tend to be foreign-born—is an object lesson in this variation. An analysis of 2010 census data by an NYU-based urban-policy think tank found that the city’s majority-Asian neighborhoods are more economically depressed than those of most other racial distributions: Their average household income of less than $52,000, for example, was less than that of majority-black neighborhoods. That same report found that fewer than a quarter of the adults (25 years or older) living in the majority-Asian neighborhoods at the time had a bachelor’s degree or higher.



The bare-bones admissions policy for the city’s eight exam-based, elite public high schools has hardly changed in a half century: A student’s score on a standardized test is the single deciding factor for whether she’s accepted; each school has its own confidential cutoff score, though Stuyvesant is widely thought to be the most selective. Neither a student’s grades nor her previous teachers’ recommendations have a bearing on the decision.

The city has experimented with a string of work-arounds, such as programs that provide exam prep to low-income students and ensure ample test-taking opportunities at underrepresented middle schools. One of de Blasio and Carranza’s latest proposals would basically earmark admission to low-income students who meet a set of rigorous criteria; another would eliminate the test altogether. Opponents argue that in guaranteeing objectivity, the status quo is the only admissions system that protects everyone’s civil rights.

In a court filing responding to the complaint, the city maintains that the model it proposes would have a negligible impact on Asian American representation at the eight schools. Instead, the city argues that by proactively promoting socioeconomic diversity, its plan would elevate the prospects of students of all races—benefiting low-income Asian students just as much as their similarly disadvantaged black and Latino peers. Most of the Asian American students enrolled in the specialized schools are low-income, according to Doug Cohen, a district spokesperson; an earlier district report also indicates that the schools’ Asian American populations tend to be poorer than their classmates of most other racial groups.

“Opponents who seek continued reliance on standardized tests are out of step with the growing body of evidence that confirms that these tests are infected with racial bias and poor predictors of a student's academic potential,” said Kristen Clarke of the Lawyers’ Committee for Civil Rights Under Law, in a press release Tuesday.

But research has shown that measures to expand high-school admissions criteria beyond standardized tests, to include metrics such as grades or attendance records, would hardly ameliorate the diversity problem. A 2015 study co-authored by the education economist Sean Corcoran, for example, found that an admissions system based on expanded criteria would do very little to enhance minority representation at the schools. Elite high schools’ limited diversity seems to stem from the earliest stages of children’s education—and even from their experiences predating kindergarten. The study describes, for instance, the often biased decisions in elementary and middle school around whom to sort into gifted-and-talented programs or relegate to special-needs classrooms. Reforming high-school admissions can only do so much if they don’t tackle the myriad factors that play into a child's success before that child applies to high school.



Even if Stuyvesant, Queens High School for the Sciences, and Staten Island Technical High—the latter of which has a single black student in its most recent admitted class—transformed into bastions of educational egalitarianism, one major problem would remain: These elite campuses serve just 6 percent of NYC’s public-high-school population.

The tiered public-school system isn’t inherently unjust because it creates a hierarchy, argued Pawan Dhingra, a sociologist and American-studies professor at Amherst College, in an email. Rather, a hierarchical system is unjust if each school’s quality correlates in some way with the background of students who attend it—their race, their class, their gender, their immigration status, their cognitive abilities. Every student should have access to both high-caliber instruction and specialized curricula, said Dhingra, who has researched the tendency to conflate Asian Americans with white Americans when it comes to education and economic mobility.

In New York City, the non-elite public schools vary greatly in quality; few students are guaranteed customized learning opportunities. Thanks mostly to its largest metropolis, New York State is home to the most segregated school system in the United States, as my colleague Adam Harris has reported. This is the result of historically entrenched biases, gentrification, zoning laws, and school policies that disproportionately slot kids from privileged backgrounds into gifted-and-talented programs and their disadvantaged peers into special-needs classes.

New York City is thus a case study in the unfortunate truth that in the United States, one’s zip code is often her destiny. Nineteenth-century policymakers had various reasons for establishing a national network of public schools. But scholars tend to agree that the American educational system was in large part designed—and is today explicitly tasked— with the goal of promoting a healthy democracy by ensuring color- and class-blind opportunity. All too often, the opposite is true.



For all the trouble with the specialized schools, eliminating them wouldn't do much to make education in NYC more egalitarian. A ban on selective public high schools wouldn’t eradicate the legacy of racism; it wouldn’t address housing segregation; it wouldn’t fix the sorting system that filters through earlier grade levels.

Stuyvensant's abysmal enrollment numbers of black and Latino youth are evidence that its admissions process is broken. But it is far from the only school where such problems occur. Elite university admissions are similarly disintegrating. And the students fighting for admission in these dysfunctional systems are often at a disadvantage because of opportunity gaps that started long before they set foot in a school for the first time.



Headlines touting the Next Big Idea in education have become so common in recent years that it’s tempting to dismiss every new K-12 initiative as a fad or fantasy doomed to either flatline or fail. A skeptical observer might be inclined to sweep LeBron James’s I Promise School into that pile. But teachers and executives who’ve worked closely with James on this endeavor insist that he won’t let that happen. The professional basketball player and Akron, Ohio, native, they say, really wants to rethink how public education should be delivered—not only in Akron, but across the country.

And his vision is already having a tangible impact: Last week, the Democratic U.S. Senators Sherrod Brown and Chris Van Hollen, of Ohio and Maryland respectively, introduced a bill that would set aside $45 million for federal competitive grants to fund partnerships between schools and their communities. The idea, Senator Brown indicated in a tweet, is to replicate the I Promise model in places that don’t have “a LeBron James.”

What makes I Promise unique, its creators and outside experts say, is that it combines various features that are seldom seen in a single school—and that it is poised to potentially spur similar education-reform efforts across the country. The Atlantic has obtained I Promise's “master plan” document—its blueprint for the next five years, which was approved last fall by Akron’s school board. The document can be found in full at the end of this article. While the plan leaves some questions unanswered—about the details of the curriculum, for example—it reveals much about the school's philosophy and unorthodox approach. Here are some of the things that make I Promise unique:   

1. It’s a public school.

Unlike many other celebrities and magnates who’ve turned to education philanthropy—James created a school that would belong to the district, rather than a private school or a charter school. James’s school is housed under his I Promise nonprofit, which he created in 2011 as part of an effort to shift his now-14-year-old foundation’s focus toward education. From the get-go, I Promise sought to tackle the high-school dropout rate in Akron Public Schools. It made a lot of progress in that effort over the years: In 2015, for example, it started funding full-tuition, four-year scholarships to the University of Akron for eligible students in the I Promise program. Still, fewer than three in four public-school students in Akron—where about a quarter of the city’s population lives below the poverty level—graduate high school within four years.

The I Promise school was designed to target the Akron Public Schools students who struggle despite the existing supports provided by the nonprofit. It started its first year of classes on July 30, welcoming onto campus 240 students in the third and fourth grades, and will grow gradually over the years, eventually serving children in grades one through eight by 2022.

It would have been challenging for James to target this population through a charter or private school. While those models may have, in theory, allowed for more experimentation, such innovation would happen in isolation and would be difficult to extend into the city’s other public schools. It could alienate the local teachers’ union and district administrators and, potentially, families without the savvy to take advantage of public-school alternatives. Pulling away from Akron Public Schools would have also made it difficult to create a pipeline into I Promise for the at-risk students he sought to target.

James and his nonprofit team started developing the master plan in April 2017. By October, they’d finalized the first draft of the proposal and presented it to the school board for consideration. The proposal details five teams tasked with designing different components of the school—including its “instructional framework,” its human resources, and its community-engagement efforts—each of which was co-chaired by an Akron Public Schools staff member. The board formally approved the plan a month later.

“LeBron grew up as a public-school kid,” says Michelle Campbell, the executive director of the LeBron James Family Foundation, which partnered with Akron Public Schools in creating the I Promise School. “And the reality is that, in a lot of our urban cities, the vast majority of kids are going to go to public schools.” Making I Promise a part of the public-school system, she believes, “is what helps make what we're doing scalable and provide a learning laboratory for the rest of the country.”

2. It has huge ambitions. 

Akron Public Schools states on its website that it wants to be the "#1 urban school system in the United States." I Promise is on a mission to help make that happen, and has an explicit goal of improving the well-being of residents across Akron—not just its students. “Classroom instruction and assignments are grounded in the health and prosperity of the City of Akron and local efforts to build inclusive, healthy, and socially just neighborhoods for all its citizens and families in an increasingly global and multicultural world,” the master plan says. To do so, it’s implementing a suite of supports that are rare at conventional public schools: attendance incentives, outings to local businesses, mentorship programs, after-school tutoring, and constant encouragement from James through things like video messages and written notes.

“I remember when we had a year-end meeting” to discuss the I Promise foundation's work, Campbell says. “It was that meeting where I said, ‘We’ve grown quickly, and we're doing amazing things, but we have hit a wall if we don’t bring them all to one school.’ ... I can't even explain [James’s reaction]—he was like: ‘Well, then, that’s what we’re doing.’”

3. It wants to be involved in every aspect of a student's life—not just academics. 

The master plan says I Promise will focus on “rigorous problem-based, inquiry-oriented learning,” especially pertaining to STEM. But the plan also emphasizes  “social emotional supports and trauma-informed practices.” Prioritizing both of these elements, the plan says, will allow the school to “educate the whole child.”

In plain English, what that means is that the school wants to ground its curriculum in real-world issues. As I Promise sees it, math instruction should entail more than worksheets that drill students on long division; science class shouldn’t just mean memorizing different types of rocks. Instead, the school wants to have students learn those subjects by engaging in hands-on projects to solve problems that are relevant to them.

I Promise also believes that a student’s life outside the classroom has a huge bearing on her academic performance, particularly for children of color and those who grow up poor. So the school is providing programs to help improve kids' ability to, for example, regulate their emotions, develop self-awareness, and cooperate with others. I Promise also places an emphasis on mental and physical health for both students and teachers, offering the following resources:

Data compiled in 2015 by the Association for Supervision and Curriculum Development suggests that while a growing number of districts and states are embracing this idea of educating "the whole child," it’s hardly yet the norm.

4. It helps provide for the basic needs of students' families 

A key, if not the key, facet of I Promise’s “whole child” approach is the weight it gives to family support. “We understand,” Campbell says, “that if you send a child home with no dinner or let a child leave school without knowing where they’re going to sleep that night, there’s no way that child is going to learn.”

At the center of the school’s community-engagement work is a family resource center, whose staff includes a “liaison” tasked with connecting families with educational resources (like GED programs and English-as-a-second-language classes) and other services, like child care. Family members (as well as students) also have access to amenities to support their everyday needs: a barbershop and hair salon, financial-literacy tutorials, and a food pantry, to name a few.

This resource center, Campbell says, was informed by a body of research showing that things like parental stress and dysfunctional homes can significantly undermine a child’s ability to learn.

5. Its founder is LeBron James, and his fingerprints are all over the master plan.

Yes, James is widely considered to be the best basketball player in the world. Yes, he has 41.3 million followers on Twitter. And yes, his net worth is at least $440 million. But he also has a history of progressive political activism, and has advocated for racial justice, the Black Lives Matter movement, and gun control; his involvement in education issues traces at least as far back as 2011, when he partnered with State Farm to launch an initiative geared toward reducing the high-school dropout rate. The I Promise school’s pillars seem drawn directly from James's philosophy: “Be Best: Constant pursuit of improvement,” “Family: If you fail, we fail,” and “Mindfulness: Drop baggage at the door,” to name a few.

James is also intimately familiar with the needs of the community I Promise is serving. Raised in Akron by a single mom who had him when she a teenager, James had a turbulent childhood and at times struggled in school; in the fourth grade, he says he missed the equivalent of 16 weeks of school days. In a country where ambitious educational ventures like I Promise are so often driven by philanthropists who parachute in from somewhere else, James is spearheading something that is both truly novel and close to home.







On Tuesday morning, the Department of Justice accused more than 50 people—parents and college-athletics coaches—of a nationwide scheme to get the children of the wealthy into selective colleges such as the University of Southern California, Georgetown, Yale, Wake Forest, and the University of Texas.

William Singer pleaded guilty on Tuesday to charges of racketeering conspiracy, money-laundering conspiracy, and obstruction of justice. He was allegedly the fixer behind the scheme, helping parents create fake athletics profiles to give their children a leg up with admissions. Singer is accused of funneling bribe money to coaches at these schools through a fake charity organization he ran that was, ironically, supposed to be helping “underserved kids”—parents received letters after transferring money thanking them for the generosity that would help “provide educational and self-enrichment programs to disadvantaged youth.” The organization also allegedly advised parents on how to get their kids more time on standardized tests such as the ACT and SAT, and arranged for graduate students to take the tests for them

In total, from 2011 to 2019, parents paid Singer tens of thousands of dollars, and in one case upwards of $1 million, to falsify students’ athletics profiles. In addition, Singer charged anywhere from $15,000 to $75,000 for each fake test score.

For the most part, the students caught up in the scandal seem to have been unaware of their parents’ underhanded dealings. So far, none of them have been named in the indictments, and whether or not they’ll remain enrolled at their respective colleges is unclear.

The indictment is 269 pages long, and some of the details are truly astonishing. Below are nine of the most striking examples from the document that show the lengths that parents were allegedly willing to go to in order to send their children to prestigious universities.

1. One father, Houmayoun Zadeh, is a professor at USC’s medical school—and yet court documents claim he still felt that he had to bribe his daughter’s way into the school. The indictment reads: 

In a lengthy text message exchange that began on or about March 20, 2017, ZADEH discussed the admission of his daughter to USC with CW-1 [Cooperating Witness One], who appears to be a fixer involved in setting up back door deals. In the conversation, CW-1 requested that ZADEH confirm that his daughter would attend USC … ZADEH replied that his daughter was concerned that “she did not get in on her own merits. I have not shared anything about our arrangement but she somehow senses it. She’s concerned that others may view her differently.”

2. Another parent, Jane Buckingham, allegedly pressured her son into getting on a plane to Houston to take the ACT at a fake testing center, even though he had tonsillitis and his doctor advised him against traveling. 

BUCKINGHAM: First of all, he can get on that plane like he, according to him, he’s like, “I really don’t feel that bad, I think I’m okay.” And I do think that this doctor is a little over conservative. Part of my challenge is that my ex-husband is being incredibly difficult about the whole surgery, and if I take him to Houston and then he can’t get the surgery he’s gonna be very annoyed with me.

And later, when Buckingham and CW-1 decided to have her son take the test at home instead: 

BUCKINGHAM: Yeah. I know this is craziness, I know it is. And then I need you to get him into USC, and then I need you to cure cancer and [make peace] in the Middle East.

3. The indictment describes one of CW-1’s employees submitting applications on behalf of the younger daughter of the fashion designer Mossimo Giannulli and his wife, the actress Lori Loughlin, because the daughter was confused about how to do it.

On or about December 12, 2017, LOUGHLIN e-mailed CW-1, copying GIANNULLI and their younger daughter, to request guidance on how to complete the formal USC application, in the wake of her [other] daughter’s provisional acceptance as a recruited athlete. Loughlin wrote: “[Our younger daughter] has not submitted all her colleges [sic] apps and is confused on how to do so. I want to make sure she gets those in as I don’t want to call any attention to [her] with her little friend at [her high school]. Can you tell us how to proceed? CW-1 responded by directing an employee to submit the applications on behalf of the GIANNULLIS’ younger daughter.

4. The actress Felicity Huffman allegedly sent an email to CW-1 about a snag in their plan to have her daughter take a test with extended time, which included the phrase “Ruh Ro!”

On or about October 16, 2017, HUFFMAN’s older daughter received a letter from the College Board advising that she had been approved for 100 percent extended time … The high school counselor wrote back to HUFFMAN the next day, stating, “Now you will register [your daughter] for the December 3rd SAT … Collegeboard considers double time a school based exam, so [our high school] is the test center. I will proctor test on Dec 4th & 5th and that’s the process in a nutshell.” HUFFMAN forwarded the email to CW-1 with the note, “Ruh Ro! Looks like [my daughter’s high school] wants to provide own proctor.” CW-1 responded, “We will speak about it.”

5. Michelle Janavs, a former executive at a food manufacturer, paved her older daughter’s way into college through side-door schemes, according to the indictment. But her younger daughter got suspicious when Janavs allegedly started a similar process for her. 

JANAVS: I had a question for you. So I was able to get [my younger daughter] the multiday ACT.
CW-1: Okay, you got her extended time multiple days, got it.
JANAVS: Yes, so I got that, the only thing is [my younger daughter] is not like [my older daughter] … She’s not stupid. So if I said to her, “Oh, well, we’re going to take it up at CW-1’s testing center] she’s going to wonder why …   She’s smart, she’s going to figure this out. Yeah, she’s going to say to me— she already thinks I’m up to, like, no good.

6. CW-1 explained to one father, George Caplan, that his daughter needed “to be stupid” when undergoing an evaluation to get extra time on the ACT—an accommodation to help students with learning disabilities. As the indictment describes it, Caplan seemed to recognize he was acting unethically, but did so anyway.

CW-1: The goal is to be slow, not as bright, all that, so we show discrepancies. And she knows that she’s getting all this extra time, everywhere that she is right now. At the Academy kids are getting extra time all the time.

CAPLAN: You mean the Greenwich Academy?

CW-1: Everywhere.

CAPLAN: Oh, oh you mean at her tennis academy. I see. Yeah. Okay.

CW-1: Yeah, everywhere around the country. What happened is, all the wealthy families that figured out that if I get my kid tested and they get extended time, they can do better on the test. So most of these kids don’t even have issues, but they’re getting time. The playing field is not fair.

CAPLAN: No, no its not. I mean this is, to be honest, it feels a little weird. But.

CW-1: I know it does. I know it does. But when she gets the score and we have choices, you’re gonna be saying, okay, I’ll take all my kids, we’re gonna do the same thing. (laughing)

CAPLAN: Yeah, I will.

7. Robert Zangrillo, the CEO of a private investment firm, is accused of planning for someone to retake supplemental classes that his daughter had failed in community college. 

ZANGRILLO’s daughter inquired, in substance, what CW-1 was doing about an ‘F’ grade that she had received in an art history class she had taken. CW-1 explained that he had [arranged for someone to retake the class].’ CW-1 asked if this plan made sense. ZANGRILLO and his daughter both replied, ‘Yes.’

ZANGRILLO then inquired, in substance, whether Sanford could take his daughter’s biology class as well. Sanford replied that she was ‘happy to assist.’ ZANGRILLO added: ‘If you can do the biology thing, just makes sure it gets done as quickly as possible, so we have a backup plan for the conditional [acceptance to USC and then you do the best you can to overturn the art history grade].’

8. Devin Sloane, a CEO and businessman, is accused of purchasing water-polo gear from Amazon and hiring graphic designers to create fake images of his son playing the sport to send to college recruiters.

Records obtained from Amazon.com indicate that, on or about June 5, 2017, and June 16, 2017, SLOANE purchased water polo gear, including a ball and a cap.
Thereafter, on or about June 26, 2017, SLOANE received an e-mail from a graphic designer bearing the subject line, “Water Polo Photo 06/26/17.” The designer wrote:
We researched a few water polo athlete images and the majority are cropped against a background so they can use them in promotional materials (and it takes out undesirable elements from the crowd etc). We were able to adjust the color and complete a clean extraction to mimic this look (attached).

On or about June 27, 2017, SLOANE e-mailed a photograph of his son
purporting to play water polo, with his right arm and upper torso exposed above the water line. In the e-mail, SLOANE asked, “Does this work??” CW-1 responded: “Yes but a little high out of the water- no one gets that high.”
On or about the following day, June 28, 2017, SLOANE sent a photograph in which his son appeared to be lower in the water, with his torso and arm now mostly submerged. SLOANE wrote, “Hope this works...” CW-1 replied, “perfect.” In both photographs, SLOANE’s son appears to be using the items SLOANE purchased from Amazon.com a few weeks earlier.

9. Parents allegedly consented to being recorded on the phone with a cooperating witness as they discussed different elements of their fraud. Here’s an example of one of those calls, with Marjorie Klapper, the owner of a jewelry business.

On a telephone call with KLAPPER on or about October 24, 2018, CW-1 acting at the direction of law enforcement agents, told KLAPPER that his foundation was being audited. The following is an excerpt from the call, which was consensually recorded.

CW-1: So, I wanted to let you [know]—our foundation, is, is being audited—

KLAPPER Yeah.

CW-1: —which is very normal. Right?

KLAPPER Yeah.

CW-1: And so they’re lookin’ at all of our payments.

KLAPPER . Mm-hmm.

CW-1: And so they’re lookin’ at, you know, the payment—including your payment that you made for 15K, to have [CW-2] take the test for [your son].

KLAPPER Yeah.

CW-1: So I just—I just want to make sure that you and I are on the same page. Cause, of course, I’m not gonna tell the IRS that—that, you know, you paid 15,000 for to take the test for [your son], obviously. So I just wanted to make sure that you and I are on the same page, in case you get a call.

KLAPPER: Okay. So if I get a call—

CW-1: You’re gonna say that the—the $15,000 that you paid to our foundation was to help underserved kids.

Klapper: Okay.

It's brazen enough to commit fraud, but even more so to admit it on a recording and apparently not suspect you might get caught. Taken together, the lurid details from the case reveal just what their kids’ admission to elite colleges is worth to some parents—in terms not only of the money they are willing to spend, but of the lines they are allegedly willing to cross.



In the lobby of a deserted student-union building in Peoria, Illinois, the George Mason University speech team falls into formation. Following their coach, a petite, white-haired man in a silk designer tie, they walk single file down an empty hallway and into an empty classroom, where someone plugs in a speaker, turns up the music, and announces that it’s time to dance.

To hear more feature stories, see our full list or get the Audm iPhone app. 

On this rainy Saturday morning in April 2017, no one really wants to dance. It’s 6:30 a.m., and most team members are running on four hours’ sleep and a granola bar for breakfast. Everyone is in a suit. Still, they sway their hips, kick the air, jump up and down, bang on the walls, and belt out their best rendition of Nicki Minaj’s “Starships.” At least one person leaps on top of a chair. Because standing off to the side, arms crossed, their coach, Peter Pober, is watching.

Pober considers the dancing essential. It’s his time-honored pretournament ritual, designed to coax students out of their head for a few moments right before they compete. The prevailing wisdom in collegiate public speaking is that to be truly excellent, the performer must expose himself completely, presenting a speech so “raw” and “real” that he sheds his self-consciousness. So as the team dances—for about 20 minutes, before every tournament—Pober closely examines each student. If someone appears too reserved or too controlled, he will often arrange to meet with him after the tournament, and let him know.

In the world of competitive public speaking, known to insiders as “forensics,” Pober is legendary; his team, legendary by extension. Pober has participated in speech, as a competitor and then as a coach, for more than 35 years, steering two of the country’s top speech programs—at the University of Texas at Austin, where he worked until 2003, and at George Mason—and winning more top awards than almost any other coach in the country, building an international reputation. In 2005 he started the George Mason Institute of Forensics, colloquially known as GMIF, one of the preeminent high-school public-speaking camps in the country, and led it for 13 years. When Pober walked through the halls at a speech tournament, people would turn around and stare.

Many who knew Pober well weren’t surprised when, in February 2018, after 15 years as the director of George Mason Forensics, he was placed on administrative leave amid allegations of sexual harassment. Pober’s special interest in “good-looking, skinny white boys” was an “open secret,” Jon Tyree, who graduated from GMU in 2014, told me. According to several of Pober’s former students, he would invite his “favorites” out for one-on-one dinners, buy them round after round of margaritas, and host them at his home for Thanksgiving. Less well known were the things he’d allegedly whisper to certain students and young alums in tournament hotel rooms or nestled in the back corner of his favorite dive bar: to the then–GMU student Jim Welty, “I want to fuck you on this bed,” or to the alum Sean Cummings, “I have wanted to fuck you” since an encounter they had when Cummings was 17. (Pober did not respond to multiple requests for comment on this story.)

Forensics afforded Pober the ultimate cover. The best speeches—the ones that feel “real,” and that go on to win national championships—are deeply personal, says Landry Ayres, a former GMU Forensics student and coach. Selecting topics at the beginning of each season, Ayres told me, many students ask themselves, What makes me vulnerable? What is uncomfortable for me? What can make me cry in 10 minutes? Students often choose to speak publicly about unprocessed trauma from their past, opening up about things they’ve never told anyone. And if GMU team members’ competitive success led them to an emotional breakdown, Pober was there to help build them back up.

In the quest to create formative experiences for high-school and college students, many extracurricular activities, such as competitive speech, encourage vulnerability. In college-essay workshops, music programs, and theater troupes, students are pushed to mine for meaning—to write, speak, sing, play, or act out their most personal thoughts and memories. This can be empowering: I competed in forensics in high school, sharing things in my speeches that I’d never even told my parents—and because of public speaking, I started college with far more confidence than I’d had four years earlier. But this emphasis on vulnerability also gives a tremendous amount of power to the people in charge. “It makes it easier for someone, if they’re a predator, to prey,” says Welty, who filed the Title IX complaint that led to Pober leaving George Mason.

I interviewed five men who described being sexually harassed by Pober as GMU students or young alumni. Their stories—strikingly similar, though they came from students and alumni who graduated more than a decade apart—suggest that Pober had a clear strategy for drawing select students close. He would, they said, often begin with a practice session in a hotel room or windowless office, where he’d wring all possible emotion out of a student’s speech. (“Get vulnerable!” was a Pober mantra.) By the end of the hour, multiple alums told me, they’d both be crying, sitting inches apart. “Peter would say ‘I love you,’” Tyree said. “And you always felt like you had to say it back.”

Most college competitors begin their forensics career in high school. More than 150,000 high-school and middle-school students participate in the National Speech and Debate Association (NSDA). The group touts big-name alumni such as Brad Pitt, Sonia Sotomayor, Bruce Springsteen, Elizabeth Warren, and Oprah. The college circuit, while considerably smaller, attracts the most die-hard high-school competitors, who tend to believe deeply in the stated mission of the activity: to speak truth to power, and to “make a difference in the world.” For many students, forensics is their first-ever opportunity to speak, uninterrupted, for up to 10 minutes and have people listen. Some will have substantial impact: Over the course of a season, competitors deliver their speeches in front of hundreds of people. If they advance to a national final round, they might reach tens of thousands, in person and online.

More than a dozen categories exist in forensics. Students can choose to deliver a prepared speech, perform an excerpt from a play, or read a selection of prose or poetry. Others make up speeches on the spot. In what is perhaps the most objectively bizarre category, “duo,” two competitors stand side by side, acting out a sequence of scenes—laughing, crying, “popping” from one character to the next—and never once looking at each other.

“It’s kind of like the island of misfit toys,” said Quincey Smith, who graduated from GMU in 2011, when I asked him what kinds of people are drawn to forensics. In the four years I competed in high school, I found the average “forensicator” to be quieter and more introspective than you might expect—and intensely relieved to have found a team that requires no athletic ability whatsoever. “It’s full of queer folks,” Smith said. “Young people who are, for the first time, learning to identify and understand themselves in new ways.”

Pober knew how to talk to speech kids. Addressing the high-school students at GMIF, he’d announce, with booming bravado, that speech would make them better researchers, writers, speakers, and citizens, multiple GMU alumni told me. Connor Manning, who attended GMIF as a student for three consecutive summers, told me they saw Pober as a kind of god. (Manning, who identifies as nonbinary, uses plural pronouns.) After years of feeling like they were floating—queer, closeted, and unsure what they wanted in life—Pober gave Manning something to work toward: “With the way he talked about speech and debate, I felt like I could do something that mattered.” Once Manning “got on [Pober’s] radar,” distinguishing themselves at camp and winning national awards, they said Pober would regularly seek them out at tournaments, asking about their speeches and their future. At the tail end of their last summer session, after most campers had left, Manning says Pober scheduled private practice sessions to work with them one on one. “It felt like, Wow, one of the most important people in this community actually cares about what I’m doing,” Manning said.

At camp each year, Pober invited rising seniors to audition for the GMU team. GMIF was an important recruitment mechanism for him—approximately half of all GMU team members in any given year had been campers first. (Manning joined the GMU team after auditioning the summer before their senior year of high school.) Pober sought out other, non-GMIF students at the high-school NSDA National Tournament, which he attended, and judged, for many years.

When Sean Cummings met Pober at nationals as a high-school junior, he was immediately “completely enamored,” he told me, and eager to join the team. But once he got into GMU, his parents were hesitant to let him go—no one in his family had ever left their home state of Massachusetts for college. Pober met with Cummings’s dad, promising him that his son would be joining a “family,” Cummings said. A few months later, in early 2011, when Cummings still hadn’t committed to the school, he said Pober called him on his cellphone and offered to increase his scholarship with money from Pober’s own pocket. “He said, ‘I believe in you that much. I want to invest in you that much,’” Cummings said. Cummings felt like he couldn’t say no. He joined the team that fall.

A few days before each tournament, Pober would sit in his office while a string of students cycled through, each modeling the suit they planned to wear. “Turn around,” he’d say, twirling a finger. If a student’s suit was pulling across the belly or thighs, Pober would point to the offending area and instruct him to either pay for alterations or return it. With women, Pober was particularly strict, according to Jenny Questell, who graduated from GMU in 2014. Female team members could wear only skirt suits; gemstones were strongly discouraged, as were sparkles and the color black. At tournaments, Pober would often approach his female students, gesture to their cheeks, and say, “More rouge.”

Even when they weren’t traveling in a pack, at tournaments, Mason students were easy to spot. Competitors from other schools sometimes called them “Peter’s robots.” The men, especially, were styled in Pober’s image, encouraged to select a tie from his personal collection. “He’d say he was building our team look,” said Mickey Cox, a former GMU Forensics student and coach. “But what he was really doing was marking people.”

Pober started every school year with a lecture on the “legacy” of GMU Forensics. At tournaments, team members had to embody the epitome of professionalism, friendliness, and class, according to the team handbook—because, as Pober would say, their association with GMU meant someone was “always watching.” And, to some extent, he was right. As the team danced during warm-ups, competitors from other schools would sometimes peer through the door. Many admired the GMU team from afar, former competitors told me, wishing they could be a part of it. Pober was determined to keep things that way.

Pober, staunchly opposed to social media, would allegedly use his husband’s Facebook account to monitor his students through their photos and profiles, according to several former GMU team members. Under one particular photo posted in 2012, a student wrote that she was laughing so hard she was “peeing her pants.” Soon after the comment was written, Pober responded with an email to the team titled “EVERYONE READ NOW!!!!” “I AM COMPLETELY AND UTTERLY DISGUSTED ABOUT THE UNPROFESSIONAL BEHAVIOR THAT OCCURRED TONIGHT,” he wrote in all caps. “Behave like the Legacy demands or get out! And I mean it!” Three years later, when a GMU coach shared a team joke with members of a different forensics program, Pober wrote, in another note to the listserv, “Do NOT EVER discuss outside of our team ANYTHING personal and playful. We MUST be able to play with each other NEVER in fear of implications outside of our family. NEVER!”

While Pober would regularly refer to the George Mason team as a “family,” he also made sure students knew they could be asked to leave at any time. Team members were required to re-audition once or twice a year. These tryouts weren’t just a formality, Pober assured the team. “This is a true audition,” he wrote in an email in 2014. “We expect substantial cuts to the roster.” Pober would often threaten to force students out. “Watch yourself, Tyler,” Pober wrote in a 2016 email to the then-student Tyler Watkins, when Watkins asked to reschedule a meeting with Pober over Thanksgiving break. “You might find the January auditions tougher than you think.”

Because a large portion of GMU team members came to Mason on speech scholarships—funds multiple alums told me Pober appeared to unilaterally control—the continuous audition process gave Pober tremendous leverage. For students who don’t live in Virginia, where GMU is located, the school’s sticker price is $48,552 a year. Without their speech scholarships, many former team members, almost all of whom came from out of state, told me they never could have gone to Mason. Occasionally, Pober revoked scholarships from team members, multiple GMU alumni said—some for a low GPA, others for smoking a cigarette on tournament grounds. If they crossed him, several alumni said, they knew they might have to drop out of school. (A university spokesperson did not address Pober’s power over scholarship money when asked.)

The surest way to get on Pober's good side, it seems, was to tell him things—the juicier and more personal, the better. Three times a year, the team gathered for “campfire,” an event designed by Pober ostensibly to facilitate bonding. For approximately four hours, students would sit in a circle at a tournament hotel or retreat facility and air their most intensely personal experiences: mental-health issues, family crises, eating disorders, sexual assault. (Depending on the location, the event only occasionally included an actual campfire.) For some, the event became a display of competitive emotion: Who could make the most people cry? Months after a campfire session, when everyone else had forgotten exactly what was said that night, Pober would remember. “He’d bring it up in conversation,” said Jim Welty, Pober's former student who filed the Title IX complaint against him, “saying offhanded things like, ‘Hey, is it your mom again?’”

Pober knew that Cummings’s mom was addicted to prescription painkillers. When Cummings started brainstorming topics for his speech in his senior year at GMU, Pober suggested one he thought would be particularly powerful: What is being the child of an addict like? Over the next few months, Cummings said he and Pober spent hours together in a conference room the size of a large closet, rehearsing the piece and discussing its subtext.

On some level, Cummings told me, he knew he probably shouldn’t have been doing the piece. He’d leave practice sessions in tears, unable to shake the memories that Pober had asked him to recall in painstaking detail. Cummings couldn’t just stop, though, because the piece did well, advancing to the finals at multiple national tournaments. He knew Pober wouldn’t want him to switch to something different. Even after watching him deliver the same piece for months, Cummings said Pober still cried every time he heard it.

On the GMU team, tears were how you knew you were doing something right. Sure, it was “a little weird,” Tyree said, when Pober would start to cry in the middle of a speech—but for the most part, students didn’t question it. They wanted to believe that their coach was genuinely moved by what they had to say.

Welty, who graduated from GMU last spring, wasn’t interested in getting personal with Pober. He watched his teammates use speech as an outlet for their deepest thoughts and feelings, weeping in front of rooms full of strangers—and if that worked for them, he thought, that was fine. But he’d pass.

Welty wasn’t dazzled by Pober the way many of his teammates were. For starters, before coming to GMU, Welty had never heard of him. When he first met Pober, Welty said, “I could tell he was taken aback that I didn’t know who he was.” During team meetings, Welty, a team captain, would openly challenge Pober, demanding explanations for his actions and decisions. When Pober cried during one particular practice session, Welty said he waited, unfazed, for him to stop, then coolly offered him a glass of water. “For once, the person who Peter was trying to favor wasn’t interested,” said a current junior on the GMU team, who asked to remain anonymous because of his continued involvement with GMU’s forensics program.

Starting freshman year, students on the GMU team talked about “senior trip” in hushed tones: “the highlight of college,” “the best night of my life,” “epic.” It was supposed to be the ultimate reward: After four years of demanding behavior befitting of the “legacy,” for one weekend Pober would let the rules slide. He’d put the seniors up in the best hotel, take them out for five-course meals, and buy them as much alcohol as they could keep down. “What happens on senior trip, stays on senior trip,” Pober would tell the senior class. On the trip, the line between student and coach would blur: They were all drunk; they were all friends. “It was Peter’s ritual of having us move from student to adult,” said Welty’s former teammate Lucas Muratore.

The last night of Welty and Muratore’s senior trip began at Galatoires, a swanky, jackets-required French-Creole restaurant in New Orleans’ French Quarter. The team—six members of the senior class—arrived in full suits, exhausted from a long day of competition in Baton Rouge and starving. But as soon as they started perusing their menus, Welty said, Pober told the team to put them down. “No, no,” multiple team members remember him saying. “Cocktails first.” After cocktails, two three-liter bottles of wine appeared. About two hours passed, Welty told me, before Pober allowed the team to order any food. “Peter turned the waiter away seven times,” filling up everyone’s glass as soon as it was less than half empty, said Alekhya Tallapaka, another senior on the team and Welty’s co-captain. (Both have since graduated.) When the team left the restaurant at 12 o’clock—two hours after closing time—almost everyone was drunk.

At dinner, Tallapaka said, she started to notice that Pober was treating Welty differently than the others: touching his arm and shoulders, holding his gaze, leaning in toward him when they laughed. The team kept drinking at a nearby bar after dinner, taking shots—and by 3 o’clock, Welty was struggling to stand. When the DJ announced that the next song would be slow, those who were there remember that Pober, also extremely drunk, his shirt mostly unbuttoned, pulled Welty in toward him. “We were all just standing around, watching as they slow danced,” Tallapaka said. “They were so close, and Jim was clearly so uncomfortable.” When the team said goodnight, around 4 a.m. in the hallway, breaking off to their separate hotel rooms, Pober asked Welty if he could speak to him in private. “It’ll just be a second,” Pober said, and Welty followed him into his room. Worried about her teammate, who she knew was severely intoxicated, Tallapaka waited for him outside, sitting with her back to the door.

Inside the room, Welty told me, he remembers Pober saying, “I want you to know that I have never worked with a student like you before.” He complimented Welty as a speaker and as a team captain. Pober allegedly told Welty that he’d been having problems with his husband and that they hardly ever had sex. Welty remembers Pober saying, “I just wanted to tell you that I have wanted to fuck you for years.”

Welty was in the hotel room with Pober for an hour and a half that night. For most of that time, he said, he was leaning against the wall, trying to keep his balance, head spinning, as Pober tried to persuade him to have sex. Eventually, when Welty announced that he was going to bed, Pober put his hand on his shoulder. “I was planning on taking advantage of you,” he said. “But you just had to take control.”(In a statement to The Washington Post last year, Pober said, “I admit that in February 2018 I had an inappropriate conversation with a student on a school trip, although I continue to deny several of the allegations regarding the content of that conversation.”)

The following afternoon, sitting on the ground by his gate at the New Orleans airport, Welty typed out a first draft of the Title IX complaint he would submit two days later.

“It was a major slipup,” said Jenny Questell, as we sat outside a café in Washington, D.C., in August. Pober had been harassing young men for years, she said. She told me she personally knew of six victims harassed by Pober from 2010, when she joined the team, to 2017. Jon Tyree and Sean Cummings, two of her best friends, each spoke with her after Pober solicited them for sex. But there was one big difference between Welty and the rest of the men Pober targeted, Questell said: At the time of the harassment, Welty was a student. The others were not.

At George Mason, the university’s Title IX office provides students with an avenue to report incidents of sexual harassment perpetrated by a professor. And Pober was smart, Tyree told me: “I think he knew there would be less chance of someone coming forward with alumni, whereas students might.” Pober would often invite the best students—usually his favorites—to stay on campus as graduate assistants, or GAs, coaching the team for two years after graduation while earning a significant scholarship for a master’s degree at GMU.

While these students still had access to the University’s Title IX resources as GAs, multiple former coaches told me that they felt completely dependent on Pober—for money and for their education. When contacted about this story, Michael Sandler, a university spokesperson, said the school had received no Title IX complaints about Pober before it heard from Welty in February 2018. “George Mason University takes enforcement of Title IX very seriously,” Sandler wrote in an email. “The university thoroughly investigates Title IX complaints, and when there is evidence of violations, it takes appropriate action.”

When Pober asked Cummings to stay on to coach, Cummings wasn’t interested. After he graduated in 2015, he moved to Boston, got a job at a prominent theater, and tried to put some distance between himself and forensics. But one year later, he moved back to D.C.—to work in an Eastern Market office building one block from Pober’s favorite restaurant. Three or four days a week, he’d see Pober sitting outside, drinking margaritas. Pober would wave; Cummings would sometimes walk over to say hello. Occasionally, they would plan to have a drink or dinner.

Before it closed down in the winter of 2017, Banana Café was a staple in Washington’s Capitol Hill neighborhood, with picture menus coated in heavy plastic. “Banana,” as Pober called it, wasn’t anything special. “It had good salsa, good queso, and their Cadillac margaritas were the strongest in town,” said Rob Warchol, a GMU alum. “That’s all Peter cared about when we were there.”

At any given time, Tyree told me, a “rotation” of people—mostly coaches and local alumni, primarily men—received regular invitations to join Pober for an evening at Banana. When Cummings met Pober at the restaurant one night in the summer of 2017, the evening started out like all the others he’d spent there: Pober ordered a round of margaritas, then another—assuring Cummings that “all this” is “on me.” Somewhere around Cummings’s fourth drink, the conversation turned explicitly sexual. “When you performed your piece for me, there were so many times when I wanted to bend you over and fuck you,” Cummings remembers Pober saying. Pober reminded Cummings of the second time they met—when Pober persuaded his dad to send him to Mason. “He told me he wanted to fuck me,” Cummings told me. “Even all the way back then.”

Cummings thought about reporting the incident, but he didn’t know who to tell. Even though he went back to campus often, to judge tournaments and help out with the team, he was no longer officially affiliated with the school. So he avoided one-on-one meetings with Pober, and tried to put it out of his mind.

Eight months later, Cummings got a text from Welty, who had been three years behind him in school. On the team, Cummings had been Welty’s captain and mentor. When, in a subsequent conversation, Welty recounted, word for word, his encounter with Pober in the New Orleans hotel room, Cummings told me that he could finish Welty's sentences: “The things he said to Jim were pretty much exactly what he said to me.” Cummings decided to share his experience with the administration, contributing his own story to Welty’s complaint. He wanted to make sure Pober couldn’t just move to another school, coach a different group of students, and start over. Now that Welty had been brave enough to come forward, Cummings told me, this had to be the end.

Pober was placed on administrative leave in February 2018, shortly after the team got back from New Orleans, and retired in May. He was later charged with four counts of felony embezzlement of university funds. (The charges were dropped in January 2019. Pober’s lawyer did not respond to a request for comment.) At first, Pober told students that he’d be gone only temporarily—and would still be available to practice over Skype. But the Skype meetings never materialized. Over the next few weeks, Tallapaka, Welty’s co-captain, met with individual members of the team, one on one, to tell them that Pober was gone, though at first she didn't say why.

No one was in the mood to prepare for nationals. Andrew Eilola, who took over as interim director of forensics when Pober left, rescinded some of Pober’s policies, lightening the mood. Flashy nail polish, sparkles, and flat shoes, he announced, would all be permitted at tournaments in the post-Pober era. The women on the team immediately started shopping for pantsuits.

But there was still the question of how to tell people what had happened. When they saw other teams at nationals, what would they say? By this point, most people had heard that Pober was out—he’d resigned from his leadership position in the American Forensic Association, the organization that hosted college nationals each year—but almost no one knew why.

Adelina Mitchell, a team member who had attended the senior trip with Welty, decided to write a poem. She’d been performing a selection of poetry on the #MeToo movement for months. A few weeks before nationals, with Welty’s blessing, she narrowed the scope of the piece by removing certain poems and adding others, now focusing specifically on sexual harassment in forensics. Similar incidents, she said, were also “open secrets” within the forensics community.

In October, Ken Young, the forensics director at Bradley University, another top college-speech program, resigned over an allegation of sexual assault. While teaching at a speech camp for high-school students about a decade ago, Young allegedly assaulted a fellow counselor, a 23-year-old woman, according to a social-media post the female counselor wrote about the incident. (Young did not respond to requests for comment on this article.) While no other harassment or assault allegations against top forensics coaches are public, several current and former forensics competitors, including Mitchell, told me that the problem extends far beyond Young and Pober. Mitchell expects to see more resignations in the future.

The final poem in the collection would be about the GMU team, written by team members, Mitchell decided. To write it, she drafted a few lines about how she saw Pober—“this imperial perfect person,” “revered as royalty”—then shared the document with five current and former team members. “Add whatever you want,” she wrote in an email. Over the course of three days, they edited the same Google Doc, adding lines and comments, sharing stories. It was important to Mitchell that the final product feel like a true collaboration. “We did this together,” she told me.

Before nationals, Mitchell ordered 500 teal ribbons printed with the phrase #IEToo (“IE,” or “individual events,” is another term for competitive speech), a hashtag inspired by #MeToo. The first day of nationals, she handed out 50. By the end of the tournament, all 500 were gone.

Mitchell sailed through the tournament’s preliminary rounds, quarterfinals, and semifinals. When she performed her poetry in the final round of nationals, more than 200 people were in the banquet hall, sitting on the floor and standing in the back. Many were wearing her ribbons. Welty, Tallapaka, and the rest of the GMU team were scattered throughout the auditorium, some holding one another, as Mitchell launched into the final stanzas of their poem:

We saw the Pedestal you Perched yourself upon
begin to crumble
So we, your loyal followers
We flocked to the base and
We kicked
We punched
We fought that throne
With tears in our eyes and holes in our hearts
Until that pedestal came crashing to the ground

And when the air cleared,
We smiled

Because we could finally see
The Legacy
of Honor
of Excellence
of Resilience
of Opportunity
of Empowerment
of Siblings
That we always were

Not because of you,
But in spite of you

The audience leapt out of their seats, cheering. In the poem, Mitchell had, in broad strokes, described the night in New Orleans: Pober pushing the team to celebrate, his teeth stained purple from the wine. It was the first time anyone had said anything about the incident in public. When the round was over, a group of GMU alumni—all men—found one another in the hallway outside of the banquet hall. They huddled in a circle, arms draped over one another’s shoulders, crying, while hundreds of coaches and competitors streamed past. “These were all people who were betrayed by Peter,” Tallapaka said, “some who had finally accepted that ‘Yes, this happened to me, too.’”

For support and resources related to sexual assault, call the National Sexual Assault Hotline at 1-800-656-HOPE.

This project is supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press and the Fetzer Institute.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?



Highly selective colleges have long struggled with racial and economic diversity. At 38 such institutions in the United States, more students come from households in the top 1 percent than from those in the bottom 60 percent. That is in part due to who applies to the universities: Many high-achieving students from a low-income or minority background don’t think they can get in to a prestigious institution, let alone pay for it—despite the fact that many such colleges have generous financial-aid packages—so they end up not applying.

A new study, however, found that a few extra dollars on a university’s part might go a long way in terms of changing that calculus for low-income students. The working paper, published by the National Bureau of Economic Research, examined the effects of a targeted-outreach campaign for low-income students at the University of Michigan.

The campaign, known as the High Achieving Involved Leader (HAIL) Scholarship, encourages highly qualified, low-income students to apply to the university, promising them four years of education free of tuition and fees. Students are sent a personalized mailing with all of the information, which costs the university less than $10 each to produce and send out; the students’ parents and school principals are also contacted separately. And the offer of free tuition isn’t contingent upon filling out financial-aid forms such as the Free Application for Federal Student Aid (FAFSA).

The researchers, led by the University of Michigan economist Susan Dynarski, found “very large effects of the HAIL scholarship offer on application and enrollment rates at the University of Michigan and more generally on college choice.” Students who received the mailing were more than twice as likely to apply to the University of Michigan compared with a control group. The percentage of low-income students enrolling at the university more than doubled as well—from 13 percent in the control group to 28 percent in the group of students who received the mailer.

The HAIL Scholarship is a new program, but even without it the students would likely have been able to attend the University of Michigan free of charge—90 percent of similarly situated high-achieving, low-income students receive full-tuition scholarships. But HAIL makes that fact explicit: It isn’t that students can apply and have the chance to afford the college—if they apply and are accepted, it is guaranteed.

The study shows one way to tackle the phenomenon known as “undermatching,” which is when high-achieving students don’t attend the most selective college they could get into. It’s something researchers have studied and worried about for several years now, since it tends to occur most frequently among low-income students. While it has been argued that there’s too much attention being focused on getting low-income students into a small number of elite colleges, as I’ve previously written, students who undermatch are less likely to graduate than their peers who don’t, and they forgo a range of social benefits accrued from attending an elite college.

In some cases, the students enrolling at Michigan wouldn’t have gone to college at all had they not had been contacted. “One-quarter of the enrollment effect (four percentage points) is driven by students who would not have attended any college in the absence of the treatment,” the authors of the report wrote. “The balance would have attended a community college or a less selective four-year college in the absence of the treatment.”

For the researchers, the next step in evaluating the program is to track its effects on students’ choice of major, graduation rates, and, in the long term, lifetime earnings. But for now, the results “show that a low-cost, low-touch intervention can strongly affect student application and enrollment at selective colleges.”

This is the second study in the past week showing the positive effects of a guarantee for low-income and minority students. A study published by the American Educational Research Association found that undermatching is reduced when low-income students know that their admission is ensured through state policy. The study examined the University of Texas system and its “top 10 percent plan,” which guarantees admission to students in the top 10 percent of their high-school class.

In both the Michigan and Texas studies, the students were given clear information that going to college—and to an elite college, at that—was a real possibility. As Kalena Cortes, an associate professor at Texas A&M and one of the Texas study’s authors, said, “Demystifying college-admissions policy is a pathway to greater inclusion.”



There’s a unique tradition in Montana. Once every decade since 1948, voters have taken to the polls to give the state’s colleges a report card and decide whether or not they want to tax themselves to support the institutions. The tax, known as the six-mill levy, is a small charge on property that helps fund higher education. It provides about $20 million in funding for the state’s public colleges each year.

The tax referendum has passed every time it’s been voted on since 1948, but this year the result wasn’t as certain, and education advocates feared the worst. But the measure ended up passing with 62 percent of the vote, the first time there has been an increase in support for it in four decades.

Montana’s referendum was seen as a bellwether of whether distrust of higher education would translate directly into decreased funding—and its passage was taken as a positive sign for colleges. But the question of why it passed is an interesting one. And one that institutions may do well to pay attention to as state funding for higher education continues to dry up.

Montana is already below the per capita national average on higher-education spending, Thomas Harnisch, a policy director at the American Association of State Colleges and Universities, told me. And if the referendum hadn’t passed, the defeat would have been a blunt blow to higher education in the state. “This ballot measure was one way to guard against potential cuts in program quality or tuition increases,” Harnisch says.

The primary reason for concern: Distrust in higher education. Last year, a Pew survey found that the majority of Republicans lacked strong confidence in higher education. And in a deep-red state such as Montana, where support for this 70-year-old tax has fallen decade over decade since 1978, that distrust could have meant $20 million less for the public universities.

“The political climate just seems so uncertain,” Bob Brown, a former state senator who is a member of the advocacy group supporting the tax, told me on Tuesday, before the election. “Before, we’ve been able to showcase what our universities have done in Montana,” he said, but “people were angry and seem to want to break things right now.” And he was worried that the thing they would break would be higher-education funding.

But the voters didn’t break anything, and that’s likely a reflection of a phenomenon that other polls have found: Even though Americans—particularly Republicans—distrust higher education, they’re fond of their local colleges. And one reason people love the colleges near them is that they see the good the institutions are doing, Brown says, and disassociate them from the national higher-education enterprise. And that may have helped propel Montana’s tax to reauthorization.

As an example, Brown cited the research that the state’s institutions do on seeds. “The more conservative, rural parts of Montana—maybe the parts of Montana most inclined to vote against the levy—could point to the fact that we did some wonderful research in drought-resistant and cold-resistant seeds,” he said. “That’s put a lot of money in a lot of farmers’ pockets.”

The victory in Montana might be instructive for other universities. One of the major themes of last night’s election was the partisan divide over education among white voters. The Republican Party is now solidly the home of white voters without a college degree. And that might mean that the Republican concerns over the value of college will be increasingly shaped by those who have not attended one. But Harnisch says enhancing the image of colleges as “economic drivers” may stem some of that animosity.



During a listening session on live television in February, President Donald Trump, surrounded by students and parents directly affected by school shootings, offered a bold suggestion. He highlighted a coach who had died protecting students just one week prior at Marjory Stoneman Douglas High School in Florida. “If he had a firearm, he wouldn’t have had to run, he would’ve shot, and that would’ve been the end of it,” he said. “If you had a teacher who was adept at firearms, they could very well end the attack very quickly.”

Teachers, administrators, and policy advocates around the country immediately scoffed at the idea of arming teachers. “This is bar none, the worst theory of action I’ve ever heard,” Shanna Peeples, a teacher from Texas and the 2015 National Teacher of the Year, tweeted in response to the president’s remarks. “Texas law allows schools to arm their teachers. That’s not a good thing. None of us are trained to respond to threats in the way law enforcement is.” Congress has positioned itself firmly against arming teachers, too, making it clear in recent legislation that it doesn’t want federal funding used for that purpose.

But on Wednesday night, The New York Times reported that the Trump administration might be closer to arming teachers than anyone expected. Betsy DeVos, the education secretary, is considering a proposal, according to the Times, to allow school districts to pay for firearms and firearm training through a grant program in the federal law governing K–12 policy known as the Every Student Succeeds Act, or ESSA.

The grants, which amount to $1.1 billion, are called Student Support and Academic Enrichment grants—Title IV is the shorthand for them—and they provide education funding to states for three categories of initiatives: “well-rounded education,” “safe and healthy students,” and “effective use of technology.” It’s the most flexible part of ESSA because states are able to define what those things mean and determine the best ways to achieve those goals—the federal government just has to sign off. To receive the funds, states have to submit an application to the Education Department, and once the state application is approved, districts apply for that funding from the state.

The proposal DeVos is reportedly mulling would allow the applications for funding to include firearms purchases and still be approved. States would likely have to include such a request in the safe-and-healthy-students category—which has to equal at least 20 percent of a district’s allocation.

The Education Department lists several examples of what it means to promote safe and healthy schools, including suicide and bullying prevention, child-sexual-abuse awareness and prevention, and drug and violence prevention. It doesn’t explicitly include guns. But the law doesn’t explicitly say the funds can’t be used for guns. According to Education Week, the issue was first raised in a letter from Texas officials who inquired about whether the grants could be used for firearms purchases. (Texas is one of the states that allows school districts to arm staff.)

It’s a loophole that the original architects of ESSA had not been thinking about when they wrote the legislation. Several congressional aides whom I’ve spoken with said the news caught them off guard.

“I am certain that Congress never intended—or even imagined—the Education Department would use Title IV funds to buy guns for school teachers,” Representative Bobby Scott, a Democrat from Virginia who is the ranking member on the House Education Committee, said in a statement. “However, even if there is confusion about Title IV’s flexibility regarding school safety, Congress made our position clear when we provided funds for school safety and violence prevention in the aftermath of the school shooting in Parkland, Florida.” The bipartisan STOP School Violence Act passed the House, 407–10, and the bill clearly stated that the extra funding could not be used to arm teachers.

Senator Lamar Alexander, a Republican from Tennessee and the chair of the Senate Education Committee, also played a major role in crafting ESSA. “I’m not a fan of arming teachers,” the former governor of Tennessee and U.S. secretary of education, told me in a statement. But the senator didn’t seem to rule out the idea that states could choose to do so if they wanted. “The safe-schools block grant for many years has allowed states to make the decision about how to use those federal dollars to make schools safer for children.”

Senator Patty Murray, the ranking member on the Senate Education Committee, was much less willing to let states make that decision. “Using these funds to add more firearms into schools is not only the opposite of what Congress intended, it is wrong and will make schools more dangerous and students less safe,” she said in a statement.

But the loophole in the ESSA law remains, and lawmakers are acting quickly to clarify it. On Thursday, Senator Chris Murphy, a Democrat from Connecticut who became one of the most outspoken advocates for preventing gun violence after the shooting at Sandy Hook Elementary School, introduced a bill to prevent the use of Title IV funds for the purpose of arming teachers.

The administration contends that the idea to allow states to use the Title IV funding to arm teachers is just that, an idea, and one that wasn’t theirs to begin with. But it’s an audacious and unpopular one—on both sides of the aisle.



A gunman entered Borderline Bar and Grill, in Thousand Oaks, California, late Wednesday night and opened fire. By the time the rampage was over, at least 13 people were dead, including one police officer and the gunman.

Thousand Oaks, California, is routinely named one of America’s safest cities for its relatively low number of crimes reported in FBI statistics. But such day-to-day statistics can’t neatly forecast mass shootings, which are seemingly random and can happen anywhere. The sites of mass shootings over the past few years have touched so many corners of American public life: churches, malls, synagogues, bars, concerts, schools, movie theaters, office buildings, even a yoga studio.

The bar, located near Pepperdine University and California Lutheran University, was frequented by college students, and it was hosting a “college country night” for students on Wednesday, according to Ventura County Sheriff Geoff Dean. Pepperdine confirmed on Twitter that multiple students were among the hundreds of people inside the crowded bar at the time of the shooting. Law-enforcement officials have not yet determined a motive. Southern California had another mass shooting on a similar scale just three years ago, in 2015, when 14 people were killed in San Bernardino.

Earlier this year, a spate of school shootings—in Parkland, Florida; Marshall County, Kentucky; and Santa Fe, Texas—ignited a new wave of activism around gun-control laws. Parkland, too, was rated one of the safest cities in the country before a gunman killed 17 people at Marjory Stoneman Douglas High School in February. The Parkland students made passionate calls for action, moving lawmakers in Florida, one of the country’s most gun-friendly states, to pass an array of gun-control regulations.

But efforts to weaken the influence of the National Rifle Association, the leading gun-rights advocacy group, in the state seem to have hit a wall. In Tuesday’s midterm elections, a candidate for governor who was backed by the NRA claimed victory, and the state may have two NRA-supported senators. The reporter Lois Beckett, who was with Parkland students Tuesday night, wrote that one student, Jaclyn Corin, said that she was “shaking with anger” over the election results. “It’s like the same feeling I was getting the night of February 14, so angry that I don’t know what to do with that anger,” Corin told those gathered. “We’re not going to stop fighting, I can tell you.”

During a press briefing after the Thousand Oaks shooting, Dean expressed an all-too-common sentiment. “I never thought I would see the things around the country that would happen, but I’ve learned it doesn’t matter what community you’re in,” he said. “It doesn’t matter how safe your community is; it can happen anywhere.”



On January 9, 2017, a Northwestern University sophomore named Jordan Hankins died by suicide in her dorm room in Evanston, Illinois. This week, two years after her death, her mother—Felicia Hankins—filed a complaint in federal court against Alpha Kappa Alpha, the sorority her daughter was pledging at the time of her death. The complaint alleges that Jordan Hankins, also a member of the university’s women’s basketball team, was subjected to “physical abuse including paddling, verbal abuse, mental abuse, financial exploitation, sleep deprivation, items being thrown and dumped on her, and other forms of hazing intended to humiliate and demean her” during the hazing process, which triggered her post-traumatic stress disorder and caused the prolonged anxiety and depression that eventually led to her death. (The lawsuit does not specify whether Hankins’s PTSD was a direct result of the hazing or existed before it.) Prior to Felicia Hankins’s complaint, most media coverage of Jordan Hankins’s suicide did not characterize it as having any relation to sorority hazing.

In late 2018, Hank Nuwer, the author of Hazing: Destroying Young Lives, estimated in a CNN story that across the country, at least one hazing death had occurred each year since 1970, and by CNN’s count, more than 77 fraternity hazing deaths had occurred since 2005. Death by Greek-system hazing, in other words, is hardly an uncommon tragedy in American higher education, and as Caitlin Flanagan wrote in her 2017 Atlantic story “Death at a Penn State Fraternity”—about the death of Tim Piazza, a sophomore pledge who died in the campus Beta Theta Pi house—a certain sequence of events tends to transpire when a young man dies as a result of fraternity hazing. The fallout from Jordan Hankins’s death has, unfortunately, begun to follow the familiar trajectory for hazing deaths on college campuses. But her case, if it can even be considered a hazing death, would be a somewhat unusual one.

In filing her complaint, Felicia Hankins has initiated what Flanagan describes as the “second half” of the hazing ritual—the half that gets invoked only after one of the pledges being hazed has died. After a “period of reflection” at the Greek house itself, in which the chapter will perhaps appoint a “blue-ribbon panel” to analyze what went wrong and then be shut down or suspended for a few years, then come condolences and condemnation from the university administration, and a media frenzy. Then the grieving parents “will hope to press criminal charges. Usually, they will also sue the fraternity,” Flanagan writes.

In a statement to The Atlantic, the headquarters of AKA emphasized the sorority’s “zero tolerance” policy for hazing: “We consistently educate incoming and current sorority members about behaviors that constitute hazing and the repercussions of such behaviors, including suspension and expulsion.”(Alpha Kappa Alpha, a historically black sorority, is governed by the National Pan-Hellenic Council, which also oversees eight other African American fraternities and sororities, and is distinct from the two umbrella organizations that oversee most other national social sororities and fraternities.) In a statement, a university spokesman said the school is “deeply saddened” by Hankins’s death. Meanwhile, the Gamma Chi chapter of Alpha Kappa Alpha has been suspended from campus since May 2017. It is reportedly scheduled to be reinstated this coming fall, but both AKA headquarters and the university declined to comment on why exactly the Northwestern chapter of AKA was suspended from campus, or whether it will return later this year.

But what usually follows, Flanagan writes, is this:

The parents will try to turn their grief into meaningful purpose, but they will discover how intractable a system they are up against, and how draining the process of chipping away at it is. They will be worn down by the endless civil case that forces them to relive their son’s passing over and over.

Jordan Hankins’s death and the ensuing lawsuit, of course, involve a mother seeking justice after the death of a daughter, not a son—a characteristic that would make the Hankins case something of a rarity in the long historical catalog of students who have died as a result of hazing. That list is made up overwhelmingly of young men, many of whom died as a result of alcohol poisoning or injuries sustained while extremely intoxicated. The two hazing-related deaths that have been reported since Piazza’s death, for example, were young men—a freshman pledging Phi Delta Theta at Louisiana State and another freshman pledging Pi Kappa Phi at Florida State—who died of alcohol poisoning in 2017. And as of September, police were investigating the death of another male student who was in the process of pledging the Alpha Phi Alpha fraternity at the University of California at Riverside. His mother alleges that “extreme hazing” was to blame.

There is some precedent, though, for sorority hazing deaths. Notable recent examples include two women pledging Delta Sigma Theta at East Carolina University, who died in a car accident in 2010 when a fellow pledge fell asleep at the wheel after an all-night hazing ritual deprived her of sleep, and a woman who died in a car accident in 2003 when she and several other Plymouth State students who were seeking membership in Sigma Kappa Omega, a sorority that was not officially recognized by the college, were passengers in an SUV that crashed during a hazing event. The families of the deceased filed lawsuits in both cases. The year before, two women pledging Alpha Kappa Alpha, the same national sorority to which Jordan Hankins was seeking membership, drowned in the ocean during a hazing ritual imposed by the chapter at California State University at Los Angeles. The two women’s families’ lawsuits were settled out of court, according to the Los Angeles Times, and as part of the deal, the sorority reportedly vowed to work harder to end hazing.

Hankins’s death also stands apart from most hazing deaths in that it did not happen during a hazing event or as a direct physical result of one. Often a coroner’s report or medical intake form can provide evidence to link the cause of death to Greek-life hazing activities—a lethally high blood-alcohol content level, perhaps, or injuries that align with activities involved in the hazing. Felicia Hankins’s lawsuit instead alleges that her daughter’s suicide was the result of the emotional trauma inflicted on her during hazing, which will likely make it more difficult to prove a link between any hazing that may have occurred and Jordan Hankins’s death.

Still, while Jordan Hankins’s death looks different in a few ways from the “typical” hazing fatality, the figures that have emerged in the aftermath—the anguished parent seeking justice through the courts, the Greek organization keeping mum on its role in the incident—are all deeply and sadly familiar. And as the organization accused of playing a role in her daughter’s death prepares to return to campus and move on from the incident, Felicia Hankins is embarking on what may be a long, and likely unrewarding, search for closure.



On Tuesday, court documents alleging a major college-bribery scheme described some outlandish behavior on the part of wealthy parents looking to give their children an edge in the admissions process. Allegedly, the parents were open to falsifying learning disabilities, athletic accomplishments, and grades on their children’s behalf, as well as paying millions of dollars in bribes.

These strategies are, of course, extreme, and the government argues that they crossed a legal line. But they are manifestations of a common desperation, one shared by many law-abiding peers of these wealthy parents, to get their children into top-tier schools. The sometimes outrageous strategies alleged in court documents are an indication of the extreme pressure that many affluent parents feel to ensure that their kids go to a “good” school, which will lead to a “good” career, which will lead to, they hope, a good life.

In a way, these parents have correctly assessed the high stakes of attending a highly prestigious college. “When you apply for a job and you went to Bucknell, versus an applicant where everything else is the same and the kid went to Yale, my bet is on the kid from Yale every time out of 10,” says Brian Taylor, the managing director of Ivy Coach, an admissions consultancy in New York City with clients from around the world.

In response to this dynamic, many parents want to do all they can to get their kids into a tiny set of exclusive institutions. “There’s little question that highly selective schools provide an earnings premium over the entire life course,” says Mitchell Stevens, a professor at Stanford University’s Graduate School of Education and the author of Creating a Class: College Admissions and the Education of Elites.

Stevens also brought up the phenomenon that researchers refer to as assortative mating, in which married couples tend to match up based not just on having a college degree, but also on the perceived prestige of those degrees. “If you’re worried about the people with whom your son or daughter is going to spend the rest of their lives with,” he says, “then you worry about where they’re going to go to school.”

Stevens says that the impulse to get one’s child into a top-ranked college can be just as much about parents’ wishes as their kids’. “These mothers and fathers live in a world in which the mark of good parenting is substantially tied to where one’s children are admitted to college and university,” he says. “There are bragging rights, and fear of shaming if one’s sons or daughters are not in the running for at least moderately elite colleges and universities.”

Indeed, admissions consultants I spoke to said that the parents they work with aren’t only concerned with their children’s long-term career prospects. “The parents want to brag to other parents at the grocery store when they’re standing in line,” Taylor says. “‘My kid got into Stanford.’ ‘My kid got into Harvard.’” Similarly, another admissions consultant I talked to, Maria Laskaris of the Massachusetts-based firm Top Tier Admissions, cited the possible motivation of “wanting that bumper sticker on the back of their car.”

Laskaris, a former dean of admissions and financial aid at Dartmouth College, says that many parents seem to hold the belief that if their children don’t enroll at their dream school, it will ruin their life. “And I think we all can realistically step back from that and say that the very best students make the most of whatever opportunities are afforded to them,” she said. In fact, a 2002 study suggested that those who were admitted to both a highly selective private school and a less selective public school, but chose the public school, ended up just as financially well-off in the long run as those who picked the private one. (Interestingly, students from the poorest households seemed to benefit from attending selective private colleges, while everyone else—including well-off students such as those at the center of this scandal—did fine pretty much regardless of where they went.)

“There are plenty of examples of young people who go to all kinds of different schools who lead very successful and fulfilling lives, regardless of the name on their diploma,” says Laskaris. That may be true, but it’s harder to convey on a bumper sticker.



John Engler was supposed to be a safe choice. He was a former Michigan governor and an alum of Michigan State University, and last January he was brought in to replace Lou Anna K. Simon, who had resigned following the Larry Nassar scandal. He was a Republican, and his board-appointed senior adviser was a Democrat; the board thought that would quell fears of overt partisanship. On Wednesday, Engler, not yet 365 days on the job, tendered his resignation.

The board was initially happy with its choice in Engler; the students and survivors of sexual abuse by Larry Nassar, who pleaded guilty to criminal misconduct for molesting seven girls and was accused of assaulting more than 150 people, were not. Engler himself had been accused of failing to respond to allegations of sexual assault at a women’s prison while he was governor. “To choose someone like John Engler, it tells us that they’re learning nothing from what’s going on,” Natalie Rogers, a student and co-founder of #ReclaimMSU, told The Atlantic at the time.

A full year had not lapsed before the board was at Engler’s throat. In April, Kaylee Lorincz, who was sexually assaulted by Nassar, said that Engler offered her $250,000 to drop her lawsuit against the university. One of his senior advisers called the accusation “fake news.” In June, emails revealed that Engler accused Rachael Denhollander, the first gymnast to accuse Nassar, of getting a “kickback” for helping lawyers “manipulate” other gymnasts into coming forward. Eight days after the initial report, Engler apologized. Then, in an interview with The Detroit News this month, he suggested that some Nassar survivors might be “enjoying” the “spotlight.” Finally it was one comment too many. Survivors, students, and advocates fumed. The board, which had been fielding calls for his removal since he was appointed, called an emergency session. Individual board members voiced their frustration.

He offered his resignation before the board had a chance to fire him. In an 11-page letter sent Wednesday night, Engler laid out his case for how his tenure had made Michigan State a better place. “I sought to move with urgency and determination to initiate cultural change at MSU,” he wrote. This was a job, he added, that he did not want, but which he accepted to help a university that he loved as it faced a crisis. There were now 24-hour counseling services; athletic trainers now had to report to doctors rather than coaches; the incoming freshman class was the most diverse in university history. “The bottom line is that MSU is a dramatically better, stronger institution than it was one year ago,” he said.

But even for the changes, Michigan State’s handling of the fallout from the Nassar tragedy has been a slow-rolling public-relations catastrophe. Since January of last year, revelation after revelation surfaced about the university’s handling of the Nassar case. The university claimed that an “independent investigator” had been hired to look into the case and assigned a university lawyer instead. An employee with ties to Nassar was also accused of sexual crimes. Simon was charged with lying to investigators. The number of applicants to the university dropped.

The board met on Thursday morning and voted to remove Engler immediately rather than allow him to serve until January 23, which he had requested in his resignation letter. The university must move on again. The crisis continues, and it’s become another interim president’s responsibility. Satish Udpa, an executive vice president at the university, has been tapped to take it on. The university is still looking for its next permanent president. But for now, as the trustee Brian Mosallam, one of the most outspoken critics of Engler, said during the meeting, the healing begins—again.



The Trump administration’s new policies on college sexual misconduct, spearheaded by Education Secretary Betsy DeVos, could drastically change how administrators handle sexual assault on campus. Under a draft version of the proposed rules, published on Wednesday by The New York Times, colleges and universities would be held responsible for far fewer incidents, legally exempt from investigating, for example, any assaults not reported to the school official designated to deal with these cases, and any that take place outside of school grounds. The alleged victim could also have to prove his or her case by the “clear and convincing” standard of evidence, as opposed to the lower “preponderance of the evidence” standard required by the Obama administration.

Plenty of schools will probably maintain the same, more stringent Title IX policies they had under Obama, at least at first. Wary of the optics of appearing soft on sexual assault, they’ll likely keep investigating off-campus incidents, and assume broad responsibility for Title IX violations, says Erin Buzuvis, a law professor at Western New England University who specializes in Title IX.* But eventually, Buzuvis expects schools to loosen up—if not in their written policies, at least in how they enforce them. “Now a university could, without fear of liability from the courts or the government, drastically decrease its overall attention to sexual misconduct.”

The proposed rules, once officially released, will have to go through a lengthy process before they’re approved, but if they hew closely to the interim guidance the administration introduced last fall and the proposed regulation reported by the Times, they could dramatically change the landscape of campus sexual-assault investigations.

So, what could the new rules look like in practice? Let's examine a hypothetical scenario where a  student is assaulted at a college party after these proposed rules take effect. Here’s what might happen next:

If the party is on campus

The university is required to investigate the allegation, provided that the alleged victim reports to the correct administrative official.

If the party is off campus

The college is not legally required to investigate. Spaces that fall outside university jurisdiction under DeVos’s new rules include off-campus housing, off-campus fraternity houses, and local bars and restaurants. Under the Obama administration guidance, schools were expected to investigate any assault that occurred between two students, regardless of where the assault took place.

Many—if not most—incidents of campus sexual assault and harassment occur off campus, says Sage Carson, a manager at the nonprofit Know Your IX. Eighty-seven percent of U.S. college students live outside campus bounds, and it’s common for assaults to take place in a student’s place of residence. Accusers at community colleges, where, in most cases, all students live off-campus, will be particularly affected by this clause in DeVos’s rules.

If the alleged victim reports the incident to “an official who has the authority to institute corrective measures” 

The university becomes legally “accountable” for the complaint, and is required to look into it. At this point, the alleged victim can either drop the complaint, enter into an informal mediation process with the alleged perpetrator, or start a formal disciplinary process.

If they do not report to “an official who has the authority to institute corrective measures”

The university is not required to investigate. It’s not yet entirely clear which campus administrators, and possibly professors, would qualify as officials with this kind of authority—and how, or if, the university would convey that information to students. If the alleged victim reports the incident to the residential advisor in their dormitory, a peer sexual-assault advocate, or another school employee who is not a designated “official,” the university bears no responsibility for the complaint. Under Obama-era guidance, a school had a responsibility to look into an alleged incident of sexual abuse if the institution knew, or reasonably should have known, about the allegation. That meant that if an alleged victim reported to an RA, the school was usually on the hook.

“Schools are being given a path to cover up sexual assault and sexual abuse, simply by saying it’s the survivor’s fault for not telling the right person,” says Carson. She cites Michigan State’s investigation into Larry Nassar as an example. In that case, she told me, several victims reported the abuse to coaches employed by MSU. Under this new rule, those employees would have no responsibility to relay what they heard to other university administrators.

If the alleged victim decides to move forward with a formal disciplinary process 

The disciplinary process varies from institution to institution. Some universities have a process where an investigator—typically an internal official—is appointed to try to determine what happened. Other institutions have an investigator gather evidence and have so-called hearing panels review the evidence and reach a final decision on whether a student is guilty or not.

Under the Obama administration's guidance, if an accuser could prove with a “preponderance of evidence” that the assault happened and that the accused committed the act, that was enough to prove guilt. But due-process advocates argued that was too low of a standard and could potentially let wrongful accusations slip through the cracks. They argued that the evidence needed to be “clear and convincing,” which is a higher standard of proof. The Trump administration allows institutions to choose what standard they will use—as long as it's consistently applied.

If they decide not to move forward with a formal disciplinary process

The Title IX coordinator would have to decide whether they could honor the student’s request, essentially, of confidentiality, Scott Schneider, a higher education lawyer at Husch-Blackwell, told me. The school may feel it has an obligation to act on any sexual-misconduct accusations, even if the student changes their mind about wanting to pursue a formal inquiry. If the coordinator decides that they cannot honor that request, then the disciplinary process will go forward.

If the alleged victim agrees to be cross-examined by the accused 

Under the new rules, the accused would be able to request to directly question the accuser, as part of the disciplinary proceeding. If the accuser agrees to that, they would also have the ability to cross-examine the accused, and the adjudication process would move forward.

If the alleged victim does not agree to be cross-examined by the accused

The accuser would likely drop their case, Carson told me, and the disciplinary process would end. The possibility of a direct confrontation with the accused in a disciplinary proceeding, deemed “inappropriate” by the Obama administration, is what “victims fear most” about the process, according to Carson. “That’s not because they’re worried about someone getting to the truth, but because they are so afraid of the power that the abuser holds over them,” Carson says.

If the accused is found guilty 

The accused might appeal the decision, if the school allows it. Schools are not required to allow students to appeal a guilty decision. However, under the now-rescinded Obama-administration guidance the college had to allow both the accused and accusers to appeal, or neither. The interim guidance from the Department of Education stipulates that an institution may allow appeals just for the accused, and a final rule is likely to reflect that interim standard—though it is unlikely that many colleges would limit the appeals if they offered them. The end result would vary on a case-by-case basis, but if the accused loses an appeal, they could face any number of punishments up to being kicked out of school.

If the accused is not found guilty

Depending on a university’s policy, the accuser can choose to appeal the decision.

If the accused decides to appeal the decision 

The information goes to a university leader, typically in the Office of the President, who will review the all of the documents related to the investigation and issue a final verdict. If, upon reaching a final decision, the accused is still unhappy with the decision, they can sue the university. And that’s where things could get interesting, Schneider says, because the new regulation, after the department’s rulemaking process, will essentially have the force of law. And it will be something that judges consider when deciding whether an institution violated Title IX.

If the accused decides not to appeal the decision 

The case is over.

The proposed rule is expected to be officially announced in September, and after it is introduced, it will likely take months—or even a year—to be finalized. But the Trump administration has already signaled to schools that things are changing, and that knowledge will likely begin to shape how they think about their long-term approach toward sexual misconduct on their campuses.

* This article originally misstated Erin Buzuvis’s university affiliation. We regret the error.



Editor's Note: In the next five years, most of America’s most experienced teachers will retire. The Baby Boomers are leaving behind a nation of more novice educators. In 1988, a teacher most commonly had 15 years of experience. Less than three decades later, that number had fallen to just five years leading a classroom. The Atlantic’s “On Teaching” project is crisscrossing the country to talk to veteran educators. This story is the first in our series.

On Rebecca Palacios’s first day in front of a classroom, one of her white students picked up his chair and threw it toward her, declaring that he refused to be taught by a “Mexican teacher.” It was 1976, Palacios was 22 years old, and many of her first-grade students were at the school because of a recently launched busing program in Corpus Christi, Texas, that the courts had mandated in an effort to racially integrate campuses. Large numbers of white students were now traveling across town to her school—Lamar Elementary—which for generations had served mostly working-class Mexican American children.

Growing up in the 1950s and ’60s, Palacios learned about American discrimination against Latinos first-hand. Her father, a World War II veteran who worked for the public-park service in Texas, spoke frequently about the daily humiliations of being a Latino in America—of not being able to eat in certain restaurants or use certain water fountains. He would recount stories of teachers prohibiting him from speaking Spanish in school, sometimes hitting him when he spoke it with his friends.  

The use of Spanish was still discouraged in Corpus Christi school buildings when Palacios became a student in the 1950s. Designed to funnel Latinos into vocational tracks such as factory jobs or secretarial work, these segregated schools didn’t offer academically ambitious students like Palacios the advanced classes they needed to attend college. But thanks to her high-school teachers—both white and Latino—who created the necessary coursework using their own resources, Palacios became the first person in her family to go to college.

Those teachers had a profound impact on Palacios's life, and, in turn, on the thousands of students she taught in Corpus Christi. Over the three decades that followed that September day in 1976, Palacios would go on to became one of the most distinguished early-childhood educators in the country, renowned for promoting her students’ sense of agency, intellectual curiosity, and love of learning. The arc of her career captures some of the major shifts—desegregation, resegregation, and declines in public funding—that have shaped America's schools over the past several decades.

Palacios’s first two years of teaching at Lamar Elementary were some of the toughest in her life, she recalled earlier this year, sitting in her office in downtown Corpus Christi. Palacios retired in 2010 and now works as a consultant for the district as a coach of teachers. Behind her, pictures of Palacios’s five children, her husband, and their grandchildren dotted a bookshelf.

The Corpus Christi busing program that began around the time Palacios started teaching was the byproduct of a ruling by a federal judge in 1970 that made the city the first in the United States to extend the 1954 Brown v. Board of Education Supreme Court decision to Mexican American students. Prior to the 1970 ruling, Corpus Christi officials argued that Brown only applied to black-white segregation. It wasn’t until Jose Cisneros and 23 other fathers—all members of the United Steelworkers union—sued the district for isolating Latino students in inferior, underfunded schools that the courts recognized Mexican American students as a minority group with their own history of discrimination in education. In establishing that Latino children deserve the same protections as their black peers, the Cisneros v. Corpus Christi Independent School District ruling had far-reaching consequences for every school in the nation: It prompted additional rulings that eventually extended Brown’s protections to all historically marginalized students of color.

Around the same time that the Corpus Christi district started providing funding for its busing program, the federal government began sending money to schools serving children who’d grown up in poverty. Project Follow Through, which was part of President Lyndon Johnson’s War on Poverty, funded intensive coaching of teachers, medical care for children, engagement of families in school governance, and parenting classes. These investments, which at their peak had a budget of $60 million, contributed the most to Palacios’s teaching successes as a bilingual early-childhood educator early on.

About half of Palacios’s first-graders at the time were white, and many of their parents weren’t happy about the new busing arrangement. But many supported the idea of integration and lobbied district officials to bring in new resources to the school, like art and science supplies, and advanced classes. Palacios recalled those years as an intense period of growth that pushed her to go beyond traditional teaching methods focused primarily on content delivery and memorization. She yearned to create engaging learning environments that challenged her students to ask questions, deliberate answers with their peers, and learn how to integrate diverse ways of thinking about the world.

In 1982, Palacios enrolled in the graduate school at the University of Texas in Austin to work toward her doctorate in education, which would, she reasoned, help her ground her innovations in the latest research, and give her more authority to bring those changes beyond the confines of her classroom. The following year, Eduardo Torres, who had left Lamar to become the principal at Zavala Elementary, asked Palacios to join his team as an early-childhood educator, where Palacios ended up working for 24 years, focusing her methods entirely on preschool-age children.

While at Zavala, Palacios developed an innovative curriculum—in collaboration with her colleagues—that the district adopted for all preschools from 2001 to 2010. Palacios’s two-week units were based around the theme of families: human, animal, plant, and insect “families.” With that change, for instance, rather than reading a book on farm animals, and then developing vocabulary by answering simple questions about the book, and memorizing key words and concepts, Palacios’s lessons now integrated multiple disciplines in every hour of instruction, including literacy, math, science, and social studies. As students investigated farm animals—often guided by their own questions about the topics—they could leverage and build on previous knowledge they learned while exploring other families.

Because integration of different disciplines helps children engage with new concepts through familiar themes and patterns, such approaches can make classrooms more inclusive and engaging for diverse children with varying skills and interests. A child who finds certain math tasks, like memorization and repetition, boring or too abstract, for example, forgets that she is engaging in those tasks by counting the wheels of the farm trucks or comparing the shapes of the buildings on a farm.

For Palacios, such approaches—which fall under the rubric of teaching “the whole child,” in education jargon—require well-trained educators, sustained funding for learning materials, such as building blocks or paint, and supportive administrators like Torres. “When my teaching partner and I would come to the office of Mr. Torres, asking for something to implement our latest innovation, he’d always say, ‘If it’s for the kids, we’re going to make it happen.’ Having that stance was a critical base for my ability to succeed and stay in teaching as long as I did.”

Just as Palacios reached a degree of success in her sixth year of teaching at Lamar, the Corpus Christi school district, the courts, and the Cisneros plaintiffs were sparring over the mechanics of busing. District officials were constantly changing bus routes and school assignments, which exacerbated the growing resistance to integration among many parents. By 1982, the plaintiffs agreed to end the court-mandated busing, settling for a district program that would allow students to attend schools outside of their neighborhoods but wouldn’t cover the cost of transportation. The court also mandated increased funding to high-poverty schools like Zavala and Lamar as the means of fulfilling the 1970 ruling.

This marked the end of one of the 20th century’s most significant civil-rights battles. Corpus Christi schools soon resegregated. Today, 93 percent of students at Zavala Elementary are Latino, and 95 percent are poor. Roughly two-thirds of its students, meanwhile, are labeled as “at risk of dropping out” based on their achievement levels and disciplinary issues. Most of the extra local funding that came as a result of the Cisneros lawsuit also disappeared over time, compounded by the deep state cuts, which have reduced the overall pool of funding for all of Texas public schools.

Meanwhile, Palacios continued to refine her methods, developing “journals” to detect what her 4-year-olds—who typically can’t yet read or write fluently—learned every day. Students would respond to Palacios’s questions by drawing pictures and telling stories about them, using new concepts and words they’d learned. She also started coaching parents every six weeks, including by modeling lessons on how to teach reading at home, which she said became one of the most effective strategies she’d implemented in her career.

“The hardest part about teaching before I retired was seeing the disintegration of support for public schools,” Palacios said over lunch at a local restaurant, during an all-day training session for preschool teachers she organized in collaboration with the district. “What I’ve seen over time, especially in the last 10 years, [is that] there are so many new, unfunded demands and programs. STEAM [science, technology, engineering, the arts, and mathematics] initiatives, for example, require resources. You can’t talk about granite if the kids haven’t seen granite. You can’t talk about water pressure, water displacement, or buoyancy without water droppers, PVC pipes, or water tables that make up these experiences.”

When touring classrooms in the Corpus Christi district a few years ago as part of a teacher-training initiative, she observed that worksheets had replaced the paint, glitter, and building blocks that once dominated preschool learning spaces.

Despite the retreat from integration efforts and anti-poverty programs by the courts and the government, Palacios still views the legacy of the Cisneros case as crucial progress. “Schools resegregated, but the eyes were open: Separate is not equal.”

These days, as Palacios coaches dozens of teachers in Corpus Christi, she talks to them about the importance of leadership and advocacy, just as much as she talks about teaching practices. Palacios tells them how she created a pre-kindergarten professional association, which, at one point, convinced the school board not to cut the district’s paraprofessional positions. She also hosted a yearly open house in preschools for school-board members and administrators across the district to show them the promise of effective and engaging teaching through sustained funding.

“I know it takes a lot of energy to do all that, but if you’re going to complain about it, it's never going to make a difference,” Palacios said at the end of a long day of coaching teachers. “You’ve got to be in there, be the advocate, and make the changes for the children.”



The school year at Santa Fe High School in Santa Fe, Texas—roughly 30 miles outside of Houston—was winding to a close. The seniors would be honored on Saturday during a baccalaureate ceremony, and they were just weeks away from graduation. Then, on Friday morning, a 17-year-old male student allegedly opened fire on campus, killing 10 people, according to Governor Greg Abbott, and wounding several others. There is one suspect in custody, and at least one other person of interest who has been detained.

Many high-school students live with a constant feeling of uncertainty about school shootings—not if there will be another one, but when and where. Such shootings are rare, but each new one, each breaking-news alert announcing several more children who have been killed, can trigger widespread fear. If it can happen there, it could happen here, the thought goes.

In a clip that has gone viral in the aftermath of this morning’s shooting, a student put that feeling plainly. When asked by a reporter if she was surprised that there was a shooting at Santa Fe, she replied: “It’s been happening everywhere. I've always kind of felt like eventually it was going to happen here, too.” Her peers agree: A majority of teens—57 percent—say they worry that a shooting could happen on their campus, according to a Pew Research Center survey released last month. For nonwhite teens, the fear is even more pervasive, with 60 percent of black teens and 73 percent of Latino teens sharing it. Parents, too, are worried, with 63 percent saying that they are at least somewhat concerned about a shooting on campus. Still, mass shootings at school are quite rare, and the likelihood of one actually occurring at any one particular school is minuscule, but they happen, often enough to stir a strongly felt anxiety for millions of students, teachers, and their families.

And of course, it’s not just school shootings themselves that perpetuate this anxiety, but all the attendant consequences, such as false alarms and regular drills at schools across the country. That is true of Santa Fe High School, where in late February—weeks after the deadly shooting in Parkland, Florida, where a gunman killed 17 people—students and teachers reported hearing “popping sounds” outside of the building. The noises sounded like gunshots, so, as they had been trained to do, the campus launched into its crisis plan, and went on lockdown. The event was concerning, wrote Leigh Wall, the superintendent of the school district, in a memo to the community, especially in light of the Parkland shooting.

Emergency lockdown drills have become more common in the years that followed the shooting at Sandy Hook—in some states they are required by law. It’s unclear how many, if any, lives these drills save, but one thing is certain: They normalize preparing for something that should be abnormal, re-writing curricula to include reading, writing, arithmetic—and staying alive in the event of an active shooter.



When the Trump administration released its school-safety report last month, it landed with a thud—and only partly because it’s a clunky 180 pages. Many of the recommendations in the report, authored by the Federal Commission on School Safety, are aimed at fostering a better school climate—how a school feels to the students who attend it—whether that’s through improved access to counseling and mental-health services or a greater emphasis on social-emotional learning. But other recommendations were met with derision, such as a proposal to rescind an Obama-era rule urging schools to be mindful of whether they might be punishing minority students at a higher rate than white students.

Study after study has shown that black students are unevenly suspended or expelled from schools nationwide. The 2014 school-discipline guideline was the Obama administration’s attempt to remedy that. The Trump commission, however, argued that deciding how students should be disciplined should not be the federal government’s job, but the teachers’. Both administrations, at least, agreed that discipline was also a matter of school climate—something educational leaders have been trying desperately to improve.

A new study by the Rand Corporation, a nonpartisan think tank, shows just how crucial improving the climate at school can be to helping decrease suspensions. In 2013, Pittsburgh’s public schools were trying to figure out how to remedy racial disparities in discipline. At the time, they had mandatory diversity training for staff that sought to address implicit bias and discrimination in the classroom, but they wanted to do more. Restorative practices, which are nonpunitive ways of responding to conflicts, had been gaining momentum among school leaders as a way to help curb suspensions.

So the district got a grant to try out restorative practices in their schools, randomly selecting 22 of them to receive the restorative treatment, while 22 others went about business as usual. The basic goal of restorative practices is to build relationships between teachers and students, so that students will be less likely to act out. Teachers start off the school year by asking students innocuous questions such as what the students did that summer. As the year goes on, the questions grow more personal and introspective, and students build trust with the adults and classmates around them. Of course, formal times for such events can be time-consuming, so it is often recommended that the practices are woven into the day. As much as restorative practices aim to change how students are disciplined, they also seek to change the behavior that might require discipline, improving the overall climate of the school.

The researchers examined the schools—elementary, middle, and high schools—over two years and found that restorative practices greatly reduced the number of school days lost to suspension, particularly among elementary schoolers. The dip was most acute among black, low-income, and female students, and nonviolent offenses drove the decline. “It seems to be the case that restorative practices were providing an alternative that the staff felt they could use to enforce discipline, [especially] for offenses that weren’t extremely serious in the sense of endangering people’s safety,” John Engberg, a researcher at Rand, told me.

On top of that, the report found no negative impact on the test scores of students in the schools that had restorative treatments. “That seems to indicate that keeping kids in school is not leading to a deteriorating learning environment,” Engberg said. And, for their part, teachers who worked at schools with the restorative treatments rated their climate as comparatively more positive.

There were some things that restorative practices couldn’t change, though. Sure, academic outcomes, such as test scores, didn’t drop, but they didn’t improve either. The decline in suspension rates was most stark for elementary-school students rather than middle- or high-school students, where the effects were more muted, suggesting that early intervention is important.

Changing a school’s climate is a long process, Catherine Augustine, a senior researcher at Rand, told me.“This isn’t Let’s go to a one-day workshop and we’ll all be restorative,” she said. It takes work from teachers, faculty, staff, and students. And the researchers themselves still have a lot of work to do in terms of understanding how restorative practices work and whether the gains made by the elementary schoolers will carry forward through middle and high school. Still, the bipartisan goal of improving school climate may not be as elusive as it seems.



If everyone strived to embody the core values listed on fraternities’ and sororities’ websites, the world would be a lovely place, full of “true friendship,” “mutual support,” “personal integrity,” and, of course, “scholarship.” The hundreds of thousands of undergraduate students currently in Greek organizations, a new study suggests, could stand to focus a bit more on that last one.

The study, from the economists William Even and Austin Smith of Miami University, in Ohio, examined data on about 34,000 students at a large public university in the Midwest from 2007 to 2017, and found that joining a fraternity or sorority hurt students’ grades. On average, the GPAs of the students who joined the Greek system were 0.1 points lower in the semesters after they joined than what would have been expected based on their grades before. Smith described the effect of joining a fraternity or sorority to me like this: “You can think of it as having all of your professors be worse than average.”

Smith and Even found that the grade drop-off was larger for the students who just barely made the university’s 2.5 GPA cutoff for Greek eligibility. The researchers compared these students to students who fell just under that threshold of 2.5, since all of their GPAs were very close numerically, just on the opposite sides of an arbitrary cutoff. When comparing those two groups’ performance, the researchers calculated that the cost of joining a fraternity or sorority for those with these lower eligible GPAs was an average of about 0.25 points in the semesters after joining. That’s almost the difference between, say, a B and a B- average.

An important distinction is that in Even and Smith’s sample, Greek-affiliated students had GPAs that were an average of between 0.1 and 0.2 points higher than non-Greek-affiliated students’ (which is a bit larger than the advantage that fraternities claim to have nationally). But that likely has more to do with the fact that the university in question required Greek-affiliated students to keep their GPAs above a certain level, and with the types of students who join Greek organizations in the first place—on average they are whiter and come from wealthier families than the students who don’t join. So fraternities and sororities’ members may get better grades, but that doesn’t mean fraternities and sororities make their members’ grades better. Instead, as Even and Smith found, Greek organizations likely make them worse.

The academic downsides of joining a Greek organization were especially large, Even and Smith found, during pledging, when hopefuls undergo “new-member education,” which often includes lots of drinking and sometimes includes hazing. (Even and Smith also noticed that during pledging, students were more likely to pick easier classes.) But in cases where students were suspended from their Greek organization as a result of a disciplinary action, their academic performance actually tended to start improving, in line with what the researchers would’ve predicted had those students not joined in the first place.

Even and Smith’s study didn’t pinpoint what it is about Greek organizations that might hurt their members’ grades (and it’s worth noting that Greek systems at other colleges might have slightly different cultures that could produce different results), but previous research provides a hint. A 2009 study found that Greek-affiliated students drink more than non-Greek-affiliated ones, and other studies have suggested that students’ grades tend to slip if they start drinking more than they did in their earlier college years.

What Greek organizations lose in academics, one could argue, they might make up for in improving their members’ job prospects, perhaps through strong professional alumni networks. Indeed, the students in Even and Smith’s sample tended to make more money—roughly 15 percent more—in their first job after graduation if they’d been in a fraternity or sorority. But that doesn’t mean Greek organizations are themselves the cause of their members’ increased earnings. Students who join the Greek system, Smith told me, tend to have higher-earning, better-educated parents. “And those types of students are probably more likely to have a higher salary early in their careers than those with lower socioeconomic status,” Smith said. After accounting for that, he and Even wrote in the paper that they found “no evidence of a Greek salary premium.”

Students in fraternities and sororities do seem to get better grades and go on to earn more money right out of college—but this research suggests it’s for reasons other than their membership in the Greek system. Their houses may actually be holding them back.



“When you know better, you do better,” the old adage goes, and colleges are working hard to make sure that their students know not to wear racist or offensive costumes this year.

The University of Oklahoma sent a memo reminding students that costumes should be “designed respectfully.” The University of Wisconsin at Madison told students that they’re free to wear what they want, but “racist, crude, and culturally insensitive costumes say a lot about the person wearing that costume.” Ohio University, too, posted a reminder to “use good judgment when choosing a costume.” It’s become a tedious, if necessary, routine for institutions hoping to avoid a scandal.

However, some people’s impulse to wear racist or offensive Halloween costumes hasn’t gone away. Year after year, there are reports of people wearing blackface, Native American headdresses, and caricatured costumes of Mexican people. A cursory search of this Halloween season yields yet more examples of such behavior.

Last week, a student at Brigham Young University donned blackface to attend a Halloween party on campus. The response was swift. Administrators started investigating the “improper and offensive behavior.” Ed Carter, the director of BYU’s School of Communications, apologized on behalf of the school, where the student is enrolled. The student, for his part, apologized as well.

A 2017 Cato Institute survey on free speech and tolerance found that 65 percent of college students think that they should be able to discuss offensive costumes without administrator involvement—though they were sharply divided when the data were broken down by race. Seventy-one percent of white students said that students should be allowed to discuss and resolve issues on their own, while 56 percent of Latino students and 43 percent of African American students responded the same way. But if student conversations alone could solve the issue, a fresh crop of offensive costumes would not likely make headlines every October.

Of course, the scope of racist or offensive Halloween costumes isn’t limited to college campuses. Take the first-grade teacher in Iowa, for example, who wore blackface to a Halloween party earlier this month as the character Lafawnduh from the movie Napoleon Dynamite. Or consider the father in Kentucky who dressed himself as a Nazi soldier and his son as Adolf Hitler last week as a historical costume for a trick-or-treating event.

“I think it was in bad taste for me to let my child wear that, probably for me to wear that,” the father told a local news outlet. “It didn’t occur to me. I thought it was a bad decision on my part.” This is a common refrain after a racist or offensive costume is donned: It didn’t occur to me that it was wrong.

Megyn Kelly, whose unceremonious departure from NBC following her remarks about blackface received national attention last week, made a similar plea. “What is racist?” the former daytime host asked. “You truly do get in trouble if you are a white person who puts on blackface at Halloween or a black person who puts on whiteface.” And, in her initial estimation, that shouldn’t have been the case. “That was okay when I was a kid, as long as you were dressing like a character,” she said.

A day later, Kelly apologized for her comments. “I’m sorry,” she said. “I defended the idea, saying as long as it was respectful and part of a Halloween costume, it seemed okay. Well, I am wrong, and I am sorry.”

Some argue that offensive costumes are a form of free expression, or, more innocently, done in the name of cultural exchange. However, as Mia Moody-Ramirez, a professor at Baylor University, notes, “Cultural appropriation is distinct from equal cultural exchange because of the presence of power inequities that are a consequence of oppression.”

Not to mention the fact that “cultural exchange” is rarely the argument made in the aftermath of such events. The “it didn’t occur to me” argument is more common—despite an annual cycle (2017, 2016, 2015, 2014, 2013, and so on) of offenses, apologies, and claims of unawareness. And on campuses, regardless of routine efforts by administrators and fellow students alike to nip any offensive costume ideas in the bud, the incidents are guaranteed to happen anyway. News outlets may just as well have a skeleton post titled “College Student Facing Discipline After Blackface Incident” prewritten and waiting on Halloween.

The old saying that with knowledge comes a change in behavior isn’t holding up. This year, there were incidents of blackface, at least one of which happened on a college campus. A father and son dressed as Nazis. And that was all before October 31. More instances seem inevitable because after years of warnings, America still hasn’t learned.



One of the most striking patterns in yesterday’s election was years in the making: a major partisan divide between white voters with a college degree and those without one.

According to exit polls, 61 percent of non-college-educated white voters cast their ballots for Republicans while just 45 percent of college-educated white voters did so. Meanwhile 53 percent of college-educated white voters cast their votes for Democrats compared with 37 percent of those without a degree.

The diploma divide, as it’s often called, is not occurring across the electorate; it is primarily a phenomenon among white voters. It’s an unprecedented divide, and is in fact a complete departure from the diploma divide of the past. Non-college-educated white voters used to solidly belong to Democrats, and college-educated white voters to Republicans. Several events over the past six decades have caused these allegiances to switch, the most recent being the candidacy, election, and presidency of Donald Trump.

Last night’s results confirm that the diploma divide is likely here to stay—especially if the GOP maintains its alignment with Trump and the nationalist, anti-immigrant sentiments he hangs his hat on. The gap is likely to be one of the most powerful forces shaping American politics for decades to come.

The Democratic and Republican Parties looked a lot different in 1952, when the American National Election Studies—surveys of voters conducted before and after presidential elections—were in their infancy. The Republicans, to some extent, were still regarded as the party of Lincoln, even though they had shifted their focus to courting southern white voters, causing black people to leave the party. Meanwhile, the Democrats were the party of a coalition that pushed for social services—the party of the New Deal. There were far fewer college-educated Americans at the time, but the white Americans who did have degrees tended to vote Republican, and those who didn't sided with the Democrats by a significant margin.

This split was relatively stable for decades and then, steadily, it began to change. “The shift in whites without a college degree away from the Democratic Party begins as the Democratic Party becomes identified as the party of civil rights,” starting in the 1960s, Robert P. Jones, the CEO of the Public Religion Research Institute, told me. Disaffected white southern Democrats, in particular, fled in droves.

Party realignment doesn't happen overnight. Just because some voters swing across the aisle in one election doesn't mean they’ll quit the party they've identified with their entire lives. Still, strong support for the Democrats among whites without a college degree, borne out of economic incentives—and racial resentment—began to wane. In their book, The Rise of Southern Republicans, the scholars Merle Black and Earl Black call this shift the “Great White Switch.”

From the mid-1990s to 2008, the diploma divide was small, if not negligible. Even though the Democrats had become the party of civil rights and a broad, multicultural coalition, they were also still the party of unions, which were largely made up of non-degree-holding whites. Therefore, white people with and without college degrees were equally as likely to be Democrats or Republicans.

But in 2008, the election of Barack Obama, a black man, signaled that the Democrats were becoming the party of progressive racial politics. “Obama’s presidency simplifies the politics of race,” Michael Tesler, an associate professor of political science at UC Irvine, says. “If you were a low-educated white, you were much more likely to know about the partisan differences on race [after Obama] than you were before.”

That change didn’t show up in the party-affiliation data right away, but that’s common, Tesler says. It often takes more than one election for people to switch their party identification. But by 2012, white voters without a college degree were distinctly more likely to vote Republican than those with college degrees.

In the 2016 election, 48 percent of college-educated white voters voted for Trump, compared with 66 percent of non-college-educated white voters. A Marist poll in October of this year found that 55 percent of non-college-educated white voters approved of the job Trump was doing, compared with just 39 percent of college-educated white voters. When Supreme Court Justice Brett Kavanaugh squeaked through a Senate confirmation hearing with a sexual assault allegation in tow, 54 percent of non-college-educated white voters supported him, compared with 38 percent who had gone to college. And the partisan diploma divide held steady last night, reflecting a divide in values between those with degrees and those without.

There’s a question that splits Americans neatly in two. Every year, on its American Values Survey, the Public Religion Research Institute asks Americans whether they “think American culture and way of life has mostly changed for the better, or has it mostly changed for the worse,” since the 1950s. Fifty percent of Americans say that it’s gotten better in this year’s poll, and 47 percent say that it has gotten worse.

But for white voters, the answer to that question is split by education level. Fifty-eight percent of college-educated whites this year say that America has gotten better since 1950, while 57 percent of non-college-educated whites say that it’s gotten worse. When President Trump says “Make America great again,” the again is instructive. He’s capitalizing on the nostalgia that non-college-educated white voters have for America’s past. “That harkening back to a supposed golden age where things were better has a really, really strong appeal for whites without a college degree,” Jones said.

That nostalgia, however, is for a time when black Americans and other minority groups had significantly fewer civil rights. And a Republican rhetoric that centers a longing for an era of white prosperity, rife with racist violence against black people, is why it’s impossible to understand the diploma divide without accounting for racial resentment. Needless to say, black Americans and other minority groups aren’t as keen on returning to the past.

When researchers control for voter attitudes on race in addition to white voters’ education level, Tesler says, the diploma divide disappears. No other factor, he says, explains the education gap as well—not economic anxiety, ideology, income, or gender.

David N. Smith, a professor at the University of Kansas, came to a similar conclusion when he and Eric Hanley took a dive into the 2016 American National Election Survey. They found that demographic data such as education are important predictors of which party someone votes for. But “when you bring the attitudes variables into account as well, what emerges is that attitudes loom even larger than demographics,” he told me.

Here’s how he put it: If you look at white people who voted for Trump—both those with college degrees and those without—and identify everybody with a high level of resentment toward minorities, women, and Muslims, as well as those who want an arrogant, assertive leader, there’s almost no one left. The vast majority of Trump voters share those sentiments, the researchers found, regardless of education level.

The GOP has come around to Trump. As my colleague McKay Coppins wrote, “Trump’s conquest of the Republican Party is complete, and the former ‘fringe’ has become so thoroughly intertwined with the ‘establishment’ that the two are virtually indistinguishable.”

The growing diploma divide is less a result of non-college-educated white voters becoming Republicans, and more of college-educated white voters finding that they can’t fully support the party anymore. “What's happened since 2016 is that the low-educated whites have kind of plateaued in their support for the Republicans,” Tesler says. “But you've seen this trend increase [of] high-educated whites [moving] towards the Democrats.”

Smith told me that from 2015 to 2017, the Weidenbaum Center at Washington University in St. Louis conducted a monthly panel survey—where the same statistically significant number of people are interviewed each month—that cataloged Republican attitudes toward Republican candidates. Over time, those who supported Ted Cruz, who called Trump a “sniveling coward” during the campaign, and those who supported Marco Rubio, who called him a “con man,” tended to come around to Trump.

But the voters that stand out, Smith said, are those who initially supported John Kasich. “They, in many instances, agree with Trump on policy issues, but the best data indicates that they are uncomfortable with him personally,” he said. “There are key aspects of his rhetorical style, of his governing style, that they don't like.”

Kasich has been on a crusade in recent weeks combatting the Republican rhetoric around the migrant caravan. “The Lord doesn’t want” America to build walls around around itself, he told CNN. And that wasn’t the first time he’d expressed concern about the state of the Republican party, and its rhetoric, as it has inched closer and closer to Trump. “If the party can't be fixed,” Kasich told Jake Tapper in October 2017, “then I’m not going to be able to support the party. Period. That's the end of it.”

Jones argues that the logic is simple. “The risk that the Republican Party runs by becoming the party that’s opposed to immigration, that’s worried about the country becoming more diverse,” he said, “is that they will turn off college-educated whites.”

But the consequences of the diploma divide are not just evident in the demographics on Election Day. Hidden in that gap is a threat to higher education itself. Last year, Pew issued a sobering survey. “Republicans have soured on higher education,”  the survey declared, and it threw people into a frenzy.

Sixty-seven percent of Republicans, the survey found, had “some” to “little” confidence in colleges as institutions. A number of factors contribute to this distrust, the rising cost of tuition and the perception of a liberal bent at colleges among them. And if one major party believes that higher education is an engine of liberal indoctrination, and that party’s voters are increasingly likely not to have attended college, the political benefits of an anti–higher education stance are obvious.

That puts the budget lines for public colleges, in particular, at risk. Decades of funding cuts by state governments have already hit the institutions hard. And these cuts, in turn, have driven an increase in tuition costs and more animosity toward higher education. As Michael Grunwald recently wrote in Politico, “The next big Republican culture war will be a war on college.”

As the Republican party continues to cozy up to Trump, whose political career began by questioning the legitimacy of the first black president, and who rests his laurels on hostile anti-immigrant sentiments, more moderate Republicans—who, often, are college educated—will likely continue to flee. And the GOP will have even less of a reason to try to cater to the college set, or to embrace higher education–friendly policies. The diploma divide is wide, and the closer Republicans embrace Trump, the wider it may get.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

At least 2,000 children have now been forcibly separated from their parents by the United States government. Their stories are wrenching. Antar Davidson, a former youth-care worker at an Arizona shelter, described to the Los Angeles Times children “huddled together, tears streaming down their faces,” because they believed that their parents were dead. Natalia Cornelio, an attorney with the Texas Human Rights Project, told CNN about a Honduran mother whose child had been ripped away from her while she was breastfeeding. “Inside an old warehouse in South Texas, hundreds of children wait in a series of cages created by metal fencing,” the Associated Press reported. “One cage had 20 children inside.”

On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.

About 65 million years ago, shortly after the time of the dinosaurs, a new critter popped up on the evolutionary scene. This “scampering animal,” as researchers described it, was likely small, ate bugs, and had a furry tail. It looked, according to artistic renderings, like an especially aggressive New York City rat. And it had a placenta, an organ that grows deep into the maternal body in order to nourish the fetus during pregnancy.

The rodentlike thing would become the common ancestor of the world’s placental mammals, with descendants that include whales, bats, dogs, and humans, among many other species. And today, the placenta might hold the key to one of the most enduring mysteries in human medicine: Why do women suffer much higher rates of autoimmune disease than men do?

Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

There’s a moment about 15 minutes into the first episode of Years and Years that made me gasp at its audacity, its prescience, its visual horror. The new six-part series from the British writer Russell T. Davies (Doctor Who, A Very English Scandal) charts the life of the Lyons family over the course of 15 years, starting in 2019 and ending in 2034. It’s a kitchen-sink saga that barrels its way through births and marriages and betrayals, but also through the near-future. In 2024, Stephen Lyons (played by Rory Kinnear), a financial adviser, is at home with his wife, Celeste (T’nia Miller), both rushing their way through the morning routine. When the camera turns to their teenage daughter Bethany (Lydia West), her face isn’t recognizably human. Instead, she looks like a 3-D version of a Snapchat puppy, with vast cartoon eyes, wagging pink ears, and a brown snout. When she talks, her voice is grotesquely distorted, a robotic hallucination of a child’s cadence. “I might have to start limiting filter time,” Celeste says in the same exasperated, noncommittal way that you might think, I really should spend less time on Twitter.



Classrooms full of crying students. That’s how the scene is often described. In November 2005, at Kalamazoo Central High School in Michigan, every classroom was full of teary-eyed students—jubilant, but teary-eyed.

They had good reason to be happy. The vice principal had just announced over the P.A. system that anonymous benefactors would be paying the students’ college tuition—all of the students across the entire school district, from kindergarten to high school, in perpetuity. Starting in 2006 and continuing until this day, the students have taken part in a social experiment of sorts.

The school district saw results: Its enrollments jumped, and so too did the number of teachers in the district. The district was able to build new schools for the first time since the 1970s. The offer brought change not just to Kalamazoo schools, but to the whole city. Businesses came to the area, and with them workers anxious for their children to get free tuition. These families would still have to pay room and board and other college fees on their own, but to have tuition covered surely alleviated at least some of their fears, and reduced the likelihood of these kids having to take on a lifetime burden of student debt.

It was the beginning of a wave. As the college-affordability crisis reaches a fever pitch, and students have to take out more and more loans to obtain what is becoming to be seen more as a necessary credential, some leaders have stepped in to pick up some of the slack. There are more than 350 local and state college-promise programs scattered across the country—California, for example, has 43—many of which are modeled after the Kalamazoo Promise program. Some are funded by the government, others, like Kalamazoo, through philanthropy. And the offerings tend to have the same goal: increase college-attainment rates, which in turn provides an economic bump to the area.

Tennessee launched the Tennessee Promise—a statewide program offering high-school seniors the opportunity to go to any of the state’s community colleges tuition free—in 2014. The City of Chicago also announced a tuition-free community-college program that year. Meanwhile, researchers were busily studying the effectiveness of such programs. “Free college” looked doable on a larger scale. Perhaps, the thought went, the federal government could use its financial muscle to incentivize states to adopt the program. Even if states couldn’t pay for four years of college for every student, just covering two years would be a significant benefit—and one report from 2014 showed that free two-year programs in all 50 states could be funded using federal financial-aid resources that were already readily available. Many two-year free-college proposals would apply only to two-year associate’s degrees, while some would also cover two years of tuition for students pursuing four-year degrees.

The free-college movement had momentum, though it was an uphill sort, the kind that needs prodding and support to keep going. And for a time, it received plenty—from advocates, members of Congress, and even the president. By January 2015, tuition-free college was a significant part of higher-education-policy discussions when then-President Barack Obama delivered his State of the Union address.

Americans should be able to upgrade their skills affordably, Obama argued. Forty percent of American college students attended community college, he pointed out, suggesting that that was the place to start with free tuition. He called out two places—one close to his home, another in the deep-red South—that he thought were examples of the achievable excellence he was talking about. “Tennessee, a state with Republican leadership, and Chicago, a city with Democratic leadership, are showing that free community college is possible,” Obama told lawmakers and those gathered on Capitol Hill. “I want to spread that idea all across America, so that two years of college becomes as free and universal in America as high school is today.” It was a noble goal. Two years of college for free. It wasn’t exactly the Kalamazoo Promise, but it was ambitious.

As Robert Kelchen, an assistant professor at Seton Hall University, put it, “The Obama administration’s proposals really thrust [free college] into the national spotlight.” Even though the plans the administration laid out in its higher-education platform had no chance of becoming law, he told me—primarily because Congress was not as supportive of the idea as the president was—they still received a flood of attention.

The free-college snowball kept gaining mass. After all, it was election season. Senator Bernie Sanders of Vermont announced that he would be introducing legislation to make college tuition free for all, so did Senator Elizabeth Warren of Massachusetts. There were debates where tuition-free college was a primary point of contention between Sanders and Hillary Clinton—who originally argued that she believed in “affordable college” but not “free college.” Later in the campaign, she changed her tune, announcing a proposal to eliminate tuition at public colleges for families making less than $125,000 annually.

Free college became a litmus test for liberals. And when Clinton won the Democratic nomination for president, progressives applauded Sanders for pushing her to the left on the issue. But there was a voice conspicuously missing from the conversation about free college: Donald Trump.

The Republican nominee’s campaign was light on specifics about higher education. But in May 2016, Inside Higher Ed spoke with Sam Clovis, a former co-chair of the Trump campaign, about the candidate’s higher-education platform. Would Trump, they asked, support free college? The answer, Clovis said, would be “unequivocally no.”

That didn’t matter too much, many thought, because of how heavily favored Clinton was to win the presidency. A national program for free college—at least for some students—still seemed possible. And then Trump won.

Promise programs are a little more complicated now than they were in 2005. And “free college” has become an inaccurate catchall term for all kinds of plans intended to make college more affordable, if not literally free. But there are substantial differences between the many kinds of plans at the local, state, and federal levels—the ones that exist, and the ones being proposed.

Tuition-free-college programs, for example, tend to be “last dollar in.” That means a state will cover the cost of tuition after grant aid—federal Pell grants and other financial aid that students don’t have to pay back—is applied. Unfortunately for many low-income students, though these programs do ease their burden considerably, “last dollar in” plans often mean they have to use their grant money for tuition, and can’t count on it for other costs associated with college such as books, fees, housing, and food. Most states that have adopted—or are proposing—some form of “free college” programs are using tuition-free models.





“To some extent, it’s almost the new way to do financial aid in some states,” Kelchen told me. As opposed to doling out money through merit aid, the kind where the amount of money a student receives is based on things like their grade point average and SAT score, he said, as some states did in the 1990s and 2000s, states are shifting to more need-based aid, or implementing programs to make sure that tuition is covered.

The other popular model, though less frequently practiced, is debt-free college. Advocates for expanding college access have argued that debt free is preferable because it addresses the extra expenses associated with college. But the extra aid for students, of course, has to be paid for somehow.

Trump’s victory brought with it a strategy shift for free-college advocates—as hopes for a national tuition- or debt-free college plan grew dim. “You saw that [free college] was not going to happen on the national level anytime soon,” Kim Dancy, a policy analyst at New America, a left-leaning think tank, told me. Republicans controlled the House, Senate, and White House, and free college wasn’t necessarily a galvanizing issue for them —particularly as distrust of higher education as an institution grew on the right. So, she said, advocates turned their attention to the states. “We focused more on the state level and started looking at what different states are doing that is good and well thought-out.”

One of those states, of course, was Tennessee. The state’s tuition-free model had become the standard for what it looked like for a state to do free college well—especially after the state began extending the tuition-free college offer to adult and returning students in addition to recent high-school graduates this year.

But the disadvantage of focusing on state programs is that states simply have less money. “Doing it at the state level is uniquely challenging just because there are much more severe budgetary constraints,” Dancy told me. That means there are limitations on the amount of money they can—and are willing to—spend on free-college programs. But it also means that states put restrictions on programs to keep costs down, including limiting the tuition-free program to coursework at community colleges; only allowing students to study certain subjects; or requiring students to live and work in the state for several years after the program is complete. And then there are sometimes eligibility requirements on the front end. Some states only offer free tuition to recent high-school graduates with a certain GPA; or they may mandate a drug test.

It’s no secret that state funding for higher education is drying up. And when states have to make budget cuts, higher education will likely feel it before K–12 schools do, and before other social programs such as Medicare. Many of the tuition-free-college plans in states are not tied to mandatory state spending—instead, they are discretionary, and can change from year to year. The dangerous cocktail of low and uncertain funding can lead to terrible consequences for students. Oregon, which made tuition free at community colleges in 2016, for example, could not fully fund its program in 2017, meaning that some qualified students who were eligible for free tuition were denied it.

State tuition-free and debt-free programs are immensely helpful to some families—and are helping students pay for an education that is becoming more necessary for many careers—but they aren’t putting college within reach for everyone. Not yet. And advocates don’t want to miss the opportunity to get it right before it’s too late.

“There’s momentum right now around college affordability and a lot of that is driven by middle-class students and—to some extent—wealthier students, as well, who are increasingly struggling to keep up with the cost of college,” Dancy told me. “And that is creating this window of opportunity to fix the system. But I worry that if we fix it in the wrong way, then we’re still going to leave a lot of people behind.”

Abraham Lincoln signed the Morrill Act on July 2, 1862, in the midst of the Civil War. The act granted blocks of land that could be sold to fund universities to each state. The mission of those institutions: to train young people in “agriculture and mechanic arts.” The act laid the foundation for the public higher-education system we recognize today, and the resulting institutions are now staples of their home state, such as Purdue University, the University of Missouri, and the University of Minnesota.

But the colleges created by the Morrill Act, in most cases, excluded black students in the early decades of their existence—segregation was still the law of the land, and former Confederate states did not allow black students to attend the institutions. So the Morrill Act became a blessing to some, not all. Twenty-eight years later, that oversight was acknowledged and addressed. Benjamin Harrison signed a second Morrill Act into law in 1890, creating land-grant colleges that specifically served black students.

This is all to say that the United States has a history of well-intentioned, but imperfect, college-access programs. But history also shows that these programs can be improved and expanded, if there is the will to do so.

“We’re at a really critical time, and we can get this right at the beginning,” Tiffany Jones, the director of higher-education policy at Education Trust, told me. There are proposals on the table right now in states across the country. Two recent reports, one from the Institute for Higher Education Policy (IHEP), the other from the Education Trust, drill into what “getting it right at the beginning” looks like.

The Education Trust used an “equity driven” approach to critique the existing state tuition-free-college models and proposals as of 2018. They used eight criteria:

It found that the dozens of proposed—and currently enacted—programs across the country fail to meet all of the criteria. IHEP similarly found that current programs in Tennessee and New York were not benefiting low-income students as much as, perhaps, they should.

“We know policy makers have to make tough choices,” Jones told me, but she believes that low-income students should be top of mind when states and local governments are crafting tuition-free models, as opposed to an afterthought.

But, as Sara Goldrick-Rab, a professor of higher education at Temple University, writes in her book Paying the Price, “low-income families are not alone—middle-class families are squeezed too, as the current system often expects more from them than they can give.”

Still, addressing college affordability, Mamie Voight, IHEP’s vice president of policy research, argues, is kind of like having multiple injuries. If someone has a broken leg, it’s probably best to get it stabilized before dealing with smaller cuts. The nicks and scrapes heal faster, but the parts of the student body that have been hit the hardest need the most attention.

Several advocates I spoke with argued that the only way to get enough aid for those who need it most is federal intervention. States would need to be incentivized in some way.

That’s where Senator Brian Schatz of Hawaii believes he can help. In March, Schatz introduced a debt-free-community-college bill, and it was met by fanfare in the higher-education community. It even picked up some national steam, and Senate Minority Leader Chuck Schumer included the plan in a video highlighting the Democrats’ higher-education platform. The plan includes a dollar-to-dollar match for states from the federal government for two-year and four-year free-college programs. States would submit their proposals to the government, and the government would match the states’ financial commitment on all approved plans. This bill would reward the states that have already created free-college programs and incentivize those that haven’t to get on board.

The only problem: Democrats have little to no power on the Hill right now. So even well-crafted, well-intentioned bills come off as little more than virtue signals in this partisan Congress. Still, Schatz says, there’s a chance Democrats return to power after the 2018 election. And if they do, “we have decided that we want students to be able to afford college,” Schatz told me. And what I’m trying to do is make sure we have legislation to do just that.”

But until and unless there’s a blue wave, it’s all hypothetical. The bill does not have a reasonable shot at passing without a Democratic House, a Democratic Senate, and, potentially, a Democrat in the White House—and even then, all Democrats may not be on board, let alone Republicans. Democratic aides are working to convince lawmakers that debt-free college is an idea they should get behind.

The Kalamazoo promise was simple. Live here, go to school, and your tuition is paid for. But with scale comes complication. The idea of free college is still in its infancy—it took 28 years to get the Morrill Act right, and it’s only been 13 since the Kalamazoo Promise. But in the current political climate, the path forward is murky and winding, and that makes it hard for the movement to maintain the momentum it needs. The window of opportunity for nationwide tuition- or debt-free college is still ajar. The next couple of elections could close it completely or throw it wide open.  

However, the idea of truly free college for everyone—a system where fundamental public education is no longer considered K–12 but K–16—appears out of the country’s grasp for now, and people have, for the most part, stopped reaching.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

At least 2,000 children have now been forcibly separated from their parents by the United States government. Their stories are wrenching. Antar Davidson, a former youth-care worker at an Arizona shelter, described to the Los Angeles Times children “huddled together, tears streaming down their faces,” because they believed that their parents were dead. Natalia Cornelio, an attorney with the Texas Human Rights Project, told CNN about a Honduran mother whose child had been ripped away from her while she was breastfeeding. “Inside an old warehouse in South Texas, hundreds of children wait in a series of cages created by metal fencing,” the Associated Press reported. “One cage had 20 children inside.”

About 65 million years ago, shortly after the time of the dinosaurs, a new critter popped up on the evolutionary scene. This “scampering animal,” as researchers described it, was likely small, ate bugs, and had a furry tail. It looked, according to artistic renderings, like an especially aggressive New York City rat. And it had a placenta, an organ that grows deep into the maternal body in order to nourish the fetus during pregnancy.

The rodentlike thing would become the common ancestor of the world’s placental mammals, with descendants that include whales, bats, dogs, and humans, among many other species. And today, the placenta might hold the key to one of the most enduring mysteries in human medicine: Why do women suffer much higher rates of autoimmune disease than men do?

Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.

There’s a moment about 15 minutes into the first episode of Years and Years that made me gasp at its audacity, its prescience, its visual horror. The new six-part series from the British writer Russell T. Davies (Doctor Who, A Very English Scandal) charts the life of the Lyons family over the course of 15 years, starting in 2019 and ending in 2034. It’s a kitchen-sink saga that barrels its way through births and marriages and betrayals, but also through the near-future. In 2024, Stephen Lyons (played by Rory Kinnear), a financial adviser, is at home with his wife, Celeste (T’nia Miller), both rushing their way through the morning routine. When the camera turns to their teenage daughter Bethany (Lydia West), her face isn’t recognizably human. Instead, she looks like a 3-D version of a Snapchat puppy, with vast cartoon eyes, wagging pink ears, and a brown snout. When she talks, her voice is grotesquely distorted, a robotic hallucination of a child’s cadence. “I might have to start limiting filter time,” Celeste says in the same exasperated, noncommittal way that you might think, I really should spend less time on Twitter.



AVE MARIA, Florida—In this enclave in Southwest Florida, the lush, pruned golf course and ritzy subdivisions are eclipsed only by the magnificent church that marks the town’s distinctive Catholic character. The town is also home to a similarly named religious institution, Ave Maria University, which was founded in 2003. The institution—and the master-planned community in which it is now located—is the brainchild of Tom Monaghan, the billionaire founder of Domino’s, who is originally from Michigan and known for his Catholic philanthropy.

Ave Maria is still in its infancy compared with the big names in Catholic higher education. But Monaghan has a vision. He wants to build a campus that is more religious than the Notre Dames of the world, and this patch of Florida, he decided, was the right location for that. The secluded community feels less like the rest of the state and more like a paradise for those who want to live faithfully. One student, Anne Marie Schlueter, a sophomore, told me the institution’s mission of faith-driven education drew her here from Ohio; it was a university where she could build a strong Catholic foundation with which to answer critical questions about the world. But the young institution still has important questions to answer of its own—many about itself—as it grows and navigates debates within its central Catholic identity.

Last week, another religious philanthropist from Michigan drew a spotlight on the conservative-leaning university: Education Secretary Betsy DeVos. And her appearance here animated an ongoing debate about whether there is any good way for Catholic institutions to invite speakers to campus from the world of American politics, at a time when neither political party is perfectly aligned with Catholic teaching, and there is little breathing room in the political discourse for anyone else.

Perhaps it was inevitable that even in an environment as welcoming of DeVos’s policies as this, there would be opposition to the university honoring her by inviting her to speak on campus. Though the Church has clear views on a number of matters—such as its opposition to all forms of abortion—others, such as whether the death penalty is ever warranted, are a bit more muddled.

As Miriel Reneau, the valedictorian of the 2009 graduating class at Ave Maria, told me, “there is a trend to equate faithful Catholicism with allegiance to the Republican Party in its current form—which is complicated—that I am convinced is a very misguided trend, and ignores key parts of Catholic social teaching.” Those who opposed the secretary’s appearance on campus, for the most part, were not upset because of her vocal support of elementary and secondary school-choice, as many who protest DeVos are, but they were concerned about how her policy moves affect the poor and downtrodden, as Catholic social teaching requires. They also expressed unease about what she represents as a member of an administration whose leader, in their view, could be perceived as having a shaky foundation in sexual ethics.

There are unclear areas in what Catholicism recommends—for example, the Church holds that members should care for the poor, but what that means in practice is debated—that make it hard to associate the religion with one party exclusively. But the rigidity of polarized American politics isn’t accommodating of a cafeteria-line approach to political positions: There’s no taking a little from one party, a little from another, and a little from a third. It’s all or nothing. That often means that if someone picks a side in one policy, he or she will be criticized for aligning with the broader agenda of that side.

Richard Garnett, a professor at Notre Dame who writes about freedom of speech and religion, put it like this: “It’s going to be a rare politician [who is] going to line up with the catechism on all fronts.” So, predictably, when a political figure is invited to speak at a Catholic event, it is going to be divisive. “It’s almost always going to be true given American politics and the way our parties divide up,” he said.

This has been true for many of the leading Catholic institutions that have sought to honor various political figures over the past decade. When Barack Obama was slated to deliver the commencement address at Notre Dame in 2009—as many presidents have done in the past—students and members of the Catholic community protested. They did so again when John Boehner and Joe Biden were awarded the prestigious Laetare Medal, which recognizes Catholics for “outstanding service to the Catholic church and society.” Last year, a group of students walked out as Vice President Mike Pence delivered the commencement address at the university. One way or another—whether it was more liberal Catholics protesting Republicans, or more conservative Catholics protesting Democrats—the Church’s moral and social teachings could be used to justify opposing the speaker.

DeVos, this year’s commencement speaker at Ave Maria, has gotten quite familiar with protests these last 15 months. Opposition to her presence has become something of a ritual. Since being confirmed in February of last year, her campus visits across the country, from Kansas to Nebraska to Florida, have been accompanied by groups standing—both literally and figuratively—in opposition to her perceived policy goals. Some of the most notable protests of the past year, at Bethune-Cookman University and the University of Baltimore, have occurred at graduation ceremonies—during which students have stood and turned their backs in opposition. Often the protesters have their sights set on issues that extend far beyond DeVos: Students in multiple cities have told me that they are protesting what she represents as a member of the Trump administration more broadly.

On Saturday, students stood as DeVos delivered her address. But this time it was different: They were standing, alongside their family and friends who joined them for their honored day, in rousing applause for the secretary who delivered an address on the importance of service. “You’re blessed to live in the most successful and most free country in the history of human civilization. But there are those who are vulnerable, those who are forgotten right around us,” she told the captive audience in a fieldhouse-turned-events-center. “What will you do to put your newly gained skills to work in the service of others?”

The address continued like this, with line after line of ordinary commencement-speak boilerplate. The room was dim aside from spotlights that illuminated the stage. And the crowd was indistinct but for the motion of heads nodding in agreement as the secretary spoke, buoyed by applause, and a handful of laugh lines made it clear she was playing to a friendly audience. There was no honorary degree conferred—the most common way of honoring a commencement speaker—but there was no doubt that the platform, and praise from the university’s president, represented some kind of honor.

Weeks before the address, in an open letter to the Naples Daily News, dozens of alumni took issue with their university’s decision to honor someone whose actions they found inconsistent with Catholic social teaching. Moreover, they were concerned about what it meant for a university, particularly a Catholic one—in honoring DeVos with the slot of commencement speaker and by praising her in such glowing terms—to essentially align with the Republican Party.

“While we encourage AMU to invite speakers of diverse political, social, and religious backgrounds who are open to respectful dialogue, a public endorsement of an incumbent Cabinet member and her achievements from the University’s most senior administrator rings as an endorsement of a specific political agenda,” the alumni wrote. “We are concerned that this endorsement degrades AMU’s liberal-arts character that allows students to ‘become actually free in … mind and judgment’ and casts the University in a pointedly partisan light.” (In a separate letter, more than 100 alumni responded, defending the university’s decision.)

In an opinion column in The Daily Caller on Thursday, Jim Towey, the president of the university, did more than suggest support for DeVos’s actions—he explicitly applauded them. The university gained national attention last fall for its response to Hurricane Irma, since it sheltered hundreds of people, including elderly immigrants and children, who had been displaced by the deadly storm. However, it was not only the power of prayer that helped the university through the difficult time, he wrote in the column. “In a strange way,” he said, “we also had the Obama Education Department’s Office of Civil Rights (OCR) to thank for teaching us how to weather eight years of Category 5 storm conditions.”

He argued that the Obama administration had been overzealous in the guidance letters it had issued, particularly the 2011 “Dear Colleague Letter” that outlined how universities should deal with sexual assault on campus. The goal of ensuring colleges work diligently to respond to sexual violence was widely shared, but, he argues, its implementation was flawed. “Enter Secretary DeVos,” he continued, “who immediately saw the imbalanced landscape and came to the rescue.”

Towey echoed that endorsement during his speech introducing DeVos on Saturday. He thanked her for “leveling the playing field” by lessening the regulatory burden placed on the institution by the Obama administration. And he congratulated her on the work she had been able to do over the last 15 months despite having a scarcely populated political staff at the department. But, most importantly, he concluded, she was invited, and they were grateful to have her, “because Ave Maria has a tradition at commencement of bringing in role models for our students: Individuals of high character and civility; leaders who conduct themselves graciously, and embrace moral principles and moral truth in the pursuit of higher purpose.”

The ringing endorsement in—at times—partisan terms, some alumni argue, is exactly the kind of thing that an administration, particularly at a Catholic institution, should avoid.

By explicitly endorsing policies associated with a Republican administration, Reneau, who signed on to a letter opposing the secretary, said, it “raises reasonable doubt about the ability of the university to critically evaluate the relevant political questions.” And faithful Catholics well-versed in the social teachings, she continued, “will understand that really neither political party in their contemporary forms in the United States espouses what Catholics are really required to believe and practice on the political front.”

On a more practical front, a de facto endorsement of the Republican Party might isolate politically liberal Catholics who might otherwise have sought to attend the institution but were dissuaded by overt political leanings.

The United States Conference of Catholic Bishops has tried to clarify who in political life—or otherwise—should be honored by Catholics and their institutions. “The Catholic community and Catholic institutions should not honor those who act in defiance of our fundamental moral principles,” they wrote. “They should not be given awards, honors, or platforms which would suggest support for their actions.” The open-endedness of the statement, however, leaves room for interpretation about the level of “defiance” that would preclude someone from speaking at a university. And it opens the floor for both liberal and conservative Catholics to protest those who are honored on campuses.

Garnett has tried to grapple with the question as well, and, as he put it, “our goal when we ‘honor’ is not merely to avoid scandal or culpable complicity; it is to hold up for emulation, and to attract others to, actions and actors we admire and think are admirable, because of who we are.” In an interview, he told me that the university could have extended the offer to DeVos in terms that were purely in line with Catholic teachings—arguing that she has done a lot to raise awareness about choice-based education reform. In fact, in her speech on Saturday, the secretary called it her “moral obligation to expand educational opportunities for each and every child.” And Catholics from across the political spectrum, including Archbishop Blase Cupich, who helped tip the scale in a battle over education reform in Illinois, tend to get behind choice policies.

But even then, there would likely have been opposition, because the lines that divide America divide the Church.



Updated at 4:45 ET on January 23, 2019

In Los Angeles, more than 30,000 teachers remain on strike; it took union and city officials more than a week to eke out a tentative agreement that, they announced Tuesday morning, will likely bring them back to their classrooms this week. Last Friday, teachers from a handful of public schools in Oakland, California, staged a one-day walkout, too, and they’re planning for another demonstration this Wednesday. Meanwhile, a citywide strike is brewing a few states over in Denver, as could soon be the case in Virginia, where teachers are gearing up for a one-day rally in Richmond later this month. An educator uprising is even percolating in Chicago, where the collective-bargaining process is just getting started: “We intend to bargain hard,” the teachers’ union’s president told the Chicago Tribune last week.

These protests follow many  others around the country. Last February, roughly 20,000 teachers in all of West Virginia’s 55 counties walked out. A month or so later, teachers in Oklahoma boycotted their classrooms; Kentucky’s educators staged their own strike that same day in early April, as did their counterparts in Arizona a few weeks later, picketing for a week. Later, a one-day rally by teachers in North Carolina forced numerous school districts to cancel classes. And last month, unionized educators in one of Chicago’s largest charter networks walked off the job—the first strike of its kind in the country’s history.

Taken together, these strikes amount to an unprecedented wave of teacher activism. For several decades, teachers’ unions generally shied away from striking. While strikes occasionally cropped up due to frustrations over demanding requirements and stagnant pay, they typically did so as isolated blips, generating little attention beyond the affected locale. A similarly significant period of teacher strikes arguably hasn’t happened since 1968, when large-scale walkouts occurred in Florida, Pennsylvania, Oklahoma, and New York City, along with smaller-scale ones in cities such as Cincinnati and Albuquerque.

Even that wave pales in comparison with today’s. Inconsistencies in the Bureau of Labor Statistics’ data-collection methods make it tricky to compare the two periods in quantitative terms. What’s clear, though, is that the eight major 2018 strikes—including the four high-profile statewide walkouts—involved a total of more than 379,000 teachers and school staff. Taking into account the current L.A. strike—which is poised to end after Tuesday, pending teachers’ ratification of their union’s newly inked agreement with the district—brings the tally to at least 409,000. The four major teachers’ strikes of 1968, by contrast, involved some 107,000 educators total, according to a Bureau of Labor Statistics analysis.

If nothing else, education-policy scholars, legal analysts, and labor experts tell me this wave is unprecedented in the terms that matter most: the stakes, the sentiments, the long-term implications. The walkout in Los Angeles is distinct from its red-state predecessors of 2018 in many regards—its participants are effectively facing off against a Democratic-controlled school district and state, for example, and a plurality of them are Latino, including many whose activist roots run deep. Still, the impact of this strike, which has shut down the country’s second-largest school district for more than a week, amounts to much more than a disruption to classes for nearly 500,000 students. It could go as far as helping to solidify this sequence of strikes as a pivotal moment in a 21st-century labor movement that is characterized by its radicalism and sense of collective action, suggests Charlotte Garden, a professor at Seattle University School of Law who studies labor.

Back when teachers’ unions first rose to prominence in the early 20th century, the organizations were seen as white-collar guilds tasked with serving educators’ professional needs, Garden says. They were conceived as distinct from, say, the steelworker and coal-miner unions, which were known for their activist bent and narrative of class struggle. But in recent years, many teachers’ unions have been modifying their brand and their explicit mission, placing emphasis on issues beyond educators’ own pocketbooks. In last year’s West Virginia strike, for example, teachers decried students’ limited access to quality instruction; in Oklahoma, their targets were outdated textbooks and dilapidated facilities; in Los Angeles, they condemned the paucity of counselors and classrooms packed like sardines.

These issues “get at the heart of public education,” says Kent Wong, the director of UCLA’s Labor Center, meaning that, in a sense, teachers’ unions aren’t fighting just for teachers anymore, but also for students themselves. By expanding their demands beyond their own compensation, teachers’ unions are transforming into some of the most significant advocacy groups striving for socioeconomic equality in America today. As part of the tentative agreement announced Tuesday, the Los Angeles school district will shrink class sizes and better incorporate the real world into curricula on top of increasing teachers’ salaries by 6 percent.

This broader, more public-minded approach has its roots in 2012, and in a city well versed in teachers’ strikes: Chicago. The timing was hardly auspicious for an uprising: American taxpayers, whose support for unions in general had been declining, had started to see public-sector unions as incompatible with their interests as taxpayers; politicians from both parties were starting to place restrictions on such organizations. The impulse for many political leaders in the Windy City was thus to dismiss the walkout as unnecessary and superficial.

Yet, as Erik Loomis writes in his recent book on the history of strikes in the United States, money was an afterthought for Chicago’s teachers. Instead, echoing a landmark report their union had published earlier that year outlining the changes the students needed to thrive, teachers demanded more and better training for serving specific populations, as well as fair evaluations designed with kids’ success in mind; they called for air conditioning in their sweltering classrooms and lower limits on how many students could be placed into those classrooms.

The teachers wanted, Loomis writes, “to work and live with human dignity,” an objective the teachers’ union framed as inseparable from a similar sense of dignity among children both in and outside of school. After a week of boycotting their classrooms, the teachers secured some concessions from the district—including a carefully crafted evaluation system that relies partly on student test scores, textbooks for all kids on the first day of school, and a more holistic curriculum with a greater investment in extracurriculars such as art.

Since then, teachers’ strikes have continued to focus even more on these beyond-the-pocketbook issues. One reason is simply that the quality of the country’s public schools is, in certain places, terrible. The Great Recession ushered in an era of austerity measures that significantly hamstrung public schools across the country; in a handful of red states, school spending never returned to pre-2008 levels. Additionally, schools have been resegregating, contributing to growing race- and income-based disparities in achievement, and standardized testing, which proliferated following the No Child Left Behind Act signed into law by George W. Bush in 2002, continues to dictate the way many schools are measured and run.

At the same time, the American public maintains tepid attitudes toward unions in general and wariness of their political influence specifically; since the mid-20th century, there has been a general decline in union membership. These trends came into sharp focus last summer with the Supreme Court’s ruling in Janus v. AFSCME, which deemed it unconstitutional for public-sector unions to collect membership dues from workers who don’t support the union, a tactic on which they’d relied for decades. In light of this, teachers’ unions have sought to rebrand themselves as activist organizations charged with fighting for children’s needs in the name of the collective interest, an overhauled identity that has resulted in both more striking and more results.

Even so, critics suggest that self-interest is nevertheless what’s driving teachers’ unions to the picket lines. Jeanne Allen, the founder and director of the Center for Education Reform, a pro-charter-school organization, says that following Janus, “teachers are desperately afraid that if they have to go out and recruit members and convince them that [the unions] are worthwhile,” the unions won’t be able to collect the fees needed to sustain themselves.

As evidence, Allen cites the collective-bargaining proposal submitted by the L.A. teachers’ union earlier this month: It stipulated that the district would have to provide the union with the contact information of every LAUSD employee, for example, and restrict the number of activities for which schools can request teachers’ participation rather than leaving that up to individual campuses. In other words, the union may be attempting to keep a tight rein on staff who in a post-Janus world may choose to distance themselves from the union. The union is seeking to “micromanage the district,” Allen argues, by gaining more control over decisions that individual schools should have the power to make.

Teachers concede that the walkout had been in the works for some time, but their motives, they argue, go beyond self-interest and beyond strengthening the union for the union’s sake. “People are pissed about the conditions in L.A.” says Pedro Noguera, a distinguished professor of education at UCLA whose research as a sociologist focuses on the impact of race and class on schools. By “conditions” he means the class sizes (some are as large as 46 students, exceeding the 39-pupil limit stipulated by teachers’ last contract), the lack of support staff (each high-school counselor in the district has an average caseload of nearly 400 students), and the rapid growth of charter schools (at 224, Los Angeles has more such institutions than any other U.S. city, and a number of studies, at least one of them union-funded, have found that the charter-school sector siphons hundreds of millions of dollars out of the union every year). “All those things come together to make people very angry,” Noguera said.

Beyond that, the six educators I spoke with in recent days all alluded to their growing realization that change won’t happen without major disruption. (Five of the teachers are in L.A., while one spearheaded the one-day walkout in Oakland, where the teachers’ demands placed a similar emphasis on charter schools and sorely deficient classroom conditions.) They’re not criticizing the growth of the charter sector—which in L.A. now enroll nearly 140,000 students—because such institutions operate beyond the union’s purview, they argue, but because they fear the sector is depleting the city’s public-education system at the hands of private, sometimes for-profit, entities. Public per-pupil funding follows students who transfer into charters out of the public schools, where enrollment has plummeted in recent years. The teachers contend that this trend has contributed to public schools’ deterioration in both the city and the state—largely attributable to a property-tax amendment passed in the 1970s commonly known as “Prop 13”— which once boasted one of the country’s best education systems.
“We’ve been in this fight since before Janus … We believe in this stuff,” says Arlene Inouye, one of the union’s chief negotiators and a former public-school educator, pointing to the overall decline in classroom conditions and highlighting the union’s leadership overhaul four years ago. In an interview, John Rogers, an education-policy professor at UCLA,suggested that more teachers in L.A.—and across the country—are starting to see themselves as “guardians of democracy.” While the legislative results of last year’s strikes have been mixed, various polls showed rising support nationally for teacher-salary hikes, strikes, school-funding increases, and labor unions more generally.

Still, even if L.A.’s teachers have broad support from the public, it remains unclear how their demands will be funded; as of Tuesday morning local time, details on the tentative agreement hadn’t been released. While union officials and some analysts pointed to the district’s nearly $2 billion in reserves, LAUSD maintained that the remaining money it has is already being spent or has been committed to critical expenditures, including pay raises and staffing increases that partly heed teachers’ demands. When we spoke last week, UCLA’s Noguera emphasized that he sympathizes with the teachers’ concerns and their impulse to walk out—but that he recognizes the district’s fiscal dilemma, too. Because the school district receives its per-pupil funding from the state, every day of the strike—with the declining rates of kids showing up to school—comes with an immense deduction in those public dollars. As of Friday, according to district data, LAUSD had lost close to $125 million in gross revenue. “If you’re really trying to fund public education, and the strike weakens the system,” Noguera suggests, “then you’re actually going to be weakening public education.”

The irony of it all is that the recent strikes transpired during a time of widespread skepticism about unions' political influence, a Supreme Court decision that appears to side with a majority of Americans by restricting unions’ fundraising capabilities, and overly stretched state budgets that make many of teachers’ demands all but impossible to fulfill.* Teachers are attempting to leverage these adverse realities to their advantage—and based on the public’s response, this unlikely strategy appears to be working.

* This piece originally stated that public support of unions was waning, when in fact it has grown in recent years.



Many proposals for addressing school segregation seem pretty small, especially when compared to the scale and severity of the problem. Without the power of a court-ordered desegregation mandate, progress can feel extremely far off, if not altogether impossible. Some even believe—understandably though mistakenly—that no meaningful steps can be taken to integrate schools unless housing segregation is resolved.

But a new theory from Thomas Scott-Railton, a recent graduate of Yale Law School, provides reason to believe there are still new ways to think about this issue. Railton’s approach does something that’s all too rare in education-policy debates: He takes what are normally viewed as discrete issue areas—K–12 segregation, college admissions, and the lack of diversity at top universities—and says, what if those can all be addressed together? What if, in fact, it’s impossible to address them apart? Scott-Railton’s proposal, which he published in the Yale Law & Policy Review, is to reduce K–12 segregation by reforming the college-admissions process.

Scott-Railton began thinking about this last fall, after listening to Nikole Hannah-Jones’s reporting on This American Life about school segregation in the St. Louis metropolitan area. The radio broadcast featured wealthy white parents in a St. Louis suburb distressed by the prospect of black students from a neighboring town enrolling in their public schools. The black children’s district had recently lost its accreditation due to poor academic performance. (It was the same district that Michael Brown, who was fatally shot by police in August 2014, had graduated from.) If a Missouri school district loses its accreditation, the state permits any student enrolled to transfer to a nearby accredited one.

Packed at a school-board meeting, white parents one after another spoke out about their fears of this new incoming student population—that they’d bring increased crime, violence, and disease. And, some parents feared how the black students’ test scores might threaten their own children’s academic standing. “Once [they come] in here, will that lower our accreditation?” asked one parent, to thunderous applause.

Many of the white parents’ fears were prejudice, plain and simple. But Scott-Railton knew that the parents were right about one thing: Integrating the school could mean that the school’s rating would drop, and schools with lower ratings tend to pay a penalty in the highly competitive college process. Universities tend to give a leg up to affluent, high test-scoring suburban schools—which then incentivizes wealthier parents to seek out segregation. But what if those incentives could be changed?

And thus Scott-Railton’s idea was born: to take demographics of schools into account in college admissions—giving priority to applicants who attended schools with a certain threshold of low-income students (say, above 40 percent). In other words, admissions officers would look favorably on students who attended an economically integrated school, much as they do those who have had unusual travel experiences or outstanding extracurricular achievements.

In a nutshell, he argues, this idea would drive integration in three ways: It would create an incentive for middle class and wealthy parents to enroll their students in socioeconomically integrated schools, it would create countervailing considerations for white parents considering leaving currently integrated school districts, and it would provide an incentive for private schools to enroll more low-income students. Middle-class students would likely benefit more from Scott-Railton’s idea than low-income students, since his proposal doesn’t inherently change the financial barriers to attending college. But millions more would benefit from the increased K–12 integration, which decades of research show improves public schooling.

It wouldn’t be the first time colleges sought to change applicant behavior by altering admissions incentives. In 2016, deans and admissions officers from more than 50 elite universities signed on to a report—Turning The Tide—a first-of-its-kind effort led by Harvard’s Graduate School of Education to signal that going forward, colleges will work to de-emphasize resume padding and hyper-competitive achievement, and prioritize communal values and work taking care of others. The colleges recognized that they were powerfully positioned to transmit different cultural messages to applicants and their parents.

One strength of Scott-Railton’s proposal is that colleges and universities would not have to sacrifice much to make it work. It would be relatively cost-neutral to implement, and wouldn’t require schools to accept any particular students. As he puts it, the plan operates within higher education’s “existing institutional constraints.” But that also means it would be unlikely to substantially increase campus diversity, at least initially, and for that reason Scott-Railton says his idea should not be seen as an alternative to measures like affirmative action and Pell Grants.

Nevertheless, Lloyd Thacker, executive director of the Education Conservancy and an expert on college admissions, said one of the biggest challenges this kind of proposal faces is just institutional inertia. “A lot of this will come down to courage,” he said. “Universities get bogged down in political constraints, caught up in managing competing interests, and it can sometimes just be easier to do nothing, rather than try something new.”

But if colleges could work up the will to try it, another benefit of this idea would be that it seems to be on solid footing legally. In the wake of Supreme Court decisions that have challenged both K–12 desegregation plans and university-level affirmative-action policies, advocates for diversity have been wary of pursuing new strategies. Scott-Railton took that into account in crafting his proposal, which recommends that admissions boosts come primarily from taking the poverty level of a school—not its racial makeup—into account, and for this reason it is more likely to withstand any kind of constitutional challenge.

“My sense of his plan is that it probably threads the needle pretty effectively,” said Sam Erman, a law professor at the University of Southern California who has studied integration and affirmative action. “There are some ambiguities in the legal doctrine, but it’s hard to see how you would launch a successful attack on this idea.”

Fear that the Supreme Court would eliminate race-based affirmative action has led other scholars to propose a college-admissions focus on school or neighborhood demographics. For instance, in her 2014 book Place Not Race, law professor Sheryll Cashin proposed substituting race-based affirmative action with a geographically-based system that took segregation into account. Scott-Railton’s idea builds upon this sort of notion by focusing more explicitly on using admissions to transform the makeup of K–12 institutions.

As Erman told me, without some kind of new experiment, integration advocates shouldn’t expect much to improve. “Most of what we’ve seen implemented are ideas that nibble at the margins, that make relatively small adjustments to things that the court has already approved,” he said, noting that unless the court swings left, it’s reasonable to expect the legal constraints to narrow even more.

“This is a very smart and strategic way of dealing with what has been the overwhelming obstacle to school integration, which is white and middle-class resistance,” said Rick Kahlenberg, a senior fellow at the Century Foundation and a longtime scholar of segregation. Kahlenberg said he likes the idea not only because it creates incentives for hyper-competitive affluent families, but also because it creates a way for universities to have more students who arrive with experience navigating diverse environments. “Elite universities need more bridge-builders,” he said. “I think this is a win-win.”

While the idea remains in its infancy, some other researchers have launched efforts to develop it further. Ilona Arnold-Berkovits, an education researcher at Rutgers who also began thinking more deeply about these issues after listening to the same This American Life episode which inspired Scott-Railton, launched a website, schoolbonuspoints.org, to begin mobilizing other policy experts, researchers, and funders around this idea of voluntary incentives.

There may be room for additional development. Scott-Railton’s idea could offer a real bulwark against white flight, but it is ultimately focused on integrated schools more than the truly disadvantaged schools. If an incentive-based policy like this were to be truly successful, leaders would need to coordinate it with efforts that directly address schools where racial and economic segregation are far worse. A strategy that preserves integration in schools that are 40 percent low-income may have no impact at all in a school that’s 90 percent low-income.

Perhaps one of the strongest merits of Scott-Railton’s idea is that it advances a new way of thinking about some very old problems, and encourages thinking about two issues—K–12 integration and diversity in higher education—together, rather than apart.

“In reality, for students, it’s a seamless web,” said Kahlenberg. “One impacts the other, and it’s not really until this proposal that we’ve seen those two worlds come together.”



The former education secretary says it’s time for American families to boycott school to fight for stricter gun laws.

Over the weekend, Arne Duncan, who served in the Obama administration, replied approvingly to a radical suggestion from a former colleague. “Maybe it’s time for America’s 50 million school parents to simply pull their kids out of school until we have better gun laws,” tweeted Peter Cunningham, another Obama-era education official. Duncan’s reply: “This is brilliant, and tragically necessary. What if no children went to school until gun laws changed to keep them safe? My family is all in if we can do this at scale. Parents, will you please join us?”

After Duncan tweeted, Wendy Kopp, the founder of Teach for America, said she was on board. So did Jim Manly, the superintendent of KIPP public charter schools in New York City.

Duncan has been pushing for tougher gun laws since leaving the Obama administration. I spoke with him on Monday about school shootings and why he believes in a boycott. (Duncan is a managing partner at Emerson Collective, which owns a majority stake in The Atlantic.) The conversation that follows has been condensed for length and clarity.

Adam Harris: Can you expand on the idea behind this boycott, beyond what you said on Twitter?

Arne Duncan: This gun issue has been one that has been the source of tremendous personal pain for me most of my life. I’ve talked about it extensively. It’s actually what I’m working full-time on now in Chicago. I’ve said very publicly that I thought my greatest failure when I ran Chicago Public Schools was the number of our students who died under my watch—who were killed. So, this is not a new issue, by any stretch. Sandy Hook—I talked about it, the president talked about it—that was the worst day for me in D.C. It was the worst day of President Obama’s presidency, and he dealt with the hardest issues on the planet, by definition. And you have these series of mass shootings, whether it’s churches or malls or movie theaters or baseball fields or schools. And I don’t know if we’re numb, or helpless, or feel hopeless, but any objective look at the data shows that it just doesn’t happen in other countries.

So, that’s a long way of saying: The fact that we can’t get that done in this country, it just—it breaks my heart. I’m angry. I’m infuriated.

Harris: How likely is it that a massive boycott would actually happen?

Duncan: The short answer is: We’ll see. We put this out a few days ago, and it was definitely intended to be thought-provoking. And you think about, you know, not all schools, but many schools, come back to school after Labor Day, that first week of September. That would give us a little time to see whether it makes sense. But there is clearly, as of now, very significant interest.

And, you know, teachers have walked out for higher pay, kids have walked out on the gun-violence issue, and my question is: What have we as parents done? We’re not protecting our kids. And, again, that’s the most fundamental thing. You want your kids to be safe. That’s instinctual. And the fact that we’re not doing that—we’re not willing to think radically enough to do it—I can’t stomach that.

So, the thought was, let’s see if it develops, let’s see if it continues to pick up momentum. But if you could do something in September, you’d see whether politicians move or not. If they move, fantastic. If they don’t move, then you’re looking at the November elections. Then you act.

Harris: You’ve worked with a lot of these politicians you’re talking about. Do you think that this is something that would push them to action?

Duncan: Clearly everything that we have done to this point has failed. We have failed to move them. So, this is definitely a radical idea, but I think I can make a pretty compelling case that we have to think radically to get them to do something different. I also think that many politicians—not all, but many—just act out of self-interest. And I know that many on the Republican side think they’re losing a whole generation of young people. And young people, they’re sick and tired. They’re not going to walk away from it. So, if for nothing other than self-interest, there’s an opportunity here.

So, nothing we have done to date has worked. We have absolutely failed. I have failed. We’ve all failed. But I am also more hopeful today than I have been at any time since the Sandy Hook massacre.

Harris: And is some of that hope due to the student activism in the wake of the Parkland shooting?

Duncan: Absolutely. The young people are absolutely leading the country where we as adults have failed to take it. And I am more hopeful today precisely because of their strength and their commitment.

Harris: Organizing a mass school walkout seems like a logistical nightmare, if you think about things like figuring out what to do with students whose parents might not be able to take off work to take care of them during school hours. How do you think a boycott would work, practically?

Duncan: Let me just say, I more than recognize how difficult and impractical this is. But the Montgomery bus boycott went on for a year. These were poor people who denied themselves access to public transportation, and they managed to do that for a year and change the world. I would argue that it is also very difficult and impractical to send your kids to school and have them shot and killed. It’s very impractical and difficult to try to go to a movie theater, or a concert, or the mall, or to worship in church, and to be murdered en masse. And there’s nothing easy or practical about this, but it’s all relative. And we’re dealing with a reality today that’s infinitely harder than that.

So, those are very important considerations, and we have some time to think those through—and we’ve had a lot of people saying they would step up and help. But, I think, if this was easy, it would have happened, and it’s going to take something hard. When we were part of the administration, we played by all the rules after Sandy Hook. We did a study, we did a report, we worked with Congress, and guess what we accomplished? Nothing. So, playing by the rules hasn’t worked. We need to change the game.



Arne Duncan, the former education secretary under President Barack Obama, has always been more candid than others who’ve served in that role. He’s often used his platform to talk about what he sees as the persistent socioeconomic and racial disparities in access to quality schools. His new book, How Schools Work: An Inside Account of Failure and Success From One of the Nation’s Longest-Serving Secretaries of Education, further cements that reputation. How Schools Work’s first chapter is titled “Lies, Lies Everywhere.” The first sentence: “Education runs on lies.” If one were to create a word cloud of the book, lies would probably pop out as one of the most frequently used words. Duncan writes that even the countless fantastic schools across the country “haven’t managed to defeat the lies that undermine our system so much as they’ve been able to circumvent them.” These lies, according to Duncan, include a culture of setting low expectations for high schoolers who later discover they’re not prepared for the real world, and poorly designed accountability systems that allow teachers to fudge their students’ test-score results.

Duncan started his education career in Chicago as a tutor, mentor, and researcher at his mother’s after-school program for low-income, black youth on the city’s South Side, and eventually became the head of the city’s massive public-school system. He occupied that role for nearly eight years until 2009, when then-President Obama—whom he’d met through mutual friends years prior—tapped him as the country’s education secretary, bringing him to Washington, D.C., where he’d spend another seven years as one of the president’s longest-serving cabinet members. In 2015, Duncan, holding back tears, announced that he was resigning, marking the end of his leadership at the U.S. Education Department, a tenure marked by demanding reform initiatives—such as efforts to tie teacher pay to test scores, which took an immense toll on educators’ morale and garnered a lot of criticism. Hungry to spend more time with his family, Duncan returned to where it all started—Chicago’s South Side—and he’ll likely finish his education career there: Today, he’s at the helm of an anti-violence initiative called Chicago CRED that provides job training and positions to Chicago’s unemployed, out-of-school black men. (The CRED initiative was created in 2016 by the Emerson Collective, which now owns a majority stake in The Atlantic and at which Duncan is a managing partner.)

I recently spoke to Duncan about the entrenched obstacles he’s long felt are keeping kids in the United States from succeeding in school—and about what he’s learned from his experiences trying to combat them. An edited and condensed transcript of our conversation is below.

Alia Wong: In what ways do you think Chicago was a good training ground for your later role as the U.S. secretary of education?

Arne Duncan: There were three different experiences in Chicago that shaped me. First, there was my mother’s after-school program, [the Sue Duncan Children’s Center], where my brother, sister, and I pretty much grew up. My mom’s whole philosophy was that 10-year-olds taught 5-year-olds, and that 15-year-olds taught 10-year-olds, and so on, so from a very young age we were both teaching and being taught. The neighborhood in which we worked happened to be all African American, it happened to be largely poor, and unfortunately it suffered from a significant amount of gang violence. But I grew up with friends who had this amazing, amazing potential … I took a year off from college to work with my mother full-time to figure out if [working as an educator] was just a part of who I was or if it was actually who I was. During that year I decided that I wanted to find a way to follow in my mom’s footsteps.

The second piece was running the I Have a Dream program [which provides long-term academic support to students who attend underfunded schools or live in housing projects] for six years with my sister and others to build upon my mother’s work. We worked with a group of students from when they were in the sixth grade through their high-school graduation. I learned so many lessons there about what’s possible when kids have high expectations and tremendous support.
And then finally, it was leading the school district, which for me was a chance to apply so many of the lessons I had learned throughout my life and also preparation for me to go to D.C. At the citywide level, I started to think about scale, and how you can have big-picture impact. What I didn’t know going into D.C., by the way, was rural America.

Wong: Back in Chicago, it seems like the largely negative responses you got to your decision to close some public schools really struck a chord with you. Can you talk more about that? How, if at all, did that experience inform your approach to the role of U.S. education secretary?

Duncan: To be clear, we closed a very small handful—about half of 1 percent of CPS’s 600 or so schools in my first year. And there were a lot more openings than closings happening; every year we closed, say, three, we’d open eight or 10.

We should always be trying to fix and improve schools, and in the vast majority you can. But when you look at the results at those schools we closed, they had kids that were just falling further and further behind every single year they were there, and it was never the kids’ fault. Kids have one chance to get an education. I was happy to make some tough calls, happy to take a little bit of heat, when I knew in my heart that what we were doing for kids wasn’t good enough and we could do better.

Giving parents a chance to see what’s possible at schools that were sometimes less than a mile away from where their kids are going to school, with a very different set of expectations, that was hugely important. When they saw what was possible, they became the biggest supporters.

It’s the parents who aren’t present whose kids you have to worry about even more because those parents just have too much going on in their own lives to be engaged in their children’s education. Those kids are the ones I actually worry about the most.

Wong: It’s in some ways counterintuitive—you often hear from teachers and others that vocal or difficult parents are a major obstacle to effecting positive change.

Duncan: I never felt that—ever. Parents were the biggest allies and, I would argue, the most important allies. If you’re educating not just children, but also parents and siblings and other family members, then great things are going to happen for kids.

Wong: You talk a lot about the importance of telling stories through data while acknowledging the limitations of that approach. A lot of education advocates maintain that the embrace of data, while beneficial, has had the unintended consequence of dehumanizing education-reform efforts. How do you reconcile those two perspectives?

Duncan: I try to tell stories in the book rather than just reciting a huge amount of data—I think the stories are very compelling, and that people can draw their own conclusions from them. But if you look at every level—access to early-childhood education, math and reading scores, college-graduation rates—relative to the world, [Americans] are top 10 in nothing, and that’s not good enough. This is a national-security issue and an economic issue: We need to have the best-educated workforce in the world if we want to keep jobs here. If we want to have a vibrant participatory civic democracy, we have to have the best education system in the world. If we want to break cycles of poverty and give kids a trajectory to the middle class, the only way to do that is through a high-quality education.

But Chicago Public Schools’ “Freshman On-Track” initiative—that’s a good example of how data can do the opposite of dehumanizing. When I was at CPS, we got info [from the University of Chicago Consortium on School Research] about the importance of focusing on freshman success in reducing dropout rates and increasing graduation rates. We found out that if you’re trying to reduce dropout rates and you wait until students are in their junior or senior year, you’ve already lost them—they’re gone.Those freshman-on-track numbers—the percentage of students who make it to their sophomore year on time and in good standing—have gone from the 50s back then when we started [in 2007] to close to 90 percent today. This data-collection effort was not a focus on some aggregate number—it said that schools had to track every single student relentlessly, and if a student missed a day of school, the school wasn’t to wait until the end of the week or the month or the semester; they were to follow up with that kid and ask, “Why weren’t you here? What can we do to help? Are there things going on at school, at home, in your community?” That’s really recognizing the humanity of every single student.

Wong: Reform so often comes with unintended consequences. Even the Freshman On-Track initiative at least initially incentivized some schools to fudge their numbers. We saw that with No Child Left Behind—a law that you describe as “horribly constructed.” Can the prospect of unintended consequences be avoided?

Duncan: You have to constantly be learning. We have to be very clear about our goals—whether it’s college-going rates or access to pre-K—and then allow a lot of flexibility, a lot of innovation, to achieve those goals. What works best in rural Montana may look a little different from what it is in Anacostia in Washington, D.C., or in California. If you’re clear about your goals and creating real-time adjustments, you’re learning and getting smarter. You’re never going to anticipate every potential bump in the road, but if you’re nimble and thoughtful and pragmatic—and not dogmatic—you can effect real change.

Wong: What compelled you to frame your memoir around the theme of lies?

Duncan: Far too often political leaders mouth platitudes. I’ve never met a politician who was anti-education—who didn’t like to kiss babies and pat them on the head and do photo ops. Everyone says they value education.

I talk a lot about gun violence—it’s what I’m dealing with in Chicago all the time; it unfortunately shaped me as a kid; we saw it in the Sandy Hook massacre, which happened when I was education secretary. There’s no political leader who says they don’t value kids, but the truth is: We value guns more than we value the lives of our children. And that is irrefutable if you look at the rates of gun deaths in the U.S. compared to other nations that make other policy choices.

So whether it’s valuing education or truly valuing teachers or valuing the lives of our kids and giving them a good start to life with early-childhood education, everyone will say yes, yes, yes, yes, yes, but their actions don’t follow, don’t correspond, don’t correlate. It’s intellectually dishonest, and the stakes are too high. I worry about a caste system; I worry about people feeling like they can’t get ahead.

I don’t only blame politicians—I blame voters. We don’t vote based on education at any level—local, state, Congress, president; we don’t hold anyone accountable for results, voting based on whether a politician is going to help increase access to pre-K, is going to increase high-school graduation rates, and so on. Education should be the ultimate nonpartisan issue.

For me, the joy in education, the reason I devote my life to it, is that education should be the ultimate equalizer. It shouldn’t matter what your race or class or zip code is; it shouldn’t matter where you come from. It should be that if you work hard because you have access to a great education, you can do anything. But we don’t do that, and as a result we can actually exacerbate the divides between the haves and have-nots. We’re all part of the problem. Those are the lies that I try to confront very openly.

Wong: These days, especially amid growing political polarization, it seems that many of the main issues in education are prone to reductive debates that come down to semantics. Even the mention of terms like school reform and school choice can steer a constructive conversation off course. Did you notice that becoming a problem during your time as secretary?

Duncan: So much of that stuff is about adult dysfunction and has nothing to do with what kids want and need. Work in education is nothing if it isn’t humbling, so whenever you have people who say they have it all figured out, I think they probably don’t. If people are shutting down a conversation based on a word or a phrase, how is that in the students’ best interest? When I see adult ego get in the way, it troubles me. It misses the point of why we do this work.



Even as college students on the whole began to shun humanities majors over the past decade in favor of vocational majors in business and health, there was one group of holdouts: undergraduates at elite colleges and universities. That’s not the case anymore, and as a result, many colleges have become cheerleaders for their own humanities programs, launching promotional campaigns to make them more appealing to students.

As Benjamin Schmidt wrote in The Atlantic recently, humanities majors—which traditionally made up one-third of all degrees awarded at top liberal-arts colleges as recently as 2011—have fallen to well under a quarter. Meanwhile, at elite research universities the share of humanities degrees has dropped from 17 percent a decade ago to just 11 percent today.

“This wasn’t a gradual decline; it was more like a tidal wave,” says Brian C. Rosenberg, the president of Macalester College. The Minnesota campus, which is well known for its international-studies program, has “never been a science-first liberal-arts college,” Rosenberg said. But now 41 percent of its graduates complete a major in a STEM (science, technology, engineering, and mathematics) field. That’s up from 27 percent only a decade ago.

The reasons for this national shift are many, but most academics attribute it mostly to the lingering effects of the Great Recession. One of the earliest memories for the generation entering college right now is of Americans losing their jobs and sometimes their homes. Financial security still weighs heavily on the minds of these students. Indeed, a long-running annual survey taken of new college freshman has found in the past decade that the No. 1 reason students say they go to college is to get a better job; for the 20 years before the recession hit in 2008, the top reason was to learn about things that interested them.

Unlike automakers, which can swiftly switch production lines when consumers start buying SUVs instead of sedans, colleges can’t adjust their faculty ranks as quickly in response to public demand. Often, schools wait for professors to retire to reassign those openings to disciplines with the greatest need. Even then, small schools might only recruit a handful of new faculty every year. When they hire, most colleges also need to keep a balance of professors across departments to teach introductory classes that are part of a core curriculum. Macalester, for instance, hired 11 full-time faculty members this year—four of them in computer science and statistics. “We have vacant positions in history and English, and we decided not to fill them,” Rosenberg says.

With that pace of hiring, it’s nearly impossible for many colleges to keep up with increasing enrollments in popular majors while maintaining small classes. What’s more, faculty members hired for tenure-track positions who eventually earn tenure are essentially promised lifetime employment at the college. “When you put labor in position for 30 years, your ability to respond to future trends becomes really challenging,” says Raynard Kington, the president of Grinnell College, in Iowa. Grinnell expects 70 students to graduate with computer-science degrees this spring out of a class of around 400; four years ago, it graduated just 15 computer-science majors.

To avoid further slippage in humanities majors, elite colleges and universities have resorted to an all-out campaign to convince students that such degrees aren’t just tickets to jobs as bartenders and Starbucks baristas. Colleges are starting early with that push. Stanford University writes letters and sends brochures to top-notch high-school students with an interest in the humanities to encourage them to apply, says Debra Satz, the dean of Stanford’s School of Humanities and Sciences. Prospective students can also take humanities classes at Stanford while still in high school.

What’s puzzling to the college officials I spoke to is that they say students’ interest in humanities majors remains high during the college-search process, according to what students indicate on their applications. Then something happens between when students apply and when they actually declare a major, usually in their sophomore year. Perhaps students’ intentions on their applications weren’t serious, but if they were, Satz says it’s critical that humanities courses in the freshman year capture their attention. At Stanford, she said introductory courses in the humanities are focused on “big ideas,” such as justice, ethics, and the environment, to appeal to students trying to choose their major.

“We have to make the offerings really good, really enriching,” Satz says. “Part of our challenge is when students see so many of their peers going into computer science.”

To help guide the course selection of incoming students, Grinnell sent a booklet to all freshmen this past summer that outlined the importance of a broad liberal-arts education. The college also added a session on the topic to orientation in advance of students meeting their academic advisers. Both initiatives, Kington said, were intended to encourage students to select courses across a range of academic disciplines, given that Grinnell lacks a traditional core curriculum with mandated requirements.

Macalester’s tactic has been to try to inject some humanities into STEM classes and some practical career training into the humanities. Last year, Rosenberg, the school’s president, brought the faculty together at a retreat to discuss the shifting balance of majors. One outcome was that faculty members were encouraged to pair together courses across academic disciplines so that, for example, a new class in social media might be a blend of computer science and philosophy. Professors in the humanities were also encouraged to give their students more career guidance than in the past, when many humanities students simply went to graduate school or law school after college.

“The typical English major is designed to get students to go to graduate school,” Rosenberg says. “We need to rethink the curriculum so that it’s more focused on what employers will immediately find attractive.”

Rosenberg was present when several presidents of elite colleges gathered last fall for a meeting in New York City. At our table during lunch, there was a debate about whether the changing distribution of majors was really a crisis. After all, at least at liberal-arts colleges, the humanities remain a central part of the curriculum, including for STEM majors. Indeed, Satz of Stanford says she’s less concerned about the 14 percent drop in humanities majors at the university over the past decade, and more focused on the 20 percent increase in enrollment in humanities courses.

“There’s only so much we can do to stem the tide in majors,” she says. “What I care about is that every student in engineering can think critically, can read carefully, and they can listen empathetically. That happens by taking courses in the humanities.”

Rosenberg, an English professor and Charles Dickens scholar by training, agrees. He says he doesn’t blame students for flocking to computer science and applied mathematics. Mathematical literacy and the ability to manipulate large data sets are becoming more critical in every job, including those the humanities traditionally trained, from journalists to sociologists. “We’re not giving students enough credit,” Rosenberg says. “They’re picking something that’s really interesting to them.”

Unless colleges in the United States want to follow the European model, where prospective students apply to specific degree programs instead of a given university, the choices of American students will likely always shift with the winds of employment. Some studies suggest that many of the tasks done by humans in STEM fields will be automated in the future; robots may well end up writing most programming and intelligent algorithms. So if elite colleges just wait long enough, perhaps the humanities will make a comeback as humans look for the kind of knowledge that helps them complement rather than compete with technology.



Americans tend to think of colleges as falling somewhere on a vast hierarchy based largely on their status and brand recognition. At the top are the Harvards and the Stanfords, with their celebrated faculty, groundbreaking research, and perfectly manicured quads. Toward the bottom are the chronically underfunded community colleges and obscure state schools, where part-time students and drab buildings are the norm. And then there are the predatory for-profit colleges that pray on the most vulnerable students—like veterans and single moms.

This “prestige hierarchy,” as a higher-education expert once put it, isn’t limited to the United States. A testament to this trend has been the proliferation of global university rankings, including those released annually by the United Kingdom–based publication Times Higher Education (THE).* To rank the schools for the 2018 list, a team of researchers conducted surveys among a group of more than 10,000 academics across 138 countries, asking them to assess institutions’ “esteem” via questions about research and teaching. The THE rankings have their flaws, but they’re the most influential when it comes to comparing universities from country to country. Plus, in explicitly treating a university’s perceived “esteem” as a proxy for its caliber, THE’s rankings offer a compelling look at how the most prestigious colleges vary depending on where that college is located.

And vary they do. Unlike the vast majority of the other 100-plus universities that appear on the list, those located in the U.S. are almost all private institutions. Of the 105 institutions globally on the list, just 21 are private. And all but two of those 21 private colleges are in America. “As far as global perceptions of excellence are concerned, there is a really a stark divide between the U.S. public universities and the private ones,” says Phil Baty, a former journalist who’s edited the THE rankings for nearly a decade. And this divide could help explain why the U.S. is home to the highest tuition fees in the world.

Among the universities listed in the top 10, for example, eight are in the U.S. They include Harvard, MIT, and Stanford, where the undergraduate sticker prices during the 2018–19 school year are $76,650, $70,240, and $71,587, respectively. (All colleges and universities are legally required to publish the total “cost of attendance,” which includes room and board and other fees on top of tuition.) Princeton (No. 7) and Yale (No. 8) also make the list, as does the University of Chicago (No. 9). Just two of the top 10 colleges are public—UC Berkeley (No. 6) and UCLA (tied for No. 9), both of which are highly selective and come with sticker prices that are more on par with those of private colleges than they are state-funded ones, verging on $35,300 for California residents. Meanwhile, tuition at the University of Oxford (No. 5) is roughly $12,000 a year, a fourth of Harvard’s.

Scrutinizing the THE data underscores how just about all of the most prestigious American colleges are private. In the top 25, another three Ivy League institutions enter the mix, as do the California Institute of Technology and Johns Hopkins University. But only one more public university made the cut: the University of Michigan, which comes with a total in-state price tag of $30,298, though a majority of undergraduates are from out of state and pay an even higher cost.

According to Baty, at least throughout Europe, private colleges and universities are mediocre at best, typically housed in dilapidated buildings and offering low-cost vocational training. And gaining admission to top public colleges like, say, the University of Oxford is no easy feat. Roughly 17 percent of those who apply for one of its undergraduate seats gain admission to the nearly millennium-old institution.

This anomaly may be a big reason why the price tags of the most prestigious U.S. colleges have soared to near-absurd levels. As private schools, the bulk of THE’s top U.S. colleges generally don’t receive funding from state legislatures; instead, they rely predominantly on student tuition and research grants. They also benefit from hefty charitable donations that have built massive endowments. (Harvard’s $37 billion endowment outstrips the annual budget of Colorado.) That leads to higher price tags.

The prestige gap between public and private colleges isn’t a new phenomenon, but it’s gotten worse in recent decades. While America’s colleges and universities across the board have dealt with economic strife after the Great Recession, elite private colleges have been inoculated from the volatility of state budgets. A 2017 report by the left-leaning think tank Center on Budget and Policy Priorities found that, even despite a small infusion of funding in recent years, state spending on public higher education “remains well below historic levels”: Adjusted for inflation, legislative allocations for both two- and four-year public colleges were, during the 2017–18 school year, close to $9 billion below 2008 levels. These cuts have forced public colleges to compromise the quality of their academic programming by reducing faculty and limiting the number of courses available. But the problem traces back to well before the Great Recession, as public colleges and universities have long struggled to obtain adequate funding.

That could, in part, be attributable to the fact that public higher education isn’t as integral to the country’s DNA as it is to that of other countries in the West. The American higher-education system began in the 1600s as a network of Christian institutions reserved for the elite, and the creation of policies in the early 1800s asserting colleges’ freedom from governmental intervention helped solidify the notion that higher learning was a private enterprise. Public universities only started opening en masse in the 1860s, when the federal government set aside resources that allowed for the creation of the nation’s land-grant colleges.

These circumstances undermine the ability of public colleges to lobby for more funding: It’s difficult to convince an already strapped legislature to set aside funding for an institution that’s struggling. And it’s also difficult to attract students to an underfunded school. Top that off with the clout of the U.S. News & World Report rankings, in which an institution’s wealth—and, relatedly, prestige—influences its standing, and a vicious circle emerges. In 2016, 65 percent of U.S. freshmen said reputation was “very important” when it came to selecting a college. That was the near the highest level ever, according to a nationwide survey of students that’s been conducted regularly since 1967 by UCLA’s Higher Education Research Institute.

“It’s a real shame that some of America’s great public universities are suffering this perception gap—it means they’re unable to compete for faculty superstars with higher salaries and better teaching and learning environments,” Baty says. “The reality is that these [disparities] in resources will lend fuel to disparities in genuine quality, and the publics will struggle more and more.”

To be sure, rarely do students who attend private colleges in the U.S. pay the full sticker price. For example, a recent report found that, during the 2017–18 school year, just 11 percent of first-time, full-time freshmen at private colleges in the U.S. paid the full price, thanks to financial aid and other grants that, on average, covered more than half of students’ tuition and fees that year.

And as Baty points out, just because European universities have been spared the soaring costs currently dogging America’s higher-education system, they have struggled with their own set of headaches. In the many European countries that put a cap on tuition, or charge nothing at all, some say the limits prevent them from doing what they need to compete with, say, Harvard and Stanford; in turn, policy makers have flirted with the idea of privatizing certain aspects of higher education.

Still, the fact that the sticker prices are so staggering draws attention yet again to one of America’s key higher-education peculiarities: that America’s top colleges are funded through student tuition, rather than the government. And it’s contributing to the inexorable rise of through-the-roof price tags—with no end in sight.

* This article originally misstated that Times Higher Education releases its rankings in partnership with Thomson Reuters.



On Friday, the Education Department released its heavily anticipated proposal that would revamp the way colleges deal with accusations of sexual misconduct on campus. Many of the details in the proposed regulation did not come as a surprise. Still, one feature of the rules in particular stood out: Colleges will be required to allow students accused of sexual assault to cross-examine their accuser at a live hearing.

“We can, and must, condemn sexual violence and punish those who perpetrate it, while ensuring a fair grievance process,” Education Secretary Betsy DeVos said in a press release on the new rules. “Those are not mutually exclusive ideas. They are the very essence of how Americans understand justice to function.” But several higher-education attorneys told me that instead of setting clear policies for institutions to follow, the new regulations may push institutions toward less formal methods of resolving sexual-misconduct complaints that can result in less harsh of a penalty for wrongdoing.

To be sure, cross-examination is a “powerful tool,” says Scott Schneider, an attorney at the firm Husch Blackwell who specializes in higher education—but only when used in certain ways. “When people glibly talk about cross-examination being the greatest tool for discovering the truth in the history of the Western world, they obviously haven’t seen some attorneys do cross-examination,” he says. DeVos’s proposal stipulates that the cross-examination can be done by a third party, such as a lawyer.* Schneider worries that this could create a system where rich students who can afford a good attorney would have an unfair advantage in the hearings.

Victims’ advocates have long argued that cross-examination could dissuade those who have been assaulted from reporting what happened to them. Meanwhile, due-process advocates have argued that cross-examination in a live hearing is important to suss out any discrepancies in testimonies. And in favoring that method, the new rules would ban colleges from having a single investigator—usually a lawyer or an administrator—gather facts and issue findings.

In recent years, a number of mostly private colleges have opted for the single-investigator method instead of the live-hearing model. And one of the primary reasons for the preference has been that live hearings created an environment that was “ripe for mistakes,” Kathryn Nash, a higher-education lawyer, told me. Nash says that when colleges have tried the live-hearing model in the past, in addition to potentially dampening the number of students who report their assaults, it also sets up thorny situations in which the institutions have to make decisions about whether to allow certain questions without a lawyer present to advise them.

Of course, the simple solution to that problem would be to just have an in-house counsel there to help make those decisions, but that is time- and resource-intensive. “The vast majority of institutions that are operating in this space are pretty limited in their resources,” Schneider says. That includes lots of small private colleges, as well as plenty of regional public institutions. “I worry that what’s going to happen here is that this process is going to become so cumbersome by design that people start pushing for ‘informal resolutions’ of these sorts of complaints.”

In other words, due to labor and budget constraints, institutions might find informal processes—such as issuing no-contact orders, counseling, and other methods of resolving sexual-misconduct allegations—more appealing. Of course, both parties—the accuser and the accused—would have to agree to an informal process. However, advocates for sexual-assault victims argue that the prospect of being cross-examined by an accuser could lead more students to choose the informal route. That could lead to “a patchwork system of handling sexual-assault complaints,” says Schneider.

That’s echoed by Catherine Lhamon, the chair of the U.S. Commission on Civil Rights and a former assistant secretary at the Department of Education. “Virtually everybody would try to avoid live hearings,” she says. “It would be difficult to administer effectively and difficult to live through as either the accuser or the accused student.”

The proposed regulation will now undergo a 60-day public-comment period, and the department is obligated to respond to the public comments. It’s unclear whether the final rule will look exactly as it does now, but regardless of how the comment period goes, the end result will be a seismic shift in how colleges respond to—and dish out punishment for—accusations of campus sexual misconduct.

*A previous version of this story mischaracterized the proposed questioning process for students accused of sexual assault. We regret the error.



It’s expensive to be poor. And few places in higher education feel that more acutely than historically black colleges and universities (HBCUs), where endowments are typically smaller and enrollments have fluctuated wildly over the past decade.

Now, to be clear, the financial misfortune of black colleges does not rest squarely on their shoulders. Born out of necessity primarily after the Civil War to educate black people who were shut out of most other colleges, the institutions have been plagued by unequal and inadequate funding ever since. HBCUs, half of which are public, draw a lion’s share of their revenue from state and federal funding. And as states tighten their belts on higher-education spending, these institutions are struggling to come up with the funds to improve their campuses by constructing new buildings or renovating ones that have started to wear down.

But there’s a way for colleges to circumvent their funding woes to pay for campus improvements: taking on debt. But even then, the legacy of racism in the treatment of black colleges is apparent.

There are a couple of steps colleges have to go through to issue bond debt. First, they have to find a bank to buy the debt. The bank will then sell the debt to public investors. The banks are the gatekeepers, and they’re essentially signing off on the fact that the loan isn’t a scam. But the banks don’t do this for free. They typically sell the debt at a slight markup as compensation for expenses and management fees—and that ultimately falls back on the college to pay off.

A forthcoming study in the Journal of Financial Economics examines the differences in these markups for HBCUs and non-HBCUs. The researchers—Casey Dougal of Drexel University, Paul Gao of Notre Dame, William Mayew of Duke University, and Christopher Parsons of the University of Washington—used a 23-year sample of 4,145 tax-exempt municipal bonds issues issued by 965 four-year, not-for-profit colleges.

They found that black colleges pay more to issue debt. “For the typical non-HBCU, 81 cents out of every $100 raised flows to banks. The average for HBCUs is 11 points higher, at 92 cents per $100 raised.” So, for a $30 million bond issuance, a black college would pay $276,000, while a non-HBCU would pay $243,000.

Now, that doesn’t definitively mean that race is the determining factor. The hard part of the analysis, Gao told me, was figuring out whether the difference could be attributed to any factors other than black colleges’ affiliation with racial minorities. So, the researchers controlled for the bond features such as the amount raised, when the bond will be paid off, and colleges’ ability to pay early. They also looked at the quality of the bank selling the bond, as well as school metrics like enrollment, alumni-giving rates, and rankings. But even after controlling for all of these factors, black colleges still paid significantly more—16 points more than non-HBCUs.

Another possible explanation, that HBCUs have bad credit and aren’t appealing to investors, also couldn’t explain the difference. The researchers controlled for credit rating, and only looked at deals with AAA-ratings—the kind where timely repayment is essentially a given—and the difference, 16 points, remained the same.

That led the researchers to conclude that there could not be any other answer: Racism was the primary driver.

Yet another finding drove home that conclusion more clearly. “If racial animus is the primary reason why HBCU-issued bonds are harder to place,” the researchers wrote, “then these frictions should be magnified in states where anti-Black racial resentment is most severe.” And sure enough, by separating out black colleges in Alabama, Mississippi, and Louisiana, the researchers found that the markup rates for HBCUs were 30 points higher than non-HBCUs in those three states, nearly triple the 11-point difference elsewhere in the country.

Black colleges have a few options to get around this. The federal government has a program—the HBCU Capital Financing Program—that provides low-cost loans to the institutions, but it has its fair share of problems. The researchers offer a handful of policy fixes: Giving incentives to out-of-state investors for buying the bonds, or, perhaps, exempting HBCU bonds from all taxes, which would make them more appetizing for potential investors.

Whether those recommendations will be taken seriously is unclear, but what is clear is that the factors driving difficulties for black people in financial markets aren’t sparing black colleges.



Developed countries like the United States have seen a remarkable transformation in education over the last century: Girls and young women—once subjected to discrimination in, and even exclusion from, schools and colleges—have “conquered” those very institutions, as a report from the Organization for Economic Cooperation and Development (OECD) put it. Today, for example, women comprise a growing majority of students on college campuses in the U.S., up from around 40 percent in the 1970s.

One understated contributor to this development has been that girls routinely outstrip boys at reading. In two of the largest studies ever conducted into the reading habits of children in the United Kingdom, Keith Topping—a professor of educational and social research at Scotland’s University of Dundee—found that boys dedicate less time than girls to processing words, that they’re more prone to skipping passages or entire sections, and that they frequently choose books that are beneath their reading levels.

“Girls tend to do almost everything more thoroughly than boys,” Topping told me over email, while conversely boys are “more careless about some, if not most, school subjects.” And notably, as countless studies have shown, girls are also more likely to read for pleasure.

But it’s not just a phenomenon in the U.K.: These trends in girls’ dominance in reading can be found pretty much anywhere in the developed world. In 2009, a global study of the academic performance of 15-year-olds found that, in all but one of the 65 participating countries, more girls than boys said they read for pleasure. On average across the countries, only about half of boys said they read for enjoyment, compared to roughly three-quarters of girls. (The list generally excludes less-developed countries where girls and women tend to have lower rates of literacy than boys and men.)

But that girls read more than boys the world over doesn’t mean that biology is the driving force. As Lise Eliot, a neuroscientist at Chicago Medical School, said at the Aspen Ideas Festival in June: The brain “is a unisex organ,” meaning gender differences are mostly a result of socialization, not genetics. After all, boys tend to be more vulnerable than girls to peer pressure, and that could discourage them from activities like reading that are perceived to be “uncool.”

David Reilly, a psychologist and Ph.D. candidate at Australia’s Griffith University who co-authored a recent analysis on gender disparities in reading in the U.S., echoed these arguments, pointing to the stereotype that liking and excelling at reading  is a feminine trait. He suggested that psychological factors—like girls’ tendency to develop self-awareness and relationship skills earlier in life than boys—could play a role in the disparity, too, while also explaining why boys often struggle to cultivate a love of reading. “Give boys the right literature, that appeals to their tastes and interests, and you can quickly see changes in reading attitudes,” he says, citing comic books as an example.

Topping suggests that schools ought to make a more concerted effort to equip their libraries with the kinds of books—like nonfiction and comic books—that boys say they’re drawn to. “The ability to read a variety of kinds of text for a variety of purposes is important for life after school,” he says.

Understanding why girls are so much more inclined to read might help eradicate what is proving to be a stubborn gender gap both in the U.S. and around the world: the lagging educational outcomes of boys and men. Reading for pleasure is, as the OECD has concluded, a habit that can prove integral to performing well in the classroom. “Any cognitive skill can be improved with practice,” Reilly says. “If girls are reading more outside of school”—if they’re doing so out of an intrinsic motivation rather than because they have to—“this provides them with thousands of hours of additional reading over the course of their development.”

And those extra hours pay dividends for years to come in the classroom.



It’s easy to blame the editors.

Last week, during a hearing before the Senate Judiciary Committee, Brett Kavanaugh suggested his classmates working on the yearbook—and not him—were responsible for the material that appeared on his page. “I think some editors and students wanted the yearbook to be some combination of Animal House, Caddyshack, and Fast Times at Ridgemont High, which were all recent movies at that time,” he told the Senate panel.

One of those editors was Mark Judge, Kavanaugh’s friend who Christine Blasey Ford has said was in the room when Kavanaugh allegedly sexually assaulted her.

I’ve reviewed several years worth of yearbooks from Georgetown Prep, including those from 1983, 1984, and 1986, the year Supreme Court Justice Neil Gorsuch graduated from the school. In the 1983 yearbook, Judge is listed as “caption editor.” In most cases, the yearbooks follow a similar structure. There are a series of interstitial pages with photos of the year—Winter Ball, pep rallies, campus life— followed by underclassmen photographed in small groups of five or six, organized alphabetically, and then the seniors’ pages. The seniors would submit their page to the editors of the yearbook, including Judge, who ultimately compiled the book. The resulting product is, in many of the years I reviewed, rather juvenile, as expected, and, at times, overtly misogynistic.

Judge declined to comment for this story through his lawyer. Several other Georgetown Prep yearbook editors did not respond to interview requests.

In 1983, each senior was given a full page in the yearbook, where they listed high-school accomplishments and, for some, a litany of inside jokes. Kavanaugh’s yearbook page includes lines such as “100 Kegs or Bust,” “Renate Alumnius,” “Devil’s Triangle,” and “Beach Week Ralph Club.”

“Renate Alumnius” refers to Renate Schroeder Dolphin, a young woman from a nearby Catholic girls’ school, and a handful of football players at Prep’s “unsubstantiated boasting” about their sexual conquests with her, according to The New York Times. Kavanaugh has denied that interpretation of the note on his and 13 other pages in the yearbook, but a handful of classmates argued to the Times that it was in fact meant in a disrespectful way. And, for her part, Dolphin told the Times, “I can’t begin to comprehend what goes through the minds of 17-year-old boys who write such things, but the insinuation is horrible, hurtful, and simply untrue. I pray their daughters are never treated this way.”

The uncouth and sexist tone of the yearbooks, year after year, was ubiquitous enough that it suggests more of an intentional theme than the isolated actions of a handful of yearbook editors. In 1984, the year after Kavanaugh and Judge graduated, for example, captions say things like, “Some girls will do ANYTHING to go to a Prep dance!” and “Good friends always share” next to a photo of a young woman sandwiched between two Prep students with their arms around her.

The captions on the interstitial pages—things, in 1983, like, “Do these guys beat their wives?” next to a photo of Prep students—were Judge’s responsibility. But, as one Georgetown Prep alum told me, they are broadly reflective of the general sense of humor of the student body—at least the “popular” kids. He asked to remain anonymous, because he didn’t want former classmates to know he had shared the yearbooks with a reporter.

Kavanaugh was a part of that crew: the captain of the basketball team, a staple at parties—which were the home of, as many former classmates have said, heavy drinking. Of course, there were those in the Prep community who did not take part in those activities, as the alum I spoke with told me. However, this person says drinking was pervasive among the crowds Kavanaugh hung out in.

For its part, Georgetown Prep has tried to distance itself from the culture many ’80s alumni have described, and which it argues the media is covering “in pursuit of their own agenda,” without mentioning Kavanaugh specifically. “It is demonstrably false that such behavior or culture is tolerated, still less encouraged, at Georgetown Prep,” the institution said in a statement last week. The school did not return a request for further comment.

Regardless of the school’s potential cultural flaws, one particularly striking back and forth during last week’s hearing, between Senator Sheldon Whitehouse and Kavanaugh, stands out:

Whitehouse: One of the reasons, Mr. Kavanaugh, that we are looking at the yearbook is that it is relatively consistent in time with the events at issue here, and because it appears to be your words. Is it in fact your words on your yearbook page?

Kavanaugh: We—we submitted things to the editors and I believe they took them. I don’t know if they changed things or not, but—

Whitehouse: You’re not aware of any changes? As far as you know …

Kavanaugh: I don’t — I’m not aware one way—

Whitehouse: … these are your words?

Kavanaugh: I’m not aware one way or the other, but I’m not going to sit here and contest that.

Kavanaugh’s attempt to distance himself from his words by allowing that, perhaps, the editors could have changed what he submitted is understandable. However, to blame the editors is, in part, to blame his friend—and any legitimate attempt to distance himself from those words comes off as empty when that close relationship is taken into account.

During the Senate hearing, what began as an attempt to resolve whether Kavanaugh was party to a misogynistic culture that lent itself to the potential of sexual assault morphed into a discussion about whether he would be honest about his own words and actions, or try to push the responsibility onto others.



Every so often a tweet breaks out of its social medium, and finds its way to Instagram and Facebook. On Wednesday, the tweet spreading across the internet came from Burger King.

got student loans? what's ur $cashtag?

Either Burger King was saying that it was going to send money to student borrowers using Cash App, a mobile payment service (a $cashtag is its version of a username), or the fast-food giant was trolling all 92,000 people who responded to the tweet. Some of the responses to the Whopper purveyor were in jest, others seemingly genuine, but everyone wanted to know: Is anyone actually getting any money?

On Thursday, Burger King provided an answer. An ad showed a white screen overlaid with a jarring statistic in slime green as “Pomp and Circumstance”— you know, the graduation song—plays; “65 percent of students enter the world with student debt,” it says. Then, in an abrupt transition, the Burger King “King” appears swinging a flamethrower like Michael B. Jordan in Fahrenheit 451. “Your student debt goes here,” a caption bubble reads.

for real tho, we’re trying to pay off those loans. introducing Whopper Loans – make a purchase through the BK app for a chance to have your student loans paid off.
see App for details. no purch req’d.https://t.co/5XnCilnPW4 pic.twitter.com/3JKIuXdctB

To be clear, no one who sent in a $cashtag actually got money from Burger King. This was a marketing stunt to promote Burger King’s new initiative, called “Whopper Loans.” It encourages borrowers to make a purchase through its app (but there is no purchase necessary, per a bit of fine print), enter their monthly student-loan-debt amount, and then “cross your fingers.” “LET BURGER KING EAT YOUR STUDENT DEBT,” a promotional site declares. The contest runs for two weeks. During the first and second weeks, the company is providing 150 prizes of up to $500 in debt relief; each time someone completes the form, that person will be eligible for the grand prize of up to $100,000 in debt relief. (If the grand-prize winner’s loans total less than $100,000, the difference will not be paid in cash.)

College is expensive, so brands have taken to these kinds of social-media antics occasionally. Last year, Kentucky Fried Chicken announced that it would pay $11,000 to the first baby born on September 9, Colonel Sanders’s birthday, who bears the name Harland—Sanders’s real name. As my colleague Joe Pinsker wrote at the time, “Surely KFC intended for this stunt to get attention and press, which is a disappointing confirmation of the lengths to which corporations will go to set themselves apart in the churn of the social-media age.”

Burger King’s marketing push doesn’t require parents to sell away the naming rights to their child for an amount that is unconscionably low, given the expected rising costs of college. But it could have, instead, had a normal sweepstakes—you know, buy a burger, win some money, and do with it what you will—although that would hardly gin up the attention that paying off loans would.

And by doing it this way, BK could actually be saving some of the money that’s on offer. If the winner of the contest has the average amount of student debt—$28,560 as of 2017, according to a report from the Institute for College Access and Success—the company will be spending significantly less than the promised $100,000. When I asked a representative for the campaign about the potential amount of the payoff, she noted that Burger King also has a foundation that last year gave out $3.7 million in scholarships.

Student debt is a problem that needs a systematic fix. Without such a fix, a dystopian genre of debt relief is filling the void: the billionaire generous enough to pay off a class of graduates’ student debt, the game show where contestants compete for a student-debt-free life, the chicken place that wants to name your child, and the home of the Whopper that wants your $cashtag. This genre treats the idea of debt as a sweepstakes that only a lucky few can win; the fear is that people will get accustomed to it.



It was just a hair past 7 o’clock in the evening at Frederick Douglass Academy in Harlem, and Richard Carranza was a little late to the party. The cafeteria was bulging with parents, translators, and a handful of staff. The recently minted chancellor of the New York City public-school system had planned to arrive at 6 to talk to a handful of community activists in advance of a town-hall-style meeting. The topic at hand: diversity in the city’s public schools. Or, to put it more pointedly, desegregating them.

The racial makeup of the room was as varied as one might expect for a conversation about desegregation, particularly at such a tense moment in the city’s history. The movement to integrate New York City’s public schools had gotten new energy in recent months, but it was also met with fierce opposition. There have been viral videos of white parents angrily arguing that changing the schools will unfairly harm their children, politicians who backed reforms and then waffled after public pressure, and protests outside of the city’s Education Department punctuated by chants of “Save our schools.” In 2014, a study from the Civil Rights Project at the University of California, Los Angeles found that New York State has the most segregated public schools in the country, and that’s driven largely by New York City. Carranza, after just a few months on the job, has quickly positioned himself as the leading voice for integration—and he has his work cut out for him.

But on this humid Thursday in late June, Carranza was running behind. His meeting with the activists—which was scheduled to last roughly 30 minutes—was cut to five. He had to get to the main event—the diversity town hall. But even considering the disorganization, there was no sign of hurried concern as Carranza, 51 years old with jet-black, slicked-back hair, strode in through the back of the cafeteria. He has a giant personality packed into a 5-foot-8-inch frame, and was draped in what he calls his urban school-chancellor’s uniform—a pinstripe suit, neatly pressed shirt, a cornflower-blue tie, and pocket square to match.

“Good evening, everybody!” Carranza said after being introduced. His booming voice—cultivated from decades spent singing and playing in a mariachi band—filled the room. The crowd responded in kind. “Buenas noches,” he added.

Carranza doesn’t spend a lot of time reviewing what he’s going to say at events like these. He tends not to pre-write his speeches, he says, and keeps it simple. He opens by emphasizing the importance of talking about desegregating schools—not only because it’s a conversation he wants to have, but because kids in the classrooms are talking about it. People in the community are talking about it, as well. But with something as complex as dismantling a system of segregation, you could wear out your vocal chords before anything fundamentally changes—and people in New York City, which has one of the most segregated school systems in the country, have been talking about it for a long time.

“Sixty-four years ago, the question of diversifying schools—” Carranza caught himself. He considers diversifying to be weak language.

“—integrating schools,” he continued, “was definitively settled by the United States Supreme Court in Brown v. Board of Education.” The court said separate is never equal, especially in education, he told the audience—which applauded. But 64 years later, the city, and the country, have little to show for it, Carranza said. And nationally, the United States is resegregating, with the number of schools that are less than 40 percent white doubling between 1996 and 2016.

At this point, the chancellor was preaching. He proclaimed that the U.S. had become complacent after electing its first black president. He expressed dismay about the past 17 months of the Trump administration. And he didn’t mince words about the racially coded language people had used to criticize his approach to changing the city’s schools. He was standing before a cafeteria table turned pulpit and the crowd found itself attending the Church of Carranza.

“It’s important that we put the real issue on the table, and the issue on the table is this,” Carranza said near the end of his speech. “In one of the most diverse cities in not America but the world, and in the largest school district in America, a school district that is public,” he said, underlining the word public in the air, “are opportunities really open for all people?”

After his remarks, Carranza made his way out of the cafeteria through a swarm of people. A slender black man stopped him just outside the doors. “You’re tackling a big tiger, you know that, right?”

Carranza smiled. “You’ve just got to jump on it,” he said.

The man quizzed the chancellor with his eyes. “Okay,” he told Carranza, “I’ve been jumping on it for decades.”

Activists have indeed been trying to integrate New York City schools for a long time. The implied question was: What’s different now?

“Well,” Carranza said, “you’ve got a new one helping you.” But more than 50 years after the Supreme Court definitively settled the matter, school segregation remains a formidable foe, a Goliath that no single David may be able to conquer.

There are a couple of guitars that rest against the back wall of Richard Carranza’s office at the Tweed Courthouse in Lower Manhattan—next to City Hall—where the city’s Department of Education is headquartered. One of them has traveled with him to every office he’s held as an administrator. Carranza, who was inducted into the Mariachi Hall of Fame in 2016, says music is what drew him to education.

He started learning to play mariachi when he was a little kid, maybe 6 or 7 years old, he says. His reason was simple: He didn’t want to go to bed. His father, a sheet-metal worker and a first-generation American, and his uncles told him that only people playing music were allowed to stay up late—so he picked up the guitar. Carranza, who didn’t speak English until elementary school, quickly fell in love with the instrument.

Carranza and his twin brother, Reuben, went to the public schools in Tucson, Arizona. Then, in the mid-’80s, they both went to the public college nearby: the University of Arizona. They participated in a summer bridge program that gave them an early exposure to the campus. They took classes, learned about financial aid, the dorms, student life, the whole nine. The program was full of students like him. “It was fantastic because there were a bunch of kids that looked like me in a sea of a kids that looked nothing like me,” he told me. In college, Carranza remembers realizing the extent of the gaps in his education up until that point. Sure, he could keep up, and he wasn’t forced to take remedial courses, but there were little things, like books he hadn’t read that all the other students seemed to be able to cite. Lessons many of the white kids had learned in secondary school that he hadn’t. It was an early lesson for him: Not all public-school educations are created equal.

When it came time to choose a major, Carranza went where the futurists said all of the jobs would be: electrical engineering. Meanwhile, he was still playing mariachi—“gigging,” as he says—all around town, and teaching guitar lessons to children, which helped him pay for college.

The engineering program wasn’t easy. The math he had to take for his major didn’t come naturally, and he was struggling to get C’s. He found himself spending more time teaching kids how to play guitar than he did focusing on his classwork. Maybe, he thought, he was in the wrong field. He asked a friend about transferring to the School of Education. He had two years of classes toward an engineering degree under his belt, but he wasn’t feeling excited about it. So, he switched his major. It wasn’t until Carranza’s final semester at the university, however, that he really knew that was the right call. It was time for him to be a student teacher, and he was nervous. It was terrifying, he says, the idea of standing in front of a classroom of boys and girls whose futures depend, at least in part, on the information you give them, and how you give it. But as soon as he stepped into the classroom, all of that went away.

Carranza went back to his old high school to be a bilingual social-studies teacher but when he arrived he was “mortified” to see how the arts offerings had deteriorated during his time away. The school was about 92 percent Mexican American and many of the students were like him: They weren’t immigrants themselves, but they were deeply immersed in Mexican culture. One weekend a group of kids saw him “gigging” at a wedding and said they wanted him to teach them how to play guitar. He happily said yes. Then, they wanted to learn to play the trumpet. Soon, the after-school tutoring inspired a student-led petition for a mariachi class—one that Carranza would give up his free period to teach.

But the road to getting the program approved, he says, was lined with “outright racism.” Music teachers “would flat out say to my face: ‘Oh, I can’t support this, this is music played in bars for drunks.’ And, ‘We can’t play this in the public-school system, this is not a legitimate art form.’” Then there were bureaucratic hurdles. “There are a couple of incidents where I ran up against people who had more authority in the system [who] were making decisions not to allow this program to really flourish,” he says, still visibly frustrated.

But the class was successful. It grew into a full-fledged mariachi program comprised of hundreds of students a year, and, nearly three decades later, is still in existence. The mariachi program did more than just sustain itself; it also reignited interest in the other arts programs—orchestra, choir, band. “I saw the power of culturally relevant pedagogy,” Carranza told me.

That experience led him to wonder if there was more he could do to help underserved students, he recalls. He felt that to make change, he needed more power. “I wanted to have authority over my school, so I became a principal,” he told me. “Well, people above me didn’t quite get it, so I wanted more authority over portfolios of schools, and eventually became a superintendent.” It wasn’t what he set out to do when he first got into education, but he says it was the best way to fix what he saw as broken systems.

He became the principal of his high school, then a regional superintendent in Nevada, before landing in San Francisco. In 2009, he was named the first “deputy superintendent of instruction, innovation, and social justice” for the city’s school district. And then, upon the retirement of the then-superintendent Carlos Garcia, Carranza was named to the leadership post in 2012. He was responsible for more than 50,000 students. He says the weight of the situation hit him, and he felt like Robert Redford at the end of The Candidate—a movie he regularly showed to his classes.

“What do I do now?” he says he asked himself at the time. “Do I try to be the stereotypical superintendent: political, hard to get a hold of, all of the things that you hear about superintendents? Or do I just be myself?”

Carranza quickly made a name for himself in San Francisco. Three years after he became superintendent, Education Week honored him as one of their “Leaders to Learn From,” for his emphasis on bilingual, bicultural education. He had also built a reputation as someone who was willing to tackle inequality in the educational system. For example, before California changed its statewide funding policy for schools, Carranza’s district was diverting extra money to schools with high proportions of poor students and English-language learners. “He’s brave, he’s honest; he’s more than just an advocate, he’s a fighter for social justice,” Eric Guthertz, the principal of Mission High School in San Francisco, told Education Week at the time.

During his tenure in San Francisco, Carranza made a point of focusing on the inequality of the city’s school system in his public remarks. When a vocal group of parents—and a pair of politicians—protested a curriculum change Carranza oversaw that removed some of the advanced math courses for middle-school students, he explained that he was not trying to harm students trying to excel, but help those who had been left behind. “We are being accused of only caring about black and brown kids,” he told parents gathered at a board meeting, before pointing out that at one high-performing high school, of the 928 students who took Advanced Placement calculus or statistics exams over a two year span, only 21 were Latino, and 7 were black.

“Not 21 percent and 7 percent; 21 and 7,” he told the audience. “Now either black kids and brown kids cannot do math—they are biologically, physiologically, genetically not prepared to do math—or something else is wrong. And I would suggest to you that something else is wrong.”

But in his four years leading the system, there were some issues he just couldn’t crack. There was the dismally low performance of African American students on California’s standardized tests. According to a report by Innovate Public Schools, a Bay Area nonprofit, in 2016, at the end of Carranza’s tenure, only 19 percent of African American students were on grade level in reading, and 13 percent in math. Similarly, the Education Trust-West, an advocacy group for low-income students and students of color, found that year over year, the San Francisco school district ranked near the bottom of schools in California on measures of black and Latino achievement.

Still, the city of Houston took note of Carranza’s personal story, and his message of equality, hiring him away from the Bay Area in August of 2016. After a “listening tour” around the city, he quickly released a pair of ambitious proposals. First, he wanted to change how schools were funded. Instead of funding schools based on enrollment numbers, he wanted to guarantee certain basic resources for every school in the district: a nurse, a social worker, a low student-to-teacher ratio. Then, he wanted to tweak the admissions process for the district’s magnet schools—some of the top schools in the state, if not the country. Two of the schools are ranked in the top 50 of the U.S. News & World Report high-school rankings, and he had proposed diverting some of the extra funding those schools received to more resource-poor schools.

Carranza has received his fair share of criticism for his time in Houston—partly because it was so limited. He only spent 18 months there. That’s nowhere near enough time to address the sorts of problem the school district faces, and indeed his proposals never came to pass. After all, four years hadn’t been enough in San Francisco. Further, during his tenure the district dealt with a looming threat of a state takeover of the school system resulting from a state law that required the Texas Education Agency to control operations of any school district in which one or more schools failed to meet state academic standards for five consecutive years.

Despite the short duration of his stint in Houston, Carranza nevertheless gets animated when he talks about it. “You would think if you want to integrate schools and really provide a robust push for the entire system, you would place some really sexy magnet schools in those African American neighborhoods,” he says, sitting up a bit. “No! They were all concentrated in white, upper-middle-class neighborhoods, so that if you’re an African American student, you have to leave your neighborhood to go to those programs.”

By the end of his time in Houston, Carranza had an answer for the question he had asked himself when he first became a superintendent:

“I’ll be damned if I’m going to turn into somebody [else]. I’m going to be myself.”

Carranza wasn’t Bill de Blasio’s first choice to run New York City’s public schools. On the last day of February this year, Mayor de Blasio announced that he’d selected someone to replace the outgoing Department of Education chancellor, Carmen Fariña. Fariña was an experienced and celebrated educator and administrator in the city, but activists had soured on her for focusing on “diversity” instead of “desegregation.” In practice that meant Fariña’s department didn’t want to force integration on the city. That approach, activists said, was too passive.

Alberto Carvalho, de Blasio said, was the right guy for the job. Carvalho, the superintendent of Miami’s public schools, checked all of the boxes it seemed the city was looking for. He was an immigrant, the first in his family to graduate from college, a star in the education world. He had experience running a system with a large share of poor, non-native English speakers, and he, himself, was bilingual.

But the plan to hire him broke down suddenly. During a five-hour board meeting in Miami a day later, at which Carvalho was expected to announce that he would be leaving the Miami school district after a decade at the helm, constituents begged him to stay. The superintendent, in a move that surprised everyone, even possibly himself, agreed.

De Blasio’s office entered full-blown public-relations-crisis mode. This was an embarrassment for the mayor, who had already been pilloried in the press for taking two months to find a replacement for Fariña in the first place. The mayor and his staff turned to Carranza, whom they had eyed for the job earlier—and the move shocked quite a few people who argued that his track record was too thin to take over a 1.1 million-student school system. “The pipeline for superintendents is very thin,” Priscilla Wohlstetter, a professor at Columbia University’s Teachers College, told The New York Times at the time. “We are the largest district in the country, and this is the caliber of person we end up appointing?”

Carranza had been getting national attention for his response to the devastation in Houston’s schools after Hurricane Harvey tore through the Texas coast. But he was still fighting an uphill battle to reform the city’s inequality. Packed rooms of concerned parents opposed any dramatic upheaval. And the school board didn’t rally behind his reform agenda either.

Then he got the call from de Blasio, and Carranza and his wife loaded up the Penske truck to move to Brooklyn. “Unfortunately,” he sighs, “all of those proposals [in Houston] went by the wayside. As soon as I left, it seemed like people just didn’t have the stomach to take the fight.” His ideas for an equitable future in Houston had come to naught—much like they had in San Francisco. But de Blasio still admired his vision. Carranza took the fight to New York. And he walked into a melee.

There are two schools—one in the Bronx, one in Manhattan—that, in some respects, represent the opposing poles of New York City’s public-school system: P.S. 277 in the Bronx and Stuyvesant High School, the prestigious “specialized” school, in Manhattan.

I met Carranza at P.S. 277 on a Thursday morning in mid-June—before the town hall later that night. There was a brief rain, and you could nearly drink the air, but Carranza didn’t show any signs of dismay. He stepped out of his chauffeured black four-door sedan wearing his usual full smile, greeting every person within a stone’s throw. Parents, checking in with the security guard at the front door of the Gothic building, were flooding into the school. It was graduation day.

It was the first full year of 3-K for All—the city’s early-education program—and a crowd of 3-year-olds were dressed in their finest for the ceremony marking their move to the next year of pre-K. The auditorium consisted of rows of stadium seats, with a stage capped by an abridged version of the Shakespeare quote “To thine own self be true, And it must follow, as the night the day, Thou canst not then be false to any man.” This was a bilingual program, but the students gathered onstage to sing a pair of songs in English. Carranza beamed in the front row as a 3-year-old in a powder-blue plaid suit and pink bowtie sang “You’ve Got a Friend in Me.”

Carranza gave brief remarks, switching between English and Spanish, and announced a book giveaway for every student enrolled in the city’s pre-K programs for 3- and 4-year-olds. Both of these programs, early interventions of sorts, are aimed at mitigating the effects of New York City’s segregation problem. The highest concentration of students going to “intensely segregated” schools—meaning schools with less than 10 percent white enrollment—are black and Latino.

P.S. 277 is one of these “intensely segregated” schools. It is nearly 75 percent Latino and 23 percent black. A sliver of its population consists of American Indians. Just under 100 percent of students are eligible for free lunch. As has been well-documented, schools with high shares of black and Latino students are placed at a disadvantage. They have worse facilities. The teachers aren’t as experienced. The instructional materials are outdated. According to the statistics, students going to P.S. 277 will have fewer, and worse, opportunities throughout their lives.

As we left the school, and Carranza and I rode in the back seat of the city-issued black sedan, this fact was on his mind. “Everywhere I’ve ever lived and worked, there are systems and structures that promulgate certain outcomes,” he told me, slightly squinting and gesturing with his index finger. “The systems and structures give you what you get. And what I’ve found is that what you get is low performance for kids of color, low opportunities for kids of color, poor kids, kids that have historically been underserved.”

A day later, I was at Stuyvesant High School, one of the oldest “specialized high schools” in the city. It is an absolute beast to look at. The building is grand; so too is the foyer. A massive wraparound staircase, with the school’s motto—Pro Scientia Atque Sapientia (“For Knowledge and Wisdom”)—engraved just overhead, leads you to the second floor. The hallways are plain, like those of just about any high school in the country. But it’s what’s in the classrooms that stands out. Eric Contreras, Stuyvesant’s principal, gave me a tour of the school. It was the day after graduation, so there weren’t many students around, but the amenities alone conveyed a lot. There were 3-D printers and robotics labs, green spaces, and giant windows with views of the Hudson River.

But for all it has, there’s one thing it lacks: a diverse student body. And Contreras knows it—not only as the principal, but as a parent. When his daughter went to Stuyvesant, prior to him becoming the school’s leader, he told me, she was one of fewer than 10 Latina girls in her class. His son will attend the school this fall, and will be one of the few Latino boys. Contreras, who himself went to segregated schools in the city, has seen the conversation about integration ebb and flow over the decades. But there is a new energy with Carranza, he says.

However, it takes more than energy to reform New York City’s public schools. Carranza is an idealist, for sure, but there have been a lot of idealists who have held his position—and the realities of the city often won out over their idealism.

To be sure, there have been some chancellors who have persevered despite the city’s aversion to sudden, substantial change. Take Joel Klein, for example, who served as chancellor under Mayor Michael Bloomberg for eight years. Klein developed a reputation as perhaps the most effective chancellor in decades, though he was also controversial, especially as a Democrat who fought the teachers’ union. He implemented a uniform math and reading curriculum, a plan to phase out poorly performing high schools, and established a training program for aspiring school administrators.

Klein’s platform didn’t focus on desegregating schools, but activists, alumni, students, and administrators told me Carranza’s passion reminds them of Klein. It’s not only that he has helped jump-start the conversation, Contreras told me, “it’s the action” that has accompanied it. But such action requires additional help from the state legislature, which has been wary of making big changes.

But the bold steps to quickly lay out a vision, Contreras says, are notable. Somewhere around the eighth floor, Contreras—who is a bilingual immigrant, and the first Hispanic principal of Stuyvesant—stopped me. “If we want to be educational leaders,” he told me, “we must be constantly imagining what’s ahead. And what I see with Richard Carranza is that he’s willing to do that.”

The “specialized high schools” such as Stuyvesant can be a way for students to get out of the intensely segregated community schools such as P.S. 277. But getting into them is difficult, to say the least.

Students who want to get into one of the specialized schools must pass the Specialized High School Admissions Test, or the SHSAT, which parents often pay exorbitant prices for their children to prepare for. Only about 10 percent of more than 5,000 seats at the eight specialized high schools in the city went to black or Latino students in 2018; 51.7 percent went to Asian students; and 26.5 percent went to white students. Black and Latino students make up 67 percent of students in the public-school system. Three decades ago, the number of black and Latino students at the specialized high schools was much higher.

In early June, Mayor de Blasio introduced a plan that would change that. He wants to do away with the admissions test, calling it an unjust barrier for black and Latino students. And Carranza agreed. “We’ve got almost 600 middle schools in the city of New York,” he told me. “Yet 21 of those middle schools account for 50 percent of the student seats in these specialized schools.” The plan, which faces tough odds of gaining support, also laid the groundwork to eventually allow the top 7 percent of students at each of the city’s middle schools the opportunity to attend one of the specialized high schools.

The criticism came quickly. One major problem is that changing the structure of admissions could disadvantage Asian students, who make up the majority of the specialized high schools, and who often come from poorer homes than the black and Latino students. Some critics argued that changing the admissions structure, ostensibly to raise the number of black and Latino students, would water down the academic integrity of the institutions. And then there was the fact that this was only addressing a small slice of the bigger problem of segregation in New York City. That’s the argument that Larry Cary, the president of the Brooklyn Tech Alumni Foundation, makes. “We believe that the test is a meritorious mechanism for selecting students for these schools—and it has the additional value of being an approach that doesn’t pit one group against another the way this proposal has,” he told me.

Carranza understands the concern about Asian American students—though, he counters, a lot of the poor Asian American students’ families are already being harmed by the test. “You have the people who can least afford to be paying for this test prep that are spending thousands of dollars to do this test prep,” he told me. Further, he said, committing to equity means that an overrepresentation of any kind—regardless of what race might be overrepresented—needs to be addressed. Particularly when the underrepresentation of black and Latino students is so stark.

Still, Cary sees the solutions from Carranza and de Blasio as “excuses” for not dealing with the most fundamental issues of inequitable education in the city. It’s one thing to pick on the top-tier school, his thinking goes, but what about the system-wide problems?

Carranza admits that introducing a policy change to the admissions process for specialized high schools only fixes a small problem, but for him, it’s an important one. He analogizes it to the image of the iceberg—one of his go-to talking points. Specialized schools are the tip of the tip of the iceberg, he says. And when you zoom out, there is 20 times more ice underwater that needs to be addressed.

In late June, Carranza released the results of a “listening tour”—where he went around the five boroughs to schools, town halls, and meetings with activists and lawmakers. His report, “Moving Toward a More Equitable School System,” lists the strengths of the city’s schools first, then it moves to the challenges. No. 1 on that list? Desegregation.

He’s been hammered for going after the top schools when so many other things need to be addressed, but he says this plan is not only symbolic, it’s tangible. It’s a change the city can make right away. But there are other goals as well: He wants to devote more funding to under-resourced schools to put them on a level playing field. (“I have never, ever, ever, ever, ever, seen a high-performing school that has a majority of privileged students that is under-resourced,” he told me.) And he’s approving district plans that increase access to high-performing schools for low-income and minority students.

The outstanding questions about how to fundamentally desegregate New York City’s public schools still need to be asked and answered. Carranza says he’s trying to find those answers, “but as I’m asking questions, we’re actually moving policy.” The city has been talking about the issue for years. Too many, if you ask him. Brown v. Board was settled more than half a century ago; desegregation is long past due. “Sixty-four years ago,” he laughs, with a hint of despair. “We’ve been admiring this issue for 64 years! Let’s stop admiring and let’s start acting.”

And he’s changing minds along the way. “I have renewed faith,” Wohlstetter, of Columbia, told me in a recent interview. “Fariña thought the way to make changes in a system was only from the ground up—unless the people, including the elites, wanted change in integration, it shouldn’t happen.” But Carranza is different—and so is the moment, she says. More and more people now know that New York has the most segregated schools in the country, and that’s allowed for an equity agenda to resonate more clearly—an agenda that Carranza, alongside the mayor, has been able to lay out early in his tenure. She reneged on the skepticism of Carranza—and the superintendent pipeline—she had shared with the Times. “This has been an issue for years but it never got traction” until Carranza, she laughed. “Maybe the pipeline is deeper than I thought it was.”

But his four years leading the system in San Francisco—with far fewer students—showed Carranza that even with an equity mission, reversing baked-in systemic issues can be difficult, if not impossible. One thing is clear, however: Richard Carranza isn’t changing his tune for anyone.

“What I said today is what I was saying in Houston, is what I was saying in San Francisco, is what I was saying in Las Vegas, is what I was saying in that classroom in Tucson, Arizona, to a bunch of barrio kids that didn’t think they could go to college,” he told me. “Why?” he asked. “Because that’s who I am. That’s what I believe in.”

As many have before him, the chancellor wants to talk about segregation and he wants to talk about genuine equity. But he also wants to do more than talk this time. What’s less clear is if the rest of the city is ready.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

At least 2,000 children have now been forcibly separated from their parents by the United States government. Their stories are wrenching. Antar Davidson, a former youth-care worker at an Arizona shelter, described to the Los Angeles Times children “huddled together, tears streaming down their faces,” because they believed that their parents were dead. Natalia Cornelio, an attorney with the Texas Human Rights Project, told CNN about a Honduran mother whose child had been ripped away from her while she was breastfeeding. “Inside an old warehouse in South Texas, hundreds of children wait in a series of cages created by metal fencing,” the Associated Press reported. “One cage had 20 children inside.”

On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.

About 65 million years ago, shortly after the time of the dinosaurs, a new critter popped up on the evolutionary scene. This “scampering animal,” as researchers described it, was likely small, ate bugs, and had a furry tail. It looked, according to artistic renderings, like an especially aggressive New York City rat. And it had a placenta, an organ that grows deep into the maternal body in order to nourish the fetus during pregnancy.

The rodentlike thing would become the common ancestor of the world’s placental mammals, with descendants that include whales, bats, dogs, and humans, among many other species. And today, the placenta might hold the key to one of the most enduring mysteries in human medicine: Why do women suffer much higher rates of autoimmune disease than men do?

Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

There’s a moment about 15 minutes into the first episode of Years and Years that made me gasp at its audacity, its prescience, its visual horror. The new six-part series from the British writer Russell T. Davies (Doctor Who, A Very English Scandal) charts the life of the Lyons family over the course of 15 years, starting in 2019 and ending in 2034. It’s a kitchen-sink saga that barrels its way through births and marriages and betrayals, but also through the near-future. In 2024, Stephen Lyons (played by Rory Kinnear), a financial adviser, is at home with his wife, Celeste (T’nia Miller), both rushing their way through the morning routine. When the camera turns to their teenage daughter Bethany (Lydia West), her face isn’t recognizably human. Instead, she looks like a 3-D version of a Snapchat puppy, with vast cartoon eyes, wagging pink ears, and a brown snout. When she talks, her voice is grotesquely distorted, a robotic hallucination of a child’s cadence. “I might have to start limiting filter time,” Celeste says in the same exasperated, noncommittal way that you might think, I really should spend less time on Twitter.



Last summer, Charlottesville, Virginia, became the site of a multi-day white-supremacist march and rally that left one woman, a counter-protester, dead, setting off a wave of emotions and accusations that shook the city and the country.

Charlottesville has still not come to terms with that event, said Melody Barnes, former President Barack Obama’s chief domestic policy adviser, late Monday afternoon at the Aspen Ideas Festival, which is co-hosted by the Aspen Institute and The Atlantic. “The trauma that you can feel and hear in conversations [today suggest that] Charlottesville has not moved forward,” Barnes said.

And that will be tough to do, Barnes said, given the deep racial divisions that characterize the city. The University of Virginia (UVA), which has strived in recent years to improve access and inclusion for students of color, remains one of the country’s least socioeconomically diverse public universities. UVA, of course, was built by slaves. And the school’s founder, and the city’s most famous resident—Thomas Jefferson—enslaved more than 600 men, women, and children.

Charlottesville faces racial divides that go way beyond its history and the university. The city’s K-12 schools, Barnes noted, comprise one of the most unequal public-education systems in the country: One 2016 study by Stanford researchers found notably large black-white educational disparities in the city. An article in The Atlantic concluded this outcome to be symptomatic of a phenomenon that it described as the “college-town achievement gap.”

Barnes, who today runs a domestic-strategy firm, and others on the panel agreed that Charlottesville won’t be able to leverage the events of last August to improve race relations within the city, if its people don’t confront the racial inequalities that persist.

“We can’t heal until we get at the truth,” said Leslie Greene Bowman, the president of the Thomas Jefferson Foundation, which owns and operates the Monticello site in Charlottesville. “The events of last summer ripped open wounds that had been … swept under the rug.”

This isn’t some phenomenon that’s particular to Charlottesville, added Barnes. “People think about this as a Charlottesville problem; people think about this as a Southern problem. It’s a problem that sits on the American DNA … and we have to grapple with it.”

“This is,” Barnes continued, “part of who we are as Americans.”



It’s widely known that young adults in the United States tend to vote at lower rates than older Americans, but it’s easy to gloss over just how stunning the numbers really are—especially at a time of such intense political polarization and divisiveness. Only half of eligible adults between the ages of 18 and 29 voted in the 2016 presidential election that sent Donald Trump to the White House. During the 2014 midterm elections two years earlier, the youth-voter-turnout rate was just 20 percent, the lowest ever recorded in history, according to an analysis of Census data.

These troubling voting rates follow decades of declining civics education. Starting in the 1960s, robust civics instruction, which usually took place through three standard high-school courses, started to atrophy. It’s likely not a coincidence, then,  given evidence suggesting a link between civics education and voter participation, that the 1960s coincided with a slump in the rate of young adults who cast ballots.

A newly released survey by the Woodrow Wilson National Fellowship Foundation illustrates the sorry state of civics education today: Just one in three Americans would pass the U.S. citizenship test. It’s not a test known for its difficulty: The vast majority of citizenship-seeking immigrants pass easily. (A real question on the test: “Identify whether Rhode Island, Oregon, Maine, or South Dakota is a state that borders Canada.”) Only 13 percent of the 1,000 survey respondents, nearly all American-born, could say when the Constitution was ratified (1788, if you were wondering), and fewer than half could identify which countries the U.S. fought against in World War II. Among the most egregious examples from the survey: Two percent of respondents identified climate change as the cause of the Cold War.

According to a report published earlier this year, just nine states and the District of Columbia require one year of government or civics classes in high school. But beyond that, most existing civics-education efforts focus on kids in high school and college who are of voting age or close to it—not younger children. For example, one of the most high-profile national initiatives to improve civics education in recent years has homed in on the tail end of the K–12 trajectory, seeking to make passage of the U.S.-citizenship test a graduation requirement nationwide. Today, 29 states have some kind of citizenship-test law on the books, according to Lucian Spataro, the CEO of the group Civics Education Initiative.

Some observers emphasize that to really ensure that kids learn the importance of civics, schools should start lessons much earlier. Ideally, says Kei Kawashima-Ginsberg of Tufts University’s Center for Information and Research on Civic Learning and Engagement, civic engagement should inspire students to translate knowledge about government and policy making into action—from volunteering and community organizing to lobbying and voting. For kids to really understand that connection, advocates say civics learning should start at a young age.

Only a couple of states, such as Florida, have civics-education requirements for middle schoolers, even though that’s when students nationwide take a standardized civics test as part of the National Assessment of Educational Progress. Middle school is also a time in students’ educational trajectory that is better structured for such education than later stages, when school becomes broken down into more distinct disciplines that make it difficult to integrate this kind of instruction seamlessly, says Kawashima-Ginsberg. And kids at this age undergo dramatic developmental and intellectual changes that render them particularly ripe for understanding the importance of civics. Likewise, if high school is the first time kids get exposure to the subject matter, teachers may struggle to motivate them. Other advocates go even farther, saying that civics lessons should start as early as kindergarten, when kids begin to read and discuss identity.

This type of early civics education might connect with students more easily if it’s woven into the existing fabric of everyday schooling—for example, into a science lesson on pollution, or a history class where students are learning about Native Americans. Civics shouldn’t just be taught in one separate class; it should be a staple of education, “the lima beans on the curricular plate of the elementary student’s day,” as Paul Fitchett, an education professor at the University of North Carolina at Charlotte, put it in a interview with the education-news outlet Chalkbeat.

That Florida requires schools to introduce civics in elementary school may help to explain why the state has seen steady improvement in students’ civics proficiency: In 2017, 70 percent of seventh-graders passed the state exam, up from 61 percent in 2014. And a Washington Monthly article even attributed the activism of teens at Parkland, Florida’s Marjory Stoneman Douglas High School—where 17 students were shot and killed in February— to the state’s early civics requirement. In launching a nationwide movement for stronger gun control, wrote the authors Frank Islam and Ed Crego, the students have “been the beneficiaries of what is arguably one of the nation’s most comprehensive and successful efforts to teach civic knowledge and engagement.”

Besides the Parkland teens, young people have been especially enthusiastic about politics of late, but it means little unless they translate it into a trip to the ballot box in November. And the early signs aren’t promising: A recent poll from Gallup indicates that just 26 percent of 18-to-29-year-olds say they intend to vote in the November midterms, compared to 82 percent of Americans 65 and older.



Last year, Lavell Burton decided he wanted to learn to code. He searched online for coding bootcamps, and was surprised to find that many of them cost several thousand dollars upfront. Burton, then 36, was hoping to move from his maintenance job aboard an American naval ship to a career in software engineering in California, where he grew up. He finally came across a 30-week remote program, Lambda School, that was free to attend. The program would provide comprehensive web-engineering training, and would help with job placement. Once employed, graduates would be required to pay back a set portion of their salary under an arrangement called an income-share agreement, or ISA.

Burton made it through Lambda School’s rigorous selection process, including an entrance exam covering math and logic. By last fall, he was back in the Bay Area, where he moved in with his ailing grandmother and prepared to begin classes. “They’re taking a chance on me,” Burton remembers thinking of Lambda School. “If I win, they win.”

The concept of ISAs has been around since at least the 1950s, when the economist Milton Friedman outlined them as a hypothetical model of repayment. Yet ISAs were rarely implemented until the past few years, as student-loan default spiked and schools sought to offer other ways to pay. In 2016, Purdue University launched an ISA tuition option aimed at families who might otherwise take out high-interest private loans or Direct PLUS loans for parents to fill the gap between federal student loans and the cost of tuition. Purdue hired Vemo Education, a for-profit startup, to help design and administer the program, which is largely backed by the university’s funds. The private schools Clarkson University and Messiah College have since announced plans to follow suit, as has the United States Collegiate Athletic Association, which has partnered with Vemo to create ISA options for its roughly 80 member schools.

Among for-profit programs, in 2012, App Academy, a coding bootcamp with locations in San Francisco and New York, began offering a twelve-week program built around an ISA. Others, like the New York Code + Design Academy, which provides a range of web engineering and design courses, and Holberton School, a two-year program in San Francisco, have similar payment options.  

General Assembly, a popular for-profit tech bootcamp, offers tuition financing through private lenders like Climb, but Jake Schwartz, the CEO and a cofounder, said he wants better payment options for students with poor credit. General Assembly recently piloted an ISA option with thirteen students, some of whom are still job-hunting. Once they are making at least $35,000, they will pay back 6.5 percent over five years. Schwartz said General Assembly is soon planning a broader rollout of the ISA option, to see whether ISAs can work on a larger scale and for a broader swath of the population than they currently do. “Right now, it’s sort of the Wild West,” Schwartz said.

This all comes at an opportune time. There are more than 550,000 open jobs requiring computer-science skills, while fewer than 50,000 computer-science majors entered the workforce last year, according to an analysis of federal labor data by Code.org, a nonprofit that seeks to expand programming instruction in K-12 schools. Leaders of the ISA-based training programs see a business opportunity in the Lavell Burtons of the world—promising individuals without access to cash or credit for tuition. They are betting they can groom them, over the course of a few months, into tech professionals who command competitive compensation in a hot job market. And then take a cut.

The ISA-based programs have generated hype, as well as some early success stories. Yet questions remain about whether they are a good deal for students and if they make for profitable businesses in the long run. For one thing, there’s little consensus around how much is fair to reap from program graduates, and for how long. Lambda School, for example, requires graduates earning at least $50,000 to pay back 17 percent of their salary for two years, with total payments capped at $30,000. The terms can vary widely among programs.

Also, while it’s clear how programs like Lambda School might help some people improve their prospects, many of them are so new—Lambda School is one year old this month—that there isn’t much data about how people do once they get through the programs. That makes it difficult for prospective students to evaluate them.

Pathrise, a remote, part-time program that started offering an ISA option in January, helps software engineers and others polish their job-search and interviewing skills. Graduates making at least $50,000 agree to pay back 7 percent of their salary for one year. The reasoning, according to Kevin Wu, a Pathrise cofounder: “We help you get a job that’s at least 7 percent better than the job that you could have gotten.” Perhaps—but with just a few dozen graduates to speak of, some of whom are still job-searching, signing on is still somewhat of a gamble for early participants.

Pathrise helped Aaron Ko, a 22-year-old software engineer, switch from a $68,000-a-year coding job to a position at an e-commerce startup called Ipsy, where he makes more than $100,000. The 7 percent payback rate seemed fair to him given the salary bump, he said, and he’s satisfied with his new job. But he pointed out that, since California taxes are so high, his Pathrise payments represented about 11 percent of his post-tax income. “That part is a little bit misleading,” he said. Wu said he is exploring how the program might be tax-deductible for students as a job-search expense.

Because programs like Lambda School and Pathrise aren’t accredited academic institutions and don’t have to adhere to external standards, some educators and policy analysts are nervous that businesses might take advantage of students. “I think there’s a significant risk that predatory or discriminatory terms could be put on ISAs,” said Clare McCann, the deputy director for federal higher education policy at New America's Education Policy program. Two bills were introduced in Congress last year—one in the Senate and one in the House of Representatives—that would establish basic rules for ISAs, like a cap on total payments. They have each stalled, and aren’t expected to proceed anytime soon.

It remains unclear, too, whether the programs can consistently recruit enough high-potential students to sustain profitable operations once they exhaust their venture capital. Last year, MissionU, a venture-backed for-profit school, debuted a mostly remote, full-time, one-year program with the bold mission of replacing traditional undergraduate education. The program, founded by Adam Braun, focused on preparing students for jobs at Silicon Valley firms like Uber. MissionU would be free to attend, and graduates making at least $50,000 would owe 15 percent of their salary for three years. But last month, after a little more than a year in operation, MissionU announced it had been acquired by WeWork, which mostly shuttered its operations and released graduates from payment obligations. Braun is now planning to help run WeGrow, a new elementary-school venture WeWork has started.

There are also some student needs that unaccredited programs aren’t equipped to meet. As a young teenager in Oakland, California, Burton was arrested multiple times for minor offenses like stealing a dirt bike. He spent a year in a juvenile detention center, followed by two years in a rehabilitation program, where he earned a G.E.D. He later worked odd jobs, and in 2009, he earned a certificate that allowed him to work as a pediatric medical assistant. He enjoyed the work, he said, and took particular pride in putting young patients at ease. After five years, he explored the possibility of becoming a registered nurse, but discovered he’d need to invest in years of additional coursework and training. He balked, and applied for the ship-maintenance job instead.

That Lambda School is free to attend made it a viable option for Burton. But because it isn’t an accredited institution, he wasn’t eligible for federal student loans to spend on expenses—and Lambda School didn’t officially cover them, either. When his grandmother died late last year, her home was foreclosed upon, leaving him without a place to stay. He subsisted on food stamps, bouncing between his father’s San Francisco single-room-occupancy unit and friends’ couches while on the waiting list for shelters. Soon after Burton began the program in April, Austen Allred, its cofounder and CEO, learned that Burton was homeless, and arranged for him to move into a home shared by several other coders near San Francisco State University. Lambda School, with the help of donors, is covering his rent.

“My goal is to take care of all the things that could be a distraction,” Allred said. “If I can do that, I know I can get them to a high-paying job.” Allred recently helped a couple of students in similar situations find and pay for housing. He’s exploring setting up a nonprofit fund to cover some students’ living expenses at scale, and said he might eventually build a brick-and-mortar campus with subsidized onsite housing.

For now, the stopgap solution to Burton’s problem made a difference. He said he sailed through Lambda School’s early lessons on front-end development. As the course turns to frameworks like React, though, the material has become more complex, so he’s lately spent more time going over lessons in online chats and meet-ups with fellow students. By the end of the program in October, he said he hopes to be well-positioned for a high-paying software-engineering job someplace like Google. He said that, whatever the ultimate outcome of his experience, he felt he had little to lose going in. “The educational system is broken,” he said. “This is, like, the best option.”



Quick, think of a college athlete. Chances are the person who comes to mind is a football or basketball player at a powerhouse Division I school like Louisiana State University or the University of Kentucky. Maybe the player resembles, say, Joel Embiid, who turned a chiseled, 7-foot frame into a full-ride scholarship at the University of Kansas before ascending to NBA stardom.

But the typical student athlete more often plays a less blockbuster sport—lacrosse, maybe, or tennis—and in many cases comes from a well-to-do family that has shelled out thousands and thousands of dollars over the years to nurture a budding athletic talent. And a majority of the time, they’re white.

The most visible college athletes—the ones running across bar-TV screens or in full-color photographs on newspaper sports pages—tend to be black. Indeed, college football and basketball players skew disproportionately African American. But, says Kirsten Hextrum, a professor of educational leadership at the University of Oklahoma, “the black men in these two sports are not the reality of who has access to college sports.”

By the National Collegiate Athletic Association’s own estimate, 61 percent of student athletes last year were white. At elite colleges, that number is even higher: 65 percent in the Ivy League, not including international students, and 79 percent in the Division III New England Small College Athletic Conference, which includes elite liberal-arts colleges like Williams College and Amherst College. As Harvard heads to court to fend off allegations that it discriminates against Asian American applicants, the plaintiffs behind the case have released to the public reams and reams of data analyzing the school’s admissions process. They allege that one factor used in admissions, called “personal rating,” systematically disadvantages Asian American students. But tucked into the 168-page analysis of Harvard’s admissions data is a curious statistic about another nonacademic factor considered by the school: athletics.

All applicants to Harvard are ranked on a scale of one to six based on their academic qualifications, and athletes who scored a four were accepted at a rate of about 70 percent. Yet the admit rate for nonathletes with the same score was 0.076 percent—nearly 1,000 times lower. Similarly, 83 percent of athletes with a top academic score got an acceptance letter, compared with 16 percent of nonathletes. Legacy admissions policies get a lot of flak for privileging white applicants, but athletes have a much bigger effect on admissions, and make up a much bigger percentage of the class. And it’s not just Harvard—in 2002, James Schulman and former Princeton University President William Bowen looked at 30 selective colleges and found that athletes were given a 48 percent boost in admissions, compared with 25 percent for legacies and 18 percent for racial minorities.

Put another way, college sports at elite schools are a quiet sort of affirmative action for affluent white kids, and play a big role in keeping these institutions so stubbornly white and affluent. What makes this all the more perplexing, says John Thelin, a historian of higher education at the University of Kentucky, is that “no other nation has the equivalent of American college sports.” It’s a particular quirk of the American higher-education system that ultimately has major ramifications for who gets in—and who doesn’t—to selective colleges.

When it comes to college athletics, football and basketball command the most public attention, but in the background is a phalanx of lower-profile sports favored by white kids, which often cost a small fortune for a student participating at a top level. Ivy League sports like sailing, golf, water polo, fencing, and lacrosse aren’t typically staples of urban high schools with big nonwhite populations; they have entrenched reputations as suburban, country-club sports. According to the NCAA, of the 232 Division I sailors last year, none were black. Eighty-five percent of college lacrosse players were white, as well as 90 percent of ice-hockey players.

And the cost of playing these sports can be sky high. “There are high economic barriers to entering in this highly specialized sports system,” Hextrum says. “White people are concentrated in areas that are resource rich and have greater access to those economic resources.” Getting good enough at a sport to have a shot at playing collegiately often necessitates coaching, summer camps, traveling for tournaments, and a mountain of equipment. One in five families of an elite high-school athlete spend $1,000 a month on sports—the average family of a lacrosse player spends nearly $8,000 a year. Kids from low-income families participate in youth sports at almost half the rate of affluent families, according to a report from the Aspen Institute. It’s no surprise, then, that per The Harvard Crimson’s annual freshman survey, 46.3 percent of recruited athletes in the class of 2022 hail from families with household incomes of $250,000 or higher, compared with one-third of the class as a whole.

But there are other, more veiled factors that may also boost the numbers of white college athletes. For one, many elite colleges—including Ivy League schools and smaller Division III colleges—don’t offer athletic scholarships, so they can’t give low-income sports stars a free ride like big, Division I schools can. Michele Hernandez Bayliss, a private college counselor and a former assistant admissions dean at Dartmouth College, walked me through the process: Over the summer, coaches compile lists of the athletes they want, which they then share with the admissions office. “Most of the recruiting happens in the early rounds. Once coaches have their list, they would rather wrap up the whole process early rather than wait until the spring,” Hernandez said. That the recruited athletes are chosen early on is seemingly mundane, but it warps the process in favor of wealthier kids who can send in early-decision applications to selective schools without fretting about the size of the financial-aid package they’ll receive.

In a recently published study in the Harvard Educational Review, Hextrum interviewed 47 athletes at an unnamed elite, Division I college about how they earned a coveted spot at the university. As she writes, there are all sorts of hidden advantages that “secure greater access to elite colleges for white middle-class communities via athletic participation.” Athletes often get noticed by making visits to the college and sending coaches intensely curated portfolios highlighting their prowess. Affluent kids, “due to their community and social networks, are better at navigating this process,” she told me. And in some cases, she found, cozy relationships between high-school and college coaches can facilitate access for students: “There were instances where if you knew someone who knew someone, you could use that advantage to get a shortcut route into athletics.”

At schools like the University of Alabama and Ohio State University with storied teams that gin up media attention rivaling the big leagues, athletics is a cash cow: In 2017, the Ohio State athletics program brought in $167 million in revenue. Yet, according to the NCAA, at all but 20 colleges, athletics programs lose more money than they make. That raises a baffling question: Why are colleges willing to lower their admissions standards to recruit the best athletes when their expensive sports programs are unlikely to return the investment?

For some colleges, it’s a ploy to burnish their national reputation by getting their name out there, on the field or on the court. And, in some cases, it works: After Florida Gulf Coast University made a David-and-Goliath-like run to the March Madness Sweet 16 in 2013, the school saw a 27.5 percent jump in applicants the following year.

Incidental marketing aside, sports can also make a college seem more attractive to its students. Athletics, Thelin says, “is one of the few unifying activities that can bring the school together. Football, especially.” And, he told me, college sports can nurture loyalty to an institution years after a student leaves campus, and perhaps inspire one to donate money to the school.

But how many people are really going to lacrosse games and sailing meets and the other sporting events that don’t typically have graduates reaching for their checkbook? Part of it is the power of tradition: For more than a century, colleges—starting with elite schools in the Northeast—have fixated on physical activity and sports as a way to mold young, impressionable students to their making. That continues today: “Strong academic colleges often like to at least offer the prospect of the sound mind, sound body,” Thelin says. And, still, colleges need to field a minimum number of sports to join a particular conference, such as the Ivy League, which prevents them from putting all their cards on the table for high-profile sports exclusively.

As Harvard’s admission policies go through the wringer, college sports has largely evaded scrutiny, even among the plaintiffs accusing the school of discrimination. “People are complaining about minority students,” Hernandez says, “but athletes are taking up almost a fifth of the class [at Harvard], and they’re lowering the academic standards quite a bit.”

Granted, athletes at elite schools are far from brain-dead jocks—they work long, grueling hours to balance their academic workload with games, practices, and travel, and have to maintain a certain grade point average to stay eligible to play their sport. But, as the Harvard case seems poised to inch its way to the Supreme Court, where a majority of justices could roll back affirmative action, it’s worth considering how other admissions practices put a thumb on the scale for white students. The processes that funnel rich white athletes to selective colleges aren’t going anywhere in the short term, but in a possible future in which colleges can no longer consider race in admissions, there could be renewed public pressure for these schools to clear the musty cobwebs of the admissions process that undermine their self-proclaimed ethos as America’s engines of social mobility.

“It’s curious to me that these elite universities are holding on to these policies, because I think they expose the contradictions of what universities do in admissions,” says the Harvard professor Natasha Warikoo. “They’re blatantly privileging already privileged groups.”

Update: This article has been updated to remove identifying information about a student athlete, to protect his privacy.



Every year at this time, headlines reveal once again what everyone already knows: America’s top institutions are selective—very. Harvard took a record-low 4.5 percent of the applicants to its 2023 class. Yale accepted 5.9 percent, the same as the University of Chicago.

These numbers—albeit wild—are outliers, representing an almost-negligible slice of the United States’ higher-education ecosystem. Approximately 10.8 million undergraduates were enrolled in the country’s more than 2,500 four-year universities in the fall of 2017, according to an Atlantic analysis of raw figures from the Education Department’s data center.

The majority of students—more than 80 percent—attend schools, such as Texas A&M, Rutgers, and Simmons University, that accept more than half their applicants. In 2017, our analysis shows, roughly 3 percent of the country’s bachelor’s-degree candidates were enrolled at a four-year university that accepts fewer than a quarter of undergraduate applicants; only 0.8 percent of undergraduates were attending one of the handful of universities that accept fewer than one in 10 applicants.

Most schools are not these highly selective institutions, and the application process for millions of students is not the stress-inducing nightmare that gets so much public attention. Excluded from the narrative are the thousands of four-year colleges that serve millions of undergraduates, including many historically black colleges and universities—not to mention the 1,000-plus community colleges.

Various characteristics set these more-typical institutions apart from their brand-name counterparts, such as the fact that the former are more likely to enroll Pell grant recipients (read: very low-income individuals), as well as “nontraditional” students (that is, those who are 24 or older and/or have children of their own) and military veterans, according to the New America higher-education policy analyst Iris Palmer. They’re also less likely to be considered research universities—generally those that offer doctoral-degree programs—and more likely to be commuter campuses, according to Georgetown University researchers. Of all the country’s four-year institutions, slightly more than half are private, nonprofit schools, such as Massachusetts’s Endicott College and Texas’s Trinity University. About 29 percent are public—Mississippi’s Alcorn State University, for instance, and the University of California at Merced, near Fresno. The remaining 17 percent are for-profit, such as the College of Westchester in New York, and Oregon’s Pioneer Pacific College.

These schools dominate the options for most American high schoolers; attending them is a far more common experience than that provided by the Dartmouths and Dukes and Davidsons of the country. The landscape of higher education is far more sprawling than a focus on selective schools allows.

Moreover, the student bodies of the upper tier of competitive colleges are not representative of the demographics of the country at large. Research published by Opportunity Insights, a think tank led by the economists Raj Chetty, John Friedman, and Nathaniel Hendren, has found that roughly three dozen of the country’s “elite” colleges—schools including Washington University in St. Louis, Trinity College (Connecticut), Tufts, Yale, and Brown—enroll more students from households in the top 1 percent of the income scale than they do students from the bottom 60 percent of that scale. In fact, students from the top 1 percent are 77 times more likely to attend “elite” colleges, here defined as schools that accept fewer than a quarter of undergraduate applicants, than are their peers in the bottom 20 percent.

Another often-overlooked feature of higher education in the U.S.: community colleges. Of the nearly 2 million bachelor’s degrees granted last year, roughly half of the recipients had community-college credit. In some states, a solid majority of bachelor’s-degree recipients at some point attended community college—in Texas, for example, the rate last year was three in four. In the fall of 2017, 5.8 million people were enrolled at community colleges, most of them as part-time students.

The most selective schools produce many of the people who populate the top ranks of American business, media, and political leadership. But the country is much bigger and more multitudinous. The work of educating its people falls by and large not to the small set of famous schools, but to the much wider array of ordinary schools, where millions of Americans go to learn every day.



Russell Lowery-Hart spent a Texas winter weekend sleeping outside, even when a light rain fell and it grew so cold that he forced muddy shoes into his sleeping bag to warm his feet. By day, the 48-year-old became increasingly sunburned crisscrossing the streets of Waco, applying for fast-food jobs and searching for soup kitchens. He arrived at one charity at noon to find that lunch ended at 11:30; luckily, a homeless woman shared her cinnamon bread with him.

He was unshowered and unshaven, in the same secondhand clothing the whole weekend. By Sunday morning, the humiliations had undone him. When a family heading to church crossed the street to avoid him, he hollered out, “I’m a fucking college president, you can look at me!”

The family hustled away. But Lowery-Hart is, in fact, a college president. And he was on the streets to find a better way to lead a school where poverty intrudes into the classroom every day.

Lowery-Hart is the president of Amarillo College, a community college on the Texas Panhandle, and he had driven seven hours down to Waco to participate in a two-day, two-night simulation of homelessness run by a religious charity, in the hopes of more deeply relating to his many students who live in poverty. “Just having a food pantry like we do isn’t enough,” Lowery-Hart said in a video diary recorded by a friend that Sunday morning last February. He was flat on the grass, still burrowed inside his sleeping bag as if fending off the trials yet to come that day. Then, in a kind of a forlorn chant, he added, “It isn’t enough, we’re not doing enough, we have to do more.”

Lowery-Hart was already doing a lot more than running a food pantry at Amarillo College. The school of 10,000 students has an emergency fund that can cut a check within hours to cover the car-repair or water bill that could push a student to drop a class—or quit school for good. The school employs social workers who counsel students through these types of financial crises, runs a legal-aid clinic, and offers free mental-health counseling (the latter is standard at private colleges but spotty in the community-college world). Last fall it debuted a low-cost day-care center that keeps its doors open 14 hours a day to serve student parents with jobs in the early morning or evening; students who qualify for a state subsidy only pay $5 a week. Tutoring is available evenings and weekends.

Administrators are working on an alert system that flags incoming students who are at high risk of struggling academically, and then assigns professors to reach out to them before trouble hits. In the fall, staff called and emailed over 800 students who had at least one dependent and a family income under $19,600 a year—less than half of what would be a living wage for a single parent or a one-income household with a child—to make sure they know about the school’s support services. In its quest to improve student performance, the college is questioning academic traditions as fundamental as the length of a semester, which has been cut in half for many classes.

What separates Amarillo College from most of its peers is not any particular program, but how much it focuses on addressing the effects of poverty. The school and Lowery-Hart are being watched by college leaders all over the country, because finding realistic solutions for student poverty could be transformative for the U.S. higher-education system.

Among the poorest 40 percent of Americans, only 12 percent of young people born in the 1980s earned a bachelor’s degree by age 25. But a college degree is not optional for most good jobs in today’s economy, so more and more students from low-income backgrounds are pursuing higher education, and they are most likely to end up at community colleges. Despite President Trump’s recent comments that “We do not know what a ‘community college’ means,” these institutions comprise more than 40 percent of the country’s undergraduate population. While most community colleges were built after World War II to support the needs of the modern workforce—which would of course improve students’ livelihoods as a result—they weren’t explicitly designed to relieve poverty. Yet by default, given the limited reach of programs such as welfare and food stamps, community college has become one of America’s largest and most important anti-poverty programs.

The federal Pell grant for low-income students maxes out at about $5,900 a year, which is usually more than enough to cover community-college tuition but too little to live on. (Starting in July, the maximum will go up to $6,095.) And the gap between a Pell grant’s value and the cost of living grows bigger every year. The result is that many students are struggling with basic survival. A 2017 survey found that 42 percent of community-college students nationally experienced food insecurity within the past month—which could mean missing meals altogether or not being able to afford balanced meals—while 12 percent were considered homeless at some point in the previous year. Among Amarillo College students who took the same survey, 54 percent had experienced food insecurity within the past month, and 11 percent had been homeless in the past year. So the student body is not significantly needier than those of many other institutions, but the college leadership’s interest in highlighting the extent of the need is much more unusual.

Beyond food insecurity, many students lurch from crisis to crisis, semester by semester. That’s part of why community-college graduation rates are so low, with only four in 10 students earning a degree within six years.  

The 9.9 Percent Is the New American Aristocracy

A number of signs suggest Amarillo College is doing better by its students than it did just a few years ago. The graduation rate is rising, more students are studying full-time, and students of color are doing as well as white students, according to Collin Witherspoon, the college’s executive director of analytics and institutional research. But some of Lowery-Hart’s biggest bets have yet to prove effective, and there are at least a few professors who question whether the fixation on poverty is in students’ best interests.

After all, as the college experiments, it is the students in poverty who are taking the biggest gamble. They might be forgoing wages they could earn if they weren’t in class, eating into their six years of lifetime Pell Grant eligibility on a semester they may not finish, or even taking out loans—although the latter is quite rare among Amarillo College students—that they will struggle to repay if they end up dropping out. Ending up worse off than when they started is a real possibility.

Mandi Wheeler, a math professor, loves serving in a coaching program for students who arrive at the college from the two low-income high schools in Amarillo—as an example, she recalled a young man she coached who arrived “scared to death” but soon blossomed in calculus.

But she questions Lowery-Hart’s view that the college itself can be the route to stability for students even in the throes of crisis. Wheeler recalled one homemaker with young children who came to the college in pursuit of employability, soon after leaving an abusive husband. At the beginning of the semester, according to Wheeler, the mother was staying in a shelter and had no computer.

Wheeler was relieved when the woman withdrew from her class in order to take a new job. “They can’t focus on learning the quadratic formula when they don’t know where their next meal is coming from,” she said. “My heart breaks for so many of those students that do have stuff going on … And then here I am saying, ‘Where is your homework?’”

But colleges need to stick with this type of student if they are truly committed to helping lift families out of poverty, according to Sara Goldrick-Rab, a sociologist at Temple University. Goldrick-Rab, the lead researcher on the survey identifying high rates of hunger and homelessness in college, has been a major force in drawing attention to the phenomenon of student poverty.

Goldrick-Rab and a co-author are planning to publish a case study in June about Amarillo College, which drew her attention as one of the few places she’s been able to find that’s taking a systemic approach to fighting poverty. The report, Goldrick-Rab said, will highlight practices that other colleges should consider adopting. For example, she praised Amarillo’s emergency aid fund for making grants within hours and without red tape, which she said makes it more useful to students in crisis. The fund asks for documentation of the expense a student needs help with—a lease or utility bill, for example—but doesn’t require an application.

While emergency aid is spreading in popularity, some colleges worry about “frequent flyers” who keep coming back for more help. Goldrick-Rab called that “naïve to what poverty is.”

“If they really get it, if really there are ‘no excuses,’ when they have impoverished students, then they have to roll with all those punches,” she said, referring to the name of an Amarillo community initiative to address low educational attainment, “No Limits No Excuses.” She continued, “It is not easy, and they don’t get an immediate success story wrapped up with a bow.”

Yet the potential payoff is more than worthwhile, Goldrick-Rab added, noting that a college degree can be transformative for an entire family. Even for students who don’t go on to get a bachelor’s degree, an associate’s degree makes a real difference in earnings, worth thousands of dollars a year. And when parents get more education, their children tend to do better, not only in school but in all sorts of health outcomes.

And if not college, what is the path for the students whom Amarillo College is trying to lift out of poverty? People can’t securely raise a family on a minimum-wage job. In an economy that increasingly has made a college degree practically a prerequisite for decent work, what other choice is there?

A few months after his weekend living “homeless” in Waco, Lowery-Hart was trying to identify the “more” that he’d declared from his sleeping bag the college needed to do. So he asked his director of social services, Jordan Herrera, to set up a lunch with some students who had experienced homelessness.

Lowery-Hart frequently asks students for advice. Once a week or so he sits down to converse with a few of them at random, buying them sandwiches from the Chick-fil-A food truck that replaced the cafeteria shuttered several rounds of budget cuts ago. On this particular warm day last May, he had club sandwiches and iced tea waiting in his office for two students. Justin Allen was a 32-year-old single father who was about to graduate from a dental-assistant program. The college had put him and his two kids up in a motel for a few weeks, after his father kicked them out over a money dispute.

Across the president’s conference table was Alicia Pruett, a 44-year-old mother of six, who had the words “A Roller Coaster Ride” tattooed in curvy script down her left leg, originally a commentary on life with her husband but one that was proving equally germane to her college career. That she was still enrolled, after what she’d been through the last few months, already made her, in one sense, a success for Amarillo College’s poverty initiative. Before signing up for Amarillo College in fall 2016, Pruett had been a stay-at-home mom, and before that had worked as a Comcast customer-service rep and a cook. She was seeking a degree in communications, hoping she could one day do PR for an adoption or foster agency. The main goal, though, was to give her kids a better life.

“I’m going to be able to give my kids everything that every parent wants to give to their kids,” said Pruett, who lives with her husband and their five children, and also has an older son who is in her ex-husband’s custody. “Which is a good birthday, a good home, the opportunity to be able to do things, to take vacations.”

But not long after Pruett started school, her husband Mike fell out of work. A long-time roofer, he suffered from back problems but, she said, was turned down for disability benefits. When he took under-the-table manual-labor jobs out of desperation, he said, he was repeatedly cheated out of his paycheck.

The couple fell behind on their bills. A professor referred Pruett to the Advocacy and Resource Center, or ARC, the nucleus of the college’s poverty work, where a small team including Herrera helps hundreds of students each semester through their financial and life crises, marshals the college’s own resources, and hustles to connect students to every possible community or government program.

Pruett took advantage of the food pantry, and the college emergency fund covered half a month’s rent and some utility bills. Herrera put Pruett in touch with a local church that also chipped in. More importantly, she helped Pruett get on the waitlist for a Section 8 housing program that provides affordable rentals to college students with families. Months later, just before Easter, the housing program offered Pruett’s family a four-bedroom house for $1,000 a month. But when they gave notice to their current landlord, she put them out on the street with three days’ notice, even though they wouldn’t get the new place for a couple of weeks. Herrera tried to find shelter beds for the family, but no one could offer space for a family of seven. So the college paid for them to stay about 10 days in a Travelodge.

By the time Pruett found herself in Lowery-Hart’s office, she and her family had been in the new house for a few weeks. Pruett and her husband were both interviewing for jobs at Sam’s Club after Pruett’s math professor put in a good word for them. Things were falling into place.

Pruett told Lowery-Hart that she would graduate, “no two ways about it,” and that seemed like a decent bet. She earned a 3.75 GPA in her first semester, she told the president. When I later followed her to class, I learned that she was a star in her math section, beckoned over frequently by her classmates to explain problems.

But her story would be, for a long time to come, more of a cautionary tale than one of clear-cut success. Just the day before she showed up for the lunch in Lowery-Hart’s office, she learned that her aging Chevy Suburban, the family’s only means of transportation, was being repossessed. She was going to ask Herrera for help getting it back, but she had an even more pressing concern, which she kept to herself as she chatted with the president: She didn’t know how she was going to feed her family dinner that night. The Pruetts were receiving $1,022 a month in food stamps, but with three meals a day for seven people, that works out to $1.60 per meal per person. They had a few days to go before the next month’s benefits would replenish. And their bank account held just $17.

When it was time to head home and face dinner, Pruett set out from campus on foot, winding her way first past mansions with rose gardens and fountains near campus, then under a couple of highway overpasses and finally to her down-at-the-heels neighborhood not far from the city’s business district. In addition to the laptop in her backpack, she was lugging a pack of diapers she picked up in Herrera's office. But she couldn’t handle carrying groceries home as well, so she hadn't taken anything from the food pantry.

Mike and their kids, who ranged in age from 2 to 11, were in the yard, attacking the ground with hoes in preparation for a garden where they hoped to grow their own vegetables. Nine-year-old Lena, who aspires to be a cook like her mom, had blueberry bread in the oven.

Pruett stepped into the pantry to survey her options. There was Hamburger Helper, but no hamburger. Tuna fish, but no bread to make sandwiches. Some beans, but the kids don’t like beans. She decided she would ask Mike to go out and get some hamburger so they could have spaghetti with meat sauce.

In between snuggling her two youngest kids and refereeing a video game the older ones were playing, Pruett described to me some of the ways that the family’s financial crisis had impinged on her academic life. They couldn’t afford internet service, so sometimes she would sit in her car at night in a college parking lot to use the campus Wi-Fi, piling on jackets to withstand the cold temperatures of nights on the high plains. Her GPA tumbled. She dropped a media course she loved because she was embarrassed to go to campus when the water was turned off and she couldn’t shower.

That evening last May when they were scrambling to come up with dinner, Mike came back with hotdogs, buns, and canned chili to make chili dogs. Because they had less than $20 in their bank account, he could only get a $10 bill from the ATM, not enough for the hamburger. Pruett spread ketchup and mustard on the kids’ hot dogs in loops so artful they betrayed her professional kitchen experience. The kids came to the table, and Lena and her 7-year-old brother, Robert, said “cheers” as they clinked their hot dogs together.

The Texas Panhandle is a windswept prairie 3,600 feet above sea level and bigger than West Virginia. Its heart is Amarillo, a pancake-flat city of around 200,000 bounded by cattle ranches and corn, cotton, and wheat fields that is in danger of growing poorer. In the view of many civic leaders, the community is overly dependent on meatpacking and trucking as well as on the motels and fast-food joints hugging Interstate I-40, the ribbon of highway tethering the vast Panhandle to the rest of the United States.

Here, the kindness of close-knit church communities meets the bootstraps mentality of pioneer days. In A Strong West Wind, her memoir of growing up in Amarillo in the 1950s and 1960s, the writer Gail Caldwell described the way the people of the Panhandle were hardened by ferocious hail storms, tornadoes, and even blizzards. “There are no trees or rises of the land to break the wind,” she wrote, “and so the cattle can breathe the snow, in its horizontal flight, and drown. People, too, have been brought to their knees for generations by this kind of weather: In the midst of so much nothingness and force, it's difficult not to feel beholden to some larger design.”

Over a decade ago, Lowery-Hart got involved with a community initiative to to get a handle on the threats to Amarillo’s prosperity. The conclusion: lack of education, with only a third of adults in the city earning any kind of college degree, and a shortage of high-skilled job opportunities meant a perpetual brain drain.  

At the time, Lowery-Hart was an administrator at the local university, West Texas A&M. He became convinced that he could do something to help the prospects of his region, but more so at Amarillo College, where seven in 10 students are the first in their family to go to college and four in 10 are Latino. He often cites a statistic in the Harvard economist Edward Glaeser’s book Triumph of the City—that as the share of the population with college degrees increases by 10 percent, per-capita gross metropolitan product rises by 22 percent.

He eventually applied to Amarillo College for the position of vice president of academic affairs. To this day, he is sometimes brought to the verge of tears when talking about the challenges his students face. The reasons for his deep feelings harken back to his childhood in a small town outside Lubbock, when he took refuge in school from home life with an abusive, alcoholic father. Teachers “loved me even when I was unable to love myself,” Lowery-Hart told me. “I’ve always been fighting for that student, because that student was me.”

When Lowery-Hart arrived at Amarillo College in 2010, he began asking why the graduation rate, which that year was just 9 percent, was so low. He expected to hear students blame academic troubles—poor high-school preparation, perhaps, or inconvenient class schedules. Surveys and focus groups revealed an entirely different set of issues, all related to poverty: food, housing, utility bills, transportation.

Budget constraints have posed the biggest challenge to this work. Community colleges receive less than half the government funding that public research universities do, and, echoing trends in other states, Texas is spending 15 percent less on higher education than it was before the recession. Amarillo College lost a total of $3.5 million in state funding for instruction in the last two state budgets, partially because of an enrollment dip, and cut dozens of staff positions a couple of years ago.

The largest source of the college’s nearly $66 million budget this academic year was tuition and fees, which brought in $23 million, including financial aid awards to students from state and federal governments. The next biggest chunk was support from local taxes, about $21.3 million, with state support third at $13.5 million. However, other than salaries for social workers, the poverty work is largely funded by other means. A private foundation created in 1961 to handle donations to the college, the Amarillo College Foundation, bankrolls the emergency-aid fund, with a contribution of $60,000 this year. Other gifts and grants have helped with bits and pieces of the work. For example, a federal Perkins grant supports transportation and childcare for adult students in career and technical programs.

The college is typical in depending on a combination of tuition and state and local support, with grants from foundations and gifts from local benefactors coming in to support specific initiatives. A gift from a local bank, for example, funded a renovation project that made space for the ARC. Perhaps less typical is that the Amarillo College Foundation is relatively well off with $43 million in assets, and it gave the college and its students over $3 million for the 2015-2016 school year. The foundation for many years was focused on raising money for scholarships, according to Kathy Dowdy, its co-executive director. But in recent years, she said, the board has embraced Lowery-Hart’s emphasis on combating poverty. The money they raise—largely from local families and businesses—is increasingly targeted at helping the college offer support to keep students from dropping out. “We have these students with 3.8 GPAs who all of a sudden find themselves homeless, and if we’re not equipped to help them, we’ve lost the possibility of changing somebody’s life,” Dowdy said.

Students, meanwhile, don’t get the same level of government support that previous generations did. In 1975, a federal Pell Grant covered 79 percent of the cost of attending a four-year public college. Today, it covers just 29 percent. At the same time, more college students look on paper like Alicia Pruett—older, poor, underrepresented minorities. In the absence of more commitment from the states and federal government to higher education, leaders at many community colleges have come to the same realizations as Lowery-Hart—that educating their students effectively requires not just good academic programs, but also a host of supports to tackle poverty. At Patrick Henry Community College in rural Virginia, a scholarship program awards cars, donated by dealerships, as scholarships to a few students each year who need them to get to class. Houston Community College is offering scholarships for groceries. Tacoma Community College in Washington and the local housing authority provide housing vouchers to homeless students. Nineteen schools recently worked with a community-college-reform group called Achieving the Dream to change campus culture around these issues. Poverty is a growing concern, as well, at four-year colleges, where 36 percent of students are estimated to experience food insecurity.

Most colleges, however, have just a discrete poverty program or two—the food pantry, most likely, or the emergency aid. Lowery-Hart’s ardor for the topic has made Amarillo College stand out considerably.

Lowery-Hart was named president of the college in 2014, and over time, he developed what he calls the college’s theory of change. “Life-barrier removal” plus relationships “equals completion,” he says—meaning that if the college can help a student overcome a life barrier, perhaps by connecting them to housing or food stamps, and also offer a meaningful personal relationship, the student will be more likely to graduate.

Sometimes he forms that relationship himself. One day in September, I accompanied him on his Chick-fil-A gambit to listen to students’ concerns, and he approached three young people chatting in a lounge. It turned out only one of them, a 19-year-old named Julie, was enrolled in the college, but she was facing possible eviction and thinking about dropping out to get a second job. Her two friends had just tagged along with her to campus. Alexandra, 18, said she’d recently gotten clean after her mother kicked her out. Eddie, 20, had a young child and had spent time in jail. Both said they wanted to go to college soon, but neither felt ready quite yet.

Lowery-Hart listened to their life stories, then quickly made his pitch: He urged Alexandra and Eddie to sign up for classes that very day. Then he spent 45 minutes shepherding them around to meet advisors. He brought Julie to the ARC, then tried to find out whether there might be an on-campus job for her.

Later that September afternoon, Lowery-Hart told a group of staff that Alex and Eddie are the future of Amarillo. Whether they have a criminal record, or children of their own, or doubts about whether they can succeed, those not traditionally viewed as “college material” are, to him, exactly who the college should be serving.  

“Quit wishing for a different kind of student,” he said. “We want to be the right college for the students we have.”

When Amarillo College renovated the student-commons building at the center of its main campus two years ago, it drew together a variety of programs to create the ARC, which it set up on the first floor, surrounded by glass windows. Some staff worried that students would feel too exposed to come in to use the food pantry or talk to caseworkers, but demand for the ARC’s services has grown dramatically. Herrera, the social-services director, who presides over the ARC, believes the prime location has taken some of the stigma out of asking for help.

Inside is a small suite of offices adorned with succulent plants and Mexican folk art, the neat food pantry, a supply of toiletries and toilet paper, and a clothing closet. Herrera and her staff have gone from restocking the pantry twice a month to twice a week.

Herrera is gregarious, and prone to talking about her work in the language of blessings and prayers. She is herself an Amarillo College graduate and grew up helping her mom, who left school after the sixth grade, run a small janitorial service. The rest of her team also come from backgrounds that help them understand the lives of students they help, including a social worker who was the first in her family to graduate from high school, and an assistant who is a “Dreamer” and spent a year saving waitressing tips in a shoebox to pay for college, because her undocumented status made her ineligible for financial aid.

On my visits to Amarillo, I’ve walked into the ARC to find the assistant on the phone helping students who are parents get reimbursement for babysitting bills, which is available through a federal grant. I’ve heard Herrera on the phone advising a student where to go for affordable car repair. And I’ve seen students dropping off plastic bags filled with donations for the food pantry, for which many professors offer extra credit.

I visited the ARC with Pruett when she came in, the morning after the chili dog dinner, to find out whether Herrera was going to be able to help her get her car out of repossession. She owed $950 to cover payments, plus $250 in fees. Herrera had done “a little bit of begging,” she said, and the school would indeed be able to write a check—directly to the repo shop—for the $1,200. It would be the last money the college could help with for a while.

The fact that Pruett and her husband were both expecting to start jobs helped make the case, Herrera said. Not to mention that they wouldn’t be able to get to work without the truck.

Pruett did a little dance in her chair. Then they discussed what she could do to raise her GPA back up again.

There is something shocking about a cash-strapped community college shelling out $1,200 to help a student get her car out of repo—on top of the motel bill, on top of the water bill, on top of the help with rent. Certainly, the unusual level of support the emergency fund gets from the Amarillo College Foundation is what makes this possible. But this kind of money still pales in comparison to what wealthier colleges spend as a matter of course on all their students. Community colleges spend less than $1,400 per student each year on all non-academic student services, a category that covers everything from mental-health and career counseling to support for student groups and intramural sports. That’s compared to almost $4,500 per student at private four-year colleges. Of students who got emergency aid from Amarillo College in the fall of 2016, according to the college, 57 percent were still in school a year later, compared to 48 percent of the overall campus population—impressive given that the emergency-aid recipients are more likely to have major distractions in their lives.

When I told Goldrick-Rab, the expert on poverty in college, about Pruett’s troubles, the professor said, “Poverty is going to try to knock her down at every turn and every month.”

“That’s why social mobility is so hard,” she continued. “The bottom is extremely sticky—that’s how we put it in sociology.” But Goldrick-Rab added, “the return to this is not just the return to one woman—it’s the return to her and her five kids. All the research shows that students like her might take a really long time to finish school, and at the same time, that degree will really pay off for her.”

When Pruett left Herrera’s office with the news that she would be able to get her truck back, she headed over to the Math Outreach Center to study for her final. Apart from its colorful grandfather clock that tutors built out of K’nex toys, the center is a drab room full of computers and faux wood tables. Yet during my visits to Amarillo, it was the most bustling place on the main campus.

Scattered around the room were several of Pruett’s classmates, as well as a Navy veteran in his mid-70s who comes every day as he plugs away at his degree, and a tutor who was illiterate at 13 when he came to the U.S. as a Rwandan refugee. He was now about to graduate and pursue his BA in mechanical engineering.

Many students make this their study space of choice, but tutoring is also required for students who earn below a C in certain classes, and data suggest that the assistance can make a major difference. That’s the conclusion of Witherspoon, the college’s executive director of analytics and institutional research. As a former math professor and software developer, Witherspoon can do the kind of sophisticated data analytics for which many colleges pay private companies hundreds of thousands of dollars. And Lowery-Hart—like many of his peers—puts great stock in using data to guide decisions.

Perhaps the college’s most dramatic change precipitated by data is the transition from traditional 16-week classes to 8-week mini terms. Amarillo students across the board are getting better grades in the shorter, more intense terms. One theory is that the shorter the term, the fewer days and weeks there are when a student could get thrown off, as Pruett did, because their water gets turned off, or their car breaks down, or a relative gets sick.

Some professors, however, think the eight-week terms are a big mistake. They say that students can't grapple effectively with difficult concepts in such a short period. The data only look good, the critics say, because instructors are taking pity on drowning students and offering them extra-credit opportunities, letting them rewrite papers, or simply inflating grades.

“These kids don’t know how to read a textbook, they don’t know how to study, they don’t know how to write … and then we’re rushing them through,” said Deborah Harding, who teaches psychology and sociology at the school. “I think it’s a terrible way to learn.”

The concerns about grade inflation raise some uncomfortable questions about the “No Excuses” philosophy. Lowery-Hart says that students have to hold up their end of the bargain and earn a fair grade, but this remains a source of confusion among the faculty.

That said, there are a number of signs that Amarillo College is generally doing a better job serving students than it used to. For example, its three-year federal graduation rate for first-time, full-time students was 9 percent when Lowery-Hart joined the college in 2010. It then hovered around 15 percent for several years and most recently spiked up to 23 percent. (The national average for community colleges is 24 percent.) Other aspects of the college’s poverty agenda lack evidence of systemic improvement, including the ARC. The college can point to students for whom help from the ARC clearly made the difference between dropping out and graduating, including Justin Allen, the single dad who was at the lunch with Pruett and Lowery-Hart. But Witherspoon’s efforts to identify a broad impact through data have come up short.  

Goldrick-Rab, the Temple University professor, is planning to conduct a new evaluation in the fall. It's possible, she said, that the ARC’s social workers, pantry, and emergency funds aren’t making a big difference in students’ lives. It's also possible that they are helping students, but it's difficult to prove without an expensive randomized experiment.

Lowery-Hart and his colleagues also know that, despite the earnestness of the “No Excuses” pledge, there will be failures. The gold standard in community-college reform today is a program that was pioneered at the City University of New York called Accelerated Study in Associate Programs (ASAP). It offers students a package of supports including intensive advising, scholarships, and free MetroCards for the New York subway. It’s also very expensive—over $11,000 per student over three years—which is why it has yet to be widely adopted. At CUNY, ASAP has about doubled the three-year graduation rate—but only got it up to 52 percent.

In a society that offers so little support for a community-college education, and where growing up in poverty guarantees immense disadvantages, there’s only so much even visionary college leaders can do.

Just weeks after getting her truck out of repo and starting a part-time job in the cafe at Sam’s Club, Pruett called 911 with an attack of excruciating abdominal pain. It turned out she had a perforated bowel and a raging infection. She had an emergency colostomy, and then wore a colostomy bag the entire summer while the infection healed.

She had to put school on hold the first half of the summer, and missed weeks of work. The second job at Sam’s for her husband, Mike, didn’t materialize, he believes because of his felony record from years earlier. Once again without income, the family went without gas and water for parts of the summer, barbecuing and hauling ice chests from the neighbors.

When she went back to school after a second surgery in the fall, a new crisis hit. A year earlier, Mike had written a bad check at a grocery store when, Pruett says, they were desperate for food and diapers. Prosecutors offered him a plea deal, but only if he first paid back the $340 he owed the store. Now Mike faced a deadline to come up with the $200 he hadn’t yet repaid —or face a jail sentence of up to six months.

Robert Love, the first assistant district attorney in Randall County, said his office does not want to send “hot check” offenders to jail, but rather wants them to pay restitution to their victims. But Alicia and Mike were broke, and neither had any family members in a position to give them cash, so they were convinced Mike was headed for jail. There was no way Alicia could stay in college without Mike pitching in with the kids, so I expected that she would check whether the ARC could help.

But perhaps she had taken it too much to heart when Herrera had warned her in the spring that the truck was the last thing the college could help with for awhile. At the same time, like many low-income and first-generation students, she has no trace of the sense of entitlement of a stereotypical college student. “The world doesn't owe you crap,” she told me. Over the course of at least a month, Pruett avoided asking Herrera or the other social workers for help. She stopped by the ARC now and then to ask for an emergency gas card or to use the pantry, but when they asked how she was, she told them, wryly, that she was “living the dream.”

Pruett told me that she just kept picturing a single parent who needed help even more than she did. “That's where guilt starts to play on me, because I think I'm taking away from another child,” she said.

In the end, Pruett did confide in Herrera, and the school helped out with two utility bills. That allowed Alicia and Mike to scrape together the $200 to repay the grocery store and keep Mike out of jail.

It was a reprieve, for sure. There was no stability in the offing, however. Mike’s plea deal left him owing about another $350 in court costs. Alicia Pruett’s laptop was at the pawnshop. Still, shortly after that crisis passed, she told me she had no doubt that college was the right choice. She had a plan for when she gets her associate's degree—to go on to pursue a bachelor's degree at Louisiana State University. “I try to tell everybody that going back to school, next to being a mom, is probably the best thing I've ever done,” Pruett said.

As the near-catastrophes have piled up in the year I’ve known Pruett, I haven’t always been able to envision that rosy outcome—the diploma, the great job. In March, the family was facing possible eviction after Pruett, who was coping with the deaths of three family members, missed a deadline to submit paperwork to the affordable housing program. I haven’t been able to reach her since then, and Herrera hasn’t heard from her recently, either. So I don’t even know what happened, except that she did finish her spring semester, according to Herrera.

Could she stay in school if her family lost their home, again? It feels like everything could unravel, leaving her with nothing to show for two years of college.

I mentioned Pruett’s struggles to Lowery-Hart at the time when she thought Mike was headed for jail, and his first concern was that she didn't feel comfortable asking for more help.

“That's my biggest fear,” he said. “We have students that use the food pantry, for example, and then they bring food back, they'll try to replenish it. Even when you talk to students that have been ultimately successful, there is that feeling like, ‘oh, I require too much of you.’”

Lowery-Hart’s voice was cracking; he was on the verge of tears. He furrowed his brow as he typed a text message to ask Herrera about Pruett's situation.

I then mentioned to him the concern among some faculty that the college runs the risk of giving troubled students false hope.

“Without us there is no hope,” Lowery-Hart said. “I’ll take the risk of false hope, because then there’s still a chance. But no hope is no chance at all.”

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

At least 2,000 children have now been forcibly separated from their parents by the United States government. Their stories are wrenching. Antar Davidson, a former youth-care worker at an Arizona shelter, described to the Los Angeles Times children “huddled together, tears streaming down their faces,” because they believed that their parents were dead. Natalia Cornelio, an attorney with the Texas Human Rights Project, told CNN about a Honduran mother whose child had been ripped away from her while she was breastfeeding. “Inside an old warehouse in South Texas, hundreds of children wait in a series of cages created by metal fencing,” the Associated Press reported. “One cage had 20 children inside.”

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

About 65 million years ago, shortly after the time of the dinosaurs, a new critter popped up on the evolutionary scene. This “scampering animal,” as researchers described it, was likely small, ate bugs, and had a furry tail. It looked, according to artistic renderings, like an especially aggressive New York City rat. And it had a placenta, an organ that grows deep into the maternal body in order to nourish the fetus during pregnancy.

The rodentlike thing would become the common ancestor of the world’s placental mammals, with descendants that include whales, bats, dogs, and humans, among many other species. And today, the placenta might hold the key to one of the most enduring mysteries in human medicine: Why do women suffer much higher rates of autoimmune disease than men do?

On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.

Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

There’s a moment about 15 minutes into the first episode of Years and Years that made me gasp at its audacity, its prescience, its visual horror. The new six-part series from the British writer Russell T. Davies (Doctor Who, A Very English Scandal) charts the life of the Lyons family over the course of 15 years, starting in 2019 and ending in 2034. It’s a kitchen-sink saga that barrels its way through births and marriages and betrayals, but also through the near-future. In 2024, Stephen Lyons (played by Rory Kinnear), a financial adviser, is at home with his wife, Celeste (T’nia Miller), both rushing their way through the morning routine. When the camera turns to their teenage daughter Bethany (Lydia West), her face isn’t recognizably human. Instead, she looks like a 3-D version of a Snapchat puppy, with vast cartoon eyes, wagging pink ears, and a brown snout. When she talks, her voice is grotesquely distorted, a robotic hallucination of a child’s cadence. “I might have to start limiting filter time,” Celeste says in the same exasperated, noncommittal way that you might think, I really should spend less time on Twitter.



There’s a perception, flawed as it may be, that college admissions are a zero-sum game. One student gets in, another loses out. That perception is even more acute when it comes to selective institutions, where the seats are few and the applications from qualified students are plenty.

Once students get into such selective schools—with all of the money, prestige, and support that comes with them—they tend to perform well, stay in school, and graduate. According to a new report from the Jack Kent Cooke Foundation, that is particularly true of students who transfer from community colleges. The report, released Tuesday, finds that graduation rates of community-college transfers meet or exceed those of students who enroll at selective institutions as first-time freshman. Community-college transfers also graduate at higher rates than students who transfer from other four-year colleges.

But as Jennifer Glynn, the director of research at the foundation, put it, “There is an underrepresentation issue.” Selective colleges don’t enroll a lot of transfer students. Princeton, for example, recently moved to reinstate its transfer program. The institution hadn’t accepted transfers since 1990. The university then offered admission to just 13 transfer students. That low number is not uncommon at private, elite schools like Princeton.

According to the report, 35 public selective colleges together “enroll 4 times as many transfer students as the 140 private selective institutions.” That’s likely due in part to the low overall enrollment at private institutions, alongside a commitment to a “traditional” college experience, one in which a student graduates from high school and goes directly to live on campus. What makes a traditional experience is changing though. These days, the typical student is likely older, or lives off campus, or has a full-time job, or is going to school part-time, or has a child, or has some combination of any of those traits. And more often, students are starting their higher education at community colleges. In fact, more than 40 percent of all U.S. undergraduates attend community colleges.

Of those community-college students who want to transfer to a four-year college, there are many who might be a good fit for highly selective institutions. (Of course, they could also succeed at a wide range of schools.) However, community-college transfer students make up just 15 percent of all newly enrolling bachelor’s-degree students nationwide, and only about 5 percent of enrolling undergraduates at the top 100 schools.

For the students who do ultimately transfer to selective colleges, it’s not that there are just a few shining stars skewing the data—say, a couple of community colleges launching dozens and dozens of students to selective institutions. The greatness is everywhere. “Fully 84 percent of the nation’s two-year institutions transferred at least one student to a selective four-year institution in fall 2016,” the report says.

Admissions officers are starting to notice, as evidenced by a 2018 National Association for College Admission Counseling report that found that roughly 90 percent of admissions counselors regard transfers as moderately or considerably important to enrollment goals. But it will likely take considerable gumption to push selective colleges to enroll more transfer students, if only because the status quo is so baked in to admissions officers’ mind-set. Foundations such as Jack Kent Cooke have been working with colleges to help them enroll and fund transfer students, and organizations such as the American Talent Initiative have been pushing to get more community-college students into these schools. Even still, the mighty few who have large endowments, a working business model, and few empty seats may not feel compelled to enroll more transfer students.

Still, this report shows that if admissions officers will accept them, community-college students are prepared to succeed at any college—even the most selective.



On the second floor of a brick building on Branch Avenue in Washington, D.C., green and white signs celebrating innovation and professionalism decorate the classrooms of Digital Pioneers Academy, the first computer-science–focused middle school in the nation’s capital. One early afternoon, students at DPA worked on Scratch, an animation-based coding platform, to make a virtual cat move around in a box. When Crystal Bryant, one of the school’s STEM teachers, told the students it was time to close their Google Chromebooks—class was over—they groaned.

The school’s founder and principal, Mashea Ashton, has almost 20 years of experience teaching at and running charter schools. She grew up in New Jersey but has been in and around D.C. for more than 25 years, partly because her husband is a sixth-generation Washingtonian; he grew up on the street where DPA is located, in D.C.’s Hillcrest neighborhood. Before opening DPA, a charter school, Ashton surveyed more than 200 of the community’s families about what they were looking for in a school.

The survey responses were telling: Ninety percent of the families wanted their children to take a computer-science class. The Hillcrest families were clearly aware of the ways technology is disrupting the economy and of the importance of computer-science education. Walmart, for example, is increasing its number of self-checkouts and has plans to grow a grocery-delivery business. As robots and other forms of automation enter the workplace, the demand for workers who understand how to use technology increases: For example, the Bureau of Labor Statistics predicts that software-developer jobs will grow by 31 percent from 2016 to 2026.

But computer-science education is lacking across the United States. Just 40 percent of schools in the U.S. teach computer programming; computer-science–focused schools, like DPA, are hard to come by. Some policy makers, including those in the Trump administration, have called for employers to look outside of the traditional education system, recruiting from training programs, for example, for the jobs of the new economy.

To a certain extent, there is only so much that educators can do: Technology is changing quickly and often, making it difficult for teachers to keep up. But Tiffanie Williams, DPA’s director of curriculum and instruction, believes that the school can deal with those challenges by continually adapting its curriculum and teaching practices. “We want our students to not just consume the digital economy, but to also be a part of creating it,” Ashton says.

The idea is to address a shortage of computer-science education in the nation’s capital, as well as income inequality and a lack of gender and racial diversity in tech. D.C.’s Ward 7, where DPA is located, has a median household income of almost $40,000; the median household income for D.C. as a whole is more than $75,000, and on average, software developers make more than double what entire families in Ward 7 earn. Almost 30 percent of the population in Ward 7 lives below the poverty line. And fewer than 20 percent of residents in the ward have obtained a bachelor’s degree or higher. In D.C. as a whole, fewer than 20 percent of residents live below the poverty line, and almost 60 percent have a bachelor’s degree or higher. DPA’s students are from Wards 7 and 8, which are, respectively, almost 95 percent African American and more than 93 percent African American, according to 2010 data. Not even 3 percent of Google’s workforce is African American.

The school day starts at 7:30 a.m. for the inaugural class of almost 130 sixth-grade students. (Ashton expects to add the seventh and eighth grades in coming years.) During the first hour of school, the students—who teachers call “innovators”—eat breakfast and, starting in October, will experiment regularly with robotics with the help of CodeREV, an organization that inspires kids and schools to code by providing STEM-curriculum resources. At 8:30, students move on to the core curriculum, which includes not only computer science but also math and English language arts, and incorporates computer-based learning. “I like games,” Nasir Holloman, a sixth-grade student, told me at the end of one day, during the school’s first week. “I heard we can create games.”

DPA judges its success on whether its students score a 3 on the AP Computer Science Principles exam in high school, and on whether students get into college. The school has been working with Craig Meister, an independent consultant, to adapt a computer-science curriculum from RePublic Schools, a network of schools in the South that teaches coding skills; Meister previously worked for RePublic as a curriculum designer.

RePublic Schools has developed a four-year computer-science program that is meant to start in fifth grade, but DPA hopes to run that curriculum over the course of three years, starting in the sixth grade. In the first years, students learn about basic platforms: MIT’s Scratch, the animation-based platform, as well as HTML and CSS. Later on, they move to JavaScript, a language used to develop websites. “They’ll create pretty advanced websites,” Meister says. Teachers are encouraged to give specific feedback on, for instance, whether the games they’ve designed run smoothly and lack noticeable glitches. “They’ll have had significantly more background and standard-aligned instruction in order to put them ahead of the typical 10th-grader,” Meister says.

Of course, curriculum aside, many socioeconomic factors outside of a child’s control, such as the presence of healthy foods and parental involvement, influence that child’s level of preparedness for school. DPA has partnered with the Flamboyan Foundation, a D.C.-based organization that helps schools with community building, to build a home-visit program; each family will have been visited by DPA teachers or staff by November 1. These visits are supposed to give DPA insight into kids’ homes: “Do they have a quiet space to do homework?” Ashton said. “Do they have the resources they need? And if not, we’ll work with families to figure out how to make sure that they have what they need.”

Below the school, on the first floor, is the century-old East Washington Heights Baptist Church. The school and church share a building, and Kip Banks, the church’s pastor, said DPA families will have access to activities and resources ranging from a monthly food bank to parenting courses and seminars. (That said, Ashton and Banks emphasized that there would be “a clear separation of church and state.”) Banks told me in his first-floor office that “one of the biggest responsibilities as a church and as a community is to make certain that our children are doing well.”

Ashton also emphasized the importance of academic and personal rigor—a crucial aspect, she believes, of preparing students for high-level careers. “I would call us ‘high expectations, high empathy,’” she said. As my colleague Isabel Fattal has written, research has shown that later school start times are better for teens’ mental and physical health and academic performance; scientists typically recommend pushing the bell to 8:30 a.m. But Ashton hopes that DPA’s start time of 7:30 will prepare innovators for their future work routines: “We tell our students all the time that if you’re going to be successful … you’re going to have to outwork everybody.”



Every few years, typically four to six, Congress dusts off the federal law that governs higher education—there are no penalties, per se, if it doesn’t, but the law can quickly become outdated, and if lawmakers want to ensure that federal college programs run smoothly, they keep that schedule. At least that’s what is supposed to happen.

The reauthorization of the Higher Education Act is a seemingly endless Will they or won’t they?—the wonky romantic comedy that writers haven’t been able to finish. The last reauthorization was in 2008, meaning that the typical deadline has long passed and making this the longest the bill has gone without a touch-up. But lawmakers in both the U.S. House and the Senate seem eager to get a deal done, with a rush of activity—speeches, public hearings, and even a New York Times op-ed—stoking the anticipation that the long-overdue update to the HEA may be nigh.

The law oversees federal programs—student loans, accreditation, completion initiatives—and updating it could change a lot of things about higher ed. A reauthorization could range from just clearing some cobwebs to a gut renovation of the bill. It could fix the Free Application for Student Aid, the FAFSA; it could make sure the amount of Pell Grants for low-income students is consistent with the rising cost of college; it could increase federal oversight for higher-education institutions; or it could eliminate some regulations to make it easier for colleges to try new things.

One of the reasons why lawmakers are so keen to update the law is a near-universal belief that college—the affordability of it and access to it—is in desperate need of repair. In recent years, students, parents, and policy makers have all been questioning whether college is still worth the astronomical cost. On Friday, the U.S. House Committee on Education and Labor, led by Representative Bobby Scott, a Democrat from Virginia, released a new report, arguing that though higher education has its issues, a college degree still packs a significant value.

The report, titled “Don’t Stop Believin’ (In the Value of a College Degree),” is the committee’s attempt to lay out its guiding principles as it prepares for its first hearing on reauthorization next week. “As the Committee begins to debate solutions for the vast challenges in higher education, the findings in this report must guide our approach,” Scott said in an emailed statement to The Atlantic. “Rather than diminishing the value of a college degree, we should recognize that all students should have access to the substantial financial and social benefits that come with a quality higher education.” The committee Democrats still believe that college is the right choice for most people, and they want to emphasize racial and economic equity as part of the effort to expand access to college credentials.

The numbers, the report says, speak for themselves. “Two out of three jobs are filled by individuals who have at least some college education,” it reads. That doesn’t refer only to two- or four-year degree programs. The report also advocates for certificate programs, but urges the need for accountability, cautioning against for-profit programs in particular, where students may pay more for less return on their investment. “The cost of attending for-profit colleges is three times that of attending a community college,” the report notes.

Over the past several weeks, Senator Lamar Alexander, the Republican chair of the Senate’s education committee, and Senator Patty Murray, the committee’s top Democrat, have laid out their own visions for a reauthorization. That committee will also be hosting its first hearing on updating the law next week. While both Alexander and Murray have told The Atlantic in emailed statements that they would like the resulting legislation to be bipartisan—“We have a good history of working together to find areas of agreement, and I expect that we will be able to do the same this year,” Alexander said in his statement—and that they have been “encouraged” by the discussions up to this point, there are still significant partisan gulfs on basic policy that could prevent a final bill from passing.

For example, Alexander has pointed out that the “current level of generosity” in the form of grants and loans to students is “unprecedented,” leading to increased government spending; meanwhile, Murray argued in a keynote address at the Center for American Progress late last month that the government should be factoring in child care, books, and housing when addressing college costs and student needs, suggesting that she will push for a greater federal investment. “It’s becoming increasingly clear that the cost of living is the cost of college—and that many students are struggling just to meet their most essential and basic needs,” she said during the speech.

Still, despite their differences, the serious activity in both the House and the Senate suggests that the shape of federal higher education could change significantly in the near future. Deciphering whether or not a Higher Education Act reauthorization will actually pass can feel like trying to read tea leaves, but if the recent flurry of activity is any indication, a failure to reach a deal will likely be due not to a lack of trying, but to fundamental disagreements.



When hundreds of high-school students gathered on George Washington University’s campus this week, they may have expected to clash with protesters. After all, they were invited by Turning Point USA, the right-wing group that identifies faculty members who it perceives to be biased against conservative students and shames them on its “Professor Watchlist.” The organization also regularly decries the overpolicing of speech by liberals on college campuses.

But there were no speech police present on this dreary day in the nation’s capital—the event went on without a glimmer of protest. And for those who are used to protests wherever they go, such as Education Secretary Betsy DeVos, who would be speaking later, it must have been a  welcome change.

GW’s Lisner Auditorium  was every bit a Young Republicans conference, with a 2018 twist. There were tables with Ayn Rand literature, pamphlets on “The Case Against Gun Control,” “Socialism Sucks” T-shirts, and “I Love Capitalism” paraphernalia. And then there were the students. Some of them were attending because they’d seen the list of speakers—Attorney General Jeff Sessions, Anthony Scaramucci, House Majority Leader Kevin McCarthy, UN Ambassador Nikki Haley, and, of course, Turning Point USA’s founder, Charlie Kirk—and they couldn’t pass up the opportunity to meet them. Others said they had lost friends when they “came out as conservative” and were there to connect with likeminded peers. And still others said they were there to learn how to “own the libs.”

The inside of the auditorium generally reflected that sentiment. The students were alert during every speech, seemingly waiting for cues to chime in. When Rick Santorum said Hillary Clinton’s name, they chanted “Lock her up!” He mentioned CNN and they booed; when former President Barack Obama came up, his name got a similar response. One student, during a Q-and-A session, prefaced his question with a statement: “Hillary Clinton is not president!” The crowd erupted in cheers.

Some speakers fed into the rowdy vibes, joining the crowd in disparaging one liberal figure or another. The New York Times reported that Sessions, for one, laughed during a round of “Lock her up!”

The auditorium was dimly lit, and anonymous shouts came from islands across the room. When the president of the Heritage Foundation discussed building bridges with those on the left, a young man in the front yelled, “And a wall!” While several students I met in the lobby were looking for engaging intellectual conversation, the ones in the auditorium seemed more interested in Trump-rally-style eruptions. Dave Rubin, the host of The Rubin Report, a talk show and podcast, remarked that it felt like “Twitter in real life.”

This was the energy in the room when DeVos took the stage. It had already been quite a day for the secretary. Her department had issued its proposed changes to the “borrower defense” rule—an Obama-era regulation that helped students defrauded by their colleges receive debt relief. And on Capitol Hill, a reauthorization of the law governing more than $1 billion in grants to states for career and technical education—which received bipartisan support—had just been passed and was headed to the president’s desk. Neither of those topics came up during her roughly 30 minutes onstage.

Kyle Kashuv, a survivor of the shooting in Parkland, Florida, and Turning Point’s director of high-school outreach, introduced the secretary. The students in the audience had spent the entire day being primed to boil over in bursts of teenage energy. But during DeVos’s relatively tame speech, the outbursts were few and far between. She opened by talking about gun violence, and the Federal Commission on School Safety. “School safety is not a partisan issue. It is about protecting students' lives. Your lives,” she said. And then she launched into a familiar monologue about batting down a “one size fits all” approach to education in favor of expanded school choice.

Then came an interview with Charlie Kirk, who lavished praise on the secretary for her accomplishments—both personal and as a member of the administration—before lobbing a handful of questions her way: What does school choice mean? How should we be thinking of education after high school? How have her private successes helped with her work at the department? DeVos answered the last question by noting that the private and public sectors are quite different, and that she hadn’t been aware just how “formidable” the bureaucracy was in the Department of Education.

And then Kirk asked what the secretary would tell young conservatives who might face backlash on college campuses for their political views. She offered a bit of temperate advice. “I would encourage you all to be curious, learn, study ideas, and frame your opinions from an informed perspective. Listen to others, especially those with whom you don’t agree,” she said.

Despite the pugilistic attitude among the teenage attendees (and some speakers), civility was a common message onstage. Haley, two days earlier, had encouraged students to focus less on “owning the libs,” and a handful of speakers that day had done the same. It’s fun, sure, Haley told them, “but step back and think about what you’re accomplishing when you do this — are you persuading anyone? Who are you persuading?”

When the conversation wrapped, DeVos was ushered off the stage by Kirk. Students I spoke with had mixed reactions to her session: Some enjoyed her advocacy for school choice; others were a bit puzzled. A large group of students hurried to the stage for a shot at a photo with the secretary. But there would be no photo opportunity, just a handful of disappointed sighs. But they didn't last long. Several speakers will still to come: the billionaire investor Peter Thiel, Congressman Louie Gohmert, the Breitbart News editor Alex Marlow. Compared with the rest of the day, DeVos’s appearance was tame—she, and others, came to the students preaching policy and civilized debate, but it’s not clear that they were paying attention.



Yale has doled out more than 2,500 honorary degrees since it was founded in 1701. On Tuesday, Bill Cosby, who had an honorary doctorate of humane letters from the university—the kind awarded to people who have made “contributions to society”—conferred upon him in 2003, became the first person in the institution’s history to have his rescinded.

The decision was “based on a court record providing clear and convincing evidence of conduct that violates fundamental standards of decency shared by all members of the Yale community, conduct that was unknown to the board at the time the degree was awarded,” Tom Conroy, a university spokesman, said in a statement. He further noted that the university “is committed to both the elimination of sexual misconduct and the adherence to due process,” adding that the university was reaffirming its commitment to those goals by pulling the honor.

But the decision to rescind the doctorate—and turn back on centuries of precedent—does something else as well: It underscores the gravity of the crimes of which Cosby has been found guilty, and the pressure upon universities to signal they are taking the issue of sexual abuse on campus seriously.

Revoking an honorary doctorate is rare in higher education, so Yale’s more-than-300-year streak of never having done so stood out—alongside those of the nation’s oldest colleges, Harvard and the College of William and Mary. So it was news last week when Yale announced, after Cosby’s guilty verdict came in, that it would consider withdrawing honorary degrees it had given out. Over the years, by Inside Higher Ed’s count, Cosby has been the recipient of at least 60 honorary degrees, and dozens of colleges had already revoked the honor before Yale did—including Cosby’s alma mater, Temple University, which did so last week. Students had been calling for Yale to yank the honor since 2014, when allegations against Cosby began to resurface.

It wasn’t the first time Yale’s students had expressed sharp displeasure with someone the university had chosen to honor. In 2001, students protested as George W. Bush, a Yale alum, received an honorary doctorate. And earlier this month, alumni renewed calls for the university to rescind the honorary degree of Stephan Schmidheiny, who was convicted six years ago for his responsibility in the deaths of more than 2,000 people from asbestos-related diseases.

Across the Ivy League—and higher education more generally, which has grown ever more generous with giving honorary degrees to celebrities—the degrees are not often pulled, outside of particularly serious circumstances. For example, the University of Massachusetts revoked one such degree given to Zimbabwean President Robert Mugabe in 2008, calling his leadership “an assault on human rights.” And in 1918, the University of Pennsylvania revoked an honorary doctorate it had conferred upon German Kaiser Friedrich Wilhelm II after World War I. Wilhelm and Germany’s then-ambassador to the United States, Johann Heinrich von Bernstorff, were the last names stricken from the rolls of honorary degree recipients at Penn prior to Cosby and Steve Wynn, the embattled hotelier, who also lost his degree last week.

As my colleagues Adrienne Green and Alia Wong noted in 2015, “many of the universities who’ve granted Cosby their highest honor are also struggling to convince the public of their commitment to eradicating campus sexual assault. Retaining any affiliation with an alleged rapist could be seen as disingenuous.” In the era of #MeToo and a heightened concern about colleges’ commitment to curbing sexual violence—particularly following the Larry Nassar scandal, and the fear of how the landscape for federal policy guiding sexual assault on campus will look after a rollback of Obama-era rules by Education Secretary Betsy DeVos—schools are being forced to make such symbolic decisions with ever more urgency.



My mother died while surviving civilization. Although she outlived a traumatic childhood immersed in its teachings, she carried the pain of those lessons for her entire life. Like most Native American peoples, our family’s story is touched by the legacy of boarding schools, institutions created to destroy and vilify Native culture, language, family, and spirituality. My mother, Bernice, was a survivor of Saint Mary’s Catholic Indian Boarding School on the Ojibwe reservation in Odanah, Wisconsin. She called it the “Sister School,” a world ruled by nuns clad in long black robes.

Two hundred years ago, on March 3, 1819, the Civilization Fund Act ushered in an era of assimilationist policies, leading to the Indian boarding-school era, which lasted from 1860 to 1978. The act directly spurred the creation of the schools by putting forward the notion that Native culture and language were to blame for what was deemed the country’s “Indian problem.”

Native families were coerced by the federal government and Catholic Church officials into sending their children to live and attend classes at boarding schools. (About one-third of the 357 known Indian boarding schools were managed by various Christian denominations.) According to the Act’s text, Christian missionaries and other “persons of good moral character” were charged with introducing Native children to “the habits and arts of civilization” while encouraging them to abandon their traditional languages, cultures, and practices.

This is what achieving civilization looked like in practice: Students were stripped of all things associated with Native life. Their long hair, a source of pride for many Native peoples, was cut short, usually into identical bowl haircuts. They exchanged traditional clothing for uniforms, and embarked on a life influenced by strict military-style regimentation. Students were physically punished for speaking their Native languages. Contact with family and community members was discouraged or forbidden altogether. Survivors have described a culture of pervasive physical and sexual abuse at the schools. Food and medical attention were often scarce; many students died. Their parents sometimes learned of their death only after they had been buried in school cemeteries, some of which were unmarked.

When my mother was alive, I would often interrogate her about her life at the Sister School. Annoyed, she would demand, “Why do you always have to go poking?” And so I’ve spent much of my personal life and professional work as a journalist trying to uncover and investigate all that happened to her and thousands of others at Indian boarding schools.

For reasons I still don’t completely understand, I am consumed by the need to validate and prove, intellectually and emotionally, her experiences at the Sister School. I crave confirmation because I believe it will somehow reinforce my mother’s stories in the face of generations of federal and Church denials of their role in the boarding schools’ brutality. It will say to me: You’re not making this up. This really did happen.

As this country marks the bicentennial of the Civilization Fund Act, I think of the traumatic impact of my mother’s time at Saint Mary’s and, in turn, the effect that her dysfunctional survival strategies had on our family.

Although she died in 2011, I can still see her trying to outrun her invisible demons. She would walk across the floor of our house, sometimes for hours, desperately shaking her head from side to side to keep the persistent awful memories from entering. She would flap and wring her hands over and over again, as though to rid them of a clinging presence.

She was lost to our family during these times. We guarded her with our tensed stomach muscles, trying to help her battle the unknown demons. Eventually she would wind herself down. Sometimes, even laughing a bit in relief, she’d mutter, “Settle down, you crazy old chicken,” before collapsing on her bed.

Hypervigilance, defensiveness, resentment, and a hair-trigger temper had been her only allies against the Sister School messages of racial inferiority, daily reminders that Natives were primitive beings unlikely to rise above the role of servants in a white man’s world. She raged against the nuns’ label “dirty Indian,” haunted by the fear that the nuns were right, even as she scrubbed miles of floors and performed hours of heavy manual labor.

All of those awful Sister School doings cut her mind. I think she believed that she would break into 1 million pieces if she recalled the traumatic events that held her hostage, forever burned into her amygdala.

I remember a summer day, one of many, when I made my mother toast and brought her aspirin in her dark bedroom, where she was bedridden with a migraine. I placed my offerings on the little table next to her bed, and retreated back to my hiding place under the kitchen table.

After a while, she called to me. I found her lying in the dark, with one arm thrown over her eyes; the other arm was open for me. Silently, I climbed onto the bed, fitting myself into her armpit and gazing at the tiny blue Virgin Mary medal pinned to her brassiere, a hidden remnant of her boarding-school days. I remember the bedspread, stiff from its time drying outside on the clothesline and fragrant with fresh air and my mother’s scent. She would spend hours washing the laundry “white, white” like the Sisters had taught her, rushing up and down the cellar steps with baskets of heavy, wet sheets. “We may be Indian, but by God we ain’t dirty,” she’d say while hanging laundry on the line.

I remember her deep voice that wrapped a cocoon around us in the bedroom as she, like she had done hundreds of times before, told me her Sister School stories. There was the “evil” nun Sister Catherine, Mother Superior Sister Catherine of the Franciscan Sisters of Perpetual Adoration, who was the principal of the boarding school she had attended.

As she described the nun’s inexplicable cruelty—the beatings, the shaming, and the withholding of food—I snuggled closer to her in anticipation. Then the mood of her story lifted, and I remember how her voice took on the conspiratorial tone that I loved.

“One year during the Christmas season, Sister was marching down the cellar steps to check if we stole any food,” she said. “She fell on the bottom step—crash! She hit her head bad! Not long after, she died.”

“What a silent cheer us kids made!” she continued. “Maybe it was terrible, but it was the best Christmas present we ever got!” I remember how she clasped her hands together and how, for a few moments, we shared a little girl’s wicked happiness.

I still marvel at her ability to reinvent and protect her sanity with what I now assume were fantasies in which good always triumphed over evil.

In 2015, my questions led me to the special-collections library at Marquette University in Milwaukee, where a trove of records from the Bureau of Catholic Indian Missions is stored. Carefully preserved and tended, the documents lie in climate-controlled archival luxury. I made a special appointment with the archivist weeks in advance to examine them.

On the day I went, I was the sole visitor in the huge reading room. I sat at one of the enormous tables and opened the first of many boxes. To my great disappointment, it contained photocopies of lists of students’ names at the various Catholic boarding schools that once dotted Indian country. I’d hoped to see the original documents, and to find my mother’s report cards or documents describing her time at Saint Mary’s.

Eventually I came across the names of my mother and her siblings, the ink faded, written in careful cursive. I sat back heavily in my chair and breathed an exasperated sigh; her life at the school and all that happened there was represented by only her name written on a long, nondescript list of other students.

When the archivist arrived, he explained that even the original collection, full of yellowing documents instead of photocopies, held very little personal information about any of the students who had attended the schools so long ago. He explained that the original documents were largely administrative, but that I could view them if I liked.

I’d come this far, so I said yes.

He brought out another cartload of cardboard file boxes. Beyond the lists of student names with check marks in columns indicating whether they’d graduated, run away, or died, the boxes contained mostly bureaucratic reports and correspondence between generations of boarding-school principals and the Bureau of Catholic Indian Missions in Washington, D.C, the agency that oversaw the boarding schools.

There was nothing in the dry letters and reports concerning the people I wanted to learn about, such as Sister Catherine or my mother. I thought about calling it a day. But for a moment there in the silent room, I distinctly heard my mother whisper my name, Mary! Her tone had a familiar ring, like when she’d demand me to “get down on those prayer bones, girl!” when I scrubbed the floor.

So I continued my search, and I found documents relating to Saint Mary’s, including a yellowed, typewritten letter dated January 3, 1934. It was addressed to the Right Reverend Monsignor William Ketcham, the director of the Bureau of Catholic Indian Missions, from Sister Mary Macaria, the Sister secretary of Saint Mary’s.

It read in part:

By the time these lines reach you, our dear Mother Superior Sister Catherine will, no doubt, have been called to her eternal reward. On December 19, she fell off the second last step leading down to the kitchen entry.

She must have pitched forward with great force, for in striking her head against a windowsill; a gash was cut in her forehead by the temple of her glasses. On Friday Dec. 29, the Sister nurse noticed a change in Sister’s condition and told us she feared a stroke.

Our dear sister had convulsions, was anointed and has been speechless since. The doctor says it can hardly be but a matter of a day or so at most if she does linger even that long.  

We know you will pray earnestly for her eternal repose and for a speedy relief from her sufferings. Sorrowfully yours in the agonizing Heart of Jesus.  

Sister Macaria

When I got to the end of the letter, I stood straight up out of my chair. I recovered myself and sat back down; I concentrated on the contents of the box again. To my amazement, I found an original photo of Sister Catherine. Covered from head to toe in her black-and-white nun’s habit, she gazed sternly into the distance through her thick, wire-rimmed glasses.  

The room was air-conditioned, but I was sweating as I read the remaining documents in the Saint Mary’s file. At last, I held tangible proof  that her stories were true.

Corroborating even part of her story vindicated her wounded life. It gave me authority over our family’s mysterious, shameful secret, in which the punishment for being Native was a humiliation we could never overcome. How many other Native families could find some comfort in the information in these obscure archives?

As the United States marks the anniversary of the Civilization Fund Act and all the devastation it set into motion, the federal government and Christian churches have an opportunity to begin a new chapter in their relationship with Native peoples.

Healing is possible. Canada, which operated hundreds of Indian residential schools with similar assimilationist agendas, implemented the Indian Residential Schools Settlement Agreement in 2007, in which the government formally apologized to former boarding-school students and paid reparations to survivors. And in 2009, Canada created the (now-defunct) Truth and Reconciliation Commission, which began a multiyear process of collecting and listening to survivors’ stories, opening up residential-school records to survivors and families, and ensuring that the history and legacy of the schools are never forgotten.

According to residential-school survivors I interviewed in Canada, the public admission of wrongdoing from churches and the government, as well as the opportunity to meet other survivors, meant far more to them than reparations or public displays of reconciliation. Two sisters from the Lac Seul band of Ojibwe shrugged their shoulders in response to my questions about what the future holds for government promises to improve indigenous relations. “I buried my anger for 20 years; I blocked it out,” said one sister, who asked to remain anonymous for fear of retaliation from her non-Native neighbors. “But listening to others talk about their experience helped me make a new start and get over my bad feelings.”

Senator Murray Sinclair, Canada’s second-ever indigenous judge, who chaired Canada’s Truth and Reconciliation Commission and presented its official findings in 2015, described the impact of allowing survivors to tell their stories to me this way: “They were not subject to cross-examination as if on trial. They were invited to share what they had to share, no more, no less. Their stories were recorded into history, and at the end of each day, they were acknowledged.”

As of now, apologies in the United States have been few and far between. Although President Barack Obama signed the Native American Apology Resolution on December 19, 2009, apologizing for past “ill-conceived policies toward the Native peoples of this land,” the resolution had no impact on federal policy toward Native Americans. With its disclaimer against any legal claims, the resolution faded into the woodwork of legislative paperwork.

Statutes of limitations for civil or criminal cases make any legal action impossible in the United States, according to the Native American Rights Fund attorney Donald Wharton. Lawsuits against Christian denominations would need to take place in individual state courts, and would likely be costly and burdensome. Attempts at gaining reparations at the state-legislature level have failed, too; in February, the South Dakota legislature killed a bill that would have extended the window for childhood survivors of boarding-school abuse to file suits against organizations such as the Catholic Church.

In addition to an admission of its role in the boarding-school programs, the government could make records from the time more easily available to survivors and their families. Telling the truth won’t change the facts of all that happened or the damage that was done. It would, however, offer thousands of Native peoples the solace of physical evidence and validation like the kind I got, which could guide a path toward healing.



What should be on the list of tasks for President Trump’s newly minted school-safety commission, charged with studying what can be done to prevent campus violence?

Perhaps the commission, chaired by U.S. Education Secretary Betsy DeVos, should look at mental-health resources and student-discipline practices. And perhaps it should consider the design of campus facilities. One thing that would seemingly be an obvious candidate for the commission’s scrutiny is guns, as guns have been the weapon of choice in every major school-violence incident this year.

And yet it became clear on Tuesday, as DeVos testified in front of a Senate subcommittee to answer questions about the Education Department’s fiscal year 2019 budget request, that will likely not be the case. Amid mostly peaceful exchanges about charter-school expansion, the recent wave of teachers’ strikes, and Pell grants, among other topics, a handful of Democratic Senators repeatedly asked DeVos how gun policy fits into the commission’s duties. She didn’t verbalize the G Word once, and at one point—in response to persistent questioning from Vermont Senator Patrick Leahy about the role of guns in school violence—DeVos dismissed that question as outside the commission’s charge. It’s up to Congress to debate gun control, she indicated; she and the commissioners are instead focusing their research on other potential sources of violence.

“So we’ll look at gun violence in schools, but not look at guns,” Leahy, the subcommittee’s vice-chair, said at the end of his back-and-forth, after unsuccessfully pushing DeVos to opine on whether an 18-year-old should be able to easily purchase an AR-15 rifle and hundreds of rounds of ammunition. “That’s an interesting concept.”

DeVos’s admission stands in contrast with the duties the commission was given at the outset—in fact, examining age restrictions on certain firearm purchases is the first item on the White House’s bullet-point list detailing the commission’s areas of focus. When the Education Week reporter Andrew Ujifusa asked DeVos’s spokeswoman on Tuesday to clarify the matter, she emphasized that, unlike Congress, the commission can’t create or amend gun laws but confirmed that it will look into “all issues the President asked the committee to study”—a framing that appeared to contradict what DeVos had said in her testimony.

The responses from both DeVos and her spokeswoman will likely do little to assure the Senators and others who believe gun reform is integral to efforts to make schools safer. For them, the secretary’s promise to study the “culture of violence,” where it comes from, and how it manifests itself in different ways is incomplete if it’s not coupled with a hard look at gun laws.

By relegating gun control to the backburner, the commission could wind up exemplifying what critics say is the Trump administration’s half-hearted approach to the country’s school-violence phenomenon. After all, the budget DeVos was promoting on Tuesday proposes cutting by $25 million funds designated for national school-safety activities compared with 2017 levels; it also would do away with a $400 million grant program that can be used for violence-prevention efforts.

“This budget is another example of an empty promise made by this administration to address the senseless gun violence devastating our families and our schools and our communities around the country,” said Washington Senator Patty Murray, a Democrat, during the hearing. “Your safety commission has yet to take any real action steps and now your budget would eliminate grants used to improve student safety for the second year in a row. After the tragic Parkland shooting, you said Congress should hold hearings on gun and school safety. So, in a show of good faith, I urge you to commit to testify on what meaningful gun safety reform we can enact to help end the scourge of violence in the schools.”

When it was her turn to question DeVos, New Hampshire Senator Jeanne Shaheen, also a Democrat, pointed out that the school-gun-violence problem is unique to the United States. She then went on to beg the secretary to tweak the commission’s mission to ensure it actively studies gun laws and the role that guns play in school violence.

That DeVos will change course seems unlikely. As striking as her testimony was, it was right in line with her track record on the guns question; DeVos has consistently distanced herself and the commission from gun control. Her responses at the Tuesday hearing were evocative, for example, of those she provided in her widely ridiculed interview with Lesley Stahl on 60 Minutes in March, when she refused to acknowledge that the post-Parkland youth movement was focused on gun control. “They want a variety of things,” the education secretary had responded when Stahl stressed the activists’ gun-control mission. “They want solutions.” That distancing could itself serve as a clue as to what the country can expect from the commission when it announces its conclusions later his year: a litany of solutions in which the word “gun” barely registers, if it gets mentioned at all.



During a speech on Thursday, President Trump revealed a striking ignorance of one of the pillars of his country’s educational system. In the course of promoting his infrastructure plan, he, a bit perplexingly, dismissed the country’s community colleges, suggesting he doesn’t know what purpose they serve. “We do not know what a ‘community college’ means,” he told the crowd in an Ohio training facility for construction apprentices, moments after expressing nostalgia for the vocational schools that flourished when he was growing up—schools that offered hands-on training in fields such as welding and cosmetology.

He seemed to have a better grasp on these latter schools, analogizing them to the apprenticeship programs he was promoting in his effort to create 400,000 high-paying infrastructure jobs. The implication, as he brushed aside one form of higher education and lauded another, was that he’d like to resuscitate short-term training opportunities and phase out community colleges in the name of workforce development.

One of Trump’s stated goals is to ensure that every American knows “the dignity of work, the pride of a paycheck, and the satisfaction of a job well done”—but he seems to be unaware of the vital role that community colleges play in realizing that vision. As Jeffrey Selingo wrote in The Atlantic earlier this year, the fastest-growing jobs in the United States require candidates to have training and education beyond high school, and community colleges, which typically offer associate’s degrees, will be key to filling those openings.

Community colleges are not just a substantial part of the future of American education—they are also a substantial part of its present. More than 40 percent of the country’s undergraduates are currently enrolled in community colleges, according to the College Board, the higher-education research firm and test administrator. Preliminary federal data suggest that roughly 9 million undergraduates were enrolled in community colleges in the 2015-2016 school year. And with their low tuition (typically costing less than what federal Pell grants provide) and practice of letting in all applicants, community colleges serve as a pathway to the middle class for low-income and first-generation students. Further, one in three community-college students transfers to a bachelor’s-granting institution within six years.

Enrolling in a community college certainly doesn’t guarantee a steady, well paid job. As my colleague Ann Hulbert has pointed out, too many community-college students never earn a degree. But that’s largely because two-year institutions serve a disproportionate percentage of students whose life circumstances—many have families to support and are working full-time jobs to pay their bills—make completing a degree particularly difficult. (Community colleges are acutely aware of this challenge and have implemented programs to better support such students; many are even evolving from learning and training institutions into holistic support systems, establishing food pantries on campus and offering subsidized daycare.)

On Thursday, Trump said the vocational schools of yore “were not called community colleges, because I don’t know what that means.” The president was right that there’s a difference between vocational schools and community colleges: Historically, the former were offered at the secondary level and seen as an alternative to a college degree, designed to prepare students for careers in industries like manufacturing. The latter took a broader approach, giving students skills that might apply across industries. Indeed,  the term community college is unambiguous. As one administrator of a community college in Oregon told my colleague James Fallows back in 2015, “When we say we are a ‘community college,’ we really mean that we are for and of this community.” Replacing community colleges with vocational schools would mean doing away with institutions that have given millions of Americans the practical skills, liberal-arts background, and diploma that are considered prerequisites for a growing number of jobs—and shepherded millions of others to four-year institutions.

What’s more, Trump’s insinuation that the aims of vocational training and community colleges are mutually exclusive signals a misinterpretation of the latter’s role in today’s workforce-development initiatives; community colleges also help keep local and regional economic engines running. Community colleges were established after World War II to churn out qualified workers—a duty they’ve continued to fulfill. As Selingo noted, “Some 34 percent of the roughly $114 billion the federal government spends annually on workforce development and education goes to higher education, with much of it flowing to two-year colleges.”

And even though the term vocational education isn’t used today as often as it was in the 20th century, that doesn’t mean that community colleges have crowded out such training opportunities. In fact, they’ve seen a resurgence in recent years. The difference is primarily semantic: Nowadays,  such training is typically described as “career and technical education”—the result of a rebranding effort aimed in part to counter vocational schools’ (somewhat earned) reputation for tracking disadvantaged Americans into low-wage jobs.

The incorrect assumption that Trump made in his speech on Thursday was that community colleges and vocational schools haven’t been able to and can’t exist alongside each other—a misunderstanding that further underappreciates an already underappreciated component of American education.



In the late 1800s, one of the most enduring fictional characters of all time first appeared on the scene. No, I am not talking about Sherlock Holmes or Oliver Twist, but a less well-known though arguably more influential individual: Homo economicus.

Literally meaning “economic man,” the origins of the term Homo economicus are somewhat obscure—early references can be traced to the Oxford economist C. S. Devas in 1883—but his characteristics have become all too familiar. He is infinitely rational, possessing both unlimited cognitive capacity and access to information, but with the persona of the Marlboro Man: ruggedly self-centered, relentlessly materialistic, and a complete lone ranger. Homo economicus, created to personify the supposedly rational way humans behave in markets, quickly came to dominate economic theory.

But then in the 1970s, the psychologists Daniel Kahneman and Amos Tversky made a big discovery. The academics drew on psychological evidence to show that the actions of human beings deviate from the ironclad rationality of Homo economicus in all sorts of ways: People make systematic errors of judgment, such as being excessively attached to what they own, and yet are also more generous and cooperative than they’re given credit for. These insights led to the founding of a new field, behavioral economics, which became a household name 10 years ago, after Cass Sunstein and Richard Thaler published the best-selling book Nudge and showed how this new understanding of human behavior could have major policy consequences. Last year, Thaler won the Nobel Prize in Economics, and promised to spend the $1.1 million in prize money “as irrationally as possible.”

But despite the fanfare, Homo economicus remains a stubbornly persistent part of the economics curriculum. While it is fashionable for most economics departments to have courses on behavioral economics, the core requirements in economics at many colleges are usually limited to only two substantive courses—one in microeconomics, which looks at how individuals optimize economic decisions, and another in macroeconomics, which focuses on national or regional markets as a whole. Not only is the study of behavioral economics largely optional, but the standard textbooks used by many college students make limited references to behavioral breakthroughs. Hal Varian’s Intermediate Microeconomics devotes only 16 of its 758 pages to behavioral economics, dismissing it as a blip in the grand scheme of things, an “optical illusion” that would disappear “if people took the time to consider choices carefully—applying the measuring stick of dispassionate rationality.” The staple textbook on macroeconomics, written by Gregory Mankiw, gives behavioral approaches even shorter shrift by scarcely mentioning them at all.

Instead, the overwhelming majority of courses that students take in economics are heavily focused on statistics and econometrics. In 2010, the Institute for New Economic Thinking convened a task force to study the undergraduate economics curriculum, following up on a report from 1991. What changed in the intervening years, it found, was “an increase in mathematical and technical sophistication” that was “not sufficient to foster habits of intellectual inquiry.” In other words, Homo economicus is going strong in lecture halls and textbooks across the country.

Economists’ resistance to incorporate the wisdom of behavioral approaches may seem like a frivolous concern confined to the ivory tower, but it has serious consequences. What students are taught in their economics classes can perversely turn models and charts that are meant to approximate reality into aspirational ideals for it. Most economics majors are first introduced to Homo economicus as impressionable college freshmen and internalize its values: Studies show, for instance, that taking economics courses can make people actively more selfish. The consequences are only made more acute by the fact that business, a more preprofessional version of economics, is the single most popular major for college students in the United States—some 40 percent of undergraduates take at least one course in economics. That behavioral economics has been minimized and treated as an aberration by the mainstream has major bearings on how students make sense of markets and the world.

What is so surprising about the hesitancy of economists today to absorb the learnings of behavioral economics is that until the appearance of Homo economicus, invoking psychology in the teaching of economics was standard. At the University of Cambridge, for instance, before a stand-alone department was established in 1903, economics was taught alongside psychology and philosophy. Only after World War II, when the center of gravity of the discipline shifted across the Atlantic, did the rupture became so stark. The dawn of the American era in economics marked a more intense commitment to mathematical analysis, at the exclusion of all else.

This profound change in the economics curriculum has resulted in a discipline that is sterile, tone-deaf, and lacking an emotional pulse—but also one that has proved ineffective in its explanatory and predictive capacities. Economists don’t exactly have a great track record at anticipating the pertinent developments of late: The discipline as a whole was caught off guard by the Great Recession in 2008 and has been late to recognize the skyrocketing rise of inequality. It is even more ill-equipped to deal with looming seismic shifts on the horizon, such as the accelerating effects of climate change or how advances in artificial intelligence will affect workers. Given the greatly amplified role of professional economists at every level of policy making, the extent to which economics is disconnected from reality is becoming more alarming.

Making behavioral economics compulsory isn’t a cure-all for the ills of the economics discipline, but doing so would go a long way in encouraging students to think about building economic models around actual human beings rather than around the caricature that is Homo economicus. If there’s a deeper lesson to come out of the behavioral revolution, it’s that the vagaries of human behavior make it very difficult to model as a pure science, and economists have a lot to learn from other disciplines, including other social sciences and the humanities. This may mean a dose of humility for economists, but it would enrich both the education that their students receive and their prospects of making positive change in the real world.

So because rumors of the demise of Homo economicus have been greatly exaggerated, economics professors today still have the chance to cast aside this antiquated character once and for all.



As the costs of college have climbed, some students have gone hungry. When they’ve voiced frustration, they’ve often been ridiculed: “Ramen is cheap,” or “Just eat cereal.”

But the blight of food insecurity among college students is real, and a new report from the Government Accountability Office (GAO), a nonpartisan congressional watchdog, highlights the breadth of those affected. There are potentially millions of students at risk of being food insecure, which means they do not have access to nutritious, affordable food, the report says. It is the first time the federal government has acknowledged food insecurity on campus in a significant way. The federal government spends billions of dollars on higher education each year, and this report finds that some students are at risk of dropping out because they cannot eat, although there aren’t good data on just how many.

Existing studies vary in how they describe the scale of the problem. “Nationally representative survey data that would support direct estimates of the prevalence of food insecurity among college students do not exist,” the report says. So the GAO conducted a review of 31 studies that met their criteria—meaning they had been conducted in the United States since 2007 and did not have severe methodological limitations. Twenty-two of those 31 studies estimate that more than 30 percent of students are food insecure.

“[The report] put it very clearly for us that we can see that especially first-time students, first-gen students, students who are raising children, single parents, face increasing obstacles to be able to complete that critical college degree,” Senator Patty Murray, the top Democrat on the Senate’s education committee, told me. The report was in response to a letter sent to the GAO on behalf of Murray, Senator Debbie Stabenow, Senator Edward Markey, and Senator Elizabeth Warren last year.

One chief way that campuses have been addressing hunger is by building food pantries on campus, but Sara Goldrick-Rab, a higher-education professor at Temple University and a leading scholar on campus hunger, told me that those only scratch the surface of the issue. “When there’s a food pantry, there’s somebody who is acknowledging the problem,” she says, but advocates have been fighting for a more systemic response.

The government can address this issue systemically through the Supplemental Nutrition Assistance Program (SNAP, commonly known as food stamps), the report says, but it adds that “almost 2 million at-risk students”—defined as students who are low income or first generation, are raising children, or have another, similar risk factor—didn’t receive SNAP benefits in 2016, even though they potentially could have.

That could be because those students didn’t know they were eligible: The government restricts students who attend college at least half-time from receiving the benefits, but certain students are exempt from that restriction. The information that most schools and SNAP offices provide students about the program is shoddy, says Samuel Chu, a national organizer for Mazon, an advocacy organization focused on eradicating hunger. “There are very specific ways and accessible ways that students can access SNAP,” he says, but even local SNAP offices are often unaware. For example, students who meet the basic criteria for SNAP eligibility and are younger than 18 or older than 50, or who have children, or who work a minimum of 20 hours a week are also eligible to receive the benefit. The GAO implored the Food and Nutrition Service, which administers SNAP, to improve information about student eligibility and share that information with its local offices.

Of course, the SNAP program is dependent on government funding, which makes it subject to budget cuts or unforeseen events such as the ongoing partial government shutdown. If the shutdown continues for a couple more weeks, SNAP may run out of funds for the 38 million Americans who receive its benefits.

Naturally, the report focuses heavily on low-income students, as they are perhaps those most likely to experience food insecurity. But Goldrick-Rab notes that they aren’t the only students who are going hungry. Middle-class students, those who are “too rich for Pell and too poor to afford college,” struggle as well. And they may not be as likely to use things such as the food pantry.

Murray told me that addressing food insecurity is one of her top priorities as Congress negotiates a reauthorization of the Higher Education Act, the major federal law governing colleges and universities. “Often we just talk about the tuition costs and dealing with that,” she says. “It has to be broader than that—[it has to be] all of the costs that come to a student as they try to complete college, including food and housing.”

Goldrick-Rab put it more bluntly. The report shows “that food insecurity is a college-completion issue,” she says. “We’re undermining our federal investment in financial aid by not paying attention to this. We have to stop pretending like living expenses are not educational expenses.”



Last Tuesday, the Justice Department charged 50 people with involvement in an elaborate scheme to purchase spots in some of the country’s top schools. The tactics described in the indictment were complex and multipronged, requiring multiple steps of deception and bribery by parents and their co-conspirators to secure their children’s admission to the schools of their choice. The plot purportedly included faking learning disabilities, using Photoshopped images to make it seem as if students played sports that they did not actually play, and pretending that students were of different ethnicities in an effort to exploit affirmative-action programs. The alleged scheme was led by a man named William Singer, who called his business venture a “side door” into college. On Tuesday, Singer pleaded guilty to all charges.

The case, rightfully, has set off a wave of conversations about how the wealthy are able to lie and manipulate their way into the country’s elite colleges and universities. But the scandal also provides an opportunity to interrogate how these universities are set up in ways that systematically amplify and exacerbate the class differences between their students. Students from low-income backgrounds receive daily reminders—interpersonal and institutional, symbolic and structural—that they are the ones who do not belong.

To understand the prevalence of wealth at top-tier schools, and how those schools often fail to adequately serve low-income students, it helps to turn to a book called The Privileged Poor,  by the Harvard University professor Anthony Abraham Jack, published earlier this month. In the book, Jack combines his own journey as a low-income student from Miami who attended selective schools (Amherst College as an undergrad and Harvard for graduate school) and his two-year ethnographic research project, in which he interviewed and followed the lives of low-income students as they navigated life at an unidentified elite school he refers to as “Renowned University.”

In the early pages of the book, Jack outlines how top colleges and universities are and have long been havens of the wealthy. In 2017, a team led by the Harvard economist Raj Chetty found that students coming from families in the top 1 percent—those who make more than $630,000 a year—are 77 times more likely to be admitted to and attend an Ivy League school than students coming from families who make less than $30,000 a year. Furthermore, the study found that 38 elite colleges have more students who come from families in the top 1 percent than students who come from the bottom 60 percent (families making less than $65,000 a year). In other research, Anthony Carnevale and Jeff Strohl, of Georgetown University’s Center on Education and the Workforce, have documented how just 14 percent of undergraduates at the most competitive schools—places like Stanford, Princeton, and Columbia—come from families who make up the bottom half of U.S. income distribution.

While many top schools have taken steps to provide more access to disadvantaged students and become more socioeconomically diverse, they remain saturated with wealth. Most low-income students still receive their education elsewhere, disproportionately attending for-profit colleges, community colleges, and less-selective four-year institutions.

The low-income students who do end up at these elite institutions are often treated as homogeneous in both policy and the scholarly literature, as if they all navigate these schools in the same way. This is one of the most important contributions Jack has made with his research—disaggregating the experience of low-income students at elite colleges.

Jack describes two categories: the privileged poor and the doubly disadvantaged. The privileged poor are students who come from low-income backgrounds but attended wealthy private high schools, giving them a level of familiarity with and access to the social and cultural capital that tend to make people successful at elite universities. The doubly disadvantaged are students who arrive at these top institutions from neighborhood public schools, many of which are overcrowded and underfunded. They are schools where these students have excelled, but that are ill-equipped to give them the sociocultural tools necessary to understand the nuances of how these elite colleges operate. For example, without being explicitly told, how would students know what “office hours” are, and that they are encouraged to use them? Many low-income students attending these universities are unfamiliar with what Jack refers to as “the hidden curriculum,” those invisible rules and expectations that can lead some students to success while leaving others floundering. The book is full of examples like this, the sort of social capital that many students, faculty, and administrators take for granted.

But certain common experiences affect both categories of low-income students, regardless of where they went to high school. For instance, Jack’s research documents how three out of four colleges close their dining halls during spring break. Many low-income students cannot afford to leave campus, much less go on vacation for break, and as a result take extraordinary measures to make sure they have enough to eat. Some students ration their food, skipping meals to make a limited supply last the entire break. Some students go to food pantries, leaving the campus of a school that might have a billion-dollar endowment to stand in line for a can of beans. One student Jack interviewed described how she increased her online-dating activity to secure meals on first dates where she expected the men to pay. “She was treating Tinder as if it were OpenTable,” Jack writes. The closing of dining halls reflects a lack of consideration of what many of these students need to survive.

Jack refers to these formal university policies as “structural exclusion,” and the dining hall is far from the only example. Many low-income students at Renowned University also participated in a pre-orientation program Jack calls “Community Detail,” in which students administer janitorial services in the university dormitories. The program is offered during the summer and throughout the year as a stand-alone job. While the students are paid, many of them found that the work brought about enormous humiliation. These disadvantaged students were put in a position where they had to clean up soiled tampons, used condoms, and dried vomit from their classmates’ bathrooms to complete their custodial obligations. Some of the students described the intense shame they felt as they sat in class alongside students whose toilets they had just cleaned. Having students who need money clean the bathrooms of their more affluent peers reifies existing class boundaries.

“Poor students come to this institution and the first thing that they see are dirty dorms they have to clean,” said one of Jack’s research participants. “I think it’s really unfair that students who are lower-income go into Community Detail whereas wealthier students are doing Summit Seekers and going climbing. Or playing instruments. Or doing artsy thing with Vamonos Van Gogh.” Or as another student put it, “Say I was to knock on someone’s door. I’m like, ‘Yo, can I clean your bathroom real quick?’ I’m going to clean the toilet you just threw up on this past weekend when you were partying like crazy. Let me just clean that for you. And then just add the fact that I’m a minority reinforces that stereotype that all Spanish people do is clean and mow lawns.”

Even well-intentioned efforts to provide opportunities for low-income students can inadvertently play a role in magnifying class differences. At Renowned, a program Jack calls “Scholarship Plus” allows students on financial aid to attend events on campus that they might not have otherwise been able to afford. (Not to be confused with the college support program of the same name, on whose board Jack serves.) A lot of the students Jack spoke with said that without the program, they wouldn’t have been able to participate in many parts of campus life. However, the process of getting tickets to events made them feel acutely conscious of their class status. The system had two lines for tickets: one for the students who could pay, and another for the students who could not. What’s more, the line for the students using the Scholarship Plus program was near the back door, and students entered the theater via a small side door rather than the main entrance used by their peers. And because of the socioeconomic realities of the United States, the main line was made up of primarily white students, while the Scholarship Plus line was made up of mostly students who were black and Latino. “It’s embarrassing,” said one of the students Jack interviewed. Another student said, “I was ashamed of what I was coming from. So being in that line, saying Scholarship Plus, I dunno. It was like being on a welfare line, or social services.”

The examples of social and economic dissonance are plenty, and as Jack puts it, “Elite universities are now a bundle of confusing contradictions: They bend over backwards to admit disadvantaged students into their hallowed halls, but then, once the students are there, they maintain policies that not only remind those students of their disadvantage, but even serve to highlight it.”

The students described in Jack’s book are the students I was thinking of after news of the scandal broke. These low-income students—overwhelmingly students of color—arrive on elite-college campuses and are perpetually made to feel as if they don’t deserve to be there, whether it’s while cleaning a classmate’s bathroom, stocking up on nonperishable food for spring break, or overhearing an offhand comment about how their acceptance was predicated on the color of their skin, or the lower socioeconomic status of their family. Meanwhile, many wealthy students for all intents and purposes have their parents buy their way into these schools through private-school tuition, test prep, donations to colleges, and myriad other advantages. And they rarely experience the same level of skepticism as to whether they have “earned” their place.

I have seen this sense of frustration and disillusionment in the eyes of undergraduates I’ve worked with at Harvard, young people who over the course of four years endure the psychological toll of navigating a school environment that both implicitly and explicitly tells them that the only reason they were admitted was an undeserved handout, that their place was not earned but is instead an act of charity, that they were given someone else’s spot. But what this scandal demonstrates is that the very idea of our society—in the context of higher ed or otherwise—being a “meritocracy” was made up to justify and reify existing social hierarchies. It is not real. What is real is the advantages of wealth and race, which often combine to give people things that they have told themselves they deserve. What is real is that students who have done everything right are often the ones made to feel as if their place on campus is anything other than earned.



Samantha remembers her high-school days more as a trial version of college. She seems part amused, part ashamed as she recalls the hours she dedicated to reworking her résumé—or the hours on top of that spent plowing through SAT exercises in the home of her one-on-one college-application coach, even though she had already achieved near-perfect scores on practice tests. On any given weeknight in high school, she says, she was likely up until 3 or 4 a.m., studying in her twin bed, then waking up at 7 to go to school. College prep consumed her already-limited free time, even cutting into hours she needed to work on homework ranging from AP-physics problem sets to her senior thesis.

Samantha, 20, who asked to be identified by her first name only so she could speak freely about a sensitive topic, is now a sophomore at Johns Hopkins University in Baltimore, some 500 miles east of her suburban Cincinnati home. A Korean American who graduated from a predominantly white, affluent private high school, she’s double majoring in international relations and East Asian studies. The century-old Baltimore campus is gradually becoming home. But the way she got there still makes her uncomfortable. “I got a very high SAT score,” Samantha says, “literally because my parents hired somebody.”

The college-admissions process, especially for highly selective, elite schools, incentivizes students to distort their identities to fit the profile they think the people reviewing their applications will find appealing. This dynamic becomes particularly problematic when it involves a student’s racial identity, whether that means over- or underemphasizing this background in an effort to seem more appealing to diversity-minded admissions officers. And that process is susceptible to subterfuge by privileged people like Samantha and her parents, who can afford to hire consultants to help them game the system.

Some of the application-juicing services are unobjectionable—basic study help and practice interviews, for example. And Samantha, who’d already started to feel disillusioned with the admissions system by the time she’d embarked on the process, didn’t lie about herself in her applications. But sometimes, in an effort to pour their personalities into a college-friendly mold, students encounter more sinister pressures. From the get-go, Samantha says her tutor and college counselors (all of whom were white) encouraged her not to sound “too Asian” in her application. She took their advice, opting not to write about her violin playing given the racial stereotypes about such instruments, and scrapping one essay she’d written about being an Asian in the mostly white equestrian world.

“A lot of the essays I wrote were dismantled,” Samantha says. “Now that I’ve looked back on it, I’m like, This is the most unfair thing ever … Sometimes I even have to stop and think about why I’m [at Hopkins]. Who’s not here because I’m here?”

On Monday, a federal judge in Boston will hear the opening arguments of a high-profile federal lawsuit that has brought national attention to the nitty-gritty details of the elite-college admissions process in the United States. Contending that Harvard University illegally discriminates against Asian American applicants, the suit is expected to eventually bring the debate over affirmative action back to the U.S. Supreme Court. In 2016, the high court ruled on Fisher v. University of Texas, determining the use of race as one factor in admissions to be constitutional. But there’s a key difference between the Harvard case and the many high-profile cases that have come before it. Where Fisher and others argued that affirmative action is harmful to white applicants, the Harvard suit hinges on the idea that affirmative action hurts minority applicants. Both Fisher and the Harvard case were brought by Students for Fair Admissions and spearheaded by the same conservative legal strategist, Ed Blum.

Students for Fair Admissions argues in this suit that Harvard’s subjective evaluation of things such as students’ personalities enables admissions officers to penalize Asian American applicants. An analysis of student data included in the plaintiffs’ court filings found that Harvard’s Asian applicants have better GPAs, higher test scores, and more prolific extracurricular involvement than their counterparts of any other race. But because of the customized and inherently nebulous approach that elite-college admissions officers take to evaluating each candidate, this fact doesn’t mean Asian students are the victims of unconstitutional discrimination at Harvard. Proving that’s the case will be incredibly difficult.

Whether or not discrimination is happening at Harvard, and whether or not it can be proved in court, the suit is shining a bright, if indirect, light on a crack in the foundation of elite-college admissions across the country. The lawsuit, it seems, is a by-product of the fact that too many students are applying for too few spots at too few colleges. The number of college-going Asian Americans in particular has surged in recent years; it may naturally follow that more seemingly eligible Asian American candidates get rejected from Harvard's limited slots.

“There’s a disease in that so many people are focused on 10 to 20 highly selective colleges that aren’t any better than 100 other colleges,” says Richard Weissbourd, a developmental psychologist and Harvard lecturer, who co-founded a national initiative that tries to encourage children to be altruistic contributors to society. “If we don’t break the back of that [disease],” Weissbourd says, “we can’t get rid of achievement pressure.” The Harvard lawsuit is merely a symptom of this disease that will likely continue to metastasize.

In the early 20th century, the country’s handful of elite universities began to request essays, teacher recommendations, and other information regarding candidates’ “background” and “character” beyond an entrance-exam score in their effort to surreptitiously restrict the number of Jewish students on campus. But the scope and purpose of this “holistic” approach to evaluating students have evolved since then, and today, in its most genuine form, it evaluates each applicant through the lens of her context—her interests and personality, yes, but also her race and parents’ educational background, for example, and the ways in which that identity may have hindered her opportunities. These days, elite colleges tend to “laud it as a legally viable method to reduce inequality and promote college access,” according to a 2017 University of Michigan policy brief co-authored by the higher-education professor Michael Bastedo. Holistic admissions can be very effective at achieving those goals: A recent study by Bastedo and several co-researchers published in the Journal of Higher Education that analyzed higher-education institutions across the United States found that those that use holistic admissions are far more likely than those that don’t to enroll low-income students.

But this complex, imprecise approach to admissions is used primarily by the most selective schools (possibly because those schools are in demand enough that they have the luxury of choosing from among many qualified applicants). According to the Journal of Higher Education study, nearly half of “Tier 1” (most competitive) institutions look at each student’s context in addition to GPAs and test scores, compared with just about a quarter of those in “Tier 3.” This approach to admissions is virtually unheard of in the vast majority of remaining colleges, many of which are probably worrying more about salvaging declining enrollment than they are about which articulate, awe-inspiring, accolade-bearing savant to choose from a sea of applications.

In the past 15 or so years, most of the country’s colleges and universities have seen a steady surge in the number of freshman applications received, but the trend has been particularly pronounced at elite institutions. In 2015, the most recent year for which national data are available, schools that accept fewer than half of all applicants accounted for just 19 percent of U.S. higher-education institutions, yet still accounted for 37 percent of all applications received that year. Lower-tier universities that primarily serve their local populations are projected to see their student numbers drop by some 11 percent over the next decade or so, while America’s elite colleges could see demand rise by 14 percent, according to predictions from the Carleton College economist Nathan Grawe, who maintains an online index with forecasts on college-attendance rates. A key historical turning point in the 20th century was the establishment of universities geared toward working-class Americans, as well as of tuition grants earmarked for populations like veterans and low-income Americans. This led to an explosion of the college-going population in the 1980s. Other factors are at play, too: the growing popularity of the Common App, which allows students to use one application for any number of schools, including all the Ivies, and has resulted in a dramatic increase in the number of schools to which each student applies. For many, there is also a growing sense that success in the modern economy requires a college education.

What’s more, an idea that two higher-education scholars once dubbed America’s “gospel of education” has for decades pervaded U.S. society: the notion that schooling is the solution to everything, and that its purpose is workforce preparation. A body of evidence does suggest that attending a top school can greatly increase one’s chances of getting a well-paying job. One 2017 study found a 21 percent difference in earnings between students who attended the country’s most selective colleges and those who attended non-selective ones like community colleges. And a 2014 study found that securing a spot at a top graduate program is incredibly difficult for students who attended less-competitive programs as undergraduates—even if they boast excellent grades and test scores.

What students want from their education may also be changing, though. Younger generations seem to value personal prestige more than older ones—and what better to confer it than an elite school on your résumé? The rate of students who identify reputation as “very important” in their college choice, for instance, has reached record-high levels in recent years, according to a nationwide survey of students that’s been conducted regularly since 1967 by UCLA’s Higher Education Research Institute; the survey found prestige to be a top priority for roughly two in three incoming freshmen in 2016.

A 2012 study published in the Journal of Personality and Social Psychology and co-authored by the San Diego State University psychology professor Jean Twenge echo this trend, finding that, in contrast with older generations, Millennials and Gen Xers view “money, fame, and image” as more important than “self-acceptance, affiliation, and community.” In 1967, for example, 86 percent of respondents in a large national survey identified “developing a meaningful philosophy of life” as an essential life goal; in 2004, the rate was 47 percent. The goal of “being well-off financially” saw a comparable uptick during that time frame. The fact that elite colleges are becoming more selective likely promotes these mentalities, resulting in a self-perpetuating circle.

Students and parents (and journalists) tend to give outsize attention to the few colleges atop the U.S. higher-education hierarchy that shower thousands of teens with rejection letters every spring. Just 4 percent of U.S. students attend colleges that accept fewer than one in four of their applicants, according to a 2016 analysis of U.S. Education Department data. But droves of students apply to those schools—nearly 43,000 people applied for one of the 1,655 spots in Harvard’s class of 2022— and prospective students and parents continue to give immense weight to rankings such as those published annually by U.S. News & World Report, which emphasizes quantitative metrics that tend to favor such institutions (like admitted students’ standardized-test scores, alumni giving, and—until this year—selectivity). All this attention raises their profile, giving elite, selective schools disproportionate power to shape the cultural norms of the higher-education ecosystem. And that includes how students approach the application process.

A few years after graduating from Harvard in the late 1980s, Naomi Steinberg started volunteering as an alumni interviewer of prospective freshmen seeking to attend her alma mater. In the mid-2000s, Steinberg, who’d left her job in marketing, decided she wanted to leverage her experience as an interviewer to establish a “boutique” college-admissions consulting firm in Boca Raton, Florida. Today, she works one-on-one with no more than 15 students at a time, most of them private-school kids with big aspirations. Two or so years ago, she noticed that she was, more and more, having to actively discourage her clients from losing sight of themselves in their pursuit of an acceptance letter.

“You can do everything ‘right’—have a 35 [out of 36 on the ACT]; have a lot of leadership, whatever that means; have all the things on some fictitious checklist of things you assumed you need to do—and you are just as likely or exceedingly not likely to get into insert-whatever-premium-university-here,” Steinberg says, stressing how arbitrary the process can be. “Admissions officers are thinking, I need a redheaded, ambidextrous tennis-star-slash-tuba-player, and now they can’t take your application that was thoughtful and wonderful because of the directive that just came down … They just need a student to fill that spot on the beautiful mosaic they’re creating.”

But as Samantha’s story attests, and as Steinberg has witnessed time and time again, it’s hard for teens to keep things in perspective when they’re in the thick of it. The application process rests on, as the Chronicle of Higher Education journalist Eric Hoover has put it, “a maddening mishmash of competing objectives.” This can make it seem like a game to be conned—something Lenora Chu, a Shanghai-based journalist and the author of the 2017 book Little Soldiers, about the Chinese educational system, has noticed is widespread among students in China seeking to get into a U.S. college. “There’s a growing perception that there are more losers than winners in this new world”—that admissions is “a zero-sum game,” Chu said in an email. “This perception of scarcity drives behavior.”

In some cases, students resort to duplicitous tactics. Some cases are extreme—hiring a ringer to take the SAT in a student’s place, for example—but for the most part they involve exaggeration or omission, often influenced by advice gleaned from forums, application consultants, and books promising to help people crack the code of elite-college missions. Steinberg does what she can to discourage this impulse and emphasize the value of the process as a “journey.” One student she has worked with, for example, tried to write a personal essay about Cinco de Mayo after discovering that a distant relative had hailed from Mexico, perhaps thinking that any connection to a marginalized identity would give him a leg up in admissions. She immediately told him that wasn’t a good idea—the holiday, for starters, is largely an American celebration.

But it’s seen as common knowledge among many Asian American students and the application consultants who cater to them that emphasizing their racial and cultural identity could hurt their prospects. Some suspect that stereotypes of Asian Americans as the overachieving “model minority” lead admissions officers to stigmatize them as boring or unoriginal, or as students preoccupied with quantifiable outcomes who lack the coveted X-factor the sought-after schools are seeking to finesse a perfectly balanced freshman class.

Liana Wang, a Yale student from Houston whose parents are working-class immigrants from China, remembers how she and her friends had assimilated the message, so ubiquitous that its source is hard to ascertain, that they needed to avoid “becoming the media-caricature ‘nerd’ type,” to be “more gregarious, more extroverted,” Wang says. She and her Asian American peers assumed that “if you’re interning in the medical center or doing research … you shouldn’t do that because people will just see you being just another stereotypical Asian.” These days, Wang, a junior majoring in economics and global affairs, has her sights on getting a Ph.D. in economics. In high school, she shunned STEM-focused extracurriculars and tried to convince herself that she wasn’t especially good at those subjects. After taking some math courses in preparation for that degree, she was surprised to discover that they weren’t that difficult, that perhaps she was good at math. “Maybe I could’ve pursued something that was more quantitative-focused, but I just didn’t think about it because I thought, Oh, I just don’t want to be that stereotypical Asian,” she says.

While Wang ultimately came to realize that such denial was counterproductive, to embrace interests and strengths that confirm stereotypes about people of her race. Yet many other Asian American students likely encounter constant signaling—including after they arrive on campus—that they’ll be better off if they downplay their racial identity. This underscores how the lawsuit against Harvard is a symptom of the larger problem with elite-college admissions. The stakes attached to the process have become so unwieldy, and are clashing to such an intense degree, that many Americans find it conceivable that it is enabling widespread racial discrimination.

Most methods of admissions subterfuge rely on money, savvy, or some combination of both. In some ways, holistic admissions privilege the already-privileged—who, data suggest, are already far more likely to use test-prep services and attend schools that inflate grades. And many of those already-privileged people get an extra boost from the people reviewing their applications. Take, for example, the fact that most top colleges give preference to applicants whose relatives are alumni: At Harvard, for example, at least 12 percent of first-year students—a majority of them white—fall in that “legacy” category. Then there are those who are recruited for their athletic talents, most of whom come from white, middle-class families, research suggests. In her new book, Race on Campus: Debunking Myths With Data, Julie J. Park, an education professor at the University of Maryland, concludes that as many as 40 percent of Harvard’s white students are legacies or recruited athletes.

As a high-school senior, Jalen is in the 11th hour of his well-planned-out bid to gain admission to Yale, the University of Chicago, or UPenn, but he doesn’t seem overly stressed. At 17, he’s already spent years preparing for this moment both inside the classrooms of an elite boarding school in Ontario and outside them. His extracurricular resume, for example, includes but isn’t limited to piano, basketball, badminton; his school chapter of DECA, an international entrepreneurship competition for teens; and volunteer work as a photographer and marketing consultant at the Toronto Military Family Resource Center.

But Jalen, whom I am identifying by his first name only to protect his privacy as a minor, frequently catches himself wondering whether that’s enough. “When you’re competing against every applicant … it’s hard not to just want more and more and more and more,” he says, noting that it can be hard for prolific high-schoolers like himself to figure out what’s motivating them to do a certain activity. “Sometimes I notice I’m thinking a lot about what I can do to make [whatever I’m doing] grander. It’s like I can’t ever be satisfied.”

The Swarthmore College psychologist Barry Schwartz has long argued that the abundance of choices in the U.S., whether of higher-education institutions or of salad dressings, is making Americans miserable. Abundant choice, he argues, compels those doing the choosing to set unreasonably high expectations for themselves. This, he suggests, plays out in especially acute ways in college admissions.

For example, a 2013 paper published in the journal Development and Psychopathology suggested that the unprecedented numbers of students seeking help at college-campus counseling centers for substance abuse, depression, anxiety, eating disorders, and non-suicidal self-injury might be suffering in part from the “built-up stresses from the 18 years of trying to achieve admission to top-tier colleges.”

Are elite colleges, as the Chronicle’s Hoover suggested, “victims of their own popularity”? These sought-after institutions have certainly played a role in creating the current system’s twisted incentives, but they’re somewhat hamstrung in their ability to change things. How do you stop Americans from associating, to borrow the words of the Harvard law professor and affirmative-action scholar Lani Guinier, “selectivity with excellence”? Universities—both elite and open-access, private and public—are heavily reliant on students’ tuition money and research-grant funding, and are thus forced to compete with one another to stay on top. And even if they wanted to band together in an effort to fix the admissions system, those fixes would likely be prohibited by federal antitrust law, as The Atlantic’s Jeff Selingo has reported; many of the proposed solutions would require colleges to share information about applicants with one another and thus cooperate, violating laws pertaining to corporate competition. As one college-admissions expert concluded in a 2012 interview with Inside Higher Ed, students and colleges just keep “chasing each other around a round table.”

If you’re looking for culprits, there are plenty of other targets on whom it’s tempting to pin blame—college-application coaches who help package students into perfect candidates, sometimes at the expense of their true selves, or high-school counselors who keep aiming their students at the same famous elite colleges without considering other options. But are they perpetuating the problem or simply delivering what the system demands? Steinberg says she regularly feels a psychological tension between the fact that she profits off the cultural fixation on elite colleges but also recognizes its consequences.

“What we universally have created is a dysfunctional system that is demanding something that most 17-year-olds aren’t developmentally quite ready to [give],” she says—a definitive, nuanced answer to the question of who they are and how they fit into the world.

Some elite colleges have taken small steps to combat their own elitism. Harvard, for example, a few years ago launched an online-education portal allowing any member of the public to access and take its courses. And Jill Dolan, Princeton University’s dean of the college, says that the school’s admissions officers consistently stress, on campus tours and at events for prospective students, that the Ivy League institution isn’t for everyone and that a lesser-known school is often a much better fit for many candidates. Many top colleges are also members of the Coalition for Access, Affordability, and Success, which has developed an alternative universal application that’s designed to encourage kids to think more deeply about the process. Some, most notably Yale, have recently increased the sizes of their freshman classes; Princeton has major plans to expand its undergraduate body, too.

But college admissions won’t be fixed by these tweaks alone. And perhaps the lawsuit against Harvard, whatever its merits, could help start to dispel the illusion that whether one gets into an elite college or not is any reflection of a student's worth or future prospects. In a recent survey of admissions directors by Inside Higher Ed and Gallup, half of respondents said that the Harvard lawsuit “has created significant distrust among Asian American applicants and their families” in the admissions process. Perhaps it’s raising awareness about the flaws in the system forcing conversations that could serve as an important first step in effecting change.

In the meantime, the students who do win the elite-college admission lottery often find themselves stuck on the hamster wheel of achievement. Though they may be better positioned for success than their peers at other colleges, they also find that the stress and competition they endured to get accepted doesn’t end once they’re on campus. “At Yale, everyone is competing against these standards that they set for themselves, and ... that is something I wish just didn’t exist,” says Wang, the aspiring economist. “But I don’t know how I could’ve approached [the admissions process] better in high school. It’s kind of like a Tragedy of the Commons: If everybody is competitive, you have to be, too.”

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

At least 2,000 children have now been forcibly separated from their parents by the United States government. Their stories are wrenching. Antar Davidson, a former youth-care worker at an Arizona shelter, described to the Los Angeles Times children “huddled together, tears streaming down their faces,” because they believed that their parents were dead. Natalia Cornelio, an attorney with the Texas Human Rights Project, told CNN about a Honduran mother whose child had been ripped away from her while she was breastfeeding. “Inside an old warehouse in South Texas, hundreds of children wait in a series of cages created by metal fencing,” the Associated Press reported. “One cage had 20 children inside.”

About 65 million years ago, shortly after the time of the dinosaurs, a new critter popped up on the evolutionary scene. This “scampering animal,” as researchers described it, was likely small, ate bugs, and had a furry tail. It looked, according to artistic renderings, like an especially aggressive New York City rat. And it had a placenta, an organ that grows deep into the maternal body in order to nourish the fetus during pregnancy.

The rodentlike thing would become the common ancestor of the world’s placental mammals, with descendants that include whales, bats, dogs, and humans, among many other species. And today, the placenta might hold the key to one of the most enduring mysteries in human medicine: Why do women suffer much higher rates of autoimmune disease than men do?

Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.

There’s a moment about 15 minutes into the first episode of Years and Years that made me gasp at its audacity, its prescience, its visual horror. The new six-part series from the British writer Russell T. Davies (Doctor Who, A Very English Scandal) charts the life of the Lyons family over the course of 15 years, starting in 2019 and ending in 2034. It’s a kitchen-sink saga that barrels its way through births and marriages and betrayals, but also through the near-future. In 2024, Stephen Lyons (played by Rory Kinnear), a financial adviser, is at home with his wife, Celeste (T’nia Miller), both rushing their way through the morning routine. When the camera turns to their teenage daughter Bethany (Lydia West), her face isn’t recognizably human. Instead, she looks like a 3-D version of a Snapchat puppy, with vast cartoon eyes, wagging pink ears, and a brown snout. When she talks, her voice is grotesquely distorted, a robotic hallucination of a child’s cadence. “I might have to start limiting filter time,” Celeste says in the same exasperated, noncommittal way that you might think, I really should spend less time on Twitter.



At the very first Harvard College commencement ceremony, nearly 400 years ago, markers of exclusivity were front and center. The graduating class consisted of just nine students: no women, no people of color; only, in the words of a Boston historian, “young men of good hope.” The order in which they received their degrees was determined “not according to age, or scholarship, or the alpheber [sic], but according to the rank their families held in society.”

The freshman class admitted to Harvard University last spring was much less homogenous. According to a survey conducted by the student newspaper The Harvard Crimson, more than half of the accepted students were nonwhite; more than half were women; more than half would receive financial aid once enrolled. But vestiges of the same exclusivity remained. Legacy applicants, predominantly white and wealthy, were admitted at five times the rate of non-legacies. And white students with annual family earnings exceeding $250,000, legacy or not, constituted more than 15 percent of the admitted class—despite coming from an income bracket representing less than 5 percent of Americans of any race.

Those students have always enjoyed disproportionate access to elite colleges in the U.S. They were meant to. The parents charged in the college-admissions scandal this month risked criminal prosecution in order to gain an unfair advantage in a system that was built to offer them unfair advantages already. Even as selective institutions began, in the early 20th century, to admit a more diverse array of applicants, they adopted new policies in order to protect white, upper-class students from being entirely displaced. Neither affirmative action nor the diversity drive of recent years has eliminated those protections.

In the schools’ earliest decades, wealthy white students weren’t just privileged in admissions; they were essentially the only ones considered. Up until the end of the 19th century, campuses were generally populated by graduates of private high schools who performed well in school-specific criteria and on entrance exams. When it was first founded, Harvard based its admissions decisions on subjective judgments of students’ character and family background as well as their demonstrated proficiency in Latin and Greek.

By 1892, academic expectations had ballooned; in an Atlantic article written that spring, James Jay Greenough wrote that Harvard hopefuls were tested on “an elementary working knowledge of Latin and Greek … French and German … English classical literature … algebra and plane geometry … the laws and phenomena of physics … descriptive physics and elementary astronomy … and, last … the history and geography either of ancient Greece and Rome or modern England and America”—as well as an ability to write and speak intelligently about those subjects. These criteria largely shut out those who couldn’t afford to attend prestigious preparatory schools, and wealthy white Christian men continued to dominate student bodies.

But some lower-income students did attend Harvard, even in its earliest days. In his 1933 Atlantic article “College and the Poor Boy,” Russell T. Sharpe detailed how Harvard administrators had found a way “to solve the financial problems of needy students as early as 1653, when [they] gave Zachary Bridgen a job ‘ringeing the bell and waytinge’ on table. Through the succeeding years, more or less informal and unorganized assistance was rendered.” Harvard’s first endowed scholarship was funded in 1643, and similar charitable funds provided the majority of financial aid for decades. Then, in 1838, the school established a private student lending agency and began offering zero-interest loans to support “young men of ability … when their families are not able to help them.” The idea of providing students scholarship and loan money quickly spread to other selective colleges.

In the early 1900s, lower-income students and the efforts to accommodate their needs became still more ingrained in the structure of those schools. Opening their doors to public-school students and standardizing their admissions criteria for the first time, elite colleges met with a flood of newcomers who didn’t fit the mold created by centuries of largely unvaried graduating classes. The number of Jewish students on campuses soared; by the early 1920s, they made up 21 percent of Harvard’s student body, and nearly 40 percent of Columbia’s. Freshmen with Irish, German, and eastern-European backgrounds streamed in, as did students from western and midwestern states or from lower-class families.

“President [A. Lawrence] Lowell, in 1909, pointed out to his alumni that Harvard was to a large extent a poor man’s college, that there was a good deal of suffering and want, that many students were insufficiently clothed and not a small number insufficiently fed,” Sharpe wrote. “To help these men the colleges built up huge scholarship and loan funds and organized employment bureaus to find work for students.”

Lowell proved much less willing to accommodate Harvard’s increasing racial, ethnic, and religious diversity. He instead worked to codify his own bigotry into school policy, banning black students from freshman dormitories and dining halls and proposing a quota system to impede the rapid increase of Jewish students. “The summer hotel that is ruined by admitting Jews meets its fate, not because the Jews it admits are of bad character, but because they drive away the Gentiles, and then after the Gentiles have left, they leave also,” he wrote to a philosophy professor in 1922. Limiting the number of Jewish students, he believed, was essential to the school’s survival.

But the Harvard Board of Overseers didn’t institute the quota system Lowell wanted. It instead adopted an application system that prioritized subjective qualities—birthplace, family background, athletic ability, personality—over test scores. Publicly, the board represented these changes as a boon for inclusivity. The original report proposing the new system characterized it as a “policy of equal opportunity regardless of race and religion.” But privately, Lowell’s sentiments were shared by many in the Harvard community, and the new policies allowed the administration to justify exclusion.

Administrators at Harvard, Yale, and Princeton “realized that if a definition of merit based on academic prowess was leading to the wrong kind of student, the solution was to change the definition of merit,” Malcolm Gladwell wrote in a 2005 New Yorker article. And so the modern college-admissions system was born.

By design, the system favored the same kind of wealthy white students who almost exclusively populated elite colleges for hundreds of years; they benefited from legacy status, athletic recruiting, family donations, and many other advantages. The same policies that enabled the exclusion of applicants based on race and religion also cast low-income students back into disfavor. They were less likely to be able to secure personal recommendations from administrators at “approved schools”—high schools that were prestigious, exclusive, and expensive. Their parents were less likely to hold degrees from selective colleges, or any colleges. And tuition fees and living costs presented their own particular obstacles.

“Of late … the colleges have restricted admission, thus making the acquirement of the higher education difficult,” Sharpe wrote in 1933. “Now there are signs that another barrier may be erected. Last June, Yale announced that it would henceforth admit only as many financially needy students as could be cared for through existing channels of aid. Other colleges have since … declared that they may follow suit.”

He described how, as the number of students on campuses rose in the 1920s and ’30s and the Great Depression set in, campus employment opportunities dwindled and schools struggled to provide sufficient support. Federally funded financial aid arose to fill that void as World War II drew to a close, and the G.I. Bill enabled millions of veterans to attend and pay for college. But the loan system grew and mutated and spawned a new crisis for low-income students, many of whom now face the choice between turning down offers to attend prestigious schools and taking on backbreaking debt.

“For a generation or more,” Sharpe wrote, “it has been a part of the democratic creed of many Americans that every mother’s son is born with an inalienable right to a Bachelor’s degree, regardless of his ability to pay for it.”

But that creed never wholly extended to nonwhite, non-Christian sons and daughters, and the ability to pay still matters. For centuries, family money has benefited applicants in admissions considerations; provided access to prestigious preparatory schools; paid for tutors, trainers, and extracurricular activities; enabled hefty donations; and funded tuition. And if those advantages aren’t enough, then family money can evidently, according to federal prosecutors, be used to cheat on standardized tests and bribe athletic recruiters, too.



It’s hard to snatch attention from the jaws of intrigue, and Varsity Blues had it all. There were fake SAT scores, a shady deal maker, and wealthy parents eager to lay waste to anything standing in front of their children on the road to a selective college—the vaunted status symbols that they are. This exposes the gritty underbelly of the race to get into America’s colleges, a common refrain went.

As my colleague Alia Wong noted shortly after the scandal broke, these sorts of high-stakes admissions antics represent only a fraction of college admissions—a small one at that—because most colleges aren’t that selective. More than 80 percent of students attending bachelors-degree-granting colleges go to those that accept more than half of their applicants, according to an Atlantic analysis. These not-so-selective schools are the big picture of higher education, the forest so many miss while examining in microscopic detail the bark and leaves of a few “top-tier” trees.

A pair of new reports show how even looking at that bigger forest still misses the wider world that it grows on and that shapes it. On Wednesday, the National Center for Education Statistics released new data showing a 50-percentage-point gap—that’s right, 50 percentage points—in college-going rates between students who come from the highest-earning families and the lowest earning. Of students who entered ninth grade in 2009, 78 percent of those from the wealthiest 20 percent of families were enrolled in college seven years later (in 2016), whereas just 28 percent of students from the lowest quintile were.

The numbers, although not necessarily shocking to those paying close attention to higher education, are jarring. Going to college—and staying there—are rites of passage for only certain slices of the American public.

That said, over time, the trajectory for higher education is that it is becoming more inclusive, and more lower-income students are attending than in the past. The Pew Research Center released a new analysis on Wednesday showing that the number of low-income students has increased “dramatically” over the two decades from 1996 to 2016, and now makes up nearly a third of the overall student population. The bulk of the growth occurred at two-year colleges and private for-profit institutions, but there was also significant growth at less selective bachelors-degree-granting colleges. Similarly, the share of racial minorities increased across all sectors of higher education, but, again, the increases were most prominent at less selective bachelors-degree-granting institutions and two-year colleges. This is due, in no small part, to efforts from universities—especially regional, open-access institutions—to recruit low-income and minority students. The highly selective institutions continue to draw the majority of their students from middle- and high-income families, the report said.

But the fact that regional, open-access schools are making strides with low-income and minority students comes with a catch: During this same time period, state funding of higher education has declined significantly. “Overall state funding for public two- and four-year colleges in the school year ending in 2018 was more than $7 billion below its 2008 level,” a report from the Center on Budget and Policy Priorities reads. On top of that, the purchasing power of the Pell Grant, a federal grant for low-income students, has dipped as well. So as higher-education opportunities and outreach to poor students have increased, the resources available to them on campus—both in terms of the opportunities they have and the support they can access—have dwindled.

Still, even taking account of the gains described in Pew’s report, the overall picture is bleak for low-income students, the vast majority of whom will never go to—much less graduate from—college. Varsity Blues was easy to see and pick apart from the canopy. But for most Americans, what matters is the wider forest—and whether they can get there at all.



Student debt is a crisis, for students and for graduates living with debt. There’s near-universal bipartisan agreement that reform is desperately needed, but almost as much disagreement about what, exactly, to do about it. On Monday, Senator Elizabeth Warren, one of the Democratic hopefuls vying for the White House in 2020, released a comprehensive college-affordability plan that she believes could fix a fundamentally flawed system of paying for college.

In a Medium post, Warren criticized the government’s hands-off approach as affordable access to America’s universities declined. “Rather than stepping in to hold states accountable, or to pick up more of the tab and keep costs reasonable, the federal government went with a third option: pushing families that can’t afford to pay the outrageous costs of higher education towards taking out loans,” she wrote in the post. To remedy this, she is calling for a series of ambitious proposals, including the cancellation of student debt, universal free public college, and greater support for minority and low-income students. Of course, Warren is not the first politician to call for any of these policies specifically, but the details of her plan separate her reform package from the pack; she plans to pay for it with her “ultra-millionaire tax”—an annual 2 percent tax on families with $50 million or more in wealth. Critics of a wealth tax argue that it would be difficult to implement—accounting for assets such as antiques or land poses considerable difficulties—and that it would lead to more aggressive tax avoidance.

Warren’s plan would cancel student debt up to $50,000 for borrowers who make less than $100,000 a year. For every $3 a borrower earns yearly over that $100,000, the amount of debt forgiven would decline by $1 . “So, for example, a person with a household income of $130,000 gets $40,000 in cancellation, while a person with household income of $160,000 gets $30,000 in cancellation,” she wrote. Those who earn more than $250,000 a year would not be eligible for any debt cancellation, and the cancellation for borrowers who do receive it would not be treated as taxable income.

Lindsey Burke, the director of the Center for Education Policy at the Heritage Foundation, a conservative think tank, worries about the effects of a debt-cancellation policy on tuition. “Universities will continue to do what they’ve been able to do for decades, and that’s increase tuition, because they [will] know there are policies like debt-cancellation and loan forgiveness,” she says. “They enable universities to be as profligate as they always have been.”

What about those borrowers who have already paid off their loans? Warren’s plan, like other debt-cancellation plans that have been floated in recent years, is targeted to help those who need it most, and that’s a good start to addressing the debt that borrowers have already amassed, Tiffany Jones, the director of higher-education policy at the Education Trust, a nonprofit focused on education equity, told me. One potential weak point, however, is that the proposal focuses on income rather than wealth. When the racial-wealth gap is accounted for, targeting would need to be more specific than in Warren’s proposed policy in order to help those who truly need debt cancellation the most. That’s why, she added, it is heartening to see this proposal coupled with one that targets aid to historically black colleges and other minority-serving institutions.

Research has shown that student debt has devastating effects on black students in particular, and Democratic candidates have discussed that outsize debt burden as they’ve focused on historically black colleges and universities this election cycle in the hope of ginning up support among black voters. But Warren’s plan offers one thing that has yet to be promised to the black colleges in a significant way: money.

“For decades, Black Americans were kept out of higher education by virtue of overtly discriminatory policies,” Warren wrote. “Even as the civil rights movement rolled back racially discriminatory admissions policies, the stratification of our higher education system kept students of color concentrated in under-resourced institutions and left them vulnerable to predatory actors.” She hopes to create a fund of at least $50 billion to help HBCUs, which have historically been underfunded, as well as other minority-serving institutions—such as Hispanic-serving institutions and tribal colleges—spend as much money on each of their students as predominantly white institutions do.

The glue that holds Warren’s plan together for the future, however, is her universal debt-free-college proposal. It has been a part of her higher-education platform for the past several years, and as I wrote in February, a free-college proposal—or an explanation for why they do not have one—is practically an entry fee for the 2020 election for Democratic candidates. Warren proposes that the federal government commit to investing in higher education at a level that, coupled with state spending, would make public two- and four-year colleges tuition-free. She would also expand the Pell Grant program to address additional living expenses associated with college.

Randi Weingarten, the president of the American Federation of Teachers, said Warren’s package of proposals would be “as consequential as the GI Bill,” and more equitably distributed. But it will be difficult to gin up the type of support necessary for this legislation to pass without the House, Senate, and White House all being in Democratic control. Even then, there may be disagreements about exactly how the proposal is targeted. Though a lot would have to happen in order for these policies to ever take effect, Warren is, so far, setting the bar for the most radical reimagining of higher education among the Democrats in the 2020 race.



Updated July 30, 2018

This week, advocates for student-loan borrowers have seen some of their worst fears come true. More than a year after Education Secretary Betsy DeVos announced that the U.S. Department of Education would begin to unwind two Obama-era regulations aimed at holding for-profit colleges accountable, the department has started to make good on that promise. One of the regulations is being scaled back significantly; the other is reportedly going to be eliminated altogether.

When the Education Department announced, in June 2017, that it would begin the process of rewriting the rules, borrower advocates saw it as evidence of a coziness with the for-profit sector. Several staffers who had relationships with for-profits were forced to recuse themselves from working on regulations such as these. But now it has come to light that in the early days of Donald Trump’s education department at least one official was communicating with his contacts in the for-profit industry while also eagerly seeking to discuss the two rules now being rolled back.

The two regulations are known as the “borrower defense” and “gainful employment” rules. Borrower defense provided students a streamlined path to debt relief if they were defrauded by their college; the 2016 rule was rolled back before it even took effect. The gainful-employment rule sought to cut off federal loans to schools if their students did not make enough money after graduation to pay them off. Both regulations were an attempt by the Education Department under President Barack Obama to protect students from fly-by-night colleges in the for-profit sector.

The department announced on Wednesday its proposal to significantly dial back the borrower-defense rule, raising the bar that students have to meet to receive debt relief. “The regulations proposed,” DeVos said in a news release, lay out “clear rules of the road for higher education institutions to follow and [hold] institutions, rather than hardworking taxpayers, accountable for making whole those students who were harmed by an institution’s deceptive practices.”

Borrower advocates weren’t sold on the change. And their fears were once again piqued on Thursday night when The New York Times and The Wall Street Journal reported that, instead of rewriting the gainful-employment rule, the Education Department planned to eliminate it altogether.

“These are two of the highest-priority rules for the advocates, and their nightmare would have been that borrower defense becomes entirely unusable and gainful employment no longer exists,” Clare McCann, a policy analyst at New America, told me. “And that seems like where we are headed right now.”

But the news wasn’t exactly a surprise. Higher-education observers assumed that the department would be taking a fresh look at the Obama-era regulations, which for-profit colleges have called overly burdensome, and which they have fought to eliminate. Changing these rules was one of the first agenda items for some officials in the Trump administration.

Taylor Hansen was one of those officials interested in rolling back the regulations.  He was a member of the “beachhead” team—paid temporary appointees who help get the government up and running and who do not require Senate confirmation—at the department at the beginning of the Trump administration. According to emails obtained through a Freedom of Information Act request by the left-leaning think tank The Century Foundation and shared with me, Hansen, who formerly worked as a lobbyist for the largest trade group representing for-profit colleges, Career Education Colleges and Universities (CECU), set to work immediately. He scheduled meetings to discuss the regulations with top officials in the department. (Hansen, who resigned in March 2017, did not immediately respond to a request for comment.)

“Since gainful employment is a hot button item it may be good to discuss that as one of the items—if possible,” he told Colleen McGinnis, the chief of staff at the Federal Student Aid office, in one email on February 14, 2017, seven days after DeVos’s confirmation. A day later Hansen told Michael Dakduk, a senior official at CECU, that he would pass along a letter from the CECU president and CEO, Steve Gunderson, requesting a meeting with the new secretary.

In an email, Gunderson confirmed that CECU reached out to people at the department, but insisted that all of their interactions were "aboveboard, transparent, and in line with all ethical requirements." He added that the organization has not met with Secretary DeVos.

One week later, in an email to a staff member at the Federal Student Aid office, Hansen again asked to discuss gainful employment, as well as borrower defense. Other items, he said, could be discussed if there was time, but these were his primary focus.

Hansen was later told by the ethics office at the department that he was not to work on projects involving his former employer or the gainful-employment rule. He told ProPublica, shortly after his resignation, that he had not been working on the gainful-employment regulation.

Elizabeth Hill, a spokeswoman for the Education Department, told me in a statement that the department, “under the leadership of Secretary DeVos, takes seriously its commitment to all ethics rules and guidelines. Mr. Hansen was a member of the beachhead team and left the department more than a year ago.” She added that Hansen was not involved in “developing the substance of the gainful employment rule which has yet to be finalized and published.”

Still, advocates worry that this was not an isolated incident, but a trend. In one email exchange, Hansen tells CECU that he, along with Robert Eitel, a senior counselor to DeVos who has also been questioned by Democratic lawmakers and advocates about potential conflicts of interest from his time at a for-profit college operator, and James Manning, a senior department official, would be “happy to meet” with the leadership.

“There has been a clear shift” in the priorities of the Education Department, Tariq Habash, a policy analyst at The Century Foundation, told me. “There’s no question that there have been ties to the industry directly,” he continued, citing Hansen and Eitel, “and that really raises red flags about who these individuals are really working for.”

Here are the emails:







The first speech that Oliver, a West Coast fraternity-chapter president whose story I closely followed for a year, gave his new pledges was not the lecture one might expect from a fraternity brother. “We’ve worked really hard to build a reputation as a house of nice guys. If you endanger that reputation, you’ll immediately be kicked to the curb,” Oliver told the pledges. “That’s not the kind of people we want. We’re not the douchey frat house. We’re not here to ‘get bitches and get fucked up.’ We’re here to learn how to grow up a little bit. And with that comes learning how to be a nice human being; how to look out for each other, for guests, and for girls; and how to properly treat girls. If you’re consistently nice and respectful, you’re going to build a good reputation, and that’s going to help you a lot in life.”

As I learned in more than two years of reporting for my book, Fraternity, about fraternities and masculinity on campus, Oliver’s attitude is much more common than the dominant narratives about college men suggest. (I used a pseudonym for Oliver so that people in his story are not easily identifiable; similarly, other sources in this article are not identified because they appear anonymously in the book.) Too often, when the public hears about boys in college, the context is negative: sexual-assault cases, for example, or boys’ dreary academic performance compared with girls’. Media coverage about college guys tends to lament the problems they cause rather than explore the challenges they face. The message that doesn’t come across often enough is that the same forces that have led to what has been called  “toxic masculinity” on campuses do more than oppress girls; they can suffocate boys, too. And, surprisingly, the college organizations that might be best positioned to battle this culture are the ones that publicly take the most heat for representing it.

For boys who attend college, the experience is usually when they begin to determine their identity away from their family and the anchors they’ve known since childhood. Experts say that the college years, when they are expected to somehow independently transition from boyhood to manhood, are also the stage at which they feel the most vulnerable. Researchers have described boys’ freshman year as characterized by separation anxiety, loss, and grief. At the same time, these boys frequently think that they can’t express those feelings, because they are strongly pressured to fit into what academics call “traditional masculinity.”

What does it mean to be masculine in the 21st century? Masculinity can, of course, take multiple forms, but psychologists say that men are commonly expected to suppress emotions, desire multiple sexual partners and casual relationships, engage in risky behaviors and physical aggression, want to dominate situations, assert independence, and have control over women.

Just because these are the prevailing masculine characteristics doesn’t mean that the majority of men want to follow them, however. Surveys have found that most college guys don’t endorse traditional masculine norms, but believe that most other men do. More specifically, college men overestimate their peers’ use of alcohol and other drugs, amount of sexual activity, desire to hook up, willingness to use force to have sex, acceptance of homophobia, and tolerance of behavior that degrades women. They don’t necessarily know what their peers truly believe, possibly because they think that having intimate conversations about those things would be unmasculine.

At many colleges across the country, fraternity brothers told me that, in general, the guys who are considered most masculine are the ones who hook up the most—and, especially among underclassmen, the ones who drink. To be considered masculine at one Florida college, “you gotta be fit, very social, good-looking, love to party, be able to talk to girls, play the field well, hook up,” a sophomore fraternity brother told me. “And on my campus, everyone loves to be involved, so also having high-up positions or a good job.” At an Oregon school, a junior said, “a zero-cares attitude makes you more masculine.”

Several studies have found that men who adhere to traditional expressions of masculinity (such as the aforementioned) have comparatively worse mental and physical health and increased chances of illness, injury, and death. College students who follow this path are more likely to drink more, become depressed, and commit sexual assault. And it’s common for men to become emotionally isolated because they worry that showing vulnerability isn’t manly.

But researchers have found that the traditional idea that men are innately tough, independent, and stoic is not true. Actually, in infancy, boys are more emotional than girls. As children grow up, however, while girls are permitted to express their feelings, boys are taught to suppress them. “But this doesn’t mean men aren’t experiencing the same feelings,” the neuroscientist Lise Eliot wrote in Pink Brain Blue Brain. “In laboratory studies, men respond even more intensely than women to strong emotional stimuli.”

Now consider the predicament of a new college student, an 18-year-old boy who is expected to become a man, with these masculine norms discouraging him from expressing his emotions or seeking intimacy—important tools for forming meaningful connections—at precisely the time when he is most vulnerable and alone. At precisely the time when he most yearns to make friends.

That’s where some healthy fraternities can be helpful. They specifically promote their friendships as “brotherhoods,” seeming to promise the kind of supportive relationships that could alleviate a freshman’s separation anxiety, loss, and grief.

Fraternity brothers told me that because the point of fraternities is to form close friendships, they bonded more quickly than they otherwise would have. “Guys are more expected to hold emotions back and [have] everything in control. Classes and organizations only get you so far in terms of having personal connections. So for guys, it’s much more difficult to meet a lifelong friend,” the Florida brother said. “There’s always the fear of not being accepted anywhere. It’d be very tough to open up to people if you didn’t already have a fraternity as a catalyst for your emotions.”

Then how do we explain the disturbing fraternity behavior in headlines? We could call it the result of a clash between nature and culture.

Non-Western cultures don’t necessarily have the same prejudice against male intimacy. It’s acceptable in many countries for male friends to hold hands or shed tears, the NYU psychology professor Niobe Way says. But in the U.S. (and other countries influenced by Western culture), boys’ emotional skills and intimate same-sex friendships are often ignored or insulted. It’s possible, then, that fraternities are such a distinctly American phenomenon because other cultures don’t stigmatize men who seek these relationships.

Fraternity culture changed significantly in the first half of the 20th century, when the term homosexuality entered popular usage. Because fraternity brothers lived, ate, and slept together in close quarters, outsiders began speculating that fraternities were dens of homosexuality. To prove that they weren’t gay (though some were), members loudly boasted about their dating lives and heterosexual conquests. Some fraternities still struggle to reconcile male intimacy with society’s pressure to perform heterosexuality, per traditional masculine standards. Rituals and living conditions encourage guys to bare their souls. Some chapters participate in activities that brothers might worry could be perceived as having gay overtones. Members might discuss the physical attractiveness of male recruits, for example, or in a small minority of chapters, participate in nude or seminude all-male rituals, as did the chapter of another brother I spoke with. (“Showing private parts is probably the most expressive way of proclaiming, ‘You’re in our brotherhood now! No more walls or secrets between us!’” he told me.) And recruits and pledges want fraternity members to desire them as brothers. A recent ASHE Higher Education Report noted, “This is a challenging concept for men to express when most language they know at their age about desire depicts a romantic or sexual connection, rather than an emotionally vulnerable relationship.”

That might be one reason some fraternity brothers overcompensate, resorting to stereotypically hypermasculine behaviors to try to prove their manhood and gain acceptance. Or why some pledges are willing to, for example, drink life-threatening amounts of alcohol. “There’s a lot of fear when you feel like a little boy being yelled at by all the big kids. You don’t feel like a man,” a recent Massachusetts grad said. Some of his pledge brothers created a challenge they called “Team Savage”: They voluntarily drank a Solo cup of their own urine (talk about toxic masculinity). “It’s disgusting, but it made them seem tough, and they gained status.”

This is not to defend the fraternities that haze or engage in other dangerous behavior. But understanding how students might get to the point where they want to participate in such things is a step toward changing that culture. Oliver’s chapter was relatively healthy partly because it didn’t emphasize masculine stereotypes, but kindness and respect. It’s probably not coincidental that this chapter had fewer alcohol and sexual-assault issues—and was more vigilant about preventing and addressing them—than a typical fraternity.

Many chapters like this exist; people simply don’t hear about them, because they aren’t embroiled in scandals and focus more on their members’ inner qualities than their chapter’s external image. Chapters like these have the power to free men from the constraints of society’s narrow definition of masculinity. A recent Rhode Island grad entered college with “the view [that] I gotta go in and drink well, get a lot of girls, never show emotion, always tell everyone classes are going great, I’m not having any issues. I was trying to make it look like I could fit in and have a great time, even though I wasn’t sure of myself. But I wasn’t finding the traditional hookup scene and what I’d seen in the movies.”

Second semester, he joined a fraternity in search of that stereotypical environment. To his surprise, the fraternity’s alternative views on masculinity made him reconsider prioritizing toughness and hookups. “Yeah, it had partying and the social aspects, but it also had the idea that you can do all that stuff without having to put on a show. You can be yourself entirely in front of these people. I didn’t think you’d find a fraternity who wanted to talk about toxic masculinity and sex assault. That was eye-opening. It changed me,” he said. “I wasn’t a douchebag at heart; [I was] just thinking [that acting stereotypically masculine] was how you become successful in college. When I saw these leaders in my fraternity having success without being those guys, I realized, Wow, I don’t have to do that if I don’t want to.”

This article is adapted from Alexandra Robbins’s new book, Fraternity: An Inside Look at a Year of College Boys Becoming Men.



It had not yet been two decades since the revolution when George Washington stood before Congress on January 8, 1790, to deliver what was, effectively, the inaugural State of the Union address in the provisional U.S. capital of New York City. “Knowledge is in every country the surest basis of public happiness,” Washington told those gathered. He believed that people—at the time, white men—should be taught to know and value what it means to be an American citizen.

Perhaps this civic education, Washington suggested, could be promoted through the schools that had already been established: Harvard, the College of William and Mary, Yale University, and so on. But maybe the answer was to create something new: a national university. He implored Congress to deliberate.

By the time Washington delivered the address, the concept of a national university was already popular: Several of the fledgling country’s top leaders had argued for it. Benjamin Rush, a signer of the Declaration of Independence and one of the idea’s earliest proponents, thought a national university could “convert men into republican machines.” The founders were grappling with how to craft a unified national identity as states were entrenched in their own views and customs. As Nathan Sorber, a professor at West Virginia University, told me, an ideal path forward, they thought, could be to craft an educational institution that brought people together with a “common national mind-set.” Rush even envisioned that a national university could serve as the feeder school for future members of Congress and other federal positions.

The idea of a national university—a legitimate institution of higher education where students are provided with a nonsecular liberal-arts education and taught how to be engaged citizens—has cropped up time and again during U.S. history, often in moments of deep division and social unrest. One of those moments is now. Survey after survey has shown that the political and social rifts in the country are growing—to a point where Democrats and Republicans no longer agree on the basic facts. Couple that rift with the widespread dissatisfaction with higher education—rising college costs and ballooning student debt (nearly $30,000 for the average student, according to a new report from the Institute for College Access and Success)—and the type of environment that breeds arguments for a national university begins to take shape. The question is: Why haven’t they?

The answer may be rooted in what the national university would have looked like and why the calls for a institution fizzled out in the first place. The initial plans for the institution were diverse, but united by the notion that the chief goal of the university would be civic education: teaching young men how to do democracy. But how to achieve that goal varied, says George Thomas, a professor at Claremont McKenna College, whose book The Founders and the Idea of a National University examines the intellectual history of the concept.

Maybe the national university, some early proponents argued, should be a a finishing school of sorts for future leaders, where every state would send its best students to be educated, regardless of family wealth. Or maybe, as Joel Barlow, an early U.S. ambassador to France, suggested, the national university could serve as the flagship of a larger system that would oversee state universities and grammar schools—and would even produce the textbooks used by students. A handful of the plans even included structures for how leadership would be selected: a university president would be appointed by the president of the United States and confirmed by the Senate.

Easily lost in all of this is the idea that a top-down system so closely tied to the federal government could quickly devolve into a propaganda machine if left in the wrong hands. “It can be problematic if politicians and government entities are interfering in academic matters where they don’t have the expertise,” Sorber says. “We want knowledge to be driven by the best ideas, not political calculation.”

The War of 1812 saw a renewed push for a national university—and West Point, which was founded a decade earlier, emerged as the elite training ground for military leaders. Then there was the Civil War, and the three presidents immediately following the war advocated for a national university. In fact, legislation was proposed in Congress, while the National Education Association commissioned a report, led by Harvard President Charles Eliot, to examine the idea. (Eliot suggested there was already a national university in waiting: Harvard.)

But there was something else going on in the background: President Abraham Lincoln, in 1862, signed the Morrill Act, which granted land to each state that could be sold to fund a university. The act, which created the so-called land-grant institutions, such as West Virginia University, Texas A&M University, and Cornell University, remains one of the largest federal grant programs in history and paved the way for what we understand higher education to be today. And direction of the curriculum for these institutions was up to the states—several of which, wary of federal control after the Civil War, wanted no part of a federal university system. The land grants were enough.

The last time a national university was seriously considered was in 1914, right at the beginning of World War I, Thomas told me. But the idea never gained any serious traction. “By the time you hit the 20th century,” Thomas told me, “both state universities and private universities are actually doing much more of the work that defenders of the national-university vision hoped education would do.” While they weren’t perfect by any stretch of the imagination, they were providing a liberal-arts education and creating an educated class that could lead.

So, as decades passed, and national tensions crested and fell, there was little conversation about creating a national university—the existing colleges and universities were already entrenched. Higher education is still searching for answers to questions of access and affordability. The nation is searching for answers on how to create a more engaged, public-minded citizenry. The answer is not likely a national university. But it is not for want of trying.



The president of Georgetown Preparatory School—the elite, all-boys private boarding school from which Brett Kavanaugh, the Supreme Court nominee, graduated in 1983—has a message for students, their families, and alumni: Trust us, our school doesn’t breed sexual miscreants.

“Prep is a wonderful place, a wonderful school, a wonderful community,” Reverend James R. Van Dyke, who became the school’s president two months ago, wrote in the letter, which was sent to the campus community on Thursday, and posted online Friday. “There is no denying that this is a challenging time for a lot of reasons,” he said. “But it is a wonderful place, a wonderful school, a wonderful community.”

“I don’t say this because I have to,” Van Dyke wrote. But the truth is, he kind of did have to. Why exactly it has been a “challenging time” for the school went unspoken in the letter, but it’s obvious. Kavanaugh has been accused of attempting to sexually assault Christine Blasey Ford, a psychologist and professor at Palo Alto University, when the two were in high school. Ford alleges that Kavanaugh, while drunk at a party, cordoned her off in a room, pinned her on a bed, groped her, and put his hand over her mouth to muffle her screams. Mark Judge, a friend of Kavanaugh’s, was also in the room egging him on, Ford alleges. Both Kavanaugh and Judge are Georgetown Prep alumni.

Van Dyke’s letter is the first time the school has spoken publicly about the accusations against Kavanaugh, even though it did not reference them explicitly. Instead, Van Dyke framed the letter as a defense of all of that is good about the institution—the committed faculty, the Christian Service Program, Special Olympics volunteers, student tutors, and so on—while only obliquely referring to what he is defending it from.

The school, he argues, is being caricatured as elitist, privileged, and uncaring. In the wake of the Kavanaugh accusations, alums of such elite private schools have called them “bastions of misogyny,” researchers have argued they reinforce “hypermasculine culture,” and some say they “foster darker impulses.”

Van Dyke agrees that Georgetown Prep is elite—and even privileged—but only in the positive sense of those terms. “That we are elite, we cannot deny; every student who comes here is chosen for his personal potential regardless of financial need,” he wrote. “That we are privileged, we also cannot deny; generations of visionary Prep alumni and friends have helped to build excellent facilities for classes and for athletics and have underwritten our retreat and service and arts programs.” But he drew a line at the assertion that they’re entitled or uncaring.

Georgetown Prep is one of the most expensive private boarding schools in the country, with a price tag of over $60,000 per year for boarding students. Yes, the school has scholarships for low-income students, but it is serving a heaping helping of an elite clientele as well. Members of that elite group often do not face consequences for their actions in the same way less privileged young people do. As Josh Rovner recently put it in The Atlantic, “kids who grow up like Kavanaugh—white kids whose parents can afford prep-school tuition and, presumably, the services of a good lawyer—rarely experience prolonged contact with the criminal-justice system … But most kids don’t grow up like Kavanaugh.”

In an interview with Here and Now, Adam Howard, a professor of education at Colby College, argued that places like Georgetown Prep do, indeed, have a lot of good attributes, but “they also encourage win-at-all-costs attitudes, unhealthy levels of stress, deception, materialism, competition and so forth, selfishness and greed.” Kavanaugh himself described the school’s culture in 2015 as, “What happens at Georgetown Prep, stays at Georgetown Prep.”

Van Dyke acknowledges that the school should be evaluating its culture. “It is a time to continue our ongoing work with the guys on developing a proper sense of self and a healthy understanding of masculinity, in contrast to many of the cultural models and caricatures that they see,” he says. “And it is a time to talk with them honestly and even bluntly about what respect for others, especially respect for women and other marginalized people means in very practical terms—in actions and in words.”

Van Dyke’s letter seeks to reassure the Georgetown Prep community that it will improve without admitting it could have fallen short. The school is positioning itself as so far removed from Kavanaugh’s alleged actions that they don’t even bear mentioning, but it knows it is not removed enough to say nothing. (“I don’t say this because I have to.”) There is a tension here, a sense of wanting to fix the school’s culture of toxic masculinity, but deny it too.

Read Van Dyke’s full letter below:







“I was always gung ho about going to graduate school for some reason,” reflects Everet Rummel, a data analyst at the City University of New York. “That was naive.”

Rummel was indeed gung ho, embarking on a doctoral program in economics immediately after completing both his bachelor’s and master’s degrees in just four years. He was only 22 years old. And Rummel was indeed naive, at least in his own telling of his plans. That plan—which for the average doctoral candidate takes roughly eight years—ended quickly, not because of Rummel’s characteristic efficiency but because he never completed it. “I dropped out,” he explains, attributing the decision to a lot of different factors, many of them not directly related to his studies, but each pointing back to the all-encompassing, unforgiving stress of his Ph.D. program.

One major stressor, he says, was the requirement that all first-year Ph.D. economics students take the same three courses. But other major stressors are likely to resonate with graduate students in all kinds of disciplines. The doctoral-degree experience often consists of intense labor expectations for little pay and a resulting lack of sleep and social life. In addition, there is the notorious hierarchy of academia, which often promotes power struggles and tribalism.

To make matters worse, the payoff for all that stress may be wanting: A 2014 report found that nearly 40 percent of the doctoral students surveyed hadn’t secured a job at the time of graduation. What’s more, roughly 13 percent of Ph.D. recipients graduate with more than $70,000 in education-related debt, though in the humanities the percentage is about twice that. And for those who do secure an academic post, census data suggest that close to a third of part-time university faculty—many of whom are graduate students—live near or below the poverty line.

A new study by a team of Harvard-affiliated researchers highlights one of the consequences of these realities: Graduate students are disproportionately likely to struggle with mental-health issues. The researchers surveyed roughly 500 economics Ph.D. candidates at eight elite universities, and found that 18 percent of them experienced moderate or severe symptoms of depression and anxiety. That’s more than three times the national average, according to the study. Roughly one in 10 students in the Harvard survey also reported having suicidal thoughts on at least several days within the prior two weeks. (Other recent studies have had similar findings, including one published earlier this year that described graduate-student mental health as a “crisis.”)

The study’s results, which also include survey responses from nearly 200 faculty members, indicate that many Ph.D. students’ mental-health troubles are exacerbated, if not caused, by their graduate-education experiences. Roughly half of the respondents in the Harvard study with anxiety and/or depression had been diagnosed sometime after starting their graduate studies. And students toward the end of their programs were far more likely than those who were just embarking on their graduate journeys to report severe symptoms of anxiety or depression.

Graduate students cite the combination of financial and professional pressures as a significant challenge. Lucy Johnson, an assistant professor of digital literacies at the University of Wisconsin–Eau Claire, says that the financial burdens of her Ph.D. studies made it difficult for her to “escape the graduate curriculum”—by, say, seeing a movie or going out for dinner. Students who already feel isolated by their rigorous academic work are bound to feel even more isolated by their financial troubles, she suggests. Like many of her peers, Johnson eventually took out loans to support herself.

And then there is the academic pressure itself. Graduate education relies on “this idea that we have to produce, produce, produce, or do a lot more labor than others, so we’re worn quite thin,” says Johnson, noting that such labor is often promoted under the guise of “professionalization.” “I think it’s something we’re just supposed to accept as being part of the process.”

Similarly, Rummel—who had long daydreamed of becoming a professor, drawn to the promise of tenure and the prospect of conferences where he could discuss niche topics ad nauseam with likeminded “nerds”—says that he and his peers were expected to treat their doctoral education as a “rite of passage.” “To get that life, you have to pay your dues—and then some,” says Rummel, who’s now 25. “It’s accepted that you’re supposed to hate your life for a long time.” His school made some effort to ameliorate students’ stress—hosting events on self-care, for example, and offering free massages during final-exam weeks. “But no one,” he adds, “has time for that.”

Compounding the pressures is the sense, at least according to the economics Ph.D. candidates surveyed by the Harvard researchers, that their work isn’t useful or beneficial to society. Only a quarter of the study’s respondents reported feeling as if their work was useful always or most of the time, compared with 63 percent of the entire working-age population. Only a fifth of the respondents thought that they had opportunities to make a positive impact on their community.

Regardless, relatively few study participants reported receiving regular mental-health treatment—including just one in four of the respondents who’d experienced suicidal thoughts. And perhaps most tellingly, the grad students in the study who scored worse than average on a mental-health assessment tended to think that their mental health was better than average. Among those who reported that they recently had suicidal thoughts, 26 percent assumed that their psychological well-being was better than the norm. This dissonance hints at the ubiquity of the problem—the widespread acceptance of poor mental health as a fact of life in graduate education.



It’s almost too easy to satirize physical education, better known by its eye-roll-inducing abbreviation P.E. From Clueless to Superbad to Spiderman: Homecoming, parodies of gym class are a pop-culture darling. Perhaps that’s because they speak to one of America’s fundamental truths: For many kids, P.E. is terrible.

A recent working paper focused on a massive P.E. initiative in Texas captures this reality. Analyzing data out of the state’s Texas Fitness Now program—a $37 million endeavor to improve middle schoolers’ fitness, academic achievement, and behavior by requiring them to participate in P.E. every day—the researchers concluded that the daily mandate didn’t have any positive impact on kids’ health or educational outcome. On the contrary: They found that the program, which ran from 2007 to 2011, actually had detrimental effects, correlating with an uptick in discipline and absence rates.

As for why this particular P.E. program was counterproductive, Analisa Packham, an economics professor at Miami University in Ohio who co-authored the study, points to bullying as one potential reason. Students are more likely to be bullied in middle school than at any other point in their academic careers, and P.E. presents a particularly ripe opportunity for abuse, whether because the class forces them to use a locker room, where adult supervision is limited, or because it facilitates the teasing of overweight or unathletic kids.

The paper posits that by subjecting participants—namely low-income kids, as the Fitness Now grants targeted campuses serving disadvantaged populations—to these circumstances on a daily basis, the P.E. requirement made students less inclined to go to school. “These adolescents were not enjoying the daily P.E. requirements and would’ve rather skipped school,” suggests Packham, who as an economist has focused her research on the outcomes of health programs. The Fitness Now program required that students participate in at least 30 minutes of physical education every school day. Schools that took part in the grant received $10,000 on average to help improve their P.E. programs by adding classes, for example, or hiring coaches and fitness instructors. They also used the money to purchase equipment such as stopwatches, jump ropes, and free weights.

According to the study, the program resulted in a roughly 16 percent increase in the number of disciplinary actions for each student. The study also found that the proportion of misbehaving students went up by more than 7 percent.

The findings of the study, which has yet to be published in an academic journal, are limited in scope. Still, the new paper adds much-needed nuance to the body of research that has evaluated the effectiveness of various approaches to P.E., complicating the findings of studies that generally assert the importance of school policies that encourage regular opportunities for physical activity.

It’s hard to argue that a given P.E. program is anything but well intended, particularly when considering that children spend most of their waking hours—and meals—at school, and that childhood obesity is a national crisis. But the kind of strategy taken by many of the Fitness Now schools may not be the most effective way to achieve the purported goals.

To be effective, a P.E. program typically needs to be multifaceted and holistic, suggests a 2013 book on America’s physical-education landscape that was co-edited by Harold Kohl, a professor of kinesiology and health education at the University of Texas at Austin. That might involve healthy-living and nutrition classes, parent education, and frequent opportunities for unstructured play—all on top of more conventional “gym class.” This may help explain why, for example, one 2012 study based on data from the National Survey of Children’s Health found that required P.E. alone generally doesn’t have any noteworthy impact on boys’ physical-activity levels or obesity, though it did have a marginal impact on girls’. Similarly, an earlier 2015 study on Texas’s Fitness Now program found it to be largely ineffective, resulting in slight improvements to kids’ fitness skills and having no impact on BMI or academic achievement.

The results of Packham’s paper on the Fitness Now program support the basic takeaway that the design of P.E. courses is what’s most consequential, and they hint at two interconnected factors that experts suggest tend to undermine the impact of such curricula. For one, P.E. programs often rely on a superficial notion of gym class—conceiving of physical activity as little more than a timed run around the track, for example, or a game of kickball—and this results in worse offerings. And then, when students feel forced to take these basic offerings, they may resent the classes more than they would otherwise. “Older kids have already formed these important eating and exercising habits, and changing their daily decisions is more complicated than just providing money for jump ropes,” Packham says.

Despite greater recognition of the academic benefits of physical activities—including guidelines from agencies such as the Centers for Disease Control and Prevention stressing that kids should get at least an hour of such activities a day—schools began to deprioritize P.E. about two decades ago, and the cuts have persisted in many cases, suggests Kohl. Accompanying this shift has been a movement away from casual activities such as recess, which experts argue is one of the more effective means of promoting children’s physical health. An immense body of research demonstrates the positive benefits of increased recess time, which schools started to cut after No Child Left Behind was signed into law, because of the policy’s emphasis on academic subjects such as reading and math.

Justin Cahill, a veteran P.E. educator who’s taught at an Atlanta-area private school for the past decade or so, stresses that it’s the typical application of physical education rather than the fundamental concept that results in bad outcomes. Until the past few years, P.E. classes tended to focus on kids’ acquisition of skills, such as dribbling a ball, and the fulfillment of universal benchmarks, such as the ability to run around a track three times within some specific amount of time. This approach, he says, “breeds stagnation and disinterest—the kids are like, ‘Yeah, this is ridiculous.’” It can also, as Packham’s study suggests, breed resentment: After all, in this “old school” version of P.E., certain kids are bound to struggle.

Cahill maintains that many P.E. programs are high caliber, successful in both engaging students and producing positive health and wellness outcomes. Echoing the findings outlined in Kohl’s book, he says that positive results are contingent on a multifaceted and holistic design—what he defines as programs that inspire children to exercise without realizing they’re exercising, that simply ensure they’re constantly moving, during recess, frequent “brain breaks” to get out “the sillies,” morning jogs, and, yes, regular P.E. class. Positive results are also contingent on experienced, empathetic P.E. teachers—those who know to modify a curriculum to meet a certain student’s needs, and to give kudos to that child who can’t run around the track. After all, research shows that people can get a good workout even when walking, and the more important thing is to create a healthy relationship with exercise that can last for decades.

Cahill’s own observations at annual conferences—and in his Facebook group for physical-education teachers across the country looking to exchange research on best practices and their own anecdotal advice—make him confident that P.E.’s reputation will improve in the years ahead. “I think P.E. is in a very good place right now,” he says, comparing it with the norm of earlier decades, and even of the early 2000s, after the passage of the federal No Child Left Behind Act. “Teachers are enlightened. The arrow is flipped.”

Still, even if P.E.’s bright spots are evolving into the status quo, both Kohl and Packham argue that P.E. has been scapegoated for public-health problems concerning children, including obesity. “It’s been a false flag that we’ve only looked at P.E.,” Kohl says, “when in fact it’s not the only way that kids can get physical activity.

“By making kids sit and be quiet and learn rather than allowing them to be physically active, we may actually be holding their test scores down,” Kohl continues. “We may be kidding ourselves by making kids sit in classrooms all the time.” For Kohl, the ideal P.E. program would still be five days a week—but unlike the Texas requirement, it would be more focused on building active recess periods into the day and include opportunities before and after school to, say, ride one’s bicycle or walk to and from school and participate in sports.



Every year, Harvard’s admissions officers are charged with whittling a batch of 40,000 applicants down to a bare-bones selection to fill the institution’s roughly 1,600 freshman seats. Those officers can’t just set a high bar for test scores and GPAs to arrive at that selection; far too many candidates boast those qualifications. Plus, even if that arithmetic were possible, Harvard prides itself as an institution where students learn from each other in addition to their professors. Building each freshman class is, in turn, both an art and a science—one that effectively requires admissions officers to exercise a combination of number-crunching and intuition.

An organization representing Asian Americans who were at some point rejected from Harvard is suing the school for that art-and-science approach. The group, Students for Fair Admissions (SFFA), recently reignited tensions around that approach with a new legal filing that it says confirms suspicions that the university’s admissions practices discriminate on the basis of race. The documents, filed on Friday in federal court by SFFA, could influence admissions policies at universities across the country; the case is slated to go to trial in October.

One of the most striking revelations pertains to Harvard’s consideration of applicants’ soft skills—things like “likability,” “helpfulness,” “integrity,” and “courage”—in determining their acceptance. Despite boasting higher test scores, better grades, and stronger extracurricular resumes than applicants of any other racial group, Asian American applicants consistently received lower rankings on those personality traits, according to a statistical analysis conducted on behalf of SFFA of more than 160,000 student records. This emphasis on personality, the analysis concludes, significantly undermined otherwise-qualified Asian Americans’ chances of getting in.

The news media have largely fixated on whether the evidence contained in the filing is the “smoking gun” needed in the longstanding crusade to crack down on admissions practices at the country’s premier institution of higher learning, practices that until now the school hadn’t disclosed to the public. Whether the evidence is incriminating isn’t clear, but it does reveal how tricky it is to assign value to personality traits in college admissions. In offering a glimpse into how the emphasis on those traits might favor some races over others, the filing points to a puzzle whose solution could be integral to the quest to get affirmative action right: Is it possible to define a characteristic as intangible and subjective as good personality in a way that protects students against people’s deep-seated, and often subconscious, biases?

“However you measure these things—whatever you do [in the admissions process]—is going to privilege one group and disadvantage another group,” said Natasha Warikoo, an associate professor of education at Harvard who wrote the book The Diversity Bargain, which explores the role of race at elite universities. “There’s no such thing as a perfect admissions system that leads to ‘a meritocracy.’” Warikoo wasn’t involved in this lawsuit.

SFFA’s filing includes a report by Peter Arcidiacono, a Duke University economist, that delves into the process by which Harvard rates applicants in five main categories: academic, extracurricular, athletic, personal, and overall. Arcidiacono shows that, after narrowing down applicants to those with the strongest objective academic qualifications, Asian Americans were far more likely than blacks or Hispanics to receive a low personality score from admissions officers. The analysis juxtaposes the Asian Americans’ personality scores from admissions officers with the relatively high personality ratings given by alumni interviewers, as well as with the relatively positive feedback provided to Harvard by applicants’ teachers and counselors, for those same students.

Arcidiacono concludes that this apparent personality-score phenomenon leads to what he describes as “the Asian-American penalty”; if that so-called penalty were removed, he contends, Asian Americans’ admission rate would increase from 5.2 percent to 19.2 percent. Is it possible to justify the glaring discrepancies identified by Arcidiacono? Should Harvard admit one out of every five Asian American applicants to ensure its admissions practices are “fair”?

Arcidiacono’s data certainly indicate a correlation between an applicant’s race and her personality rating—among the four main racial groups, Asian Americans have the lowest share receiving a top personality score even though, for all racial groups, applicants with top academic qualifications are most likely to receive top personality ratings. But establishing a causal relationship between students’ race and their personality scores is tricky.

In its 2016 decision on Fisher v. University of Texas, the U.S. Supreme Court confirmed that race can be used as one of many factors in admissions, reiterating the notion that a diverse student body is educationally beneficial. In assessing applicants based on a nebulous suite of academic and non-academic qualities, Harvard’s policy makes it all but impossible to draw a statistically—and legally—airtight conclusion about why one applicant was chosen over another. Further complicating matters is the ambiguity Harvard’s admissions office assigns to the “personal” category. While the other categories come with detailed and straightforward criteria, a vague rubric determines applicants’ personality rating; “outstanding” personal skills secure an applicant a top score, for example, and being “bland or somewhat negative or immature” gets her a middling one.

Harvard has long argued, as it does in its own expert analysis filed Friday, that diversity is inherent to its broader mission in justifying its “holistic” approach to admissions. In pursuit of this mission, admissions officers every year are charged with constructing a freshman class that features students who express an array of academic interests; who represent a range of cultural, socioeconomic, and geographic backgrounds; who bring a breadth of sought-after personality traits, like humor and sensitivity, that may be hard to define but often have intuitive appeal.  

Against this backdrop, it’s easy to chalk up the correlation between Asian Americans’ racial identity and their relatively low personality scores to mere coincidence. And that’s essentially what Harvard has done in response to any critique of its admissions practices. The basis of SFFA’s filing was an internal investigation conducted by Harvard in 2013 that found that being Asian American puts applicants at a disadvantage. But as the school alludes in its latest court filing, such findings—the 2013 analysis for its part focused on the hypothetical impact of an academics-only policy—amount to little more than an unintended byproduct of what one official, according to Inside Higher Ed, described in an internal memo as “relative trade-offs.” Were the institution to judge students only on objective academic metrics—a very rare practice among selective U.S. colleges and universities—the share of Asian Americans in a given class would more than double, yet that of blacks and Latinos would be significantly reduced. An academics-only approach, the thinking goes, would undermine Harvard’s ability to be the institution it strives to be.

“The reality is that Asian Americans don't do as well on” certain measures that Harvard prioritizes when building a class, said Warikoo, who’s of Indian descent. ”We tend to live on the coasts, are less likely to be recruited athletes or legacies, more likely to want to study medicine,” and so on. Determining whether that’s a fair outcome of Harvard’s emphasis on applicants’ non-academic qualities, she said, “depends on what we think is important for admission—how does the system of selection further the university’s goals?”

Efforts to arrive at a consensus on that issue have fallen flat. Yet, regardless of the merits of SFFA’s lawsuit (and of Harvard’s response), there’s compelling evidence that the emphasis on character traits disproportionately undermines Asian Americans’ admissions prospects. And given how subjective personality is, implicit biases against that racial group could explain the trends Arcidiacono identified; Asian Americans, for example, are consistently regarded as more “foreign” than other racial groups and are widely stereotyped as being reserved. Perhaps these hypothetical biases, and the “trade-offs” that hypothetically feed them, are worth scrutiny that could advance the affirmative-action debate past the standard ideological arguments. Few would argue that an individual’s worth stops at her success in school—that limiting an evaluation of her strengths and weaknesses to easily quantifiable metrics is a productive means at ensuring Harvard and other schools provide a “world-class education.” But SFFA’s latest filing brings into sharp relief the difficulty of relying on metrics that extend beyond the classroom and in turn necessitate some degree of gut instinct.

Warikoo in our conversation broached the idea of a lottery system into which Harvard would feed all applicants who meet certain criteria, establishing weights for particular categories. Not only could that system help reduce the consequences of the current approach to students’ personalities, it could also free up resources that could, say, instead be invested in financial aid; according to Harvard’s own Friday court filing, a team of roughly 40 officers votes on each final freshman admissions decision at the school.

But while they could spark discussions about alternatives to the use of race in achieving socioeconomic equity, neither SFFA’s case against Harvard nor a similar probe by the Justice Department is likely to result in a simple rethinking of resource-allocation. Nicole Ochi, an attorney with Asian Americans Advancing Justice, said she fears SFFA’s suit could have far-reaching negative consequences by prompting other higher-education institutions across the country to roll back the extent to which they consider race in admissions or eliminate the practice altogether. Research has already shown that cases like this one have a chilling effect on affirmative action: One study, for example, found that the rate of “very competitive” schools, including private institutions, that factor race into admissions has plummeted in recent decades, dropping from 75 percent in 1994 to 47 percent in 2014. If the court rules that Harvard’s policy is unconstitutional, Ochi argued, “then that will be the death knell for affirmative action everywhere, throughout the country.”

That prospect makes Ochi and other supporters of affirmative action all the more frustrated with Harvard’s reliance on such a vague means of evaluating applicants’ personalities, and with the school’s failure until now to publicly disclose exactly how character traits factor into that evaluation. For advocates of affirmative action, these omissions allowed SFFA to conflate the consideration of race in admissions with discrimination against Asian Americans—even though there’s little hard proof that allowing colleges to consider race in itself disadvantages them.

“I’m willing to entertain the notion that there implicit bias is at work in the personal score that results in some discriminatory impacts against Asian Americans,” Ochi said, “but I do not think that that provides evidence that the consideration of race in the admissions process is causing that—especially since that score doesn’t consider race.” In other words, Ochi and others contend that if something is indeed amiss in Harvard’s admissions office, the source of the problem is implicit bias. It isn’t affirmative action.  



In March, Kyle Kashuv got the news he’d been waiting for: He’d been admitted to Harvard. The Parkland-shooting survivor, who had become a conservative rising star, had spent his senior year as a school-safety and gun-rights activist, traveling the country as the high-school outreach director for the right-wing group Turning Point USA. He planned to take a gap year before enrolling in the fall of 2020. But today Kashuv tweeted that Harvard had rescinded its offer, in an apparent response to racist messages he had written years earlier.

The first sign of trouble came in mid-May, when Kashuv announced that he would be leaving Turning Point USA. Hours later, screenshots began to surface on Twitter. In text messages and Google Docs from when he was 16, Kashuv allegedly used the word nigger repeatedly, made crass remarks about women, and used other racist and anti-Semitic language. A week after the messages first became public, he posted an apology on Twitter in regard to “callous” remarks he had made earlier in his high-school career. (An attempt to reach Kashuv for comment on Twitter did not elicit a response.)

The fallout from Kashuv’s remarks ultimately led Harvard to write to Kashuv on June 3, “After careful consideration the Committee voted to rescind your admission.” In a thread posted to Twitter on Monday morning, Kashuv explained the back-and-forth that transpired between him and the college in the weeks leading up to the rescission. Two days after Kashuv posted a public apology, on May 22, stating, “We were 16-year-olds making idiotic comments, using callous and inflammatory language in an effort to be as extreme and shocking as possible,” the college’s admissions dean, William R. Fitzsimmons, sent him a letter, according to a screenshot posted as part of Kashuv’s Twitter thread.

“Harvard reserves the right to withdraw an offer of admission under various conditions,” Fitzsimmons wrote to Kashuv, “including ‘if you engage or have engaged in behavior that brings into question your honesty, maturity, or moral character,’” per the school’s admissions policy. The reports of the messages had brought each of these qualities into question, but the college wanted to offer Kashuv a chance to explain himself. He had until May 28.

In his response to Harvard, Kashuv was contrite. “I understand Harvard’s concern over these offensive statements from my past, and I further understand that Harvard has been contacted about them by people expressing concern about them,” he wrote. “While I will forever bear incredible shame for typing them, I especially feel remorse now that they have been made public knowing that they have caused terrible pain to people I care about.” He similarly emailed the Office of Diversity and Inclusion at Harvard to offer an apology, and pledged that during his gap year, he would “supplement my activism to include reaching out to minority communities.”

But it was too late to salvage his Harvard acceptance. In a letter dated June 3, Fitzsimmons wrote to Kashuv that the committee appreciated the “candor and expressions of regret” in his letter, but “the Committee takes seriously the qualities of maturity and moral character. After careful consideration the Committee voted to rescind your admission to Harvard College.” Kashuv attempted to meet with the committee in person, but it declined his request. In an email, Rachael Dane, a spokeswoman for the college, told me, “We do not comment publicly on the admissions status of individual applicants.”

The admissions policy at Harvard, and most other colleges, stipulates that the college can withdraw an offer of admission in certain cases, and there are several situations that might lead a college—and, indeed, have led colleges in the past—to pull an admissions offer. Students are required to send updated transcripts after their senior year, so if there is evidence that a student tanked during his last semester, that can be reason enough. This was the case when the University of North Carolina at Chapel Hill rescinded an offer of admission to a student in 2003. Sometimes the reasons are more institutional than individual: In 2017, UC Irvine withdrew admissions offers to more than 100 students because, well, more students had accepted offers than the school had expected, and it could not accommodate everyone.

There have also been situations in which bad behavior, including prior bad behavior (as in Kashuv’s situation), has resulted in an offer being revoked. In 2017, Harvard rescinded admissions offers to 10 students who were members of a meme group on Facebook and shared messages that were often anti-Semitic and sexist. It’s impossible to know how often these rescissions happen, because admissions offices tend to keep a tight lid on their affairs—the ones that are known typically come as a result of the students voluntarily making the information public or lawsuits where they are revealed. But the overall picture suggests that they are fairly rare.

The way the colleges see it, these sorts of late-to-the-game revelations are nevertheless relevant to their decisions, even if a decision has already been made. “Everything a kid does, starting in ninth grade, matters for admissions purposes,” Anna Ivey, the founder of Ivey Consulting, an admissions-counseling company and former admissions dean at the University of Chicago Law School, told me. “That’s sometimes a tough thing to hear, especially if it happened earlier in one’s high-school years. But that’s the reality for applicants.”

College admissions officers are not typically sitting around trolling the internet for evidence of bad behavior by their prospective students, Ivey said, but when that information comes to light, they have a responsibility to take it seriously, and typically they will give the student an opportunity to explain the situation. A college’s post-admissions decision depends largely on the details of each specific case, but the additional processing that colleges employ to evaluate student conduct is a sign of a different standard of evaluating information before and after an offer has been made.

That, of course, raises the question, How much regret is enough? “There are all types of mea culpas that happen, and schools consider them,” Ivey said. “This wouldn’t have been a required disclosure, but that’s the hazard of living in the internet age and being a digital native. Here’s a case of screenshots coming back to bite you.” But at a certain point, even the most repentant prospect may not get to stay in, especially at hyper-selective private colleges that can fill their seats dozens of times over with qualified applicants. Sinners can repent, but that does not mean they will not sin again, and that’s a risk some colleges are not willing to take.

A college can rescind an offer of admission at any time up to the student’s actual enrollment, Ivey says. The dynamics do change once a prospective student becomes an enrolled student, though at that point the student may well be brought in front of a university ethics board to answer for prior misdeeds. Still, “when you’re dealing with a place like Harvard, they don’t have to take a risk like [admitting a given student] unless they really feel like it,” Ivey said. “That is tough, but welcome to the world of highly selective college admissions.”



On Tuesday, the Charles Koch Foundation announced that it would be making a significant change: The philanthropic behemoth would begin publishing details about the multiyear contracts that it makes with universities. The contracts, known as “grant agreements,” lay out the “term, scope, and purpose” of the funds the foundation gives to organizations. The effort at transparency was big news, not least because it came on the heels of a controversy over what exactly was in the libertarian organization’s agreement with George Mason University.

“There has been a lot of mischaracterization of our grants in the past,” Brian Hooks, the foundation’s president, told The Wall Street Journal. “The opportunity to be crystal-clear about how our foundation interacts with universities is a good opportunity.” The foundation awarded more than $49 million to more than 250 colleges in 2016, according to the Associated Press. And a new grant agreement that Koch shared with The Atlantic—the first since the announcement of the foundation’s transparency push— shows exactly what goes into those contracts.

The new grant is with Arizona State University, and is being given to the Academy for Justice, a coalition of criminal-justice scholars housed at the Sandra Day O’Connor College of Law; it is a five-year grant for $6.5 million. The academy, which is led by Erik Luna, a professor at the law school, recently produced a four-volume publication that addresses criminal-justice topics such as racial profiling, mass incarceration, and use of force by police, as well as potential reforms. The grant, Luna told me in an interview, will help build on the model they used to create the report—injecting rigorous academic research into real-life policy conversations on criminal-justice reform.

That was the university’s initial proposal for the grant, and the agreement reflects that the money will go to that project.  And, as the foundation outlined in its newly released statement of giving principles, “the faculty call the shots” when it comes to exactly how the funds are used. The agreement describes the grant’s purpose thusly: “As stated in the proposal the mission of the Center is to pursue scholarly research and analysis of criminal laws, procedures, policies, and practices.” It also explains how leadership will be selected, consistent with the university’s proposal: “The Center will be led by a Director, (the “Center Director”), who will be selected by the University according to its normal procedures.”

The agreement also outlines how much money will be contributed each year and to what. “Salary and fringe benefits for two tenured or tenure-track professorships”; “Costs and expenses for the Center Director Stipend”; “Costs and expenses for the Administrative Assistant,” and so on.

The transparency effort has been welcomed in the education community, but cautiously. It’s nice, some say, that the foundation will be announcing its new agreements, but what about the details of the old agreements?

Connor Gibson, a researcher with Greenpeace, told Inside Higher Ed that the new effort doesn’t address “existing concerns” and hides conditions outlined in previous agreements. Several critics point to the case of Koch’s grants to George Mason, in which the foundation retained the right to be involved in grantee’s hiring processes. After students and faculty submitted Freedom of Information Act requests for information about GMU’s ties to the foundation, the institution’s president, Ángel Cabrera, released the grant agreements dating back to 2003. All but one of the agreements explicitly stated that the university had final say in hiring, but Cabrera admitted that the limited involvement the foundation still had in hiring fell short of academic standards. “The issue was that the agreements granted donors the right to participate in selection and evaluation committees, a circumstance that falls short of the standard of academic independence we should expect in every gift,” he wrote in The Chronicle of Higher Education.

There has also been similar criticism by students and faculty of grants at Wake Forest University, Florida State University, and elsewhere. The foundation counters that the grant agreements, both then and now, are in line with the giving principles they’ve recently restated. “This move builds on our long-standing giving principles and takes things one step further,” Hooks told me. “We’re excited to be at the forefront of how philanthropies engage with universities.” The new agreement explicitly states several times that hires will be made according to university procedures and does not mention foundation involvement in faculty selection.

Here’s a full copy of the Arizona State University agreement:







Maybe higher education has reached its peak. Not the Harvards and Yales of the world, but the institutions that make up the rest of the industry—the regional public schools who saw decades of growth and are now facing major budget cuts and the smaller, less-selective private colleges that have exorbitant sticker prices while the number of students enrolling in them declines.

Higher ed is often described as a bubble—and much like the housing market in 2008, the thought goes, it will ultimately burst. But what if it’s less of a sudden pop and more of a long, slow slide, and we are already on the way down?

Bryan Alexander started grappling with the idea of “peak higher education” in 2013—inspired by the notion of “peak car,” “peak oil,” and other so-called “peaks.” At the time, there were signs that the industry was already struggling. The number of students enrolled in higher education had dropped by a little over 450,000 after years of booming growth, the proportion of part-time faculty—more commonly referred to as adjuncts—had steadily become a more significant part of the professorship, and there was a general skepticism about the skyrocketing costs of college and concerns over whether a degree was worth it. Taken individually, he said, each sign was troubling enough. But when looked at together, they represented the outlines of a bleak future for higher education. Alexander, a self-described higher-education futurist and a former English professor, came to the conclusion that after nearly a half century of growth, higher education might be as big as it could get. It would, he reasoned, only get smaller from there.

Now, five years on, he says the “depressing” hypothesis is playing out. In the spring of 2013, there were 19,105,651 students enrolled in higher ed; this spring, there were 17,839,330, according to recently released data from the National Center for Education Statistics. That represents a roughly 7-percent decrease—and is driven largely by declining enrollments in the for-profit and community-college sectors, as well as stagnant enrollments among four-year non-profit public and private institutions. And the trend of declining enrollment in higher education is likely to continue, he argues, for a couple of reasons, but most notably, a declining birth rate means that there will be fewer 18-year-olds entering academe, and there are fewer international and immigrant students to fill those seats.

Why is the dip in enrollment such a big deal? Well, quite plainly, the business model for a lot of colleges is dependent on enrollment. If enrollments decline, revenues decline, and colleges have less money for facilities, faculty, and programs. That creates a sort of death spiral in which colleges are getting rid of programs, which in turn makes it harder to attract students, and so on. For non-selective private liberal-arts colleges, this could mean mergers or closures—something that’s already happening in quite a few places, such as at Marylhurst University in Oregon, Wheelock College in Massachusetts, and St. Gregory’s University in Oklahoma. And for other institutions, Alexander told me in a recent interview, it could mean a shifting of institutional priorities—particularly in the students they recruit and teach, moving away from a primary focus on 18-to-22-year-olds towards more adult learners, as administrators at the University of Memphis have done in Tennessee.

Declining enrollments could also mean the decline of research faculty, increased workloads, and more rapid adjunctification. And given how colleges have treated adjunct faculty, Alexander says, “it would be a humanitarian disaster”—one of higher education’s own doing. “We’ve done it to ourselves with open eyes since the 1990s. And we know about it, it’s kind of an open secret,” he says. “The Research I universities keep pumping out Ph.D.s, and they haven’t slowed down at all. And they know exactly what that means, you know, that the majority of these Ph.D.s are either going to leave academia or end up with horrible labor conditions.”

It’s not a difficult future to imagine—largely because most of it is already happening. Some institutions will be shielded from the decline—most obviously the major players and media darlings such as Ivy League institutions and major public institutions like the University of Texas at Austin. But most colleges will not be so fortunate, he says. They will either have to adapt or die out.

Perhaps this is just a blip driven by declines in the for-profit sector that will correct itself, or the consequence of a growing economy in which more people choose jobs over school. More optimistically, maybe higher education as an enterprise finds a way out of this rut. State legislatures could reverse course and shift more funding to higher education, though with the polarized political environment around views of higher education and its chief purpose, particularly among Republicans, that seems unlikely. Maybe colleges will wind up taking a proactive approach and innovate their way out, shifting, as some have already, to serve more adult students alongside recent high-school graduates, and moving more of their coursework and programs online to serve a wider audience of students and reduce campus costs. (Alexander also points out that moving more programs online could help with international enrollments, as students wouldn’t have to worry about potential political issues in the U.S.)

It’s ironic, he says, that “we are living through the greatest time in history to be a learner,” with the availability of so many high-quality free materials online. But at the same time, the institutions most affiliated with knowledge and learning are facing crisis.



Jake Wakefield, who graduated from high school in Fort Collins, Colorado, in 2003, recalls that April 20 was the date of his Senior Ditch Day. One reason for the chosen date was “a tongue-in-cheek thing,” he told me; April 20 is an unofficial cannabis holiday. But he remembered students talking about another reason: “If someone wanted to re-create Columbine, the seniors wouldn’t be there, so we’d be okay.”

This second reason was sort of a joke, as far as Wakefield remembered—but it was still on seniors’ minds on Ditch Day. For Wakefield and many others who attended high school in the years shortly after the Columbine High School shooting, on April 20, 1999, the tragedy became a cultural touchstone, imprinting itself on teens’ minds and coloring their high-school years with nervous jokes, new fears, and new routines.

When I spoke with people who were in high school around the time of the Columbine shooting about how the school experience changed, one of the first things that came to mind for them was the introduction of school-shooter drills. Wakefield, who was in eighth grade at Lucile Erwin Middle School, in Loveland, Colorado, when the shooting occurred, underwent his first drills that same spring, which he remembered felt somewhat “rushed,” albeit “well intentioned.” He recalled a drill in the school gym where “they had us line up as far away from the door as we could, and all in a line against the wall.” He said he looked up at the small windows of the gym and thought, There’s just enough room to fit a gun through, and we’re all perfectly lined up. I wonder if they’re going to rethink this plan eventually. Wakefield went to a different middle school for ninth grade and then moved up to high school, where he said the drills were “more ironed out.” (The school districts mentioned in this story either did not have records of specific school policies or did not return requests for comment, so policies are described as the students remember them.)

After the Columbine shooting, schools moved quickly to take measures they hoped would prevent another attack, and in the process created the school environments that today are second nature to students across the country. While previous school shootings had stoked fear in students and parents, Columbine was at that point the deadliest high-school shooting in U.S. history, and it resonated on a national level. Some schools introduced surveillance cameras and locked more of their doors; some brought in armed officers. Drills like the ones Wakefield recalled, in which schools practiced their response to a shooter, were quickly popularized—they were actually called “Columbine drills” at first, the criminologist James Alan Fox recently told NBC News. (According to the National Center for Education Statistics, as of 2016, 95 percent of public schools conduct lockdown drills, in which students simulate the experience of hiding in locked classrooms.)

Jill Westendorp, who graduated from Southwest High School in Minneapolis in 2000, told me that “there were doors all over” her school, which consisted of two separate buildings, and before the Columbine shooting, “most of them were unlocked” during the school day. Students could walk freely in and out of whichever door they wanted, and Westendorp said she was never concerned about violence at school. After the shooting, “they put electromagnetic locks on all of the doors that would only release if the fire alarm was pulled,” she told me. Students were able to enter and exit through just one set of doors, she remembered.

The safety measures that some kids experience can leave them with warped perceptions of what going to school is like. When Nicole Martin’s daughter started high school this year and asked for a new backpack, Martin, who graduated from high school in 2001, was shocked. “I was like, ‘But you can’t carry one?’” she told me in a Twitter direct message. “My husband thought I’d sprouted a second head when I said that.” Martin was remembering the backpack ban at her own high school, East Carter High, in Grayson, Kentucky, which was first put in place after a shooting there in 1993, in which a teacher and a custodian were killed. When Martin’s daughter told her that she was, in fact, allowed to carry a backpack, Martin responded, “Oh, a clear one, right?”

After Columbine, Martin said, security measures increased. She recalled that even though her high school had already experienced a shooting, Columbine was something of a turning point. “In a way, it was still a little easy to imagine that what had happened before [at my high school] was a onetime thing,” she said. The shooter “had carried the pistol in his backpack, so get rid of backpacks. A teacher and a janitor had died, but no kids did. Columbine was that kick in the head that no, the kids were sitting ducks and could be killed, too.”

The effects of these sorts of school-safety policies are still unfolding. Researchers don’t yet have a clear idea of whether lockdown drills and other measures are actually effective in preventing a shooting, and though they’re meant to protect kids, they can also do damage. Exposing kids to shooter drills at young ages can give them unnecessary anxiety about a risk that is still relatively rare. And students of color tend to get disproportionately targeted by some of the post-Columbine disciplinary and law-enforcement measures.

For many students who attended high school after the Columbine shooting, this is all they know. And for those who attended high school before Columbine—even just before—many things were entirely different. The year 1999 is, for many, a bright line that divides one type of school experience from another. Laura Lineberger, who graduated from West Mecklenburg High School, in Charlotte, North Carolina, in 1998, told me that she “never feared for a school shooting, ever,” and that her high school never had a lockdown drill while she was there, as far as she can remember. Lineberger is now a teacher at a school in downtown Raleigh; she said that lockdown drills started there approximately five or six years ago. Her students have “grown up” with drills. “They expect them; they know what to do,” she said, especially by the time they get to high school.

The former students I spoke with also pointed to shifts in teen culture as a result of the Columbine shooting. After the shooting, stories spread quickly; some media outlets fixated on the black trench coats the shooters wore and reported that they had been influenced by goth subculture. Later research and reporting found that many of the media’s theories were inaccurate, but they changed the way some teens who fit these descriptors were treated at school. Meghan Bishop, who was a junior at Beaverton High School, in Beaverton, Oregon, in the spring of 1999, remembers her school focusing on “What makes a person go and do this?” News of the Columbine shooting “came out at the time of The Matrix. My friends loved The Matrix; my boyfriend at the time had one of those trench coats, and all of a sudden [people wondered], ‘Okay, does that make you a shooter, because you’re wearing a trench coat and dark glasses and you’re kind of a loner?’ So he was singled out.” She told me that her boyfriend, who went to a different high school, was “disciplined for coming to school in a trench coat, even though … he just really liked The Matrix and computers.”

Parents, school administrators, and other adults also viewed video games as a cause for concern; the Columbine killers were reportedly fans of the shooting game Doom, which was released in 1993, and observers worried that it had influenced them. “I remember so many people talking about it, so many people worried about, Is playing video games going to make my kid shoot up a school?” Wakefield said. “Before Columbine, video games were just kind of like something everyone did. You’d go rent a video game from an old Blockbuster or something. I’d remember playing games with my sisters. After Columbine, video games started to be seen as something that the fringes played.”

For some students, Columbine created an undercurrent of anxious jokes and banter. Wakefield told me that the Columbine shooting was a consistent subject of conversation among his middle-school peers (until the September 11 attacks, after which “that was all we talked about,” he said). “A lot of it was talking about what we would do if there was a shooter in the room, what we would say if they had a gun to our head,” he said. “A lot of middle-school-level bravado: ‘Oh, yeah, if a gunman came after us, we’d just karate-chop them in the neck and we’d save the day. I’d be great—we’d take the gun from them and then we’d be the hero.’”

The joking and bluster sometimes gave way to real fear. Wakefield said that he and his classmates would talk about the design of their school buildings, “loosely planning what would happen if there was a disaster like this.” When he started at a new middle school in ninth grade, he analyzed the school’s structure with his friends. “There’s more corners that we can hide behind” compared with his previous school, he remembered discussing. “If we can make it to the parking lot, we can hide behind a car or something. There’s lots more cover here.”

The Columbine shooting led some students to grapple with violence that already existed at their school. Westendorp, who went to high school in Minneapolis, remembered that at first the shooting felt “a little bit more removed.” But then a teacher “sat down with us,” she said, “and she’s like, ‘People do bring guns to school. We’re here to keep you safe, but you’re not immune to this. It could happen. It could happen anywhere.’”

Katreena Lloyd-Williams, who graduated from high school in 2002, remembers that at Audenried High School, in South Philadelphia, where she went for part of her freshman year, metal detectors were in place before Columbine. “That school was kind of known in the neighborhood as not the bad school, but a bad school,” she told me. “There was always something going on there.” Even so, Columbine changed how Lloyd-Williams thought about the dangers of going to school. “The violence that happened in the school, it was something that was very personal,” she said. “You knew if you weren’t fighting with somebody, then you weren’t going to be a target. When I thought about Columbine, it in a weird way took away that peace of mind. You realize: Okay, so somebody could just be pissed and come in and shoot everybody. I never thought that way. I just thought, Oh, I keep my head down, I mind my business, I’m good. That definitely freaked me out a little bit.”

Still, the Columbine shooting felt “removed,” Lloyd-Williams told me, “because it was across the country, [and] a mass shooting wasn’t so common” at the time. Today, she attends Temple University as an adult student, and she thinks about the risk of a shooting much more often. “That’s so in my head when something happens. Oh my God, this is a big campus, there’s a lot of kids here, anything could happen. And I know that I didn’t think about that before.”

Lloyd-Williams’s point is one that stood out in all my conversations. For many people who were students in 1999, the shock of the Columbine shooting punctuated their high-school years in a way that is hard to imagine in 2019. Now about 57 percent of teens worry that a shooting could happen on their campus. Most of the people I spoke with remembered the hour, even the minute, when they found out about the shooting; they recalled crowding in front of a TV in a school classroom, turned on during class by a frightened teacher. “I remember eating dinner that night with my family, and my mom sitting across the table from me, and she started crying,” Westendorp told me. “I had literally never seen my mom cry.” The Columbine shooting was, for many, a moment when the impossible suddenly seemed possible; today, teens, families, and schools know this all too well.



When Dolores Huerta took the stage at California State University at Los Angeles to address a room of more than 600 people at the 50th anniversary celebration of the Chicana(o) and Latina(o) Studies department on Thursday, she began with a reflection. “It was actually here in the city of Los Angeles where the Chicano movement started,” she said. That activism was the only reason she was in the room at all, the reason this Chicano studies program—the first in the nation—had come to be in the first place.

Cal State LA’s program, founded in 1968, came at the beginning of ethnic studies at American universities. It presented a different approach to teaching history by focusing on one ethnic group and its relationship to the rest of the United States, instead of the previously standard “dates and places” approach to American history. This spread across the country; now there are dozens of Latino studies programs and departments at U.S. colleges. Since the founding of Latino/Chicano studies, a similar approach has been used to develop other ethnic studies programs, such as African American studies and Asian American studies. The students who take these classes, the vast majority of whom come from the marginalized communities being studied, have the opportunity to study their own identity and political histories, often for the first time in their academic careers.

These departments offer their own courses and house their own majors; instead of focusing on Latin American politics or the history of ancient Mesoamerican civilizations, students learn about what it means to be a Latino in the United States. Each differs from campus to campus, though; some are not “departments” but “programs”, meaning that faculty members are jointly appointed from other departments. The names of the departments also vary dramatically, depending on when and where they were established; for example, Chicano studies departments came along in response to the Chicano movement of the 1960s that fought for civil rights, Puerto Rican studies became popular among New York public campuses, and Latino studies departments were established to study Latinidad as a transnational identity.

This kind of scholarship wasn’t taken seriously by academia before this time, says Dolores Delgado Bernal, the chair of Cal State LA’s Department of Chicana(o) and Latina(o) Studies, and it didn’t come easily. Change came along because students—both black and Latino—pushed for better curriculums at both Cal State LA and local high schools that served hundreds of Mexican American students.

Cal State LA's campus is located near one of the most pivotal events in the Chicano movement: the East L.A. school walkouts of early 1968. Mexican American students living on the east side of the city were angered by their schools’ conditions; apart from facing prejudice from teachers and administrators, the dropout rate was as high as 60 percent in some of the area’s schools, which were made up of over 75 percent Mexican American students; they were also often put into trade classes in lieu of college prep ones. Over the course of a week, 15,000 students walked out of classes en masse carrying signs that read “WE DEMAND SCHOOLS THAT TEACH” and “WE ARE NOT ‘DIRTY MEXICANS.’” They came with a list of demands: no more beatings for speaking Spanish, more Mexican American teachers and administrators, and a curriculum that included Mexican American history and bilingual education. Local Chicano college students who had helped to organize the high schoolers also called for similar additions to their curriculums.

That fall, Cal State L.A. launched the Mexican American Studies Program, which would later be renamed Chicana(o) and Latina(o) Studies. The program started with four interdisciplinary courses focusing on history, culture, psychology, political science, and Chicano literature, all with the express aim to combat the “negative portrayal of Americans of Mexican ancestry in U.S. literature and the media” and prepare students for careers in a variety of fields, according to their website.

For many Latino and Latina students, this was the first time they had the opportunity to study their own history; it’s something that K-12 education rarely teaches well, says James W. Loewen, the author of Lies My Teacher Told Me. In his studies of American history textbooks, Loewen has found that students often are not exposed to the histories of large swaths of the country’s population, including Latinos. Textbooks “see our past from the vantage point of New England,” he says, which ignores the fact that for much of history, the Spanish controlled a large part of what is now U.S. territory, and the indigenous people who lived there.

Even the parts of Latin American and Latino history that are taught in American textbooks, Loewen told me, have gaping omissions. For example, he says that most textbooks include some explanation of President Franklin Roosevelt’s “Good Neighbor” foreign policy of non-intervention in Central and South America, but few mention what Loewen calls America’s “Bad Neighbor” policy—the legacy of “Manifest Destiny” and imperialism in Latin America. “In our history textbooks, that’s usually handled, if at all, in the passive voice, like ‘Troops were ordered into Haiti,’” Loewen says.

Mexican American studies wasn’t the only ethnic-studies program that Cal State LA established at the time; they also established a Pan-African studies department in 1969,  the second-oldest in the country after the one at San Francisco State University. Since then, ethnic-studies departments across the country have grown to include Asian American, Native American and Indigenous, and comparative ethnic studies.

Ethnic-studies classes, then, can be a corrective to students’ previous Eurocentric education, revealing these concealed histories. Delgado Bernal has noticed that all of her students, Latino and non-Latino, have had “lightbulb moments” in the classes that she has taught, realizing that they had never before learned about seminal events like the East L.A. walkouts in school.

Courses like these can also give Latino and Latina students the tools to understand their present experiences. At many colleges, Latino students are navigating a predominantly white environment, but even at majority-Latino schools like Cal State LA, Delgado Bernal says that these courses can help these students better understand their own lives. In one of Delgado Bernal’s courses, she spends the first half of the semester teaching theory to give her students basic concepts about race relations, class differences, and gender roles in order to make sense of history as they’re learning it. Then, she has them write personal essays about their relationships to the theories they’ve learned.

“In story after story, students say, ‘[High school] counselors told me not to take that class because I probably wouldn’t go to college anyway,’ or ‘I’m the first in my family to go to school,’” she says. “And now they have tools to understand the microaggressions they’ve experienced or the economic struggles in this society, and that they’re not the only ones.”

Since 1968, Cal State LA’s Chicana(o) and Latina(o) studies department has grown from four classes to 150. It currently has 55 students majoring in Mexican American studies, a number that has grown by nearly 40 percent over the past year, she says. Research has shown that taking just one Latino or Chicano studies course can “significantly” improve Chicano students’ self-image, improve first-generation Latino students’ sense of feeling community on campus, or increase their academic engagement.

“It opens up their minds to see their history, see themselves, see their culture,” she says. “And in the political climate that we’re in, it gives them the theoretical tools to analyze what’s happening, and to be able to have tools and skills to respond.”

At many institutions, the legacy of ethnic-studies programs has shaped the requirements that students have to fulfill for graduation. Delgado Bernal notes that many campuses now have a “diversity” course requirement, and that Cal State LA also has an even more specific “race and ethnicity” requirement, and many of those classes are housed in her department. Even if other history classes are taught from Eurocentric viewpoints, she says, all students are exposed to the ethnic-studies curriculum at some point in college.

The effects of this focus have also trickled down to the high-school level in some places; lawmakers in California are pushing to make ethnic studies a high-school graduation requirement, while the Texas State Board of Education approved an elective ethnic-studies course in April that can be taught throughout the state. Some initiatives are based in specific school districts, such as Seattle, where educators are developing a curriculum “incorporating the history, culture and literary experience” of marginalized groups.

To be sure, many people have raised critiques of these kinds of programs, some claiming it breeds racial resentment. That was the argument that led lawmakers in Arizona to ban ethnic studies programs in 2010. (A judge struck down the ban in 2017.) Others have said these classes do more advocacy than teaching. Victor Davis Hanson, a historian at the Hoover Institution, once called ethnic studies students “zealous advocates who lacked the broad education necessary to achieve their predetermined politicized ends.” In a more tongue-in-cheek way, the journalist Gustavo Arellano recently wrote that he used to “ridicule” Chicano studies as “achieving little more than inspiring third-generation Mexican Americans from Whittier to change their name to Xipe or Xochitl from Bryan or Yennifer. (He now supports the field, he writes, and has taught classes himself.)

It’s worth noting that Latino studies departments and programs, even within the few schools that house them, only have as much clout in shaping the curriculum as administrators will allow them. Cal State L.A.’s department currently has fewer than five full-time, tenure-track faculty, less than half the size of larger departments like political science or history. And having full-time faculty isn’t a given for schools where Latino studies is a "program" and not a "department."

Part of these departments’ and programs’ power, then, comes from the courses’ ability to transform students’ thinking. Delgado Bernal notes that many of the people who take the department’s courses are studying to become educators. And if this has a ripple effect—future teachers learning the histories that they can pass onto their students, who can pass them on even further—then these small departments can have a far-reaching legacy.



Editor's Note: In the next five years, most of America’s most experienced teachers will retire. The Baby Boomers are leaving behind a nation of more novice educators. In 1988, a teacher most commonly had 15 years of experience. Less than three decades later, that number had fallen to just five years leading a classroom. The Atlantic’s “On Teaching” project is crisscrossing the country to talk to veteran educators. This story is the third in our series. Read the first one here, and the second here.

On March 9, a few days after teachers in Oklahoma threatened to walk out to demand more funding for public schools, I was standing next to Deborah Cornelison, a veteran science teacher, in the courtyard of Byng Junior High School. At 11 a.m., the school’s only outdoor space was already hot, and a group of teens moved underneath a large beige canopy to catch some shade. The protective canvas—spread over half of the school’s only outdoor space—is there thanks to students in Cornelison’s physical-science class. In 2008, four ninth-graders investigated the harmful effects of ultraviolet radiation, tested different types of shade materials, and—in a district with limited resources and no wealthy PTA—raised funds to purchase and install it.

One of five schools in a rural southeast school district, Byng serves mostly white and American Indian students in Pontotoc County, the home of the Chickasaw Nation. The district, located in a tiny community of about 1,100 residents, was lucky to be open on a Friday: Nearly one-fifth of public schools in Oklahoma have shortened the school week to four days to help fill the gap caused by the budget cuts. From 2008 to 2015, Oklahoma cut its spending on public schools by 23.6 percent—more than any other state.

The canopy is one of many ways in which students in this rural school serving 320 teens have used science projects for class to improve their community. Cornelison’s students have also pressed their school to change heating and cooling practices to reduce the elevated levels of carbon dioxide they found in the classrooms, lobbied for healthier food options in the school cafeteria, and developed stronger school-emergency plans, such as yearly lockdown drills, which inspired a state law that extended them to all campuses in 2007.

Projects like these earned Cornelison, who now works as a trainer of principals and teachers at the Oklahoma Department of Education, national recognition during her tenure at Byng from 1988 to 2014, as well as a spot in the National Teachers Hall of Fame. Meanwhile, her students have traveled across the country, often flying on an airplane for the first time, collecting  more than 300 awards at local and international science competitions, including some of the world’s most prestigious. For many students, access to the competitive science-fair circuit also brought acceptance letters to coveted universities, internships, and eventually a career in stem, law, health care, and other fields.

Jobs in the stem fields are among the fastest-growing occupations in America, according to the Pew Research Center. But as with girls and people of color, students from rural areas have been mostly left out of the push to prioritize stem, and many, like Cornelison—a proud third-generation Oklahoman—don’t want to leave their hometown for a job at a big company like Google or General Electric. That’s why Cornelison’s approach to science education sought to orient her stem teaching around students’ ability to take what they learn and improve their communities—regardless of what discipline they choose as a career. Science in Cornelison’s classrooms was just as much about the future of innovation as it was about values such as self-sufficiency, work ethic, and collaboration.

These beliefs run deep in the tallgrass prairies and oak savannas of rural Oklahoma. Cornelison grew up on 160 acres of farmland near the town of Seminole, where she was a straight-A student in a class of just 16 students.

Each year, Cornelison competed in the fall county fair, where locals showed off their harvest bounty, farm animals, and handmade arts and crafts. Whenever the awards were announced, Cornelison’s family rushed to the winning entries to see how they could improve their methods. “You learned to view every failure as an opportunity to learn from your mistakes,” says Cornelison, who competed for the first time when she was in fifth grade, submitting a hand-stitched handkerchief. “And you internalized the idea that those who won succeeded because of their effort and persistence, not because they were born good gardeners.”

A local nonprofit helped students like Cornelison send in submissions for the fair and participate in other regional competitions promoting research and presentation skills, among others. Cornelison later traveled to a nearby town to participate in a speech contest at which she presented a research project on tornado-precaution procedures.

Even though Cornelison was a top student in her school, she credits extracurricular activities like these with the development of important career and life skills such as self-reliance and the value of hard work. These activities, Cornelison told me, connected concepts she learned in school textbooks to the daily concerns of rural life—and served as inspiration for Cornelison to change traditional science classrooms dominated by lectures and formulaic lab work.

At its core, Cornelison’s philosophy of teaching science can be summed up in four tenets. One, students should practice what scientists do: Observe the world and ask questions, set up rigorous experiments, and gather and interpret data. Two, young adults will be motivated if they’re given a choice over the topics they investigate. Three, learning science through research projects teaches not only academic content but also social and emotional skills such as problem solving and resilience, which research shows are greater predictors of life success than are standardized-test scores. Four, when teachers encourage students to research and implement solutions to problems in their communities, they develop key citizenship skills, such as a sense of agency and social responsibility.

Eleven years into Cornelison’s teaching, a ninth-grader named Maghen Petty became the first student in Byng’s history to win an award at the prestigious Intel International Science and Engineering Fair. (Last year, the Intel fair had 1,500 competitors from 75 countries.)

In 2004, another of Cornelison’s students, Cortney Cowley, placed fourth at the Intel science fair. Now an economist at the Federal Reserve Bank of Kansas City, Cowley told me that she wasn’t interested in science until she worked with Cornelison, who gave her the first opportunity to research a topic that she’d been curious about her entire life. Cowley grew up in a home with a wood-burning stove for heat, and wanted to know why ashes discarded in her backyard sometimes worked as a fertilizer and at other times destroyed all plant growth for years.

Cornelison encouraged Cowley to investigate the topic, which Cowley summed up in a 10-page class research paper. Cowley enjoyed the process of researching her own questions so much that she asked Cornelison to mentor her on another project—this time, investigating fungi in indoor air, which landed her at the Intel science fair and eventually as a doctoral student in agricultural economics.

Sometimes students joined the teams participating in science fairs after hearing about them from friends. That’s how Sarah Jones, another of Cornelison’s former students, joined the shade project in 2008. At first, Jones thought it would be a fun way to compete for a trophy, but she ended up enjoying the challenging process of gathering data using ultraviolet radiation meters, and then promoting the canopy to the school community and fund-raising for it. Now working in the Chickasaw Nation’s communications department, she learned the most important career skills through her science research. “In my job, I have to solve problems on my own every day,” Jones told me. “I learned that independence and a strong work ethic in Ms. Cornelison’s class.”

Today, Cornelison continues to advocate for the importance of learning through research projects in her current job at the Oklahoma Department of Education. On one hand, the audience for her message has grown much larger as project-based learning has become increasingly popular over the past five years. Yet many resources that contributed to Cornelison’s success have withered amid the budget cuts in the state, coupled with increased pressure to prioritize high test scores in math and reading.

Byng Junior High can’t afford to offer an elective class that teaches year-long research projects, Kevin Wilson, the assistant superintendent of Byng schools, told me. Last year, investment in stem education had grown so sparse that a retired teacher donated $50,000 to save the Oklahoma State Science Fair from shutting down.

Meanwhile, many skilled educators are leaving for jobs in other states, making teaching through projects—which requires more training and experience than teaching through lectures and exams—less tenable.

The walkout in April resulted in a 5 percent pay raise for teachers in Oklahoma—among the lowest paid nationwide—but no significant increases in funding for public schools. Some teachers took on an additional gig: running for office. In the state primaries this year, 64 teachers filed to run, a higher number than in any other state, according to an Education Week analysis.

Cornelison remains focused on inspiring schools and students to embrace stem in spite of the low priority the state has placed on  education in recent years. The renewed sense of solidarity among teachers keeps her optimistic that, in spite of the budget cuts, her vision of a robust, hands-on stem education in the Sooner State will ultimately prevail.



In 1995, the University of Vermont sociologist and historian James W. Loewen published a book that sought to debunk the myriad myths children were often taught about the United States’ past. Framed largely as a critique of the history education delivered in America’s classrooms but also serving as a history text itself, Lies My Teacher Told Me was the result of Loewen’s analysis of a dozen major high-school textbooks. It found that those materials frequently taught students about topics including the first Thanksgiving, the Civil and Vietnam Wars, and the Americas before Columbus arrived in incomplete, distorted, or otherwise flawed ways. Take, for example, the false yet relatively widespread conviction that the Reconstruction era was a chaotic period whose tumult was attributable to poor, uncivilized governance of recently freed slaves. Textbooks’ framing of the history in this way, according to Loewen, promoted racist attitudes among white people. White supremacists in the South, for example, repeatedly cited this interpretation of Reconstruction to justify the prevention of black people from voting.

Loewen didn’t veer from his conclusions with the second-edition release of Lies My Teacher Told Me in 2007, for which he analyzed six new history textbooks. The books’ treatment of what were then new developments, such as 9/11 and the Iraq War, reinforced his belief that history education in the U.S. is fundamentally broken.

Now, with the release this summer of a new paperback version of Lies My Teacher Told Me, Loewen contends that his bestselling book has “new significance … owing to detrimental developments in America’s recent public discourse.” By providing students an inadequate history education, Loewen argues, America’s schools breed adults who tend to conflate empirical fact and opinion, and who lack the media literacy necessary to navigate conflicting information. I recently spoke to Loewen about how the quality of Americans’ history education could affect the country’s civic health. An edited and condensed transcript of our conversation is below.

Alia Wong: What’s changed with regard to your thinking on history education since the first edition came out in 1995? What about since the second edition in 2007?

James W. Loewen: Not much has changed in my thinking, and that’s because I think I was right in the first place. What has changed has to do with our current intellectual era. History and social studies, as taught in school, make us less good at thinking critically about our past. For one, textbooks don’t teach us to challenge, to read critically—they are just supposed to provide exercises in stuff to learn. Secondly, the textbooks (and the people who teach from those textbooks) don’t teach causality. They aren’t designed to have students memorize anything about causality—what causes racism, for example, what causes a decrease in racism. That means that those of us who are more than 18 years old and are out of high school and voting may have never had anybody teach us anything about what causes what in society.

Wong: How do you think inadequate history education plays into what some describe as the country’s current “post-truth” moment?  

Loewen: History is by far our worst-taught subject in high school; I think we’re stupider in thinking about the past than we are, say, in thinking about Shakespeare, or algebra, or other subjects. We historians tend to make everything so nuanced that the idea of truth almost disappears. People in graduate history programs have said things to me like: Why should we privilege one narrative above others with the term “true”? That kind of implies that all narratives are equal—or, at least, that all narratives have some merit, that no narrative has all the merit. But maybe there is such thing as a bedrock of fact. Take the way we talk about the Civil War, for example. A lot of people will say that the war grew out disputes about tariffs and taxes; many others say it had to do with states’ rights. Well, it’s quite the contrary—the southern states seceded so they could uphold slavery. Sometimes we don’t need nuance.

Wong: How should teachers and history materials treat information that does deserve nuance?

Loewen: Textbooks should admit uncertainty. The very first thing that we teach in U.S.-history courses is when and how people first got to the Americas. The best answer is: We’re not sure. But the darned textbooks don’t say that—except for one of the 18 textbooks I studied intensively. Ironically, it’s the oldest one—it was published way back in the 1970s, and it says something like: The information in this section may be outdated by the time you read it. And by just saying that, it turns out to be the only textbook that is not outdated, even in 2018. All of the others conclude that the ancestors of Native Americans walked across the Bering Strait on a certain date. The consensus on that has broken down in the last 10 years. Textbooks could start right off by saying: We don’t know everything—isn’t that cool?

[History classes teach fictions about race in America.]

Wong: I was talking with a colleague about her history-education experience, and she recalls never learning what happened after the 1960s; I don’t remember my history classes ever extending beyond that period, either. Is that common? And if so, why is it that U.S.-history classes so often fail to teach students about the country’s more recent past?

Loewen: The recent past is always more controversial. It used to be that classes never even reached the war in Vietnam—even today that happens. Nobody’s going to get in a big fight with their parents about what their teacher said on the War of 1812, but what about when a teacher says the war in Vietnam wasn’t in our interest, that it was a terrible mistake, that it was done for domestic political reasons? What about when a teacher says that Bill Clinton shouldn’t have been impeached? Many Americans supported his impeachment, and a lot of those people are still alive, so teachers often decide: Let’s not emphasize the recent past.

I argue that anything with implications for the present is de-emphasized. For example, we can talk about slavery because it ended; it now has become an American success story because we voted it out and fought it out. What about racism, though? Racism was, of course, the ideological justification for slavery. Slavery and racism were tightly entwined, but while slavery ended in the 1860s, racism doesn’t just end. We should discuss what caused racism to endure. If you can’t use history to illuminate racism, what is history good for?

Wong: Isn’t it possible that history books are just really long, and that—perhaps because of poor planning—classes simply run out of time to teach the last few chapters?

Loewen: Certainly time pressure and the felt need to cover so many topics play a role. But I’d argue that that poor planning has an interest behind it because the earlier history is less controversial.

Wong: You write in the new version of Lies My Teacher Told Me that “there is a reciprocal relationship between truth about the past and justice in the present.” What do you mean by that?

Loewen: Take, for example, the way textbooks handle the incarceration of Japanese Americans during World War II. The practice was hardly a secret—at the time it was well covered in the press. But what did the textbooks say in 1947? What did they say in 1950, or 1960? Well, they said very little about the incarceration; they just had a couple of sentences, if anything, and sometimes they even tried to justify it. But then the country changed course and paid $20,000 to every survivor; the federal government issued a formal apology. After that, some textbooks have two whole pages on this, with pictures, denouncing the practice. Why did the textbooks do that? Now that they have justice in the present, it makes it easier for us to face the past. And the reverse is also true—it’s a two-way street.



The presidential-election cycle has barely begun but one thing is already clear: The Democratic candidates want to talk about student debt. No surprise there; the trillion-dollar student-loan bubble has captured the national imagination in ways few higher-education issues have, and candidates are essentially obligated to have a plan to address it.

But what is surprising—how quickly we forget—is just how recent a development this is. When Barack Obama was simply a senator running for the Democratic nod in 2008, the conversation around student debt and college affordability looked different—very different.

Just a dozen years ago, Democratic hopefuls such as Joe Biden, Hillary Clinton, and Obama kept their proposals limited. Biden wanted to increase the Pell grant, a federal grant for low-income students, by $300 a year; Clinton similarly pushed to increase the maximum. “The first bill Barack Obama introduced in the U.S. Senate would have helped make college more affordable for many Americans by increasing the maximum Pell grant from the limit of $4,050 to a new maximum of $5,100,” a fact sheet released by the Obama campaign read. The candidates also pushed to make a switch in how student loans were disbursed. The government, not private banks, they argued, should be the entity distributing federal student loans.

John Edwards, who was then the Democratic Party’s most left-flank candidate, proposed making one year of college free for “qualified students.” His plan included a work requirement, and students would have had to complete a college-prep curriculum and “stay out of trouble.” It was, at the time, radical.

Meanwhile, other candidates did not even have particularly fleshed-out higher-education policies at all. Dennis Kucinich, for example, simply issued a statement saying that he would “provide universal education to all Americans from pre-school through college.” (John McCain, who would ultimately become the Republican candidate, did not issue any statements on student aid until three months before the general election.) Student debt had yet to secure its position in the national zeitgeist, and the candidates’ policies reflected that.

By today’s standards, these proposals are peripheral, small-scale interventions that are simply no match for the debt people are dealing with. The higher-education proposals the Democratic candidates are rolling out today are aggressive. There’s Elizabeth Warren’s plan to cancel—yes, completely cancel—the majority of borrowers’ student debt. Bernie Sanders says he will make college tuition-free. Julián Castro is pushing to fundamentally reform how student debt is repaid. It’s remarkable, really, that in such a short time, Democrats have gone from proposing relatively modest tweaks to advocating a wholesale reimagining of higher education’s economics. This shift isn’t the direct result of a Democratic Party moving leftward—though that may play a role—but it is fundamentally rooted in something much more concrete, and much more pervasive: the exploding scale of the problem.

Julie Peller has a chart on a wall in her office in Washington, D.C., a relic of sorts from her time on Capitol Hill as an adviser to the U.S. House Committee on Education and Labor. It’s a useful cheat sheet she referred to when I asked her about the push among Democratic candidates ahead of the 2008 election to increase the maximum Pell amount, but it’s also a reminder that things were simpler then—even if they were technically complicated.

In January 2007, just a shade over six months after Peller, now the executive director of the education-policy nonprofit Higher Learning Advocates, joined the committee’s staff, the House passed a spending bill that gave Pell its first boost since 2003. Pell grants, created in 1972, are funds intended to form the foundation of the financial-aid package for low-income students, and do not have to be repaid. “In 2003, it had a $50 increase, and then it was flatlined at a maximum of $4,050 until 2007,” Peller pulled from the chart. The 2007 bill gave Pell a $260 boost—increasing the maximum to $4,310, and that was significant. “The purchasing power of Pell had really decreased by staying flat and tuition prices going up,” Peller said. “And there was a thought that it was overdue for an increase because it had been essentially flatlined for at least five years.”

Democrats would tuck away the messaging about the grant’s purchasing power as debates about Pell evolved over the next several years. But before they could have that conversation, there was another, more pressing matter. Pell covered only a piece of education for only a slice of the public—low-income students. And often, students were turning to private-industry loans to pay for the rest. At the federal level, public pressure to reform the student-loan industry was becoming unavoidable.

Since 1965, the federal government had provided subsidies to banks such as Sallie Mae to lend money to students. The program, called the Federal Family Education Loan (FFEL) Program, was a regular whipping post for Democrats. They wanted to switch to something different—direct lending to students from the federal government—and several of the 2008 presidential candidates, including Obama, Clinton, and Biden, made doing so a foundation of their higher-education platform.

“I can’t overstate the extent to which the fight over direct lending versus FFEL really sucked up all the oxygen,” Ben Miller, the vice president of postsecondary education at the Center for American Progress, a liberal think tank, told me. It was hard, he said, to have any other conversation about completion (whether students who enroll in college eventually graduate) or affordability “while people were fighting about the best way to issue a federal student loan.”

Getting rid of bank-based lending would have served a dual purpose: By eliminating the subsidy for banks, it would have freed up money to increase the maximum size of Pell grants and the number of them that were disbursed. And students would need the extra Pell money.

President Obama was air-dropped into a crisis when he was sworn into office. A recession had hit, and it was changing the ways Americans lived, worked, and, as it would happen, went to college. Enrollments exploded at state universities, private colleges, and for-profit colleges—and so did the number of Pell recipients. From 2006 and 2011, total college enrollment grew by 3 million, according to the U.S. Census Bureau. Two-year-college enrollments grew by 33 percent during that same time.

Meanwhile, state funding for universities began shrinking dramatically. At the peak of the recession, state appropriations per student were down, on average, more than 13 percent, which meant colleges relied more heavily on tuition for revenue. That, in turn, meant that students had to pay more for their education, at the precise moment they had less money to do so. And middle- and high-income students who could no longer borrow on their parents’ home-equity lines to pay for college turned to bank-based student loans. “If you just look at the trends in borrowing from the pre- to postrecession, it’s a massive swing,” Miller said. “We added millions of [student] borrowers so quickly.”

By 2010, after the recession had ended and the economy had begun to pick up again, President Obama had moved on to more proactive legislation: namely, his campaign promise to get rid of bank-based lending to students, and to replace it with direct loans from the federal government. In March of that year, he succeeded. Congress approved an overhaul of the student-loan system, barring private banks from issuing loans with federal money, implementing a federal-lending program, and, as The New York Times put it, “ending one of the fiercest lobbying fights in Washington.” Ending that fight meant higher-education policy makers could think about the next one.

By March 2011, the administration was looking for its next big thing in higher education, and it had its eyes on affordability. That’s when Zakiya Smith Ellis, who now serves as the secretary of education for the state of New Jersey, joined the White House as a senior policy adviser. “The president was wondering: How do we actually make a dent in this?” she recalls. “You’re not going to get there by only focusing on increases to Pell.”

The initial results of the administration’s efforts focused on transparency. It launched the College Scorecard, which lets students compare costs of institutions, and created the Financial Aid Shopping Sheet, now known as the College Financing Plan, a tool designed to more clearly show students what their financial-aid packages would look like.

The 2012 election had few higher-education fireworks, partly because when politicians run for reelection, they run on their record. President Obama focused on increases to Pell, the switch to direct lending, and changes to income-driven repayment of loans. It was messaging that connected with voters because it was simple, Smith Ellis told me. “If you don’t earn that much, you don’t have to pay that much. That makes so much sense,” she said. “Simplicity matters when you’re talking about politics to people… If people can’t explain it, then they don’t understand what your policy is and what it does to them in a very clear way.”

As politicians were trying to suss out a clear way of addressing student debt, it was growing. By 2013, the student-loan portfolio had reached $1 trillion, and it was rising rapidly. This was not a result of Obama-era policies, but rather the natural outcome of 3 million additional students who were borrowing more money as states were spending fewer and fewer dollars on higher education.

What the federal government was struggling with, some state and local leaders were addressing. Across the country, a handful of state and local governments had been creating “college promise,” or as they’re commonly known, “free college,” programs. Tennessee launched the Tennessee Promise in 2014; the city of Chicago launched a free-two-year-community-college program. And in January of 2015, as President Obama stood before Congress and delivered his annual State of the Union address, he brought the idea to a national stage. “I want to spread that idea all across America, so that two years of college becomes as free and universal in America as high school is today,” he said. The president began pushing for his America’s College Promise proposal, which would have offered two years of community college free to “responsible students.” This was, at the time, an ambitious idea, but four months later, Obama was one-upped. Senator Bernie Sanders, who was vying for the presidency in 2016, announced his plan to make public colleges and universities tuition-free for all.

“It may seem hard to believe, but there was a time when higher education was pretty close to free in this country, at least for many Americans,” Sanders wrote in The Washington Post a few months after first announcing his plan. “It is time to build on the progressive movement of the past and make public colleges and universities tuition-free in the United States—a development that will be the driver of a new era of American prosperity.” If Obama lit the match, Sanders, as part of his primary bid, doused it in kerosene.

For years, Smith Ellis said, politicians had been saying that they would make college more affordable, but that begged the question: What is “more affordable”? Sure, there were calls to increase the Pell grant to put college within reach, but “that does not mean anything in terms of the tangible What is it that I pay in your ‘more affordable’?” she said. “The thing people really gravitated to with [Sanders] was, ‘I get that this “more affordable” means I won’t have to pay tuition.” Of course, there are other costs associated with college, but tuition-free college was a sticky, easy-to-understand concept that, once planted, all other ideas had to compare with.

Separately, a month after Sanders released his plan, Senator Elizabeth Warren announced a debt-free college plan—one that went beyond Sanders’s to include costs other than tuition, such as books, housing, and food. But this was hardly the party line. These were two of the most progressive Democratic senators proposing progressive policy. Most of the party’s leaders were still supporting smaller-scale interventions such as tying the Pell grant to inflation or student-loan refinancing.

This divide was put on display in February 2016 during the fifth Democratic debate, where Hillary Clinton and Sanders squared off. “I … believe in affordable college, but I don’t believe in free college,” Clinton said, “because every expert that I have talked to says, ‘Look, how will you ever control the costs?’ What I want to do is make sure middle-class kids, not Donald Trump’s kids, get to be able to afford college.” Sanders retorted that he knew a way to control the costs. “It’s an expensive proposition,” he said. “We pay for it, in my view, by a tax on Wall Street speculation. The middle class bailed out Wall Street in their time of need. Now it is Wall Street’s time to help the middle class.”

Clinton began to feel the pressure of a shift that, despite its bubbling up at the state level, had caught policy experts by surprise coming from a presidential candidate. By July 2016, Clinton had her own free-college proposal: making public college tuition-free for students from families who made less than $125,000 a year. Sanders called Clinton’s proposal a “very bold initiative,” adding that “the final product is the work of both campaigns.”

The idea of free college went dormant on the federal level after Donald Trump was elected. Sure, Democrats such as Senator Brian Schatz of Hawaii proposed legislation to make college “free,” but there were no reasonable expectations that it would move. Senators Kamala Harris, Kirsten Gillibrand, and Cory Booker, all candidates for president in 2020, signed on to Schatz’s bill.

The Democrats did not have power in either chamber of Congress early in the Trump presidency, so new legislation they introduced was largely for messaging purposes. Their primary, comprehensive offering on higher education came with the Aim Higher Act, which was notably more modest than the one-off free-college bills. It offered expanded Pell grants, free community college, and a crackdown on for-profit institutions. But the bill also played to a conventional wisdom. As Amy Laitinen, the director of higher-education policy at New America, a liberal think tank, put it to me, “In a world where we have financial constraints, and where we don’t have unlimited resources, or even a huge infusion of new resources, the truth is, choices are going to have to be made about where dollars are spent.” For congressional Democrats, the priority seems to be on expanding resources to available programs.

But presidential elections are times when parties can play around with—and possibly embrace—new, previously out-there ideas. They make room for the land of what’s possible, the landscape that could be. And as candidates have come to recognize that a growing share of the electorate is saddled with student-loan debt, those reimagining the landscape are taking more of a slash-and-burn approach than manicuring the hedges, whether that’s Warren’s proposal for large-scale debt cancellation, Harris’s push for debt-free college in her campaign launch, or Sanders’s ongoing cry for free college.

“There’s this feeling that this stuff that’s tinkering around the edges isn’t working,” Miller said. And a presidential election is a time when the hope that things will change still feels real.



Students at Howard University occupied the campus’s Johnson Administration Building in protest in 1968. They did so again in 1989. Those occupations lasted four and five days, respectively, and ended with varying degrees of success. Now, current Howard students are in day seven of an occupation of their own. It is the longest takeover of the building in the institution’s history.

The dynamics currently driving campus activism are coming to a head at the illustrious historically black university in the nation’s capital. And Howard's experience, and in particular the unprecedented length of the students’ protest—even though the university may never meet their demands—may be a harbinger for the sort of tenacious pushback on long-simmering issues that other college leaders might soon encounter.

In late March, a student organization “dedicated to the liberation of Howard University” called HU Resist released a list of nine demands, which ranged from reasonable to extreme. Some of the demands are broadly reflective of student grievances across the country: The protesters want the administration to do more to address campus sexual assault, provide more support for mental health care, and curb tuition hikes. Other demands were more Howard-specific, and a few of those were quite far-reaching: Students want the power to “directly propose new policies and revise existing policies”; ratify all hiring of administrators, trustees, and faculty; and most of all, they want the resignation of the university’s president, Wayne A.I. Frederick, whom they blame for many of the university’s issues and who, they argue, is too cozy with the Trump administration.

The group posted their demands on Twitter on Sunday, March 25. Then, two days later, scandal struck the campus: An anonymous whistleblower released information alleging that a handful of employees appeared to have, for years, embezzled financial-aid money. The university acknowledged that it had learned of the potential misuse of funds in 2016 and had conducted an investigation. Six employees had been dismissed for “gross misconduct and neglect of duties,” according to a statement from the university. Many students are now wondering why they weren’t alerted sooner, and questioning the university’s commitment to transparency. Two days after that, on Thursday of last week, HU Resist students started to fill the administration building in protest. At 3:04 in the afternoon, HU Resist tweeted: “We’ve taken the administration building #StudentPowerHU.” The occupation had begun.

President Frederick, who had already been speaking to media and issuing statements after the news of the financial-aid scandal spread, responded to a handful of the student grievances the following day. “I want you to know that I hear you, and my team and I are committed to being responsive to your needs,” he wrote in a statement. “I am listening to you, and I am challenging my team to make the changes you are expressing a dire need to see.”

He noted that the campus was in the process of finalizing a new policy regarding the university’s processes and procedures for handling sexual violence and that the university would hire additional student counselors as demand for them grew. But he did not budge on several of the other complaints. The administration, as is often the case on college campuses when students protest, was caught in a difficult position: It may want to hear and address students’ concerns, but it is also faced with the financial and logistical realities of running a university.

Over the next several days, as the protest drew national attention, there was a war of statements. Faculty announced its support of the students. The Council of Deans and the alumni association sided with the administration. Rihanna weighed in (applauding the protesters). Supporters donated water and pizza to keep the students, roughly 400 at any given time, hydrated and fed. And the students have had a handful of meetings with members of the Board of Trustees—one of which ran until after 2 o’clock in the morning.

The students are getting results. Some of their demands have been met, Maya McCollum, a freshman journalism student who is a part of HU Resist’s leadership committee, told me. The university agreed to extend the deadline for submitting housing deposits until May, and if enough students requested campus housing, the institution would delay renovations to accommodate them, according to the student newspaper. But the group is not yet satisfied, and they’re prepared to stick around until they are.

Howard is one of the most recognizable black colleges in the country, and those institutions face their own unique set of challenges. But many of the issues historically black colleges and universities are in no way specific to them. Walter Kimbrough, the president of Dillard University, a private historically black institution in New Orleans, argued last year that higher-education leaders could learn a lot from black colleges, if only they would pay attention. Oftentimes these colleges are written off as a provincial portion of higher education rather than something integral to it, but they have valuable cautionary tales to share.

Kimbrough saw firsthand how one such cautionary tale was overlooked. In November 2016, before the election, Dillard was roiled by controversy following an appearance at a debate on campus by David Duke. “It signaled that we were in an era when rational dialogue and debate had been abandoned for the high of in-your-face confrontation,” Kimbrough wrote, “with social media as an accelerant.” Months later, Middlebury College and the University of California, Berkeley, became similar flash points. Likewise, a previous takeover of the administration building at Howard—the one in 1968—came weeks before the more widely remembered Columbia University occupation.

McCollum says the students are discussing whether to discontinue the protest without all of the demands being met, as students did in 1968, including their chief demand of Frederick’s resignation—though, she noted, the general consensus among protesters right now is that they will not relent without a resignation. The president currently faces a vote of no confidence by the faculty.

The students at Howard see power and want more of it. “This entire protest is dictated not by the resignation of the president,” McCollum says, “but by the ideal of student power, and letting students have a bigger voice on their university’s campus.” What’s striking—as other campuses may soon find—is not what they are asking for, but their commitment to getting it.



It is a very odd thing to think of myself as a school-shooting survivor. The first time I acknowledged that I was a survivor was on October 5, 2018, when I attended an event as a guest of Everytown for Gun Safety. I went over to the Moms Demand Action table to sign up to be a volunteer. As I filled out the form, I stared at the question asking how I was connected to gun violence. I stood there for what felt like an hour. Finally I checked the box to indicate that I was a survivor of gun violence. I had never thought of it that way before.

I wasn’t in Building 12. I didn’t see anyone get shot. I never saw the shooter. I didn’t think of myself as a survivor. When I said that to my husband, he told me that I absolutely was. I was on campus that day. I heard the shots when I got outside after the fire alarm went off. I returned to my classroom, where I kept 15 students safe in my classroom for two and a half to three hours, until the SWAT team entered my room. I might not have seen anything, but I was there and didn’t know whether I’d be next.

I remember the day vividly. It’s the hours, days, and weeks following that are a blur. I went to school the morning of February 14, 2018, to give a quiz to my senior English classes. I joked that I was ruining their Valentine’s Day by giving them the quiz. To make them smile, I put Hershey’s Kisses on their desks. Later that day, 20 minutes before school ended, my world changed forever. I left school shattered, broken, lost.

On February 15, I did a 12-hour media marathon, appearing on TV stations across the country. It was surreal to stand across the street from my school and talk about an event that had happened less than 24 hours before. In the afternoon, I attended a vigil at Pine Trails Park, a mile north of the school. I saw students who I had seen only the day before, but it felt like a lifetime ago.

On February 16, I attended the funeral for Meadow Pollack, whom I had as a freshman in my English class. That was the first time I cried since leaving the school two days earlier.

On February 17, I met with my yearbook staff. I told them how much I loved them, and how glad I was that they were safe. Several members of the staff not only were in Building 12, but were in the classrooms the shooter turned his gun on. They watched their friends and classmates die. They were injured. If the shooting had happened one day later, it would have taken place during yearbook class. I couldn’t wrap my head around how many of them could have been traveling around the building getting quotes, or taking pictures. The thought that I could have lost anyone was too much to take. I began to cry. They cried too.

On February 18, I attended the funeral for Jaime Guttenberg, who was in my Journalism 1 class that year.

After that, I don’t know what I did most days. I just know that I tried to keep myself busy.

On February 23, I went back to school for the first time. I entered my classroom, and it looked like a freeze frame of the moment before the shooting, like time had stood still. The date February 14 was still on the board; the quizzes were still on the desks; students’ phones were still plugged in; the computers were still on. I began to have an anxiety attack and couldn’t breathe. I had to get out of there. I was in the room for a total of five minutes.

When school resumed on February 28, I hugged each one of my students. I told them that I would always be there for them. Within the next few weeks, my students started opening up about what they had experienced. I never prompted them. I always listened. It broke my heart that these things had happened at all, but especially to children—because that’s what they are.

In the months that followed, we put together a yearbook like no other; one that was perfect, that honored the victims. We added pages for profiles of those we had lost, and yet more pages to cover what happened that day and in the weeks after. I edited and published a book, Parkland Speaks, that features Parkland students’ writing about that day. I have worked hard to take care of myself. I see a psychologist weekly. I also spent much of 2018 planning my son’s bar mitzvah, which was last month. That would have stressed me out in a different period of my life, but it  turned out to be a nice diversion from the stress and pain that permeated every other second. It was nice to make sure he felt special and to not focus so much on myself. Perhaps this was my way of putting off the feelings I knew I’d have as February 14 drew close again, but I was okay with that.

Moving forward, I plan to take things one day at a time. That’s really all I can do. I’m a survivor, after all.



The War on Drugs locked up thousands of black men, and a new study finds that it may have also locked many out of the college classroom—and all the benefits that come with a college degree.

There was a time when black men’s college enrollment was gaining ground, as compared to white men’s. From 1980 to 1985, college enrollment among black men ages 18 to 24 grew slightly faster than it did for their white peers.

However, the upward trend started to reverse for black men after the passage of the Anti–Drug Abuse Act of 1986. According to the study, the probability a black man would enroll in college declined by 10 percent due to the passage of the law, from 22 percent to 20 percent, after researchers controlled for other factors, such as changes in the state-level unemployment rates and the costs of college. The study, written by the University of California, Berkeley professor Tolani Britton, appears to be the first to establish a direct link between ’80s drug laws and college achievement.

Decreased college enrollment has life-long consequences. Only 24 percent of prisoners have some college education, compared with 48 percent of the general public. Without a college degree, the odds of obtaining stable, well-paying employment are even lower; bachelor’s degree holders earn $21,632 more a year than individuals with only a high-school diploma, according to the Bureau of Labor Statistics.

As the government spent more money sending black men to prison, it devoted fewer resources to programs that would have helped the formerly incarcerated reenter society after they were released. In 1996, Bill Clinton’s administration passed a law barring drug felons from support services such as food stamps and welfare. Without the added economic security these programs provide, the formerly incarcerated are likely to struggle to pay for college on their own: 44 percent of community-college students are employed part- or full-time.

The War on Drugs also includes a slate of policies that make it nearly impossible for someone with a drug conviction to access financial aid for college. In 1994, the Clinton administration passed the Violent Crime Control and Law Enforcement Act, which made prisoners ineligible for Pell grants, educational grants that help low-income people pay for postsecondary education— including college programs specifically offered in prisons. In addition, the 1998 aid-elimination amendment to the Higher Education Act denied any federal aid to students who were convicted on drug-related charges while receiving  federal aid, further limiting financial aid to drug felons.* While Pell grants were experimentally reintroduced to some prisoners in 2015 by Barack Obama’s administration, most incarcerated and formerly incarcerated people are still ineligible for federal aid today.

What’s more, prior convictions can block students from admission to college. Some colleges ask for a criminal history in their application process, and studies have found that having a conviction dramatically decreases the likelihood of admission, even when controlling for all other factors.

Without a college degree, steady employment, and support services, formerly incarcerated people struggle to rebuild their life. Fifty percent of felons are rearrested, and 25 percent are re-incarcerated within eight years of their initial release from prison. Access to education could lower these high recidivism rates. Prison education has been found to reduce re-incarceration by 13 percentage points and increase the odds of employment by 13 percent.

These prison education programs also benefit society. According to the Vera Institute of Justice, a nonprofit research institute that advocates against mass incarceration, the programs save American taxpayers $366 million a year by reducing recidivism; increase public safety by reducing crime; and support businesses by providing a trained workforce.

However, only 6 percent of incarcerated people have access to a college program at their institution today. Programs such as Sinclair Community College at Dayton Correctional Institute and the Prison University Project at San Quentin State Prison, where I previously taught a course, provide college education to inmates. But these programs are limited without federal funding, relying mostly on state-correctional-department support, volunteers, and philanthropy to run effectively. Federal funding of prison education can provide consistency to these programs.

Critics ask why federal money should be spent on educating felons while law-abiding citizens also have limited access to higher education. Initiatives such as Elizabeth Warren’s free-college proposal can address this issue for Americans broadly, but ultimately fail to address the specific, damaging effects of the War on Drugs. “We as a society need to increase not just access but success in postsecondary education for people who are incarcerated or formerly-incarcerated,” Britton says. “Because that is one of the few ways for people to change not only their outcomes, but their children’s life outcomes.”

*  This article has been corrected to reflect that formerly incarcerated individuals are not ineligible for Pell grants. Additionally, only students who were on federal aid at the time of a drug-related conviction are ineligible for aid, not all students with these convictions. 



Editor's Note: In the next five years, most of America’s most experienced teachers will retire. The Baby Boomers are leaving behind a nation of more novice educators. In 1988, a teacher most commonly had 15 years of experience. Less than three decades later, that number had fallen to just five years leading a classroom. The Atlantic’s “On Teaching” project is crisscrossing the country to talk to veteran educators. This story is the second in our series. Read the first one here.

“I want to say something important about writing,” Pirette McKamey told 25 seniors in her English class at San Francisco’s Mission High School one fall afternoon in 2012. It’s incredibly hard, and always incomplete, she explained. “I’ve reread some of my essays 20 times and I still go, ‘I can’t believe I made this mistake or that mistake.’”

“I’m going to read a powerful essay as a model today,” said McKamey, who frequently shares her students’ work at the beginning of class as a way to showcase examples of effective and creative approaches to writing. She appreciated the student’s paper for “the heft of its content,” she told the class. “It also feels real. It was written with real engagement and honesty.”

In his essay, one of McKamey’s students wrote about his life ambitions, including his desire to become a musician. He compared his goals with those of two other individuals, chosen from the many real and fictional people the students had studied earlier that year in a five-week-long unit titled “Quests.” The vision behind this unit was rooted in McKamey’s observation that as teenagers approach adulthood, they want to examine how people from different eras and cultures have defined values such as success, goodness, and courage.

After McKamey finished reading the essay, students discussed what made it work—and which approaches they could employ in their own writing. As the discussion winded down, McKamey passed out a grammar worksheet.

Today, there is a growing consensus that students need strong writing skills to succeed in the workplace and to fully participate in society, but educators passionately disagree on the best ways to teach those skills. Some call for greater focus on the fundamentals of grammar: building vocabulary, identifying parts of speech, and mastering punctuation. Others believe that students need more opportunities to develop their writerly voice through creative expression and work that allows them to make connections between great literature and their personal lives.

Meanwhile, it appears that many of the methods seem to be falling short: Results from the most recent National Assessment of Educational Progress suggest that only one in four 12th- and eighth-graders is meeting grade-level expectations in writing. In both tested grades, Latino and African American students scored lower than their peers in other racial and ethnic subgroups.

[The best writing teachers are writers themselves]

McKamey spent 29 years teaching in majority black and Latino schools. Over the years, she observed that many of her students came into her classroom believing that they “don’t like writing” or are “bad writers.” Since McKamey first started teaching at San Francisco’s Luther Burbank Middle School in 1989, she has been refining her own methods to help dispel these self-perceptions.

In McKamey’s classes, this means that students must feel compelled to write every day. But rather than prioritizing the mechanics of sentence structure or writing rooted in personal experiences, McKamey’s students work on a variety of exercises, including punctuation worksheets, argumentative and narrative essays, poetry, fiction, and long research papers. And while McKamey’s methods have evolved significantly since she first started teaching, her goal has remained the same: help every student develop a portfolio of high-quality work, which will serve as irrefutable evidence that they are capable of writing.

McKamey’s approach to writing instruction was shaped in part by her own experiences as a high-school student. One of just a handful of African American students at a Quaker boarding school in Pennsylvania, she noticed that most of her teachers would return papers with feedback that focused on what she did wrong. Whenever McKamey’s teachers praised her in the classroom, their feedback usually centered on her personality—rather than her intellectual contributions. Fran Bradley, McKamey’s high-school economics teacher, was an exception. When McKamey asked a question or made a comment, Bradley would engage in an enthusiastic discussion about McKamey’s ideas. He often read passages from her work in front of the class.

Even though McKamey’s parents always told her that she was intelligent and a good writer—despite her uneven grades—Bradley made an effort to cite evidence showing the benefits of McKamey’s intellectual contributions in her writing. When McKamey felt valued for her intellect, she explained, she was more willing to engage with the classwork—and she produced some of her strongest academic writing.

McKamey’s years as a teacher were deeply influenced by the research of the social psychologist Claude Steele. Best known for his studies on what researchers call the “stereotype threat,” Steele uncovered a unique form of distress that suppresses academic achievement in certain situations—during tests for African American students or math classes for women, for example—when an individual has the potential to confirm a negative stereotype about his or her social group. Steele’s research found that certain actions by teachers or mentors can dispel these crippling anxieties—they can signal in their feedback that they hold a student to high standards while also citing spots in the work where the student meets the challenge, for example.

Pablo Rodriguez—a former student of McKamey’s, who moved to the United States from Guatemala in 2009—still remembers McKamey’s feedback on his first essay in her class. He recalls the stars dotting the paper next to specific passages, and comments such as, “This is so interesting. I never thought of it this way,” or “I’m so intrigued by the point you are making here. Could you tell me more what you mean by that?”

In the past, most of Rodriguez’s writing earned D’s and C’s, and his papers would come back with a lot of grammar corrections, Rodriguez, who is now 23 and works as a youth counselor, told me. This made him feel hopeless about his ability to write. “Ms. McKamey taught me skills to deal with my weaknesses,” Rodriguez explained. “But she saw my strengths and it made me feel motivated. I wanted to write essays that would make Ms. McKamey love it more than anything she’s ever read, and I started spending hours at the library rewriting my papers.”

McKamey argues that the most important skill for a teacher is his or her ability to build trust with a student, which develops when students can sense that the educator is willing to hear their ideas, thoughts, and musings despite their challenges with grammar, low grades, or test scores in previous classes. This doesn’t mean that teachers need to cushion their feedback with fake praise, but it does mean, she thinks, that schools should help teachers develop skills to recognize what all students, including those who might be considered “low achieving,” do in their classrooms—instead of focusing mostly on what they don’t do or know.

[A educator witnessed school desegregation—and resegregation]

“Just because I struggle with some grammar rules doesn’t mean I can’t think deeply,” says one of McKamey’s former students, Ajanee Greene, who’s now 23 and a student at Jackson State University. In 2012, McKamey says, Greene wrote one of the strongest research papers McKamey had read in her classes, even though she had received a D in English at another school. Her 12-page final paper explored how the long history of racial exclusion contributed to violence in black communities—and affected her own family in San Francisco.

“The newspapers talk about the violence, but they don’t talk about a much bigger epidemic—the private pain of families who are left to live with the aftermath” of that violence, Greene, who became the first in her family to graduate from high school, wrote in 2012. “Personal, private, solitary pain is more terrifying than what anyone can inflict. The violence stays with families and becomes a part of their lives. Nobody feels the same and family relationships get strained. This causes more pain, and the cycle intensifies … The psychological damage destroys communities more than unemployment and poverty.”

For her paper, Greene had read and analyzed 20 articles and studies, interviewed neighbors, and added her own point of view. Before McKamey’s class, Greene had never written a research paper. “Ms. McKamey believed in me and then pushed me to work really, really hard,” Greene explained. She ultimately got an A- in McKamey’s class.

Drawing on the methods she uses in her English classes, McKamey has been coaching other teachers across all subjects for about a decade now. As part of this process, teachers meet in small groups where they review the work of middle-achieving students who have made a recent shift—went from chronic C’s to an A- in a recent essay, or analyzed passages more deeply, or showed intellectual engagement instead of just trying to get a good grade. Teachers then share practices that contributed to the growth in that student’s skills: verbal or written feedback, more explicit instruction in the components of academic writing, or reading student work in front of the class, among others.

Analyzing the work of middle-achieving students—rather than just failing or thriving ones—can significantly improve teachers’ effectiveness with underachieving students, McKamey argues. When teachers focus on the work of the lowest-achieving students, McKamey has observed that such conversations often turn into a space to blame the students, their parents, or other teachers, or they veer off into emotionally invasive discussions of a student’s private life. Focusing on middle-achieving students who showed recent improvement helps teachers dispel unrecognized stereotypes—and learn how to notice and build on their strengths. (One study found that white teachers graded black and Latino students more harshly for the same performance, accounting for as much as 22 percent of the achievement gap.)  

“The task is to educate all students in front of me,” McKamey reflected. “There are so many opportunities to miss certain students: not see them, not hear them, shut them down. Despite years and years of teaching, there are times when the student is communicating something to me and I can’t hear their thinking at the moment, but I can’t ruin it. I have to keep it alive.”



Editor's Note: In the next five years, most of America’s most experienced teachers will retire. The Baby Boomers are leaving behind a nation of more novice educators. In 1988, a teacher most commonly had 15 years of experience. Less than three decades later, that number had fallen to just five years leading a classroom. The Atlantic’s “On Teaching” project is crisscrossing the country to talk to veteran educators. This story is the fourth in our series. Read the first one here, the second here, and the third here.

Robert Gleed was only 17 when, a few years before the start of the Civil War, he escaped from a Virginia slave owner. He was caught soon after near Columbus, Mississippi, and sold at an auction, and he didn’t gain his freedom until Union troops arrived in 1865. In the 10 years that followed, Gleed opened a general store; acquired 295 acres of farmland, three city lots, a home; and became one of the first black state senators in Mississippi.

On May 8 of this year, more than 150 years after 437,000 black Mississippians—the majority of the state at the time—gained their freedom, Dairian Bowles, a junior at the Mississippi School for Mathematics and Science, told Gleed’s story. Dressed in a black waistcoat and a white shirt with a high collar, Bowles stood in front of Gleed’s marble tombstone in Sandfield Cemetery, Columbus’s historic burial ground for African Americans.

In front of about 200 visitors, Bowles told of how, a little more than a decade after emancipation, Gleed lost his political power, his store, and his home. In 1875, after his term as a state senator, Gleed ran for the position of sheriff. The day before the election, a mob of torch-carrying whites surged through downtown, killing four black men. Gleed survived only because a white friend helped him hide in his well. Soon after, white townspeople claimed that Gleed owed them money, auctioned off his store, and pocketed the profits.

Bowles’s performance was part of the African American history class taught by a 25-year veteran teacher at the school, Chuck Yarborough. Each year, Yarborough gives his students in his African American and U.S. history classes a list of people buried in Columbus’s two historic cemeteries—Sandfield and Friendship, the latter the resting place of many Confederate soldiers. Most of the people on the list have never been researched before, so students spend months poring over primary records in the town’s archives. Their final project is a performance written and directed by the students, and anywhere from 100 to 2,000 people from all over the state show up to see them.

Among the moss-covered tombstones, students give voice to white, black, Jewish, and immigrant Mississippians, who more than a century ago—much as Americans do now—argued about who deserves the right to citizenship. But rather than prioritizing the debates of powerful leaders and the outcomes of bloody battles, which is common in history curricula across the United States, these students share stories that explore how the small, daily choices and actions of Columbus residents made Mississippi—and by extension, the country—what it is today.

The question of what students should learn about the Civil War, the role that slavery played in it, and the history of Reconstruction—the period from 1865 to 1876 when African Americans claimed their rights to freedom and voting, followed by a violent backlash by white Southerners—causes contentious disputes among educators, historians, and the American public. One outcome of these disputes is that ideologies often masquerade as historic facts. Texas’s 2010 standards, for instance, listed states’ rights and tariffs, alongside slavery, as the main causes of the Civil War—even though historians overwhelmingly agree that slavery was the central issue.

Another common problem is omissions: A 2017 survey of 10 commonly used textbooks and 15 sets of state standards found that textbooks treated slavery in superficial ways, and state standards focused more on the “feel-good” stories of abolitionists than on the brutal realities of slavery. When the same study surveyed 1,000 high-school seniors across the country, it found that among 12th graders, only 8 percent could identify slavery as the cause of the Civil War, and fewer than four in 10 students surveyed understood how slavery “shaped the fundamental beliefs of Americans about race and whiteness.”

Of course, students aren’t students forever, and the views of American adults are influenced by what they learn as children. When one 2015 poll asked American adults whether slavery was the main reason for the Civil War, 52 percent said that it was, while 41 percent said that it was not. In the same survey, 38 percent of adults insisted that slavery should not be taught as the main cause of the Civil War. That the country is divided on how to deal with Confederate statues and the Confederate flag follows in lockstep.

All this has motivated Yarborough to help his students explore the historical record; focus on primary sources, not textbooks; internalize, through performance, the stories of the people who lived through these times; and share their research with the community. He likes to paraphrase his favorite quote, by Elizabeth Cady Stanton, in his classes: “When women and men start to think, the first step in progress is taken.”

A sixth-generation Mississippian, Yarborough spent most of his childhood in Pass Christian, a small beach town on the Gulf Coast. Yarborough’s father drove to New Orleans every morning to work for Texaco as a geophysicist, while Yarborough’s mother raised five kids at home. In Yarborough’s telling, it was an idyllic childhood; he and his siblings went sailing, rode their bikes downtown to eat po’ boy sandwiches and play pinball, and spent hours reading books.

In elementary school, Yarborough became best friends with Otis Gates, who lived a few blocks away, and who was one of two African American students at the majority-white Catholic school both boys attended. In 1973, when Yarborough was a first grader, Gates invited him to his birthday party. A few moments after he arrived at Gates’s house, Yarborough realized that he was the only white kid in the large crowd of black children—even though Yarborough knew that Gates had invited all their white classmates.

Yarborough recalled this as one of the most formative moments of his youth, one that he often shares with his students. “I stayed the night at Otis’s all of the time, and he stayed the night at our house all of the time,” Yarborough told me. “But that day, it was highlighted to me that there was this big divide in our community. My entire career, I’ve been trying to step across that divide.”

While Yarborough and Gates were growing up, Mississippi became the center of one of the largest anti-integration movements in the country. In response to the Supreme Court’s Brown v. Board of Education decision ordering the integration of public schools, white segregationist organizations opened what became known as “segregation academies.” These were private schools—in part funded by the government through what became known as vouchers—that opened between 1964 and 1972 for the children of white parents opposed to desegregation. Hundreds of such academies were established, and at least 35 survive in Mississippi, including the Heritage Academy, on the Confederate Drive in Columbus. The schools recently became the brief focus of the nation’s attention when the Jackson Free Press reported that Mississippi Senator Cindy Hyde-Smith had attended one.

As Yarborough tried to understand the factors that fueled deep racial divisions in his state, he immersed himself in African American history. He majored in English at Vanderbilt University, and received his master’s degree from the University of Mississippi in southern studies, with a focus on black history and culture.

Since Yarborough first started working at the Mississippi School for Mathematics and Science, in 1994, he has taught students from all types of schools: former segregation academies, religious private schools, public schools, and charter schools. A public boarding school, the Mississippi School for Mathematics and Science teaches 248 students from all over the state who have come to spend their last two years of high school studying accelerated sciences, math, computer courses, the arts, and humanities. In a state with the second-highest rate for black poverty in the country, and a public-school system in which nearly a third of all districts have resegregated in recent decades, all the students I talked to at the school cited their highly integrated classrooms as one of the most valuable parts of their academic experience. (Eighteen percent of the students are black, 11 percent are Asian, 11 percent are mixed, and 66 percent are white.)

Each year, Yarborough surveys his students on what they know about the Civil War and Reconstruction. The feedback from the more than 1,400 students he has taught has been consistent: Out of a class of 18 to 20 students, about five come in with some basic knowledge of the Civil War, and a few have studied Reconstruction. “You can’t understand American history without understanding Reconstruction,” Yarborough argued. “Students have to understand the steps forward, racially and socioeconomically, that Reconstruction presents, and then steps backward that are taken with the violent reestablishment of white supremacy and the planter class being in control.”

Even though the U.S. history course for juniors in Mississippi is supposed to cover the period from 1877 on, Yarborough begins each year with the Civil War and Reconstruction. Students read Mississippi’s 1861 Ordinance of Secession, which, in Yarborough’s view, leaves little doubt that slavery played the key role in the Civil War. “Our position is thoroughly identified with the institution of slavery—the greatest material interest of the world,” the document states. “Its labor supplies the product which constitutes by far the largest and most important portions of commerce of the earth. These products are peculiar to the climate verging on the tropical regions, and by an imperious law of nature, none but the black race can bear exposure to the tropical sun. These products have become necessities of the world, and a blow at slavery is a blow at commerce and civilization.”

Meanwhile, students start their research for what is known as the Tales From the Crypt project with primary sources—court and census records, diaries, family and business files, among others—using them to write a paper about an individual buried in Friendship or Sandfield Cemeteries.

This year, Erin Williams, a student from Hattiesburg, Mississippi, investigated and performed the life of Susan Casement Maer, a native of Australia who, in 1881, became one of Mississippi’s first women newspaper owners— the “editress” of the Columbus Dispatch, as records of that time identify her. Kaelon McNeece, a student from Brandon, a suburb of Jackson, researched J. G. Parsons, a Confederate soldier, which led to an exploration of undiagnosed PTSD following the war. Dairian Bowles—a student from Byhalia, a rural town in northern Mississippi, who performed the story of state Senator Gleed—also investigated the life of a progressive doctor, John H. Hand. He ended many cruel, ineffective medical practices in 19th-century Columbus—and then purchased nine enslaved women and men, as his practice earned him a sizable fortune.

The Tales From the Crypt project, which added research and community performances to the U.S. history curriculum, was started by Yarborough’s late colleague and mentor, Carl Butler, in 1990. In 2007, Yarborough founded the African American history course, for which students also research those buried in Sandfield and perform their stories as part of the Eighth of May Celebration of Emancipation—a yearly tribute that had fizzled out in Columbus in the 1970s and was later revived by Yarborough’s course.

As part of the African American history class this year, Edith Marie Green, a student from Oxford, a city in northern Mississippi, investigated the life of Allen L. Rabb, owner of Rabb’s Meat Market, started by Allen’s father in the post–Civil War years.* Other students researched historic records for William Isaac Mitchell, the president of Penny Savings Bank, the first African American–owned bank in Columbus, and Richard Littlejohn, the publisher of a local black newspaper in the 1880s, among others.

Green told me that this class was the first time she’d learned anything about Reconstruction, and she certainly hadn’t learned about black life during that period. “In my history classes, we covered slavery and Martin Luther King. That’s it,” she said.

Green, who is white, said she especially appreciated hearing the perspectives of her black classmates during frequent discussions that made connections between Reconstruction, Jim Crow, and contemporary issues of racism. “Black students encouraged white students to go beyond outrage over great injustices to think about what we can do to change things now,” she said. Helping more Americans recognize black history as part of U.S. history is a priority for Green. She plans to become a high-school history teacher someday, she told me.

Bowles described his performances of state Senator Gleed—along with the process of researching Dr. Hand’s life—as the highlights of his high-school experience. Spending time in the archives, Bowles told me, made him feel like a private investigator, caught up in the excitement of one court record he’d uncover leading to another, as small puzzle pieces of his research subject’s life fell into place. The contradiction Bowles uncovered—an innovative, progressive doctor who made medicine more humane, and a person who failed to see the inhumanity and cruelty of slavery—became the central question Bowles explored during his performance to a crowd of about 1,000 mostly white Columbus residents at Friendship Cemetery. “It was important for me to understand how common his views were and where his mindset came from,” Bowles reflected. “Developing an understanding doesn’t mean justifying or excusing someone’s actions.”

Yarborough told me that Bowles did what many Americans struggle to do when they consider the past—recognize the contributions of individuals without whitewashing their flaws and inconsistencies. “Human beings like there to be no shades of gray,” he said. “We want simplicity in history. We want either good or bad, just or unjust, right or wrong. And while that’s very satisfactory to us individually, any project in history that is going to reflect our world, and teach kids how to operate in our world, has to explore that complexity.”

Yarborough argues that reliance on textbooks, which compress complex events or individuals into one paragraph or page, is not an effective way to teach key moments in American history. Instead, students should have opportunities to research primary sources in the context of other historic accounts about the events.

Prior to performing the stories of Hand and Gleed, Bowles told me, he used to think that he didn’t like being onstage and tried to find every excuse to get out of performing. He ended up enjoying it more than anything he’s done in high school, and is now considering majoring in screenwriting and film in college. “I didn’t go into this project thinking, I’ll be helping the community understand something, but seeing people engage and react to my characters was really satisfying. It was a really important moment in my life.”

*This article originally mischaracterized Oxford as a suburb.



When the Trump administration released its school-safety report last month, it landed with a thud—and only partly because it’s a clunky 180 pages. Many of the recommendations in the report, authored by the Federal Commission on School Safety, are aimed at fostering a better school climate—how a school feels to the students who attend it—whether that’s through improved access to counseling and mental-health services or a greater emphasis on social-emotional learning. But other recommendations were met with derision, such as a proposal to rescind an Obama-era rule urging schools to be mindful of whether they might be punishing minority students at a higher rate than white students.

Study after study has shown that black students are unevenly suspended or expelled from schools nationwide. The 2014 school-discipline guideline was the Obama administration’s attempt to remedy that. The Trump commission, however, argued that deciding how students should be disciplined should not be the federal government’s job, but the teachers’. Both administrations, at least, agreed that discipline was also a matter of school climate—something educational leaders have been trying desperately to improve.

A new study by the Rand Corporation, a nonpartisan think tank, shows just how crucial improving the climate at school can be to helping decrease suspensions. In 2013, Pittsburgh’s public schools were trying to figure out how to remedy racial disparities in discipline. At the time, they had mandatory diversity training for staff that sought to address implicit bias and discrimination in the classroom, but they wanted to do more. Restorative practices, which are nonpunitive ways of responding to conflicts, had been gaining momentum among school leaders as a way to help curb suspensions.

So the district got a grant to try out restorative practices in their schools, randomly selecting 22 of them to receive the restorative treatment, while 22 others went about business as usual. The basic goal of restorative practices is to build relationships between teachers and students, so that students will be less likely to act out. Teachers start off the school year by asking students innocuous questions such as what the students did that summer. As the year goes on, the questions grow more personal and introspective, and students build trust with the adults and classmates around them. Of course, formal times for such events can be time-consuming, so it is often recommended that the practices are woven into the day. As much as restorative practices aim to change how students are disciplined, they also seek to change the behavior that might require discipline, improving the overall climate of the school.

The researchers examined the schools—elementary, middle, and high schools—over two years and found that restorative practices greatly reduced the number of school days lost to suspension, particularly among elementary schoolers. The dip was most acute among black, low-income, and female students, and nonviolent offenses drove the decline. “It seems to be the case that restorative practices were providing an alternative that the staff felt they could use to enforce discipline, [especially] for offenses that weren’t extremely serious in the sense of endangering people’s safety,” John Engberg, a researcher at Rand, told me.

On top of that, the report found no negative impact on the test scores of students in the schools that had restorative treatments. “That seems to indicate that keeping kids in school is not leading to a deteriorating learning environment,” Engberg said. And, for their part, teachers who worked at schools with the restorative treatments rated their climate as comparatively more positive.

There were some things that restorative practices couldn’t change, though. Sure, academic outcomes, such as test scores, didn’t drop, but they didn’t improve either. The decline in suspension rates was most stark for elementary-school students rather than middle- or high-school students, where the effects were more muted, suggesting that early intervention is important.

Changing a school’s climate is a long process, Catherine Augustine, a senior researcher at Rand, told me.“This isn’t Let’s go to a one-day workshop and we’ll all be restorative,” she said. It takes work from teachers, faculty, staff, and students. And the researchers themselves still have a lot of work to do in terms of understanding how restorative practices work and whether the gains made by the elementary schoolers will carry forward through middle and high school. Still, the bipartisan goal of improving school climate may not be as elusive as it seems.



When the United States ratified the Nineteenth Amendment nearly a century ago, the law’s immediate impact extended far beyond giving women the right to vote. Women’s suffrage—widely viewed as one of the 20th century’s most important events—coincided with a growing (if gradual) embrace of gender equality, increased social spending, and a greater tendency among politicians to take a progressive stance on legislative proposals. Evidence suggests that women’s suffrage also corresponded with a significant increase in municipal spending on charities and hospitals, as well as on social programs; one study found that when women gained the right to vote, child mortality dropped by as much as 15 percent. A new study shows that another one of the ripple effects of women’s suffrage was that, across the board, children were more likely to stay in school.

For this study, three economists—Dartmouth College’s Na’ama Shenhav, Bucknell University’s Esra Kose, and Southern Methodist University’s Elira Kuka—digitized archival local school-enrollment and school-spending figures dating back to the early-20th century for around 500 U.S. cities with at least 10,000 residents, and analyzed that information alongside census statistics, among other data. They looked at adolescents who were 15 years or older (and about to complete school) by the time suffrage was granted to women, and compared them to children who were still in school, or about to start, at the time.

This allowed the researchers to see how women’s suffrage (or lack thereof) affected long-term outcomes for kids—including how long they stayed in school, their literacy levels, and their eventual income. They controlled for other factors that could have muddled the results, including compulsory-school-attendance laws and the New Deal. Those results are summarized in the working paper, which was recently published by the National Bureau of Economic Research.

Shenhav and her team found that suffrage increased local education expenditures by 9 percent on average and corresponded with a rise in school enrollment. These trends were more pronounced in cities that had high shares of African American residents, were located in the country’s South, and/or had low rates of per-capita spending on education and other social services to begin with. For black students, “full exposure to suffrage”—i.e., being born after or only shortly before the women’s right to vote became the norm—led to nearly an additional year of education. “The effects of suffrage,” the economists write, “are akin to the one-year increase in attainment of black students from court-ordered desegregation.”

For white students, the increased education amounted to a statistically insignificant 0.10 years, though white children in the South gained an additional 0.96 years in school. The gains were generally comparable between boys and girls—though they were more pronounced among black boys than for black girls.

Taken together, these findings suggest that women’s suffrage helped reduce the precursor to the modern-day achievement gap. And in chipping away at those disparities, the economists conclude, women’s suffrage may have had a longer-term impact on the income prospects of some children. “It appears that one of the main benefits of suffrage may have been to help raise the bottom and middle of the distribution of historically less-educated communities,” the researchers write.

The findings suggest that white students in the South whose formative schooling years happened after the Nineteenth Amendment’s ratification saw their incomes increase by 34 percent thanks to the law. Similar effects were not found among white students outside the South or among African Americans, but the authors point to numerous potential reasons for the discrepancy, including the fact that black workers received fewer returns in exchange for their skills in the labor market and were exposed to lower-quality education, especially in the segregated South.

In securing women the right to vote, the Nineteenth Amendment seems to have produced a positive, long-lasting contagion effect throughout society. “One of the ongoing things that we’re learning as economists is that there are spillovers from policies that are not necessarily targeted to education,” Shenhav says. “Policies that reduce political participation have implications for education policy.”

The economists could only identify a measurable impact for the generation of students that attended school during or immediately after national suffrage. Yet the researchers say that women’s ability to vote surely led to longer-term benefits, including in labor-market productivity. “What we find is that when women got power, there were changes in spending that closed various gaps—any kind of spending: health care, education,” says Kuka, of Southern Methodist University. “These kinds of changes mattered back then and they probably matter now, too.”



For the second time in just a few months, admissions at America’s elite colleges are under a microscope. In late 2018, the scrutiny was on T. M. Landry, a predominantly black private school in Louisiana that had garnered a national reputation for sending dozens of graduates to the Ivy League and other prestigious institutions. A New York Times report revealed the school as a fraud, faking transcripts and hiding allegations of abuse. The Landry scandal caused tremors in higher education, but damage was limited by the fact that colleges could plausibly claim victimhood—although, I argued at the time, it was difficult not to come away from the debacle with a sense that it called into question core tenets of the American educational meritocracy.

As explosive as the Landry affair was, it is now dwarfed by the bombshell dropped by the Justice Department on Tuesday, when federal lawyers indicted 50 people on racketeering charges for allegedly facilitating or taking part in a nationwide fraud to game admissions at top colleges. The accused include CEOs, wealthy investors, and at least two celebrities. According to the indictment, the conspiracy had been refined over many iterations, and was marketed as a service to the ultra-wealthy. Its creator described it as an innovation, a cost-effective “side door” into top colleges. In practice, it was a system of bribes to accomplices such as testing-center officials, who could help alter SAT and ACT scores, and college coaches in second-tier sports, who could help admit applicants who pretended to be athletes.

The story immediately went into the stratosphere. No one could resist the specter of the rich and famous engaging in lurid criminality to give their kids even more of an advantage. All the major news outlets led with the scandal. Twitter, the hub of the media elite, had a ball, alternating between mockery and fury. A tidal wave of scorn washed over the whole of American discourse. Ask Tom Brady, Lance Armstrong, or Goldman Sachs: The only thing people dislike more than cheaters winning is winners cheating.

Resenting the dynastically wealthy is practically a national sport, and for the most part, that’s what the admissions scandal has been understood to be about: the perfidy of the 1 percent. Many drew parallels to entirely legal ways the rich can rig college admissions, like pledging donations or enrolling in private prep schools. Implicit in the public contempt is the belief that none of this has anything to do with regular middle-class folk. In fact, some of the angriest responses came from people who attended the very colleges that had been part of the scam. For many, the scandal felt like a sign of the times, showing the divide between the rich, cheating their way to the top, and everyone else, who had climbed up the hard way.

Maybe that’s why an odd twist in Tuesday’s scandal stood out: Many of the students who benefited did not know about the fraud being committed for them. In several instances, their parents endeavored to keep the payoffs and cheating secret, arranging false tests so the children would never know that their scores had been deceitfully obtained. The kids were fakes, and ignorant of that fact.

It’s hard to blame people for mocking these oblivious teenagers, who thought they were walking on their own, but were in fact being carried. But it’s also worth considering how events would have appeared from their perspective. A high ACT score would have seemed like just another stroke of good fortune in a life full of it. The same goes for their acceptance into a selective college. In one tragicomic passage in the indictment, the scheme’s orchestrator describes how his student “clients” would sometimes come to him, surprised by their own high test scores, and suggest that maybe they’d do even better if they took the test again. They mistook the secret forces working on their behalf for their own natural talent. If you can’t see the hidden hand behind your success, what other explanations are there besides luck and ability?

In other words, from the students’ viewpoint, this is about as archetypal an instance of privilege as could be imagined. Advantage, after all, is rarely noticed by the advantaged. People don’t have an easy way to compare their lives with those of others, to see how the same situations might turn out differently if they themselves came from a different background. The first instinct is often to attribute disproportionate success to above-average aptitude, but most successful people know aptitude can’t explain everything that’s gone their way. That’s why, in many cases, privilege looks and feels like an accumulation of good luck, a series of little victories that make everything work okay in the end. In reality, luck and aptitude don’t tell the full story. Instead, wealth or caste or social standing work to load the dice in favor of the fortunate.

Now a confession: I too attended one of the colleges named in Tuesday's indictment. The news set me to wondering, Did I know someone who had bought his or her way into college? How could I tell? For that matter, how would I have known if secret forces had worked on my behalf?

At first, the question seemed ridiculous. I did not grow up fabulously wealthy, and I’m reasonably certain that my parents paid no bribes for me. I can say with total confidence that no one was seeking my athletic prowess, real or imagined.

Then I remembered that my father had also attended my alma mater. I hadn’t thought about that too much when I’d applied, believing that my grades spoke for themselves. No one ever brought it up to me, and I hadn’t really dwelled on it since. It was definitely not a fact that I had ever used to discount my own academic achievements.

But I’m nearly certain that somewhere in the application process, some admissions official, whose face I’d never see, took note that I was a legacy applicant, and moved me up a few spots on the list. Here was something I’d overlooked, a hidden hand behind my own good fortune, silently working to transmit my parents’ economic and social station downward to me. Perhaps less was separating me from the admissions-scandal students than I’d thought.

In this, I’m not alone. How many people who attended a good college, or secured a prestigious job, or otherwise climb one rung after another up the ladder of social and professional standing, can look back and see nothing similar?

While some people do start in remarkably disadvantaged places and rise through society, social mobility is the exception, not the rule. It’s true that most successful peoples’ parents have never paid an illegal fixer to secure them a college seat. But consider: If you attended a high-performing public high school, your parents probably did pay a premium on their house to live in the attendance zone. And what about the countless other, smaller outlays parents can make to help propel their children upward, things like test prep, sports equipment, after-school activities, travel? Even basic necessities like healthy food, medical care, or personal safety come at a financial cost. None of these expenditures are solely the province of the very wealthy, but nor are they guaranteed, and each serves as a little investment in the future, giving children a small leg up on peers who do not receive the same.

Parental wealth is hardly the only form of unearned advantage. Other privileges are even more deeply embedded, transmitted almost as birthright. In America, whiteness ranks highest among these. In education, in the workplace, in the criminal-justice system, white children and teenagers consistently receive hidden benefits that their nonwhite peers do not. How many white teenagers have gotten caught smoking weed or drinking, and were let off with a laugh and a warning? For a child of color—particularly a black child—the exact same episode is more likely to end with an arrest, and a ruined future. Where one person has a good chance of going home feeling lucky, another might leave in a squad car. How many white kids found it easy to get a summer job, while black children with the same applications were turned away? How many white students have been steered toward advanced-level courses, while their black peers were not? These advantages often persist across the income spectrum. For example, even after controlling for socioeconomic status, white students are significantly more likely to be assigned to a gifted-and-talented program than black students.

Legally speaking, none of these things remotely resemble paying off a test administrator. Pragmatically speaking, and from the perspective of the person who benefits? There is a certain symmetry. You have parents spending money to put their children in the place that best guarantees their success. You have many of those children growing up at least partially ignorant of the efforts expended to help them, and the forces working to protect them. Certainly, in both cases, the people who benefit are likely to end up thinking they’ve mostly earned what they’ve received, as a reward for hard work and natural aptitude. And if they got a lucky break or two along the way, well, that’s just life.

The lesson here isn’t to forgive the alleged fraudsters. Rather, it is that in a society stratified from top to bottom by race and wealth, privilege can’t be understood as something held exclusively by the richest 1 percent, or even the richest 10 percent, to the detriment of all others. If they’re propelled to their station by forces out of their sight and beyond their control, so too is everyone else lifted or confined by those same forces. Because of that, there is often no indicting the meritocracy without indicting oneself. One might even begin to wonder whether the real fraud is the idea of merit in the first place—that maybe “deservingness” is a shoddy basis for organizing a society altogether.





One month before the 2016 presidential election, I spoke on a panel in Charlottesville, Virginia, on the topic of campus speech. The audience was generally enthusiastic and engaged. A tense moment arrived, however, when one individual, who identified himself as a “deplorable,” took issue with the composition of the panel (two white women and myself, an African American male). He explained that the panel in his view was slanted, did not represent a more conservative position, and that I, as an African American, represented so much of why he as a working-class white male struggles in this economy.

I attempted to engage him calmly both during the open question-and-answer session and individually after the panel. Despite my best efforts, it was clear that he had little interest in respectful discourse, and he continued interrupting me loudly and angrily.

The incident with the self-described “deplorable” in Charlottesville left a lasting impression. My 2016, pre-election encounter now appears to be one of countless examples of the sort of uncivil discourse that has since become normal in our society. Since then, it’s become quite common, particularly within the political sphere, for all kinds of speech, regardless of how inflammatory it might be, to be expressed openly and sometimes loudly, without consequence. Many people couch this kind of speech in terms of a backlash against “political correctness,” and they view such speech as a right that comes without any responsibility to engage with others respectfully. It also appears that society has become complacent with the tendency of individuals to talk at, rather than to, one another. At its core, this notion of uninhibited, anti-politically correct speech has dimmed the hope of productive dialogue.

At a time when university administrators grapple with debates about free speech on campus and people across the nation witness the consequences of free speech in a polarized political climate, administrators, educators, and civic leaders should promote civility as an important element of constructive conversations. This duty becomes a moral imperative in forums where polemic issues take center stage. As Father John I. Jenkins, president of the University of Notre Dame observes in his book, Conviction and Peril of Our Passionate Beliefs, “Civility is what allows speech to be heard.”

While civility is crucial, it does have limits. Civility does not require engagement with individuals who utter speech that, at its core, has no connection with respect or mutuality. While those who express bigoted views may have a right to free expression, those who seek civil discourse are not required to engage with those individuals. One may simply walk away from the speaker and refuse to listen, thereby denying the speaker an audience.

My exchange with the self-described “deplorable” has haunted me and prompted considerable introspection. Could I have chosen my words more carefully to guard against alienating him? Since our encounter, did he think more about my bid for greater civility? On the day of that exchange, two men who identified themselves as attorneys for that individual complimented me on the respectful way that I dealt with the situation, saying that I had handled him better than most people he has confronted.

Though my attempt to persuade my hostile adversary seemed to fail, I take solace in the observations of those two men and those in the audience who witnessed the exchange and appreciated the civil manner in which I handled the situation. Perhaps the lesson from the incident is not the value of immediate persuasion, but the need to encourage the appreciation and embrace of civility.



“It is bananas,” Senator Kamala Harris told the audience—members of the American Federation of Teachers’ Michigan chapter—gathered at Marcus Garvey Academy, in Detroit, on Monday.

“It is completely upside down that we currently have a system where the funding of a school district is based on the tax base of that community,” the Democratic hopeful vying to run against President Donald Trump in 2020 said. The line met with approving head nods and a chorus of agreement. “It’s just basic math,” she continued, on a roll. “The community that has the lowest tax base is going to receive the fewest resources, and by the way probably [has] the highest need.”

What Harris is proposing could dramatically restructure American education. Currently, about 36 percent of public K–12 funding comes from local property taxes, depending on the state and district, according to a report from the Lincoln Institute of Land Policy, a think tank that researches land and taxation. Only about 10 percent of school funding comes from the federal government, and every state has its own mix of state and local dollars to fill out the pie.

Harris says America needs to reform the way it funds its schools. The big question is how—and Harris’s remarks did little to illuminate the mechanics of this reform. (The Harris campaign did not respond to a request for elaboration.) Her comments come on the heels of her proposal to increase federal spending to boost teacher pay by an average of $13,500 and suggest an emphasis on education as central to her campaign’s strategy.

This is not the first time a Democratic presidential candidate has criticized America’s system for funding its public schools. In 2016, during a presidential forum in Iowa, Senator Bernie Sanders declared, “We have to break our dependency on the property tax,” and suggested that the federal government play an active role in ensuring equality; his current campaign site, however, like Harris’s, does not mention property taxes in K–12 funding. Similarly, Senator Elizabeth Warren said in March that “we’ve gotta use our federal-education laws to help supplement so we can get real money into our public schools K–12.” But she has not, so far, been as specific on her K–12 policy ideas this election cycle as she has been on higher education, for which she has produced a detailed overhaul plan.

In theory, even despite unequal property wealth, America’s schools should be funded with something of an eye toward parity, because of what’s known as the “foundation” model. Under this system, which several states employ, the state legislature ensures that each school district has an equal baseline; if the school system were a car, for example, the legislature would make sure it had four tires with air in them, and a working engine. The state might set that foundation at $8,000 of funding per student, and districts must assess property taxes to see how much of that they can afford to pay on their own. The state, then, covers whatever the difference would be.

A property-poor area—one with a lot of tax-exempt buildings, or a low property value—might be able to cover $1,000, say, and the state would cover the last $7,000 to get it to the minimum threshold. In contrast, a property-wealthy area, with million-dollar homes aplenty, might be able to cover $14,000 per student with property taxes alone. The state government would not, then, provide it with any additional funding. So even though the poor districts can’t fall below a certain level, the rich districts are nevertheless advantaged because they’re significantly above the threshold.

One further problem with foundation models is that they’re rarely fully funded, Carlee Escue Simon, the executive director of the National Education Finance Academy, a nonprofit focused on school finance, told me. That means that even when the threshold is $8,000, states sometimes match up to $5,000—below the designated minimum. Meanwhile, school districts that don’t need a match might still be able to cover a full $14,000 per student.

That’s where the reliance on property taxes becomes so unequal. Simon told me that it did not appear as if Harris was saying that property taxes should not be factored into funding public schools at all. If that were the case, it would be incredibly difficult to pay for any system of public education. It is more so the “then what,” she said. “Once the property taxes are collected, how are they distributed? That needs to be examined, and states should be held accountable for that.”

How could the federal government hold states accountable for that? Perhaps simply by ensuring that they’re hitting the minimum thresholds they initially set out to meet, and encouraging them to do so by offering some form of federal match on equitable public-school spending. “It’s important that the federal government makes sure that the states are honoring their obligation,” Simon told me.

Instead of creating a new matching program, the federal government could also employ some of the programs it already has at its disposal, Roxanne Garza, a senior policy analyst at the policy think tank New America, told me. The federal government could dramatically increase the budget of programs under the Every Student Succeeds Act, the law aimed at improving basic educational programs offered by state and local governments. “It just comes down to how we prioritize whether or not we care about equity,” she said. The government is willing to fund a range of other things—the military, a wall—she said; why not schools?

Such approaches, however, would undoubtedly run into the philosophical debate over who—or what—is fundamentally responsible for schools. As Simon put it, “There are people who think that our federal-level Department of Education is already pushing [the] boundary”—overstepping into what is fundamentally a state and local issue. Still, Simon said, “the states should be recognizing that there are property-rich districts and other districts that do not share that same level of wealth. And they should balance this out.” Harris nodded to the disparity; now it’s a matter of what she proposes to address it.



At 9 o’clock eastern time yesterday morning, Kyle Kashuv—a gun-rights activist and survivor of the 2018 shooting at Marjory Stoneman Douglas High School in Parkland, Florida—announced on Twitter that Harvard University had rescinded its offer of admission to him. One hour and 12 minutes later, Kashuv and his now-uncertain educational future had been officially declared victims of an overzealous progressive agenda that was either unwilling or unable to forgive.

“The progressive black balling of Kyle Kashuv is a reminder that there’s no concept of grace in the secular religion,” the conservative commentator Erick Erickson tweeted.

Erickson’s read on the situation turned out to be a popular one across social media. In the hours since Kashuv tweeted about Harvard’s decision, a number of conservative commentators and publications have weighed in. Many of them have situated Kashuv against the backdrop of what they perceive to be a larger problem on the left: “cancel culture.” When a public figure’s racist, sexist, or otherwise offensive behavior comes to light, widespread condemnation and calls to stop supporting that person tend to follow—especially on social media, where people often say that person is “canceled.” Some conservatives feel this shows an unwillingness to acknowledge a person’s growth and learning from mistakes.

In the 14 months since the shooting at Stoneman Douglas, Kashuv, 18, has become the only prominent Parkland survivor turned activist to come down on the gun-rights side of the debate; schoolmates of his such as David Hogg, Emma Gonzalez, and Cameron Kasky have become high-profile advocates for stricter gun legislation. As a supporter of stricter background checks but also armed teachers, the elimination of gun-free zones, and heightened school security, Kashuv stands in contrast to the majority of the gun-safety activism that grew out of the shooting at his high school. In doing so, he’s become something of a folk hero for other conservatives and gun-rights advocates.

Last month, a former classmate of Kashuv’s disseminated screenshots of text messages and Google docs in which a 16-year-old Kashuv had allegedly written racist slurs. Kashuv was revealed to have repeatedly written nigger in the screenshots; he tweeted an apology statement at the time. But as he revealed on Twitter yesterday, the admissions team at Harvard, where Kashuv was planning to matriculate next year, contacted him soon afterward. They had received complaints and wanted an explanation.

In a Twitter thread, Kashuv released copies of the letter he sent to Harvard’s dean of admissions. “Let me first state that I apologize unequivocally for my comments, which were made two years ago in private among equally immature high school students,” his multiple-page letter began. He went on to describe how surviving the shooting at Stoneman Douglas had forced him to mature quickly into someone who does “not recognize the person who wrote those things.” He also tweeted the text of an email he sent to the Harvard Office of Diversity and Inclusion, promising to visit its office upon arriving on campus. Still, after reviewing Kashuv’s explanation, Harvard notified him earlier this month that his offer had been revoked.

A number of prominent conservative figures have since argued online that Kashuv deserves forgiveness, not further punishment, from the Harvard admissions office because he took responsibility for his behavior and apologized. Erickson, in a blog post on The Resurgent, wrote that “Kyle apologized and is clearly not the same person he was then.”

“Hopefully this terrible decision by @Harvard will be reversed. We all have a past and we all have done and said things we regret. He has apologized and become an extraordinary young person,” tweeted Dave Rubin, the host of the right-leaning YouTube show The Rubin Report. “Now the mob wants to make forgiveness a sin, too.”

Some have argued that Kashuv’s repeated use of the racist term, because it took place in private and not in public, should be considered a juvenile mistake rather than a hostile act. “So if you say something terrible in a private chat room when you’re 16, then get outed by political opponents, Harvard tosses you?” tweeted Ben Shapiro, the editor in chief of the conservative website The Daily Wire. In a story for The Daily Wire, Shapiro again emphasized the private nature of Kashuv’s use of the racist slur: “He didn’t commit a crime; he didn’t espouse his gross views publicly; his behavior since has not mimicked any of the content or attitude of the comments.”

Other commentators similarly relied heavily on the context in which the comments had been originally made. Guy Benson, the politics editor of Townhall and a Fox News commentator, seemed of two minds about the incident, writing that while Kashuv’s use of racial slurs was inexcusable, the private setting in which it occurred should have been taken into consideration. “This does not feel one bit like ‘progress.’ My advice to Kyle before all of this blew up publicly was to tell the truth & to apologize deeply and sincerely (there is no excuse for using that word—even if the context was teenage boys’ private shock Olympics). He did both things,” Benson tweeted. “The use of a disgusting word, in private, by a 16-year-old, should not be an unforgivable event.”

It is worth noting that Harvard has rescinded offers of admission to other accepted students in the past on the basis of online activities the students believed were private at the time. In 2017, according to The Harvard Crimson, the university rescinded the admissions of at least 10 accepted students after they were found to have “traded sexually explicit memes and messages that sometimes targeted minority groups in a private Facebook group chat.”

Other conservative publications and commentators, meanwhile, took the rescission of Kashuv’s admission offer as evidence of selective forgiveness on the part of the progressive establishment (which they seemed to see Harvard as a part of). Liberals, and institutions such as Harvard that these writers consider to be liberal, extend grace and charitableness to the past misdeeds of only those who agree with them politically, some conservatives implied. A few prominent figures, for example, invoked the senator from Massachusetts and Democratic presidential candidate Elizabeth Warren, who formerly taught at Harvard Law School. Warren has apologized for identifying as American Indian in the past, in contexts such as her registration for the Texas bar association in 1986, a practice that some conservatives see as taking advantage of affirmative-action policies.

Dana Loesch, a conservative gun-rights advocate and radio host, gestured at Warren in a tweet. “Wait, does them mean Harvard is going to condemn Warren?” she wrote. “Because her sin by comparison is exponentially worse. I know rules derive strength from consistent enforcement and all.”

Matt Walsh, a Daily Wire blogger and podcast host, made a similar comparison, invoking Ralph Northam, the Democratic governor of Virginia, who was found to have dressed in blackface for a medical-school yearbook photo in 1984. “Kyle Kashuv used the n-word when he was 16 and now his Harvard acceptance has been rescinded. Ralph Northam dressed in blackface as an adult and he is still governor,” Walsh tweeted. “That tells you everything you need to know about how the rules are applied in our society.”

Still, the prevailing sentiment among those on the right seems to be that the Kashuv decision embodies everything they see as wrong with cancel culture. “The idea of repentance and forgiveness is dead in our society,” Loesch tweeted. “Redemption and forgiveness are politically disadvantageous. Only those confident in their convictions make room for them.” The Daily Wire, meanwhile, tweeted a textual representation of a bunny holding out a stack of books and then whisking them out of reach. “Welcome to Harvard,” it read. And then, “Never mind, ppl cant grow, change or be forgiven.”

The libertarian outlet Reason drew a direct line between cancel culture and the rescission of Kashuv’s admission, running a story headlined “Harvard University Cancels Kyle Kashuv.” For one thing, the author Robby Soave wrote, it was a victory for the cancel-happy online “mob.” But perhaps more troublingly, in Soave’s view, a teen being held accountable for his online misdeeds as a slightly younger teen sets a dangerous precedent.

“Harvard’s decision here is also an endorsement of the position that people should be shamed and punished for their worst mistakes as kids,” Soave wrote. “But moving forward, as technology gives everyone the ability to record every moment of our lives, this will be an untenable position—all embarrassing moments will be preserved forever, available for re-litigation. This is excessively punitive, and counterproductive to the healthy socialization of young people. Kids are not perfect: They must be given the opportunity to fail, and to learn and grow from their errors.”

Of course, as the discussion of the topic of forgiveness for teenage misdeeds intensified, the question of which teens’ misdeeds deserved forgiveness rather than punishment arose. Allegations of selective empathy could cut both ways, several other commentators pointed out. When some right-leaning voices discussed the deaths of unarmed black children including Trayvon Martin, Tamir Rice, Michael Brown, and Laquan McDonald, who were gunned down on the mere suspicion of wrongdoing, they focused on perceived misbehavior on the part of the kids. Loesch, for example, asserted after Rice’s death in 2014 that although the police officer who shot him was “in the wrong,” so was the 12-year-old boy, who had been playing with a toy gun at the time.

It’s impossible to know what factors might have influenced Harvard in deciding whether Kashuv’s personal and moral growth since his sophomore year of high school were enough to outweigh his racist comments. But the whole saga leaves open the question of what would have happened if he’d been forthright about his prior misdeeds and later atonement before being prompted—before they might have cost him admission to Harvard—perhaps even as part of his application. That might have meant more, both to the public and to his school of choice.



Teachers across Los Angeles fought hard and, after just over a week of striking, got more or less what they had hoped for: more librarians and nurses for their schools, smaller class sizes, and nicer campuses. Not on that list? Higher pay—the teachers had already successfully negotiated a 6 percent raise before the strike.

This is the most significant part of the L.A. teachers’ strike story, and the key to understanding the broader dynamics of today’s teachers’ movement. Salaries were never a major sticking point in the negotiations: The final figure for the raise is 6 percent, identical to the numbers that the Los Angeles Unified School District (LAUSD) had outlined in its most recent set of offers—and, in fact, pretty much the same as the number negotiated even before the strike began.

“Our salary demands have pretty much been met, so we’re clearly not striking for that issue per se,” Martha Infante Thorpe, a veteran social-studies teacher and Eastside L.A. native, told me on the eve of the walkout. Instead, she—like the handful of other educators I interviewed—stressed that she and her fellow LAUSD teachers were striking as a last-ditch effort to improve the education of the nearly 500,000 children they serve.

Topping the union’s list of priorities were demands around class sizes, which in many schools often exceeded the limits stipulated in the teachers’ previous contract—and in some cases were well upwards of 40 kids. While research on the benefits of class-size reduction is mixed, a number of compelling studies suggest that smaller class sizes can be a significant predictor of student success. Another concern: the paucity of school staff tasked with supporting students’ extracurricular needs and well-being. Many campuses, for example, have for years operated without a full-time librarian or nurse, and a 2017 report found that a Los Angeles public-high-school counselor’s average caseload was 378 students, though that might have been a conservative estimate given recent analyses of the settlement, which concluded that the small number of additional hires will leave the ratio at 1 to 500. Nationally, the recommended student-to-counselor ratio is 250 to 1. Yet the ratio should, arguably, be even lower than that in the Los Angeles public schools, which suffer from one of the greatest concentrations of student poverty among California’s school districts, with more than eight in 10 students relying on subsidized meals.

On both of these issues the teachers basically got what they wanted: class sizes will go down—immediate reductions for secondary math and English classes (from a limit of 46 students to 39) and, eventually, modest cuts to the size caps for every class in all but the earliest grade levels—and the number of support staff will go up, including hundreds of new nurses and dozens of new librarians. And it was on these issues that the differences between LAUSD’s earlier offers and the final compromises are most striking. Pronounced juxtapositions tend to signal areas that were the biggest sources of dispute in the negotiations, revealing what most preoccupied teachers.

In general, the agreement requires that the district, over the course of several school years, invest $403 million in those staffing increases and class-size reductions—more than three times the amount the district had offered in its final contract proposal before the strikes. Beyond those funding commitments, the union is claiming victories in its promotion of “community schools” designed to improve the well-being of both the students and their broader social networks, as well as in its condemnation of random searches of students on certain campuses. It even secured the district’s vow to add more green space to school campuses (by removing asphalt, for example, or creating more verdant play areas), though the details have yet to be hashed out.

While the strike’s outcomes are largely school- and student-focused, educators, too, will benefit, notes Mark Hlavacik, a communications professor at the University of North Texas who studies teachers’ union rhetoric. They’ll have smaller classes to manage, more help from other school staff, and fewer headaches over standardized testing, which, as part of the contract, the school district has agreed to curtail. But the important takeaway is that teachers are advancing themselves as advocates for students and and schools.

“What is impressive here is how well the teachers are folding their interests and the interests of their students together to create an outcome that any parent would be pleased with for the sake of their child in the district,” Hlavacik told me in an email. This pattern is not going to be limited to Los Angeles. In Denver and Oakland and Virginia, teachers are saying their professional demands are synonymous with kids’—and society’s—general well-being, a sign that this is an approach that future educator walkouts are bound to leverage.



Editor's Note: If you are having thoughts of suicide, please know that you are not alone. If you are in danger of acting on suicidal thoughts, call 911. For support and resources, call the National Suicide Prevention Lifeline at 800-273-8255, or text 741-741 for the Crisis Text Line.

Over a period of just 10 days this month, three people directly affected by school shootings committed suicide.

Two were survivors of the 2018 shooting at Marjory Stoneman Douglas High School in Parkland, Florida; the third was the father of a first grader killed in the 2012 shooting at Sandy Hook Elementary School in Newtown, Connecticut. Sydney Aiello was 19 and a student at Florida Atlantic University, and she was a close friend of Meadow Pollack, who died in the Stoneman Douglas massacre. The identity of the other Stoneman Douglas student, reported to be a sophomore boy, has not been released. Jeremy Richman, 49, was a neuropharmacologist.

The death by suicide of someone connected to a school shooting is, unfortunately, a familiar story line. Carla Hochhalter, the mother of a student injured in the 1999 shooting at Columbine High School in Colorado, took her own life six months afterward; family members later stated that the tragedy had exacerbated her preexisting clinical depression. Greg Barnes, a Columbine student whose best friend died in the massacre, committed suicide a few weeks after its first anniversary. And in 2008, eight months after the shooting at Virginia Tech, a 21-year-old student named Daniel Kim took his own life in an act that his parents said was linked to the shooting.

Some 28 percent of people who survive mass shootings in the United States develop post-traumatic stress disorder, according to the National Center for PTSD at the U.S. Department of Veterans Affairs. (By comparison, 7 to 8 percent of the U.S. adult population will experience PTSD symptoms at some point in their lives.) Research has also linked PTSD to suicide, particularly when it’s paired with depression. In this sense, having survived or having been directly affected by a mass shooting is certainly “a risk factor” for suicide, says Heather Littleton, a professor of psychology at East Carolina University who specializes in recovery from trauma. Additionally, Littleton says that recovery can be made harder by a prevalent misconception that grieving is a linear, incremental process, one that can be completed within the months or years after a tragedy.

Mass shootings often result in a particularly difficult kind of grief known as traumatic grief. Littleton describes traumatic grief as a PTSD reaction that occurs when someone is grieving over another person’s violent or unexpected death; in other words, traumatic grief occurs when someone has PTSD symptoms on top of grief symptoms. And as with PTSD, “a traumatic-grief reaction could last for a number of years,” Littleton says. (Some people do, of course, grieve over traumatic deaths without experiencing traumatic grief, Littleton notes.)

In a traumatic-grief situation, she adds, “those traumatic symptoms then interfere with the resolution of the grief reaction,” which can result in the phenomenon commonly known as “survivor’s guilt”: “The person sort of gets stuck on this idea that ‘I should have been able to prevent this death,’ or ‘Why did this person die instead of me?’” The mother of Sydney Aiello, the 19-year-old who took her own life last week after surviving the shooting at Stoneman Douglas last year, told the press that her daughter had been having thoughts like those.

The nonlinear nature of grief—the fact that it can ebb and spike over time rather than steadily decrease—tends to become clear with the passage of certain milestones. As the author Dave Cullen illustrated in his 2009 book Columbine, school-shooting survivors and the families of victims tend to have a tough time in the days around the anniversary of the tragedy for years afterward. For some, Littleton adds, that “anniversary reaction” can persist into the days and weeks after the anniversary too. The two Parkland survivors who committed suicide did so about 13 months after the shooting at their high school.

One of the best predictors of a positive mental-health outcome after a shooting, Littleton says, is social support for survivors and the victims’ families. “Overall, individuals who have good social support, who report strong feelings of social solidarity after the trauma, who do not have a history of mental-health problems or other traumatic experiences, are those most likely to experience resilience,” she says. But often the social support offered to them—as well as the formal psychological support—seems predicated on the notion that grief is temporary and eventually wanes and dissipates.

“Initially, there’s often an outpouring of support—this increased sense of community solidarity, where [survivors] feel very connected to other members of their community,” Littleton says. But eventually that sense of community solidarity goes away.

“It could be because there are divisions in the community about what [they] should be focusing on, or what direction [the community] should be going in,” she adds. “Maybe the community has a negative identity now, so survivors don’t really want to be associated with that community anymore—you don’t want people to think about you as a student at that school, or ‘You were in that community where that horrible thing happened.’ That can fuel a sort of decline in community solidarity, which naturally tends to happen about six months after communal traumas.”

In addition, much of the mental-health support offered to survivors of shootings and the families of shooting victims dissolves around the same time. Counselors and mental-health practitioners who are integrated into the community immediately after the tragedy may leave before the community has truly healed. One case study of the aftermath of a shooting at Dawson College in Montreal found that counselors were readily available on school premises for six months.

“Separate from the formal support going away, informally, other people are moving on. People aren’t talking about it as much anymore,” she says. “So if you are still struggling—maybe you don’t have those informal supports, and maybe you also don’t have the formal resources anymore—and there’s this expectation that you should be moving on, or that we should not be talking about this anymore. That can fuel more distress.” At Virginia Tech, a “sizable percentage of students” reported elevated symptoms of PTSD one year after the shooting, according to a study Littleton conducted.

“That’s when they noticed a surge [in feelings of distress]—when there was that sense of ‘Well, other people are doing better, but I’m not,’” she says.

The majority of individuals who experience or are affected by mass trauma, Littleton points out, are resilient—they do not develop persistent symptoms. Many report feeling jumpy or edgy or having unwanted thoughts or dreams in the immediate aftermath of the trauma that go away within a few days or weeks, while for others, the symptoms last for a few months and then go away on their own. Survivors who are most likely to show resilience after a shooting are those who had no strong emotional reactions while the shooting was unfolding and those who never felt that they or their loved ones were in danger during the shooting.

Some Virginia Tech students who struggled with anxiety and depression before and at the time of the shooting in 2007, Littleton notes, actually showed improvements in the longer term, seemingly as a result of the solidarity and support they felt. They reported increases in social support, feelings of connection to others, and a sense of purpose in life in the months after the shooting, Littleton says.

Many survivors of mass shootings go on to find purpose through activism against gun violence. Several Parkland students, for example, have lobbied state and federal governments for gun-law reform. Jeremy Richman, the father of a 6-year-old who died in the Sandy Hook Elementary School shooting, started the Avielle Foundation, a violence-prevention nonprofit named for his daughter, in the wake of her death, and as recently as this month, he spoke to students at Florida Atlantic University about how to identify and help people who might be at risk of violence to themselves or others. He told The Atlantic’s Isabel Fattal last year that his activism was a valuable outlet for the sorrow and anger he felt. “You feel like you’re not just broken but you’re missing something that’s part of you,” he said. “You have to find some meaning or action to move, to get out of bed.”

Richman took his own life on Monday, some six years after the shooting at Sandy Hook. For some, finding meaning after a tragedy doesn’t necessarily make it bearable; as many Americans have already learned in the wake of other mass shootings, even survivors and family members who outwardly seem to be coping may need social support and resources.



A federal court has in recent weeks unsealed a trove of documents revealing how Harvard decides whom to admit out of the 40,000 or so students who apply each year for its roughly 1,600 freshman seats. The documents, provided as part of a 2014 lawsuit filed by the organization Students for Fair Admissions (SFFA), which represents Asian Americans who at some point were rejected from Harvard, contain compelling evidence that the university’s admissions system disadvantages Asian applicants. Behind the scenes, the plaintiffs allege, the school’s admissions officers engaged in crafty tactics to build freshman classes comprised of students with a range of backgrounds, interests, and strengths. This scheme, according to the lawsuit, which is slated to go to trial in October, entails a degree of racial balancing that disadvantages Asian Americans and thus violates federal civil-rights law.

I’ve argued that ascertaining whether Harvard does indeed discriminate on the basis of race is all but impossible. The university, like most of the country’s elite higher-education institutions, takes a holistic approach to admissions: Rather than looking strictly at an applicant’s standardized-test scores and GPA, officers also consider where she’s from (to ensure geographic diversity on campus), what her professional goals are (to ensure academic diversity), what her non-academic strengths are (to ensure extracurricular diversity), what kind of person she is (to ensure incoming freshmen will infuse the campus culture with leadership, charisma, and benevolence), and so on. The court filings suggest that Asian American applicants in particular are penalized when it comes to that last category. They consistently received lower rankings when it came to their soft skills—traits ranging from “likeability” to “courage”—which aligns with harmful stereotypes about Asian Americans. This seemed to indicate that some degree of racial bias is influencing admissions decisions—though it hardly proves it.

[Asian Americans have a thorny relationship with affirmative action.]

As Natasha Warikoo, an associate professor of education at Harvard and the author of The Diversity Bargain, a book about the role of race at elite universities, recently told me, “There’s no such thing as a perfect admissions system that leads to ‘a meritocracy.’” In other words, no matter what, any admissions process is inherently going to privilege one group over another. And when the criteria are so fuzzy, there’s no way to definitively identify, let alone root out, discrimination.

But what if Harvard created a fixed set of criteria that it deems desirable—say, an SAT score of 1470 or above, a 3.5 or higher GPA, a demonstrable interest and aptitude in particular non-academic activities, a record of overcoming obstacles, and so on? To continue to promote diversity, the school could give extra weight to certain applicants depending on, say, their zip code, the kind of high school they attended, their income, and their race. Then admissions officers could use those criteria to whittle down their batch of 40,000 applicants to a much smaller pool of qualified contenders and from there select the final 2,000 or so through a lottery (not everyone who’s admitted attends). Proponents, including Warikoo, suggest that this approach could help Harvard (and other universities) avoid accusations of racial discrimination while still helping it achieve its goal of building a diverse class.

In this system, “instead of being the ‘best,’ [students] would only have to be ‘good enough’—and lucky,” wrote Barry Schwartz, a psychologist at Swarthmore College, in a 2015 opinion piece for The New York Times. And while it may feel unjust to the students who aren’t lucky enough to get their name drawn out of a hat, experts have long argued that such a strategy is in fact the most fair. As the philosopher Peter Stone wrote in the journal Comparative Education Review, “Fairness … requires random selection under the right circumstances.”

The idea of a lottery system as a fix for elite-college admissions isn’t new. Lani Guinier, a professor emerita of law at Harvard, for example, broached the idea in a 1997 Times op-ed on affirmative action: Schools, she wrote, could establish a minimum test score; students “who offer qualities that are considered valuable would then have their names entered more than once … to increase their chances of being selected.”

And the benefits of such a system would, proponents argue, extend beyond creating transparency in colleges’ racial-diversity efforts. In a 2005 op-ed in The Chronicle of Higher Education, Schwartz described the elite-college admissions process as “a fool’s errand”—one that disadvantages both students and schools.

For example, Schwartz contended, lotteries would encourage a certain degree of risk-taking among high-school students. In recognizing that their admission is random, perhaps highly qualified high-schoolers would embrace their passions and explore their intrinsic interests rather than pad their resumes with accomplishments and activities they think—and have been told—those elite colleges prioritize. Under the current model, “everything they do is calculated to produce better credentials—high grades, great SAT scores, impressive extracurricular activities,” Schwartz wrote. “They choose classes that play to their strengths, rather than those that might correct their weaknesses or nurture new interests.” The result, he argued, is a “distorted adolescence” for many of the country’s most talented youth.

[Getting into an elite college is a frenzied, soul-deadening process.]

The current approach to admissions, Schwartz concluded, could even undermine students’ learning and academic performance once they get to college. “By making students so competitive, our selective institutions are subverting their own educational aims,” he wrote. “They are admitting students who have done things for the wrong reasons in high school, and who are likely to be disappointing in college.” By reducing the transactional nature of elite-college admissions, a lottery system could reverse that trend. (Such a system could also save families money, reducing parents’ urge to invest in test-prep courses and tutoring, extracurricular activities, and private education in the hopes that such spending will give their kids a leg up in the admissions process.)

The proposal certainly has its opponents, including those who believe that a lottery is at odds with the principles of a meritocracy, which the country’s elite colleges and universities theoretically promote. Some argue that this model would simply shift the emphasis toward what criteria make or break an applicant’s chance of making it into lottery territory, ultimately failing to fully eliminate the problems it was designed to address. Jeffrey Selingo, an Atlantic contributing writer, has also noted that a lottery system probably wouldn’t “pass muster” with the Justice Department because antitrust law (which the department enforces) prevents colleges from sharing information with each other about applicants—a practice that would likely be integral to such a system.

Still, lotteries aren’t uncommon at charter schools in the country, as well as at colleges outside the U.S. As Stone, the philosopher, points out, England’s Leeds Metropolitan University and Huddersfield University use a lottery to determine applicants’ admission to their highly sought-after physiotherapy courses; universities across the Netherlands have likewise historically used a random-selection process to admit students to their medical, veterinary, and professional schools, giving extra weight to applicants with higher exam scores. The systems have faced scrutiny, but proponents of lotteries argue that their results are much fairer than the kinds of practices employed by America’s elite institutions.

But lotteries would only have a chance to make admissions fairer if all elite colleges embraced the system. On Monday, more than a dozen highly selective schools filed a court document in support of Harvard’s current practices. If that is any indication, a complete countrywide overhaul of admissions is very unlikely.



Airbnb, the popular platform that lets people rent out their homes and apartments, released the results of a volunteer survey this week containing the striking statistic that nearly one in 10 of its hosts in the United States is an educator. In some states the trend appears to be even more pronounced—more than a quarter of all Airbnb hosts in Utah and Wisconsin, for example, work as teachers or in education (the company includes in that category administrators and college professors). This is especially noteworthy given that an analysis of census and National Center for Education Statistics figures suggests that just less than 2 percent of adults in the country work as full-time K–12 teachers.

Many of these 45,000-plus educators in the U.S. are presumably using Airbnb to supplement their regular income, as teachers struggle with stagnant, if not declining, pay. The average annual salary for K–12 public-school teachers is roughly $58,000, and they typically spend a sizable chunk of that on classroom supplies integral to their jobs. Teachers’ frustration with the situation has become so acute that it drove educators en masse to the picket lines in certain parts of the country this past spring.

The typical teacher host earned $6,500 through Airbnb last year—hardly a negligible boost for financially strapped educators. And for many teachers, that boost is far more appealing than other means of supplementing their incomes. For one, the personality traits found in the quintessential teacher—socially adept and empathetic, responsive and adaptable, a passion for sharing knowledge—are also typical of good hosts. For another, teachers’ schedules mean they often have more flexibility in the summer. Some economists who study the teaching force, like the University of Missouri’s Michael Podgursky, argue that this flexibility, and not a need for supplemental income, is the key driver behind the trend. Still, according to the report, teachers last year earned roughly one-third of their total annual earnings from Airbnb through hosting during the summer months alone, suggesting that while they do host at a slightly higher rate during their “off season,” they’re still using the platform a fair amount during the school year.

[A coupon from Target is indicative of the state of teaching today]

This data echoes similar trends across the so-called sharing economy. While comparable statistics for other companies aren’t available, ample anecdotal evidence suggests that many teachers in recent years have gravitated toward companies like Uber, which has courted teachers as drivers after school and on the weekends. And as Vox has reported, citing Bureau of Labor Statistics data, close to one in five public-school teachers in 2016 held a second job during the school year; teachers were about five times more likely than the average full-time worker in the U.S. to have a part-time job.

The pay gap between teachers and other college-educated workers is bigger than ever, according to a 2016 report by the left-leaning Economic Policy Institute. “This is a crisis,” says Sylvia Allegretto, one of the report’s co-authors. Allegretto is referring to low pay, limited benefits, and a lack of funding for supplies and crumbling classrooms—all of which played into walkouts in states like West Virginia and Oklahoma, which are traditionally averse to union activity. And the fact that striking teachers managed to garner so much community support, Allegretto argues, is “very telling” given that a growing share of Americans feel that teachers’ unions have a negative influence on public schools.

“I think we’re starting to turn the corner now,” in part thanks to the strikes, she added, “and people are realizing that teachers are one of the most valuable, critical professions in the country.”

That Airbnb and Uber are leveraging those sentiments to advance their business goals is a testament to this evolving mentality. Both companies spotlight the crisis Allegretto describes in touting their pull on educators. In the introduction of its report, for example, Airbnb highlights the alarming statistic that 94 percent of public-school teachers pay for school supplies with their own money, and that, on average, teachers earned less last year than they did in 1990 when adjusted for inflation. In that sense, the company suggests that its platform is helping invaluable members of society cope with the aftermath of the Great Recession.  

Uber has frequently disseminated a similar message: “Every day teachers are asked to do more with less, constantly faced with new challenges and limited resources. Uber opens the door for more possibilities and delivers a meaningful impact to the communities we serve,” the company wrote in a 2014 blog post. Uber has even held initiatives in some cities aimed at supporting teachers: In Portland, for instance, it had a promotion in 2016 for teacher drivers in which the company returned 3 percent of a rider’s fare back to the classroom of that driver (a.k.a., in the company’s parlance, the “UberEDUCATOR”).  

Both companies stress that this trend consists not only of a financial pick-me-up for cash-strapped teachers, but also of a symbiotic relationship of sorts. “Right now, the nation is having a conversation about how … teachers in this country are not given the respect and dignity they deserve,” said Christopher Nulty, an Airbnb spokesman. “We certainly don’t think homesharing is a solution [for all those problems] but we do believe it’s an important tool for teachers” to help cope with them, “and frankly we’re really proud of the fact that 10 percent of the [Airbnb hosting] community is teachers.”

[There are larger concerns behind the teachers’ strikes]

That pride, suggests Arun Sundararajan, a professor at the NYU Stern School of Business, stems in part from the fact that the company has faced intense scrutiny from critics who claim that it enables landlords to take housing off the rental market and basically convert buildings and apartments into hotels, and that it intensifies gentrification. In many cities, proposed regulations threaten to crack down on this phenomenon by significantly limiting the company’s operations or banning it altogether; New York City, for example, recently passed a measure that significantly hamstrings Airbnb’s operations in the city.

Companies like Airbnb and Uber are trying to “promote the narrative that [hosts and drivers] are truly everyday people” who are “casually” participating in the platforms on the side, Sundararajan says. “Highlighting the number of workers who are teachers can be a particularly effective way of advancing that narrative.” It helps humanize the companies. It emphasizes the message that these are safe alternatives to regular cabs and hotels—as Sundararajan puts it, “If society trusts this person with our children, then I feel more comfortable sleeping in their bedroom.”

Nulty, the Airbnb spokesman, expresses these very sentiments in explaining why the company is proud that so many of its hosts are teachers. “It’s hard to imagine a group of people who are more welcoming, more thoughtful, and who enjoy sharing about their community and about their world more than teachers,” he says. “In a moment when there are conversations about building walls, putting up barriers, we really see the ability of people to stay in someone else’s home and have an experience and a connection with another person as a powerful and transformative moment and experience. In classrooms across the country every day, teachers are making those sort of moments and experiences happen in a really compelling and tangible way.”

Chances are that, on top of the supplemental income, many of those educators find joy in meeting and learning from new people, in sharing and welcoming others into their homes. And Airbnb and Uber love letting the public know that their ranks are brimming with teachers. But this relationship, even if mutually beneficial, only exists because for so many teachers, their primary career isn’t enough to sustain them. 



Michelle Robinson didn’t shy away from her background in her application essay for Princeton University. The Chicago native wrote about the lack of college degrees in her family, and her father’s struggle with multiple sclerosis. While she was in the top 10 percent of her high-school class, a member of the National Honor Society, and the class treasurer—not to mention that her older brother was already enrolled there—she was far from a shoo-in at the Ivy League university. Less than 8 percent of the undergraduate students at Princeton were black, and it wasn’t exactly known as a mecca for low-income students. But her essay worked, and in the fall of 1981, she left Chicago for Princeton, New Jersey.

Of course, Robinson would go on to marry Barack Obama and serve as the first lady for eight years. In Becoming, her newly released memoir, she reflects on her experiences in high school and college. Just as her college essay embraced her background, so too does Becoming. And beyond revealing her own story, Michelle Obama’s tales of applying to and enrolling in Princeton are emblematic of an all-too-common narrative for low-income and minority students, particularly those at elite institutions.

Obama arrived on campus earlier than most other students. She had been identified as a good candidate for a three-week orientation program “meant to close a ‘preparation gap’” for certain incoming freshmen—specifically, low-income and minority students. But there are some things even a head start can’t prepare students for. “Princeton was extremely white and very male. There was no avoiding the facts,” she writes. “If during the orientation program we’d begun to feel some ownership of the space, we were now a glaring anomaly—poppy seeds in a bowl of rice.”

That is a shared sentiment among students of color on selective college campuses today. In 2015, Tavaris Sanders, a black student at Connecticut College, put the sentiment bluntly: “I’m always segregated in classes. I’m like the only black male in there, always, usually, most of the time,” he wrote. “I don’t belong here at all.”

But there are often places of refuge for minority students, and Obama found hers at Princeton’s so-called Third World Center. As she writes, it “quickly became a kind of home base for me. It hosted parties and co-op meals. There were volunteer tutors to help with homework and spaces just to hang out.”

There she found students like herself, who had arrived on campus unaware of their disadvantages relative to their classmates. They weren’t afforded the privilege of SAT prep or AP classes in high school. They hadn’t attended boarding school, and so often weren’t as comfortable with being away from home. “It was like stepping onstage at your first piano recital and realizing that you’d never played anything but an instrument with broken keys,” she writes. So, to adapt and overcome, she leaned on a community that was experiencing the same struggles she was.

The administrators, though, probably weren’t too fond of this setup, she says—with the majority of the minority students hanging out with one another. The university was after campus diversity—the compelling governmental interest that had been outlined in a Supreme Court decision just a few years earlier. As Obama puts it, “The ideal would be to achieve something resembling what’s often shown on college brochures—smiling students working and socializing in neat, ethnically blended groups.”

But the dynamics on campus never quite resembled the glossy brochure images. “Even today,” Obama writes, “with white students continuing to outnumber students of color on college campuses, the burden of assimilation is put largely on the shoulders of minority students.” And in her experience, she writes, “it’s a lot to ask.”

For black students such as Obama, affirmative action was a constant elephant in the room, she writes. Though they knew they were qualified, “you could almost read the scrutiny in the gaze of certain students and even professors,” she writes. And the practice of affirmative action recently received a renewed wave of scrutiny as Harvard University, where Obama’s daughter Malia is now a sophomore, is being sued for allegedly discriminating against Asian American applicants.

More than three decades later, with her own undergraduate years firmly in the past, Michelle Obama’s struggles as a black student at Princeton are eerily similar to the experiences of students today. Nestled within Becoming is a long-held truth about American higher education: Supporting students—particularly low-income and minority students—once they’re on campus matters at least as much as getting them there in the first place.



Since sexual-assault allegations against the sports doctor Larry Nassar became public, top administrators at Michigan State University have claimed they didn’t know—and could not have been reasonably expected to know—about the systematic abuse that took place on their campus for more than two decades. But according to a new lawsuit, in 1992, 24 years before Nassar was fired from the university, MSU’s then–athletic director and head football coach, George Perles, was allegedly presented with perhaps the most damning piece of evidence imaginable: a videotape. The tape, which the lawsuit claims was shot by a cameraman at Nassar’s request, allegedly showed the sports doctor raping a drugged and near-unconscious Erika Davis, a 17-year-old member of the MSU field-hockey team. The lawsuit accuses Perles (who has denied the allegations) of making sure the tape went nowhere, returning it to Nassar, and then forcing the coach who obtained the footage to sign a nondisclosure agreement and resign.

Today, Perles is one of eight members on the MSU board of trustees.

It’s been two years since the Nassar story broke—and eight months since the sports doctor was found guilty of assaulting more than 150 women, including dozens of former MSU students. For many, there have been serious consequences. Nassar will, in all likelihood, be in prison for the rest of his life. Multiple MSU staff members accused of covering up the abuse, including former President Lou Anna K. Simon, have resigned or been asked to leave. Meanwhile, MSU’s top governing body—its board of trustees—has remained entirely intact, despite campus-wide protests calling for all eight members to step down.

Since the Perles allegations became public, MSU students and faculty have begun asking old questions with new urgency: Did board members know about the abuse? Did they cover it up? What could the board have done to stop Nassar, years or even decades before he eventually left the school? “A board of trustees is, at the end of the day, responsible for everything that takes place on campus,” says Michael Poliakoff, the president of the American Council of Trustees and Alumni (ACTA). “And the MSU board was not nearly as proactive as it should have been.”

In the months since Nassar’s conviction, most board members have shirked all responsibility for how the case was handled. This lack of accountability, Poliakoff told me, likely stems from the board’s process for selecting new members. Michigan State is one of three universities in the country that chooses its board via statewide elections. (The other two are the University of Michigan and Wayne State University, in Detroit.) The vast majority of boards at public colleges are appointed by the governor of their state, a process endorsed by industry specialists. “That way, the governor is identifiable as the person who has put that particular group of trustees onto the board,” Poliakoff said. “If the board is not acting in a proactive, responsible manner, the governor will be called to account.” After MSU’s board members are elected to eight-year terms—the norm in other states, according to Poliakoff, is four to six years—by a constituency that, for the most part, has no connection to the school, there is very little to compel them to stand up to the administration, or to answer to MSU students, faculty, and staff. “You have to understand, this is a very, very unique structure,” the current MSU board member Brian Mosallam told me in an interview. “Because we are elected in this way, we have no oversight—except what we do to police each other.”

The MSU board has long been cozy with top administrators, particularly President Simon, multiple staff and faculty members said. “The board seldom met without Simon,” Mosallam wrote to me in an email. “There was no fire wall between President Simon and the Board.” Mosallam said he privately voiced concerns about trustees’ close relationships with Simon to several of his fellow board members. “I know they felt the same way that I did.” (Former President Simon did not respond to a request for comment on this story, and neither did any of the other trustees.) After Nassar’s trial, when victims began calling for Simon’s resignation, the board initially stood by the president, issuing a public statement of support. “That’s not going to happen. Period,” the trustee Joel Ferguson said in a radio interview, when asked about the possibility of Simon stepping down. “She’s not going to get run out of there by what someone else did.” Facing mounting national pressure, two trustees, Mitch Lyons and Dianne Byrum, finally called for Simon’s resignation in late January. She stepped down four days later.

Most of the staff members accused of covering up Nassar’s abuse—or of failing to adequately investigate—are affiliated with the university’s athletic department. Nassar himself, of course, was a world-renowned Olympic sports therapist. So the board’s close ties to MSU athletics have raised questions about its members’ personal biases: the trustees Mosallam and Lyons are former MSU football players, and Perles was the head football coach for 11 years. The school’s basketball arena was named after the board chairman Brian Breslin’s father.

The trustees continue to be die-hard Spartan sports fans. MSU is one of the few colleges in the country that allows trustees to travel with school sports teams on chartered planes and buses, covering all travel costs for the trustees and one guest each. This kind of perk—which six of the eight trustees have taken advantage of at least once—can sow resentment on campus, said Armand Alacbay, ACTA’s vice president of trustee and government affairs.“It can lead to the appearance of favoritism,” he said. (As of July, the trustee Ferguson had traveled with the MSU football or basketball team 19 times.)

These kinds of close relationships are likely a direct result of long term limits, Poliakoff believes. Four of the current MSU trustees have held their position for 10 years or more—and Ferguson, MSU’s longest-serving trustee, was elected in 1986. With these long tenures, Poliakoff said, board members risk becoming too close with the administration. “They can become complacent about the actions of university personnel—and not inquire in the way that responsible fiduciaries should,” he said. When responding to a sweeping scandal like the Nassar case, he told me, trustees need to question every administrator who could have possibly been involved, regardless of how well they know them. That includes, as the Perles allegations have made clear, fellow members of the board. “Boards will sometimes say, ‘Oh, we know we can trust her, she’s been here for 15 years,’” Poliakoff said. “No. No, you don’t know that.”

When Simon resigned, campus leaders issued clear statements about the kind of person they thought should take her place. The faculty senate recommended they choose an interim president with experience both leading a university and dealing directly with cases of sexual assault and harassment. The board selected former Michigan Governor John Engler, who had neither—and who, as governor, was publicly accused of ignoring female inmates who claimed they were raped and sexually harassed by prison guards. The faculty senate immediately issued a vote of no confidence, calling on the entire board to resign.

Around the same time, several administrators organized a town hall, a public conversation with the board of trustees. More than 600 people—students, faculty, staff, and alumni—lined up outside the campus conference center. But of the eight board members, only one—Mosallam—showed up. Even after the Nassar case, Mosallam told me, the trustees still weren’t fully focused on what was happening on campus. “There are some that are disengaged; there are some that are afraid of litigation,” he said. “There are some who just want to put their heads in the sand and make sure it all goes away.” When I asked him why he spoke to the MSU community alone in February, he replied, hotly, “You would have to ask the other trustees.”

After watching the current slate of trustees respond to the Nassar case, several groups want to change the way the board works. James Lower, a Michigan state representative, has proposed amending the constitution to have trustees be appointed by the governor, rather than selected through statewide elections. Other figures on campus, including Mosallam and the leaders of the faculty senate, have called for faculty and student representatives to be added to the board. But that probably won’t happen anytime soon. Until the trustee-selection process changes, some Michigan residents may be paying closer attention to the names of the board candidates at the bottom of their ballot. Kellie Dalton, a 44-year-old MSU graduate, says she used to ignore the trustee races. “Not this year,” she said in an interview with the Detroit Free Press. “I think I’m going to do more studying on the MSU board than I’ve ever done in all the years I’ve been voting combined.” (Two of the board’s eight positions will be open this November.)

With a current trustee accused of personally covering up Nassar’s abuse, campus activists aren’t sure of their next move. Students and faculty certainly want Perles to resign, said Anna Pegler-Gordon, a professor of social relations at MSU, but they also want to stay focused on the university’s future, particularly the upcoming administrative changes—the two open positions on the board and the search for MSU’s next president, especially after one trustee recently suggested the school consider internal candidates for that position. “People seem concerned that this is much broader than just Perles, even though he is the center of attention,” Pegler-Gordon wrote in an email. But she said she has no expectation that Perles will step down.



As the costs of college have climbed, some students have gone hungry. When they’ve voiced frustration, they’ve often been ridiculed: “Ramen is cheap,” or “Just eat cereal.”

But the blight of food insecurity among college students is real, and a new report from the Government Accountability Office (GAO), a nonpartisan congressional watchdog, highlights the breadth of those affected. There are potentially millions of students at risk of being food insecure, which means they do not have access to nutritious, affordable food, the report says. It is the first time the federal government has acknowledged food insecurity on campus in a significant way. The federal government spends billions of dollars on higher education each year, and this report finds that some students are at risk of dropping out because they cannot eat, although there aren’t good data on just how many.

Existing studies vary in how they describe the scale of the problem. “Nationally representative survey data that would support direct estimates of the prevalence of food insecurity among college students do not exist,” the report says. So the GAO conducted a review of 31 studies that met their criteria—meaning they had been conducted in the United States since 2007 and did not have severe methodological limitations. Twenty-two of those 31 studies estimate that more than 30 percent of students are food insecure.

“[The report] put it very clearly for us that we can see that especially first-time students, first-gen students, students who are raising children, single parents, face increasing obstacles to be able to complete that critical college degree,” Senator Patty Murray, the top Democrat on the Senate’s education committee, told me. The report was in response to a letter sent to the GAO on behalf of Murray, Senator Debbie Stabenow, Senator Edward Markey, and Senator Elizabeth Warren last year.

One chief way that campuses have been addressing hunger is by building food pantries on campus, but Sara Goldrick-Rab, a higher-education professor at Temple University and a leading scholar on campus hunger, told me that those only scratch the surface of the issue. “When there’s a food pantry, there’s somebody who is acknowledging the problem,” she says, but advocates have been fighting for a more systemic response.

The government can address this issue systemically through the Supplemental Nutrition Assistance Program (SNAP, commonly known as food stamps), the report says, but it adds that “almost 2 million at-risk students”—defined as students who are low income or first generation, are raising children, or have another, similar risk factor—didn’t receive SNAP benefits in 2016, even though they potentially could have.

That could be because those students didn’t know they were eligible: The government restricts students who attend college at least half-time from receiving the benefits, but certain students are exempt from that restriction. The information that most schools and SNAP offices provide students about the program is shoddy, says Samuel Chu, a national organizer for Mazon, an advocacy organization focused on eradicating hunger. “There are very specific ways and accessible ways that students can access SNAP,” he says, but even local SNAP offices are often unaware. For example, students who meet the basic criteria for SNAP eligibility and are younger than 18 or older than 50, or who have children, or who work a minimum of 20 hours a week are also eligible to receive the benefit. The GAO implored the Food and Nutrition Service, which administers SNAP, to improve information about student eligibility and share that information with its local offices.

Of course, the SNAP program is dependent on government funding, which makes it subject to budget cuts or unforeseen events such as the ongoing partial government shutdown. If the shutdown continues for a couple more weeks, SNAP may run out of funds for the 38 million Americans who receive its benefits.

Naturally, the report focuses heavily on low-income students, as they are perhaps those most likely to experience food insecurity. But Goldrick-Rab notes that they aren’t the only students who are going hungry. Middle-class students, those who are “too rich for Pell and too poor to afford college,” struggle as well. And they may not be as likely to use things such as the food pantry.

Murray told me that addressing food insecurity is one of her top priorities as Congress negotiates a reauthorization of the Higher Education Act, the major federal law governing colleges and universities. “Often we just talk about the tuition costs and dealing with that,” she says. “It has to be broader than that—[it has to be] all of the costs that come to a student as they try to complete college, including food and housing.”

Goldrick-Rab put it more bluntly. The report shows “that food insecurity is a college-completion issue,” she says. “We’re undermining our federal investment in financial aid by not paying attention to this. We have to stop pretending like living expenses are not educational expenses.”



Even some of the most powerful tech companies start out tiny, with a young innovator daydreaming about creating the next big thing. As today’s tech firms receive increased moral scrutiny, it raises a question about tomorrow’s: Is that young person thinking about the tremendous ethical responsibility they’d be taking on if their dream comes true?

Greg Epstein, the recently appointed humanist chaplain at MIT, sees his new role as key to helping such entrepreneurial students think through the ethical ramifications of their work. As many college students continue to move away from organized religion, some universities have appointed secular chaplains like Epstein to help non-religious students lead ethical, meaningful lives. At MIT, Epstein plans to spark conversations about the ethics of technology—conversations that will sometimes involve religious groups on campus, and that may sometimes carry over to Harvard, where he has held (and will continue to hold) the same position since 2005.

I recently spoke with Epstein about how young people can think ethically about going into the tech industry and what his role will look like. This interview has been lightly edited and condensed.

Isabel Fattal: Tell me a bit more about what you see as the purpose of your new role, particularly as it relates to the ethics of technology.

Greg Epstein: I’ve been the humanist chaplain at Harvard since 2005. In these 14 or so years of experience that I've had, the single biggest thing I think we as humanists and human beings need to look at when we’re training young leaders today is the need for more attention to human values in science, technology, and business. The world is being reshaped before our eyes, and we’re not ready on campus, because we don’t have an ethical footing from which to teach. At MIT I feel like I’m being given an opportunity to offer a perspective and to help students determine their own perspective.

Fattal: How would you advise students working with technology to think about ethical dilemmas?

Epstein: One of the things that I would start with is to say, “When you’re thinking it through, whatever you do, do not think these things through isolated and alone—you must be part of some kind of broader community in order to make reasonable, effective moral decisions.” A lot of the young men who are taught to be entrepreneurs are trying to become a kind of superhero, to go and solve the world’s problems on their own, and to receive ticker-tape parades and the admiration of the masses for doing so. That mentality is one of the things that is most dangerous in our contemporary ethical life. You have relatively well-meaning people in many cases with at least half-decent ideas who end up inflicting so much damage.

Fattal: It’s probably really hard to tell someone just starting out in their career to make choices that might get in the way of their making a profit. How do you think about getting students to see that longer-term goal?

Epstein: Privilege is losing its luster. People are more interested in figuring out how they can be of service to others and how they can be the solution to society’s problems than anything else. I'm talking to nuclear engineers, artificial-intelligence engineers, math geniuses, chemists, and physicists who really want to use their skill sets to make the world better. They don't necessarily know how. But they’re looking for a hub to bring together like-minded people to become friends with one another in the interest of being a more powerful moral community. There’s a real need right now to bring these students together. Each of these students that meets with me feels isolated. They’re all really surprised to see that there are these clusters of people like them who want to do something ethical with their gifts.

Fattal: There seems to be a general sense lately that tech has crossed a kind of ethical line. Are you seeing that mindset in the students you work with at MIT?

Epstein: Yes—we’ve crossed a red line. These companies have reshaped the world for better and for worse. We have to fix them. It’s not a coincidence that when I first got to Harvard, about 15 years ago, the gravitational pull on most of my students was from investment banking, and now it is Silicon Valley, technology, and social media. That is the gravitational pull. They no longer aspire to work at Goldman Sachs. They want to be Elon Musk. And Elon Musk will be the first to tell you that there can only be one Elon Musk.

Fattal: Why can there only be one Elon Musk?

Epstein: I’m not an expert on Elon Musk. But I do think that while it must be flattering for him to see so many gifted young people on campuses like Harvard and MIT idolizing him and worshipping him as a hero, if I were him I would also be a little bit concerned about the idea that we’re making any one individual in this day and age into a hero to be worshipped, particularly a white male, given that we’ve had dozens of years of Hollywood movies to tell us that white men will save the world, when in fact we can’t and we won’t. We, too, just as much as anybody, if not more so, need to be part of bigger, broader, collective structures, and we need to be part of empowering people who don’t look like us and who weren’t socialized like us.



The first sentence of the New York Times story was like a blow to the gut. “Seven black students have been offered a chance to start classes at Stuyvesant High School in September,” out of 952 total offers. It was two fewer black students than the nine the school had accepted the year prior in a freshman class of 963 students. In response, a state lawmaker declared that he would redraft a bill he had introduced three years earlier to change the admissions policies at the school; the city reeled. It was 2014.

On Monday, almost five years later to the day, the New York City Department of Education released data about the students admitted to its vaunted selective schools. More than 27,000 eighth graders took the Specialized High School Admissions Test (SHSAT) this year—a rigorous aptitude test that is the sole factor for admission to eight of the nine selective high schools—and 4,798 students received offers based on those exam scores. Of those offers, 10.5 percent went to black and Latino students—a tenth of a tick up from the 10.4 percent of offers in 2018—despite New York City’s public schools being nearly 66 percent black and Latino.

It’s an uncomfortable truth that, at this point, this is the result that the New York City public-school admissions infrastructure seems designed to produce. But the result is so galling that, year after year, it triggers a shocked response. Monday’s Times headline: “Only 7 Black Students Got Into N.Y.’s Most Selective High School, Out of 895 Spots.” A different byline, a different year, the same problem. Only seven students, again.

“We’re … once again confronted by an unacceptable status quo at our specialized high schools,” Richard Carranza, the chancellor of the New York City public-school system, said in a statement. “We need to eliminate the single test for specialized high-school admissions now.”

The public schools in New York State are the most segregated in the country, according to a 2014 study from the Civil Rights Project at UCLA. That’s largely driven by New York City. The selective high schools are by no means the only places where inequality exists in the system, but they are the most visible, the easiest apple to pick. The black enrollment at Stuyvesant peaked in 1975, according to state records highlighted in a 2012 profile in the Times, when there were 303 black students out of 2,536 total. “In 1980, there were 212 black students; in 1990, 147; in 2000, 109; and in 2005, 66.” Last year, there were 24 black students, according to city data. The SHSAT was introduced as the sole admissions criterion for the school in 1972.

Rudi-Ann Miller, a black woman who attended Stuyvesant and whom the Times followed for the 2012 story, had her five-year high-school reunion last year. In an interview on Wednesday, she told me that she was the only black student who showed up. Even though there were a handful of black students in her class, “it wasn’t an experience that they wanted to go back and celebrate,” she says. Stuyvesant is diverse, she says—among the Asian population, in particular—but the low number of black and Latino students made her experience difficult. “I’m not going to sugarcoat my experience and say it was lovely and great and this amazing intellectual challenge,” she says. “There were also a lot of social issues to deal with.” Still, she added, it was the “best educational opportunity in the city.”

Last year, when I interviewed Carranza for a profile examining the city’s efforts to desegregate the public schools, he reflected on his career. “Everywhere I’ve ever lived and worked, there are systems and structures that promulgate certain outcomes,” he told me. “The systems and structures give you what you get. And what I’ve found is that what you get is low performance for kids of color, low opportunities for kids of color, poor kids, kids that have historically been underserved.”

Miller says that she was the only student in her majority-Latino middle school who planned to take the selective high-school placement test. Many of her fellow students didn’t know about it, she says. The city has expanded efforts to inform more students about the test, and provide preparatory tutoring for them, but the needle still has not moved on black enrollment. Miller isn’t sure that getting rid of the test altogether is a good idea, but she is concerned that the test can be gamed. She took a prep course, and she heard of several other people who took three or four. Some students can learn how to take the test and get a leg up; others think the odds are so stacked against them that it isn’t even worth it to try.

It is likely that next year the internet will be shocked once again by the staggering disparity in black enrollment at Stuyvesant, and there will be another conversation about what needs to happen to fix it. And then it’s likely to happen again the year after that.



Every few years, new concerns bloom about the changing ways young people are approaching relationships, from the stigmatized early years of online dating in the 1990s and 2000s to the panic over campus hookup culture in the early 2010s to the dawning concern that rather than having too much sex, Millennials aren’t having enough. Many young people are now experiencing a sex recession, my colleague Kate Julian wrote for the cover of this magazine in December.

But long before Tinder or Match.com were founded, and even before most universities went coed, the seeds of these ideas were planted in another Atlantic article: Nora Johnson’s influential “Sex and the College Girl.” Written in 1959, the article captured a snapshot of college romance on the lip of the sexual revolution and the second-wave feminist movement: Young women were pulling back from romantic commitment and domestic life to explore their options; young men were left bewildered and resentful as their relationships shifted in turn.

Johnson framed the moment not as one of ecstatic liberation, but rather as an uncertain and sometimes overwhelming introduction of possibility for female students. She observed educated women navigating a convoluted path of desire, respect, security, and shame in pursuit of the dream of a full life: “a husband, a career, community work, children, and the rest.” Only an exceptional few could achieve that life without sacrificing personal or professional goals along the way, she predicted. For many of the rest of them, this pursuit would end in “an ulcer, a divorce, a psychiatrist, or deep disappointment”; and for some of them, those who were put off by the apparent futility of trying to balance all the expansive possibilities, “the most confining kind of domestic life.” Without the “moral generalizations” of her grandmother’s era, Johnson’s college girl was left to forge ahead toward those difficult choices with more subjective, and personal, judgment—carrying “her belief in herself,” or what she calls the “modern version” of herself, forward into the unknown.

Johnson wrote “Sex and the College Girl” when she was 26, just five years after graduating from Smith. Though young, she was already beginning to establish herself as an author. She’d grown up as the daughter of a Hollywood filmmaker, surrounded by “an encampment of storytellers,” as she later recalled, and had published her first and ultimately most successful novel, The World of Henry Orient, a year earlier. Like “Sex and the College Girl,” the book drew on her own experiences as a student, fictionalizing the crush she and a friend had nursed for an actor-musician while they were in high school.

As Johnson grew older, the subjects of her writing generally did too, maturing as the decades wore on from students navigating the college dating scene to married couples to divorcées to aging lovers. But though the characters changed, the sense of uncertain possibility she described in “Sex and the College Girl” remained—sometimes joyful, sometimes dutiful, sometimes onerous, but never entirely gone. Johnson’s love stories, told in an era of expanding female choices, were weighted with the consciousness of them.

In “Sex and the College Girl,” the choices were myriad, novel, and full of potentially far-reaching consequences. Female students faced decisions about who to date, what to offer physically and emotionally, and how much to hold in reserve for how long. Beyond that immediate horizon stretched a broader array of opportunities and potential pitfalls: children, careers, and all of the self-betterment and intellectual rigor their educations were preparing them for. Commitment and marriage, in a sense, presented an out—a sense of certainty, a solid support system. “Joe has a future,” Johnson wrote. “He knows exactly what he is going to do after graduation … The decision about [the college girl’s] life keeps her awake at night, but when she is with Joe things make more sense.”

Two years later, in “The Captivity of Marriage,” Johnson described the constrained choices of the women who stuck with their Joes. Now juggling the responsibilities of raising children, keeping a house, and engaging in “community or P.T.A. work of some kind,” married women “feel … like a pie with not enough pieces to go around,” Johnson wrote. But the new responsibilities and family and community ties did not put the “undefined dreams” of their younger years to rest; instead, the wife and mother “vaguely feels that she is frittering away her days and that a half-defined but important part of her ability is lying about unused.” That feeling of dissatisfaction, Johnson observed, was coupled with the lingering “quality of excitement that comes from strangeness and the idealization of still-unknown experience” that made the concept of sex with an unfamiliar partner attractive. But those choices, which would take women away from their husbands and children, were now taboo. In their place were new choices, more limited but still unfamiliar and consequential. “Choosing a house and everything that goes into it, and a school, and a competent doctor are decisions that the young mother makes without adequate knowledge,” Johnson wrote, “and she can ill afford mistakes.”

She described the fallout from one error in judgment a year later in “A Marriage on the Rocks,” an article published in the July 1962 issue of The Atlantic. “The moment when it first becomes apparent that one’s marriage was a mistake,” she opened the piece, “is the beginning of probably the longest, darkest period in the human lifetime.” She chronicled the slow fracturing of a union that, to the college girl, had carried a promise of lifelong certainty in an otherwise unknown future. Unhappiness settled in and grew unbearable as the relationship devolved into “the endless opening of wounds … capitulating one’s beliefs … [and] adjusting oneself to the dismal and baneful workable compromise.” But choosing to break free of  that unhappiness meant exchanging it for a new, unknown one, defined by a sudden and “terrible feeling of having no one around on whom to blame everything.”

Johnson expressed the frustration of seeing a marriage fail while knowing that, with the newly available options for women to marry for love and to define more aspects of their life and work, “all of us ... have the potential to become the greatest lovers on earth.” She wondered: “All this freedom and opportunity are breathtaking. Do we deserve them, and can we possibly live up to their obligations?”

Divorce loomed large in Johnson’s life. Her parents’ marriage ended when she was 6 years old, and they moved to separate coasts, leaving Johnson to shuttle back and forth between her mother’s New York home and her father’s star-studded Hollywood life for much of her childhood and adolescence. “My heart begins to tear, a long ragged rent which I have spent my life trying to mend,” she reflected in her 1982 memoir You Can Go Home Again, looking back on the dissolution of her family. She recalled how her mother’s attempts to become “an elegant divorced lady in a lovely house in the most exciting city in the world” transitioned into a second marriage to a possessive man who resented Nora when she returned home for a time as an adult after her own first marriage failed.

By the time she turned 32 in 1965, Johnson had already been married, divorced, and married a second time herself. In The Atlantic's June 1961 issue, in which "The Captivity of Marriage” was published, she was introduced to readers as “happily married and the mother of two daughters.” When “A Marriage on the Rocks” was printed in the July 1962 issue,those details were omitted from her introduction. By the time she published You Can Go Home Again at the age of 59, her second marriage had also ended in divorce. In that sense, she fulfilled the melancholy predictions of “Sex and the College Girl” twice over.

But she had also built a successful career as a writer of novels, memoirs, articles, and, once, in collaboration her father, a movie based on The World of Henry Orient. Decades later, in an essay for The New York Times, she wrote about something she hadn’t predicted: finding love again. Johnson “was a long-divorced 71”; George was 83 and “recently widowed.” He became her third husband. “What astonished us,” she wrote, “was that the electricity we generated was as strong and compelling as love had been 50 years before, that it scrambled the brain every bit as much. Yet more surprising was that we had a rousing and delightful sex life.”

They still faced daunting choices and disappointments. At first they lived together in Florida, but they grew bored and moved to New York, only to grow bored there too, and be cold, and miss Florida. They dealt with natural disasters and health problems. They had difficult conversations. And then, seven years after they met, George died.

All Johnson’s stories resist the neat closure of the happily ever after. The security that Joe seems to present in “Sex and the College Girl” proves illusory; love degrades, fractures apart, or abruptly ends. “Marriage, entered upon maturely, is the only life for most women,” Johnson wrote in 1961. “But it is a way of life, not a magic bag of goodies at the end of the road.” Even old age, retirement, and George, who she said “brought joy and magic to my life,” don’t put the uncertain possibility of other paths to rest or stave off the sting of disappointment.

But her stories also resist the closure of a final failure. The college girl grows up, gets married, gets divorced, gets married again. She makes the wrong choices and then gets to make new ones. “This, then, is what the result is for a girl who has been brought up in a world where the only real value is self-betterment,” Johnson concluded in 1959. “She has had to create her own right and wrong, by trial and error and endless discussion.”

This is the story that Johnson wrote again and again, for several decades, until she died in 2017: There’s no happily ever after, or any ever after at all, but there’s happiness. Heartbreak. Regret. Magic. Surprise. Her extraordinary work was also a life lived, and recorded in pieces, over decades of love stories.



Medical school costs a lot of money that a lot of people don’t have. That often means students do a bit of cost-benefit analysis: Is it worth it to take on hundreds of thousands of dollars of debt now for the possibility of making hundreds of thousands of dollars a year later?

New York University’s School of Medicine is trying remove that calculation as a factor in students’ career decision making. The school announced yesterday that it will provide all new, future, and current students a full-tuition scholarship—financial need and merit aside, meaning wealthy students and low-income students alike will receive it. The scholarship doesn’t cover the rest of the costs associated with college—housing, food, child care—but it takes $55,018 a year out of the picture.

“This decision recognizes a moral imperative that must be addressed, as institutions place an increasing debt burden on young people who aspire to become physicians,” Robert Grossman, the school’s dean, said in a statement. “A population as diverse as ours is best served by doctors from all walks of life, we believe, and aspiring physicians and surgeons should not be prevented from pursuing a career in medicine because of the prospect of overwhelming financial debt.” The school will need to raise $600 million to fund the project—$450 million of which it says has already been raised.

But beyond simply making it easier to pursue a career in medicine, perhaps removing at least a portion of the debt associated with medical school—the median debt of a student graduating from a private medical school is more than $200,000—will also allow students to chase less-lucrative yet socially important fields of medicine. And if other institutions follow NYU’s lead, that may help put a dent in the dearth of diversity in a field in which a little more than 8 percent of physicians are black and less than 7 percent are Latino.

“Tuition-free medical education goes beyond the merit and financial scholarships, and debt cancellations that other academic centers have traditionally favored,” Rafael Rivera, the associate dean for admissions and financial aid at the medical school, said in a statement. “More importantly,” he continued, “it addresses both physician shortages and diversity.”

According to the Association of American Medical Colleges (AAMC), the United States is on track to have a shortage of up to 120,000 doctors by 2030. Up to 49,000 of that shortfall will be in the realm of primary-care physicians—typically the first doctors patients see when they know something is wrong but aren’t exactly sure what, or when they need a routine checkup. Primary-care work, however, pays far less than many other specialties. A recent survey showed that, on average, primary-care physicians make around $100,000 less than specialists each year—the average salary hovers around $223,000, though family doctors and primary-care physicians can make slightly more in rural areas.

Even though some doctors may choose to work in rural areas—where they could make more money—to help chop away at their educational debt, the areas still have a great need for more doctors. And since 2010, there have been 87 rural-hospital closures.

The number of graduating medical students who say they plan to care for “an underserved population,” according to an AAMC survey, has increased seven percentage points over the past four years to 34.7 percent. (Though that percentage dropped to 26.4 when the question became, “Do you plan to work primarily in an underserved area?”) But research has shown that students with higher debt than their peers at their institution were less likely to practice in underserved locations—and, on top of that, they are less likely to become primary-care doctors, shirking the first-alert field for more lucrative specialities, such as orthopedic surgery or cardiology.

One school’s decision to offer free tuition won’t fix the primary-care crisis, of course, but if other institutions follow suit, some of those students who might have made different career calculations just to pay off their debt might have the freedom to instead go where they’re needed most.



In education, initiatives tend to roll down from above. A district buys a new curriculum, or gets funding for a new program, and principals receive their marching orders, which they in turn hand down to teachers below.

That’s not the case at Ohio Avenue Elementary School in Columbus, Ohio.

The 19th-century corniced brick building is perhaps an unlikely home for experimental methods of nurturing children’s developing brains. The surrounding streets are lined with abandoned buildings, pawn shops, cash-advance outlets, and dollar stores. A large house with a boarded-up door sits directly across from the school’s playground. In Ohio Avenue’s zip code, half of the families with children under 18 live in poverty, as compared with 25 percent across Columbus and 17 percent nationally, according to census data.

Many of Ohio Avenue’s children have brushed against violence and other traumatic experiences in their short lives—abuse and neglect, a household member addicted to drugs, homelessness, to name a few. At schools like this, a small dispute can easily turn into a scuffle that leads to an administrator or school-safety officer corralling the kids involved, if not suspending them. But Ohio Avenue is trying to find another way: Every adult in the building has received training on how children respond to trauma. They’ve come to understand how trauma can make kids emotionally volatile and prone to misinterpret accidental bumps or offhand remarks as hostile. They’ve learned how to de-escalate conflict, and to interpret misbehavior not as a personal attack or an act of defiance. And they’re perennially looking for new ways to help the kids manage their overwhelming feelings and control their impulses.

Ohio Avenue struggles at times with managing students’ behavior, and some teachers have embraced the schoolʻs approach more than others, which itself can cause some tension sometimes. Meanwhile, it’s impossible to draw conclusions about the direct relationship between these efforts and student results. But educators say the positive changes that have accompanied this model are encouraging enough to continue experimenting with it.

“If the focus is on what the adults are doing, that’s where you get the bang for your buck. We can control what the adults do,” explained Olympia Della Flora, the school’s principal, when I visited this spring. “How are [the children] going to learn a positive way of dealing with conflict if we’re not the ones showing it?”

We were standing in Ohio Avenue’s vestibule talking with Tony Schwab, a kindergarten teacher. Schwab had just told us about a disturbing incident: Three of his students had clustered on his classroom’s tile floor. One laced his hands behind his head and knelt; the other two then copied him. All three soon had their foreheads on the ground. They were, according to Schwab, practicing how to avoid getting shot in the event of a confrontation with police.

“Three 5-year-old boys teaching each other how to stay alive,” said Schwab, who’s been a teacher for 15 years. “I’m still shocked. It’s rough.”

Possible police aggression is just one of the realities that make life challenging for this group of kids. Della Flora cited one child whose mom was in the hospital having recently had a stroke; he kept fighting at the slightest provocation. Another had just arrived at Ohio Avenue after being placed in foster care. Not only was he attending a new school and living in an unfamiliar home, he was also being deprived of his usual medication because his biological mom still had his prescription. Lastly, Della Flora recounted two fifth-grade boys who’d recently gotten in a punching match in front of a girl. Instead of running for help, the girl—who’d witnessed domestic violence—froze.

Despite the poverty and violence students experience, Ohio Avenue is making academic strides. The school received an A for progress on most of its recent annual report cards, which measure students’ growth based on past performance as part of the state’s accountability system. Meanwhile, its nearest neighbor, Livingston Elementary, received F’s on its two most recent report cards. Ohio Avenue’s approach to helping children cope with trauma could help explain why its students have performed so well.

America’s schools have long relied on punishment to handle discipline issues. In the 1990s, suspensions and expulsions soared due to the rise of “zero tolerance” policies that harshly punished students even for minor infractions such as swearing or chewing gum. Still, over the past decade, policymakers have started to sour on punitive discipline. Studies found that punishments fall disproportionately on African American children and those with disabilities—even when accounting for parents’ education, income, school climate, and other demographic factors. In recent years, districts have begun to discourage and even ban suspensions and expulsions, with at least 22 states and the District of Columbia changing their laws to this effect. These efforts led to guidance from the Obama administration in 2014 that compelled schools to minimize suspensions and ensure they don’t fall disproportionately on certain groups.

But schools have in some cases struggled to adjust to this new direction. An analysis of Philadelphia’s ban on out-of-school suspensions by the conservative Thomas B. Fordham Institute, for example, highlighted the initiative’s mixed outcomes and concluded that top-down mandates that allow for little flexibility at the school level can have unintended consequences. In Philadelphia, researchers found that the new policies not only failed to improve achievement for previously suspended students and to reduce the number of low-level “conduct” suspensions in the long term, they also correlated with more racial disparities in punishment rates at the district level.

It’s in part because of experiences like this that discipline has become the subject of one of the most polarizing and entrenched debates in education: Opponents of the Obama guidance argue that it has handicapped schools from ensuring schools are safe and productive learning environments; proponents assert the rules promote equity and prevent educators from resorting to punitive discipline practices that are ineffective at best and pernicious at worst.

Della Flora—who this fall will be starting a new job mentoring principals and leading community-engagement efforts in a Connecticut school district—is trying something different, pushing the school to be more experimental and use whatever methods will meet children’s needs. This is particularly evident when it comes to the school’s approach to “social-emotional skills,” an area that’s received substantial attention in recent years, as research links these “soft” skills (like impulse control and empathy) with academic and life success. Ohio Avenue features a patchwork of strategies that staff members of all levels have cobbled together in their effort to help the students grow—and the school’s academic and behavioral gains suggest that approach has worked. As a majority–African American school, led by an African American principal, social worker, and principal-in-training, Ohio Avenue provides a compelling case study.

A school represents a microcosm of decisions, actions, and trials by the school leaders and students themselves. It’s not a controlled setting, like a research laboratory, where one variable can be changed to prove causation. So it’s difficult to say conclusively what portion of the strides Ohio Avenue has made stems from its principal and her approach.

It’s also important to acknowledge the hiccups the school has experienced in testing out various approaches. One challenge: When every teacher is empowered to introduce a new idea, some choose not to follow the models that are successfully improving behavior. Several classroom educators complained that their students were out of control when they returned from art, physical education, or music, reasoning that teachers for those classes didn’t consistently use effective methods like the PAX game or self-regulation tools like stress balls and glitter jars (more on these later). Then there are the days that an educator calls in sick and no substitutes are available. Della Flora divides up the teacherless students so there are a few in different classrooms, disrupting the usual routine.

Moreover, it can be hard to change entrenched habits. One teacher who’d explained to me one morning that yelling rarely helps calm the class was shouting at her students to be quiet every time I walked past the door of her classroom later that day. She only had a dozen students present, yet still seemed unable to maintain control of the classroom.

But the experience of Ohio Avenue offers a compelling argument for a different way of thinking about how to help children to manage their emotions and behavior—one that isn’t either the latest fad or a traditional system of rewards or punishments. What if, instead of district-wide mandates that oppose suspensions or promote a designated social-emotional curriculum, school leaders freed their staff to meet the specific needs of their students, in turn freeing those children to develop customized self-calming strategies? What if the most effective way to help kids learn self-control is for adults to stop being so controlling?

The culture of entrepreneurship at Ohio Avenue can be seen throughout the hallways and classrooms. Recognizing that some children can self-calm with sensory toys, the staff lined the molding in the hallways with bottle caps, puzzle pieces, and plastic teddy-bear shapes for agitated children’s fingers to touch. A first-grade teacher, Jessica Bedra, applied for a grant to secure beanbags and stress balls that the children can manipulate or push their faces into when they feel overwhelmed. Another staff member filled Gatorade bottles with liquid and glitter as a tool that children can use to become centered. Suddenly the bottles were in almost every classroom.

Teachers who produce the most orderly, productive classrooms combine a nurturing approach with clear limits and predictable routines. On my most recent visit, I watched Kathleen McAfee stroll around the desks in her fourth-grade classroom. She peered over the kids’ shoulders as they practiced subtracting large numbers, borrowing from the higher place value to make the calculations. Upon noticing one of her students vainly trying to subtract five from four, she gently cupped his face with both hands. “Child,” she said with a smile, proceeding to correct his math.

Elsewhere in the classroom, one girl pulled a mini–elliptical machine in front of her chair and pedaled while she worked on the problem, while others bounced their feet on elastic bands tied taut across the legs of their desks.

One child in McAfee’s class, Marshaun, had dramatically turned around his behavior in the last three years, she told me. In fact, I hadn’t paid much attention to him on my visits because I was looking for disruptive kids or those who needed help self-regulating—he didn’t fit either category. During his earlier years at the school, Della Flora later told me, Marshaun would regularly wander the halls, tense with anger. He fought a lot, often resorting to closed fists and throwing chairs and flipping desks, and was suspended multiple times.

Now, at age 10, Marshaun could calm himself down when upset in the classroom. Occasionally he’d struggle in transitions between classes or at recess when boys jostled against each other, but the staff could de-escalate him with stress balls and fidget spinners. “He’s found things to help him,” Della Flora said.

Another major strategy: a behavioral-management tool known as the PAX game the school introduced. Distributed by the nonprofit PAXIS Institute since 1999, the PAX game aims to teach children to control their impulses by making good behavior fun. The students agree on the type of behaviors they want to see (referred to as “PAX,” the Latin word for peace) and the types they don’t want (“spleems,” an invented word the game’s creators adopted because it’s impossible to say without a smile). These unusual terms help shed any baggage children might have associated with “good choice” or “bad choice” in other environments. Teams of kids compete to win an intangible prize—usually a short, playful activity such as Simon Says—which all students can win as long as their team keeps its spleem count low. Many teachers at Ohio Avenue wear a harmonica on a lanyard around their necks, which they play gently to call kids to attention. Research shows that children with a trauma history may be more sensitive to flashing lights or loud noises, such as the common classroom strategies of getting students’ attention by clapping or flipping the classrooms lights on and off. Harmonicas, blown from high to low, won’t trigger the so-called “fight-or-flight response,” which is a physiological reaction to stress, and which often leads to an escalation of conflict.

Long-term studies of children who experienced the PAX game for just one year, in first grade, showed they were more likely than those who hadn’t to graduate high school; avoid teen pregnancy, drug use, or crime; and achieve better mental and behavioral health. The game also correlates with a reduction of attention-deficit hyperactivity disorder (ADHD) symptoms, such as poor impulse control and distractibility. After a year of the game, the research found, many children had learned to stop such behaviors.

After participating in PAX training a few years ago, Ohio Avenue teachers found themselves sending far fewer children to the room on campus where students go to let out frustration and regain self-control. The number of kids sent to the room for more than an hour, for example, fell from 317 in the 2013–2014 school year to 39 in the 2016–2017 year.

Education policymakers often look for clear narratives in their effort to identify the programs and curricula that will help at-risk children succeed. My time at Ohio Avenue showed me that the approach and mindset of the educators are a key determinant of progress. Those are things that are hard to measure, but ultimately it’s the specific people who shape the outcome of a given policy.

The adults at Ohio Avenue believe so deeply in the power of self-regulation that they’ve embraced it personally. Teachers need tools to self-calm just as much as the children do. McAfee, the fourth-grade teacher, manages her stress by pacing the classroom during lessons; many of Ohio Avenue’s teachers snack on Hot Tamales candy, claiming that the cinnamon helps them calm down. When McAfee and a few other teachers went to an education-leadership summit, she packed so many in her luggage that airport security flagged her bag for a hand search—in an X-ray machine, a carton of Hot Tamales can look like a box of bullets.

After Della Flora and I heard Schwab’s story of the three kindergarten boys rehearsing a nonviolent arrest by police, we stood together for another moment in the vestibule. Finally, Della Flora broke the silence with a joke: “I don’t know if you like tacos. Taco Tuesday—that is my regulation,” she told Schwab, encouraging him to shake it off.

Ohio Avenue demonstrates that mitigating the effects of poverty, trauma, and racism in schools might require a shift in focus toward intangibles—namely, the teachers’ perspective on trauma and their relationships with children. These things are harder to measure than, say, test-score improvement and the number of counselors on campus, and embracing them might get messy at times. But if this Columbus school is any indication, that mess will be more than worth it.

This story was produced with support from the Education Writers Association Reporting Fellowship program.



On Tuesday, dozens of parents—actresses, hedge-fund managers, doctors—were charged by federal prosecutors for their alleged role in a bribery scheme that cleared the way for students to get into selective colleges. Some parents are accused of cheating on the ACT or SAT, bribing test proctors to let someone else take the test for students to make sure they got the right score to get in. Other parents allegedly had an intermediary bribe coaches so that students could use an athletic designation for easier entry, because recruited athletes get a significant bump in the admissions process.

Admissions news rarely lands with such a splash. This story, however, genuinely shocked many higher-education experts. But maybe it shouldn’t have. The race to get into elite colleges is a full-blown “hysteria,” Michael Crow, the president of Arizona State University, told me. “We’ve created a crisis of access to these social-status-granting institutions.” It’s a crisis of higher education’s own making, he said. “If you keep something as an extra-scarce commodity, then you will encourage behaviors by certain people, including crimes and bribery and all sorts of bad things.”

College seats, overall, aren’t scarce by any means, but seats at selective institutions are—and purposely so. Institutions typically argue that keeping a steady, reasonably sized enrollment allows them to maintain high-quality services for students: student-teacher interaction, tutoring, and a vibrant campus culture. But scarcity has the added benefit of increasing an institution’s prestige. The more students who apply, and the fewer students who get in, the more selective an institution becomes, and, subsequently, the more prestigious. And parents are clawing over one another to get a taste of the social capital that comes with that.

“What we have now is people bribing their way into country-club schools that grant status by admission to the country club,” Crow said. This isn’t a new phenomenon. As the journalist Daniel Golden has outlined extensively in his book The Price of Admission, “The rich buy their under-achieving children’s way into elite universities with massive, tax-deductible donations.” But in this case, parents allegedly took the quest for admission at any cost across the lines of legality.

How can colleges fix this crisis? The simplest way would likely be for selective institutions to stop being so selective and enroll more students. Instead of carefully crafting admitted classes—taking a little bit of diversity and a little bit of athleticism and a little bit of legacy and mixing them into the ideal freshman stew—institutions could open their doors and serve more students, Julie Posselt, an associate professor at the University of Southern California’s Rossier School of Education, told me. (Though USC was mentioned in the suit, Posselt was unconnected to the scandal.) Selective institutions would undoubtedly take a “prestige hit” because of that, but it could alter the way parents think about college: not as social capital to be bought, but as an opportunity for learning and growth.

If something doesn’t change, things are likely to get worse. “The population only continues to grow. Demand for these elite schools only accelerates,” Crow said. And currently, Posselt said, there is an incredible incentive to get into a selective institution—to purchase that elite credential: The labor market rewards it. “The prestige factor won’t go away until the labor market stops rewarding it.” But perhaps colleges could preempt the labor market. If elite schools enrolled more students and forfeited some prestige, maybe there wouldn’t be such angst about who does or doesn’t get into any one in particular.

Arizona State, where Crow became president in 2002, is now a higher-education behemoth with more than 100,000 students enrolled on campus and online across the world. It was, notably, not the type of institution that these parents were trying to get their children into. In fact, one parent cited in the complaint even went as far as to ask for a “road map for success” to getting his daughter “into a school other than ASU!” Parents don’t need to use a “side door,” as William Rick Singer, a cooperating witness for the government, called it—legal or illegal—to get into an institution that is more accessible.

After I spoke with Crow, a spokesperson for Arizona State sent an email with the university’s comment on being mentioned so flippantly in the suit. “Some universities have decided the most important thing they can do is turn away deserving, qualified applicants just so they can seem more exclusive,” the spokesperson wrote. “That leads to perverse incentives and perverse actions, as we are witnessing unfold right now.”



There was a time, not so long ago, that Oprah Winfrey’s name was floated as a potential presidential candidate for the 2020 election. It started in jest, sort of, but there’s reason to believe that a candidacy that begins as a joke can end in the Oval Office. Some people still swear Donald Trump’s presidency can be traced back to an infamous 2011 comedic roast by Seth Meyers.

If the Donald could be dared into running, why couldn’t Oprah? She is, like him, one of America’s most famous television stars. Winfrey has publicly ruled out a run—it’s “definitely not” happening, she said in a late-night talk-show appearance in February—but she hasn’t stayed quiet on politics.

“Vote! Vote! Vote!” she urged graduates in a commencement address at the Annenberg School for Communication and Journalism at the University of Southern California on Friday. “Everything around us, including—and, in particular the internet and social media—is now being used to erode trust in our institutions, interfere in our elections, and wreak havoc on our infrastructure.”

She went on: “Pay attention to what the people who represent you are doing and saying in your name and on your behalf... If their policies are at odds with your core beliefs, then you have a responsibility to send them packing.”

Here, a full transcript of Winfrey’s remarks:

Thank you Wallis Annenberg and a special thank you to Dean Willow Bay for inviting me here today. And to the parents, again I say, and to the faculty, friends, graduates, good morning.

I want to give a special shout out because I was happy that Dean Bay invited me but I was going to be here anyway because one of my lovely daughter girls attends the Annenberg School of Journalism and is getting her masters today, so I was coming whether I was speaking or not. So a special shoutout to a young woman who I met when she was in the seventh grade and it was the first year that I was looking for smart, bright, giving, resilient, kind, open-hearted girls who had “it”—that factor that means you keep going no matter what. And this was the year that I chose everybody individually. And I remember her walking into the office in a little township where we were doing interviews all over South Africa and she came in and recited a poem about her teacher and when she walked out the door I go, “That’s an ‘it’ girl.” Thando Dlomo, I’m here to say I am so proud of you. Long way from the township in South Africa and her Aunt has flown 30 hours to be here for this celebration today. Thank you so much.

Today I come bearing some good news and some bad news for anybody who intends to build their life around your ability to communicate. So, I want to get the bad news out first so you can be clear. I always like to get the bad stuff upfront, so here it is: Everything around us, including—and in particular the internet and social media—is now being used to erode trust in our institutions, interfere in our elections, and wreak havoc on our infrastructure. It hands advertisers a map to our deepest desires, it enables misinformation to run rampant, attention spans to run short and false stories from phony sites to run circles around major news outlets. We have literally walked into traffic while staring at our phones. Now the good news: Many of your parents are probably taking you somewhere really special for dinner tonight. I heard. I can do a little better than that. Now that I have presented some of the bad news, the good news is that there really is a solution. And the solution is each and every one of you. Because you will become the new editorial gatekeepers, an ambitious army of truth seekers who will arm yourselves with the intelligence, with the insight and the facts necessary to strike down deceit. You’re in a position to keep all of those who now disparage real news, you all are the ones that are going to keep those people in check. Why? Because you can push back and you can answer false narratives with real information and you can set the record straight. And you also have the ability and the power to give voice, as Dean Bay was saying, to people who desperately now need to tell their stories and have their stories told.

And this is what I do know for sure because I’ve been doing it a long time: If you can just capture the humanity of the people of the stories you’re telling, you then get that much closer to your own humanity. And you can confront your bias and you can build your credibility and hone your instincts and compound your compassion. You can use your gifts, that’s what you’re really here to do, to illuminate the darkness in our world.

So this is what I also know: This moment in time, this is your time to rise. It is. Even though you can’t go anywhere, you can’t stand in line at Starbucks, you can’t go to a party, you can’t go any place where anywhere you turn people are talking about how bad things are, how terrible it is. And this is what I know: The problem is everybody is meeting hysteria with more hysteria and then we’re all becoming hysterical and it’s getting worse. What I’ve learned all these years is that we’re not supposed to match it or even get locked into resisting or pushing against it. We’re supposed to see this moment in time for what it is. We’re supposed to see through it and then transcend it. That is how you overcome hysteria. And that is how you overcome the sniping at one another, the trolling, the mean-spirited partisanship on both sides of the aisle, the divisiveness, the injustices, and the out-and-out hatred. You use it. Use this moment to encourage you, to embolden you, and to literally push you into the rising of your life. And to borrow a phrase from my beloved mentor Maya Angelou: Just like moons and like suns, with the certainty of tides, just like hopes springing high, you will rise.

So your job now, let me tell you, is to take everything you’ve learned here and use what you learned to challenge the left, to challenge the right, and the center. When you see something, you say something, and you say it with the facts and the reporting to back it up. Here’s what you have to do: You make the choice everyday, every single day, to exemplify honesty because the truth, let me tell you something about the truth, the truth exonerates and it convicts. It disinfects and it galvanizes. The truth has always been and will always be our shield against corruption, our shield against greed and despair. The truth is our saving grace. And not only are you here, USC Annenberg, to tell it, to write it, to proclaim it, to speak it, but to be it. Be the truth. Be the truth.

So I want to get down to the real reason we’re here today. In about an hour and a half, you’re going to be catapulted into a world that appears to have gone off its rocker. And I can tell you I’ve hosted the Oprah show for 25 years, number one show. Never missed a day. Never missed a day. Twenty five years, 4,561 shows. So I know how to talk, I can tell you that, but I was a little intimidated coming here because graduations, it’s tough, it’s hard trying to come up with something to share with you that you haven’t already heard. Any information or guidance I can offer is nothing that your parents or your deans or professors or Siri haven’t already provided. So I’m here to really tell you: I don’t have any new lessons. I don’t have any new lessons. But I often think that it’s not the new lessons so much as it is really learning the old ones again and again. So here are variations on a few grand themes beginning with this: Pick a problem, any problem, the list is long. Here are just a few that are at the top of my list. There’s gun violence and there’s climate change, there’s systemic racism, economic inequality, media bias. The homeless need opportunity, the addicted need treatment, the Dreamers need protection, the prison system needs reforming, the LGBTQ community needs acceptance, the social safety net needs saving, and the misogyny needs to stop. Needs to stop. But you can’t fix everything and you can’t save every soul. But what can you do? Here and now I believe you have to declare war on one of our most dangerous enemies, and that is cynicism. Because when that little creature sinks its hooks into you, it’ll cloud your clarity, it’ll compromise your integrity, it’ll lower your standards, it’ll choke your empathy. And sooner or later, cynicism shatters your faith. When you hear yourself saying, “Ah, it doesn’t matter what one person says, oh well, so what, it doesn’t matter what I do, who cares?” When you hear yourself saying that, know that you’re on a collision course for our culture. And I understand how it’s so easy to become disillusioned, so tempting to allow apathy to set in, because anxiety is being broadcast on 157 channels, 24 hours a day, all night long. And everyone I know is feeling it. But these times, these times, are here to let us know that we need to take a stand for our right to have hope and we need to take a stand with every ounce of wit and courage we can muster. The question is: What are you willing to stand for? That question is going to follow you throughout your life. And here’s how you answer it. You put your honor where your mouth is. Put your honor where your mouth is. When you give your word, keep it. Show up. Do the work. Get your hands dirty. And then you’ll begin to draw strength from the understanding that history is still being written. You’re writing it every day. The wheels still in spin. And what you do or what you don’t do will be a part of it. You build a legacy not from one thing but from everything. I remember when I just opened my school in 2007, I came back and I had the great joy of sitting at Maya Angelou’s table. She hadn’t been able to attend the opening in South Africa. And I said to her, “Oh Maya, the Oprah Winfrey Leadership Academy, that’s going to be my greatest legacy.” I remember she was standing at the counter making biscuits, and she turned, she put the dough down, and she looked at me and she said, “You have no idea what your legacy will be.” I said, “Excuse me? I just opened this school and these girls, and it’s going to be … ” And she said, “You have no idea what your legacy will be, because your legacy is every life you touch. Every life you touch.” That changed me.

And it’s true, you can’t personally stop anybody from walking into a school with an assault rifle, nor can you singlehandedly ensure that the rights that your mothers and grandmothers fought so hard for will be preserved for the daughters you may someday have. And it’ll take more than you alone to pull more than 40 million Americans out of poverty, but who will you be if you don’t care enough to try? And what mountains could we move, I think, what gridlock could we eradicate if we were to join forces and work together in service of something greater than ourselves? You know my deepest satisfactions and my biggest rewards have come from exactly that. Pick a problem, any problem, and do something about it. Because to somebody who’s hurting, something is everything. So, I hesitate to say this, because the rumors from my last big speech have finally died down, but here it is. Vote. Vote. Vote. Pay attention to what the people who claim to represent you are doing and saying in your name and on your behalf. They represent you and if they’ve not done right by you or if their policies are at odds with your core beliefs, then you have a responsibility to send them packing. If they go low, thank you Michelle Obama, if they go low, we go to the polls. People died for that right, they died for that right. I think about it every time I vote. So don’t let their sacrifices be in vain.

A couple other thoughts before I go. Eat a good breakfast. It really pays off. Pay your bills on time. Recycle. Make your bed. Aim high. Say thank you to people and actually really mean it. Ask for help when you need it, and put your phone away at the dinner table. Just sit on it, really. And know that what you tweet and post and Instagram today might be asked about at a job interview tomorrow, or 20 years from tomorrow. Be nice to little kids, be nice to your elders, be nice to animals, and know that it’s better to be interested than interesting. Invest in a quality mattress. I’m telling you, your back will thank you later. And don’t cheap out on your shoes. And if you’re fighting with somebody you really love, for god’s sakes find your way back to them because life is short, even on our longest days. And another thing, another thing you already definitely know that definitely bears repeating, don’t ever confuse what is legal with what is moral because they are entirely different animals. You see, in a court of law, there are loopholes and technicalities and bargains to be struck, but in life, you’re either principled or you’re not. So do the right thing, especially when nobody’s looking. And while I’m at it, do not equate money and fame with accomplishment and character, because I can assure you based on the thousands of people I’ve interviewed, one does not automatically follow the other.

Something else, something else. You need to know this. Your job is not always going to fulfill you. There will be some days that you just might be bored. Other days, you may not feel like going to work at all. Go anyway, and remember that your job is not who you are, it’s just what you are doing on the way to who you will become. Every remedial chore, every boss who takes credit for your ideas—that is going to happen—look for the lessons, because the lessons are always there. And the number one lesson I could offer you where your work is concerned is this: Become so skilled, so vigilant, so flat-out fantastic at what you do that your talent cannot be dismissed.

And finally, this: This will save you. Stop comparing yourself to other people. You’re only on this planet to be you, not someone else’s imitation of you. I had to learn that the hard way, on the air, live, anchoring the news. One night in my twenties, when I first started broadcasting, I was 19, moved to an anchor by the time I was 20. I was just pretending to be Barbara Walters. I was trying to talk like Barbara, act like Barbara, hold my legs like Barbara. And I was on the air, I hadn’t read the copy fully, and I called Canada, Canahdah. I cracked myself up, because I thought, Barbara would never call Canada Canahdah. And that little breakthrough, that little crack, that little moment that I stopped pretending allowed the real me to come through. Your life journey is about learning to become more of who you are and fulfilling the highest, truest expression of yourself as a human being. That’s why you’re here. You will do that through your work and your art, through your relationships and love. And to quote Albert Einstein, “Education is what remains after we forget what we’re taught.” You’ve learned a lot here at USC. And when all that you’ve been taught begins to fade into the fabric of your life, I hope that what remains is your ability to analyze, to make distinctions, to be creative, and to wander down that road less traveled whenever you have the opportunity. And I hope that when you go, you go all in, and that your education helps you to walk that road with an open, discerning mind. Discernment is what we’re missing. And a kind heart. You know, there are 7 billion people on the planet right now. And here you are. Your degree from the USC Annenberg School for Communication and Journalism: This degree you’re about to get is a privilege. It’s a privilege. And that privilege obligates you to use what you’ve learned to lend a hand to somebody who doesn’t get to be here. Somebody who’s never had a ceremony like the one you’re having this morning.

So I hold you in the light, and I wish you curiosity and confidence. And I wish you ethics and enlightenment. I wish you guts. Every great decision I’ve ever made I trusted my gut. And goodness. I wish you purpose and the passion that goes along with that purpose. And here’s what I really hope: I hope that every one of you contributes to the conversation of our culture and our time. And to some genuine communication, which means, you have to connect to people exactly where they are; not where you are, but where they are. And I hope you shake things up. And when the time comes to bet on yourself, I hope you double down. Bet on yourself. I hope you always know how happy and how incredibly relieved everybody is in this room is that you’ve made it to this place, at this time, on this gorgeous day. Congratulations USC Annenberg Class of 2018!



In recent years, many of America’s urban schools have improved significantly. A 2016 report from the Urban Institute found that while all the country’s public-school students improved in the decade starting in 2005, the gain for those in large cities was double that of the U.S. average; the advances are especially pronounced in kids’ reading scores. With these strides, the achievement gap between city districts and their suburban and rural counterparts closed by roughly a third during that same period.

In some cases, the gap is all but nonexistent. Take, for example, Chicago, which in the late 1980s was notoriously deemed the country’s “worst school system” by then-Education Secretary William J. Bennett. A number of recent studies have shown that while standardized-test scores across Illinois have been flattening for the past decade or so, achievement in Chicago’s public-school district (CPS) has been steadily rising.

In fact, data from 11,000 school districts studied by Stanford researchers last year suggest that CPS ranks first in the nation for academic growth, and state statistics show that its students’ college-attendance rates are steadily improving, too: Sixty-five percent of the district’s 2018 graduates enrolled in college within a year after getting their diploma, compared with an average of 75 percent across the state. CPS students’ college-going prospects still fall toward the bottom when compared with those in most nearby districts, but they’re far from the worst—and the Stanford researchers’ findings around future growth in CPS indicate that its students’ postsecondary-achievement levels are poised to continue improving.

But middle-class, white parents tend to make assumptions otherwise—and research suggests that those assumptions are the result of racial biases. A recent study in the journal City & Community based on survey data out of eight metropolitan areas in the U.S. suggests that residents—including, presumably, parents—frequently harbor negative associations with the term urban and, by extension, “inner-city” communities and institutions, such as schools. To them, these words may connote scenes of educational dysfunction—rows of decrepit classrooms, for example, each stocked with an overworked teacher and a cluster of indignant teens, almost all of them poor students of color.

By contrast, the study pointed to evidence that the term suburban tends to elicit images of productivity and well-being among white parents. Of course, these stereotypes that white, middle-class parents harbor aren’t simply about population density, but about race, with urban standing in for predominantly black or Latino. A number of studies have shown that white parents tend to select schools with lower proportions of black students, regardless of school quality.

“We know that these terms, which might seem like they are neutral descriptions of physical spaces, are not neutral,” says Shelley Kimelberg, a sociologist at the University at Buffalo who co-authored the study with the Wichita State University sociology professor Chase Billingham. “They reflect people’s lived experiences and the social environment.” According to Kimelberg, the influence an individual’s personal experiences have in shaping how she defines the term urban contributes to a feedback loop, cementing “the idea that urban equals bad school and suburban equals good school.”

In their study, Kimelberg and Billingham analyzed data from a survey of residents in metropolitan areas across the U.S. When controlling for other factors, every one-point increase in whites’ perception of their neighborhood’s school quality was associated with a 15 percent decrease in the odds that they would describe their area as “urban.” The same effect was not evident among people of color.

Jack Schneider, a historian who studies education, has described this as “a gap in perceptions,” pointing as one example to public-opinion polls finding that while parents consistently give high marks to their own neighborhood schools, they also tend to report a lack of confidence in U.S. public education as a whole.

One of the most glaring manifestations of this gap, Schneider has argued, is the stigma against urban schools. Not only do stereotypes fail to acknowledge the variation within these districts, as Kimelberg’s study highlights, but they also place too much emphasis on test-score data, which, as Schneider has shown, provide a flawed illustration of school quality. For example, one 2006 study found that a majority (60 percent) of the variance in students’ test scores is attributable to kids’ lives outside of the classroom—where they live and with whom. The quality of instruction, including things like teacher characteristics, had little bearing on exam performance. Other research has found that the quality of one’s schooling plays a very limited role in determining whether she climbs up the economic ladder later in life.

Yet the stigma persists, and the tragedy of all this is that the stigma itself is a key reason educational inequality remains. Despite signs of a reversal in the white flight that crippled urban school districts following desegregation orders tracing back to the late 1960s and ’70s, research suggests that the country is seeing a new iteration of income-based housing segregation driven almost exclusively by affluent families with children. By moving to certain neighborhoods in pursuit of what they perceive to be good schools and to flee what they perceive to be bad ones, they contribute to school-funding inequalities by taking resources and social capital with them.

Chicago Public Schools, where close to nine in 10 students are black or Latino, offers a case study for these trends. The district has in recent years engaged in earnest efforts to attract middle-class families—launching International Baccalaureate programs at a slew of high schools, for example, and building new schools in white neighborhoods.

And, perhaps in part as a result, a body of scholarship corroborates the turnaround narrative that district officials have—sometimes suspiciously—long been touting. For example: CPS students, no matter the demographic subgroup, generally perform better than their peers in other Illinois school districts. These results are partly attributable to the district’s rising graduation rates and scores on the ACT college-entrance exam, but they also owe themselves to growing poverty and racial diversity in suburban school districts—a trend that Kimbelberg highlighted when reflecting on the outdated or otherwise flawed assumptions that seem to inform people’s mental associations with the words suburban and urban.

Despite these changes, CPS has struggled to generate a critical mass of middle-class parents interested in its public schools—at least beyond those schools where students need a certain test score to get in. While reporting by WBEZ shows that the rate of families in Chicago who choose to send their children to their neighborhood school has declined, the trend is particularly evident among white families. Just half of Chicago’s white, school-age children attend the city’s public schools, compared with about 80 percent of their black counterparts, according to a 2014 report by WBEZ; the remainder attend other types of schools, like charters, magnets, or private institutions.

This dynamic, which is seen in urban areas across the country that give parents significant choice over where to send their kids to school, has been found to exacerbate educational stratification and racial segregation. The result is that even when urban districts improve a little, they struggle to improve a lot. And yet another generation passes through an education system defined by its unevenness and its racial divides.



Updated at 2:47 p.m. ET on June 6, 2018.

The motto of Sidwell Friends School, the hyperselective “Harvard of Washington’s private schools,” is simple and lofty. “Eluceat omnibus lux”—Latin for “Let the light shine out from all.” But bright lights sometimes illuminate the worst in people. Last month, shocking behavior by parents may have led two of the school’s three college counselors to leave their jobs.

School officials have repeatedly warned parents, who represent the pinnacle of elite Washington, about their offensive conduct. In January, the head of the school, Bryan Garman, sent a remarkable letter to parents of seniors in which he demanded that they stop “the verbal assault of employees.” He also reiterated a policy banning them from recording conversations with counselors and making calls to counselors from blocked phone numbers. Garman also suggested that some parents were responsible for the “circulation of rumors about students.”

Anger, vitriol, and deceptiveness have come to define highly selective college admissions. In the now notorious Varsity Blues scandal, the desire of wealthy parents to get their children into such elite institutions as Yale and the University of Southern California led them to lie on applications and obtain fake SAT scores. At Sidwell Friends, one of America’s most famous Quaker schools, the desire manifested itself in bad behaviors—including parents spreading rumors about other students, ostensibly so that their children could get a leg up, the letter said.

The letter, which was first described in The Washington Post, is published below in full. Garman was following up on a separate letter sent by Patrick Gallagher, then the director of college counseling at the school, prior to the school’s winter break. Gallagher, Garman recounted, had alerted parents to a new set of rules in the counseling office, including the no-recording mandate and guidance that the office would not “consider anonymous and/or unsubstantiated claims made about student behavior.” Reached by email, a spokeswoman for the school, Hellen Hom-Diamond, declined to comment, stating, “Sidwell Friends has a policy that precludes us from commenting on personnel matters.”

The oddly specific policy tweaks weren’t coincidental. “The new policies stem from a handful of unfortunate and uninformed interactions, some of which have been unkind to students, others that have disrespected our counselors,” Garman wrote. The string of incidents were “anomalous and often anonymous,” he wrote, but they had become “increasingly intense,” and they were “antithetical to the School’s values.” The departures have become a subject of gossip among parents and faculty at Washington private schools.

As a Quaker school, Sidwell Friends derives its motto from the Quaker notion of inward light—or the idea that God is in every person, and should lead people to do good for others. But anonymous rumblings on message boards have been anything but generous, often suggesting that the college counseling office was responsible for students not getting into selective schools.

In 2003, my colleague James Fallows wrote about the dysfunction—manufactured as it might be by overanxious parents—of college admissions. “With highly selective institutions there is no way to predict with confidence whether a student will get in,” one college dean of admissions told him. That helps create chaos, and “the neurotic intrusiveness of parents” adds fuel to it, Fallows writes—but aggressive parents, to a certain extent, come with the territory of college counseling.  

In June of this year, Gallagher, as well as Adam Ortiz, one of the other members of the college-counseling office, will leave the school.* Only one counselor remains from this year’s staff. (Attempts to reach Gallagher and Ortiz for comment were unsuccessful.) The school hired an interim director of college counseling—one who had previously worked in the counseling office—in order to steady the ship. (After publication, a spokeswoman for Sidwell Friends confirmed that two college counselors will leave in June.)

It’s not unusual for there to be high turnover among younger college counselors, Ned Johnson, the president and founder of PrepMatters, an academic-tutoring and test-prep company in the Washington area, told me. “Being a college counselor at a highly academic, highly competitive independent school—where both kids and their parents have high aspirations and high expectations of the next steps of their education—creates a lot of pressure,” he said. The tension comes from the parents and the kids, and “anyone who is playing the counselor in the middle of that,” he said, “is going to feel a lot of stress and pressure as well.”

In his letter, Garman added a note of hope for the adults at Sidwell. “I hope we will reaffirm our commitment to the well-being of our students and to the common good,” he wrote. He hoped that they would embrace the idea of inward light. “And I hope that we will always treat one another with respect.”

Here’s the text of the letter:

Dear Senior Parents,
I hope you had a restful break, and that you experienced the joy and peace we seek through the diverse end-of-year traditions we celebrate. In addition, I hope you were able to share some special time with your seniors, who have contributed immensely to the School. We are proud of their achievements, and look forward to celebrating them in June.
I am writing in follow up to Patrick Gallagher’s pre-break letter, which shared several newly implemented policies in the College Counseling Office (CCO). As you will recall, the letter stated that the CCO prohibits the recording of conversations with our counselors; will not consider anonymous and/or unsubstantiated claims made about student behavior; will not respond to calls issued from blocked telephone numbers; does not respond to any inquiry for student records unless that request is made by the student or an approved family member or guardian.
The new policies stem from a handful of unfortunate and uninformed interactions, some of which have been unkind to students, others that have disrespected our counselors. The vast majority of our parents, of course, work to support and honor all of our students and staff. In addition, they value the extraordinary advice, expertise, and guidance that our counselors offer, and work collaboratively to promote the interests and emotional development of their children throughout a stressful process. As a father who witnessed his daughter's college search last year, I know firsthand that it can stir deep emotions and elicit insecurities. The application process can push students to their limits, especially when it is heightened by high expectations and external pressures. And there is no doubt that the process can stretch the patience and emotional capacity of parents.
Our counselors are acutely aware of this challenge. They understand that we parents love our children, and they demonstrate tremendous patience when that love blurs our vision. Because they understand emotional complexities and enrollment management, they approach the task compassionately and strategically, and recognize that some parent and student meetings can become difficult. We must remember, however, to maintain perspective and act with respect even in emotionally trying circumstances.
Instances of disrespect are anomalous and often anonymous, but have nevertheless become increasingly intense and inappropriate. The circulation of rumors about students and/or the verbal assault of employees are antithetical to the School’s values and create a dispiriting work environment. When transgressors can be identified, they may be prohibited from meeting with the CCO and/or be subject to additional penalties as articulated in the Community Handbook.
No matter how difficult the college process becomes, as parents we must remember to use it to underscore our values. We can be sure that our children are acutely aware of how our words and actions speak to our priorities. “Too often, today’s culture sends young people messages that emphasize personal success rather than concern for others and the common good,” reads Turning the Tide, a compelling study commissioned by Harvard University. “And too often the college admissions process ... contributes to this problem. As a rite of passage for many students and a major focus for many parents, the college admissions process is powerfully positioned to send different messages that help young people become more generous and humane in ways that benefit not only society but students themselves.”
In this new year, I hope we will reaffirm our commitment to the well-being of our students and to the common good. I hope that we will recommit to helping children understand that college is merely the next destination on a lifelong journey, not their destiny. I hope that we will embrace the concept that there is that of God—of goodness—in each individual, and that addressing the needs of every child, not just our own, is essential to the health of our community. And I hope that we will always treat one another with respect.
I am grateful for those of you who work in trust and collaboration with the School, and I look forward to celebrating with you as the Class of 2019 enters their final semester at Sidwell Friends.
Thank you, as always, for your time and attention.
In peace and friendship,
Bryan
Bryan Garman
Head of School

* This article previously stated that the counselors left the school in May.



One of the few good things about acne is that it hardly discriminates: With some variation, it afflicts people of all races and income levels, from all regions and countries. Acne is the eighth-most-common disease globally, affecting roughly two out of three people ages 15 to 19.

Another one of the good things? Acne may contribute to better grades and longer-term academic success, according to a forthcoming peer-reviewed study in the Journal of Human Capital by the economists Hugo Mialon and Erik Nesson, of Emory University and Ball State University, respectively.

Seeking to investigate how acne affects educational attainment and labor-market success, the researchers looked at data from a survey of tens of thousands of teens in the United States starting in the mid-1990s and continuing through the next decade. Mialon and Nesson found that having acne in high school was associated with a higher overall GPA—as well as a greater likelihood of earning an A in math, science, history and social studies, and English—and a higher chance of earning a bachelor’s degree. The academic differences between teens with skin problems and those without them weren’t dramatic, but they were statistically significant. For example, acne increases a student’s chances of getting an A in science by 1.8 percentage points.

Like learning to drive a car or sharing a first kiss, acne is a rite of passage for many American teenagers. While factors such as diet and lifestyle may explain some instances, the disease is primarily attributable to genes—a hereditary trait that often arises because of puberty-induced hormones. For most teens, acne is temporary and goes away as they get older. Still, pimpled adolescents, who are at a time in their lives when a heightened sense of self-awareness makes them highly preoccupied with how others perceive them, seldom come to terms with the fact that the condition is both common and short-lived. Acne can significantly undermine a teen’s self-image and is associated with feeling ugly and ostracized. It’s no wonder that Americans spend about $3 billion a year on acne treatments.

This psychological impact is serious and shouldn’t be brushed off as frivolous. But it does help explain the researchers’ findings. Self-esteem effects, they theorize, make teens who have acne more likely to prioritize studying over socializing than those who don’t, and that leads to their higher grades and better educational outcomes down the line. But the relationship between acne and athletics is the opposite: Teens with pimple problems are less likely to participate in sports teams —and more likely to participate in other types of school clubs—which could indicate, the authors write, “a possible shift from physical to intellectual pursuits.”

Specifically, the correlations were stronger for girls, especially those who identified as white or Asian. That matches past research showing that girls are more prone to developing a poor self-image because of their acne than are boys. And in a phone call, Nesson told me that the racial differences might be attributed to the fact that white and Asian teens generally have lighter complexions than, say, their African American peers, which makes their acne more visible.

That doesn’t mean ambitious high-school students should be clamoring for more pimples on their face: The study, of course, comes with lots of caveats. For one, the factors that influence academic motivation and achievement are incredibly complex. To state the obvious, plenty of people who don’t have pimples excel at school, and the reverse is true for kids with bad skin. For another, the self-esteem challenges faced by teens with acne could negate the potential academic benefits—social and emotional health, after all, is a very strong predictor of academic success.

Still, this study is a useful reminder that even seemingly mundane aspects of life for teens can play a role in their educational outcome. What’s especially valuable about the focus on acne is that, unlike many other components of appearance—for example, weight, fashion, or having braces—it generally occurs independent of class. Economic inequality tends to complicate research on the connection between just about all traits and students’ educational outcomes, yet acne is virtually income-blind. (To avoid complicating their findings, the researchers decided not to factor in high-schoolers’ use of acne treatments like Accutane, as access to such medications likely correlates with class.)

The data should still deliver a small but valuable nugget of good news for teenagers suffering from acne. The “silver lining,” Nesson says, “is that the acne is not only likely to go away by the time you reach early adulthood; it’s also likely to have some positive side effects that are going to last for much, much longer.”



In 1925, the U.S. Supreme Court issued a ruling that cemented the country’s thinking on school choice: Families, the justices concluded in Pierce v. Society of Sisters, had the right to decide where to send their children to school and thus could choose private education. Catholic schools, which were the target of the lawsuit, rejoiced. They could continue serving as an alternative to the United States’ system of “common schools.”

The Catholic Church went on to dominate America’s private-school world for several decades. But starting in the 1970s that dominance started to fade—and by the late 1990s, it was clear that the country was witnessing  parochial education’s demise. Today, the number of students who attend Catholic schools (roughly 1.8 million children) is fewer than half of what it was half a century ago, according to an analysis of federal data published in the latest issue of Education Next. The National Catholic Education Association says that more than 100 Catholic schools were consolidated or closed altogether during the 2017–18 year alone.

This trend isn’t just a source of concern for the Catholic community. It’s also troubling to those worried about growing inequality and income segregation in the education system as a whole. As the new Education Next report concludes, the demise of Catholic education correlates with a decline in the share of middle-class students attending independent schools. The authors—including Richard Murnane, a Harvard education and economics professor, and Sean Reardon, a Stanford expert on educational inequality—write that this exacerbates a system in which private education is largely reserved for the wealthy and for the few low-income children who are eligible for and manage to secure vouchers or financial aid.

The tuition charged by private schools—which in the 2010–11 academic year, the most recent year for which such data is available, averaged about $11,000 annually—renders them out of reach for most Americans. Just 10 percent of school-aged children in the United States attend a private school. That number has been largely the same for  decades. What has changed is the demographic makeup of that 10 percent—and that’s in part because of the loss of many Catholic schools, which have historically sought to enroll lower-income families by keeping tuition low and providing financial aid. What’s more, as Maria Ferguson, who oversees George Washington University’s pro-public-education Center on Education Policy, pointed out, many Catholic schools are prohibited from turning students away, meaning there’s “no creaming off the best and most affluent students.” Between 1968 and 2013, as the number of Catholic schools declined, the proportion of middle-class children enrolled in private elementary schools dropped by nearly half while that of their more affluent counterparts remained steady, the Education Next report found. “The private-school pool is more predictably affluent (and likely whiter) because private schools are usually more expensive than Catholic schools and tend to serve higher-income families,” Ferguson said in an email. “As families of color become more affluent, that trend will likely change as they too pursue other non-public educational options for their children.”

Parochial education has been shown to have long-term positive effects on kids’ outcomes. The right-leaning Thomas B. Fordham Institute, for example, has found that students in Catholic schools exhibit more self-control (keeping their tempers in check, respecting others’ property, accepting their classmates’ ideas, and handling peer pressure, to name a few) than their counterparts in other types of schools. And students at Catholic schools tend to outscore their peers in other learning environments on standardized tests; on the nation’s educational assessment, for instance, the reading scores for eighth-graders at Catholic schools were 7.2 percent higher than the average. Research also shows that exposure to students from different backgrounds—including different incomes—has inherent educational benefits, and that one’s schooling can have a profound impact on his or her worldview. These implications are especially noteworthy at a time when the country’s political and social divides continue to widen.

A number of factors are contributing to the  phasing-out of Catholic schools. One is a drop in the number of clergy members, who historically taught for relatively low wages. Another is the Church’s sex-abuse scandals, whose financial ramifications have undermined its ability to operate schools. In addition, demographic shifts such as falling birth rates, the growing concentration of black and Hispanic families in the bottom tier of the country’s income distribution, and a decline in religiosity among Americans, combined with the rise of charter schools, have led to lower enrollment in parochial education.  

As a result, many of the Catholic schools that do remain are expensive. The average tuition at Catholic elementary schools in 2010, the most recent year for which comparable data are available, was close to $6,000 in 2015 dollars, six times more than what it was in 1970 ($873 in 2015 dollars), according to the Education Next report. (On the more extreme end of the spectrum, the Washington, D.C.–area school Georgetown Preparatory School—the alma mater of Supreme Court Justice Neil Gorsuch and prospective Justice Brett Kavanaugh—costs $60,000 a year for students who board and $37,000 for students who don’t.)

The tuition at other types of private schools has skyrocketed, too—at a faster rate than the rise in median incomes, the Education Next analysis notes. Adjusted for inflation, the average tuition at nonsectarian private elementary schools increased from just over $4,000 in 1979 to close to $23,000 in 2011. It isn’t surprising then that such schools have grown even more exclusive. At such schools, the enrollment gap between families in the top income bracket and those in the middle grew from 5.5 percentage points in 1968 to 9.3 percentage points in 2013.

The authors of the Education Next report conclude that these “troubling” shifts are hugely consequential for the country despite the relatively low percentage of students who attend private schools. The United States, as the early-childhood-education expert Erika Christakis has argued in The Atlantic, is witnessing a war on public schools, fueled by politicized notions that their failure to produce substantial gains in academic achievement is evidence that they’re dragging the country down. As affluent families gravitate toward expensive private schools that are becoming less and less accessible to students in other income brackets, they could take with them political and social capital that public schools desperately need.



The results of a new poll suggest that a majority of Americans now support the expansion of school choice for all families. With 54 percent of respondents saying they favor universal-choice policies—which typically come in the form of programs that let families use government money to pay for private schools—the findings released on Tuesday by the policy and opinion magazine Education Next indicate that the idea has enjoyed a substantial jump in popularity since last year, when just 45 percent of respondents said they supported such proposals.

These findings are a boon for the Trump administration, which has advocated for school choice from the get-go to little avail, with Congress ignoring his 2017 budget plan calling on the federal government to dedicate $1.4 billion to expanding vouchers and again rejecting a similar proposal this year. Education Secretary Betsy DeVos previously served as the board chairwoman of the American Federation for Children, which describes itself as “the nation’s voice for educational choice”; when announcing DeVos’s appointment, Trump indicated he selected her precisely to help advance his school-choice agenda.

It's not clear whether the administration's public support for school-choice policies is driving the apparent shift in public opinion. But it's curious, considering that DeVos, the most high-profile cheerleader for school choice, is also Trump's least-popular cabinet member. In a March 2018 poll, 28 percent of respondents said they have a “very unfavorable” impression of DeVos, while just 8 percent found her “very favorable.” But at least according to these numbers, her reputation doesn't seem to be hurting public support for school choice. That’s especially evident among Republicans, who have in recent years grown to espouse school choice as a key component of the party’s platform. And in this survey, 64 percent of Republican respondents said they support school choice for all families, a 10-percentage-point increase from last year. Fewer than half—47 percent—of Democrats said they’d favor such a proposal, up 7 percentage points from the 2017 poll.

DeVos’s press secretary began promoting the Education Next results on Twitter as soon as they were released. In one tweet, she cited an analysis of the poll by the K-12 expert Frederick Hess, of the right-leaning American Enterprise Institute: “public strongly prefers Betsy DeVos’s ‘extremist’ views.” It was the first time she’d tweeted in weeks.

The poll surveyed a nationally representative sample of roughly 4,600 adults this past May. Notably, the survey included oversamples of parents with school-age children living in their home, teachers, African Americans, and Hispanics. Also notable: While Education Next, which was founded in 2001 by a school-choice-focused task force based out of Stanford’s Hoover Institution, states on its website that it “partakes of no program, campaign, or ideology,” many education insiders describe it as partial toward “free-market education-reform ideas” like charters and vouchers.

But Americans’ support for these programs changes depending on how they’re presented. Fifty-four percent of respondents said they were in favor of universal vouchers only when asked about a proposal that “would give all families with children in public schools a wider choice, by allowing them to enroll their children in private schools instead, with government helping to pay the tuition.” The word “vouchers” wasn’t included. But among respondents who were asked explicitly about vouchers, support dropped to 44 percent. Previous research has suggested that people are less likely to support the use of public money for private-school tuition when it’s described explicitly as a “voucher” program. As Chalkbeat’s Matt Barnum writes, such inconsistencies are common in surveys that ask laypeople about vouchers because the polarization surrounding the topic means that even a small semantic nuance can affect a person’s perception. The issue has become so politicized that advocates of such programs often avoid the word “voucher” altogether—National School Choice Week, for example doesn’t use the word on its website, instead using the euphemistic “opportunity scholarships”—a strategy that aligns with advice often disseminated by Republican pollsters.

Interestingly, when it came to respondents’ opinions on vouchers earmarked only for low-income students, whether the question included the word “vouchers” made little difference: The percent in support for low-income voucher programs hovered around the mid-40s for each phrasing.

But the role of semantics in shaping public opinion on vouchers is clear, echoing a broader trend in education rhetoric. Even the term “school choice” has become loaded—so much that even DeVos has started to shy away from it. In a February analysis, Politico’s Kimberly Hefling and Caitlin Emma highlighted the secretary’s tendency toward more politically palatable phrases instead—things like “innovation” and “blended learning” and “a paradigm shift.”

Charter schools are perhaps the most well-known "school choice" model. Since many people are generally familiar with how charters work, the term isn’t as susceptible to spin, which could mean polling on this front is a more authentic barometer for shifting opinions on school-choice issues. Close to half—44 percent—of respondents in the Education Next poll this year said they support the formation of “charter schools,” a term defined in the question as meaning “publicly funded but ... not managed by the local school board.” That’s up from 39 percent in 2017—a year marked by a drastic decline in public support for the model—which may help convince skeptics that Americans are truly, albeit gradually, buying more and more into school choice.

Then again: Those opposed to school-choice policies might take issue with the wording in that question, too. Describing them as “not managed by the local school board” sounds a lot more appealing than directly noting that they’re managed by private entities, including both nonprofit and for-profit organizations. That’s particularly true in an era when “privatization” is practically  a taboo word for many in the education world. But however carefully these models are described, they'll still carry polarizing subtext. It’s almost impossible to completely take politics out of schools.





Subscribe to Radio Atlantic: Apple Podcasts | Spotify | Stitcher | Google Play

A college education has become a key asset towards success in the American economy, but for many Americans, access to higher education—especially at a prestigious university—feels increasingly out of reach. With its capricious admissions and massive debt loads, the system is struggling. So we’re sitting down this week with two members of our Education team—editor Alia Wong and staff writer Adam Harris—to ask the question: is U.S. higher education sustainable?Links
- “Harvard Admissions on Trial” (Alia Wong, October 5, 2018)
- “America Wakes Up From Its Dream of Free College” (Adam Harris, September 11, 2018)
- “George Washington’s Broken Dream of a National University” (Adam Harris, September 21, 2018)
- “Lotteries May Be the Fairest Way to Fix Elite-College Admissions” (Alia Wong, August 1, 2018)
- “Why the Ivy League Needs to Admit More Students” (Alia Wong, September 28, 2018)
- “Here’s How Higher Education Dies” (Adam Harris, June 5, 2018)
- “The Era of Affirmative Action May Not Last Much Longer” (Adam Harris, July 3, 2018)
- “The College-Graduation Problem All States Have” (Adam Harris, June 16, 2018)



PITTSBURGH—In so many other towns, schools have been the targets of choice for people who want to commit acts of violence. The Tree of Life synagogue, where a shooter killed 11 congregants and injured two others on Saturday, is a little more than a mile from Community Day School, a pluralistic Jewish school for kids ages 3 through eighth grade. The two communities are intimately connected: A number of the students’ families are members at Tree of Life; the middle schoolers have attended a morning prayer service, or minyan, there once a week for several years. This week, as students went back to school, the older kids were thinking, “This could have been me. I go there all the time,” says Avi Baran Munro, the head of the school.

For many of these kids, anti-Semitism is a concept from history class, Baran Munro told me. They learn about the conditions that led to the Holocaust and longtime patterns of discrimination against Jews.(Their curriculum isn’t exclusively focused on Jews, and also includes units on other forms of bigotry, such as racism, segregation, and anti-immigrant sentiment, Baran Munro noted.) “But they feel safe in America as Jews, and they feel safe in Pittsburgh as Jews,” she said. “They know it hasn’t gone away. But they don’t have examples.” She paused. “Which, now they do.”

[Read: How will Pittsburgh’s Jews translate tragedy into action?]

But at this school, the educators are determined to not let fear become a cornerstone of their students’ Jewish identity. In fact, they are doing what they can to prevent that. Schools, and particularly Jewish schools, may feel like especially unsafe places right now. But Baran Munro said she believes they are no more vulnerable this week than last, in part based on her conversations with the authorities. “I don’t think the risk is higher today than it was last Friday,” she said on Monday, the first day back. But, she added, “I think the awareness of what could happen is higher.”

Fear has always been part of the vocabulary of Jewish life, but in the United States, it hasn’t necessarily been as tangible as it is in Israel or countries in Europe. (“Israeli parents, in particular, are very sensitive to the fact that we have open playgrounds and open fields,” Baran Munro said. “In Israel, the schools are fortresses.”) As Jews have assimilated into American society, many communities have focused on constructing a positive identity based on values and heritage, rather than a negative one based on a sense of persecution.

Particularly over the past several years, though, fear and anxiety have inflected the conversations in many Jewish communities, based on the perception that anti-Semitism and xenophobia are on the rise in America. While kids may have been learning about anti-Semitism as an artifact of history, many adults seem to have a growing, ambient sense of threat. If anything, in their eyes, what happened in Pittsburgh is an ugly confirmation of their fears.

[Read: The Jews of Pittsburgh bury their dead]

But Community Day School isn’t interested in “selling … kids and families on a vision of Judaism that [says], ‘We are victims of persecution, we are victims of the Holocaust, we are endangered, it’s the end of the Jewish people,’” said Baran Munro. Especially in liberal communities, where kids might live much of their lives outside of Jewish contexts, “Jewish families are not going to embrace a message of persecution and victimhood and segregation,” she said. “So we lead with pride and joy.”

While some kids expressed fear about coming back to school on Monday, ultimately, attendance was typical that day, the school said. Walking through the halls that day, it was difficult not to think about the vulnerability of the space. In one classroom, little boys wearing kippot, or Jewish head coverings, squirmed on the carpet next to soft-spoken little girls in uniform. The cheerful classrooms, labeled with colorful Hebrew letters and bursting with art and books, seemed like a haven from what had happened. They “know that they’re sad, and that something’s not right,” said Elke Cedarholm, a third-grade teacher. “So we’re just focusing on kindness, sending good thoughts out there, and on being the best little people that we can be.”

As Pittsburgh’s Jewish community enters a new period in its history, its members have a choice about how they will frame this experience, and how they will teach it to their children. They will have to decide how much their newly legitimated fears will shape lives in their synagogues and their schools; what kind of political action they will demand; and whether their city’s name will become just another entry in a long list of sites of mass shootings.

[Read: A broken Jewish community]

On Tuesday morning, a crowd gathered at a vigil organized by the school’s eighth graders at the Holocaust sculpture on the school’s front lawn. Students and parents sang songs, including one by Matisyahu, a Jewish pop star, and took turns making remarks about what had happened. They lit 11 tall candles on a table covered in a black cloth, and shared short tributes to the victims of the shooting.

The kids here are already helping the members of Pittsburgh’s Jewish community decide who they are going to become. “They really have a no-B.S. censor, and they’re not shy about speaking out,” said Baran Munro, “which gives me hope.” Rabbi Jeffrey Myers, the rabbi at Tree of Life, attended the vigil planned by the students, who had often showed up at his synagogue to pray. “You’ve given me some strength to get through today,” he said. “And for that, I thank you.”



It’s hard to believe that nearly a half century has passed since I stood on a hillside in South Amherst, Massachusetts, with Van Halsey, then Hampshire College’s director of admissions, gazing at the rolling green farmland that stretched out toward Hadley, Massachusetts. “That is where the college will be,” Halsey explained. I was 17 years old, entering my senior year of high school, and convinced that this largely invisible place—then mostly a collection of dreams and ideals—was the only college in the country where I wanted to study.

My enthusiasm for Hampshire was shared widely that year. The new college attracted a couple of thousand applications for the 250 or so places in its first class of students. The school had no history, no traditions, no graduates, no campus when we applied in 1969. And yet we couldn’t wait to attend. The excitement I felt for Hampshire and all that it promised is as real to me today as it was on that spring day when I looked across that field and glimpsed the college’s future, and my own.

Hampshire’s core premise—that college-age students are capable of far more than what is usually expected of them—drew us to the college. We were invited to become active participants in framing our own education. Rather than selecting a major, we’d be asked to develop an area of concentration. Our progress would be measured not by grades, courses, or credits piled up, but by examinations across broad fields of knowledge. We’d be expected to create the architecture of our education, not passively wait for information to be delivered.

That message resonated with idealistic high-school graduates of my era. The prospect of taking charge of one’s own education, guided by the wisdom of talented faculty, was exhilarating. The invitation to participate in “the making of a college” likewise offered us, as very young people, an invigorating sense of purpose. Additionally, the stress that Hampshire’s literature placed on social responsibility as a critical dimension of a liberal-arts education converged with our historical moment in ways that enticed us. We were full of energy, impatient with authority, and shaped by the upheaval of the late 1960s. We imagined that we could change the society around us. What better place to start than at this fledgling college that emphasized adventure and innovation, and that made a virtue of possibility.Today that soaring sense of possibility has been brought to ground by harsh realities. Hampshire is currently embroiled in a crisis—rooted in daunting financial difficulties and the administrative decisions made about how best to deal with them—that threatens its survival as an independent liberal-arts college.

The current historical moment forms a backdrop to Hampshire’s challenges just as another one did when the college was created. What wasn’t as clear then as it is now was the degree to which Hampshire’s founding era informed the willingness—on the college’s part and on our own—to engage risk and opportunity. Hampshire’s gifted founders, Franklin Patterson and Charles R. Longsworth, observed in their 1966 treatise, The Making of a College: Plans for a New Departure in Higher Education, “No major departure, no new and consequential venture, is made without a context and a vision.” The vision of the college was obvious enough. What was less obvious were decisive elements of the context that shaped the college’s origins and that illuminate its present troubles.

Hampshire owes its existence to a perceived crisis—both “qualitative and quantitative,” as the founders’ book outlined—in the late 1950s that fueled doubts about the “fiscal base and academic viability” of private liberal-arts colleges then deemed to be “everywhere precarious.”  

Rising costs; the soaring demand exerted by college-bound Baby Boomers; and the growing dominance and appeal of research universities, with their attention to graduate study and preprofessional training, were then transforming higher education. The changes these trends wrought appeared to threaten the venerable small private colleges whose primary commitment was to undergraduate schooling. A fear that private colleges might be stretched beyond their natural limits, thereby degrading the character and quality of the education and experience they offered, concerned their leaders. Some experts viewed with particular anxiety the rising hegemony of research universities, which they warned might well vitiate the influence of small colleges, or even render them obsolete in the not-too-distant future. They also anticipated that liberal-arts colleges would confront limited “teaching resources,” given the ever-growing research imperative of larger universities and, presumably, larger faculty salaries. Public and private universities provided attractive funding and rewards for professors who devoted less time to teaching and more to producing valuable scholarship. Also at risk, liberal-arts-college leaders surmised in this Cold War era, was the perceived value of humanistic and liberal learning, given the emphasis on science, technology, and vocationalism in higher education.

Out of the maelstrom came Hampshire. In 1958, the presidents of Amherst College, Smith College, Mount Holyoke College, and the University of Massachusetts—four schools in the Pioneer Valley region of western Massachusetts—appointed a committee to “re-think the assumptions underlying education in the liberal arts.” The goal was to map out a plan for a new college that would offer an “education of the highest quality at a minimum cost per student and with as small a faculty relative to the student body as new methods of instruction and new administrative procedures can make possible.” Toward that end, the committee proposed a fifth school, radically different in structure and academic form.

The college conceived of by the “New College Plan” and then created by Hampshire’s founders did, indeed, mark a notable departure in collegiate education. It encouraged an extraordinary level of independence among its students, allowing undergraduates a primary role in organizing their own education. Taught in small classes, Hampshire students were free of grades, required courses, rigid distribution requirements, lecture courses with periodic exams, fixed majors, and the predictable four-year college sequence. Instead, they progressed by examination through three divisions—the first allowing exposure to broad areas of knowledge, the second a concentration equivalent to a major but self-designed, and the third a time of advanced study of a topic that would usually consume most of the student’s final year. Interdisciplinary work was encouraged; the college did not have departments organized by traditional academic disciplines such as biology, English, political science, or art. Instead, it established schools of natural science, social science, language and communication, and humanities and arts, to which faculty were assigned by expertise and interest.

Ironically, many of the innovations that Hampshire’s founders proposed in order to answer the perceived problems of their day complicate the school’s current crisis. The structure of the school’s faculty provides a revealing case in point. The college’s founders wanted Hampshire to have a young faculty, “relatively close to college age themselves,” joined by a much smaller number of senior and mid-career professors. The cost savings in salaries of such a system are obvious enough, though the college promised competitive pay and benefits comparable to elite, private liberal-arts institutions. (That pledge gave way in time as financial challenges mounted.) All faculty would serve under a contract system with review before renewal; no tenure would exist at Hampshire College.

Amazingly, the appeal of the college was such that it attracted at its start outstanding professors from first-rank institutions who gave up tenure to teach at Hampshire. Salary compression in the academic job market has allowed the college to continue to recruit, hire, and retain talented faculty, even without the promise of tenure. However, the faculty turnover that college administrators expected did not pan out; Hampshire professors tended to stay at the institution. Although the contract system remained in place, it gave way to reappointments of longer duration such that 10-year contracts in time provided some semblance of the stability conferred by tenure. Amid the current duress, this structure augments the vulnerability of professors who face the downsizing, layoffs, and cutbacks that Hampshire’s current administration is now pursuing aggressively.

Another innovation—the college’s unusual model of governance—figures centrally in the present-day upheaval on the campus. Although Hampshire is overseen by a traditional board of trustees and led by a president with accompanying officers who set “basic policy,” Hampshire’s founders gave to “all of the community’s constituencies” a primary role in determining “the internal governance of the College.” “The major governing bodies of the community will be few,” Patterson and Longsworth promised, “but students will have representation on each of them.” The assumption was that anyone in the community could propose “innovations and evaluations.” Members of the college community more than rose to these expectations over the ensuing decades—to the chagrin, no doubt, of its leadership on many occasions. Shared governance in nearly every aspect of college life became the norm, and a tradition of participatory democracy was thereby established, however imperfectly executed at times.

This history provides an important backdrop to the announcements earlier this year by the president and board of trustees that Hampshire is pursuing a yet-to-be-defined strategic partnership—presumably with a larger university that could help stabilize the college financially—and will not be admitting a full class of new students in the fall. The news came as a shock to most of the current faculty, staff, and students, as well as to alumni and friends of the college. A storm of protest has followed, with student sit-ins of administrative offices, including that of the Hampshire president. Ultimate responsibility over the college’s institutional and fiduciary well-being has always rested with the board of trustees. Today it is a large body of 29 members, the majority of whom are alumni of the college. Nonetheless, Hampshire’s long tradition of shared and decentralized governance offered little preparation for the top-down nature of decisions of such great institutional consequence.

A key factor in Hampshire’s current vulnerability derives from what was a critical element of the planned experiment— the college’s unorthodox financing. It was one of the proposed innovations that seemed most promising, if daring, at the college’s founding. In making “a virtue out of the necessity,” Hampshire sought to meet its costs primarily through tuition and fees—a bold move that would demonstrate that it was possible to offer, as the “New College Plan” suggested, a high-quality education at minimum cost.

Economies of scale were to be achieved at the new college in several ways. Financial aid would be limited to a modest number of mostly full scholarships based entirely on need. The college would instead meet what it felt to be its social responsibility through an “early-identification program,” which would nurture a small number of poor elementary-school children who would subsequently be offered full scholarships to Hampshire. Student self-direction would, in theory, free up professorial time and allow for a smaller faculty. (In fact, students demanded and received a great deal of individual attention from a very hardworking and dedicated faculty.) Cost savings would ideally be achieved by having a relatively high student-to-faculty ratio of roughly 20 to 1. Five College cooperation would allow students from all five institutions in the valley to take courses at neighboring campuses. Hampshire would be especially advantaged by this opportunity, permitting the new school to escape the need of duplicating everything from obscure fields of study to library resources available elsewhere. There would be no formally organized, and expensive, system of intercollegiate athletics.

A $6 million gift (worth more than $48 million today) from a wealthy Amherst graduate launched Hampshire College in 1965. It allowed for the acquisition of a site for the school and, along with additional public and private funds, construction of the campus. The money raised at that time was not set aside as an endowment, given the need for capital expenditures for buildings and operating funds with which to get the school running. The latter would eventually be paid by the tuition garnered from a carefully selected and mostly full-paying student body, as well as by grants and gifts. That seemed workable in 1966, when prospective students from “affluent families” were believed to far outnumber available space at colleges, and when sources of financial aid, including federal student loans, grants, and work-study programs, were making “financing a college education…easier than ever.”

Those assumptions were borne of a growth era, when brisk demand and expanding federal funds made higher education more affordable for college-bound students and their families. In that flush period, Hampshire’s financial plan succeeded. Impressive success in raising private funds strengthened the college, as did steady applications from eager and talented college-bound students.

Yet the scheme would soon run up against constraints resulting from less congenial historical eras. Before Hampshire’s first full class had graduated, national and local conditions produced storm clouds overhead with hurricanes possibly rising. On campus, the 20-to-1 student-faculty ratio proved unrealistic, given the individualized nature of academic instruction at the college. A somewhat larger faculty at a greater cost was thus mandated. It also became apparent that Hampshire’s professors might well wish to age in place at the College. That eventuality would inevitably drive up salary expenses in ways that other private liberal-arts colleges already found onerous. Inflation in the mid-1970s increased the costs of virtually all operations. Finally, the expense of financial aid proved much higher than anticipated. A drive to increase diversity and to enhance “educational equality” mandated outlays that diverged substantially from the model advanced in the college’s earliest blueprints.

In a forthright 1974 report, Longsworth, then serving as Hampshire’s second president, admitted that these complications would test the institution. “The fiscal future of the College,” he wrote, “is uncertain.” Hampshire had many strengths but lacked, he warned, the “financial reserves to survive a period of reduced enrollment which could result from a prolonged period of national economic recession.” Longsworth’s successors would face these very obstacles, as well as many others, over the next four and a half decades. They would do so in a much changed social and political climate than the one that had inspired Hampshire’s founding. That environment had serious consequences for the experimental young college.

By the late 1970s, applications to Hampshire began to decline. A variety of factors undoubtedly caused the trend, including a normalized level of interest after the initial, extraordinary burst of enthusiasm that accompanied the college’s opening. Of greater concern everywhere was the more risk-averse climate among middle-class Americans, who worried about economic stagnation, future job prospects for their children, and the affordability of higher education. Tuition costs across the country rose substantially. Meanwhile, federal funding became less rather than more generous, as conservatives succeeded in pushing legislative changes that promoted student loans as a favored means of higher-education assistance. Hampshire needed to contend with these realities, as well as with the chance that a rising generation of high-achieving college-bound students might be less drawn to the school and its unorthodox academic program.

Hampshire did so through the adroit management of its third president, Adele Smith Simmons, who served from 1977 to 1989. With considerable courage and a strategy that appeared counterintuitive, Simmons undertook a series of initiatives to both promote the college and steer it toward greater selectivity. She reduced the size of the entering class and focused on attracting a smaller number of excellent students who would thrive in Hampshire’s unusual, self-directed academic program. Given that tuition and fees were the institution’s major sources of revenue, it was a risky decision. But it paid off handsomely. Within a few years, applications to Hampshire rebounded. Simmons was lauded in a 1987 New York Times profile as a president who had “Hampshire feeling frisky again.” The college had once more become a “hot school”—or at least a warm one—in an era when, the Times reported, “small liberal arts colleges are becoming an endangered species.”

That breezy aside 30 years ago suggests that the survival of many small liberal-arts schools through the 1960s and ’70s had done little to allay earlier anxieties. Predictions of small colleges’ demise were a hardy perennial that persisted through seasons of plenty (the late 1950s and ’60s) and want (the 1970s and beyond). To be sure, there is ample reason today for concern. Influential demographic studies, widely touted as compelling evidence that danger lies ahead, predict a coming bust in demand for these colleges by the mid-2020s. The falloff seems likely to be particularly acute in the Northeast and Midwest, where the college-age population is expected to shrink. Other experts insist that the expansion of digital and online learning will challenge the long-term viability of many colleges and universities. Ever-soaring costs coupled with rising tuition discounts are especially perilous for institutions such as Hampshire that rely so heavily on tuition revenue.

Elite private institutions, such as nearby Amherst, with an endowment valued in 2018 at $2.4 billion (Hampshire’s endowment stands at $52 million), are not immune to such oft-invoked headwinds. But they are better positioned to weather the storms. Indeed, demographers have predicted that most elite colleges and universities will continue to enjoy rising demand in the decade ahead. The forecast for less wealthy, small institutions is a rising “failure rate” that will manifest in waves of closures, mergers, or acquisitions. Hampshire’s fate in this climate is yet to be decided.

All of the college’s presidents faced very difficult financial challenges and uncertainty throughout Hampshire’s history. There was nothing easy about creating a “new institution with stated aspirations as high as those held out for Hampshire,” Longsworth observed just four years after the college’s opening. To believe that such an institution could succeed challenged expectations to such a degree, he mused, that it would be understandable if some sought refuge in “the assumption of failure … [which] restores a sense of rightness and sensibility.” Hampshire has long had to live with unpredictability. “We faced trouble,” Simmons put it succinctly in a recent conversation, “and we figured it out.” Its oldest alumni are now aging, alas , but not fast enough to provide the kind of bequests that have so enriched its neighboring private liberal-arts schools, all of which were established in the 19th century. Hampshire’s early leaders understood that it would take at least a half century before similar alumni gifts might be fulfilled.

That longer arc envisaged for the college by its founders has been eclipsed in recent months by a mood of heightened urgency and apparent pessimism among its current administration, couched though it has been in a rhetoric of new “visioning” and future possibility. Before Hampshire’s newest president, Miriam Nelson, even took office in July 2018, she learned that the yield of admitted students for the fall had fallen significantly short of expectations. It was just the sort of reversal, comprising millions of dollars in projected revenue, that a place like Hampshire could ill afford to endure. By January, Nelson and the trustees had apparently concluded that the institution had reached its Rubicon. The college faced a stark choice between just two alternatives, it informed a group of influential donors and alumni: close, or find a “strategic partner.” As of this writing, the college continues to weigh its options.

In the current Darwinian landscape, it is easy to conclude that only the very fittest (read, wealthiest) colleges and universities should survive—a judgment that rationalizes everything from institutional suicide to empire building and hoarding. Billions of dollars in donations continue to flow toward the very richest and most heavily endowed institutions. That was also the case, Patterson and Longsworth noted, when Hampshire was founded.

One thing about the current crisis in higher education is all but certain: It is unlikely to inspire anyone to create a new experimental liberal-arts college in New England. All the more reason, many of Hampshire’s most ardent supporters have concluded, to ensure that the college survives to see its next half century.

The previous crisis in liberal education mustered the imagination and idealism that created Hampshire College and served as its wellspring for nearly 50 years. More than 11,000 students have graduated from Hampshire since the year I joined its first class, in 1970. Among them are entrepreneurs, scientists, composers, writers, filmmakers, artists, musicians, doctors, lawyers, social activists, inventors, architects, actors, and educators of remarkable achievement. (Some two-thirds of Hampshire graduates have gone on to earn advanced degrees.) They have surely put to rest the worry harbored by their progenitors that young people in the late 20th century would no longer find preparation for a useful life and engaged citizenship in a liberal-arts education. It turns out that the ideas that launched Hampshire’s distinctive approach to learning and that have flourished there remain as true and evergreen as that verdant landscape I looked over a half century ago.



Last fall was supposed to be the capstone of Braden Morris’s high-school football career. The previous year, his tiny southern Illinois school, Bunker Hill High School, which has fewer than 200 students, joined forces with a neighboring school so they’d have enough players to field a varsity team. As the starting quarterback, Morris led the combined 38-player team to a playoff berth. But heading into his senior year, he was one of only 24 boys who had signed up to play—far fewer than the 35 to 40 players that Brian Borkowski, the team’s coach, considers ideal for a school that size. Then, in the first game of the season, Morris broke his wrist, and his younger brother, Evan, the starting tailback, dislocated his hip. “They were out for the season, and that kind of started the train of injuries rolling,” Borkowski says.

By the fourth week, the team was left with just 17 players, most of whom were freshmen and sophomores. That Friday night, the game was called off during the third quarter for safety reasons—by then, the team was losing 68–0. The next week, Borkowski broke the news to his players: Their season was over.

“It was tough,” Braden Morris told me. “Part of me didn’t want to accept that this was the way I would go out.” The cancellation packed a triple punch in his household—Braden and Evan’s stepbrother, Garrett, was the team’s starting center and defensive tackle.

Similar situations played out around the country last fall as a shortage of players led teams to cancel their seasons. There are no official data on season cancellations, but Kent Johnson, a former high-school-football coach who monitors local media coverage, told me he’s aware of 61 teams that did so in 2018—nearly double the number he counted from the year before. Twenty-one of those teams made the decision midway through the season. While the cancellations happened from California to New Jersey, Johnson’s data show that about half the schools that called off their season this year were in rural areas, where the loss of football doesn’t just affect players and families, but ripples throughout the whole community.

When their season was shut down, Braden and his brothers had little to do after class other than their daily chores. A teammate, Trent Bertelsmann, was able to pick up more hours at his job making pizzas in a neighboring town, but as his mother, Lisa, told me, relatively few local businesses offer teens after-school jobs. “It’s a very small rural community—there’s not much here for the kids to do,” she said.

Indeed, Bunker Hill doesn’t have a lot of other extracurricular activities or weekend events: Football was the only boys’ sport offered at the high school last fall, and the closest movie theater is about 15 miles away. Adults also felt the sting after football went away; they “were bummed because that’s what they did on Friday nights,” Evan Morris told me.

It’s no big shocker that fewer boys are playing football: According to the National Federation of State High School Associations (NFHS)—the main governing body for high-school sports—participation peaked at 1.1 million players in the 2008–09 school year, and has since declined by 75,000. That dip might be linked to the growing awareness of the long-term risks of playing football. It’s not just the pros who have to worry: Starting to play tackle football at an early age puts kids at a heightened risk of cognitive and behavioral problems.

A major driver behind last season’s cancellations is that having fewer football players on a team causes a pernicious cycle in which the remaining players are at greater risk of getting hurt. “We had freshmen on the line in positions they never should have been in,” says Bryan Heflin, Garrett’s father and Braden and Evan’s stepfather. That led to injuries among not only the younger players, but also the more experienced ones, such as those in Heflin’s household, because being on a small team translates to more time spent on the field. Recent research has found that from 2005 to 2017, high-school players on smaller teams were injured at twice the rate of players on larger teams.

At some point, without enough players, it’s just not feasible—or safe—to field a team. “The risk is there, no doubt,” Bob Colgate, the director of sports and sports medicine at the NFHS, told me. “At what point does that number get too low to field a team?” Colgate said the group is looking into the issue, though any decisions about minimum roster levels would have to be made by state associations.

Last summer, fewer than 10 players showed up to preseason practice at Trimble County High School, in Bedford, Kentucky, about 45 miles northeast of Louisville. “We were counting on all these players, and it just didn’t happen,” says Will Kunselman, a senior who played multiple positions on offense and defense. Even a social-media push that prompted several more kids to sign up wasn’t enough: The school held to its decision to cancel the season.

To keep playing football, five of Kunselman’s teammates made the tough choice to transfer to a rival high school. That includes Logan Rodgers, a defensive tackle, who now spends an extra hour getting to and from school in the neighboring county. “I’ve been going to Trimble County [schools] ever since I was in preschool,” Rodgers told me, “so growing up with everybody there and then leaving my senior year was kind of rough.”

As in Bunker Hill, the loss of high-school football in Bedford was keenly felt. It was “something for the community to rally around,” Brigette Kunselman, Will’s mom, told me. “Win or lose, you go.” She missed the cheerleaders and the band, she said, as well as “the opportunity to see and be seen, to catch up with your neighbors.”

That sentiment is echoed by Bedford’s former mayor, Todd Pollock, whose two sons played on the Trimble County High School football team. Home games usually draw “a heck of a crowd,” he told me. It wasn’t just the camaraderie that was lost; Pollock points out that home games brought fans from neighboring communities, who then spent money at local businesses.

For the schools, too, the loss of games came at a cost, given that ticket sales can help fund athletics and other school programs. In Bunker Hill, for example, a typical home game would bring in $1,500 for the school, the principal, Matthew Smith, told me, with concession sales netting an additional $1,500.

Homecoming football games can be a focal point each fall for students and alumni, and after season cancellations, some schools scrambled to make alternative plans. Clarenceville High School, in Livonia, Michigan, had its soccer team play that night instead. Bunker Hill also still managed to hold a homecoming—a game of flag football played by the school’s female students. Braden Morris sang the national anthem beforehand and helped his younger sister prepare for her role as freshman quarterback.

Of course, despite the spate of season cancellations, high-school football isn’t on the verge of a death spiral: More than 14,000 schools fielded teams in 2017, with more high-school boys playing football than any other sport by a substantial margin.

However, Tom Farrey, executive director of the Aspen Institute’s Sports & Society Program, told me that small, rural schools will continue to be more vulnerable to cancellations unless they embrace different models of football. One option, he said, is flag football, which surpassed tackle football in popularity among 6-to-12-year-olds for the first time in 2017. As these players enter high school, this could help set the stage for a corresponding shift to flag football.

A major hurdle to change is that “people are just stuck on the traditional idea of what football is,” Farrey said. But for small schools, adopting alternative models might help them avoid having to eliminate the sport altogether, preserving the role that it serves as a community gathering point. As noted in the Aspen Institute’s recent white paper on the future of youth football, which Farrey co-wrote, the games “are seen by many as a useful and even essential venue for students and adults to come together for a shared purpose, especially in small towns.”

Neither Bedford nor Bunker Hill has announced whether high-school football will return next year, which leaves players and adults alike pondering the future. “What can we do to fill the void?” Pollock asked. “That’s the $64,000 question.”

Next year, Braden Morris’s brothers have the option of transferring to another school if football doesn’t come back to Bunker Hill. But for Braden, the loss of his senior season still hurts. “You want to play, to get in front of the entire town and run into the end zone and hear everybody scream for you,” he told me not long after his season was canceled. “I wish I could still hear that.”



In late June, inside an underground meeting room attached to the U.S. Capitol, past guards and metal detectors, lawmakers and representatives from multiple large security companies discussed the threat of mass school shootings and the need to, in their words, “harden” campuses before someone else gets killed.

“If you think this cannot happen to you, I’m here to tell you I used to think the same exact thing,” said Noel Glacer, a Florida-based security professional. The message—belied by the statistical rarity of school shootings—was part cautionary tale, part call to action.

Glacer is no dispassionate observer. In February, his son, Jake, was in a psychology class at Marjory Stoneman Douglas High School when a gunman opened fire, killing 17. Glacer urged people in the room to donate to SOS Parkland, a nonprofit that’s raising money to equip the city’s schools with additional security.

He was sharing his message at the annual conference of the Security Industry Association, a trade group, whose attendees included Trump administration officials, legislators from both parties, security-company executives, and industry lobbyists.

Corporate representatives at the conference hawked a range of products, including surveillance cameras with facial-recognition capability, automated door locks, gunshot-detection sensors, and software that scans social-media platforms in search of the next shooter. If schools across the country put more emphasis on securing their buildings, they said, school leaders could prevent shootings or, at the very least, mitigate the bloodshed.

Each major school shooting—Columbine, Sandy Hook, Parkland—has helped expand a multi-billion dollar industry that sells not just sophisticated surveillance technology, but also high-priced consultants to explain it all to anxious educators. The recent tragedies are providing momentum—not to mention funds, including millions of dollars in federal money—to initiatives that aim to keep children safe. As the tragedies have piled up, some education leaders say they’re inundated with sales pitches from security companies, each with the same basic message: You could be next.

Such a climate is “ripe for exploitation,” argues Kenneth Trump (no relation to Donald), the president of National School Safety and Security Services, which consults for districts on school-safety planning. The result, according to Trump, is that the security industry has dominated the policy response to school shootings, drowning out subtler conversations about issues ranging from mental health to gun control, in favor of a rush to adopt costly, and largely unproven, methods to harden schools. “It’s not that they’re villains and they don’t care and they don’t want safe schools—I’m not trying to send that message,” said Trump. “But they’re certainly opportunistic. At the end of the day, they’re looking for new revenue streams.”

The security industry’s spectacular growth began with Columbine. Before that, Guy Grace said security efforts in his Colorado school district focused on kids with cans of spray paint, not guns. Grace, the director of security and emergency preparedness at Littleton Public Schools, says the shift he witnessed was instantaneous.

On the morning of April 20, 1999, he was at the gym when his pager went off. Two students had walked into Columbine High School, in a neighboring school district, and killed 15 people, including themselves. After that, his job was never the same. “It was a complete change, just a wake-up call for us all,” he said. “It certainly has shaped a lot of what we do across the country in regards to school safety.”

Before Columbine, Littleton didn’t have any security cameras at its schools, Grace said. The district has since installed more than a thousand cameras, some with analytics capabilities that can alert authorities to unusual activity, such as someone walking onto school grounds in the middle of the night. The cameras are one part of the school-security regime the district implemented after the community approved a bond in 2013 providing more than $7.5 million for the upgrades. Just last year, Grace said that a gunshot-detection sensor, which can recognize the audio signatures of gunfire, alerted officials when a student committed suicide on a school playground.

The growth in Littleton’s school-security infrastructure is mirrored in districts across the country. During the 1999-2000 school year, 19 percent of public schools were equipped with security cameras, according to the National Center for Education Statistics. By the 2015-16 school year, 81 percent of schools had them. The percentage of schools reporting that they control access to their buildings—by, for example, using intercoms to screen visitors—has also risen, from 75 to 94 percent during the same time period.

This surge has been a boon for companies that make and install security products. In 2017, security equipment and services generated $2.7 billion in revenue, according to a market analysis by IHS Markit, a market-research firm. Each mass school shooting heightens the profile of school-security products, said Jim Dearing, a senior analyst there.

Indeed, anxiety can be good for business. “For anyone to say ‘It’s not going to happen here,’ all they’re doing is … assuming that they’re going to get lucky,” said Harry Rhulen, a co-founder of Firestorm Solutions, a crisis and risk-management firm that contracts with school districts.

To underscore the need for his company’s consulting services, Rhulen laid out a chilling scenario: Every school in America, he said, has students, teachers, or staff members who are “sitting on the fence.” Maybe they’re dealing with mental-health issues. Maybe they’re experiencing spousal abuse or are dependent on drugs or alcohol. “Something may push them off the fence,” he warns, turning them into the next shooter, “and there’s just no way to know which school is next.”

But is Rhulen framing the danger fairly? David Ropeik, a consultant on the psychology of risk perception, has written that the odds that a K-12 student will be shot and killed at a public school are roughly 1 in 614 million. According to the most recent federal education statistics, between 1992 and 2015, fewer than 3 percent of murders in which the victims were children and fewer than 1 percent of youth suicides occurred at schools. The data showed that reported incidents of violent crimes in schools has declined over the same time period.

Still, a third of parents say they fear for their child’s safety at school, according to a recent poll by Phi Delta Kappa International, a professional association for educators. That poll found widespread support for school-security measures like armed school police and metal detectors.

Recognizing the recently heightened concern, salespeople at the Security Industry Association Conference recently touted some of their latest wares: door locks that open with a smartphone app, motion detectors that notify staff before a visitor reaches a school building, and cameras that track guests as they walk around campus.

There’s a larger force motivating these new offerings. Dearing, of IHS Markit, predicts that the growth of the school-security industry will slow in the coming years. Since a majority of schools now have surveillance equipment, fewer districts are entering the market for the first time. In response, Dearing said, companies are marketing the next generation of school-safety products, like scanners that track license plates in the parking lot and high-security classroom doors.

Salespeople argue, and they hope schools agree, that as older products become obsolete that schools install the newest ones to stay safe. In order to persuade educators, security companies are making in-person sales pitches and building pop-up displays at education conferences. Some companies hold their own events to promote the importance of heavily outfitted campuses.

For example, Axis Communications, a company that sells surveillance cameras and other hardware, hosts school-safety symposiums several times a year in cities across the country. Scott Dunn, the company’s senior director of business-development solutions and services, said the symposiums aren’t designed as marketing pitches, but rather serve as opportunities to inform educators about the need for security plans and technology to keep kids safe.

Some school districts are not too keen on the sales pitches they’re getting from security companies. After the Sandy Hook Elementary School shooting in 2012, Connecticut awarded the Newtown school district $50 million to build a new, state-of-the-art campus. Joseph Erardi, then the Newtown superintendent and now retired, said sarcastically that after the tragedy, he made “dozens of immediate new best friends” from the ranks of security companies looking to get their products inside the school. “In some cases, they were sincere,” said Erardi, who is now a school-safety consultant. “In other cases, it was all about branding and marketing Newtown.”

Grace, the public-school security director in Colorado, says he had a similar experience. Five years ago, in a shooting that lasted fewer than 80 seconds, a senior at Arapahoe High School walked into the school and killed a classmate before taking his own life.

For security companies, Grace’s reality became a sales pitch. “They start pounding all the school districts across the country and then they say, ‘Don’t be like Arapahoe High School,’” Grace said. “You sit there and go, ‘Who is this idiot? He’s trying to capitalize on a tragedy that we just had in our school district.’ I just despise that with a passion.”

As industry leaders sipped cocktails at the security-conference reception, Representative John Rutherford, Republican of Florida, acknowledged he owed a recent legislative success to people in the room. Just weeks before the February shooting in Parkland, Rutherford introduced the STOP School Violence Act, a law that directs hundreds of millions of dollars over a decade toward school security and will thus be a boon for security companies. (Every year, districts spend far more than that on such companies’ products and services.)

“The STOP School Violence Act could not have gotten across the finish line as quickly as it did without the support of this group, as well as the school-safety caucus and the advocacy from the Partner Alliance for Safer Schools,” Rutherford said.

Much of the conference’s discussions around campus security were led by the Secure Schools Alliance and the Partner Alliance for Safer Schools, two advocacy groups that urge schools to take more measures to prevent shootings and other threats. Secure Schools is funded by security companies and the Partner Alliance is a joint venture of the Security Industry Association and the National Systems Contractors Association, both trade groups. And both groups maintain advisory boards staffed largely by officials from security companies; for example, the public-affairs director of Allegion, a security company that focuses on door locks and other entry technology, serves on the boards of both groups.

Robert Boyd, the executive director of the Secure Schools Alliance, says his group is funded solely by security companies because “they get it.” (He added that the group plans to add officials who represent school police and fire marshals to their board.)

He said security companies like Allegion aren’t investing in school security efforts to sell more products, but rather to help fulfill a dire need. “They look at it and they say, ‘You know, we understand what happened in Sandy Hook was a facilities failure … Folks in the security industry, we understand how to keep intruders out of a building,” Boyd said.

Of course, it’s still lucrative to outfit schools with equipment. In 2017, Allegion reported $2.4 billion in revenue.* Timothy Eckersley, the president of Allegion’s Americas region, said school security is a “significant” part of their business.

Eckersley said he thinks educators get too “wrapped up about the money.” He pointed to the Partner Alliance’s “tiered” guidelines that encourage districts to start with basic infrastructure and work their way up to the more luxe school-safety plans.

Districts that opt to implement the guidelines would be in for a large investment. Based on the costs of the recent security upgrades in Littleton, the Partner Alliance estimates it’d cost a district about $170,000 per high school to implement the most basic tier, bringing the price tag to an estimated $11 billion for all campuses across the country. For a district to implement the most sophisticated security systems outlined by the group, it’d cost an estimated $540,000 per high school, or nearly $36 billion at all schools nationwide.

Once schools reach that top level—with electronic gates, technology that scans license plates, bullet-resistant glass and other equipment—a Partner Alliance slide deck said “security is no longer a project—it is a way of life.”

Beyond the STOP Act, security companies and advocacy groups have also worked to ensure conversations about security products continue in Washington. In 2016, Representative Susan Brooks, Republican of Indiana, and Representative Rick Larsen, Democrat of Washington, teamed up to form the Congressional School Safety Caucus, which was formed, Brooks acknowledged in an interview, after executives at security companies with offices in her district, including Allegion, encouraged her to.

In order to advance federal policies like the STOP legislation, Boyd said advocates with his group “hit the pavement” on Capitol Hill: “You go office to office, staff to staff, committee to committee.” The group also advocates at the state level for specific school-safety laws, including ones that establish security standards (which can require, as more than a dozen states’ do, technology such as surveillance systems and bullet-resistant entryways), allot funding for hardware upgrades, and mandate frequent facility assessments. Boyd is also a co-chair of the homeland security task force at the American Legislative Exchange Council, or ALEC, a national nonprofit that drafts state-level legislation for use by conservative legislators across the U.S. After highlighting states with school security laws at the group’s annual meeting earlier this week, he said he hopes additional state lawmakers get on board.

Trump, the safety consultant, said he is concerned about the influence that security companies, and the advocacy partners they fund, wield over lawmakers. “While physical security has a piece in the puzzle, the concerning part is when big business in the security industry is trying to single-handedly have laws changed and rewrite codes, which at no coincidence benefit their business interests,” he said.

Boyd pushed back on this argument. He maintains that school security should be decided at the district level, but that the state guidelines his association works on help ensure that schools aren’t “throwing money at the problem.”

He said he’s simply frustrated with the level of security deemed acceptable at schools. In the interests of student safety, he’s of the opinion that “school security needs to be a little bit more inconvenient,” like it is in other government buildings such as federal courthouses. “When you go to that courthouse, if they tell you ‘Drop your pants,’ you’re going to drop your pants or you’re not getting into the building,” he said. “They’re going to inspect you thoroughly because we’ve had our share of courthouse shootings, and they stopped them. At what point does the collective outrage say, ‘Enough’? How many more kids have to die?”

Indeed, Boyd and others in the security industry insist that their products save lives. “No shooter has ever breached a locked classroom door,” he said, pointing to the example of the shooting at Sandy Hook. In that shooting, the school’s front door was locked, but that didn’t stop the gunman. He shot through a window near the front entrance to get in. In the part of the building where the shooting unfolded, classroom doors could only be locked with a key—from the outside. More could have been done to protect students, Boyd said. “If you had a ballistic-graded entrance and you had lockable classroom doors, that death toll comes way down—if he even gets in,” he said.

In some cases, though, tech-driven school-security mechanisms have been plagued by human error. In Parkland, for example, emergency personnel didn’t realize the school’s surveillance cameras were operating on a 20-minute delay, complicating the police response.

In fact, aside from anecdotes, little academic research exists on whether security technology actually makes schools safer. In 2016, the think tank RAND released a study of school districts that deployed sophisticated security technology. From video surveillance to metal detectors to software that scans students’ social-media profiles for threats, she found, independent research was surprisingly scarce on products’ ability to prevent tragedies or mitigate risk. Ironically, when lawmakers approved the STOP Act, they reappropriated funds from a post-Sandy Hook grant program that financed research on school safety. “I thought it was concerning there was such a lack of evidence about forms of technology that seem to be widely used,” Heather Schwartz, the author of the RAND study, said.

Despite the dearth of research, Trump and other critics argue that efforts to sell schools-security technology are driving attention away from other interventions like mental-health screenings, behavioral interventions for struggling students, or even gun control. In fact, some research has found that heightened surveillance instills in students a feeling that their schools are unsafe. Meanwhile, civil-rights groups have raised concerns that students of color are surveilled disproportionately.

As school officials across the country explore their options for security, Dale Marsden, the school superintendent in San Bernardino, California, said the benefits of this new technology are clear. But, he added, security equipment has its limits.

Safety efforts in San Bernardino intensified after a shooting at North Park Elementary School last year, when a man went to his estranged wife’s special-education classroom, killing her and a student before taking his own life. After the incident, the district sought input from parents, North Park teachers, emergency responders, security companies, and safety consultants that cost the district more than $100,000, Marsden said. The district spent more than $1 million to redesign the school and implement new security measures. Among the upgrades, he said, is a buzzer system that allows access to different parts of the building and a campus-entry process that runs background checks on visitors.

Nonetheless, he said, there’s no such thing as “absolute safety.” “If a shooter is intent on coming into a campus and you have a visitor-control system, it sounds harsh, but someone can take out the visitor-control system,” said Marsden, an Air Force veteran who specialized in security. “Can some of those things slow down or prevent? Yes. Can you have absolute safety? No.”

This story was produced in collaboration with The 74.

* This story originally stated that Allegion reported $2.4 billion in profit.  



The University of California at Berkeley fields more than 85,000 freshman applications every year. About 15,500 of those applicants are accepted, including 4,500 or so students who aren’t from California; roughly 9 percent of those offered admission aren’t from the United States.

Global diversity has inherent value in a college setting, but at Berkeley—a public institution that receives substantial support from taxpayer dollars—some argue it can come into conflict with its founding values as a “land-grant” university established in the mid-1800s largely to serve the children of farmers and factory workers. And as panelists acknowledged in a discussion Wednesday at the Aspen Ideas Festival, which is co-hosted by the Aspen Institute and The Atlantic, some even find international-student recruitment at private universities problematic at a time when a four-year degree remains out of reach for so many Americans.

But the panelists—all of them current or former university presidents—roundly disagree with the contention that colleges and universities in the U.S. should be restricted to those who live in the country.

UC Berkeley is charged with giving California students a premier education, and that means “having a diverse student body that includes having students outside the state of California and other countries,” said Carol Christ, the school’s chancellor. “It gives them global fluency, the ability to move across borders,” said Christ, who previously served as the president of Smith College. Not having students from other countries “is compromising their ultimate success.”

And Yale President Peter Salovey stressed that any notions that universities reap the benefits of public funding while failing to reinvest it in society are a misconception. Universities, in fact, stimulate the economy, largely through the research they conduct and the jobs they provide. It’s no coincidence, he pointed out, that the technology industry boomed in Stanford’s backyard.

Meanwhile, Daniel Porterfield, the former president of Franklin & Marshall College, argued that universities have somewhat of a duty to serve students abroad as much as they do on their own home turf, noting that “globalization gives us a feeling of connectedness, but it also gives us a feeling of fragmentation.” Universities can, argued Porterfield, who currently oversees the Aspen Institute, play a role in bridging those gaps, whether real or felt. Jack DeGoia, the current president of Georgetown, for example, believed that “Georgetown as a Catholic institution could and should play a role in spreading knowledge around the world.”

Christ added that globalization also gives universities “soft power” abroad. “America’s higher-education system is the best in the world,” she said. Ensuring the country’s universities continue to serve students from other countries is “a wonderful way of maintaining America’s power … in a constructive way.”

But Salovey appreciates concerns that universities writ large aren’t doing enough to serve their communities—concerns that have perhaps become more urgent as contempt of higher education has surged.

“We want to create the most dynamic, interesting, educationally fascinating environment that we can,” he said—and that means figuring out a way for more people to come to campus.



Every month, Fidelity Investments contributes exactly $167 apiece toward the student-loan payments of almost 9,000 of its employees. In most cases, Fidelity can make a simple electronic transfer to student-loan servicers, the patchwork of companies that handle billing and other administrative functions for student loans in the United States, of which there are over $1.5 trillion outstanding. A few servicers, though, force Fidelity to issue paper checks for individual loan payments—and if there’s an error, the check eventually gets sent back. “There are definitely issues,” says Akhil Nigam, the head of emerging products for Fidelity’s workplace-investing division. “I think it’s a learning exercise for the recordkeepers as well as the loan servicers.”

Fidelity started offering the student-loan repayment benefit to its own staff in 2016, after surveying its employees and hearing from clients that student debt was holding their workers back from saving for retirement. (Why $167 a month? That totals $2,000 a year, the threshold where employees feel that the payment substantially helps them manage their debt, according to Fidelity’s surveys of workers.) Earlier this year, Fidelity began administering the benefit on behalf of its corporate customers, charging a per-person fee to wrangle with the student-loan servicers for them. So far, 25 employers, including Hewlett-Packard Enterprise, have signed up.

Other well-known companies, such as PricewaterhouseCoopers, Staples, Aetna, and Penguin Random House, have also added student-loan payments to their list of employee perks. About 4 percent of companies said they offered the repayment as a benefit last year, and the figure rises to 8 percent for companies with 40,000 employees or more. The U.S. Consumer Financial Protection Bureau (CFPB) has said the benefit could quickly become more popular, given how many people have student loans—more than 44 million in the United States—and how worried they are about them. “A lot of people just want to get rid of it, because it’s such an emotional burden that they’re carrying from the past,” Nigam says. “They tell us, ‘I would love to get rid of my student loans before I get married or move on to the next stage of life,’ as opposed to thinking about retirement.”

In 2015, graduates who took out student loans finished with an average of $34,000 in debt, compared with $20,000 a decade earlier. In March, Jerome Powell, the Federal Reserve chairman, said swelling levels of student debt could hold back economic growth. Economists at the Federal Reserve Bank of New York have found that graduates with student debt are less likely to own a home in their early 30s than those who completed their education without taking on as much or any debt.

The Obama Administration, through enforcement actions and establishing a student-loan ombudsman in the CFPB to monitor complaints, has tried to make it easier for borrowers to pay back their loans. In January 2017, at the end of the Obama Administration, the CFPB sued Navient, the largest U.S. student-loan collector. But the Trump Administration seems to be backing off some of the earlier efforts. The CFPB has continued the Navient lawsuit and has fined other servicers for illegal practices; it also still has a student-loan ombudsman. But on May 9, Mick Mulvaney, the interim director, said its student-loan division will be folded into a broader consumer-information unit. The bureau also removed from its long-term agenda the goal of improving student-loan collection. In April, Education Secretary Betsy DeVos withdrew policy memos issued by the Obama Administration that prioritized awarding contracts to student-loan servicers who dealt fairly with borrowers.

In these challenges, financial-services companies sense an opportunity. Both large businesses such as Fidelity and smaller financial-technology start-ups are developing platforms for employers to help workers repay their loans. The benefit is pitched as a tool to recruit and retain young workers, especially for high-demand jobs, such as nursing, in a tight labor market. Memorial Hermann Health System, which owns 15 hospitals in the Houston area, started offering student-loan repayment in 2015 to attract employees with one to three years of experience. The health system makes 270 loan payments each quarter, and the retention rate of nurses who have signed up is 95 percent, compared to the average retention rate for nurses, which is 88 percent, says Lori Knowles, the chief human resources officer.  “We believe in growing and developing our employees, and this is one of the things we can point to and show that we mean it,” she says.

Considering the anxiety around student loans, the benefit is appealing, but does it make sense? For one thing, the student-loan industry is notoriously opaque and difficult to deal with. By the time college students graduate, they may have accumulated loans from a number of different places. In contrast with credit-card companies, which typically provide in monthly statements what's called a minimum-payment warning, student-loan servicers don’t have to tell borrowers how long it will take to repay their loans if they contribute only the minimum every month. “When we launch a new client, employees will call us and say, ‘This says it’s going to take 14 more years to pay off this debt, and that can’t be right,’” says Scott Thompson, the chief executive of Tuition.io, a financial-technology company that began administering student-loan repayment benefits for employers in 2016. “We’ve had people cry on the phone.”  

Last year, the CFPB reported complaints from borrowers that student-loan servicers inexplicably returned payments from employers, applied funds to the wrong account, or made other servicing errors that took months or even years to resolve. In some cases, the benefit affected people’s eligibility for loan-forgiveness programs. Thompson, whose company provided information about customer experiences to the bureau for its report, says the larger servicers have become easier to work with as more companies have begun offering the benefit. Fidelity’s Nigam says that up to 90 percent of payments have no issues. Still, problems persist.

Nor is it clear that helping employees pay off their loans is any better, from a purely financial perspective, than giving them extra money to spend as they wish. When employers make payments for their workers, those payments are considered equivalent to regular wages. There’s no tax benefit, as there is for retirement plans, health insurance, or even tuition assistance. Employers have to pay payroll taxes on the student-loan payments, and employees have to pay income taxes. It’s like a bonus—but one that involves a middleman charging fees for processing the student-loan payments. A U.S. House bill introduced in February 2017, H.R. 795, would give employers’ student-loan payments more favorable tax consideration, bringing them in line with tuition assistance. The bill has more than 100 co-sponsors, from both parties, but the measure was not included in the giant tax-reform plan passed in December, and it is stalled in the House Ways and Means Committee.

Why, despite all this, are employers still offering the benefit? It may be that there’s a psychological advantage. Steve Connelly, the president of Connelly Partners, a Boston advertising agency with roughly 170 employees, says helping his young workers address their loans is an important “expression of empathy” with their financial situation. (A further motivation: He is friends with fellow Babson College alumnus Tim DeMello, the founder of Gradifi, a Boston financial-tech company that administers the loan benefit for Connelly’s agency.) “When you’re an old man, your job is to get as many young people into a 401(k) as possible,” Connelly says. “The kids that work for me today, they’re saddled with so much debt that, one, I feel some obligation to figure out how to help them, and, two, they can’t take advantage of our traditional 401(k) match.”

Connelly Partners offers its workers $1,000 up-front toward their student loans, then an ongoing $1,200 a year. Connelly is considering extending the benefit to older employees who have taken out student loans to cover their children’s college tuition. (People over the age of 50 are the fastest-growing group of people who hold student debt in the United States.) “Some people do get mad because it is taxable,” which can be a surprise, Connelly says. “Even though we tell them and tell them.” It could be more efficient for Connelly simply to give his employees extra money, and to let them use it to repay student loans—or cover some other financial need. But Connelly has a bit of a paternal feeling toward his young employees; he wants to help them repay their loans, not just hand them a stack of cash. Give employees a bonus, and “they’ll do whatever they want with it,” he says.

Employees, too, may get some emotional reward. Kelli Hovanec, a manager at the House of Blues in Dallas, signed up last year for a loan-repayment program introduced by Live Nation, which owns the House of Blues. She graduated in 2008 from DePaul University, where I teach journalism. Hovanec’s debt totaled over $28,000, and she had been paying $150 to $230 a month toward her loans. With the new benefit, administered by Tuition.io, Live Nation contributed another $100 a month. As of a few months ago, Hovanec thought she had about a year left on her payments, but she recently received a letter saying her loans were paid off. In disbelief, she called the servicer to make sure it wasn’t a mistake. “Then I texted my parents to let them know I was done, and then a few friends to rub it in their faces,” Hovanec says. She is planning to buy a new car, after years of postponing the purchase. “I don’t know anyone else in my group of friends,” she says, “that is going to be done in the next ten years.”



When Silent Sam, the statue of a Confederate soldier that stood sentinel at the University of North Carolina at Chapel Hill until he was yanked from his station in August, was being dedicated in 1913, Julian Carr, a philanthropist and white supremacist, took a moment to brag. “I horse-whipped a negro wench until her skirts hung in shreds,” he said in his speech, adding that he performed the “pleasing duty” in front of his entire garrison.

On Saturday, Duke University announced that it would remove Carr’s name from a building on its East Campus. “[The] white supremacist actions that Carr pursued throughout his life, even when considered in light of the time in which they were held, are inconsistent with the fundamental aspirations of this university,” the committee that voted to remove his name wrote.

Two days later, and 10 miles down the road, UNC’s board of trustees convened to decide the fate of the monument that Carr was helping to dedicate 105 years ago. Ever since the statue was taken down on August 20, the question has always been whether it would go back up, and in what capacity. At a special board-of-trustees meeting on Monday, Carol Folt, the chancellor of UNC Chapel Hill, announced the board’s recommendation: Silent Sam would stay on the UNC campus, albeit in a less pronounced position.

Administrators at the university recommended that the school build a $5.3 million building on campus to house the monument, Folt announced. The new, yet-to-be-named university history center would have “state-of-the-art” security and an operating budget of $800,000 a year.

The board considered putting the statue in one of several locations across campus. Folt said she would have preferred the new center be located off campus, but state law prevented the school from doing so. The board also consulted security experts, she said, who “recommended that the solution would require us putting the artifacts ... in a single-purpose building.” Public safety alone, she continued, would prevent the university from returning the statue to its base or another outdoor location on campus.

In August, my colleague David Graham wrote that “Silent Sam, like other memorials to the Confederacy, is a monument to a treasonous rebellion against the United States, fought to preserve the enslavement of African Americans.” The fight over what to do with Silent Sam has played out in dozens of other similar conflicts around the country, as colleges and towns decide what to do with their monuments to the Confederacy.

The board’s recommendation to house Silent Sam in a museum is not unusual—and in fact, several universities have followed a similar course of action when retiring other monuments to the Confederacy and racists. But the construction of a new facility—an expensive one, at that—is unlikely to please many people on either side of the conversation.

Chancellor Folt said that though Silent Sam does not belong “at the front door of a safe, welcoming, proudly public research university,” state law requires that if monuments are removed, they “shall be relocated to a site of similar prominence, honor, visibility, availability.” Essentially, the monument, the era of racist violence it represents, and its prominence on campus are buoyed by state law.

The UNC board of governors will have the final say on whether the recommendation is accepted at its meeting December 14. And at least one member of the board has already declared that he believes that the monument should be placed back on the perch where it lived for so many years.

It’s easy enough to remove a name, such as Carr, or a statue, such as Silent Sam, but more difficult to root out an idea—one that, at some level, continues to grip the nation. In a moment when “America is still working on the project of constructing a more equal society, and reinvesting in the experiment of a multi-ethnic democracy,” as my colleague Yoni Appelbaum wrote, the project of moving beyond America’s deeply unequal past will prove difficult.



Every year around this time—when commencement season and Mother’s Day collide—moms across the country are praised for their grit and resolve. It’s a tough job for just about anyone. But for 2.1 million single mothers, according to the latest federal data, the normal difficulties are compounded by the stresses of going to college.

For these moms, there may not be enough hours in the day to do all the tasks they have to do at home while still going to college. A new report from the Institute for Women’s Policy Research, a think tank and advocacy group for advancing women’s status, breaks down the data on the amount of time single mothers in college are spending on their obligations outside of the classroom compared with women students without children. The analysis, based on data from the Bureau of Labor Statistics’ American Time Use Survey, is instructive—and eye-opening.

Single moms who are enrolled in college full-time spend about two hours a day on active child care, six on supervisory care (meaning time spent looking after their children while doing another another activity such as cooking or cleaning), and about two hours on housework; all told, these women are spending upward of nine hours a day on care and housework. Students without children devote about two hours to all of those activities combined. And on top of all of that, the report found, single-mother college students are getting less sleep, exercise, and social time than other students. In a separate IWPR study, nearly half of women who attend community college and live with children said they thought they were likely to drop out.

“Single mothers in college are doing double and triple duty to make a better life for their families,” said Lindsey Reichlin Cruse, a researcher at IWPR, in a release that accompanied the new report, “but too few have the support needed to juggle the competing time demands of college, parenthood, and employment.”

It would make sense, then, that one of the most effective ways to help the population of students would be to give them back some of their time—time that could be spent on their classes—through child-care services. However, for many single mothers on campus, finding affordable child care isn’t easy.  

In 2015, fewer than half of both public four-year institutions and community colleges had campus child-care centers. And when those centers did exist, there was often a waiting list for their services. A 2016 report from IWPR found the average waiting list at campus child-care centers was about 80 children long. As the writer Amanda Freeman asked in The Atlantic in 2016, “What does it say about the country’s priorities that it’s easier to find drop-in childcare while you take Zumba than English 101?”

Research on how campus child care affects graduation is limited, but data from at least one institution—Monroe Community College in Rochester, New York—suggests it could have a significant impact. Student parents who used the campus child-care center between 2006 and 2014 were nearly 30 percent more likely to return to college the next fall than student parents at the same school who didn’t use the service. And those students were 20 percent more likely to graduate on time.

Several colleges have launched programs aimed at students with children. Notably, Bard Microcollege Holyoke, a collaboration of Bard College and the Care Center in Holyoke, Massachussetts, is a first-of-its-kind college created specifically for low-income women whose educations were interrupted by pregnancy and parenting. And Endicott College, also in Massachusetts, is home to a “Keys to Degrees” program that is specifically tailored to provide assistance to young parents—both men and women—and their children.

For parents not at one of these specialized institutions, change is coming—slowly: The federal government injected more money into child-care subsidies, through the Bipartisan Budget Act of 2018, doubling the funding for the Child Care and Development Block Grant program, which means that states will have more money that they could allocate for student parents. And a handful of Democrats introduced legislation in the House and Senate that would reauthorize the federal grant program specifically designed for on-campus child care, but their proposal has not yet gained much bipartisan momentum.

Still, as the report suggests, a lot of work remains to be done. States and federal lawmakers can target financial aid toward student parents. They can also tweak policy to allow college attendance to count towards work requirements for child-care funding. And, for their part, colleges can improve their efforts towards making child care accessible and affordable—and giving time back to single mothers on campus.



To be nerdy these days is to be cool. Pop culture’s adoration of nerds is ubiquitous in this era of high-tech gadgets. You can see it everywhere from The Big Bang Theory to The Bachelorette to the Scripps National Spelling Bee, the latter of which is broadcast on ESPN.  

Which is why it’s curious that competitions like the International Science and Engineering Fair (ISEF)—whose contestants each year vie for more than $5 million total in prizes, including $75,000 for the top winner—haven’t quite captured the public imagination. That may soon change. A new documentary follows a handful of teens who participated in last year’s ISEF, along with the no-nonsense Long Island, New York, teacher who managed to help nine of her students qualify for the competition.

Science Fair, which was released on Friday and will be shown in theaters across the country, offers a peek into the otherwise unfamiliar world of science competitions. The filmmakers, the former investigative journalists Cristina Costantini and Darren Foster, shadowed the students as they built prototypes and presented their tri-fold poster boards to judges with precision and poise. But they also caught the teens in more candid and endearing moments of brilliance and awkward adolescence. In one scene, for example, a girl on the Long Island team mocks her coach’s expression. In another, a trio of boys from Kentucky, whose project consists of an electronic, 3-D-printed stethoscope that helps doctors better detect heart abnormalities, is shown passed out on the airplane en route to ISEF; they had their senior prom the previous night. Then there’s the scene in which Robbie Barrat, an artistic math genius from West Virginia with abysmal grades, shows off his Hawaiian-shirt collection. He started wearing the colorful, printed button-ups to competitions, he explains, “because it’s as casual you can get while still having a collar.”

These characters and their personalities alone make the world of the ISEF cable-worthy entertainment. Add in the students’ scientific accomplishments and public-speaking savvy, and science fairs’ second-tier status becomes even more perplexing.

One of the students featured in Science Fair is Kashfia Rahman, a soft-spoken girl at a sports-obsessed school in Brookings, South Dakota, who ends up winning first place in her category at the 2017 ISEF for her findings on the role of repeated acts of risky behaviors in blunting emotional and cognitive functions in adolescence—a project inspired by her surroundings in Brookings, where teen drug and alcohol abuse is common. Toward the beginning, Rahman is shown roaming her school’s campus and pointing to all the cabinets filled with frivolous trophies won by its less-than-impressive sports teams. A few scenes later, the filmmakers approach various groups of students hanging out in places like the cafeteria or the weight room—no one had ever heard of Rahman, even though she’d placed third in the ISEF the year before.

Costantini, the co-director of Science Fair, who herself participated in science fairs as a teen, told me that Spellbound, the 2002 film that followed a handful of Scripps National Spelling Bee contestants, was her favorite documentary when it came out; she wants her film to contribute to science fairs the same kind of clout that Spellbound gave spelling bees. “That has always been a driving force for me,” she says. “I wondered: Why are these kids [competing in ISEF] not being celebrated? The event is just as fun … They deserve the credit and the celebrity” that spelling-bee contestants enjoy. Constantino and Foster suspect that part of the Scripps National Spelling Bee’s mainstream appeal has to do with the competition’s relative simplicity—it’s much easier to format the one-day event for TV than it would be the multiday ISEF.

In that sense, the directors and Rahman suggested, ISEF’s second-tier status likely traces back to something deeper, too: the perception that this type of science is out of reach for all but the whizziest of whizzes. Rahman insists that perception is false—the kind of research she and her fellow contestants produce, she argues, is far more relevant to the mainstream public than it may seem. “A lot of ordinary people are afraid of science because it’s such a broad subject with so many complex aspects to it,” Rahman, who recently started her freshman year at Harvard, told me in a recent interview. “It’s just an issue of accessibility—we just need to get the message out there that science has something to offer to everybody.”

U.S. schools in recent years have been swept up in a widespread push to enhance STEM education, and never has the importance of scientific discoveries to everyday people been clearer than it is today. Yet despite polls indicating that most Americans buy into STEM’s societal benefits, few Americans are confident about the quality of STEM education in the country’s K–12 schools, with 75 percent of respondents in a 2015 Pew survey of scientists attributing the public’s limited knowledge about science to schools’ underinvestment in such education. But even when educational opportunities exist, many children shun them because they don’t think they’re smart enough. In particular, some studies have suggested that demographic stereotypes—the belief, particularly in affluent communities, that STEM-related jobs aren’t for women, for example, or the message perpetuated among low-income students of color that caring about academics isn’t masculine—discourage kids from pursuing those fields.

Science Fair’s promise to get that message out is what makes Rahman most excited about the documentary and its broad theatrical release. Maybe schools will consider redirecting some athletics funding toward STEM education, and maybe students who would otherwise be intimidated by science fairs will give them a try. “What I love most about Science Fair … is that it’s being screened in a lot of places where there are young elementary-school kids,” especially girls and minorities, Rahman says. “They’ll be able to resonate with so many of the characters in a way they never could before.”  



There was a president with an energizing message, then a sharp, seemingly instant, political shift. The new president kept an enemies list that included a number of reporters. And he was knee-deep in controversy—though that only led some people to support him more fervently.

It was the 1970s. President Richard Nixon had been undone by a pair of young reporters at The Washington Post, Hollywood had made a blockbuster movie about it, and the reporters had become celebrities. People were excited about journalism—and that was reflected in massive enrollment jumps at journalism schools across the country. In 1970, enrollment of journalism majors hovered at about 33,000; by 1979, that figure had jumped to 71,000.

The late Ben Bagdikian, who wrote a cover story for The Atlantic in March 1977 on the so-called Woodstein phenomenon, summed it up like this: Bob Woodward and Carl Bernstein “were young, inexperienced, and not particularly promising in the eyes of their superiors. Working in a city and on a paper where the country’s most celebrated journalists were in top command, the two beginners beat them all and became national heroes … If they could do it, why couldn’t every high school student?”

Of course, Watergate wasn’t the only reason for the spike.  As Bagdikian noted, the growth of interest in studying journalism had started years earlier. Michael Schudson, a journalism professor at Columbia University, explained it to me like this: Journalists' salaries were on the rise, and there was “growing centrality of news media in the culture—from Kennedy–Nixon TV debates, to the TV-centric presidency of Kennedy, to the growing symbolic significance of the evening broadcast newscast (30 minutes long after 1963, instead of 15 minutes), to the Vietnam War and the military draft that had young people tuned into the news more than they usually were.” On top of all that, the ’60s saw  a series of enormous national news events: the assassinations of President John F. Kennedy, Martin Luther King Jr., and Robert F. Kennedy; protests against the Vietnam War across the country; and the civil-rights movement. The news cycle was, in no uncertain terms, wild.

Fast-forward nearly half a century, and the attacks being made on journalism are too lengthy to list, but they flow from the top. President Donald Trump doesn’t keep a list of reporters he finds to be enemies so much as he tries to publicly shame, vilify, and discredit them on social media and in speeches. He has called journalists everything from “the enemy of the people” to “very dangerous & sick” and repeatedly decried the media as “fake news.” But just like during the ’60s and ’70s, there’s  a whiplash news cycle. And across the country, students have renewed interest in journalism.

Madeline Purdue, the editor in chief of The Nevada Sagebrush at the University of Nevada at Reno, has taken note of this uptick in intrigue. The rhetoric from the president has trickled down to the campus level, she told me in an email. Some students who are upset with articles the Sagebrush publishes retaliate by calling the paper “fake news”  or trying to personally discredit reporters. Still, she says, “there is a higher interest among my peers in not only reading the news and being up to date on current events, but also pursuing a career in journalism.”

Several college-paper editors I spoke with shared similar anecdotes. But it’s hard to find good empirical data on the total number of journalism students in the U.S. (The Grady College of Journalism and Communication at the University of Georgia released its last report in 2014.) However, individual colleges have been keeping data, and they say enrollment is up.

Columbia University, the University of Southern California, and Northwestern University are among institutions that have also seen applications to their programs increase. Gail Wiggins, the interim chair of the journalism department at North Carolina A&T University, told me that the department saw a 6 percent increase in enrollment from 2016 to 2017. North Carolina A&T requires incoming students to write about why they chose journalism as their course of study, Wiggins said. More and more students, she told me, write that “they want to tell their own stories … they want to provide truthful information to improve their communities.”

But in an era where truth has actively been questioned by an administration that has consistently lied, the school—and others like it—have doubled down on teaching media literacy, fact-checking, and the basic tenets of reporting. “We are reemphasizing truth and accuracy,” Wiggins said. “With all of the new digital tools that we have at our hands—being accurate, checking your sources, doing your research: We definitely talk more about [those values] now than ever before.”

Rather than pushing students like Purdue away from journalism, the attacks on journalists reaffirm their commitment to the craft. “I want to protect what I love by doing my absolute best work,” she told me. “I don’t think the industry is perfect,” she says, but the consensus among her classmates is that with “honest, hardworking” journalists it can get pretty close.“That's what journalism schools are pushing out into the world.”



What to do when a school is infested with vermin, when textbooks are outdated, when students can’t even read? Perhaps the answer is sue the government.

That’s what seven students in Detroit have done. Their class-action suit filed against the state of Michigan asserts that education is a basic right, and that they have been denied it.

Usually, such education-equity cases wend their way through state courts, as all 50 state constitutions mandate public-education systems, while the country’s guiding document doesn’t even include the word education. But this case, Gary B. v. Snyder, was filed in federal court, and thus seeks to invoke the Constitution. And as of this week, it’s headed to the federal appeals court in Cincinnati.

The lawyers filing the suit—from the pro bono Los Angeles firm Public Counsel—contend that the students (who attend five of Detroit’s lowest-performing schools) are receiving an education so inferior and underfunded that it’s as if they’re not attending school at all. The 100-page-plus complaint alleges that the state of Michigan (which has overseen Detroit’s public schools for nearly two decades) is depriving these children—97 percent of whom are students of color—of their constitutional rights to liberty and nondiscrimination by denying them access to basic literacy. Almost all the students at these schools perform well below grade level in reading and writing, and, the suit argues, those skills are necessary to function properly in society. It’s the first case to argue that the U.S. Constitution guarantees the right to become literate (and thus to be educated) because other rights in the Constitution necessarily require the ability to read.

The case is a long shot. Late last week, the district-court judge in Detroit, Stephen J. Murphy, dismissed it. (The plaintiffs are appealing that dismissal.) Murphy essentially stated that he needed guidance from the Supreme Court if he were to weigh in on whether the students’ abysmal proficiency levels and learning conditions amount to a violation of the Constitution. He also concluded that the suit makes too many hard-to-prove causal claims. Even though Michigan subjects the predominantly black Detroit students to conditions to which it doesn’t subject, say, the predominantly white students of nearby Grosse Pointe, Murphy wrote, there isn’t enough evidence to suggest that the state is treating the former group differently because of their race and thus violating the equal-protection clause. Another obstacle: The federal judiciary has grown particularly restrained on educational-rights issues in recent decades, in part because of the backlash from parents and others opposed to integration efforts that followed the wave of school-desegregation rulings in the 1970s and ’80s.

The fact that a suit like Gary B. v. Snyder was even filed says a lot about the state of education in the United States today. The case is indicative of a new chapter in American education in which advocates, frustrated with persistent achievement gaps and glaring disparities in school quality despite efforts to combat those problems, are resorting to unconventional means to bring about change. Similar to the recent wave of teachers’ strikes , the lawyers behind Gary B. v. Snyder seek to interrupt what the plaintiffs and their supporters argue is a status quo of educational unfairness not only in Detroit, but also across the country.

The lawyers behind Gary B. v. Snyder sought recourse through the federal system, explained Kristi Bowman, an education-law scholar at Michigan State University who cowrote an amicus brief in support of the plaintiffs, because Michigan’s courts have generally refused to take on education-rights cases. That’s largely because the language on education in its constitution is even more vague and limited than that in the constitutions of many other states, some of whose courts have been very active in adjudicating suits about how schools are funded. States including Arkansas and Delaware, for example, constitutionally require the provision of “general” or “efficient” education, while states such as Colorado and Idaho stipulate that education be “thorough” or “uniform.” A few states, like Virginia, mention quality. And one state—Montana—guarantees “equality of educational opportunity” for all its residents. It also requires in its statutes that all schools provide a sound foundation for literacy in kids’ early years.

In Michigan, though, children’s right to education is simply about access—schools essentially only need to be in operation for that right to be fulfilled—rather than about “education of a particular level or quality,” said Bowman, who also serves as MSU’s vice dean for academic affairs. As Matthew Patrick Shaw, an assistant professor of public policy and education at Vanderbilt University, put it, Michigan’s constitution contains “no aspiration to high quality, no aspiration to efficiency.”

So, the plaintiffs in Gary B. v. Snyder decided to argue, as Bowman put it, that “what’s happening [in the Detroit schools] fell so far below any unacceptable level of education that it does violate the federal Constitution,” in the sense that, “If someone is functionally illiterate—unable to read at grade level—then how we can expect them to meaningfully engage in the rest of their explicit constitutional rights?” She went on, “How can we expect them to meaningfully participate in our government and exercise the right to vote and the right to free speech if their ability to obtain information and evaluate that information is so limited because the public schools that they attended did not even give them an opportunity to become literate?”

In his opinion explaining why he dismissed the case, Judge Murphy acknowledged that literacy is integral to one’s well-being—that, as the late Supreme Court Justice William J. Brennan once wrote in his opinion on a related educational-access case, “illiteracy is an enduring disability.” Yet Murphy concluded in his analysis that the due-process guarantee to life, liberty, and property does not “demand that a state affirmatively provide each child with a defined, minimum level of education by which the child can attain literacy.” Without that clarity, he was reluctant to assert that the right to literacy exists—let alone that the state violated it.

Murphy’s opinion may be right in a narrow sense, but some legal scholars I talked to said that he could have approached the subject more broadly. Murphy concluded that the plaintiffs failed to demonstrate that the state treated the given Detroit schools differently than it did others. But given that the students lack access to qualified teachers, to tolerable facilities, and to materials that support their learning—conditions that are far less common in predominantly white districts in the state—Murphy ignored the “strong racialized component, some of which has been engineered by the state,” that has contributed to these disparities, said Vanderbilt’s Shaw, who’s also an assistant professor of law. He added, “It has ignored the role that the states have played in creating these very systems,” noting that more prosperous school districts don’t need special assistance now because their neighborhoods were allowed by the government to develop differently.

“The court’s premise … ignores everything we all know about how endemic racism is—and has always been—in metro Detroit’s housing and employment patterns, and the role the state has had in allowing school districts to assign, hire, fund, and operate in reliance on these patterns,” Shaw argued. The decision to dismiss the case, he went on, “does not incorporate this very relevant history in any meaningful way, articulating instead a set of seemingly ‘neutral’ criteria to evaluate what it knows to be a very non-neutral, complex, and context-rich set of educational-rights questions.”   

The merits of the case and Murphy’s dismissal aside, though, Gary B. v. Snyder is important in that it is a direct attempt to establish how, if at all, the Constitution ensures that all Americans, regardless of where they live, receive a decent education. As Michael Rebell, a professor of law and education practice at Columbia University’s Teachers College, noted, in previous cases the Supreme Court has never stated that the Constitution has no bearing on educational-right cases—it just has never deliberated over a suit that gets at the question without any legal snags. “Everybody agrees this has been left open,” said Rebell, who is planning to bring a different education-rights case in another federal district court this fall, “and that’s why Mark Rosenbaum [the lead attorney in Gary B. v. Snyder] brought this issue in Detroit.” While the district-court judge in this case didn’t address the question of whether learning to read and write is a constitutional requirement, according to Rebell and others, the fact that it is being appealed—and could potentially make its way up to the Supreme Court—is significant. Even if it proves too soon for the courts to respond favorably to this suit, the case has still raised important questions that might, for example, prompt changes to state constitutions.

The suit is talking about kids falling through the cracks, Michigan State’s Bowman said, and it’s arguing that “we don’t just want to fix the situation for the kids that we know about—we also want to seal up the cracks so that no one falls through them in the future.” Even if Gary B. v. Snyder isn’t ultimately the case to seal up those cracks, maybe it’s showing the way for another group of lawyers to mount an argument that will.



In a textbook feel-good business move, the retail giant Target is offering a coupon to teachers this week that gives them 15 percent off select school supplies through Saturday. The coupon is part of the store’s back-to-school promotions, and covers folders and binders, arts-and-crafts materials, and classroom-storage equipment, as well as basics such as disinfecting wipes and food-storage bags.  

For many educators, the offer could be a big help. The vast majority—94 percent—of public-school teachers report spending their own money on supplies, according the National Center of Education Statistics (NCES). This is a significant expense for many of them, especially considering the average salary for K–12 public-school teachers is roughly $58,000. During the 2014–15 school year, according to the NCES report, teachers spent an average of $479 of their own money on school supplies. A separate analysis by Scholastic estimated teachers’ annual school-supply spending to be even higher. It also found that educators in high-poverty schools are far more likely than those at more affluent schools to fork out personal money for supplies. One out of 10 teachers at high-poverty schools spend $1,000 or more each year. And a separate NCES data set suggests that teachers’ school-supply spending rates have been this high for years.

This is precisely why Target is offering the discount, said Megan Roman, a company spokeswoman, in an email, citing the NCES report. “It’s a way for Target to acknowledge teachers are going the extra mile for their students.”

The fact that Target even thought to do this is indicative of the state of teaching in the United States today. The practice of teachers at underfunded schools paying out of pocket for school supplies is so common and well known at this point that a retail corporation has picked up on it as a socially beneficial revenue opportunity.

Target is hosting its “Teacher Prep Event” the summer after a school year marked by an uptick in teacher unrest. This past spring, public-school educators staged major walkouts in West Virginia, Oklahoma, Kentucky, and Arizona; teachers’ unions in many other states considered, or are considering, doing the same. Protesters and their supporters consistently cited the lack of basic school supplies—and the financial sacrifices educators make as a result—as one of their grievances. Striking teachers pointed to their reliance on online fund-raisers on platforms such as DonorsChoose, which allow individuals to donate directly to public-school platform projects.

The experience of Teresa Danks, a third-grade public-school teacher in Tulsa, shows just how tough things had become in Oklahoma, where in 2015, following a series of cuts, per-pupil spending was a little more than $8,000, compared with the national average of $11,400. In an April 2018 op-ed for NBC News, Danks explained that budget cuts over the years had led to her standing beside a highway with a sign asking motorists for donations. “I was tired of not having enough money for my classroom, of being expected to always use my limited cash reserves to pay to enrich my curriculum,” wrote Danks, who last year established the school-fund-raising foundation Begging for Education. Failing to allocate money for supplies, she argued, doesn’t only strip teachers of their personal cash, it can also have lasting academic consequences. “By forcing teachers to pay for students’ supplemental games, activities, art, and musical supplies, the state has taken away our ability to be creative,” Danks concluded.

The school-supply trend is one consequence of what the American Federation of Teachers—the nation’s second-largest teachers’ union—refers to in a new report as a “tide of austerity” that’s hit schools in the decade since the Great Recession. In 2016, the report found, 25 states were still providing less funding for K–12 schools than before the recession, after adjusting for inflation.

For the most part, policy makers acknowledge that schools need more funding, and that teachers make sacrifices to compensate for the shortfalls. But state budgets are stretched across the board, many argue, and that forces them to make tough decisions about budget allocations. Some policy makers worry that legislative efforts to address the school-supply issue by issuing stipends, as a bill in Arizona sought to do, are just quick fixes that conflate the problems of teacher pay and school funding.

More generally, some observers are skeptical of striking teachers’ demands, and argue that the problem isn’t so much with the dollars going to public education but with how that funding is managed. In an op-ed for The Hill on the Oklahoma walkout, the American Enterprise Institute’s Frederick Hess and Grant Addison suggested that the strike was “quickly becoming detached from efforts to ensure that dollars are spent responsibly.” They cited funding concessions that the state had made even before teachers started picketing and noted that Oklahoma had long provided teachers with health care and other benefits. “Teachers and taxpayers alike will be well-served if the push for more school spending is approached with an eye toward managerial discipline and what Oklahoma’s families can reasonably bear,” they wrote.

But in many cases, teachers, particularly those at poor schools where parents have fewer resources, have filled that spending void because they feel like they have no other choice, according to John Waldron, a high-school history teacher in Tulsa whose frustration with the persistent lack of investment in education prompted him to run for the Oklahoma House of Representatives. That’s in large part because of their intrinsic dedication to the job, but it’s also because they don’t want to let kids down, Waldron suggested. A furnished, well-designed classroom is a visible manifestation of a school’s investment in children. Teachers “do these things out of a sense of virtue but also a sense of guilt,” he says. He thinks policy makers and school-district administrators have taken advantage of that. “Teaching is a tremendously rewarding job … but the darker side of it is that because we view it as a missionary role, we expect our teachers to be saints.” Waldron, who’s taught at the same Tulsa high school for two decades, (he taught in Washington, D.C., before that), estimated that he’s spent $20,000 of his own money on supplies over the last decade, including $10,000 on books.

While appreciative of the Target coupon, Waldron worries that it “normalizes” this imbalance—that it signifies a default assumption that the onus is on teachers to ensure schools are well stocked and equipped, as Target puts it, with “a little extra sparkle.”

“Our culture is full of these signals that education is disregarded by officials,” Waldron says. “We allow massive inequities to develop between rich schools and poor schools. [People think] that teaching is a calling not a profession and it’s expected that teachers will sacrifice and legislators will underfund, so corporations will throw a little charity into the mix. When you think about what a good teacher can do in the classroom for a kid—change their lives, change society—why do we make teachers panhandle for the supplies they need?”

Other than initiatives like the coupon discount at Target, teachers don’t have many options if their school administrators don’t pay for supplies. The tax benefits are limited, too: Thanks to a 2002 law, teachers can deduct up to $250 from their federal taxes for their spending on classroom materials. Pending legislation in Congress that seeks to double the deduction and index it to inflation has 50 co-sponsors, but it has yet to advance past the House of Representatives’ tax-writing committee.

Until such legislation passes, or until schools’ supply budget increases, every 15 percent off helps.



For many middle- and high-school students, giving an in-class presentation was a rite of passage. Teachers would call up students, one by one, to present their work in front of the class and, though it was often nerve-racking, many people claim it helped turn them into more confident public speakers.

“Coming from somebody with severe anxiety, having somebody force me to do a public presentation was the best idea to happen in my life,” one woman recently tweeted. According to a recent survey by the Association of American Colleges and Universities, oral communication is one of the most sought-after skills in the workplace, with over 90 percent of hiring managers saying it’s important. Some educators also credit in-class presentations with building essential leadership skills and increasing students’ confidence and understanding of material.

But in the past few years, students have started calling out in-class presentations as discriminatory to those with anxiety, demanding that teachers offer alternative options. This week, a tweet posted by a 15-year-old high-school student declaring “Stop forcing students to present in front of the class and give them a choice not to” garnered more than 130,000 retweets and nearly half a million likes. A similar sentiment tweeted in January also racked up thousands of likes and retweets. And teachers are listening.  

|￣￣￣￣￣￣￣￣￣￣￣|
stop forcing students
to present in front of the
class and give them a
choice not to
|＿＿＿＿＿＿＿＿＿＿＿|
\ (•◡•) /
\ /
---
| |

Teachers, please stop forcing students to present in front of the class & raise their hand in exchange for a good grade. Anxiety is real.

Students who support abolishing in-class presentations argue that forcing students with anxiety to present in front of their peers is not only unfair because they are bound to underperform and receive a lower grade, but it can also cause long-term stress and harm.

“Nobody should be forced to do something that makes them uncomfortable,” says Ula, a 14-year-old in eighth grade, who, like all students quoted, asked to be referred to only by her first name. “Even though speaking in front of class is supposed to build your confidence and it’s part of your schoolwork, I think if a student is really unsettled and anxious because of it you should probably make it something less stressful. School isn’t something a student should fear.”

“It feels like presentations are often more graded on delivery when some people can’t help not being able to deliver it well, even if the content is the best presentation ever,” says Bennett, a 15-year-old in Massachusetts who strongly agrees with the idea that teachers should offer alternative options for students. “Teachers grade on public speaking which people who have anxiety can’t be great at.”

“I get that teachers are trying to get students out of their comfort zone, but it’s not good for teachers to force them to do that,” says Henry, a 15-year-old also in Massachusetts.

To the thousands of teens who support the effort to do away with in-class presentations (at least enough to like a tweet about it), anxiety is no small issue. Students said they understood why older people might tell them to “suck it up,” but that doing so was unproductive. Some responses to the most recent viral tweet, though, noted that giving a presentation in spite of anxiety might reduce a student’s fear of public speaking.

Just so you know, “Exposure therapy” is commonly used amongst psychologist as a behavior therapy to help treat anxiety disorder. So your point about “ it can’t be cured facing your fears.” Is just false.

Being a high schooler in 2018 is more stressful than ever. Academic demands on students are high, kids participate in more extracurricular activities than in the past, and they are saddled with extra hours of homework.

“Kids doing sports don’t get home till 7:00 p.m. I get home at 5:30 p.m. tonight but it’s going to get worse,”  Bennett says. “Kids ... can’t be holed up in their room every night till 1:00 a.m. finishing homework on their third Red Bull.” These stressors and more have led to an unprecedented level of anxiety in their generation. Anxiety is increasing at a faster rate than depression as the leading mental-health issue affecting teenagers, a recent study in the Journal of Developmental and Behavioral Pediatrics found. Throwing things like in-class presentations on top of other stressors kids are dealing with, teens say, can be unbearable.

“Teachers think it’s just a fear,” says Jess, a 16-year-old in New Jersey. “We’ll skip school. I’ve skipped school a lot of times if I had to present. Even if a teacher lets me present alone in front of them I still wouldn’t because that’s how nerve-racking it is,” she said.

These students want more options. They say that every student has unique strengths and abilities and that they should be allowed to present their work in ways that speak to those strengths. This might mean presenting alone in front of the teacher, or choosing between several alternatives like producing a piece of art or an essay for private judgment instead of presenting their work orally.

“The resounding theory that education is holding on to right now is the idea of multiple intelligences,” says Travis Grandt, a high-school history teacher in Colorado who says he tries to accommodate students with special needs, including anxiety. “There [are] a lot of ways for kids to present information. It doesn’t have to be through a formal presentation.”

Joe Giordano, a high-school teacher in Baltimore, says that he’s also sympathetic to the movement away from mandatory in-class presentations. As an art teacher, he hosts “crit” sessions where students’ work is critiqued. He always gives the teenagers a choice as to whether or not they want to speak about their own work.

“It kind of irks me when I see a lot of other teachers say, ‘But we have to get them up there.’ These kids are living under more stressful situations than I did as a student. Their anxiety runs pretty high,” he said. “I know we should put them in uncomfortable situations, but if they suffer from anxiety they’re already in an uncomfortable situation. As a teacher I try to show compassion. It’s not about being a drill instructor.”

Kathleen Carver, a high-school history teacher in Texas, says teaching has changed since the days when she grew up. “I think in this day and age there [are] different pressures. We expect different things from our students,” she said. “We’re in a day and age where we have to acknowledge our students’ feelings. I have to listen to them and hear their feedback and respond to that. That’s how I can be a more effective teacher. If I ignored their feelings I don’t think they would like me or my class or walk away learning things.”

Those campaigning against in-class presentations said that it was important to distinguish between students with actual diagnosable anxiety disorders and those who might just want to get out of the assignment. Addie, a 16-year-old in New York, said that schools like hers already make accommodations for students with certain learning issues to get extra time on tests. She thinks similar processes could be put in place for students with public-speaking anxiety. “I think it’s important these accommodations are accessible, but that they’re also given to those who are need it instead of those who just say they don’t want to present,” she said. “There’s a big difference between nervousness and anxiety.”

Students who have been successful in the campaign to end in-class presentations credit social media. Unlike previous generations, high schoolers today are able to have a direct impact on their educational system by having their voices heard en masse online. Teenagers, most of whom are extremely adept at social media, say that platforms like Twitter and Instagram have allowed them to meet more kids at other schools and see how other school districts run things. They can then wage campaigns for changes at their own school, sometimes partnering with teens in other districts to make their voice louder.

Henry said that he’s seen the effects of these types of campaigns firsthand. This year his district shifted the school start time an hour and fifteen minutes later, something he and his fellow students campaigned for aggressively on social media, which he believes played a role in the decision. High-school students across the country have also waged social-media campaigns against discriminatory dress codes, excessive homework, and, most notably, to advocate for gun-control policies on campus. “Teens view social media as a platform to make changes,” Carver says.

Part of why students feel social media is such a powerful mechanism for changing education is because so many teachers are on these platforms. Nicholas Ferroni, a high-school teacher in New Jersey, said that “a lot of teachers use social media as a great way to learn methodologies.”

“Instead of trying to go to a school-board meeting with a bunch of adults in suits—that’s how it was—you can just talk to everyone directly,” said Addie. “We don’t have to do all that stuff formally. We can go online and say what we want to say and people have to listen to us.” “I think social media is a great way to reach educators,” said Bennett.

But when it comes to abolishing in-class presentations, not everyone is convinced.

“We need to stop preaching to get rid of public speaking and we need to start preaching for better mental health support and more accessibility alternatives for students who are unable to complete presentations/classwork/etc due to health reasons,” one man tweeted.

Some educators agree. “My thoughts are that we are in the business of preparing students for college, career, and civic life. Public speaking is a piece of that preparation,” says Ryan Jones, a high-school history teacher in Connecticut. “Now, some kids (many) are deathly afraid to do it, but pushing outside of comfort zones is also a big part of what we do.”



When Stevie Peters was a kid, she used to read books for pizza. She remembers participating in Pizza Hut’s reading program, which still exists today, as her first experience with reading challenges. “When I was a kid, I read all the time, even if it wasn’t for school, so the idea of reading 200 books just so you could get a pizza was the best thing ever,” she told me. Peters, now 31 and living in Swansea, Wales (though she grew up in the United States), started participating in reading challenges again in 2016, though no one is giving her free pizza for doing so now that she’s an adult. Every January, she logs into her Goodreads account and sets a goal to read 50 books that year. She hasn’t hit that number yet—she said she usually makes it to 45 or so. Still, “I can definitely do 50,” she said. “I just want to keep challenging myself to read as much as I can.”

Though surely people have had personal reading goals for as long as there have been books, the book-tracking social-media site Goodreads seems to have institutionalized and popularized the practice of setting yearly reading targets. The Goodreads Reading Challenge started in 2011 and had 149,716 participants that year, according to the website. This year, more than 3 million people have pledged to read an average of 59 books before the end of 2019. (This number is skewed by some particularly ambitious folks—the majority of people pledged to read 1 to 24 books.) Other sites, such as Book Riot and PopSugar, have their own yearly reading challenges, and on Reddit, users strive for 52 books a year, one a week.

In 2018, only 16 percent of participants in the Goodreads Reading Challenge actually completed it, finishing 21 percent of the total books pledged. In earlier years of the challenge, those stats were sometimes higher—in 2011, 29 percent of participants finished the challenge, and in 2013, participants read 56 percent of the books pledged. This could be because in the early days of the challenge, only the most hard-core readers were participating—Goodreads started actively promoting the challenge to its users in 2015. But Suzanne Skyvara, a spokesperson for Goodreads, told me that the company doesn’t have data on what affects whether someone completes the challenge, and declined to speculate, saying the site prefers to focus on the fact that people are reading at all.

Still, the fact remains, more and more people are making reading goals that most of them will not meet. Why set yourself an unattainable goal? Why quantify your leisure reading at all?

Perhaps the most intuitive reason is the most common: Adding some structure to your reading life can be a way of making sure that you actually read. In 2011 and 2012, Donalyn Miller, a reading ambassador with Scholastic and the author of two books about reading habits, conducted a survey of adult readers’ practices, trying to figure out what keeps people reading when they no longer have the structural support of having to read for school. One of the key things she found was that “the only difference between a nonreader and a reader is that a reader has a plan for future reading and a nonreader does not,” she told me. It’s easy enough for reading to fall by the wayside with the responsibilities of adult life and the on-demand pleasures of Netflix and the like. “A plan for future reading” might just mean putting books one is interested in on hold at the library, or a loose plan to dedicate more time for reading. Or it might mean a yearly reading challenge.

Ben Gosbee, a 31-year-old accountant in Beverly, Massachusetts, says he read all the time as a kid, but noticed that in recent years he hadn’t been reading much. So he set a goal of reading 25 books this year. The number, he told me, is “something concrete to focus on”—he fears that if he had instead made his goal to read a little bit every day, he would have found excuses not to. As an accountant, he said, he’s very “numbers-oriented—I enjoy that kind of organization and sorting through data.”

Attainable reading goals can be motivating and improve the experience of reading, according to Neil Lewis Jr., a professor of psychology at Cornell University who studies motivation and goal pursuit. But “if the goal is unrealistic (given the realities of the person’s life) then it could actually be demotivating,” he told me in an email. “When people set goals like this, we often forget to take into account the other things that usually occupy our time and get in the way … If you have not been reading as much as you would like, it is probably because you are doing other things instead; are you willing to scale back on some of those things to make time for more reading?”

Indeed, some people find the challenges to be the opposite of motivating. Sue, a 50-year-old teacher who lives in Crowthorne, England, just joined Goodreads this year and set a goal of reading 20 books. (She asked to be identified by her first name only so that her students won’t see her private information.) So far, she’s not enjoying her experience with the challenge. She’s kept a list of every book she’s read in a notebook since she was in secondary school, and can see from that record that she actually used to read more books in a year when she didn’t set a numerical goal.

“I put down 20 books, which I thought was not a lot compared to what I have done,” she told me. “Ever since I’ve done that, I found my reading rate has slowed down. I keep getting messages from Goodreads saying, ‘You’re behind target on your reading schedule.’ I’m wondering if psychologically it made it feel more like a chore as opposed to pleasure. I almost wish I hadn’t gone onto Goodreads. It’s making me feel like I’m back in my school days.”

This is the curious thing about reading goals—they are essentially homework that people make for themselves. Like homework, reading challenges can feel like pointless busywork for those who aren’t feeling intrinsically motivated to read. Or they can bring a sense of learning and accomplishment.

It’s not always a numbers game either. Browsing the forum for this year’s Goodreads Reading Challenge, I found that a lot of users, in addition to pledging to read a certain number of books, have other goals as well, seemingly intended for self-improvement or to broaden their horizons. Some want to read more books by authors of color, or more classics. One woman wants to read 100 biographies and/or memoirs before she turns 40.

Halle Stoutzenberger, a 29-year-old data-entry clerk who lives in Atlanta, in addition to her Goodreads goal of 52 books a year, has a “side goal” of reading more fantasy this year. To help with that, she has set up what many readers call a “TBR jar.” (“TBR” stands for “to be read,” and among the crowd of those who like to quantify reading, you will often find folks reveling in or bemoaning the growing size of their TBR pile.) Stoutzenberger explained how the TBR jar works to me in an email: “Write down the books you want to include in your goal on scraps of paper. Then fold up the scraps and place them in a jar. When you’re ready to select a book, simply pick out a scrap at random.”

“The TBR jar can sometimes feel like a high school summer reading list because it’s something I’m requiring of myself, but it also makes a game of my ever-increasing list of books to read, so it’s fun in that way,” she said. “It definitely feels like something in between self-improvement and leisure, though.”

Other forms of entertainment straddle that line—watching documentaries, for example, can be both educational and fun—but reading seems to inspire this gamification, homework-ification, and quantification to a unique degree. Perhaps that’s because society tends to view reading as an intrinsic good, whereas other media—movies, TV, the internet—are often seen as time-wasters. “Given many [people] feel they’re consuming too much media, the goal is usually to limit consumption,” Ayelet Fishbach, a professor of behavioral science at the University of Chicago Booth School of Business who studies goals, told me in an email. “In this sense, for many people reading is a virtue—so you want to increase it—while watching TV is a vice—so you try to limit it.”

Skyvara, of Goodreads, echoed this sentiment in our conversation, comparing reading challenges to weight loss. “Even if they don’t achieve their goal, they’re still probably reading more books than they would’ve,” she said. “It’s kind of like if you decided to lose weight and your goal is to lose 20 pounds and you’re able to lose 15 pounds, you’re still better off.” Of course, neither reading nor weight loss is an inherently virtuous pursuit—but both often get categorized as self-improvement, or as something people vaguely feel they should be doing. Both are very common New Year’s resolutions, for example.

Ultimately, the people I spoke with who seemed to be enjoying their reading challenges the most were the ones who didn’t seem to care much about completing them. Gosbee thinks he’s not going to hit his goal of 25 books this year, in part because when he reads nonfiction, he reads more slowly to try to absorb the information. But the real goal, he said, is just to spend some enjoyable time reading. (Miller pointed out that many people, like Gosbee, get some “self-awareness of themselves as a reader in the process” of doing a challenge, even if they don’t complete it.) Peters has developed a strategy of reading several books at once, so that if she gets bored of one, or just isn’t in the mood for that genre, she can dip into another. When she doesn’t make her goal, she said, it’s a little frustrating, but not a huge deal: “By the time January 1 rolls around and Goodreads asks you what you want to read for next year, I just shake it off and say, ‘We can try again.’”



OiYan Poon stumbled upon WeChat largely by accident.

Poon is a professor at Colorado State University who studies the racial politics of higher education. For years she had consistently found that most Asian Americans supported affirmative action, but in 2014, something surprised her: A fledgling network of politically savvy Asian Americans had derailed a Democrat-backed ballot initiative in California that would’ve rescinded the state’s long-standing ban on race-conscious admissions. These activists—with their loud, recurring demonstrations, scathing op-eds, pro-Republican canvassing, and roundtable discussions on Chinese-language talk shows—had materialized unexpectedly, at least to Poon.

Determined to learn more, Poon in 2016 took to her typical research methods—convening a team of students and colleagues to help her pore through court filings, news stories, social-media posts, and the like—in an effort to track these dissenters down. But the few activists who did have an online footprint didn’t respond to Poon’s inquiries. The professor continued to flounder until she took the advice of an acquaintance and opened an account on WeChat, the popular messaging app based in China. The virtual gathering place was a hub for these activists.

Once comprising a relatively small, California-centric group of well-educated Chinese immigrants, this network of activists has connected like-minded people across the country, many of whom are part of separate groups all campaigning against affirmative action—including the organization behind the pending federal lawsuit accusing Harvard of anti-Asian discrimination, as well as a group that recently filed a lawsuit against the University of California in pursuit of admissions and enrollment data. The activists’ growing savvy and resulting sway, however, contradict the narrative painted by public-opinion data, which consistently show that most Asian Americans support affirmative action. So why was it that these activists had managed to dominate headlines and distort the narrative around Asian Americans and their relationship with race-conscious admissions? The answer to that question, Poon may have inadvertently discovered, could be found in WeChat.

“There was no such mobilization [among the Chinese American] community before WeChat happened,” says Steven Chen, a Los Angeles–area computer engineer who immigrated to the United States from mainland China in the late 1980s in pursuit of a graduate degree.

Text messages and phone calls are WeChat’s bread-and-butter functions, but the app does a lot more: People can hail taxis or share car rides, exchange money, order takeout, and shop online, among a litany of other mundane tasks and interactions. A smartphone’s WeChat widget, in other words, is kind of like a portal into a sea of more widgets; iMessage, Skype, Uber, Venmo, and so on, all in one place. Every day, according to company data, an average of more than 900 million people use the app, many of them utilizing its various social-networking functions to engage with folks they’ve never met in person. One Chinese American immigrant I spoke with, Jing Liu, told me that she had met most of her present-day friends through the app.

“WeChat is a monster,” says Janelle Wong, a political scientist and professor of Asian American studies at the University of Maryland. “There’s nothing like it on Earth.”

Launched in 2011, WeChat first gained traction among immigrants who used it to stay in touch with relatives and keep up on current events in mainland China. In the years since, the app has taken on a life of its own in the United States, becoming what Chen has described as a “virtual Chinatown.”

In reflecting on the app’s reach in the U.S., Chi Zhang, a doctoral student at the University of Southern California who studies WeChat, pointed to its function as a form of ethnic media. By connecting Chinese American immigrants to their homeland and by providing them the kinds of culturally relevant news tidbits seldom covered by mainstream American news outlets, she says, it “fosters their collective memory of their political struggles.” But, Zhang notes, WeChat also helps bridge the Chinese American community with broader U.S. society; it’s the place these immigrants go to stay abreast of everything from Supreme Court developments to the goings-on of their city council. In this sense, WeChat allows Chinese American users to feel at once more Chinese and more American. And this dual empowerment helped enable the Chinese American uprising against affirmative action.

A growing body of survey data shows that Chinese Americans—the United States’ largest Asian ethnic group—are almost single-handedly responsible for what’s been affirmative action’s slight decline in popularity among Asian Americans as a whole. In a 2012 AAPI Data survey, close to 80 percent of Chinese respondents said they favored policies that promote better access to higher education for black students and other minorities; by 2016, the number was roughly half that. Interestingly, that reversal was driven by Chinese Americans who were born abroad, according to Wong. Crunching the numbers from another survey, Wong found that among respondents who said they had an opinion (a significant portion did not), the amount of support among immigrants from China was more than 20 percentage points less than that of U.S.-born Chinese Americans.

The Chinese Americans driving this movement are highly educated, many of them with an undergraduate degree in a STEM field from one of China’s extremely competitive universities and having arrived in the U.S. with the help of selective-recruitment immigration policies. These educational and immigration experiences tend, in turn, to shape their attitudes about college-admissions policies. While Wong and other scholars cautioned against buying into model-minority stereotypes, activists regularly cited such traits in explaining their fervent opposition to affirmative action.

For example, Crystal Lu, an affirmative-action opponent who immigrated to the U.S. in 1999, says that in Chinese culture “there are no shortcuts” for doing well academically or otherwise. Lu received a master’s degree in journalism from Stanford and today is president of the Silicon Valley Chinese Association Foundation. “We truly believe that education is the one single enabler for social mobility,” she told me, “and with that philosophy our children … [learn to] think about the long term and forget about the short-term pleasures like watching TV, playing games, and going to parties.” Many of her fellow activists have generally conservative political views and support Donald Trump, whose administration is investigating allegations against Yale similar to those at the center of the Harvard lawsuit. “We realized our American dream, our aspiration to move up the social ladder, was being stripped away,” Lu says. “If we do not fight, then our whole cultural heritage collapses … That’s heartening to see—that this group that had been really [politically] apathetic, really quiet, is stirred and provoked and stimulated, and started to do something that’s completely opposite to their nature.”

Is WeChat just where these people happened to be, and so that’s the tool they used? Or is there something specific about how this app works that amplified and expanded this movement? WeChat did not respond to numerous requests for comment. But virtually everyone I interviewed for this story agreed that this movement wouldn’t be where it is today—a well-organized network of activists with leaders in every major U.S. city that has garnered widespread media coverage and is poised to bring affirmative action back to the Supreme Court—if it weren’t for WeChat.

Why? A key reason has to do with the way in which information travels within WeChat’s confines.

As long as she fulfills a very basic set of criteria, pretty much any casual user can be approved as an “official account,” becoming her own news-media outlet and generating unique content or aggregating information from other sources. Much of that information is disseminated via closed chat groups, where as many as 500 members each discuss a wide array of topics, including the Harvard suit and college admissions.

The result is, to borrow Zhang’s words, a “self-contained news ecosystem” that at its best builds and bridges communities and at its worst breeds echo chambers and facilitates the spread of misinformation. As private gathering places, the groups rely on gatekeepers who effectively foster tribes—ideological safe spaces that can intensify emotions around a sensitive issue. According to Zhang and other observers, this emotional underpinning combined with the limited scrutiny of official accounts allows extreme viewpoints to spread. I reviewed a number of conversations in WeChat groups whose focus includes affirmative action and found that in some of them antiblack racism was common, as was vitriol toward members who pushed back against the dominant beliefs of the group. Such commentary often included misinformation, such as unfounded accusations that Ivy League institutions have Asian quotas.

The fact that the affirmative-action debate is so emotional, however, also reveals the limitations in attributing to WeChat the current state of Chinese American political engagement. WeChat is simply “a tool” that enabled the movement to spread beyond the core coalition of activists whose political views long preceded the app, says Jack Ouyang, the vice president of the Asian American Coalition for Education, the now-vast network of affirmative-action opponents that drove the 2014 crusade in California.

From her vantage point as an expert on WeChat as a vehicle for political mobilizing, Zhang, who hasn’t yet figured out what her stance on affirmative action is, echoed Ouyang’s point. “Especially at this moment, there’s a real sense that Chinese Americans who otherwise are pretty invisible … could change the direction that the country is heading, and that itself is very energizing,” Zhang says. “So I think there is a certain energy and momentum that people who oppose affirmative action are latching on to.” Simply put: Activists were already on WeChat, so that’s where they leveraged their existing energy and momentum. Had they dedicated more of their organizing to Facebook, the same could have happened there.

“WeChat’s impact has to be understood as an information environment as a whole—it’s kind of like a fishbowl in which you have these different narratives that kind of cohere together, one of which is the neglect and marginalization of Chinese Americans,” Zhang says. When she tries to put herself in the shoes of one of these activists—say, someone who immigrated to the U.S. relatively recently and isn’t familiar with the history of racial oppression in the country—she can see why they have taken to this cause. It’s easy to see how that person might feel especially provoked if she herself feels she was held to higher standards in her pursuit of college admission or a good job. “I don’t see how they would support affirmative action,” Zhang says, “without significant persuasion otherwise.”

Karen Yuan contributed research.

This article is part of “The Speech Wars,” a project supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press, and the Fetzer Institute.



Update: This article has been updated to remove identifying information about a teacher and to clarify the reporter’s classroom observations.

Four years ago, Paul France left a teaching job in the Chicago suburbs to move to San Francisco and be part of the so-called personalized-learning revolution in education. He joined a high-profile start-up called AltSchool whose investors include Mark Zuckerberg and the venture-capital firm Andreessen Horowitz. France was passionate about both education and technology and welcomed the opportunity to combine the two. But they would not prove to be as complementary as he thought.

AltSchool’s founder, a former Google executive named Max Ventilla, envisioned it as a place where students, aided by technology and tech-savvy teachers, would learn at their own pace, based on their interests and aptitudes. Teachers, using proprietary software to track student performance and help guide their learning, would be freed from time-consuming tasks like scoring exams and could devote more attention to students. The company’s mission was to help move the American education system from an industrial-age model “where schools were set up to resemble factories and students had a conveyor belt-like experience” to a more “learner-centric” approach that gives students a sense of agency and 21st-century problem-solving skills, Devin Vodicka, who is responsible for guiding the company’s personalized learning platform as it expands to more schools, told me.

The company opened small lab schools in San Francisco, Palo Alto, and New York. Students were provided with their own iPads or Chromebooks along with individualized “playlists” of learning activities to choose from. Cameras in classrooms videotaped students’ and teachers’ interactions, enabling teachers and engineers to analyze the footage and review what worked, a process AltSchool technologists hoped would eventually be aided by computers using machine-learning algorithms.

AltSchool was flooded with applicants willing and able to pay tuition of $30,000 or more for their children to attend, and became one of the hottest start-ups in educational technology; to date, it has raised more than $170 million in investment. It was part of a broad investor rush to ed tech. Last year, venture-capital investors put $2.7 billion into ed-tech companies, up from $1.6 billion in 2016, according to CB Insights, a software company that examines technology trends. The Chan Zuckerberg Initiative, the Netflix founder Reed Hastings, and the Gates Foundation have given millions of dollars to schools implementing technology-based personalized learning—many of them urban charter schools serving low-income children.

But in the midst of all the excitement, there’s little strong evidence that classroom technology, including personalized learning, is improving educational outcomes. A 2015 report from the Organization of Economic Cooperation and Development found that countries that invested heavily in computer technology for schools showed “no appreciable improvements” in reading, math or science, and that technology “is of little help in bridging the skills divide between advantaged and disadvantaged students.”

A recent Rand study evaluating the use of personalized learning found emerging signs of promise, but with plenty of caveats. Students in 40 schools with personalized-learning programs funded by the Gates Foundation scored a bit higher on standardized English and math tests over the course of one school year, with only the math gains reaching statistical significance. A “slight majority” of schools had positive gains, the report found. But because it didn’t have a randomized control group, “our study is not able to make a very strong statement about whether the personalized learning approaches actually caused the improvement,” Elizabeth Steiner, a study co-leader and an associate policy researcher at the think tank, told me.

The Rand report also found challenges: Helping students work at their own pace can make group projects and collaboration more difficult because students are at different places, while also making it harder to prepare kids for year-end standardized tests. Another review of the Gates-funded effort, by the Center for Reinventing Public Education, concluded that: “At the end of two years, despite some pockets of innovation, few schools had developed replicable strategies for personalized learning.”

Vodicka, aware of such findings, said the results of personalized learning depend on how it’s implemented—and that AltSchool was already addressing many of the concerns identified by the Rand review by, for example, creating flexibility in the pace at which students progress through a course and giving teachers time and resources to develop and evaluate new materials and approaches. “There’s a version of personalization which ends up as computer-based screen time in which the learner basically gives up their agency to the technology,” he told me. “That’s not what we’re trying to do at AltSchool.”

Another school network that has been using technology and personalized learning for years in an effort to eliminate the achievement gap, with mixed results, is Rocketship Public Schools a network of charter schools, which serves low-income Latino and African-American students, mostly in and around San Jose. It has won credit for pushing up test scores but has also been criticized for its heavy reliance on computer-based instruction.

At Rocketship Los Sueños in San Jose, students spend extended periods of time on laptops in their classroom and another 90 minutes in the Learning Lab—a large room where kids spend time sitting at long tables, wearing headphones and working on laptops, supervised by classroom aides. On a visit last June, I found that few things broke the silence: when kindergartners filed in from recess; when a staff member came into the room. Students scarcely talked and when they did, or their attention drifted too far, they were admonished. A supervisor prompted the kids to “focus” and “sit up”. She counted down—“8, 7, 6, 5, 4”—when it was time to switch from one software program to another. The kids looked zoned out, with blank expressions on their faces. “Technology is not a substitute for excellent instruction at Rocketship Public Schools,” a spokesperson for Rocketship said. “Our teachers lead the learning process for every single student we serve.”

When Paul France went to work at AltSchool, he told me, he believed using technology in schools could “minimize the complexity of the classroom ... and make us more powerful, allowing us to do other things with our time.” He helped open three Bay Area schools and worked closely with engineers, testing and developing software. As the school’s buzz grew, he became the company’s poster-teacher, appearing in stories in Wired,  The New Yorker, and Pacific Standard. “He is young, enthusiastic, and enterprising—the kind of teacher every parent would want for their child,” Issie Lapowsky wrote in Wired.

France and his fellow teachers prepared lengthy narrative reports on each child’s progress sent twice a month to parents. For many parents, that wasn’t enough. “Parents are coming to me asking, ‘What are you doing to individualize for my child?’” France said. “Or ‘Why is my child working on the same thing as that kid over there?’” He felt many parents seemed to put more faith in software like Lexia, a reading program, and DreamBox, a math application, than in teachers. They’d ask, for example, why a student who’d already passed a certain standard in DreamBox was still doing similar work in class. “They don’t know how mastery works with kids,” France said. “The programs aren’t really assessing for conceptual understanding, they’re assessing if they answered the question right.”

As time went on, France started questioning what he and his colleagues were doing. “The vision was a curriculum that catered to every child so they’re learning at their level all the time,” he said. “But when every child is working on something different, you’re taking away the most human component in the learning process, which is social interaction—learning from one another and collaborating to solve problems. They’re developing a relationship with their tablet but not with each other.”

For France, the turning point came one morning when he looked around a kindergarten classroom, “and the kids were staring at their tablets, engrossed by them. And I’m thinking to myself, ‘They could be building with blocks, they could be doing a number of different things that are more meaningful that also build social and emotional skills but they’re choosing not to. Why? Because the tool is so addictive, that’s all they want to do.’”

AltSchool representatives say that after four years of experimentation, and a fair bit of trial and error, they’ve solidified their approach and let go of concepts that don’t work, including some of those that bothered Paul France. Vodicka, a former superintendent of Vista Unified Schools in California, was hired last year to build AltSchool’s network of partnerships. The company closed its Palo Alto school and shelved plans to open more of its own schools in favor of providing its platform to more partners. It also ditched the idea of collecting data from classroom cameras. “That was an idea that unfortunately did not validate,” Vodicka says.

Today, 20 charter and private schools, along with five California school districts, are using AltSchool’s technology and receiving training and support. In his visits to partner schools that are using AltSchool’s technology, he says, “I’m seeing learners that are energized and inspired, that are highly collaborative. I’m encouraged by that.”

An AltSchool spokeswoman said its teacher-retention rate is 90 percent. In the summer of 2017, though, France quit AltSchool and returned to Chicago. He spent the past year  teaching at a traditional private school that’s been around for a century and, in his view, sees the “value in using a plain old notebook and pencil to engage in the writing process.” He still uses technology when it’s appropriate. His class last year did a project on Chicago neighborhoods and visited many. Since they couldn’t get to all of them, they used Google Earth to virtually walk through several. “I’m not anti-technology but I’m definitely for minimizing it,” France says. “You use technology to remove a barrier. And the question always should be: Is the tech in my classroom going to preserve or enhance human connection?”



Year after year, the admissions process at selective colleges seems to make high-schoolers and their parents only more anxious. The numbers are wild: Harvard admitted just 4.6 percent of its nearly 43,000 applicants for the class that begins this fall. Stanford accepted only 4.29 percent, and Princeton 5.5 percent. Although selective schools—those that accept fewer than half of applicants—enroll only about one-fifth of U.S. undergraduates, they account for more than one-third of applications each year.

Plenty of ideas to fix the system—to make it more bearable for students, parents, and even colleges themselves—have been floated in recent years, including restructuring the whole process to be a somewhat randomized lottery, or implementing a matching system akin to how medical-school graduates are placed in residencies. They are promising, but they have something problematic in common: In all likelihood, they’d be illegal.

That’s because, like nearly every other American company and organization, colleges and universities are subject to antitrust law, meaning they are bound to compete with one another in a way the government deems fair. Such antitrust provisions are vital—they are what stop, say, automakers from raising the price of cars in unison—but in the case of higher education, it might turn out that antitrust law stands in the way of making college admissions, as well as the linked and similarly fraught process for divvying out financial aid, fairer and less harrowing for all involved.

Take, for example, the idea of a national clearinghouse or a matching system, similar to the one for medical-residency programs. With a national clearinghouse, students could upload their academic records and accomplishments during their high-school career and then in their senior year simply press a button to apply to colleges. The database would be open to admissions officers at all colleges, so they could see where else students are applying, bringing a level of openness to the process. Under a matching system, students and colleges would each submit rank-order lists of each other and be paired as closely as possible.

Those who follow admissions closely tend to think that such a system would ease the pressures on students, parents, and schools. But, alas, antitrust law prohibits it—it would produce a level of cooperation that the federal government would likely find unacceptable. (The medical-residency match program is legal because Congress granted it an antitrust exemption about 15 years ago.)

Other promising college-admissions fixes that have been proposed run up against some of the same problems. One feature of the shared application designed by an advocacy group called the Coalition for Access, Affordability, and Success is a virtual “locker,” which is already being tested by more than 130 prestigious schools. It allows students as early as ninth grade to upload their written work, videos, photos, and other materials that show off their potential beyond a transcript. At first, only students can access the locker, but over time they can open it to their parents, counselors, and to colleges through the admissions process. While the virtual locker doesn’t have the transparency of a clearinghouse, it too might raise antitrust concerns one day, depending on how colleges want to share access with each other.

Another idea that has been floated is to have admissions to selective colleges determined by a lottery. The names of qualified students would be picked at random until a class is filled. “A strict lottery system for academically qualified applicants would be the most equitable, least costly, and most publicly explainable method of dealing with the ever-growing demand for scarce seats at our most selective institutions,” said Barmak Nassirian, the director of federal relations for the American Association of State Colleges and Universities. A lottery system would also, in all likelihood, not pass muster with the Department of Justice, which enforces antitrust law, because depending on how it was administered, it likely would require colleges to share information about applicants with each other.

Another option: Put a limit on the number of colleges to which students can apply. The proportion of college freshmen who applied to seven or more colleges reached 35 percent in 2016, up from 18 percent a decade ago, and from just 9 percent in 1990. Some eight in 10 freshmen in 2016 applied to at least three colleges. “If you limited it to, say, five, everyone would get fewer applicants,” said Catharine Bond Hill, the former president of Vassar College who now heads the nonprofit research group Ithaka S+R. This is a solution that might not be banned by antitrust provisions, as it might be able to be implemented through, say, the Common Application, rather than through the direct cooperation of colleges.

Even changes that work within the current admissions and financial-aid systems—rather than remaking them entirely—would likely run afoul of federal laws. College leaders, for instance, find themselves in a tricky position when it comes to “merit aid” scholarships that some schools give out. For instance, Grinnell College, a selective liberal-arts school in Iowa, uses merit aid as a tool for recruiting students who might otherwise turn them down—in practice, the scholarships are small discounts for wealthier students who end up paying less than full tuition.

But these scholarships serve another purpose, too: Grinnell, like other selective colleges, is trying to increase the number of low-income students on campus. This year, the college estimates 26 percent of its incoming class will be eligible for Pell Grants, which mostly go to students from families making less than $40,000 annually. But Pell Grants don’t come close to covering the cost of tuition, so to make up some of the difference, Grinnell sets aside 10 percent of its financial-aid budget for merit aid to lure students who can afford to pay a lot more.

Many of Grinnell’s higher-ranked competitors have sworn off such merit aid—on the grounds that it helps families who can already afford college—but schools right below Grinnell in the rankings offer such discounts. So Grinnell officials maintain that if they abandoned merit aid, they would also likely give up the tuition dollars of those students who would follow the money and attend lower-ranked colleges that offer discounts.

“The way to end this arms race is for institutions to spend less on merit-based aid and amenities and use that money on need-based aid,” said Hill, the former Vassar president. If such an approach were widely embraced, Hill believes it could result in greater economic diversity on campuses: There’d be more money to devote to low-income students. And affluent students wouldn’t be as tempted by money in making their college choice.

But Grinnell and other institutions that use merit aid as bait for affluent students would only stop if they knew their competitors would too. And that would require them to cooperate in ways prohibited by antitrust laws. “One effect of antitrust laws is that colleges in a weaker market position pursue strategies to generate revenue but that ultimately drive up prices across the board,” said Joseph Bagnoli Jr., the vice president for enrollment and dean of admission and financial aid at Grinnell College in Iowa. Those “strategies” he’s referring to are things like merit aid, or spending on amenities that competitors have on their campus, such as new dormitories and recreation centers. These amenities tend to siphon away money that could theoretically be put toward financial aid instead.

There is, as well, a subtler, more philosophical argument for exempting colleges from antitrust law. “If universities are getting federal funds, they shouldn’t be allowed to shroud in secrecy the process for determining who gets admitted,” said Jon Boeckenstedt, the associate vice president for enrollment management and marketing at DePaul University, in Chicago.

Antitrust law exists to protect consumers—in the case of higher education, it’s what prevents colleges from colluding on setting tuition costs. But, beyond Major League Baseball, few entities in the United States operate with the kind of freedoms from antitrust laws that higher education would need to truly reform the admissions and financial-aid process.

Recently, the association in Washington, D.C., that represents private colleges requested a five-year exemption from antitrust laws for its member schools. Its reasoning goes that if schools were allowed to cooperate, they could build new tuition pricing models together. They could also share information on applicants they have in common and the financial-aid packages they’re offering them, which might end, or at least slow, the arms race of trying to provide more money than a competitor to every student regardless of need. A sense of reasonableness might return to the admissions process and at the same time slow the rapid rise of college tuition.

The Justice Department does not appear interested in granting this request. Instead, the department has for years been bringing more scrutiny to colleges’ practices, rather than becoming more permissive. Inside Higher Ed reported earlier this month on a federal investigation of colleges—this one related to the practices of early-decision admissions—and it was the latest of several. The Justice Department in 2017 launched an inquiry into alleged discrimination against high-achieving Asian American college applicants, as well as an antitrust probe of the ethics code of the trade association that represents high-school counselors and college-admissions deans.

An earlier incident, in 2013, presaged this. In January of that year, presidents of several hundred small, private colleges gathered for the Council of Independent Colleges annual winter meeting in Palm Harbor, Florida. Among the sessions was one on how schools should end bidding wars for students and curtail the use of generous merit-aid packages.

The discussion caught the attention of the U.S. Justice Department. Five months later, lawyers for the department wrote a letter to a handful of college presidents who were at the meeting, warning them that agreements to “restrict tuition discounting” might violate antitrust laws and instructed them to preserve information related to the session. (That investigation is now closed.)

The inquiry that was first reported on this month pertains to early decision, an arrangement under which applicants commit to attending a school if accepted and agree not to apply via regular decision elsewhere. The percentage of the incoming class accepted through early decision at selective colleges has risen rapidly in the last decade now accounts for about half the class on some campuses.

Colleges are leaning more on early decision for two reasons. One, as more students apply, colleges have a difficult time predicting how many of them will actually show up. Early decision reduces that uncertainty. Second, students who apply early decision clearly want to enroll, and they often come from higher-income families. As a result, they demand less financial assistance, and that gives colleges the financial security to spend a bit more freely on the much larger pool of applicants in the regular-admissions round.

Some schools share information like this because they want to make certain their early admits are not in admissions pools elsewhere. The Justice Department, as part of its latest inquiry, wants to know if schools make admissions decisions based on what other schools have done with an applicant.

Colleges and universities have been at this crisis point before. Until the 1990s, the Ivy League colleges and the Massachusetts Institute of Technology set financial-aid awards jointly, so students could choose colleges based on factors other than cost. The practice, however, ended after the Justice Department accused the participating schools of price-fixing. College admissions have changed drastically in the intervening years, but the department’s thinking on the subject has—probably for the worse—remained the same.



Donald Trump has a habit of taking to Twitter first thing in the morning. So when he fired off a slew of tweets early one late-October morning, it wasn’t much of a surprise. “In Florida there is a choice between a Harvard/Yale educated man,” Ron DeSantis, he wrote, before vilifying DeSantis’s opponent, Andrew Gillum, who is vying to become the state’s first black governor, and just the fifth black governor in U.S. history.

Trump’s tweet was an example of the time-honored tradition of equating an Ivy League degree with a person’s bona fides for a position. But Gillum had a reminder for the president. “I am a graduate of THE Florida Agricultural & Mechanical University (FAMU),” he responded the next day on Twitter. “An HBCU founded on October 3, 1887. Google it.”

The exchange was interesting not least because the Trump administration has made a show of courting historically black colleges and universities, or HBCUs. And despite a number of public missteps, it has consistently pointed to its work with black colleges as one of its “wins” with the black community. These institutions, which were founded primarily after Reconstruction to educate black Americans who had been shut out of the rest of higher education, have had their fair share of struggles over the past few decades—budget woes, enrollment dips, and accreditation concerns among them. But they have seen a renaissance, of attention and enrollment, in the Trump era.

Another, perhaps unforeseen renaissance, however, has been the rise of black politicians who graduated from these colleges. In addition to Gillum, Stacey Abrams, a gubernatorial candidate in Georgia, and Mandela Barnes, a candidate for lieutenant governor in Wisconsin, both attended historically black colleges. The prospect of so many black-college graduates being elected to statewide office in the same year is unprecedented, Keneshia Grant, an assistant professor of political science at Howard University, told me.

Now, of course, there are HBCU alums across all levels of government. Senator Kamala Harris graduated from Howard University, and the mayors of Atlanta, New Orleans, and Birmingham—all of whom were elected in 2017—also attended HBCUs. And there have previously been governors who attended black colleges: In 1989, Douglas Wilder became the governor of Virginia and the first elected black governor in the United States. In the 1870s, there was P. B. S. Pinchback, who very briefly served as the governor of Louisiana. These candidates—Abrams, Gillum, and Barnes—are continuing that black political tradition.

However, just as the sheer number of these candidates is different, so too is the energy behind them, particularly for Abrams and Gillum, says Grant—and it’s making them more popular with students at HBCUs. The politicians are vocal in boosting black colleges. They’re celebrities at homecoming. And they’re unyielding in their clap backs during debates.

“It changes the students’ engagement with the materials for the [candidates] to look like them and quote Migos. If you show a clip of a person who is a legitimate candidate who is good on policy and can talk about ‘walking it like he talks it,’” alluding to the viral clip of Gillum that references the lyric from the rap group Migos, “it just takes the lesson [in class] to another level.”

Abrams, Gillum, and Barnes are sending a message, says Walter Kimbrough, the president of Dillard University, an HBCU in New Orleans. “It’s a reaffirmation, not only for students but for families, that you can go to an HBCU and compete with anyone.” Kimbrough told me it’s important not only that the candidates attended a historically black college, but also that they’ve embraced it as a fundamental part of their identity.

And the candidates are taking up the mantle of defending black colleges as important institutions, he says. For instance, when Representative Cedric Richmond criticized Senator Bernie Sanders’s education plan for not mentioning HBCUs, Abrams tweeted her agreement: “HBCUs are vital for economic independence,” she wrote. And the institutions, which have struggled across sectors, both public and private, could use the boost.

While it’s unclear whether these black politicians will pull out victories tomorrow, their candidacies could still prove important for HBCUs. “I always tell people you can go wherever you want to go,” says Kimbrough. “We want people to go where there’s a good fit. But don’t just assume because the person went to an HBCU that they aren’t as good.”



Teachers’ strikes have been a constant across the country in 2018, popping up in six states, from West Virginia to Oklahoma. But so far, the wave of activism has been limited to educators at traditional public schools. That is, until earlier this week, when unionized teachers from one of Chicago’s largest charter-school networks, Acero Schools, took to the picket line. The strike is the first of its kind in U.S. history; although other charter-school teachers have unionized—collective bargaining is a requirement for charters in Hawaii and Maryland—these teachers are the first in the country to actually stage a walkout.

Teachers from all 15 Acero schools—which range from elementary to high school—resorted to a strike after failing to arrive at an agreement with Acero on Monday night over the terms of a new contract, in which they had requested higher salaries and smaller class sizes.

[Read: The teachers’ movement goes virtual.]

While teachers’ unions such as the American Federation of Teachers (AFT) had been gearing up for a possible strike for weeks, this decision to walk out is unprecedented: For decades, charter schools have championed themselves as a radical experiment in education that eschews the constraints of unions and traditional-public-school bureaucracy in favor of the flexibility to innovate. Now, at least in Chicago, the mentality seems to be shifting—and charter-school advocates fear it’s a sign that teachers’ unions, in a desperate effort to retain their clout, are co-opting charters for their own political reasons. Concurrently, the head of Chicago Public Schools, Janice Jackson, recommended on Monday that the city stop accepting proposals for new charter schools, a moratorium also supported by J. B. Pritzker, the governor-elect of Illinois.

“Ten years ago, that would have been a pretty unimaginable stance to be taken in this city,” says Elizabeth Todd-Breland, a historian at the University of Illinois at Chicago who studies education reform in the city. However, as a close watcher of Chicago charter schools, she long considered a strike like this to be “inevitable.” For several years, charter-school teachers have been joining the Chicago Alliance of Charter Teachers and Staff union, which recently merged with the Chicago Teachers Union (CTU)—an organization that is affiliated with the AFT and has historically opposed including charter-school teachers, Todd-Breland says. “I think after a number of conversations [among charter-school and traditional-public-school teachers’ unions], they came to the conclusion that they had common concerns as teachers,” she says, “and they had common concerns for students that made it make sense for them to come together.”

It’s impossible to separate all of this from the broader landscape of public education in Chicago. According to a recent analysis by the public-radio station WBEZ, around 200 public schools have been “radically shaken up” or closed altogether since 2002. The majority of the 70,000 affected students are black, while a substantial number are Latino. The majority-Latino population of Acero’s schools, then, is noteworthy—these students and families are, as WBEZ has put it, part of “the school-closing generation.” And teachers now on strike have highlighted the specific vulnerabilities of these students, with union negotiators citing the need for Acero to take the official position that the schools are “sanctuary schools,” for example.

Animosity has long existed between charter schools and teachers’ unions—even though the man who conceived of the idea of charter schools in the late 1980s was Al Shanker, AFT’s then-president. Such schools were envisioned, says Randi Weingarten, AFT’s current president, as “being an incubator of ideas” while still being “accountable, transparent, and [committed to] the mission of equity.” But it wasn’t long before Shanker and other labor leaders abandoned the idea, spurning the model as too beholden to the privately managed companies seeking to run the schools.

That antagonism has only intensified in the months since President Donald Trump tapped Betsy DeVos—a billionaire who has long advocated for charter schools—to be the country’s education secretary. The partisan divide in public opinion on charters and so-called school choice has subsequently widened. According to a 2018 poll conducted by Education Next, 44 percent of Americans support charter schools, a 5 percent increase from the previous year that was driven mostly by a boost in support among Republicans.

This heightened partisan tug-of-war over charter schools can in part be attributed to the idea that their role as so-called innovation laboratories is predicated on them being free from the constraints imposed by collective bargaining. And that’s a major reason this strike is historic: It’s the most conspicuous sign to date that teachers’ unions are succeeding at recruiting charter educators to the world of collective bargaining. “This certainly debunks a lot of myths,” Weingarten says. “Charter-school teachers are starting to recognize more and more that they need the union as a vehicle to create the power to have, at the very least, conversations” about pay and conditions

But Andrew Broy, the president of the Illinois Network of Charter Schools, argues that the strike is less of a myth buster and more of an underhanded ploy by the CTU to advance its own political interests at a time when teachers’ unions are scrambling to reorient their lobbying tactics and public relations.

“This was a long time coming,” Broy says, describing CTU’s efforts to recruit charter-school teachers as an “aggressive movement” that traces back six or so years. This endeavor, he argues, was a “political calculation” to limit the power of charters in the city, as the number of Chicago families sending their children to a neighborhood public school has declined in recent years, by subjecting charter schools to the same restrictive labor contract under which their public-school counterparts operate. In turn, this could undermine the competitive advantage of charter schools as unique educational entities with their own rules. “You can’t have that robust array of options if you just have a single contract,” Broy says.

But there’s another reason CTU likely ticked its organizing up a notch earlier this year, and it has to do with the U.S. Supreme Court’s ruling in Janus v. American Federation of State, County, and Municipal Employees Council 31, which declared that the First Amendment prohibits labor unions from collecting membership dues from nonmembers. The ruling has, and will continue to have, major implications for teachers’ unions, says Martin West, a Harvard professor of education who studies charter schools and teachers’ unions. Hamstrung by their inability to rely on dues from nonmembers, West says, unions are “doing everything they can to organize as many members as possible”—fervently touting the benefits of union representation, for example, and marketing collective bargaining’s goals as focused on broader educational goals. So while the relationship may be strange, that traditional teachers’ unions and charter-school educators are becoming bedfellows is “hardly surprising,” West says.

It’s tempting to lump the charter-school strike in Chicago together with the recent spate of teacher walkouts across the country. And while there certainly are parallels, West cites the target of the charter-school teachers’ strike—Acero, a private organization—as the key distinction. The teachers who had been on strike earlier this year directed their demands at the government because the onus was on state politicians to pass legislation aimed at increasing school funding and improving their work conditions. Citing his own recent polling data, West says the notable increases in support for teacher pay and strikes are evidence that the teachers won in the court of public opinion; other surveys demonstrate similar shifts. But organizations like Acero are funded by the government, which in a sense means that they, too, “are the victim of a funding system,” West says. By striking against Acero, charter-school teachers are focusing on how the organization distributes the governmental funding it receives.

For Weingarten, such differences are secondary to the shared aspirations of teachers, whatever their school type. “As charters go from infancy to adolescence, those who want to succeed for the long haul have to have a stable, vibrant teaching force,” she says. “And that stable, vibrant teaching force wants a voice and agency.”

Regardless, experts predict that the Chicago development is a harbinger for more collective-bargaining alliances between charter-school and traditional-public-school teachers across the country. And similarly highlighting the distinction between the Acero strike and the statewide walkouts elsewhere in the country that kicked off in the spring, Broy points to politics. The strikes earlier this year took place in red-leaning states, most of which have long been skeptical of unions. It’s a different story in places like Chicago, where there’s broad public support for such organizing. And it’s in similarly big, left-leaning cities where Broy expects future developments like this one to surface.



After 20 years of telling it, the story of the day you survived a school shooting can get a little rote, admits Renee Oakley, 35. She and her husband, Ben, 36, both lived through the shooting at Columbine High School on April 20, 1999.

“I’ve always been able to tell it as though I’m reading a story to somebody,” Renee told me over a car Bluetooth speaker as she drove through Seattle with Ben, who agreed: “It feels automated” for him, too, he says.

In some ways, that’s probably for the best. Both Ben and Renee have shared their story many times over the years, sometimes in public forums, and having a succinct, memorized script can help when you’re reliving a tragedy in front of an audience. But for Renee, the script fell by the wayside when her audience consisted of one particular person: her daughter, Emma.

One afternoon before Renee married Ben, Emma came home and announced that she’d had a lockdown during the day at school. Emma was 7 at the time, and Renee, who lives with what she described as severe PTSD, said she had a small panic attack. She immediately called the school: “I was like, ‘What the hell happened?’” It was a drill, the school reassured her; the students had just been practicing for an active-shooter situation. And that’s when Renee decided it was time to talk to Emma about Columbine.

Survivors of the Columbine High School shooting are in their mid-30s today, old enough to have children of their own who now participate in lockdown drills and campus-safety trainings. The ones who have become parents face an awful new reality: Twenty years later, they are being confronted with the idea that what happened to them could also happen to their children—a notion that some Columbine survivors fear intensely and that others reject almost entirely. As their children grow up, these parents are navigating how to talk to them about the day their high-school memories were corrupted by gun violence.

When Renee first told Emma about Columbine, Emma had a number of follow-up questions. Who had died? Was Renee sad that the killers, her classmates, had taken their own lives? “I was okay until she started asking more in-depth questions,” Renee remembered. “She found out about our friend Matt [Kechter], who died, and she asked me if I ever go to his grave. She asked me [if we could] go to it.” Renee lived in Colorado at the time, about 10 minutes from where Kechter was buried. She and Emma ended up visiting the grave site almost monthly for the next year.

Renee appreciated that Emma—an “old soul”—wanted to be part of memorializing her mother’s friend. Soon, though, Emma began to have trouble focusing on her classwork while at school. Instead, she was paying attention to who was roaming the hallways, and what activity was taking place just outside her classroom.

“I essentially put the fear of God in her that she had to be ready, she had to be prepared that anything could happen,” Renee said. “That was my fault. I put my PTSD, and my fears, and my troubles, on her.”

But then came Ben, who Renee said brought balance into their lives.

The Oakleys, who own a business that performs medical exams on life-insurance applicants, have been married since 2016. After they graduated from Columbine, the two lost touch, but they reconnected in 2015 when, in the span of a few months, they each lost a parent to cancer. Ben adopted Emma in 2018.

Ben and Renee are, by their own description, complete opposites when it comes to how they handle the topic of school shootings with their daughter. Renee believes that there’s a direct line between her having survived the Columbine shooting and her becoming an especially protective parent, but Ben makes a point of not worrying about Emma’s safety at school. Renee describes Ben as the non-“helicopter” parent, the one who lets Emma jump on the trampoline without worrying that she’ll get hurt.

“When I wake up in the morning, I don’t fear my kid going to school,” Ben said. Campus shootings are so statistically rare that he feels becoming distressed over them—or trying to prepare for them—is often unnecessary. Of course, he added after a moment, “I’m not going to be ignorant, because I lived through it. But I’m not going to create a culture of fear around my kid, [or raise her to believe] that you have to be afraid on every corner.”

Kim Peyrouse, 36, lives across the street from Columbine, the high school she attended in 1999, and works as a doula. She says she’s forever proud to be a Columbine Rebel, as the school’s students are known, and to raise her three kids in Littleton, Colorado. But when her oldest, now 9, came home from school a few years back and said that the school had had a lockdown drill—that the teacher had handed the kids Dum Dums and told them they were practicing hiding quietly in case “a bear” got inside the school—Peyrouse felt a lot of feelings at once. She was terrified, angry, and—her voice breaks a little saying it—sad. “It just brings back such memories,” she says, “and it just makes me sad that that’s their reality.” She’s grateful that they have those drills at school; she’s glad plans are in place in case the thing no one wants to see happen again happens again. The last thing you want in an active-shooter situation, Peyrouse knows from experience, is chaos. And yet.

“My daughter came home from school one day this year and she said, ‘Mommy, if I’m in the bathroom and there’s a [person with] a gun or something, I’m going to put my legs up on the [toilet] and lock the door so they don’t see me,’” Peyrouse says. “I was like, ‘I’m so sorry that you have to even think about that.’”

Healing after trauma can be a long—sometimes lifelong—and nonlinear process. While some see grief and stress dissipate gradually and become manageable, others have those feelings abate and then intensify, abate and then intensify, again and again, over time. And raising kids while you recover from trauma yourself can be unspeakably hard, says Suzannah Creech, who researches how trauma can affect families for the University of Texas’s Dell Medical School and for the Department of Veterans Affairs’ Center of Excellence for Research on Returning War Veterans.

On days when certain events might trigger unwanted memories or difficult emotions for survivors of trauma, “if at all possible, [they should] take some extra care. Can they take a little time off? Can they schedule an extra therapy session? Anything that might help put them in a good place,” Creech says, “especially if they’re responsible for a little one. Because that’s so much more added stress.” Communicating to kids that “Mom is feeling sad,” or that “Daddy feels anxious,” or that “Dad’s going to take some time for himself today,” she adds, can also help kids learn to label their own emotions and better regulate them.

And when parents have PTSD symptoms or symptoms of another mental-health disorder, Creech says, they should tell children what the symptoms are. “Children can make assumptions,” she says. “That it’s about [them] or that they did something wrong, when often it’s more like, Mom or Dad is having a lot of anxiety today because it’s around the anniversary of something that happened. Or, Mom didn’t sleep well last night. Things like that to sort of let them know what they’re dealing with—that it’s not about the child.”

Frank DeAngelis, the former principal of Columbine High School, vowed in 1999 to serve as principal until every student in the Columbine system at the time of the shooting graduated, and then he stayed on for two more years after that. He retired in 2014, but over the past few years, he’s talked to multiple Columbine survivors about the new challenges presented by becoming parents.

In his book, They Call Me Mr. De, DeAngelis describes hearing from one former student (“one of my kids,” as he still calls them) that she found herself seized with panic upon dropping her daughter off on the first day of kindergarten. In an interview, DeAngelis told me that several former students he has spoken with feel like they’ll always be wondering if their children will one day have to experience the same thing they experienced at Columbine. He also said that when another survivor, who had been shot at Columbine, asked for his advice about how and when to tell his 8-year-old about what had happened to him, DeAngelis recommended having that conversation before she was old enough to hear stories about—or see footage of—the massacre elsewhere.

DeAngelis acknowledged that he himself will likely have to have a conversation like this someday soon: His granddaughter, whose pictures he stores on his iPhone and shows off unsolicited, is 5, and he suspects that it won’t be long before she asks why her Papa’s picture is on a book. He said he’ll likely seek the advice of a child psychologist before he tells her the story, because “it’s all in how you explain it.” He wondered aloud how Holocaust survivors and 9/11 survivors have talked to their children and grandchildren about what they saw.

Sharing the story of a disaster or an act of mass violence with children is never easy, and experts recommend talking about it in what Creech calls a “bird’s-eye view” kind of way: just the who, what, when, and where, without the details about what it sounded like or smelled like or looked like. “For trauma survivors, it’s often the sensory details that are the most on their minds on a regular basis, particularly if they have PTSD,” Creech says. “But those are details that we find loved ones really don’t need to know.”

Like the “children’s version” of 9/11 or the “children’s version” of the Holocaust, the children’s version of what happened at Columbine can be a ghastly thing to try to imagine, but the survivors of Columbine have been thinking about it for years. While almost every survivor I spoke with for this story mentioned wanting to protect the kids in their lives from the truth about what happened at their high school (at least while they were little), those who hadn’t told the story yet were, like DeAngelis, already thinking about how they would go about doing so.

Crystal Woodman Miller was 16 when she survived the Columbine shooting, and seven years later, she published Marked for Life, a book about the healing process that took place afterward. For a few years, she traveled frequently, speaking to audiences about her experience. Today she’s raising three children in the same area where she grew up, about a 15-minute drive from Columbine. She recently came across her oldest child, a 7-year-old, reading Marked for Life.

“I came over and I said, ‘Baby, I’m really sad. I would love to share this with you, and Mommy will, but it’s just a little too soon.’ And she said, ‘Why, Mom? I really want to read it. This is the book you wrote,’” Woodman Miller recalls. “I said, ‘I know. But there’s some stuff in here that could be very scary for you right now. I’m just not ready to share that with you.’” Woodman Miller’s daughter handed the book back to her.

Woodman Miller isn’t sure when, exactly, she will be ready. Her daughter has done lockdown drills in preschool, kindergarten, and first grade, but Woodman Miller doesn’t know when she’ll talk to her about Columbine. She knows what she wants to say when the moment arrives, though. “I’ll have to choose my words very carefully,” she says, “and I’ll have to make sure that the whole thing, the whole conversation, is surrounded in assurance. Well, baby, this is something that happened to Mommy, but you are safe. There’s a lot of things that have changed. Your school’s very safe.”

Kim Peyrouse only recently explained to her children what happened, and she gave them just the most basic version. But first, she told them what the “bear” really was.

“We just sat our kids down and were like, ‘A bear? Can you ever imagine a bear ever coming into your school? We live in Littleton. That’s probably not going to happen. But what they are referring to is some tricky person’—and we always say ‘tricky person’ because it could be a girl, or a boy, or a grandma, or a grandpa, or, you know, it could be anybody,” Peyrouse says. “So we just say someone who is tricky and that wants to bring harm to others. Basically, that’s what the bear is.”

“Our kids are old enough now that they know, like, Mommy went to Columbine and that’s where two of her friends—” Peyrouse stops. “Well, you know, not friends. But Mommy’s classmates came in and made a really bad decision. They shot a lot of Mommy’s friends and a coach, and they died.” For now, she says, that’s the extent of it.

Andy McDonald, 37, doesn’t live in Colorado anymore; 12 years ago, he and his wife moved to New Hampshire, where he now teaches social studies at the school two of his three young daughters attend. For him, the fact that his daughters have lockdown drills at school isn’t terribly alarming; as a teacher, he’s been doing them longer than they have. Still, it’s “bizarre” to think about, he says. What he witnessed when he was 17 was supposed to be an anomaly.

In February, McDonald and his wife traveled with their daughters to Denver, and McDonald took his oldest, a fourth grader, to Columbine.

“It was kind of a snap decision—I was like, Wow, we’re actually right here,” McDonald remembers. “I looked at my wife and I was like, ‘You know what, I’m going to take [her] up.’” He had actually meant to wait another year, but then there they were, and this is how he’d always wanted to do it. So McDonald and his daughter walked to the Columbine Memorial, a short distance from the high school.

“This is where Dad went to high school,” McDonald remembers saying. He can’t recall perfectly what he said next, but he thinks it went something like “There were students who died here. They were killed by other students.”

McDonald wanted his daughter to know what had happened to him, but he didn’t want to instill fear in her about going to school. “I told her, at the end of the day, this isn’t normal,” he says. “This doesn’t happen most places.” And then he let his daughter take it from there. “I tried to approach it as, if she has the question, I want her to ask it. But I also didn’t necessarily want to volunteer too much, ’cause she’s still 10,” McDonald says. “So we’re of the mind-set that if you are mature enough to come up with a question, then it deserves an answer.”

McDonald’s daughter did have questions. She asked about Rachel Scott, who had been McDonald’s friend and homecoming date that year, and who was killed in the shooting. She knew that her dad had done presentations in schools with a violence-prevention group called Rachel’s Challenge, and she recognized Scott’s name when she saw it listed on the memorial. “She asked if I knew the boys that did it. I said I did not, and I explained how big the school was compared to [the school] where she’s at,” he says.

“That was really about it,” McDonald continues. “Honestly, a lot of it was very quiet.” After a while, they left and picked up the rest of the family.

McDonald left Columbine that day feeling like he’d made the right choice. Today, though, he wonders whether the visit to Columbine will ultimately mean more to him than it will to his daughter. “I don’t know how much of that day she’ll remember, in the grand scheme of things. But for me,” he says, “that was a big thing. It might’ve been just one of those things that I built up in my mind. I guess we’ll see.”

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

At least 2,000 children have now been forcibly separated from their parents by the United States government. Their stories are wrenching. Antar Davidson, a former youth-care worker at an Arizona shelter, described to the Los Angeles Times children “huddled together, tears streaming down their faces,” because they believed that their parents were dead. Natalia Cornelio, an attorney with the Texas Human Rights Project, told CNN about a Honduran mother whose child had been ripped away from her while she was breastfeeding. “Inside an old warehouse in South Texas, hundreds of children wait in a series of cages created by metal fencing,” the Associated Press reported. “One cage had 20 children inside.”

About 65 million years ago, shortly after the time of the dinosaurs, a new critter popped up on the evolutionary scene. This “scampering animal,” as researchers described it, was likely small, ate bugs, and had a furry tail. It looked, according to artistic renderings, like an especially aggressive New York City rat. And it had a placenta, an organ that grows deep into the maternal body in order to nourish the fetus during pregnancy.

The rodentlike thing would become the common ancestor of the world’s placental mammals, with descendants that include whales, bats, dogs, and humans, among many other species. And today, the placenta might hold the key to one of the most enduring mysteries in human medicine: Why do women suffer much higher rates of autoimmune disease than men do?

Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.

There’s a moment about 15 minutes into the first episode of Years and Years that made me gasp at its audacity, its prescience, its visual horror. The new six-part series from the British writer Russell T. Davies (Doctor Who, A Very English Scandal) charts the life of the Lyons family over the course of 15 years, starting in 2019 and ending in 2034. It’s a kitchen-sink saga that barrels its way through births and marriages and betrayals, but also through the near-future. In 2024, Stephen Lyons (played by Rory Kinnear), a financial adviser, is at home with his wife, Celeste (T’nia Miller), both rushing their way through the morning routine. When the camera turns to their teenage daughter Bethany (Lydia West), her face isn’t recognizably human. Instead, she looks like a 3-D version of a Snapchat puppy, with vast cartoon eyes, wagging pink ears, and a brown snout. When she talks, her voice is grotesquely distorted, a robotic hallucination of a child’s cadence. “I might have to start limiting filter time,” Celeste says in the same exasperated, noncommittal way that you might think, I really should spend less time on Twitter.



Greg Lukianoff was preoccupied with political polarization—not just the divisiveness he observed, but the fallout—and specifically the effects of tribalism on college campuses. The year was 2015.

“It is a very serious problem for any democracy,” he and his co-author Jonathan Haidt wrote in a cover story for The Atlantic that year. “As each side increasingly demonizes the other, compromise becomes more difficult … So it’s not hard to imagine why students arriving on campus today might be more desirous of protection and more hostile toward ideological opponents than in generations past.”

In that story, “The Coddling of the American Mind,” Lukianoff, a First Amendment lawyer and the president of the Foundation for Individual Rights in Education (FIRE), and Haidt, a social psychologist at New York University, observed that “in the name of emotional well-being, college students are increasingly demanding protection from words and ideas they don’t like,” and argued that capitulating to requests to banish certain ideas from classrooms and campus events would likely increase student anxiety and depression, rather than ameliorate it.

Three years later, political polarization has only increased, as has anxiety among young people. And unrest on college campuses continues. “Everything’s speeding up,” Lukianoff says. Haidt and Lukianoff recently published a book, also titled The Coddling of the American Mind, where they go into more detail about the three “Great Untruths” they believe are behind free-speech controversies at America’s universities:

I spoke to Lukianoff about what’s changed since the publication of his Atlantic cover story, how parenting contributes to students’ expectations for their education, and the increasingly blurred lines between engaging with ideas and endorsing them. An edited and condensed transcript of our conversation is below.

Julie Beck: When you first published “The Coddling of the American Mind” as a magazine piece, did you get different reactions from students, from professors, and from the lay public not currently enrolled or working at universities?

Greg Lukianoff: Definitely. Since we were talking about topics that are very dearly held by some students, trigger warnings in particular. Trigger warnings produced the strongest reaction in the entire article. We were kind of expecting a reaction more like what I’ve seen on campus, some amount of “very interesting,” and a very large backlash.

Instead what we got, to our surprise and delight, was mostly a really good conversation. There were definitely people who disagreed with us, there’s always name-calling, but overall it was actually a really good discussion. We only really noticed the discussion starting to change around the protests in late 2015, which began after the article came out.

The protests were usually on racial-justice issues. One of the ones that got the most attention was at the University of Missouri. The first we noticed at FIRE was at Wesleyan. That was a case in which a student wrote an article that was critical of some of the tactics and positions of Black Lives Matter. And that led to demands that the newspaper, the Wesleyan Argus, stop receiving funding. Those protests, for those of us who defend free speech for a living, were a mixed bag. On the one hand we were like, this is great, students are overcoming their reputation for apathy, they’re getting out there and protesting for ideas they believe in. But at the same time, a lot of times they were calling for administrators and professors to be fired for what they said, in some cases for very clearly protected speech. That puts the free-speech defender in a little bit of a difficult situation.

Beck: In the three years since the article, how have you seen free-speech issues on campus evolve?

Lukianoff: I’d say everything’s speeding up. I usually describe my career as a bunch of trends. The first trend is, from about 2001 to 2011, the main thing we were fighting and trying to push back against was administrative censorship. I say over and over again, the students were always the best constituency for free speech. After 2011, and reaching a peak around 2013, the Department of Education started giving guidance that was really vague and broad. They stated that harassment happens any time you experience unwelcome speech of a sexual nature. In the case of that 2013 blueprint, they took out the requirement that it be something that a reasonable person would find offensive. Phase three was when we started noticing the trends that led me to talk to Jon Haidt—a sudden, seemingly overnight rise in what I call student illiberalism. And that was a real shock to us at FIRE. We like defending students. But if what you’re trying to do is shout down a speaker or prevent someone you disagree with from even coming to your campus, that’s not compatible with what higher education is supposed to be like. We wrote the article in 2015 partially in response to that.

In the second half of 2015, you started seeing the big campus protests. Then you have two additional phases after that. One is the first time I’ve ever seen violence on a campus in response to a speaker, at least in my career. That was the riots a couple weeks after the inauguration in Berkeley, where Milo Yiannopoulos had been scheduled to speak. That was unlike anything I’d seen.

The most recent phase we’ve seen on campus is more liberal professors getting in trouble for what they say, sometimes in class, sometimes online. It’s not as if we’d never seen cases like this; it’s just that it sped up a lot in the past year or two. One of the big cases that is still unresolved is Lisa Durden. She was a professor at a school in New Jersey; she went on Fox News to defend a decision by a club to have a Black Lives Matter party that was African American–only. She went on Tucker Carlson [Tonight] to argue with him about whether they should be allowed to have it. And in response the school fired Lisa Durden. Professors being disciplined is one thing. But a professor getting fired is a case that should get everybody paying attention. The echo chamber on one side of the spectrum is crashing into the echo chamber on the other side. And what it’s producing is pretty ugly.

Beck: In the book, you list several different cultural forces that have moved university culture in this more cautious direction. One of those, as you write in the intro to the book, is that this shift is really more a result of adults’ attitudes and behaviors than that of students. How do you think changes in parenting culture play into students’ eventual attitudes toward their education?

Lukianoff: The first and most important change to me is one that few people have a great deal of control over. That’s simply where we all decided to move. I was very affected by some of the insight in the book The Big Sort, about how we’re increasingly moving to like-minded counties. We’re actually literally grouping together in tight communities that are more politically homogeneous. Add to that social media, which pats you on the back for creating a particularly efficient echo chamber. So some of these trends are much bigger than the parents themselves.

Part of the problem is the unforeseen result of helicopter parenting. If you schedule your children from 6 a.m. to when they go to bed, yes, it can make a perfect heat-seeking missile directed right at Harvard or Stanford, but it can undermine students’ sense of autonomy. It can undermine their sense of competence. And that's unfortunately a really effective formula for anxious and depressed kids. And the more anxious campuses become, the harder it is to actually sustain tolerance for outsiders and dialogue.

Beck: In both the magazine article and the book, you write that the sorts of thinking getting promoted on campuses would lead to anxiety and depression, and I feel like I sometimes see anxiety used as a reason to request some accommodations in the classroom, whether that’s content warnings or kids requesting not to do in-class presentations for anxiety reasons. I’m interested to know what accommodations, if any, you think are reasonable in the classroom for someone with clinical anxiety.

Lukianoff: It’s kind of funny because contrary to the stereotypes people have of the argument we were making, I actually think we’re not taking the mental-health issues seriously enough. If you really mean someone’s going to have a medical event in a classroom due to PTSD, you’re not doing enough for them if you’re going to have a content warning. You need to take your mental-health situation much more seriously than that. The one study that's been done about content warnings is not conclusive, but it showed that they increased anxiety. In the name of mental health, we’ve done a number of things that make mental-health outcomes actually worse.

Beck: Another cultural force you wrote about was the fact that higher education is a very big business in America—the sticker price at several universities has surpassed $70,000. When students are paying that much for their education, do you think that empowers them to feel they should have a hand in shaping the content of what they’re paying for?

Lukianoff: In my experience, the thing that really motivates a lot of the behavior you see by administrations on campus is concern about lawsuits, and concern about federal regulation, and a lot less of “the customer is always right.” Market power only really becomes strong if the institution that you’re paying $60,000 a year to attend cannot just find another person to pay $60,000. You don’t actually have all that much market power at these highly exclusive universities. What they are afraid of is lawsuits, of getting bad reputations that really chill the big donors.

Beck: How is this business mind-set changing the role of professors and administrators at schools?

Lukianoff: I think that most of them think they’re totally fine and they can’t imagine ever getting in trouble for what they say. A sad thing is that I’ve heard this from professors, and two years later I’m working with them on a case. There are students from both the right and left who think you can and should be fired for opinions expressed, either in class, online, or in your academic papers. Professors have to be worried about not just outrage mobs, but also that when it comes to deciding between the professor’s future at the university and the outrage mob, that the university president or the administration might not have your back.

Beck: You write that disinvitations for speakers on college campuses have been on the rise since around 2009, and FIRE actually keeps a database of those incidents. What have you learned from tracking that over the years?

Lukianoff: A couple things. One, it does seem as though disinvitation efforts have increased over the years. Another is that while it has tended to be evenly split between conservative objectors coming from off campus, and students and professors on campus, it’s now leaning a lot more, unfortunately, toward liberal forces on campus wanting people to be disinvited. But probably the most interesting thing about the disinvitation database is a little more meta. Some cases absolutely do look exactly like the sort of archetypical situation of a fight of political correctness versus a professor, or student. And others look like the stereotype from the other side where it’s essentially a more liberal-leaning professor or student getting in trouble because more conservative forces want that person be in trouble. But there’s a big middle in there that gets very, very little attention because it doesn’t fit a culture-war narrative. The pattern is generally just that someone in the administration doesn’t like what you have to say, doesn’t like the student newspaper. This is as old as power itself.

Beck: So most of the cases coming into FIRE are not students advocating against a professor, or a university, to get someone fired, but more often the power structures in the university working against student speech?

Lukianoff: It depends on the year, but I’m pretty sure it’s a safe bet to say a lot of the cases we get don’t conform to most people’s stereotypes of what cases actually look like.

Beck: I feel like the “to invite or not to invite” question has been more in the news in the past couple of years than ever. There was a recent dustup over Steve Bannon being invited to the New Yorker festival and another festival put on by The Economist—The New Yorker disinvited him and The Economist didn’t. Do you think this invitation-backlash-disinvitation controversy loop is something that has leaked off of campus and into other realms of public discourse, or has this always been a broader issue outside of colleges?

Lukianoff: I’m sure festivals have always gotten cold feet about inviting speakers for one reason or another. But the blurred distinction between endorsing what someone has to say and having them come and do an interview, I think that’s something I saw mostly on campuses first, and now I’m also seeing it outside of campuses. My fellow First Amendment lawyers, of course, the first thing they said was, of course The New Yorker can invite whomever the hell they want and disinvite whomever the hell they want. They’re not bound by the First Amendment. They’re not a university. They don’t have any special obligation. While that’s legally true, I do think it shows a kind of misunderstanding of what the point of interviews are, what the point of journalism is.

The argument was, this is a man with marginal beliefs and we shouldn’t give him a platform, and that makes sense, if you’re talking about someone who’s a truly marginal figure. But I think that people were kind of in denial that they were talking about someone who was, for a while, arguably the second-most-powerful person in the White House. I think sometimes we think too much in terms of the battle for truth—the old kind of idea that free speech is all about figuring out what the objective, Platonic form of the truth is. And if you frame it that way, you’re bound to be disappointed. But if you frame it in a much humbler and simpler way, as an ongoing effort to understand the world in which you actually live, that changes the answer to the question of, should you listen to someone who’s highly influential in a movement that you may really, really dislike? Of course, if you want to know what the world actually looks like.



Smith College’s annual commencement ceremony begins like any other: Graduating seniors at the women’s liberal-arts college are called up one by one to collect their diploma from the president. Perhaps some students exchange a wink with the regalia-clad honorary-degree recipients nearby as they stride across a platform overlooking the dorms they’d for years called home; others may pause to flip their cap’s tassel while blowing a kiss to the sea of parents who have long awaited this milestone commemorating their daughter’s metamorphosis from undergraduate to alumna.

Except the moment, technically, hasn’t happened quite yet: The name, degree, and accolades printed inside each padded holder seldom belong to the woman who receives it. They very likely belong, rather, to one of her nearly 700 classmates.

So begins Smith’s more-than-a-century-old tradition, known as the Diploma Circle. Once the final name is called, the graduates proceed to a grassy area on campus where they, with the help of volunteer faculty marshals and students, convene into a handful of concentric circles. Each graduate then proceeds to pass diploma after diploma to the right, assembly-line style, exiting only when she receives the correct one.

American colleges cherish their weird commencement traditions. At Kenyon College in Gambier, Ohio, graduating seniors participate in “the sing,” singing the same songs they once performed in unison at the beginning of their college careers, repeated now in front of hundreds of their professors and family members. At Wells College in Aurora, New York, a series of early-morning fire alarms summon students to the campus’s historic sycamore tree, where underclassmen commemorate their robed, graduating counterparts by singing the “Wells Congratulations Song.” At Wellesley College outside Boston, seniors race down a paved, quarter-mile course, each rolling a thigh-high wooden hoop; the woman who finishes fastest, legend goes, will be the first to achieve happiness and success. At Wabash College, a men’s college in central Indiana, seniors leave with both a diploma made out of sheepskin and a red rose, meant to honor the graduating men’s mothers.





These traditions amount to more than just silly expressions of collective catharsis. Folkloric rituals like these throughout the college trajectory can create a sense of purpose, comfort, and belonging for students who upon matriculating can find themselves navigating “tough issues of their age and environment,” concludes Simon J. Bronner, an American studies and folklore professor at Penn State, in his 2012 book about the role of campus ritual in the development of American culture. If college is a rite of passage, a commencement represents the metaphorical death of the child who’d embarked on college and her rebirth “as an empowered member of a special community,” Bronner writes. In other words, “commencement” is just that, a ceremony symbolizing the commencement of adulthood in earnest.

At Smith, newly minted alumnae laugh and hug and embrace the inevitable disarray while that death and rebirth happens as if in slow motion, the circles shrinking in size and number until a single ring—and, finally, a single pair, each holding the other’s diploma—remains.“It’s kind of like organized chaos,” says Elizabeth Jamieson, a chemistry professor and faculty marshal who herself participated in this ritual when she graduated from Smith in 1994, recalling the nerve-racking euphoria she felt as someone who lasted until the very last circle. “But perhaps because the order doesn’t matter, the atmosphere is especially joyous and special.” The process is all about community and connectedness, core values that the liberal arts—women’s colleges in particular—seek to promote.

Jamieson says the ceremony reinforces the feeling that “once you’re a Smithie, you’re always a Smithie.” But in requiring each graduate to “help hundreds of [her] peers accomplish this very technical task of getting their actual diploma,” it might speak to something even deeper than that too. By withholding the one tangible reward of a graduate’s bachelor’s coursework in the precise moment she’d expect to receive the coveted object, the Diploma Circle emphasizes that college isn’t, or at least shouldn’t be, just some transactional process that treats the ends—a degree—as more valuable than the means: a postsecondary education and the relationships that come with it.



Bernie Sanders has called for tuition-free college. Julián Castro has signaled support for it as well. Elizabeth Warren has pushed, for years, for “debt-free” college. Kamala Harris, Cory Booker, and Kirsten Gillibrand have signed on to legislation that could make college debt-free. Even Amy Klobuchar, who notably shirked “free college for all” during a CNN town hall in February, signed on to a metered free-college proposal last year.

All together, the field seems to have converged on a consensus: A free-college proposal—or an answer about why they don’t have one—is something of a prerequisite for Democratic candidates hoping to challenge Donald Trump in the 2020 election.

The consensus is long in the making: In 2008, the last time there was a large field of Democratic hopefuls, the proposals were more piecemeal. Many candidates pushed tax credits to offset college costs and suggested expanding grants for low-income students. Hillary Clinton suggested a national service program that would allow students to earn up to $10,000, which could be used toward education.

Over time, the ideas grew in ambition. By 2015, in his State of the Union address, President Barack Obama was saying that he wanted two years of community college to be “as free and universal in America as high school is today.” And in the last presidential election, in 2016, Hillary Clinton, who had originally said she believed “in affordable college, but [not] in free college,” was pushed by her primary opponent, Bernie Sanders, to embrace tuition-free college. Her ultimate acceptance of a free-college model ensured that it would be a feature of future Democratic platforms.

For Democratic candidates now, the question is not so much whether to support a plan to make college more affordable, but what the right approach is for doing so. The details—whether there is an income cap for eligibility; whether the government covers tuition costs up front before grants; whether there are merit or GPA requirements—will determine who will benefit the most, and who will pay for such a plan.





A subtle tweak from Kamala Harris this past January encapsulates the coming debate over the scope of the party’s proposals. The senator from California, while making formal what many had suspected—that she would be running for president—tweaked her language in a slight but potentially significant way. She was supporting free college, but not just any free college: She was pushing for debt-free college. “I am running to declare education is a fundamental right,” she said, “and we will guarantee that right with universal pre-K and debt-free college.”

What was the difference? Free college is a catchall term for a range of college-affordability plans. There are “tuition-free” programs, where the government—or an institution—covers tuition but not the other expenses, such as books, housing, or food; then there are debt-free college plans, which aim to address all those other costs. Harris was getting specific; and she was doing so with the kind of free-college idea—debt-free—that equity advocates tend to prefer.

Oftentimes, tuition-free models are “last dollar,” which means that the government covers tuition after all other grant aid—such as Pell Grants, which are federal grants for low-income students—is applied. Oftentimes those grants cover the full tuition at community colleges, and students aren’t able to use that money for things like books, housing, or food. These are things that they may ultimately have to take on debt to afford. “Progressive candidates need to be talking about debt-free college instead of just free college, and going beyond tuition for low-income students,” Tiffany Jones, the director of higher-education policy at the Education Trust, an advocacy group for low-income students, told me.

Harris’s declaration was a departure from her language in 2016, when she first introduced a plan, toward the end of her Senate campaign, to make community college tuition-free for all, and four-year college tuition-free for families making less than $140,000 a year; it was even a departure from weeks prior, when she pushed for tuition-free college. Her development signaled, perhaps above all, how the Democratic Party has evolved on college affordability.

The United States has a long history of college-access and -affordability policies—the first Morrill Act, the GI Bill, etc.—that did not provide equitable access or universal affordability, particularly for minorities. Advocates hope that a similar mistake won’t be made with a potential national free-college policy, and that debt-free college becomes the new gold standard.

“That’s the beauty of debt-free college programs: There is a lot of flexibility in there on policy design,” Mark Huelsman, a policy director at Demos, a liberal think tank, told me. A candidate could, for example, propose massively expanding access to the Pell Grant program so that more working- and middle-class students were eligible, and then subsidize education at HBCUs or private institutions that serve large shares of low-income students. A policy could, as Senator Brian Schatz’s Debt-Free College Act does, incentivize states to invest more in free-college programs by providing a one-to-one federal match on state spending.

In recent years, in the absence of ambitious federal efforts to deal with college costs, states, both red and blue, have been introducing their own college-affordability plans. “Anybody who wanted to do anything big or bold on college affordability had to do it at the state level,” Huelsman told me. More than 20 states have adopted free-college models since 2005. New Jersey, West Virginia, and Virginia look to be the next three states to implement free-college plans, Martha Kanter, the executive director of the College Promise Campaign, told me—none of which are debt-free plans.

Debt-free college plans are, by nature, expensive, and states have to run a balanced budget. The federal government doesn’t, which means that it can take on debt to pay for a free-college plan. Some hopefuls, such as Bernie Sanders and Elizabeth Warren, have proposed taxes to help offset the cost of their plans. Others have been much less specific about how they plan to pay for their proposals. Still, candidates will be hard-pressed to convince Americans that the answer to the college-affordability crisis is for taxpayers to just eat the debt.

That said, a free-college plan is only part of the solution. As Natalia Abrams, the executive director of Student Debt Crisis, an advocacy organization, put it, “While free college is needed and will help curb future college costs and future student debt, it will do nothing to help the 45 million people that are suffering with it right now.” After all, Millennials alone hold more than a trillion dollars in student debt.

Candidates have offered some solutions. Bernie Sanders’s 2017 College for All Act, for example, would have lowered interest rates for student loans and allowed current borrowers to refinance their loans at that lower rate. Warren, Harris, and Gillibrand were among the bill’s co-sponsors.

Additionally, Abrams told me, there is an acute need for consumer protections: Free-college plans should strengthen the repayment programs that are currently available, such as income-based repayment, which allows borrowers to pay a lower, more affordable amount for their loans; and there should be active enforcement of policies like borrower defense to repayment, which allows students to have their loans discharged if they’ve been defrauded and their school was closed.

Whatever the details of the plan, the motive for action is obvious: College has become a prerequisite for most high-paying jobs, and yet college itself is unaffordable for millions. “What happens when you don’t have the full cost of attendance covered?” Jones asked rhetorically. “Students stopping out. Students working more hours. These are things that the research suggests decrease their likelihood of actually completing,” she answered. “We know that has disproportionate impact on low-income students and students of color. Black students in particular.” As a result, many feel—and indeed are—shut out of America’s prosperity.



Near the beginning of his presidency, Barack Obama gave a speech to Congress that laid out a goal for the future: “By 2020, America will once again have the highest proportion of college graduates in the world.” At the time, America was 12th, according to the Organization for Economic Cooperation and Development.

Almost a decade later, and with 2020 not far off, where do things stand? The percentage of Americans between the ages of 25 and 34 who had earned an associate’s degree rose by 7.4 percent between 2007 and 2017—a difference of more than 5 million people, according to the U.S. Census Bureau’s American Community Survey. Still, that puts America at 10th in the world, according to the latest available data.

But even though progress has been made, the data remain quite uneven. A pair of reports released on Wednesday by The Education Trust, an advocacy group for low-income and minority students, break down the attainment data more finely. They found that the share of black adults who hold a bachelor’s or associate’s degree—31 percent—is roughly two-thirds that of white ones—47 percent. And Latinos, at about 23 percent, are just half as likely. Further, the report shows, there is not a single state in the country where black and Latino adults are as likely to have earned a college credential as their white counterparts.

At the root of these differences in attainment rates are social and economic disparities that continue to benefit certain races over others. Still, graduation rates have improved over the past decade, particularly among Latinos, as a report from the left-leaning Center for American Progress shows—and there is a significant difference between the rates of native-born Latino adults and those who were born outside of the United States. (The latter are less likely to have earned a degree.) It’s these race-by-race attainment rates that the report advises policymakers to pay attention to—overall graduation rates can obscure how the educational system underserves certain groups.

Andrew Nichols of the Education Trust, one of the authors of the report, explained to me what these changes in graduation rates mean on the levels of individual lives and of society. “We know the value of a college degree, in terms of what it does for wages, what it does for being less likely to be unemployed. We know what it does for the society—having more people who are able to generate higher tax revenues.”

More than 40 states have outlined goals for these attainment rates in the past decade, often including specific goal rates for black and Latino residents. What can be done to reach those goals? Well, for one, lawmakers can make sure race factors centrally into policy conversations—and that can look different for different states. For some, it could be as simple as diverting more resources to campuses that primarily serve minority students. A recent report from the American Council on Education, a leading higher-education trade group, found that minority-serving institutions have a special knack for changing students socioeconomic fortunes of students. Such institutions—including historically black colleges and universities and Hispanic-serving institutions—propelled students from the lowest rung of the economic ladder to the highest at at least double the rate of colleges that were not focused on enrolling a particular minority.

Tiffany Jones, a researcher at Education Trust, told me about how it can also help for colleges to assist groups of people with very specific needs. Detroit’s Wayne State University, for example, has just launched what it calls the “Warrior Way Back” program (a reference to the school’s mascot), that forgives the debt of former students with an outstanding balance of less than $1,500 and no degree, and allows them to return to school. If Obama’s goal is to be realized, specialized interventions like this will be just as important as focusing on the top-line attainment rates.



On that day two decades ago, news spread from Columbine quickly, and widely. By the time the killers concluded their shooting spree by turning their guns on themselves, less than an hour after firing their first shots, the attack had already become a media event unprecedented in the history of mass shootings. Local news stations and CNN began broadcasting the scene live to viewers around the country about 40 minutes into the attack. The coverage continued unbroken for hours. The story made the front page of The New York Times the next day and remained there for a week and a half; it was a constant presence in the local Denver Post well into summer. No other school shooting had reached a nationwide audience so fast, or taken such a hold on the news cycle.

American students started bringing guns to school and firing on their teachers and peers as early as 1840, and by the late 1990s, they had begun doing so multiple times a year in classrooms around the country—more frequently even than in the present day. But Columbine was both one of the deadliest school shootings in the United States up to that point and the first one to become a national spectacle. It set the blueprint for a generation of attacks. “[Reporters] really wrote the script as they went,” says Jaclyn Schildkraut, a professor at SUNY Oswego and a co-author of Columbine, 20 Years Later and Beyond. “There wasn’t a template at the time for how these events are covered … Columbine created the script of crisis coverage.”

It also created a model for would-be killers. This week, law enforcement in Colorado searched for an armed 18-year-old woman who made multiple threats in the Denver area and was “infatuated” with the Columbine attack; the hunt ended when she was found dead. She was far from the first person to draw inspiration from the attack: In an analysis of 12 school shootings that took place from 1999 to 2007, Ralph W. Larkin, a professor of sociology at the John Jay College of Criminal Justice at the City University of New York, found that eight of the shooters “directly referred to Columbine.” A 2014 analysis conducted by ABC News found even more extensive influence, identifying “at least 17 attacks and another 36 alleged plots or serious threats against schools since the assault on Columbine High School that can be tied to the 1999 massacre.” Among those who studied and admired the killers, Eric Harris and Dylan Klebold, were the perpetrators of two of the deadliest mass shootings in American history, at Virginia Tech in 2007 and Sandy Hook in 2012.

Studies have shown mass shootings to be contagious, suggesting that inspiration to commit one can spread via articles and television segments. Researchers hypothesize that potential killers see the devastation unfold and the shooters made famous in the national media, and become more likely to act on their own homicidal impulses. In this way, the Columbine killers may have continued to infect and inspire perpetrators of violence for 20 years, aided by the massive attention the media gave them.

Schildkraut lays out some of the beats of “the narrative pattern” developed by Columbine reporters: Begin with live reports from the scene, repeatedly air “images of people running out of school buildings with their hands over their heads,” then bring on the experts to offer their assessments, loop footage from “the law-enforcement press conferences,” and finally shift, as “the scene quiets down and is cleared by law enforcement,” to identifying victims and “talking about things such as societal and legislative changes.” Developing technology has introduced new elements to the narrative, such as social-media posts and cellphone calls from people trapped inside the building while the shooting is still ongoing. But the basic pattern has remained largely static for the last 20 years, as has the amount of time it takes before the news cycle starts to turn away: about one week.

What has also persisted, Schildkraut says, is the “process of irresponsible reporting” that grew in the immediate aftermath of Columbine. The constant presence of cameras and reporters in the face of tragedy “left people to grieve in a fishbowl, with all of these lenses posted up on them,” she says. “I think there’s a lack of mindfulness about what people experience.” Writing about the attack for Newsweek on the 19th anniversary last year, one Columbine survivor remembered how she and her classmates had to learn “to hide from the cameras as we cried on each other’s shoulders.” My colleague Adrienne LaFrance covered the aftermath of the Sandy Hook massacre in 2012 and reported on the Connecticut town’s frustration with the crushing media presence. Dozens of television cameras blocked sidewalks and staked out funeral homes while back-to-back services for murdered 6-year-olds took place. “Reporters are stalking us,” one Newtown resident told her. “It’s like, Fuck you. Go away. Leave us the fuck alone.”

Also irresponsible, Schildkraut says, is how the coverage has treated perpetrators. The early Columbine coverage was heavily focused on the killers: In a 2016 study, researchers found that the two shooters were mentioned more than twice as often as their 13 victims combined in early Denver Post stories on the attack, and six and a half times as often in New York Times articles. The news ran a constant cycle of profiles, conversations, and debates, all attempting to answer the same core questions: Who were Harris and Klebold? What went wrong in their upbringing? What drove them to kill?

In fact, though Columbine came to be seen as the archetypal American school shooting, the killers didn’t intend for it to be seen as a shooting at all. They planned it as a massive bombing, a domestic terrorist attack in the mold of Oklahoma City that would claim hundreds of lives, decimate the high school, and launch them into infamy for inflicting, in Klebold’s words, “the most deaths in U.S. history.”

The coverage’s focus on them posthumously granted Harris and Klebold the macabre celebrity they had hoped for—if not quite in the way they’d imagined. They had envisioned themselves going down in history alongside the likes of Attila the Hun or the Oklahoma City bomber, Timothy McVeigh, as the ruthless killers of hundreds of innocents. With their choice of venue—their suburban high school—and the failure of core pieces of their plan, they inadvertently gave rise to a different narrative and a different kind of terror: that of the disaffected teenage shooter taking revenge.

Within a day of the shooting, this narrative was more or less set. By most accounts, the killers were outcasts, goths, loners, targets of bullying by more popular students, and members of, as described in a New York Times article, “a group of misfits who called themselves the Trench Coat Mafia.” They were said to listen to “satanic music” and be obsessed with Nazi Germany. Reports held that they had planned their attack for Hitler’s birthday, with targets in mind among the student body: athletes, students of color, Christians—groups that had ostracized them, or that they saw as inferior. A Denver Post article published three days after the attack opened by likening it to other recent shootings: “Pearl, Miss. West Paducah, Ky. Springfield, Ore. And now Jefferson County, Colo. One common denominator in all these schoolyard shootings: bullies and misfits.”

This account was widely recounted throughout the spring of 1999 and lingers as a common perception of the attack 20 years later, but later reporting showed it to be rife with inaccuracies. The killers wore trench coats during the shooting, but they weren’t members of the school’s “Trench Coat Mafia.” They weren’t loners, but instead belonged to a close-knit group of friends. They didn’t listen to Marilyn Manson music, as some reports claimed. Harris did become enamored with, in his words, “German shit” in the lead-up to the shooting, and began quoting Hitler, along with Nietzsche and Freud, and listening to German rock. But the attack wasn’t planned for Hitler’s birthday. Originally, the killers intended for it to take place a day earlier, on the fourth anniversary of the Oklahoma City bombing. They didn’t target specific groups—not athletes, not students of color, not Christians. They went into the school hoping to indiscriminately kill everyone inside and anyone who came to help.

Details about the bombs and the shooters’ true interests and personalities were included in many early accounts of the attack, even though they conflicted with the dominant narrative of Columbine as a targeted shooting carried out in response to bullying. But the myth that the killers were tormented outcasts taking revenge prevailed. “Once you put out an inaccuracy like that, it’s extremely difficult, if not impossible, to reel that back in,” Schildkraut says. The attack engendered a litany of anti-bullying campaigns in schools around the country. And more recent shootings have prompted similar responses.

In a New York Times op-ed last year, Isabelle Robinson, one of the survivors of the attack on Marjory Stoneman Douglas High School in Parkland, Florida, challenged the bullying narrative. She remembered the former student charged with the shooting once throwing an apple at her, though she had never met him, and her uncomfortable experience tutoring him as part of the school’s peer-counseling program. “I am writing this because of the disturbing number of comments I’ve read that go something like this: Maybe if [the alleged killer’s] classmates and peers had been a little nicer to him, the shooting at Stoneman Douglas would never have occurred,” she wrote. “No amount of kindness or compassion alone would have changed the person that [he] is and was, or the horrendous actions he perpetrated.”

Less than three months later, the brother of the teenager charged with carrying out the attack launched an anti-bullying program, citing bullying and isolation as root causes of his brother’s violent actions. He admitted to bullying his brother himself when they were younger; reports have not confirmed that the alleged shooter was similarly targeted by his peers. Regardless, school shootings cannot be traced to any singular experience or trait in the perpetrators, as an FBI report outlined last year, and most perpetrators didn’t live in extreme social isolation before their attacks.

In recent years, some survivors, news organizations, and public figures have made an effort to change the narrative by shifting attention away from killers, refusing to say their names or show their pictures. After a shooter killed 50 people and wounded dozens more at a New Zealand mosque last month, for instance, the country’s prime minister, Jacinda Ardern, vowed not to contribute to his infamy. “He sought many things from his act of terror,” she said, “but one was notoriety. That is why you will never hear me mention his name.”

A number of researchers have suggested that minimizing focus on the killers after attacks in this way could help combat the contagion of mass shootings. “[Reports] focus so extensively on the perpetrators that we are essentially rewarding them for killing people and incentivizing people who show a familiar like-mindedness,” says Schildkraut. “We’re not focusing on the people who are taken—we’re giving the credit to the people who did the taking, and that just seems very dangerous to me.”

She says that “some stations and some outlets” have improved their coverage strategies since Columbine, “but by and large, there are still tremendous issues”—including the disproportionate exposure of killers and the harassment of communities where shootings occur. New technologies pose still more challenges to responsible disclosure.

Social media have enabled the harassment of survivors and victims’ families by the conspiracy theorists who began falsely claiming after the 2012 attack on Sandy Hook Elementary School that mass shootings were “false flags” and survivors were really “crisis actors.” And the same venues that connect communities with harassers also provide a more direct link between shooters and mass audiences, which further complicates the effort to deny them the infamy they crave. The contents of writings and videos left behind by the Columbine killers reached the public only through the filters of law enforcement and reporters. But the New Zealand killer was able to post links to his 74-page manifesto to 8chan and Twitter and to live-stream his attack on Facebook.

These mass-consumed shootings represent one of the enduring legacies of Columbine for a new generation. Harris and Klebold hoped to leave behind a different story, but this is the narrative that grew out of their killings; it’s one that continues to terrorize the world, 20 years later.



The nonprofit organization behind the Common Application, a single form that students can fill out to apply to any college that uses it, announced this week that, starting next year, it will no longer ask students about their criminal history. The shift could alter the life course for many students with higher-education aspirations who have a misdemeanor or felony attached to their name.

The move, which was announced to Common App member institutions on Tuesday, is significant because of the sheer number of students who use the application, and of the institutions that accept it. More than 1 million prospective undergraduates every year apply to college using the Common App, which is consulted for admissions decisions by more than 830 institutions worldwide—all but roughly 60 of them in the United States, home to the world’s highest prison-population rate.

It’s difficult to tell how many applicants’ prospects will change, in part because data that the Common Application keeps about criminal histories is not public, and in part because it’s impossible to count up all the students who would’ve applied in the past but didn’t for fear of being asked about their criminal records. But the applicants who will benefit most are probably going to be the very ones for whom higher education tends to be out of reach: low-income students of color, a demographic that is disproportionately represented in the criminal-justice system.

And that is linked to one of the strongest arguments for the change: Applicants’ criminal histories can reflect society-wide biases that are beyond their control. One in five black men who belong to the lowest-income families in the U.S. is sent into a correctional facility on any given day, according to a March 2018 paper co-authored by the Stanford economist Raj Chetty and published by the National Bureau of Economic Research. And as Tiffany Jones, who directs the higher-education-policy team at the advocacy organization Education Trust, pointed out to me in an interview, young people who are not white or who are poor are more likely to receive harsher sentences. They are also more likely to lack access to effective legal representation and are disproportionately targeted by law enforcement in the first place.

[The ease of online college applications could hurt poor students]

The change goes against the results of a survey the organization  (also called the Common Application) conducted among its members in March. That survey found most colleges and universities that use the Common App wanted to know applicants’ criminal histories. The move this week could be seen as a sign that the Common App might be taking on more of a role as a proactive agent of social mobility.

Daniel Obregon, the Common App’s spokesman, told me in an email that some relevant context for the decision was a change to the organization's mission a few years ago, with the addition of a commitment to “access, equity, and integrity.” But he also focused on logistical considerations, explaining that there is “increasingly less ‘commonality’ in terms of how institutions use criminal history information in their admissions decisions.”

The new policy still gives colleges flexibility: Schools can obtain information about criminal history through other means—by, say, specifically asking in their application supplements (also available through the Common App) whether applicants have ever been convicted of a violent or sexual crime. New York University offers an example of this approach: In 2015 the school announced that it would be ignoring the criminal-history question on the Common App and would instead ask students in its supplement about their criminal background; it keeps the information confidential during the admissions-decision process, after which the information would become available to school officials only if and when a student was accepted.

Even so, some research suggests that collecting applicants’ criminal history doesn’t make campuses any safer. A survey conducted jointly by the Center for Community Alternatives, which advocates for criminal-justice reform, and the American Association of Collegiate Registrars and Admissions Officers found that colleges and universities that don’t ask students to provide such information do not report that their schools are less safe as a result; generally speaking, there’s little compelling evidence drawing a correlation between that practice and campus safety.

Some colleges might make the argument that their concerns are not about safety, but about best serving students who need a particular kind of support; they want a holistic understanding of applicants, criminal histories and all. But the change in the Common App still leaves them room to collect this information through other means.

The movement to change the Common App, which has been taken up by several civil-rights activists and members of Congress, has its roots in the largely successful effort to enact laws prohibiting private employers from asking about criminal history on job applications. The Obama administration ended the practice for federal job applications during his second term, but the results have been mixed: Research after the change indicated that without specific information about, say, a black male applicant’s criminal history, hiring managers were more likely to assume that such an applicant had committed a crime than a white male applicant.

[Elite colleges have created a new application system focused on access]

Still, numerous aspects of the college-application process are explicitly tilted against people with criminal histories. In 1994, then-President Bill Clinton signed into law a prohibition on Pell grants for incarcerated students—a ban that remains in effect today. (The Republican Senator Lamar Alexander, who chairs the Senate’s education committee, is considering reversing that policy.) In a similar vein, a law passed in 1998 barred applicants who’d been convicted of a drug-related crime from receiving any federal financial aid, including Pell grants, Stafford loans, and work-study arrangements. (The law was revised in 2007 to apply only to students who were convicted of such a crime at the time they were receiving such aid.)

“There’s growing … consensus that education is the key to successful reentry [into society for people with criminal records], and the policies we’ve had thus far that led to mass incarceration”—harsh punishment for nonviolent drug-related crimes, mandatory-minimum sentences, and the like—“just didn’t work,” said Jones, of the Education Trust. Jones is excited about the potential for the Common App’s latest move to significantly expand access to higher education, but she is also aware that students with criminal backgrounds will still face questions about their histories in other elements of the college-application process if they fill out the Free Application for Federal Student Aid and Pell grant application. And the Common App at least for now will still retain a question asking whether an applicant has ever been disciplined by his or her high school—a question whose answer is much more likely to be yes for poorer and/or nonwhite students than it is for their more affluent or white peers.

Then there’s the fact that even the Common App’s influence has limits. As a September 2017 Brookings Institution report details, various analyses have found that a solid majority of colleges and universities in the U.S., Common App member or not, inquire about applicants’ previous convictions. That’s the case at as many as 80 percent of private institutions and 55 percent of public ones; it’s even relatively common at community colleges, 40 percent of which report collecting such information. But this latest amendment to the Common App might alter perceptions of applicants with criminal histories, at least a little, at least at some schools.

This article is part of our project “The Presence of Justice,” which is supported by a grant from the John D. and Catherine T. MacArthur Foundation’s Safety and Justice Challenge.



The cost of college is one of the main things students consider when deciding whether and where to enroll. So it makes sense that students, once admitted, would rely so much on the letters from colleges that tell them how much the institution can chip in. The problem is: Those letters, called financial-aid award letters, are often confusing and vary wildly from college to college.

A new report from uAspire, a college-affordability advocacy organization, and New America, a left-leaning think tank, examined more than 11,000 of such letters from uAspire’s work with students. What they found was inconsistency. Several of the letters didn’t even use the word “loan” when referring to an unsubsidized loan, a type of loan that accrues interest while students are in school. Other letters did not include information about how much it actually costs to go to the institution, which is vital context for students trying to figure out, for instance, how far a Pell grant (a federal grant for low-income students) will go. And half of the letters did not explain what a student had to do to accept or decline the aid that was offered.

To be sure, “aid” is a fickle word, and can mean different things under different circumstances. Grants are money that does not have to be paid back, whereas loans do, and on top of that there’s work-study, another term that is not self-explanatory, and which some letters don’t explain. And if that still does not cover the costs—the report found that Pell-grant recipients typically were left to pay an average of $12,000 in unpaid costs, that they may or may not be able to cover with subsidized or unsubsidized loans on their own—if not, parents can take out a PLUS loan (a federal loan for graduate students, professional students, and parents of dependent undergraduate students that covers the cost of attendance minus other aid) to cover the remaining balance. If that seems complicated, that’s because it is.

Going to college can be a huge financial burden. And ambiguity in explaining how to pay for it can have devastating consequences. That’s why it’s important for financial-aid award letters to clearly explain to students what they’re getting, how they’re getting it, and what financial obligations remain. If colleges are not transparent in describing how they can help students pay for their degree—for instance, the amount of money that is paid out in grants versus loans—then the likelihood that someone makes a bad financial decision increases.

Why aren’t colleges sending out more comprehensible letters? Maybe they are not thinking about the letters from a student’s standpoint, Rachel Fishman, a researcher at New America, told me. “The primary thing” colleges can be doing to fix how they explain costs to students that have been accepted, she said, “is to make sure that the letters are student-focused and that you’re not looking at them with the eyes of a financial aid officer.”

Perhaps the more likely explanation for the confusion is that the federal government hasn’t established any universal guidelines or requirements for the letters. Indeed, there are a few ways that the letters could be standardized. Colleges could voluntarily adopt the standard letter that the United States Department of Education has been recommending since 2012, which clearly explains how the full financial package is put together, but making that mandatory would require Congress to pass a law. Speaking of which, Congress could implement such a fix when it updates the federal law governing higher education, known as the Higher Education Act, which is overdue for an update, and require transparency—an approach whose success appears unlikely any time soon, as fundamental disagreements between Democrats and Republicans have derailed efforts to update the law so far this year. There was also a standalone bipartisan proposal last year to standardize the letters, but it is unlikely to pass with the Higher Education Act’s renewal still looming.

Fishman notes that fixing the award letters will not solve college costs—that needs to be dealt with separately—but it would go a long way toward helping students understand what they’re getting into when they decide to attend college.



Like any Advanced Placement course, AP World History is intense, requiring students to absorb lots of sophisticated, detail-laden information in a relatively short amount of time: usually, a single year of high school. Yet AP World, as it is colloquially called, is a special breed of intense. The time span that the course’s curriculum covers is as expansive as its geographic focus: The material includes history starting around 8,000 B.C. and ends in the present—more than 10,000 revolutions around the sun later. This content, which the curriculum divides into six periods, is typically covered over the course of two sequential college classes.

Now the College Board, the nonprofit testing company that runs (and earns close to half its annual revenue from) the AP program, has decided that the course as it stands is, in fact, too intense. As of the 2019–20 school year, the organization will administer an AP World exam that’s significantly narrower in scope, assessing content only from 1450 A.D. on. The organization plans to funnel the remaining 9,000-plus years of history into its brand-new Pre–AP World History and Geography curriculum, part of a suite of pre-AP classes that are designed to prepare all students for college and will be launched this fall. In rationalizing the AP World changes, the College Board spokesman Zachary Goldberg cited survey and performance data suggesting that too many students and teachers drown in the information overload and ultimately fail to gain value from the course. What’s more, Goldberg said, most colleges reward the small minority of students who score well enough on the exam with credit for a single semester-long course—typically one that covers post-1450-A.D. history.

But an emerging group of teachers and students is appalled by the prospective shift, and in recent days has set out to stop it. Moving all of the pre-1450 A.D. history to another course, they contend, will do little to ensure that that part of the human story—which one AP World teacher in Michigan, Tyler George, described to me as “some of the most rich, diverse content of the entire curriculum”—remains a priority.

Critics have been voicing their concerns via in-person forums and social-media platforms. For example, a student-led Change.org petition calling on Trevor Packer, the head of the AP program, to retract the decision, had as of Wednesday well surpassed its original 5,000-signature goal. The petition emphasizes that the decision “removes HUGE amounts of history”—eras that, while accounting for only40 percent of AP World’s total current course work, comprise some 95 percent of human history since the development of agriculture and set the trajectories of civilizations for thousands of years to come. That history includes the technological advancements and environmental transformation that arose during humans’ migration from Africa to regions around the world; the rise of the Persian empire, the Qin dynasty, Teotihuacan in modern-day Mexico, and the Puebloan People in what today is the southwestern U.S.; and the birth of some of the world’s major religions, including Confucianism, Hinduism, and Christianity.

Dylan Black, the New Jersey high-school student who created the online petition, worries that the change threatens to further entrench in Americans’ minds a Eurocentric worldview. He noted in an email that in his AP World class he learned about indigenous populations throughout the Americas before studying the conquest of those empires by countries like Spain. “Without this previous knowledge of American civilizations,” he said, “it would seem like nobody was there until Europe showed up.”

Such sentiments square with those expressed by numerous educators, many of whom are campaigning to at the very least salvage the curriculum’s third period, which encompasses the nearly nine centuries leading up to 1450 A.D.—a time period during which human networks within and across regions flourished and deepened. This class “is probably the only real chance [high-school students] are going to get to learn the African and American and Asian history before European colonization,” said Amanda DoAmaral, a former AP World History teacher of Brazilian and Jewish descent who, at a recent open forum for teachers in Salt Lake City, got into a testy exchange with Packer about the College Board’s values. “It’s so cool for students to learn [the third period] because it’s the one time in history that Europe wasn’t the big dog—it was in the Dark Ages while the rest of the world was innovating.”

In whittling the course down to a relatively minuscule phase of humanity’s existence, critics like DoAmaral argue, the College Board is effectively threatening to deprive kids of the insight that can be drawn from the thousands of years of human experience that predated the era of Euro and Anglo dominance. “In a world that is fueled by quick reactions on social media, biased news (in all directions), and people responding on passion rather than facts, AP World History is needed more than ever,” said George, the Michigan teacher. Students, he said, would benefit from understanding the history of the world’s populations before Europeans’ so-called discovery of their lands—that those populations’ narratives began far before they were exploited and depleted by colonial powers.

In response to the backlash, Packer announced last Thursday that while the College Board still intends to narrow the exam’s scope, it will consult with experts in considering “a coherent inclusion of essential concepts from period 3.” The College Board will report on its game plan in mid-July. Some observers applaud the attempt at compromise: The George Mason University provost and history professor Peter Stearns, for example, in a blog post Tuesday commended the College Board for responding with “constructive flexibility” by making room “for a real unit on key developments in the centuries before 1450.”

Still, teachers and students told me that while they appreciate the gesture, Packer’s reassurance is too vague—and his emphasis on essential concepts too simplistic—to make them optimistic that students will still learn the deeper historical roots of the modern world. As Alexander Ledford, an AP World History teacher in Florida, wrote to me, “It is not the point of this class to delve deeply into any one history, but to show how the common history of the world came about.”

Meanwhile, critics of the change aren’t convinced that relegating early world history to the pre-AP course will do much to preserve that instruction—in part because the College Board will charge schools an additional, possibly cost-prohibitive fee to offer the pre-AP course and in part because that intro class won’t be a prerequisite for the regular AP course and will not come with a high-stakes (and valuable) exam. Because the prospect of a resume-boosting high test score and the concomitant college credit is a major incentive for taking AP World, fewer students may seek out the pre-AP course.

And as George, the Michigan teacher, points out, the exclusion of pre-1450-A.D. material from the AP exam could discourage even the most dedicated teachers from prioritizing that material in class. “How can we allocate the amount of time that periods one to three require if it will not be tested?” he asked. “We can’t.”



The grade-school lunchroom has long acted as a microcosm of social life. It’s where kids choose whom to sit with, develop friendships, and resolve conflicts. And lunch is one of the few less-supervised periods in most kids’ school days. Over the past several years, however, some school cafeterias have become invaded by a new group: parents.

Twenty years ago, when I was in elementary school, having a parent join you at the lunch table was unthinkable. Parents or caretakers dropped everyone off in the morning for school, leaving us to grow, play, and learn until we were collected. But lately, parents are playing a much more active role in their children’s educational lives. According to a September report from Child Trends, a nonprofit research organization focused on children and their family, parental involvement in school is rising. “In 2016, the percentages of students whose parents reported attending a general meeting at their child’s school, a parent-teacher conference, or a school or class event reached their highest recorded levels,” the report states.

At some schools, swarms of parents wait in line to be escorted into the lunchrooms and sit with their children, some as old as 10, for a meal. One school district in Darien, Connecticut, found its cafeterias so inundated with parents that this week it announced an outright ban on parent-student lunches. “It feels like a punch in the gut,” Jessica Xu, a parent whose oldest child is in first grade, told the Associated Press after learning of the decision. “I chose the town for the schools. I’m so frustrated the schools don’t want me there.”

As the number of parents joining their kids for a midday meal swells, schools have tried to be accommodating. Most schools value parent involvement, but at a certain point it can become disruptive. A middle-school teacher in Connecticut, who asked to be anonymous since she was not authorized to speak on the record, said that she doesn’t think parent-student lunches are a bad thing, but she has seen them cause issues in the past. “The parents would bring pizza for some students and not others. It became a little bit of a circus and I do remember feeling like it was disruptive instead of being just a sweet lunch between just the mom and the kid,” she said. “I think she was using lunch to try to buy her daughter friends,” the teacher said of one mom.

Some kids, especially the young ones, begin crying when their mom or dad attempts to leave after lunch. Other children whose parents aren’t able to visit them (possibly because they’re working) can be left feeling neglected. School districts have attempted to thwart these problems by forcing parents to sit with just their own children, sometimes in separate rooms or areas. Rogers Middle School in Texas even offers parents and children the opportunity to dine at a “bistro” with fancy-looking chairs to avoid lunchroom disruption.

But according to Katelin Chiarella, a second-grade teacher in Hayward, California, schools aren’t doing enough to stem the tide of family lunches. Chiarella bemoaned the trend, which she sees as just another example of helicopter parenting. “Some parents come in and actually spoon-feed their kids, kids who don’t need to be fed,” she says. “Some parents make hot lunch at home and bring it to them.” She says that there are at least seven or eight parents a day in her school’s lunchroom. The school has tried to curtail that number, but it hasn’t worked. “They kept showing up anyway,” Chiarella says.

Parents who do eat with their children said that family lunches are a positive thing. If anything, they argue, schools should be encouraging parents to become more active and involved in their children’s school lives. Sarah McSpadden, a mom and family vlogger who documents her family life on Instagram, said that eating lunch with her third-grade daughter and her daughter’s friends has provided a valuable window into her child’s social life. “You see what people are eating, not eating, see which kids are throwing food, talking too loud, who is sitting by themselves. It’s a chance to poke in on your kids’ day that you wouldn’t get if you didn’t have lunch with them,” she said. In her district, she says, there are parents who join their children for lunch up to three days a week.

Shamaila Quddusi Jairajpuri, a mom to a second grader in Alameda, California, said that if she doesn’t bring her son homemade hot food for lunch, he usually won’t eat. “He says, ‘Oh, Mommy, I want to have this [for lunch]. But if he takes it in the morning, it gets cold … pancakes, after three hours they are cold and rubbery, who wants to eat cold pancakes?” she said. “My son was a very picky eater in kindergarten. He would go hungry in the morning. I would feel bad because he would not eat. If I’m there, I can make him eat.”

Through volunteering at school and joining her son for lunches through kindergarten, Jairajpuri has become close with many of the children in her son’s class. “They say, ‘Oh, can you open this for me?’; they talk to me about their day,” she said.

While kids in elementary school may be thrilled to have their parents in, especially when they bring food, by middle school it’s safe to guess that most are mortified by the practice. McSpadden said she never joins her children in the ninth or 11th grade for lunch. By then, they’re more independent.

The middle-school teacher from Connecticut said that even though it can feel upsetting to be cut off from what you consider valuable time with your child, it’s important to remember that schools have the best interest of kids at heart. “I know from being an educator for over 12 years … It’s the school’s responsibility to care for the students while they’re in school, and they need to make the best choice possible for the students,” she said.

But David Frankel, a North Carolina entrepreneur who tries to join his kindergartener and fourth grader for a meal at least once a quarter, said that schools should encourage more parent involvement, not discourage it. Besides, he added, “nowadays, with most parents working, it’s hard to find quality time with your kids. After school, you’re dealing with after-school activities or hours of homework. Sometimes lunch is the only uninterrupted quality time you get.” This may be true, but Frankel admits that school districts are trying to strike a delicate balance. After all, if school lunchtime becomes quality time for kids and their family, then it’s no longer a place for them to learn how to interact with their peers without a parent’s watchful eye.



America has long had a fickle relationship with homework. A century or so ago, progressive reformers argued that it made kids unduly stressed, which later led in some cases to district-level bans on it for all grades under seventh. This anti-homework sentiment faded, though, amid mid-century fears that the U.S. was falling behind the Soviet Union (which led to more homework), only to resurface in the 1960s and ’70s, when a more open culture came to see homework as stifling play and creativity (which led to less). But this didn’t last either: In the ’80s, government researchers blamed America’s schools for its economic troubles and recommended ramping homework up once more.

The 21st century has so far been a homework-heavy era, with American teenagers now averaging about twice as much time spent on homework each day as their predecessors did in the 1990s. Even little kids are asked to bring school home with them. A 2015 study, for instance, found that kindergarteners, who researchers tend to agree shouldn’t have any take-home work, were spending about 25 minutes a night on it.

But not without pushback. As many children, not to mention their parents and teachers, are drained by their daily workload, some schools and districts are rethinking how homework should work—and some teachers are doing away with it entirely. They’re reviewing the research on homework (which, it should be noted, is contested) and concluding that it’s time to revisit the subject.

Hillsborough, California, an affluent suburb of San Francisco, is one district that has changed its ways. The district, which includes three elementary schools and a middle school, worked with teachers and convened panels of parents in order to come up with a homework policy that would allow students more unscheduled time to spend with their families or to play. In August 2017, it rolled out an updated policy, which emphasized that homework should be “meaningful” and banned due dates that fell on the day after a weekend or a break.

“The first year was a bit bumpy,” says Louann Carlomagno, the district’s superintendent. She says the adjustment was at times hard for the teachers, some of whom had been doing their job in a similar fashion for a quarter of a century. Parents’ expectations were also an issue. Carlomagno says they took some time to “realize that it was okay not to have an hour of homework for a second grader—that was new.”

Most of the way through year two, though, the policy appears to be working more smoothly. “The students do seem to be less stressed based on conversations I’ve had with parents,” Carlomagno says. It also helps that the students performed just as well on the state standardized test last year as they have in the past.

Earlier this year, the district of Somerville, Massachusetts, also rewrote its homework policy, reducing the amount of homework its elementary and middle schoolers may receive. In grades six through eight, for example, homework is capped at an hour a night and can only be assigned two to three nights a week.

Jack Schneider, an education professor at the University of Massachusetts at Lowell whose daughter attends school in Somerville, is generally pleased with the new policy. But, he says, it’s part of a bigger, worrisome pattern. “The origin for this was general parental dissatisfaction, which not surprisingly was coming from a particular demographic,” Schneider says. “Middle-class white parents tend to be more vocal about concerns about homework … They feel entitled enough to voice their opinions.”

Schneider is all for revisiting taken-for-granted practices like homework, but thinks districts need to take care to be inclusive in that process. “I hear approximately zero middle-class white parents talking about how homework done best in grades K through two actually strengthens the connection between home and school for young people and their families,” he says. Because many of these parents already feel connected to their school community, this benefit of homework can seem redundant. “They don’t need it,” Schneider says, “so they’re not advocating for it.”

That doesn’t mean, necessarily, that homework is more vital in low-income districts. In fact, there are different, but just as compelling, reasons it can be burdensome in these communities as well. Allison Wienhold, who teaches high-school Spanish in the small town of Dunkerton, Iowa, has phased out homework assignments over the past three years. Her thinking: Some of her students, she says, have little time for homework because they’re working 30 hours a week or responsible for looking after younger siblings.

As educators reduce or eliminate the homework they assign, it’s worth asking what amount and what kind of homework is best for students. It turns out that there’s some disagreement about this among researchers, who tend to fall in one of two camps.

In the first camp is Harris Cooper, a professor of psychology and neuroscience at Duke University. Cooper conducted a review of the existing research on homework in the mid-2000s, and found that, up to a point, the amount of homework students reported doing correlates with their performance on in-class tests. This correlation, the review found, was stronger for older students than for younger ones.

This conclusion is generally accepted among educators, in part because it’s compatible with “the 10-minute rule,” a rule of thumb popular among teachers suggesting that the proper amount of homework is approximately 10 minutes per night, per grade level—that is, 10 minutes a night for first graders, 20 minutes a night for second graders, and so on, up to two hours a night for high schoolers.

In Cooper’s eyes, homework isn’t overly burdensome for the typical American kid. He points to a 2014 Brookings Institution report that found “little evidence that the homework load has increased for the average student”; onerous amounts of homework, it determined, are indeed out there, but relatively rare. Moreover, the report noted that most parents think their children get the right amount of homework, and that parents who are worried about under-assigning outnumber those who are worried about over-assigning. Cooper says that those latter worries tend to come from a small number of communities with “concerns about being competitive for the most selective colleges and universities.”

According to Alfie Kohn, squarely in camp two, most of the conclusions listed in the previous three paragraphs are questionable. Kohn, the author of The Homework Myth: Why Our Kids Get Too Much of a Bad Thing, considers homework to be a “reliable extinguisher of curiosity,” and has several complaints with the evidence that Cooper and others cite in favor of it. Kohn notes, among other things, that Cooper’s 2006 meta-analysis doesn’t establish causation, and that its central correlation is based on children’s (potentially unreliable) self-reporting of how much time they spend doing homework. (Kohn’s prolific writing on the subject alleges numerous other methodological faults.)

In fact, other correlations make a compelling case that homework doesn’t help. Some countries whose students regularly outperform American kids on standardized tests, such as Japan and Denmark, send their kids home with less schoolwork, while students from some countries with higher homework loads than the U.S., such as Thailand and Greece, fare worse on tests. (Of course, international comparisons can be fraught because so many factors, in education systems and in societies at large, might shape students’ success.)

Kohn also takes issue with the way achievement is commonly assessed. “If all you want is to cram kids’ heads with facts for tomorrow’s tests that they’re going to forget by next week, yeah, if you give them more time and make them do the cramming at night, that could raise the scores,” he says. “But if you’re interested in kids who know how to think or enjoy learning, then homework isn’t merely ineffective, but counterproductive.”

His concern is, in a way, a philosophical one. “The practice of homework assumes that only academic growth matters, to the point that having kids work on that most of the school day isn’t enough,” Kohn says. What about homework’s effect on quality time spent with family? On long-term information retention? On critical-thinking skills? On social development? On success later in life? On happiness? The research is quiet on these questions.

Another problem is that research tends to focus on homework’s quantity rather than its quality, because the former is much easier to measure than the latter. While experts generally agree that the substance of an assignment matters greatly (and that a lot of homework is uninspiring busywork), there isn’t a catchall rule for what’s best—the answer is often specific to a certain curriculum or even an individual student.

Given that homework’s benefits are so narrowly defined (and even then, contested), it’s a bit surprising that assigning so much of it is often a classroom default, and that more isn’t done to make the homework that is assigned more enriching. A number of things are preserving this state of affairs—things that have little to do with whether homework helps students learn.

Jack Schneider, the Massachusetts parent and professor, thinks it’s important to consider the generational inertia of the practice. “The vast majority of parents of public-school students themselves are graduates of the public education system,” he says. “Therefore, their views of what is legitimate have been shaped already by the system that they would ostensibly be critiquing.” In other words, many parents’ own history with homework might lead them to expect the same for their children, and anything less is often taken as an indicator that a school or a teacher isn’t rigorous enough. (This dovetails with—and complicates—the finding that most parents think their children have the right amount of homework.)

Barbara Stengel, an education professor at Vanderbilt University’s Peabody College, brought up two developments in the educational system that might be keeping homework rote and unexciting. The first is the importance placed in the past few decades on standardized testing, which looms over many public-school classroom decisions and frequently discourages teachers from trying out more creative homework assignments. “They could do it, but they’re afraid to do it, because they’re getting pressure every day about test scores,” Stengel says.

Second, she notes that the profession of teaching, with its relatively low wages and lack of autonomy, struggles to attract and support some of the people who might reimagine homework, as well as other aspects of education. “Part of why we get less interesting homework is because some of the people who would really have pushed the limits of that are no longer in teaching,” she says.

“In general, we have no imagination when it comes to homework,” Stengel says. She wishes teachers had the time and resources to remake homework into something that actually engages students. “If we had kids reading—anything, the sports page, anything that they’re able to read—that’s the best single thing. If we had kids going to the zoo, if we had kids going to parks after school, if we had them doing all of those things, their test scores would improve. But they’re not. They’re going home and doing homework that is not expanding what they think about.”

“Exploratory” is one word Mike Simpson used when describing the types of homework he’d like his students to undertake. Simpson is the head of the Stone Independent School, a tiny private high school in Lancaster, Pennsylvania, that opened in 2017. “We were lucky to start a school a year and a half ago,” Simpson says, “so it’s been easy to say we aren’t going to assign worksheets, we aren’t going assign regurgitative problem sets.” For instance, a half-dozen students recently built a 25-foot trebuchet on campus.

Simpson says he thinks it’s a shame that the things students have to do at home are often the least fulfilling parts of schooling: “When our students can’t make the connection between the work they’re doing at 11 o’clock at night on a Tuesday to the way they want their lives to be, I think we begin to lose the plot.”

When I talked with other teachers who did homework makeovers in their classrooms, I heard few regrets. Brandy Young, a second-grade teacher in Joshua, Texas, stopped assigning take-home packets of worksheets three years ago, and instead started asking her students to do 20 minutes of pleasure reading a night. She says she’s pleased with the results, but she’s noticed something funny. “Some kids,” she says, “really do like homework.” She’s started putting out a bucket of it for students to draw from voluntarily—whether because they want an additional challenge or something to pass the time at home.

Chris Bronke, a high-school English teacher in the Chicago suburb of Downers Grove, told me something similar. This school year, he eliminated homework for his class of freshmen, and now mostly lets students study on their own or in small groups during class time. It’s usually up to them what they work on each day, and Bronke has been impressed by how they’ve managed their time.

In fact, some of them willingly spend time on assignments at home, whether because they’re particularly engaged, because they prefer to do some deeper thinking outside school, or because they needed to spend time in class that day preparing for, say, a biology test the following period. “They’re making meaningful decisions about their time that I don’t think education really ever gives students the experience, nor the practice, of doing,” Bronke said.

The typical prescription offered by those overwhelmed with homework is to assign less of it—to subtract. But perhaps a more useful approach, for many classrooms, would be to create homework only when teachers and students believe it’s actually needed to further the learning that takes place in class—to start with nothing, and add as necessary.



The world does not revolve around you, teens are often told. Indeed it doesn’t, as they are reminded every school-day morning when disabling their alarms. The average start time for public high schools, 7:59, requires teens to get up earlier than is ideal for their biological clocks, meaning many teens disrupt their natural sleep patterns every school day.

The world, apparently, does not revolve around parents either. Their lives also tend to be mismatched with school-day schedules, which usually end a good two hours before the typical American workday does. As Kara Voght recently wrote in The Atlantic, that leaves a daily gap of unsupervised time for many children, forcing their parents to find affordable care for their kid or to adjust their own working schedule.

It’s not entirely clear who the school day does revolve around. The schedules that dictate most of American K-12 life descend from times when fewer households had two working parents. The result is a school day that frazzles just about everybody. But a few changes could mitigate that frazzling significantly. “I don’t know about making everyone perfectly happy,” says Catherine Brown, the vice president of education policy at the Center for American Progress, a left-leaning think tank. “But I think that we could get much closer to optimizing for students, parents, teachers.” The school day, Brown says, could be improved in two main ways: It could start later, and it could go longer.

A later start, in both middle and high school, would help with the later sleep cycles that are typical in teenage years. Most teens don’t naturally fall asleep until about 11 p.m., and are supposed to get about nine hours of sleep per night. But when class starts before 8:30—as the most recent federal data indicates it does at 87 percent of American public high schools—waking up in time for school cuts into needed sleep. Postponing the start of the school day, researchers have found, does lead middle and high schoolers to get more rest—they don't just stay up later. And then, once better-rested, studies show that teens do better in school, get in fewer car crashes, and are less prone to depression.

Half past eight—the target for many start-school-later advocates—is actually still earlier than would be totally ideal. Kyla Wahlstrom, a lecturer at the University of Minnesota who conducted the first study examining the effects of later start times on high schoolers back in the late 1990s, told me that, taking only teens’ sleep needs into account, the best start time would be around 9:00 or 9:30; that would give them the optimal amount of time to sleep and get ready. “8:30,” she says, “is a compromise that allows more sleep, but does not impinge on the after-school activities.”

In the 20-plus years since Wahlstrom conducted that first study, hundreds of schools have moved back their start times, according to the advocacy group Start School Later, which does its best to count in absence of an official government tally. The group’s cause has gained momentum as the American Academy of Pediatrics (in 2014), the Centers for Disease Control and Prevention (in 2015), and then the American Medical Association (in 2016) recommended that middle and high schools start no earlier than 8:30, citing sleep deprivation’s negative effects on students’ health and academics. A California state bill currently awaiting the governor’s signature would require most middle and high schools to start no earlier than 8:30, which could affect the sleep schedules of millions of teens; still, earlier start times remain the norm nationwide. (And worldwide: “Although we don’t have comparative data, I have observed that starting [the] school day early is not an exception,” says Yuri Belfali, the head of early childhood and schools at the OECD, a group representing 36 mostly wealthy countries. “For example, it is not unusual that [the] school day starts at 7:30 a.m. or earlier in Singapore and other Asian countries, or in Brazil.”)

The rationale for the second school-day change—go longer, for working parents’ sake—is just as straightforward. More than a thousand American schools have extended their school days by an hour and a half, and many charter schools, which have more latitude than normal public ones, have school days that end closer to when work does. But no movement has formed around altering the school day in this way; there’s no advocacy group called Make School Longer (a tougher sell to students, probably) and America’s respected medical groups seem unlikely to announce a stance on how to make it easier for parents to juggle work and their kids’ schooling.

I asked Brown what her ideal school-day schedule would look like, if she could start from scratch. She told me it’d start later, at 8 or 8:30—not just for teens, but also for younger kids. The day would end at 5 or 5:30, but the extended day's extra hours wouldn't be spent solely in the classroom. Brown says she’d “have a period in the afternoon where they’re doing creative activities and they’re doing physical activities, sports, arts, music—I would bake all that stuff into the day, as opposed to the after-school being plopped on, disconnected from the rest of the learning goals of the school.” (In Brown’s hypothetical ideal school day, teachers wouldn’t be asked to work longer days, but would instead work in shifts.)

Today’s standard 6.5-hour school day looks quite different. “I’m not pretending this is a utopia,” Brown says. “I’m just repeatedly struck, as a mother and as an education policy wonk, [by] how schools don’t often consider the needs of parents' work schedules when they’re designing all kinds of policies.”

Early start and end times have remained the norm in part because inertia is powerful—it’s “a problem in the sense that this is how we’ve always done it, so this is the way we’ll keep doing it,” Brown says. And the obstacles to changing it usually fall under three general categories: sports, buses, and funding.

“When there’s a weird practice in American education and you don’t know why, if you say ‘sports,’ you’ll be right about 75 percent of the time,” says Jonathan Zimmerman, a professor at the University of Pennsylvania’s Graduate School of Education. A lot of the pushback against moving back school start times, he notes, comes from coaches, players, and parents who worry that the change would eat into precious practice and game time. For instance, when an education board on Long Island sought public comments last year on the possibility of moving school start times back, some parents fought the change passionately. “Every single contest that we play next year will be affected by a 3 o’clock [end] time,” one father warned. “Every practice and every single game.”

Frequently, though, athletics programs adjust just fine, as some school administrators have noted after starting school days later. And in fact, there’s good evidence suggesting that getting more rest helps athletes perform better and be less vulnerable to injuries. Nonetheless, sports-related concerns often dominate when the prospect of later start times is raised.

Buses are the second issue. Brown says many districts don’t have enough of them to move every kid at once, so fleets works in cycles, staggering pick-up and drop-off times based on age. High schoolers are usually first—parents tend not to want younger children waiting in the dark—then middle schoolers, then elementary schoolers.

This arrangement dates back to four or five decades ago, and teens’ sleep needs were not on its architects’ minds. Back then, buses were a way of getting kids to school amid new, pedestrian-unfriendly sprawl (most kids used to just walk), but also of assuaging fears that walking to school alone was dangerous. And as many districts bought buses and hired drivers, they kept fleets only as big as absolutely necessary, to save money. Increasing spending on buses and drivers is no small thing when many schools are already dealing with slashed budgets; transportation costs might rank as a lower priority at schools with, say, outdated textbooks or run-down facilities.

Which connects to the third common category of opposition to changing the school day: concerns about funding a longer day. Increasing the amount of time that schools operate each day, as Brown favors, would cost money. She cites this as another reason that changing the school day is difficult. “Our schools haven’t even recovered from the 2008 recession,” Brown says. “More than half of states are funding their school systems at a lower level than they were in 2008.”

Still, she says, there are ways for schools to adapt. As she outlined in a 2016 report, there are a few ways that schools could apply for federal funding to extend the school day under the Every Student Succeeds Act of 2015. Also, she says schools could have outside enrichment programs step in for a period of the day.

At any rate, many parents already are paying for the fact that the school day ends before the workday, in the form of childcare or extracurriculars. “We’re effectively asking parents right now to subsidize the school day,” Brown said.

There is probably no such thing as a school-day schedule that satisfies every constituency. Keep start times early, and teens don’t get the sleep they need. Make start times later, and people involved in sports and other extracurriculars complain, and transportation costs go up. Keep school days the usual length, and working parents are in a jam. Make school days longer, and both students and teachers might dread the added time. But still, it seems an amended school-day schedule could make a lot of these people collectively less unhappy than they are now.

Kids have to go somewhere while their parents work, and it’s going to get funded one way or another. Ansley Erickson, an associate professor of history and education at Columbia University’s Teachers College, told me about another model, from the early-20th century in New York City, when a lot of mothers worked outside the home. “There was a lot more time that kids spent unsupervised, and there were also a lot more intentional spaces in the city where kids could be and be supervised that were not school spaces,” she said. Some of these were private (after-school programs run by churches or community centers) and some were public (libraries; playgrounds staffed with supervisors to watch over children). There are, as history indicates, other ways of looking after kids when they aren’t in classrooms that could serve as a model for reimagining their schedules. It would just take creativity, some reallocating of money, and most of all a collective resistance of inertia.



Getting into America’s top colleges is extremely hard, but making sense of how it’s decided who gets in is arguably even harder. By and large, colleges—especially the most selective ones—are allowed to keep their methods to themselves.

Terry Hartle, of the American Council on Education, the leading group representing colleges and universities, calls admission to an elite college “very desirable, exceptionally competitive, and inherently subjective.” Hartle’s first two descriptors are reason enough to examine how institutions choose who to let in, but—given how lucrative it is to hold a degree from such institutions—it’s the third that most invites scrutiny.

Recently, it has been the Department of Justice that has taken up the invitation. Over the past year and a half, the department has started a handful of inquiries into the practices of a number of elite institutions in order to see if their admissions processes violate federal law.

Late last week, several highly selective colleges received letters from the department regarding “a potential agreement between colleges relating to their early decision practices.” The news was first reported by the trade publication Inside Higher Ed. The “agreement”—under which colleges are thought to pass information to each other about which students have gotten in where— may constitute an antitrust violation in the eyes of the Justice Department. Wesleyan University, Wellesley College, and Middlebury College are among the institutions that received the letters, according to The Wall Street Journal. (The Department of Justice declined to comment for this story.)

Outsiders have long been curious how admissions decisions are made. Most of the time this desire for transparency stems from a desire for fairness: Given how few acceptances elite institutions can offer, admitting any group of students almost always means excluding a much larger group that is just as qualified. So the unfortunate truth that investigators and the public may discover after peering into the black box of college admissions is that there are few, if any, procedures for deciding who gets in that would be perceived as fair.

This larger idea looms behind the Justice Department’s inquiry, but the department’s specific concern here is about the particularities of schools’ information-sharing arrangements. “Early decision” is an option offered by some schools that allows students to apply early and receive a decision sooner than usual, on the condition that they’ll accept an offer of admission. If a student is accepted early decision, they’re expected to withdraw their applications at any other schools.

Still, a very small number of students break these agreements and don’t withdraw their other applications. Which is where the information-sharing comes in: It’s helpful for colleges to know whether a student is already bound to attending another institution—and for the college that has accepted the student to know they are coming. Colleges can use this information to plan out who to admit, and it also reduces comparison-shopping on the part of students who might consider breaking an early-decision agreement for the promise of a sweeter financial-aid package at another school. But again, because it’s rare that students renege on early-decision admissions, the scope of the investigation is quite small.

Early decision has been controversial for a long time, but not for antitrust reasons. As Kim Cook, the executive director of the National College Access Network, an advocacy group, puts it, many low-income and first-generation college students do not always have the “luxury of committing to a school and a package without the ability to compare that financial-aid package and find out where they and their family can afford.”

The colleges that received letters from the Justice Department were told to hold onto documents reflecting communication that might hint at—or outright state—those agreements, among other information. Of course, several admissions officers quickly noted that they did not have such agreements, and, in fact, most colleges don’t. But some officials anonymously acknowledged to The Chronicle of Higher Education that they did have such agreements with small groups of institutions and that they only shared names of students who were accepted.

This is not the Justice Department’s first foray into investigating potential antitrust issues with college admissions. In November, the department requested information regarding a revised admissions ethics code from the National Association for College Admission Counseling (NACAC), a trade group; investigators said they were interested in whether colleges agree to “restrain trade” by complying with NACAC’s updated ethics code. David Burge, the president of the organization, said in a statement that the association had no reason to believe that this inquiry is related to the Justice Department’s more recent one.

There is another inquiry as well. Harvard does not appear to be implicated in either aforementioned antitrust investigation, but it is the subject of a separate inquiry, into the use of race in admissions, that has been ongoing since last fall. Last Friday, the Justice Department urged the public disclosure of the college’s admissions practices. It’s usually hard to argue against transparency, but the move was a bit puzzling: As Neal Hutchens, a professor of higher education at the University of Mississippi, told me, the department likely already had this information from its own investigation, and yet it was was asking Harvard to make it public.

The Justice Department and Harvard both have their own interpretations of the situation. The department argued in a “notice of interest” filed last Friday that “the public funds Harvard at a cost of millions of dollars each year, and thus has a paramount interest in any proof of these allegations, Harvard’s responses to them, and the Court’s resolution of this dispute.” The notice was filed in an outside case brought by an advocacy group called Students for Fair Admissions, which accuses Harvard of discriminating against Asian American applicants. Harvard, for its part, has alleged that the department is fighting on behalf of Edward Blum, an anti–affirmative action advocate who founded Students for Fair Admissions. (Blum has denied urging the government weigh in on his organization’s case.) Also, the department’s interest in the case may simply be a gateway to take a broader look at race in admissions (even though race usually constitutes only a sliver of the admissions criteria at the colleges that actually consider it).

The federal government’s probing of college admission is, according to Hartle, indicative of two larger tensions in American higher education. “This is fundamentally a problem about access at the best places in the world being inherently limited, and a process that is subjective and not terribly public.” As long as the process stays that way, the government—and the many students who are subject to its whims each year—will want to know more about it. And they might not like what they find.



It all seemed surreal to Sandra Alexander, the day when the response to student unrest at North Carolina A&T State University, a public historically black university in Greensboro, North Carolina, boiled over into a government occupation. The tear gas, the bullets, the tanks. It was May 1969, and the university was about to become the site of one of the largest occupations of an American college campus in history.

Alexander, who was one of the students hired as a full-time dormitory director, was on duty the night the commotion began. “The protest started right in front of the dorm I was in charge of, Curtis Hall,” she told me of the tumult over an injustice at a local high school that had leaked back to the campus. Then the Greensboro police arrived to disperse the protesters and unleashed chaos. The police fired tear gas and bullets at the students; Alexander recalled “young men running, trying to avoid being shot,” and “pounding their fists on the doors of the dorm, begging to be let in so that they could escape the gunfire.”

The violence continued through the night; then, by morning, the National Guard began showing up. The governor ordered dorms to be raided in search of guns in students’ rooms. When the occupation was over, one student—Willie Grimes, an 18-year-old freshman—had been killed, and one other student had been shot but survived. The graduation ceremony was postponed, and when it was held two weeks later, it was a shell of what it would have been.

Fifty years later, during commencement at North Carolina A&T earlier this month, members of the graduating class of 1969—more than 100 of them—gathered on the Greensboro campus. Typically, these anniversaries are marked by the seasoned graduates donning golden regalia and marching in the processional with the soon-to-be alumni. But this year there was more to it. “[These graduates] found what should have been a day of celebration a faint shadow of what it could have been,” Harold Martin Sr., the university’s chancellor, told the audience. “We cannot undo the terror of our students, faculty, and staff, and what they felt as armed National Guardsmen swarmed the campus and fired on Scott Hall,” he said. “But what we can do—what it is our honor today—is celebrate the students who persevered through that period of chaos and violence.”

Martin signaled to the audience. “And what we can do is recognize the injustice so many of them suffered in 1969”—the audience began clapping, as the class members rose to their feet, standing and waving—“in not being able to have a proper graduation to celebrate their academic accomplishments.”

The revolution was on in Greensboro in the late 1960s, particularly on the campus of North Carolina A&T. “People like Stokely Carmichael, Rap Brown, Nikki Giovanni, and Sonia Sanchez came to campus,” Alexander told me. “They were the first ones to really tell us ‘black is beautiful’—and we believed it.”

It didn’t hurt that the campus is located in what was then one of the centers of black activism. Jelani Favors, the author of Shelter in a Time of Storm, which explores how historically black colleges foster activism and leadership, says that the political fervor of students on campus was really the product of the combination of these two factors—the speakers who had come to campus and the local opportunities to organize in their own area. “In the fall of 1968, there had been an attempt to organize a campus strike on behalf of the cafeteria workers on campus,” he told me. At the beginning of the decade, the Greensboro sit-ins of 1960 inspired a wave of sit-ins across the country. “There had been a separate attempt to organize and support the blind workers who worked in Greensboro; and there was a lot of really positive, radical energy surrounding that campus prior to May 1969,” Favors said.

By the tail end of the ’60s, one of the most prominent student-led civil-rights organizations, the Student Nonviolent Coordinating Committee, was on its last legs. Student leaders at A&T thought to launch their own national organization: the Student Organization for Black Unity. The organization’s first meeting, in the spring of 1969, brought student-activist leaders from across the country to Greensboro. It was a year after Martin Luther King Jr.’s assassination and the Orangeburg massacre, where a South Carolina Highway Patrol officer killed three black men on the campus of South Carolina State University, a historically black college three hours from Greensboro. The group railed against systemic discrimination, the remaining vestiges of slavery and Jim Crow, and other injustices that had not been undone by the Civil Rights Act of 1964 and the Voting Rights Act of 1965.

Across town, on May 2, Claude Barnes, an African American junior at James B. Dudley High School, had won the race for student-body president on roughly 600 write-in ballots. But school administrators declared another student, who received hundreds fewer votes, the winner of the election. Black students at Dudley were furious. The move was politically motivated, they argued, and the school administrators were only denying Barnes the presidency because they argued he was affiliated with youth groups that were too militant. “The fact that one student was denied the opportunity to run for a school office is insignificant per se; it becomes highly significant when seen in the context of the inequities charged against the total system,” a report compiled for the U.S. Commission for Civil Rights in 1970 reads.

Barnes, it turned out, had a connection to students in the Black Power movement at A&T, and by May 9, as students at Dudley protested the decision, A&T students joined them. It made sense for them to, Favors told me, as they thought, “This is what we have this new organization for—let’s stop talking about it, and let’s go and see what we can do on behalf of these students.”

The protests continued for the next several days, and by Wednesday, May 21, the local authorities and administrators at Dudley viewed the A&T students as agitators, Favors said; and the protest spilled over back onto A&T’s campus. Students threw rocks at cars passing by. The A&T administration tried to get all A&T students to leave campus before the semester had ended, telling them they had until Friday, May 23, to collect their things. By the time the local police arrived at A&T to squelch the protest that day, “they saw the students as the enemy,” Alexander said. “They were no longer students; they were targets.”

First the police fired tear gas and pepper spray to disperse the crowd, and eventually, after reports of sniper fire, they started shooting bullets at the students. “It was dark when it started,” Alexander told me, and it continued through the night. The National Guard was alerted at 10:35 that evening, and administrators called Alexander to tell her to put her building on lockdown—no one out, no one in—as young men beat on the doors to escape the gunfire. Roughly 150 National Guard troops arrived on campus. An hour and a half past midnight, Willie Grimes, who was returning from a fast-food restaurant, was shot in the back of the head. The police said neither they nor the National Guard used bullets small enough to match the one that killed Grimes. No one was ever tried in his murder.

The next morning, at a 10 a.m. news conference, the Greensboro mayor, Jack Elam, declared a state of emergency, and an additional 500 guardsmen were called in. All told, 650 members of the National Guard were ordered to be on campus, with tanks, a helicopter, and guns. The university’s president, Lewis Dowdy, dismissed classes. An angry mob pulled a white driver—a civilian—from his truck and flipped it on its side. As the day wore on into night, sniper fire continued, and authorities said there were large stockpiles of guns in the dorms. Overnight, Governor Bob Scott made the call: The National Guard was to sweep two dormitories on campus. “Guardsmen charged through the halls kicking down doors and shooting off locks,” a local news report a decade later recapped. “In some cases students were sleeping or packing, under the impression they had until 6 p.m., May 23, to get out.” The sweep resulted in the confiscation of three working firearms. The information authorities had about a stockpile was erroneous.

On May 23, students left campus unsure of when they would be able to come back; some were unsure whether they wanted to come back at all. Seniors were left wondering whether they would have a graduation. Sandra Alexander returned home to Warsaw, a sleepy farm town in southeastern North Carolina. But she returned a little over a week later, on June 1, when the university alerted the seniors that they would be able to have commencement exercises. The communication between the university and the students was fractured as the institution tried to put itself back together. She was greeted by a classmate with congratulations, unsure why. “You’re the valedictorian,” she remembers the classmate telling her. “Would have been nice to know that,” she says now.

The bullet-stained wall of Scott Hall is still on campus at North Carolina A&T, a reminder of the occupation that foreshadowed the violence at Jackson State and Kent State the following year. The report submitted to the U.S. Commission on Civil Rights suggested that blame for the events at A&T was to be placed on everyone in the community, but particularly on the National Guard and police for excessive force.

“This really kind of exemplifies the overaggressive force that National Guardsmen, state militia, and local police were willing to use to shut down the protest energies that were very much circulating through these campuses,” Favors told me—and this kind of strong antagonism seemed to happen on HBCU campuses in particular.

During commencement this year, as Chancellor Martin stood at the lectern following a video tribute to the class of 1969, he implored the audience to honor the class. “What we can do is recognize the productive, successful lives that so many went on to live,” he said. “Carrying out exceptional careers and serving as phenomenal community leaders.”

Alexander went to graduate school at Harvard, then finished her doctorate at the University of Pittsburgh. She returned to North Carolina A&T, where she was a professor for three decades. She taught African American literature and mentored students. When she looks back at 1969, she doesn’t limit it to the violence of those three days in May; she also thinks about the energy that coursed through campus—the desire among the student body to effect change, and the effort to suppress it.



When students from Santa Fe High School in Santa Fe, Texas—where eight students and two teachers were killed in a mass shooting on May 18—went back to school last week, their school looked different from the last time they saw it. Metal detectors and a security vestibule made of bulletproof glass greeted them at the front doors, and every classroom now also contained a “panic button” to trigger an alarm system. Students also passed more police officers in the hallways than before.

The opening of the new, heightened-security Santa Fe High School marked, in a way, the school’s second reopening since the shooting. Eleven days after the shooting, students and their parents were welcomed back to campus with an event commemorating the dead; after that, the students went back to class. (The classrooms affected by the shooting were closed off by newly built walls.)

Santa Fe’s response to the school shooting closely resembles that at Marjory Stoneman Douglas High School, where students came back to class two weeks after a gunman killed 17 people on Valentine’s Day, and at Marshall County High School, where school started back up three days after two students were shot and killed in January. They more or less followed the same three-pronged itinerary: a short school closure, a memorial event to welcome back students and their families, and then a beefing up of security measures during students’ summer break.

All told, school shootings are statistically rare; the vast majority of American schools have never been and never will be sites of mass violence. Still, mass shootings at schools are, unfortunately, more common than they’ve ever been before in the United States: In the first five months of 2018, The Washington Post found 17 incidents of school shootings, the most since at least 1999. Which means a certain set of best practices for when and how to reopen schools is emerging.

It’s often no accident that schools tend to follow similar protocols after acts of mass violence: “Very often a school [that’s had a school shooting] will call the one that had the one before,” says Cathy Kennedy-Paine, who leads the crisis-response team for the National Association of School Psychologists and works with schools to help them recover after  shootings.

She’s uniquely equipped for the job. In May 1998, Kennedy-Paine was working as a school psychologist at Thurston High School in Springfield, Oregon, when an expelled student opened fire and killed two students. Eleven months later, after two gunmen killed 13 people at Colorado’s Columbine High School—Kennedy-Paine remembers getting a call from the superintendent of Columbine’s school district, “asking if we would come and talk.” Five days after the shooting, Kennedy-Paine and her colleagues traveled to the district to share how Thurston had responded.

A couple factors determine how long a school initially stays closed in the days following a shooting. “The best strategy is to go back to the school as soon as possible,” says Kennedy-Paine, “because we know that one of the best ways to reduce the impact of that trauma is to reestablish the natural social-support systems for students and teachers.” But one of the primary reasons schools stay closed for a time after a shooting is that the site immediately and automatically becomes a crime scene, which places the building or campus under the control of local law enforcement.

Even if police wrap up an investigation quickly, however, the extent of the physical damage to the building plays a role in how long its doors stay closed. “We would not send students into a building that had blood stains, or bullet holes, or any visible sign of the damage,” Kennedy-Paine says. Often, students can go back within a matter of weeks, or even days, once visible damage from the violence has been removed or repaired. But schools that suffer more extensive damage often stay closed much longer: At Columbine, for example, the school stayed closed for the remainder of the school year after the April 1999 shooting and reopened in August, but the library—the epicenter of the violence there—was permanently closed off to students. A new library opened two years later. “Sometimes that's helpful, because obviously going back into a room that you had been in during a shooting would be traumatic,” Kennedy-Paine says. “Your heart races, suddenly you're back to the day [of the shooting].”

This logic, of minimizing spaces that could trigger trauma, led Sandy Hook Elementary School in Newtown, Connecticut, to remain closed for nearly four years after a gunman killed 26 people there in December 2012. Students were sent to an elementary school in a nearby town while the entire Sandy Hook facility was torn down and rebuilt.

Kennedy-Paine believes that schools need to build some time into their schedules for recovery, and re-open with an “open house” of some sort, perhaps on an evening before school starts up again. At Santa Fe, students and their parents were invited back to campus for a two-hour assembly the morning before classes began. At Marjory Stoneman Douglas, an open house was held on a Sunday afternoon before classes resumed later in the week. When students come back, “It's not unlike when you have a home burglary—you feel very violated,” she says. At Thurston, Kennedy-Paine remembers, parents and teachers entered with the students, hand in hand. “It gave a very nice sense of taking back the school from this terrible thing that happened,” she says.

If there’s one big commonality in how schools respond to shootings, it’s reinforcing security. When students return to school in the immediate wake of a tragedy, Kennedy-Paine says, “we also want to make sure there are overt signs of physical safety.” Often, schools beef up the presence of security officers and parent volunteers, just to have “more eyes on kids, more people watching what’s going on.” And since schools often have a number of entrances and exits, Kennedy-Paine says locking more doors to limit possible points of entry for an intruder can help students feel safer.

Many schools plan out their security strategy in two phases: First, figure out what to do for the remainder of the current school year, and second, figure out what to do permanently. In both cases, some extra security measures are a given, such as an increase in the number of school resource officers (SROs)—essentially, police officers assigned to patrol a school full-time. Marshall County High School, for example, had one SRO on duty last year but reopened this fall with five, as well as a new set of metal detectors.

While an SRO’s primary duty is to protect students in the event of an attack at school, another is to prevent such attacks from happening in the first place, which Mo Canady, the executive director of the National Association of School Resource Officers, says involves building and maintaining trusting relationships with students. Of course, in communities where views of law enforcement are less than favorable, administrators are often less enthusiastic about shoring up the police presence in schools.

SROs assigned to schools in the wake of school shootings and acts of violence, Canady says, are often surprised by the degree to which they end up working to protect students’ emotional health in addition to their physical safety. Often, Canady finds, students talk to the officers about more than just potential dangers. Years ago, Canady worked as an officer in a school where one student stabbed another between classes, and the next day, “we thought we would be spending our time keeping the school physically secure, but we spent more of our time in the room where all of the counseling was going on.” Granted, not all students have positive experiences with SROs: An officer at a South Carolina high school came under public scrutiny in 2016 after he violently dragged a student across a classroom floor.

There’s no one method for schools to improve their long-term physical safety after shootings; Marjory Stoneman Douglas High, for example, now has 52 new security cameras that it didn’t when students left for summer vacation, and visitors can now only come in through one entrance, where they’re screened at the door by a video intercom system. Canady says what’s appropriate for any given school is decided locally, but he believes it’s important for schools not to implement measures that just superficially make a place seem safer. Canady’s seen some school administrators immediately express a desire to install metal detectors, but he warns against installing expensive technologies without accompanying them with the necessary personnel and policies to make them effective: “You don't want to create a false sense of security by just saying, ‘Okay. We've got metal detectors. All is well,’” Canady says.

Some aspects of the experience of returning to school after a tragedy still lack a clear blueprint or set of best practices—like whether and how to evaluate students’ academic performance when they’re recovering from a trauma. But Kennedy-Paine says she’s seen a few strategies she’s liked that help take the pressure off students. At one school that suffered a shooting just a few weeks before the end of the school year, she says, “the teachers got together and decided that the students’ grades on the day of the shooting could be their grades for the term. They could keep working and do more and raise their grades, if they wanted to, but they wouldn't penalize anyone for not continuing to work for those few weeks.”

And at Marjory Stoneman Douglas High School, students were exempted from having to take the Florida Standards Assessment and other standardized tests required by the state for the remainder of the school year.

One of the crucial elements in a good school reopening, according to Kennedy-Paine, is a recognition on school administrators’ part that things won’t be “back to normal” for a long time, maybe even ever—and that there will be certain days when shooting victims’ absences will be felt acutely among the student body. “There's prom that's going to happen, and graduation, birthdays of the victims are going to happen,” she says, “and eventually the anniversary of the shooting is going to happen.”

No matter how and when a school decides to reopen after a shooting, the key is to help students recuperate from the trauma that they’ve experienced. “It’s important to honor the students who are coming back,” says Kennedy-Paine. “Some will be overt about it; some will be crying or emotional. Some will be very introspective about it, and will appear not to even be fazed. But everyone is dealing with it in their own way.”



Some trends in higher education move up and down—ebbing and flowing with the economy and demographic shifts. And then there are those that are stagnant, ever-present reminders of the work America’s universities still need to do.

One of those is the problem of faculty diversity: Less than 6 percent of full-time faculty members at institutions across the country are black. Many factors coalesce to bring about that dearth of black faculty, but one of the most significant is the perpetual scarcity of black doctoral-degree recipients.

From 2002 to 2017, of the roughly 50,000 people who earned Ph.D.s each year, the percentage who were black increased only modestly, from 5.1 percent to 5.4 percent, according to data from the National Science Foundation. In 2017, there were more than a dozen fields—largely subfields within science, technology, engineering, and math—in which not a single doctoral degree was awarded to a black person anywhere in the United States.

The lack of black doctoral students is due, in part, to a broken pipeline, and addressing the issue is a matter of getting more students interested in pursuing the credential. But pipeline problems don’t necessarily account for the number of black college graduates who don’t pursue, or are dissuaded from, higher degrees because of how those programs treat black people. “You hear a lot of horror stories from black faculty and black doctoral students,” Felecia Commodore, an assistant professor of higher education at Old Dominion University, told me.

Those stories can make it feel like getting a Ph.D. simply won’t have the payoff for black students in the long run—stories like that of Thea Hunter, a brilliant scholar who, as a professor, was questioned about whether or not she had a doctoral degree and was mistaken for a janitor; or like that of Amherst College, where, from fall 2000 to fall 2016, black faculty were 33 times as likely to be denied tenure as their white colleagues, according to an investigation by the student newspaper.

Before experience becomes a material issue, though, a student must first get into a doctoral program, which can be a chore all its own. It is typically up to departmental faculty to decide who does and who does not get into a Ph.D. program, and “there can be a lot of politics in play that keep black students from being admitted,” Commodore told me. There could be a lack of enthusiasm about an applicant’s topic or research interest, or some students might not come with the same social capital—recommendations from noted or well-connected faculty in the field—that others might.

Then, after they are admitted, there is the question of cost. Black college students borrow at higher rates than any other racial group, and they are more likely to default on those student loans. “Imagine coming out of school with a bachelor’s degree, with such a debt burden,” Lorelle Espinosa, vice president for research at the American Council on Education (ACE), told me. “Students are thinking, I don’t have a safety net for this debt. Am I really up for going for an advanced degree where I’ll find myself in even more debt?”

That fear is compounded by the jarring fact that roughly 50 percent of black doctoral students were enrolled at for-profit colleges, according to a recent report from ACE; that means they are more likely to sink deeply into debt than they would be if they had started a doctoral program at a nonprofit college. Nearly all those students, 95 percent, took out loans and ended up with an average debt of more than $120,000.

Despite all these forces bonding together to dissuade black students from pursuing doctoral degrees, there are ways to break the cycle. One way, Espinosa suggests, is to demystify graduate school and doctoral programs in particular. “Research, exposure, and experience for undergraduates is a huge predictor of success in research careers,” she told me. Some institutions, particularly historically black colleges, are already doing this work. Among black STEM Ph.D. holders, more than a third earned their undergraduate degrees at HBCUs, according to a report from the American Institutes for Research.

“A number of black students don’t know if they can do it,” Commodore told me. “It’s our job”—not just black faculty, but all faculty—“to help them do it,” not only while they’re in the program, but after they’ve entered the job market as well.



It’s hard to snatch attention from the jaws of intrigue, and Varsity Blues had it all. There were fake SAT scores, a shady deal maker, and wealthy parents eager to lay waste to anything standing in front of their children on the road to a selective college—the vaunted status symbols that they are. This exposes the gritty underbelly of the race to get into America’s colleges, a common refrain went.

As my colleague Alia Wong noted shortly after the scandal broke, these sorts of high-stakes admissions antics represent only a fraction of college admissions—a small one at that—because most colleges aren’t that selective. More than 80 percent of students attending bachelors-degree-granting colleges go to those that accept more than half of their applicants, according to an Atlantic analysis. These not-so-selective schools are the big picture of higher education, the forest so many miss while examining in microscopic detail the bark and leaves of a few “top-tier” trees.

A pair of new reports show how even looking at that bigger forest still misses the wider world that it grows on and that shapes it. On Wednesday, the National Center for Education Statistics released new data showing a 50-percentage-point gap—that’s right, 50 percentage points—in college-going rates between students who come from the highest-earning families and the lowest earning. Of students who entered ninth grade in 2009, 78 percent of those from the wealthiest 20 percent of families were enrolled in college seven years later (in 2016), whereas just 28 percent of students from the lowest quintile were.

The numbers, although not necessarily shocking to those paying close attention to higher education, are jarring. Going to college—and staying there—are rites of passage for only certain slices of the American public.

That said, over time, the trajectory for higher education is that it is becoming more inclusive, and more lower-income students are attending than in the past. The Pew Research Center released a new analysis on Wednesday showing that the number of low-income students has increased “dramatically” over the two decades from 1996 to 2016, and now makes up nearly a third of the overall student population. The bulk of the growth occurred at two-year colleges and private for-profit institutions, but there was also significant growth at less selective bachelors-degree-granting colleges. Similarly, the share of racial minorities increased across all sectors of higher education, but, again, the increases were most prominent at less selective bachelors-degree-granting institutions and two-year colleges. This is due, in no small part, to efforts from universities—especially regional, open-access institutions—to recruit low-income and minority students. The highly selective institutions continue to draw the majority of their students from middle- and high-income families, the report said.

But the fact that regional, open-access schools are making strides with low-income and minority students comes with a catch: During this same time period, state funding of higher education has declined significantly. “Overall state funding for public two- and four-year colleges in the school year ending in 2018 was more than $7 billion below its 2008 level,” a report from the Center on Budget and Policy Priorities reads. On top of that, the purchasing power of the Pell Grant, a federal grant for low-income students, has dipped as well. So as higher-education opportunities and outreach to poor students have increased, the resources available to them on campus—both in terms of the opportunities they have and the support they can access—have dwindled.

Still, even taking account of the gains described in Pew’s report, the overall picture is bleak for low-income students, the vast majority of whom will never go to—much less graduate from—college. Varsity Blues was easy to see and pick apart from the canopy. But for most Americans, what matters is the wider forest—and whether they can get there at all.



On Tuesday, the Trump administration made its official position clear: Schools should limit their use of race as a factor when determining admissions. The administration is moving to rescind seven guidance documents from the Education Department’s Office for Civil Rights and the Department of Justice, according to The New York Times. These Obama-era memos encouraged elementary, secondary schools, and colleges to use race in efforts diversify their student bodies, and outlined how to do so within the law. The Trump administration will break with this precedent, and will not actively encourage schools to diversify, the Times reported.

The move by the Trump administration is the most recent blow to the use of race in admissions decisions, and it comes a week after Supreme Court Justice Anthony Kennedy delivered a similarly grave punch.

When Kennedy announced his retirement from the United States Supreme Court last week, affirmative action advocates worried it would bring about the end of the use of race in college admissions. In the 2016 Fisher v. University of Texas decision, Kennedy had aligned himself with the court’s liberal wing, casting the decisive vote to allow universities to continue using race as a factor in their admissions decisions. This was a departure for Kennedy, who had previously shied away from upholding affirmative action programs against constitutional challenges. It is only a matter of time before the issue comes before the Court again. And next time, assuming a Trump nominee gets confirmed to the Court, the decision will likely break the other way.

Together, these two developments swing the momentum on the use of race in admissions firmly towards those who want to prohibit doing so, and amount to perhaps the biggest shift in the government’s position on the issue in more than a decade.

Tuesday’s announcement brings in line with the policies of previous Republican administrations who have looked unfavorably upon the use of race in admissions. In 2008, the Bush administration issued guidance that emphasized the limited role that race should play in college admissions. The Obama administration defended affirmative action in court. But in the forthcoming cases—such as the lawsuit alleging that Harvard University discriminates against Asian-American students by using race as a factor in admissions—the Trump administration is unlikely to do so.

To be clear, the way that race is legally allowed to be used in admissions is already extremely limited, and not all schools, colleges or otherwise, use it. Some states, such as California, have already made it illegal to use race as a factor for all grade levels. And, across the country, even when race is used in admissions considerations, it is generally used in very narrowly defined ways.

Exactly how narrowly defined —particularly selective private colleges—is unknown, due in large part to the inherently subjective nature of the admissions process. A recent court filing in the case against Harvard has somewhat unmasked at least part of the calculus of that institution, including its use of “soft skills” such as “likeability” and “helpfulness” to determine acceptance, which are thought to disadvantage Asian-American students. Still, for the most part, race, along with everything else about the admissions process is hidden from public scrutiny.

Late last month, researchers at the Urban Institute, Matt Chingos and Victoria Lee, noted that on the 40th anniversary of the Bakke decision, which upheld the use of race as constitutionally permissible, colleges are not ready for a world without affirmative action policies. Most of the institutions that use race-conscious policies—which tend to be more selective institutions—already do not do a good job maintaining a diverse student body.

A look at the numbers makes their point clearly: Even with race-conscious admissions, black and Latino students represent a small fraction of the student populations at the country’s most selective colleges—4 percent and 11 percent of elite research universities, respectively. And a report from the Education Trust shows that black students make up less than six percent of students enrolled at public flagship universities. Several people have proposed alternatives to race as a factor, such as socioeconomic affirmative action, but there are concerns that doing so would not significantly increase racial diversity at America’s colleges. “Race plays a unique role in American society that cannot be replaced by socioeconomic proxies,” Chingos and Lee wrote, “and race-based affirmative action is likely the most efficient path to achieving racial diversity.”

All told, what this means is that in the years ahead, the country will almost certainly be entering an era in which affirmative action is without much federal support or guidance. “Colleges and universities continue to live in a climate of fear on this topic,” Catherine Lhamon, the former top civil rights official at the Education Department under Obama, told me, “and having the federal government weaken its position on it will discourage the lawful use of race to achieve diversity which will mean that our college and university campuses will become whiter and less diverse.”



On Tuesday, Lou Anna K. Simon, the former president of Michigan State University, was charged with lying to investigators during inquiries into sexual-abuse allegations against Larry Nassar, who was found guilty of abusing more than 150 young women as a doctor for the university and USA Gymnastics.

Simon, who resigned as the institution’s president in January, has been charged with two felony counts and two misdemeanor counts in state district court, several outlets have reported. She has remained part of Michigan State’s faculty since her resignation, keeping the $750,000 annual salary she made as president. But according to a statement issued by the university, Simon is taking an “immediate leave of absence, without pay, to focus on the charges.” (A lawyer for Simon, Lee Silver, did not immediately respond to a request for comment.)

Tuesday’s revelation is the latest in a case that has been a disaster for the university. Over time, several trends have emerged: the slow-footed response by Michigan State’s leadership to the reports, their sitting by as accusations against Nassar mounted, and their failure to take responsibility for Nassar’s misconduct, which occurred over several decades from at least 1992 until 2014.

In a statement immediately following her resignation as president in January, Simon suggested that she knew that in thorny situations like the one at Michigan State amid the Nassar scandal, the school’s leadership would be targeted. “As tragedies are politicized, blame is inevitable. As president, it is only natural that I am the focus of this anger,” Simon wrote. “As Nassar’s legal journey to prison was drawing to a close, more and more negative attention was focused on Michigan State University, and on me.” And that attention has now manifested as legal charges against the former president.

Since the allegations against Nassar surfaced in 2016, after an investigation from The Indianapolis Star, the fallout has continued. Nassar was sentenced to what amounts to a lifetime in prison. Several people at Michigan State have been charged or indicted, or have resigned. The United States Olympic Committee has taken steps to revoke the status of USA Gymnastics as the organization representing America on the world’s gymnastics stage. And the new charges indicate that the crisis at Michigan State is far from resolved.



The Trump administration’s relationship with historically black colleges and universities (HBCUs) started with a lot of flash and a little substance. Dozens of black educators in the Oval Office for a photo opportunity with the president. An executive order on black colleges that didn’t live up to expectations. And a host of unforced errors.

Black college leaders and their advocates, though, remained cautiously optimistic. After all, they weren’t exactly thrilled with the Obama years, and at least the early months of the Trump-era had placed a spotlight on the often-neglected institutions. There were a number of public overtures. The administration didn’t propose adding funding for the institutions—which have been historically underfunded, and have requested more federal support—but it wasn’t suggesting cutting funds either, and it supported a bipartisan budget deal that increased HBCU spending. And, above all else, they thought, they had the president’s ear—and that was due in large part to Omarosa Manigault-Newman’s presence in the West Wing.

That direct line was cut in December when Omarosa—a black college graduate herself—was unceremoniously fired from the White House. And in her new book, the former reality star and senior White House aide is inflaming what was already a tense relationship between between black colleges and the administration.  

One of the primary targets of her attacks is Education Secretary Betsy DeVos. She criticizes DeVos for her showing during a commencement address at Bethune-Cookman University, a black college in Daytona Beach, Florida, where the secretary was raucously booed—and claims the secretary questioned the students’ ability to comprehend her agenda. She also blames the secretary for the stop-and-start confusion around the White House’s annual conference for black colleges.

"This disgraced former White House employee is peddling lies for profit,” Elizabeth Hill, a spokeswoman for the department told me in a statement. “The book is a joke as are the false claims she’s making about Secretary DeVos.” Regardless of whether Manigault-Newman is telling the truth, however, her eventful departure from the White House has left black colleges with an open question: Who will fight for them now in the Trump administration?

The natural answer for that question is the executive director for the White House Initiative on Historically Black Colleges, Johnathan Holifield, who was appointed to the position just short of a year ago, and whose office Trump moved into the West Wing by executive order. (Though, it should be noted, the rest of the employees who work on the White House Initiative are in the Education Department.) And there are other areas of the administration’s agenda that HBCUs  generally approve of, such as the department’s attempt to roll back Obama-era regulations that cracked down on predatory behavior by for-profit colleges—which could have also ensnared some black colleges.

But in the dozens of conversations that I’ve had with black college presidents over the last several months, the common refrain is that their engagements in Washington were never really about the White House, or the administration. Yes, a good relationship with the presidential administration is important, but they say they were always more interested in a good relationship with Congress. Overlooked amidst coverage of the photo opportunity and missteps of that February was what many black college leaders saw as a successful event with lawmakers from both sides of the aisle, led by Senator Tim Scott of South Carolina. The second-annual such meeting was held in February of this year.

That relationship with Congress has been paying off for the institutions. In the February budget deal, lawmakers authorized the Education Department to forgive $330 million of debt related to rebuilding after Hurricane Katrina that was incurred by four black colleges in Louisiana and Mississippi. The administration forgave that debt in March.

And last week, Representative Alma Adams of North Carolina, chair of the bipartisan HBCU caucus, led a summit championing diversity in tech at North Carolina A&T University, a black college in Greensboro. The convention brought together more than 35 companies ranging from Uber to Dell to Facebook and dozens of HBCUs to discuss partnerships and ways to strengthen diversity in the companies’ hiring pipeline.

There will undoubtedly continue to be tension between the administration, black colleges, and—perhaps most notably—the students on HBCU campuses. And the claims in Manigault-Newman’s book may further strain that relationship. But black colleges believe working with the federal government can pay off, and in some ways during the Trump era, it already has—Omarosa or no Omarosa.



When sordid revelations surfaced in recent years of how the sale of hundreds of enslaved laborers in 1838 saved Georgetown University from the cliff of financial ruin, the college cobbled together a multipronged response. It summoned a working group to study how to make penance for the wrongdoing.  It held a ceremony to deliver an official apology. It began giving descendants of the 272 enslaved people a bump in admissions.

The Georgetown working group wrote that “we are convinced that reparative justice requires a meaningful financial commitment from the University”—but so far, the university has done little to follow through on that recommendation.

Students at the school have now taken matters into their own hands. Last week, in a student referendum, undergrads voted overwhelmingly to tax themselves the symbolically significant amount of $27.20 per semester to create a fund that will support the descendants of the enslaved people from whom the university profited. Many of them live in rural Maringouin, Louisiana, where the median household income is less than $24,000, far below the national average. The details of Georgetown’s potential new approach are still nebulous—Will students on financial aid have to fork over money? How exactly will the collected funds be provisioned?—and the results of the referendum could still be nullified by the administration. But if the vote indeed gets translated into policy, it will mark the first attempt by any American institution to give out reparations.

But while students by and large supported the measure, some questioned whether it should fall to the student body to make amends for the institution’s past blunders. “We are just one part of the over-100,000-member Georgetown community,” says Sam Dubke, a sophomore,* referring to the school’s alumni, “and frankly, we are the members of that community who have the least financial means.” The tax would raise an estimated $400,000 in its first year, a considerable chunk of money, but less so in the context of an institution sitting on nearly $2 billion in the bank, one that, in 2016, paid the school’s president $1,436,230 and the head men’s-basketball coach $3,967,988. (The team finished the year with its worst record since the 1970s.)

The Georgetown students behind the effort reject the premise that they themselves are absolved from any financial commitment. “I don’t think the university paying the fee would address what the referendum seeks to address,” says Hannah Michael, a sophomore who helped conceive the idea of a fund. “Students voted yes because they believe they have a financial obligation to commit to reconciliation with descendants.”

“Since 2015, Georgetown has been working to address its historical relationship to slavery and will continue to do so,” said Matt Hill, a Georgetown spokesman, when I asked why the school doesn’t just pay for the fund itself. The school’s president visited Maringouin in 2016, he added, and since then, “Georgetown has met with many descendants and heard many important ideas about how we might move forward together.”

But the fact that students may be ahead of the school in paying reparations is evidence of just how little the university has done to make amends for its misdeeds. And such inaction isn’t just a Georgetown quirk. Virtually all the antebellum colleges were active participants in chattel slavery—at Princeton, for example, prospective students would arrive on campus to be first greeted at the president’s doorstep by his slave. As the MIT historian Craig Steven Wilder writes in Ebony and Ivy: Race, Slavery, and the Troubled History of America’s Universities, higher education “never stood apart from American slavery—in fact, it stood beside church and state as the third pillar of a civilization built on bondage.”

Many of these colleges—Harvard, Brown, Rutgers, the University of Virginia, William & Mary—have begun to grapple with their slaveholding past, convening symposia, erecting memorials, renaming buildings, and so on. But none has yet acted on a plan that transcends symbols to try to make amends for the wrong it has done.

A big reason for this is that a lot of colleges aren’t quite sure how to actually do that. “It’s really clear that if those 272 people had not been sold, Georgetown as we know it today would not be here,” says Jody Allen, a William & Mary professor who directs the Lemon Project, an initiative at William & Mary to address its complicity in racism. “It can’t get much clearer than that. But at a lot of other colleges, it’s murky.” That clarity has allowed for some 8,000 direct descendants of the Georgetown 272 to be identified—a remarkable genealogical feat that may not be replicable elsewhere.

Take Harvard: In 2016, the university put up a plaque memorializing four enslaved people who worked on campus in the 1700s—but apart from their first names, not a whole lot else is known about the individuals. Without a defined set of people descended from those four, Harvard says it’s not clear what it can do to recompense for its centuries-old misdeeds.

Though colleges—ivy-laden, highly selective schools especially—have reputations as bastions of progressivism, behind that veneer, like many other institutions, they’re exceedingly cautious and resistant to dramatic moves, expensive ones in particular. “When you start doing the math, who knows what that dollar amount might be?” Allen told me. “I do think there’s probably a good amount of trepidation at looking closely at that reality. That might be slowing down some schools from actually doing it.” Even for a college like Harvard, with a virtually boundless endowment that outstrips the resources of most state governments, the more hefty attempts at compensation could raise difficult questions about who deserves it, and how much, that these institutions would much like to avoid. In that way, colleges mirror society more broadly. Though lofty reparations plans are in vogue among a set of Democratic 2020 presidential aspirants, Americans on the whole aren’t exactly clamoring to hand out cash to descendants of slaves; one recent poll found that just one in four Americans favored the policy.

But these obstacles shouldn’t mean that colleges are off the hook from doing more to atone for the profits they’ve reaped from enslavement. “People think of reparations and they think checks,” Allen told me. “But that’s only part of it. Are you providing courses around these issues? Are you diversifying the faculty? Are you supporting student organizations?”

Colleges like Georgetown could adopt a slew of other strategies, starting with a simple one: Enroll more black students. Highly selective colleges are enrolling more minority students overall—just not more black students. Leslie Harris, a Northwestern University historian and the co-editor of the newly released anthology Slavery and the University, told me that these schools could do more to help black students offset the cost of attending. Harris sees that as the biggest failing of Georgetown’s well-meaning effort to give descendants of the 272 a bump in the admissions process. “It’s not a scholarship; it’s just, ‘We might admit you.’ The students still have to figure out how to pay for it,” Harris said. “I thought it was almost laughable.”

But Harris wants colleges with multibillion-dollar endowments, such as Georgetown and UVA, to stop thinking about just their own bottom line—they could, for example, donate some of their funds to struggling historically black colleges. While the bank accounts at wealthy colleges keep inexorably creeping up, the endowments at the 10 wealthiest HBCUs combined still amount to just one-20th of Harvard’s total funds. But even without a mountain of money, HBCUs are overachievers. Nearly a third of black students who earn a science doctoral degree went to a black college. Xavier University of Louisiana, with just 3,000 undergrads, churns out more black medical-school students than any other college in the country.

“One way that the well-heeled schools could make some repair and address some of these inequalities is to shore up the finances of HBCUs and to think through how to ensure they have better access to fundraising and development,” Harris told me.

Of course, the actions of one college, or even several wealthy schools, cannot wipe away the consequences of three and a half centuries of slavery and state-sanctioned racial subjugation in the U.S. Surely colleges aren’t the lone set of American institutions that have squirmed out of reckoning with their complicity in racism, but they could be better positioned for atonement than a lot of them. As Ta-Nehisi Coates, the author of The Atlantic’s cover story “The Case for Reparations,” said in a conversation with then–Harvard President Drew Gilpin Faust, colleges “have a knowledge that maybe the Chicago Police Department does not have yet”—of where they’ve gone wrong in the past.

If there’s any hope of healing the scars of racial bondage, colleges will almost surely be at the vanguard of that movement. Higher education should have an advantage here: One asset of the Ivory Tower is that it gives those within its confines the opportunity to nurture and grow seemingly heretical ideas that could, one day, become commonplace.

“Many of the schools talk about their history all the time,” Harris said. “But it’s hard for them to look at the legacy of their own wealth. None of us were here when it happened, but we’re all benefiting from it now.”

* This article originally misstated Sam Dubke’s class year.



In the early 1980s, the world of school book fairs was “a highly competitive and very secretive industry,” according to a New York Times article at the time. The fairs numbered in the thousands and spanned the United States. They were put on by a mix of organizers: A few national corporations, about 25 to 30 regional companies, and assorted bookstores.

By the 1990s, one organizer reigned: the Scholastic Corporation. Scholastic, founded in 1920 to publish books and magazines aimed at young readers, had purchased several of its smaller competitors. The company became the largest operator of children’s book fairs in the country, a title it still holds today.

But we’re not here to talk about Scholastic’s business history, and I think you know that. If you’re a young adult who attended elementary school in the United States, I’d guess that when you saw the headline on this story, something deep inside your mind cracked open. With an unmistakable pang of nostalgia, the memory of a Scholastic book fair, with all its concomitant joys, came flooding in.

At the turn of the century, after the availability of dial-up internet but before the widespread use of mobile phones, the euphoria in the weeks before a Scholastic book fair was palpable, like the anticipation before a big holiday. When it was finally time and the doors opened, the drab libraries, auditoriums, and gyms that students moved through every day were transformed, almost as if by magic, into bookstores full of colorful covers, glittery pens and pencils, and cute classroom tchotchkes. Kids were free to roam the fair, to pick up books and sniff their glossy pages, and, if their parents had sent them to school with a few dollar bills, buy them. The thought of selecting a book all by oneself, of exercising a little independence—in such short supply at that age—was delicious.

The experience seems to have lodged in the memory of many of the adults these children became. For some, Scholastic book fairs provided a distinct brand of uncontaminated joy that exists only in childhood. Because of Scholastic’s national reach, pining for that joy can be a collective activity, which makes tweets such as this so popular and painfully relatable:

I’ve spent my whole adult life chasing the high of a scholastic book fair

It is with this high in mind that I walked into a Scholastic book fair at Woodfield Elementary, a school of about 300 students in Gaithersburg, Maryland, a suburb of Washington, D.C. When my tour guides, a pair of regional Scholastic sales representatives, arrived, they led me from the main office, down hallways covered in posters and drawings, to the library. As we approached, my heartbeat quickened in anticipation, just as it did so many years ago. We turned a corner and stepped inside.

For a split second, it felt as if someone had sucked all the air out of the room. This was not the Scholastic book fair I remembered.

It certainly looked like one. Metal bookshelves lined the room, topped with brightly colored banners designating genres—science, adventure, animals. Schoolchildren flitted from section to section, giggling as they went. A person dressed from head to toe as Clifford the Big Red Dog, the star of a well-known Scholastic-made book series, waved his fluffy red paws enthusiastically.

But unlike the fairs I attended in elementary school, the sight was underwhelming. The setup, sparkling and grand in my mind, turned out to be rather plain and small in the bright, fluorescent lighting. I felt a pit of disappointment in my stomach. Memories are notoriously malleable, and my recollection of Scholastic book fairs had become warped over the years. Each time I had thought back fondly on the fairs, I added a coat of rose-colored paint to the experience. Now that magical sheen had been stripped away.

I didn’t say any of this, of course. I came to Woodfield Elementary to interview the kids, not warn them of adulthood’s cruel tendency to render formerly wondrous things mundane. I didn’t have much time to process my reaction anyway, because the students, a group of fourth graders, wanted to give me a tour of the fair and talk about their favorite books.

Charlotte Francke likes Wings of Fire, a fantasy series about dragons. “I completely recommend it,” she said. “I just want them to come out with a second one, because I’m kind of mad at the ending. They killed one of my favorite characters.”

Her classmate Darby Hitt prefers thrillers. “I like mystery books because they leave a mystery every chapter and I get really excited to read the next one,” she said.

The students guided me through the sections. There were Picture Books, for the younger readers; Chapter Books, for older readers ready for some narrative; Friendship Tales, stories of kids and their furry companions; Fearless, stories of adventure and survival; Fun Facts, for a hint of science; and Girl Power!, a section I didn’t remember from my own experience. (A Scholastic representative later told me the section was added in 2017.)

Cassidy Kemensky said she found the book fair easier to navigate than a traditional bookstore such as Barnes & Noble. “It’s very crowded in there, and there’s sections for adults and stuff,” she said.

The selection at book fairs is carefully curated by Scholastic staffers, who receive advance copies of virtually every forthcoming children’s book from many publishers, not just Scholastic, according to Alan Boyko, the president of Scholastic Book Fairs. Before he joined Scholastic in 1988, Boyko ran a business leasing and selling trucks. He soon realized the venture wasn’t as profitable as he’d hoped; there were only so many people who wanted to buy trucks, and customers returned only when they wanted upgrades years later. Boyko decided to use the trucks to sell and distribute books instead, and Scholastic eventually scooped up his business.

The vetting process for the books is quite intense. About 50 staffers pack into a room and start talking. “It’s crazy,” Boyko says. They discuss which books sold and which flopped in previous seasons, present new ones for consideration, and then vote. Boyko says he reads every book that makes it onto the shelves.

Stephanie Brant, the principal of Woodfield Elementary, said Scholastic allows schools to tailor the book selection to their student populations. The majority of students at Brant’s previous school were Hispanic, so she requested more Spanish titles. “I think it’s really important for kids to see themselves in books,” she said.

Brant said that not everyone at Woodfield can afford to buy books at the fair, some of which cost under $5. She uses confidential school records to determine which families may not have the funds. Those students receive a bookmark that they can trade for a book of any price. (The school pays for these by dipping into the proceeds Woodfield receives from the book fairs.) This year, about 20 percent of Woodfield’s students received bookmarks, including one kindergartner who Brant says took home his first book from the fair this year. “We would never have known that he didn’t have a book at home” if he hadn’t come to the fair, Brant said.

Eventually, it was time for the fourth graders to return to class. I asked Clifford, who turned out to be the school’s building-service manager, whether he would remove the head of his costume for an interview. “No, no,” one of the Scholastic reps said. “If any child saw that—it’s way too traumatic.”

That’s when reality set in. The sight of beloved Clifford taking off his head would not traumatize me, because I am not a child and therefore I am not Scholastic’s target audience. I had embarked on the school visit thinking that the magic of the book fairs was timeless, that I would feel the same rush I did as a kid, but I had forgotten to account for the passage of time and what it does to adults.

As I drove away from Woodfield Elementary, a part of me wished I hadn’t come. I missed the dreamy soft lighting of my elementary-school memories. For those of you still chasing the high of a Scholastic book fair, take my advice: Keep chasing. Don’t go back. But if you do—this time, with your own kids—relish the knowledge that their memories will stick with them for years to come.



There’s an enduring myth that the 1954 Brown v. Board of Education decision was “the first step” in the fight to desegregate schools. Rachel Devlin, an associate professor of history at Rutgers University, is looking to upend that myth. A Girl Stands At The Door, her new account of the black girls and teens who laid the groundwork for the historic ruling, draws from interviews and archival research to show that before Linda Brown, a 9-year-old, became the lead plaintiff in the Supreme Court case, a generation of black girls and young women from the Deep South to the Midwest fueled the grassroots crusade to strike down the “separate but equal” doctrine in America’s public schools and colleges.

Before Brown, some dozen lawsuits were filed on behalf of young black women attempting to enroll in all-white schools—and after Brown, black girls, almost exclusively, did the hard labor of walking through all-white mobs and sitting in previously all-white classrooms, with sometimes hostile classmates and teachers, in pursuit of school integration.

I spoke with Devlin about the black youth who led the effort to racially integrate schools and catalyzed the broader anti-segregation movement. The interview that follows has been condensed and edited for length and clarity.

Melinda D. Anderson: A disproportionate number of black girls were at the forefront of the school-desegregation movement from the late ’40s to the mid-’60s. Why were black girls continually chosen to break the color barrier?

Rachel Devlin: Interestingly, there are no written records about why girls were chosen over and over again in individual lawsuits. These choices were made on a level that was not always entirely conscious. Parents would explain why they should file a lawsuit, and girls agreed. Many of them said, “I was willing.” Other parents drafted their daughters, and the young women cooperated, yet most of the young women who participated were fully invested in school desegregation.

The other thing about girls is that they were good at it. To speak to principals and lawyers and the press you have to be poised, you have to be personable and diplomatic, and young black women had these attributes. They dealt with constant verbal and sexual harassment on the streets of southern cities, of northern cities, and they were acutely aware of their self-presentation in public. It was drilled into them as a way to protect their dignity. Also, very few African American girls and young women did not at some point in their lives work in a white home, and they had to learn how to navigate around white people.

But I want to be clear. This was not just about being accommodating—they knew how to stand their ground. Girls were good at combining different forms of bravery; they could be both stubborn and tough, but also project social openness. They had that sense of self-possession that was extremely useful in these situations.

Anderson: You write that the language in the Brown v. Board of Education decision contains “the same moral conviction that inspired black girls to walk up to the doors of white schools and seek to cross the threshold.” In what way are these girls’ untold stories reflected in this landmark ruling?

Devlin: A black girl walking up the steps of a white school and announcing her intentions to go to school with white children was a radical act of social optimism.  Most white people—and a good many African Americans—in the late 1940s and early 1950s believed that white and black children would never be able to learn in an integrated setting. That racial hostility was intractable.

In fact, judges who ruled against these plaintiffs said just that in their decisions. By showing up at the schoolhouse door, these girls were asserting not only their right to attend historically white schools, but that they believed they were capable of sharing a classroom with white students. Their actions and moral clarity reflected their confidence that they and their white peers could coexist in the intimate setting of a school. The Supreme Court decision asserted this same presumption: that it was fitting, right, and possible for children of different races to attend school together in the United States.

Anderson: The battle for school integration sparked bitterness, anger, and even violence. Some of these black girls were elementary-school age. What was the physical and psychological cost of being first?

Devlin: Tessie Prevost-Williams and Leona Tate integrated T.J. Semmes Elementary School in New Orleans, in third grade. Along with Gail Etienne, the three of them received the worst violence that I recorded in the book. Because they were so young and so little, people would punch them, trip them, spit in their food. They said they could hardly go to the bathroom because that was a very dangerous space. It was a war inside the school. Tessie, Leona, and Gail all said it was a living hell.

I think the resilience that these young women had is hard to imagine. One would think that it would have been a crippling experience, but they sensed from a very early age the weight and enormity of what they were doing. They came to understand the notion of sacrifice for social justice. The stamina that it took to survive was fed and reinforced by the magnitude of what they were accomplishing.

I think it’s very hard from a current-day perspective to imagine a child going through that. In some ways we just have to be astonished at what they did. America was effecting social change on the backs of young children, and we have to ask ourselves what this means about political change in this country, that we leaned on young children to do this work of racial reconciliation.

Anderson: You talked to some of these women in your research. How do they view the resegregation of schools today—what some have called the broken promises of Brown v. Board of Education?

Devlin: Of the nearly 30 people that I interviewed, to a person, they still very much believe in what they did. They tend to look at the broader changes that have happened as a result of Brown v. Board, the day-to-day interactions between white and black Americans in a society that is diverse and desegregated. They see a larger tableau that has been fundamentally altered because the schools desegregated—the ripple effects of the Brown decision.

They also understand that people within the black community question desegregation. Some of them have even been the object of complaints: If you hadn’t done this, we would still have all-black schools. But they say it had to be done. Millicent Brown, who was among the first to integrate schools in Charleston, South Carolina, in 1963, put it in a way that’s quite striking: “We could not have apartheid in the schools.”



Updated on April 23, 2018

Online learning has come a long way since the turn of the millennium. It certainly hasn’t displaced traditional colleges, as its biggest proponents said it had the potential to, but it has gained widespread popularity: The number of students in the U.S. enrolled in at least one online course rose from 1.6 million in 2002 to more than 6 million in 2016.

As online learning extends its reach, though, it is starting to run into a major obstacle: There are undeniable advantages, as traditional colleges have long known, to learning in a shared physical space. Recognizing this, some online programs are gradually incorporating elements of the old-school, brick-and-mortar model—just as online retailers such as Bonobos and Warby Parker use relatively small physical outlets to spark sales on their websites and increase customer loyalty. Perhaps the future of higher education sits somewhere between the physical and the digital.

A recent move by the online-degree provider 2U exemplifies this hybrid strategy. The company partnered with WeWork, the co-working firm, to let 2U students enrolled in its programs at universities, such as Georgetown and USC, to use space at any WeWork location to take tests or meet with study groups. “Many of our students have young families,” said Chip Paucek, the CEO and co-founder of 2U. “They can’t pick up and move to a campus, yet often need the facilities of one.”

Students in many of 2U’s degree programs already meet up with each other during yearly class meetings held on campuses, Paucek said, but the WeWork partnership allows for more-consistent in-person gatherings and the potential for new programs, such as architecture, for which physical studio space is required. Paucek is, for someone who runs an online-degree company, remarkably open about the importance of physical space: “The history of online education is a vast underestimation of the power of people,” he told me.

Richard DeMillo, the executive director at the Georgia Institute of Technology’s Center for 21st Century Universities (where I am a visiting scholar paid to research the future of higher education), thinks that some traditional campuses will gradually move toward a similar middle ground. He wouldn’t be surprised if universities start fusing the best of the online experience with the best of the physical experience, possibly like 2U is trying to do with WeWork. “Think of it as the storefront for the university,” DeMillo said.

DeMillo says he’s already seen the physical-digital dichotomy start to dissolve. He remembers when, a few years ago, Georgia Tech launched an online master’s degree in computer science, and students in the program started showing up at university-affiliated events in their hometowns. Some of the online students even traveled to Atlanta for commencement—the first time many of them had ever set foot on the campus. “They wanted to see in person the professors they got to know over video,” DeMillo said. “Students don’t have a problem blending the two experiences, either for efficiency or because they are digital natives.”

Of course, blending learning experiences in this way is not always a smooth, or even feasible, process for many traditional colleges. Most of them are not designed to allow students to take just one course at a time or to toggle between online and face-to-face classes; taking a class on most campuses requires enrolling as a student in a full-fledged degree or certificate program and then choosing to participate exclusively in either online or in-person classes. “While universities have all these resources for lifelong learning, we also have all the constraints in how the model currently works,” said Carissa Carter, the director of teaching experiments at Stanford University’s Hasso Plattner Institute of Design.

In 2014, the d.school, as the Stanford institute is known, sponsored a project in which undergraduates were tasked with rethinking what a college education will look like in 2025. One of the results was a design for a lifelong, on-and-off education experience. It was called the “open loop university” and would admit students for six years of study that could be undertaken at any time. Under this system, students could “loop out” after two years to go work and then “loop in” a few years later, with four years left on the clock if they wanted to try something else. The idea is that students who returned after looping out could use the time that remained to retrain for new careers later in life, whether in their 30s or 50s.

That particular vision is not likely to be realized anytime soon, but some colleges are thinking along similar lines. Several universities, including MIT, Penn, and Boston University, recently started a type of online degree called a “MicroMasters” as a way for students to begin work on a graduate degree without committing to a years-long program. Students who do well and pass a set of proctored exams earn a MicroMasters, equal to somewhere between a quarter and a half of of a typical master’s degree. Top performers can then apply for slots in a full master’s program from the universities, to be worked toward in-person; if accepted, they would be only a semester or two away from finishing a full master’s degree. When MIT launched its MicroMasters, in 2015, it expected 200,000 students would enroll across all programs; within the first nine months, more than 1.3 million people signed up.

Such physical-digital experimentation can even alter the experiences of students already enrolled at physical college campuses. For example, 75 percent of the 56,000 undergraduates at the University of Central Florida, in Orlando, took at least one online class at the school last year, even as they were enrolled in face-to-face courses. (Another 10 percent took a hybrid course, a mix between online and face-to-face.) Nearly a third of the university’s classes take place online, which officials say has eliminated the need to build at least five additional classroom buildings.

For now, though, most short-term or blended-learning programs exist not at universities but in the professional world, with companies running ongoing programs to train their current workers. And, here too, the division between online and face-to-face learning is thinning.

Take Xerox, for example. In the 1970s, the company opened a sprawling campus in the suburbs of Washington, D.C., to train its workforce. Some 1,800 employees came through the facility in any given week for classes. But Xerox sold the campus in 2000, when it began to move its professional-development courses online. It now mixes face-to-face training with more than 10,000 short online videos and other on-demand reference materials. John Leutner, the longtime head of global learning at Xerox who retired in 2016, told me that this arrangement saves the company money and also improves retention because workers can learn on their own time and at their own pace.

Companies also regularly turn to outside help instead of training workers themselves. Employer-financed programs account for about half of the business of General Assembly, a firm that holds classes for coding and other skills. The company can customize its curriculum for companies’ most immediate needs—“unlike in the past when companies sent someone off to a university for graduate school,” said Charlie Schilling, the general manager of the enterprise business at General Assembly. He added, “Someone can take an assessment on a Friday, sit through a part-time data-science class in a week or two weeks depending on their flexibility, and immediately return to their job and do things in new ways.” It is, in a sense, a sped-up version of the open-loop university dreamt up by those Stanford designers.

As the economy continues to ask more and more of workers, it is unlikely that most campuses will be able to afford to expand their physical facilities to keep up with demand. At the same time, online degrees haven’t been able to gain the market share, or in some cases the legitimacy, that their proponents expected. Perhaps a blending of the physical and the digital is the way forward for both.



Three years ago, I sat in a quiet library speaking with a young woman about her experience at the boarding school she attended. She was a senior and she was more than ready to graduate, she explained, because though the school had been coed for years, to her it still felt like the all-boys school it had been for most of its existence.

“Why?” I asked.

“Because it’s all about them. It’s like we’re here for their benefit.”

Teachers and administrators at the school described her as a student leader, a young woman with a promising future. But as I listened to her explain her school’s social hierarchy and culture, her promising future seemed to have less to do with the elite education she’d received than the spirit of survival she had needed to develop in her four years there.

I spoke with the young woman in the library while I was researching a novel about misogyny and rape culture at boarding schools. Her experiences mirrored those coming to light from prep schools across the country. The most prominent recent example, of course, is the allegation from Christine Blasey Ford, who has accused the Supreme Court nominee Brett Kavanaugh of pinning her to a bed and covering her mouth to muffle her screams during a party they both attended when he was a student at Georgetown Prep, an elite boarding school in Washington, D.C.

Once the allegations were made public, defenses of Kavanaugh rolled in quickly, characterizing the event, if it happened, as a youthful indiscretion. All too often people dismiss this kind of behavior as just “boys being boys.” That old adage suggests the behavior is innocent. Kavanaugh himself has joked, “What happens at Georgetown Prep stays at Georgetown Prep.” The subtext is that boys will be boys—and we’re not supposed to talk about what they do.

What some boys do at these elite private schools might be as seemingly benign as pranking a school meeting by performing sexually charged dances. Or it might be, as an alumna from another boarding school detailed to me during my research, a rug in the cafeteria that she said only seniors were allowed to stand on and from which, allegedly, boys called out rankings of the attractiveness of underclass girls on a scale of one to 10 as they walked by. Or, more disturbingly, it might mean forcing a 15-year-old girl to perform oral sex on five members of her school’s hockey team, an incident that reportedly took place at Milton Academy in Massachusetts during the 2004–05 academic year, according to Vanity Fair.

Misogyny is ubiquitous. It is deeply entrenched in these school communities, and yet many young men can’t see the water they’re swimming in for what it is. They seem to have no understanding of the harm this culture of misogyny causes. As one alumnus from St. Paul’s School quipped when he heard about the alleged incident with the ice-hockey players at Milton, “The question is: Did they win?”

The joke I remember most clearly from my own ninth-grade year at an all-boys prep school didn’t come from one of my classmates or an upperclassman. It came from a guidance counselor. He was giving a guest lecture in one of my classes about how to study more effectively, and told a story about a young man who was supposed to be doing his homework but instead looked out the window and watched a girls’ cross-country team run by. The guidance counselor acted out the scene for us with grossly exaggerated caricature, pantomiming the teenager watching the girls’ breasts bounce as they ran by. He laughed when he finished, and all 20 or so of us in the room laughed along with him. This was how he got the guys in the room to trust him. By telling a crass, objectifying joke, yes, but also by implying that we should see women as nothing more than a distraction; we had more important things to do.

Later that same year, I heard a guy in my gym class talking about how to decide which of the two girls who liked him he was going to invite to the dance. It would be the one who would sleep with him, or, as he said, would let him “fuck the shit out of her” and “fuck her brains out.” These were phrases I’d heard so often I’d become numb to their meaning. They only stood out to me because they were said out loud on the soccer field instead of sotto voce at a party.

In my ninth-grade algebra class, one of the students made lewd, sexually suggestive drawings of our math teacher, a woman, and passed them around the room for us to see. Too many of us laughed along with him—that’s probably how he got caught. Our teacher stood over him and shook the paper, chastising him. He started to cry, right there in his seat. He wasn’t used to getting caught.

We were in ninth grade. We were 14 years old. We didn’t know what we were talking about. It was only “boys being boys.” But it was also boys being deeply misogynistic. If this is how we spoke about girls behind their back, how did we think about them later, when they sat next to us at the dance? How men talk about women affects the way men see and relate to women. Violent language can lead to violent action. Just because no women overheard our conversation on the soccer field doesn’t mean that conversation was harmless. We just didn’t have to experience any kind of accountability for the harm it could cause. But cultures of misogyny do have consequences.

In 2016, Chessy Prout told her story of being raped while she was a student at St. Paul’s School in New Hampshire. When the school’s tradition of a senior salute—in which senior boys were in competition with one another to try to sleep with underclass girls—made headlines, there was a national outcry about a school that would allow such a dangerous tradition to continue. And yet, when a reporter for Vice, Susan Zalkind, bumped into the man Prout says raped her, Owen Labrie, on a train to Boston, despite his mandated curfew, he showed no remorse and, in fact, was defiant, calling a Vanity Fair article about him a “hit piece.” (Labrie was convicted of a felony charge of using a computer to solicit a minor for sex.) He was visiting his girlfriend at Harvard and had taken her out to brunch, he told Zalkind. That he was breaking the terms of the court ruling didn’t put him in the wrong, he suggested; the people who were making his life difficult were in the wrong. Though his attitude surprised Zalkind, it echoes the tone offered by school administrators and others who worry about second chances for boys credibly accused of sexual wrongdoing—and suggest that these boys deserve more dignity and agency than their victims.

All too often the schools themselves shelter these boys from a greater understanding of accountability, therefore protecting and tacitly, if not explicitly, endorsing misogyny. These aren’t just boys, the thinking goes; they are future men of influence who will become leaders of one kind or another. The decision of the new president, Reverend James R. Van Dyke, at Kavanaugh’s alma mater to release his recent letter reflects this kind of forward-thinking protectionism. “Prep is a wonderful place, a wonderful school, a wonderful community,” he says in the letter. He didn’t address Kavanaugh, the allegations against him, or any other details that have emerged from his youth. Ignoring these more difficult topics sends a message to the young students of Georgetown Prep who are listening for how their school’s leaders view such grave allegations. Silence can be quite meaningful.

The boys there face a predictable future. The boys who joke about women in locker rooms, the boys who talk about how important it is to try to sleep with a girl after prom, the boys who assault girls, the boys who see women as hindrances to the future they feel entitled to—they all become men. Boys who attend elite prep schools go on to elite colleges. They become government officials, business leaders, possibly even Supreme Court justices. These men carry with them the prejudices, jokes, and attitudes toward women that shape decisions about policy and the general welfare of the public. And some of them never learn, as the young woman in the library told me, that the world they have been given is not all about them.



CAMBRIDGE, Mass. — On Wednesday, the newly minted Harvard president Lawrence Bacow delivered a sober message to the campus community. In less than a week, he said, Harvard would be heading to federal court to defend its use of race in admissions. “This lawsuit has the potential to create divisions on our campus and in our broader alumni community,” he wrote. And on a brisk Sunday here, those divisions were remarkably clear.

One day before the start of the trial, two warring rallies revealed the deep fissures in the Asian American community over affirmative action. Supporters of Harvard’s race-conscious admissions practices—mostly students—began arriving at Harvard Square early Sunday morning. They grabbed prepared signs from a box, hung banners, and slipped on light blue shirts. The message was consistent: “Defend diversity.”

It was important that they made their voices heard, they argued, because this is bigger than Harvard. And they aren’t wrong. This case, the latest in a string of challenges to affirmative action, seems poised to make it all the way to the Supreme Court, and could fundamentally change if and how race can be considered in admissions. The Supreme Court has upheld race-based affirmative action several times over the past 40 years, but as the court has lurched to the right with the appointment of Brett Kavanaugh, the future of the practice is more imperiled now than at any time in recent memory.

Starting today in federal district court, lawyers for a coalition of Asian American students, brought together by the conservative legal strategist Edward Blum and his group. Students for Fair Admissions, will argue that Harvard unfairly caps the number of Asian American students it admits in order to boost the enrollment of other racial groups. It will also argue that the college has not considered alternative strategies to diversify its campus.

Blum has made a career of challenging race-specific policies. He previously spearheaded a case against affirmative-action practices at the University of Texas at Austin, and before that, he instigated Shelby County v. Holder, the landmark case from 2013 that nullified pieces of the Voting Rights Act. Several students at the rally were aware of Blum and his litigious past, arguing that he is using Asian Americans as a cudgel to advance a personal agenda of ending affirmative action in higher education.

The lion’s share of students who had gathered in Harvard Square were themselves Asian American—including students and recent graduates who will testify in support of the university in court. That includes Thang Q. Diep, a senior who submitted portions of his admissions file to the court in an effort to bolster Harvard’s case.

“As an Asian American, I do not believe that Harvard’s race conscious admissions policy hurt me,” Diep wrote in a statement to the court. “I disclosed my race and I did not have stellar grades, but I was accepted to Harvard most likely based on my personal statement, which reflected the diversity that I brought to campus.”

And on Sunday, he forcefully declared why he was standing up for Harvard. “My stance on affirmative action is a general reminder to the rest of America—and especially to Edward Blum,” he said to a chorus of cheers, “that I, along with so many other Asian Americans, refuse to be tools of white supremacy, and that we stand in alliance with all communities of color.”

Diep’s argument is one that has resonated with Asian Americans: According to a survey by AAPI Data, nearly two-thirds of Asian Americans support affirmative-action policies. Yet specifically among Chinese Americans, support for the practice is substantially lower.  And some three miles away, across the Charles River, another group—dominated largely by Chinese Americans—voiced their displeasure with Harvard’s policies.

Unlike the student rally, that event, held in front of the historic Trinity Church, had the markings of a professionally produced rally, such as a surround-sound speaker system, an elevated stage, and metal barriers. And rather than the signs and shirts vowing to “defend diversity,” this rally featured placards decrying affirmative action. “Discrimination in the name of diversity is wrong” was the motto of the gathering, jointly hosted by the Asian American Coalition for Education, or AACE, and Students for Fair Admissions.

Yukong Zhao, the president of AACE, boasted during his speech to a crowd of roughly 250 people that the litigation is sending a message to other schools. “If you don’t stop your discrimination,” Zhao said, “we will file civil-rights complaints against you, we will take you to trial.”

There were notably fewer students at the latter rally. Kelley Babphavong, a junior at Harvard, was a notable exception. Babphavong, whose parents are from Laos, and who spoke at the anti-affirmative-action rally, believes that the Asian American students supporting Harvard aren’t considering the other possible alternatives to race-conscious admissions, such as class-based preferences. (Students for Fair Admissions has enlisted Richard Kahlenberg, a policy analyst at the Century Foundation, a left-leaning think tank, to make this point in court.)

But there are doubts that tipping the scales in favor of socioeconomic diversity will do anything to racially diversify a campus, for a simple reason. As Sue Dynarski, an economist at the University of Michigan, put it, “Most poor people are white. Putting a thumb on the scale for low-income students will help far more white students than black or Hispanic students.”

The dueling rallies on Sunday revved up both sides for the three-week-long battle over Harvard’s admissions practices. “We’re not at war with Harvard, we’re not at war with higher education,” Blum told me. But still, how the case plays out in court could ultimately have major ramifications for whether colleges in places far away from Cambridge will continue to consider race in admissions.



William R. Fitzsimmons leaned in and peeked over his glasses. “I’m not sure I understand your question,” he said into the microphone. It was the second day of arguments in the trial accusing Harvard of discriminating against Asian American applicants, and Harvard’s longtime admissions chief was on the witness stand.

John Hughes, a lawyer for Students for Fair Admissions (SFFA), had been lobbing questions at Fitzsimmons for the better part of the morning. “Would you agree that race is a determinative factor for half of the African Americans?” he asked.

The answer, the plaintiffs argued, was simple. Harvard’s own expert had shown that without race-conscious admissions, the number of black and Latino students would decline dramatically. So he repeated the question once more. Hughes was trying to get Fitzsimmons to admit that race was the reason some students got in and others didn’t.

The trial in federal district court is, for all intents and purposes, the testing ground. Hughes’s line of questioning was as much an attempt to elicit an illuminating response from Fitzsimmons as it was an attempt to gather fodder for what could potentially be a Supreme Court case. The plaintiffs are trying to see which arguments stick, while the defendants are holding the line.

Fitzsimmons didn’t bite. “I’m not sure that I would say determinative,” he said, but he agreed that race, in some instances, helped. The vague answers from Fitzsimmons didn’t satisfy Hughes, who would keep trying again and again to get a concrete answer.

There was a rhythm to the trial: first, a slate of easy questions from the plaintiffs, who then presented a few historical documents—a report from the Education Department’s Office for Civil Rights, and internal reports and emails—before making jabs at the college’s affirmative-action practices.

Harvard—despite at times shaky testimony from their admissions dean—is in the driver’s seat. Yes, it may be true that race is being used as a tip for some students, but the Supreme Court has said that such policies are permissible if the university has tried all other measures of diversifying.

The plaintiffs repeatedly came back to the thorny issue of how Harvard treats legacy admits, recruited athletes, and the children of donors—which did not reflect favorably on the college. In a case that’s garnered so much attention and scrutiny, the battle is at least as much about the public perception of the university’s admissions system as it is about the judge’s. On Wednesday, Harvard’s attorney, William F. Lee, did some damage control, telling reporters that “there are some [children of] donors who get in and some who don’t. No one claims that the admission of donors or donors’ children or donors’ relatives on the dean’s list has any effect on Asian Americans.”

The trial will last for a few more weeks, but Fitzsimmons’s testimony was the big show; it opened up the black box of Harvard’s admissions process to reveal how it chooses students. If SFFA loses this case, it’s almost certain to appeal the decision. (The judge isn’t required to issue a ruling on the final day, so it could be months before a decision is made.) But it’s unclear whether Harvard would appeal the decision if the college were to lose.

It seems that the plaintiffs’ ultimate goal is to take this case to the Supreme Court, which could happen years from now, if history is a guide. But the district-court trial is laying the groundwork. The plaintiffs are testing out their arguments to see which prove most effective. And once their line of attack has been smoothed out, they will likely have a major opportunity to present their arguments before an amenable Supreme Court made up of a majority of justices who are skeptical of affirmative-action policies.



Two surveys last year painted an unambiguous picture: Republicans had soured on higher education. They thought colleges had a negative impact on the country and the “way things were going.” But a new survey shows that Americans’ attitudes towards higher education—regardless of political affiliation—are a little more complex. Not only do Americans value education after high school, many of them—of both political stripes—are willing to have more of their tax dollars support it.

New America, a left-leaning think tank, released on Monday its second annual “Varying Degrees” survey, which examines Americans’ perceptions of higher education. Whether or not people thought higher education was worth the cost varied depending on the type of institution: For-profit colleges fared worse than four-year private colleges among all Americans, which fared worse than four-year public colleges.

But there were some forms of education after high school Americans had no problem getting behind. Eighty-three percent of Republicans and 81 percent of Democrats think community college is worth the cost. And 90 percent of survey respondents—90 percent of those who identified as Democrats and 93 percent of those who identified as Republicans—believe workforce-based skills programs, such as apprenticeships, prepare students for a good standard of living. Fifty-seven percent of Americans on the whole, the survey found, believe that there are good jobs that pay well that do not require college. But when asked whether there are good paying jobs that do not require education after high school, that numbers drops to 47 percent.

What does that mean? Essentially, people see the benefit in higher education, but that doesn’t always mean college. Higher education isn’t a monolithic enterprise, and Americans appreciate that fact. Despite lukewarm feelings about higher education generally, 80 percent of Americans have a positive view of the institutions near them—that often means community colleges. And a little over 80 percent of Americans believe community colleges are worth the cost—the highest mark among “colleges,” according to the survey. On top of that, 90 percent of Americans think that apprenticeships and skills-training programs prepare people for a good standard of living.

There’s a good reason why there are such high marks for those sectors of higher education, Representative Virginia Foxx, the Republican from North Carolina, told me in a recent interview. “There is a lot of nostalgia for what we have called ‘vocational schools’ or ‘trade schools’ in the past because people could lead very successful lives as a result of gaining skills in those programs,” she said. Skilled electricians, plumbers, welders, and so on all served the community and were respected for it, continued Foxx, who is also the former president of Mayland Community College in North Carolina. Those sorts of workforce-education programs still exist, and oftentimes, they are at community colleges—and they are in high demand.

Though, surely, many community colleges have positioned themselves as launchpads to baccalaureate programs, they often offer certificate and credential programs, and are the beneficiary of much of the $114 billion the government spends annually on workforce development and education programs. As my colleague Alia Wong recently wrote, “Community colleges are not just a substantial part of the future of American education—they are also a substantial part of its present.”

The price of college is rising, and even if oftentimes the sticker price doesn’t equal what someone will actually pay, people are questioning whether or not it is worth it. New America’s survey results show that a majority of Americans believe that public colleges, at least, are worth the cost—they are much more skeptical, however, of private colleges. Still, the price may lead people to other, more affordable options with the hope of a good job on the back end.



For 176 years, William Henry Harrison was the only president the University of Pennsylvania had any kind of claim on, and even then it was kind of a stretch. As a student, Harrison did a brief stint at Penn, but he didn’t stay long enough to get a degree. And he only lasted a month in office, dying of pneumonia in April of 1841. Ever since then, Penn has waited, as Harvard, Yale, and other of its Ivy League peers sent alumnus after alumnus to the Oval Office.

Then, in November 2016, Penn’s fortunes changed, when Donald J. Trump, class of ’68, won the presidency. The university, though, has never formally celebrated this accomplishment. On Monday, Penn’s administration convened upward of 20,000 undergraduate and graduate students for commencement, and did what it has been doing for most of the past three years: not talk about Donald Trump. Other things it did not do include having Trump deliver a speech or giving him an honorary degree.

Penn’s officials have been mostly silent about Trump, perhaps because he is not necessarily beloved on campus. Michael Williams, a rising sophomore at Penn studying political science, told me, “All of the conversations, or most of the conversations that I’ve had, and that my peers are having, is, ‘This guy’s a mess.’” Another student I talked to, Eric Hoover, an undergraduate at Wharton who founded a campus pro-life group, said, “I know probably all the people on campus who are pro-Trump, or openly pro-Trump, and it’s not many.”

With the school’s officials reluctant to talk, unease about Penn’s Trump connection has revealed itself in limited but telling glimpses. Shortly before the Republican National Convention in 2016, nearly 4,000 Wharton students, graduates, and relatives signed a petition telling Trump, “You do not represent us.” And The Daily Pennsylvanian, the student newspaper, published a slide late last year that it said the student group responsible for giving tours had used in order to advise guides about navigating potentially fraught interactions with prospective students. The slide, titled “Trump Reminder,” anticipated eventualities such as “Visitor asks about his views” and “Visitor pushes further.” (A student tour guide I talked to told me that visitors had asked questions about Trump before, but that he hadn’t heard of any of those conversations turning sour.)

When I reached out to Penn, the school declined to discuss Trump. (Wharton, one of Penn’s four undergraduate schools, and the one from which Trump graduated, did the same.) “We just don’t comment on individual politicians,” Stephen MacCarthy, Penn’s vice president of university communications, wrote to me in an email. “We are non-partisan, and try to limit any comments in the political sphere to specific issues that have an impact on the University.” That said, in the past, Penn hasn’t hesitated to wade into presidential politics at its graduations. Gerald Ford and Joe Biden both delivered commencement speeches while in office, and Barbara Bush and Hillary Clinton did while their husbands were. Penn officials declined my request to speak with someone about how the school chooses commencement speakers and honorary-degree recipients. The White House didn’t respond to an interview request.

I’m not the only journalist who’s had trouble getting an official comment. Dan Spinelli, who reported on Penn and Trump for The Daily Pennsylvanian, told me about his struggle to get officials to talk on the record. (I went to Penn too, and worked for a magazine that was part of that newspaper.) Spinelli wrote a piece in Politico magazine that described, among other things, an email that administrators sent to Wharton faculty, asking them not to speak to any reporters who wanted to discuss Trump.

Penn’s silence on its most powerful alumnus stands in contrast with how other universities have related to their own presidential (or near-presidential) graduates. George W. Bush was invited to give Yale’s commencement address just months into his first term. And Columbia, the alma mater of Trump’s predecessor, features on its website a giddy post titled “Our Top 10 Obama Highlights.” (“3. Any moment Obama displayed the incredible partnership, respect, and love he has with and for First Lady Michelle Obama.”) And then there is Wellesley’s warm embrace of Hillary Clinton, class of 1969. She spoke at commencement last year, and a page on the school’s website is dedicated to her time at the school.

That it is Penn and not any other Ivy League school now navigating this terrain is additionally awkward—for Penn, perhaps more than its peers, has long had status anxiety. (Its campus bookstore used to sell “Not Penn State” T-shirts, and the school’s rivalry with Princeton, of which the student body is aware but also skeptical, seems aspirational and unrequited.)

Contrast other schools’ webpages with Trump’s digital footprint at upenn.edu. The university only updated its “Penn’s Heads of State or Government” list to include Trump after a Daily Pennsylvanian reporter inquired about the omission three days after Trump’s inauguration. Speaking of which, the school didn’t put out a press release marking that occasion (as Columbia did to mark Obama’s inaugurations in 2009 and 2013). Wharton did, however, publish a post a day ahead of the festivities headlined “Dressing-down: The Fashion Industry’s Reaction to the Trump Inauguration.”

Still, the university hasn’t been completely silent during Trump’s political career. Amy Gutmann, Penn’s president, issued a statement after Election Day in 2016, remarking on the campaign’s divisiveness but not mentioning its newly distinguished alum specifically. “It is my hope that ideals that we hold dear at Penn—inclusion, civic engagement and constructive dialogue—will guide our nation’s new administration,” she said. Gutmann has been mostly silent on Trump since then, but did criticize his order temporarily banning residents of seven majority-Muslim countries from entering the U.S. in January of 2017 and his September 2017 announcement that he planned to end the Deferred Action for Childhood Arrivals (DACA) program.

In her comments on Trump, Gutmann has refrained from drawing directly on her own area of academic expertise—she’s a scholar of democratic discourse. “One of the things that does make Penn unique is that its president is a political philosopher, and a giant in her field,” says Jonathan Zimmerman, who teaches at Penn’s Graduate School of Education. He added, “Most of her work has been about the question of deliberation and discourse in democracy.” Zimmerman noted that he understands the political dynamic that university presidents must navigate, and appreciates why Gutmann has been careful not to say more.

Before Trump became a serious contender for the presidency, Penn made more of its connection to him. He was appointed to Wharton’s Board of Overseers in 1987, and the following year appeared in a video promoting the business school. Trump received an award from Wharton in the fall of 2014, just eight months before announcing his candidacy, and the most favorable recent mention of him as an alum comes in Wharton’s list of “125 Influential People and Ideas” from 2012. In it, Trump’s prominence as a businessman is remarked upon, if not exactly endorsed. (“Trump’s style has produced doubters, but no one could deny his ability to brand his products, and to rise, phoenix-like, from everything from corporate travails to satire.”) But these days, his presence on Penn’s website is limited to short posts promoting professors’ political takes, like “It’s not just that President Trump lies—it’s how”—the sort of regular political commentary that could come from any school, a connection to their particular campus notwithstanding.

Other alumni with notable political careers have received a different sort of treatment from the university. Jay Clayton, who holds a bachelor’s and a law degree from Penn and is the Trump-appointed chairman of the Securities and Exchange Commission, is still listed as an adjunct professor at Penn’s law school. Neel Kashkari, who now runs the Minneapolis branch of the Federal Reserve and has an MBA from Wharton, delivered a speech at a graduation ceremony at the business school’s San Francisco campus in 2014, when he was a candidate for governor in California. And Deputy Attorney General Rod Rosenstein, Wharton Class of ’86, gave a talk on campus last fall titled “Ethics, Business And The Rule Of Law.”

Penn’s lukewarm feelings toward the president are not, apparently, reciprocated. Trump regularly talks up his connection to Wharton: By the Daily Pennsylvanian’s count, he publicly mentioned the business school more than 50 times between the beginning of his campaign and January 2018. As Barbara Perry, the director of presidential studies at the University of Virginia’s Miller Center, told me, Wharton’s prestige is useful to Trump, as it supports the narrative that he is intelligent and only settles for the best.

Other modern presidents have made similar calculations about the stories they want to tell. “For [Bill] Clinton, at Georgetown, that works for his narrative of the boy from the other side of the tracks of Arkansas, raised Southern Baptist, but goes to Georgetown”—which has an excellent reputation for political science and foreign relations—“in order to work in government,” Perry said. The relationship between Obama and Columbia is not as straightforward. “Obama’s time in New York didn’t have the impact on him that Chicago or Hawaii did,” Perry said, and Columbia did not play as well with the “up-by-his-bootstraps community organizer” image he wanted to promote. So, she said, “He didn’t talk about [Columbia] much in his memoir.”

Perry says that she’ll be interested to see, years down the line, if Penn adjusts its stance toward Trump, a question that will surely turn on how he is viewed by scholars and the public more generally in the years and decades ahead. “What will [Penn] do?” she wonders. “Will they not want to claim him because of all these personal and professional foibles of his?”

It’s the example of another president with a few foibles that may prove the most instructive here: Whittier College’s relationship with its own most famous alumnus, Richard Nixon. Nixon graduated from Whittier, a small liberal-arts school in Southern California, in 1934. He was beloved on a campus of then only about 400 students, excelling at debate and drama. He joined the school’s board of trustees in his 20s, when he was an attorney, and then delivered two commencement addresses in the ’50s as vice president.

Many students and alumni were thrilled when he was elected president, and the town of Whittier vied to be the location of his presidential library. The school’s pride was enduring: “Even while the Senate Watergate Committee hearings were being televised live in May of 1973, more than 1,000 of Whittier College’s 1,600 students signed a petition for the Nixon Library to be located in Whittier,” said Ken Hughes, a historian also at UVA’s Miller Center.

But in the years after Nixon’s resignation in 1974, alumni, faculty, and students grew ambivalent and generally became less vocal about the connection. Joe Dmohowski, a serials and electronic-resources librarian at Whittier, told me about how, in the ’80s, the school’s president was stuck trying to figure out a way to solicit donations from both alumni who despised Nixon and alumni who remained loyal to him.

But now, perhaps because Nixon’s downfall is so distant in time, the school has cautiously laid claim to his legacy. It awards Nixon Fellowships to promising undergrads, and Dmohowski said the school’s current president has attended events at the Nixon Library.

At Penn, one has to look hard for any indication of Trump’s one-time presence. The only marker on campus bearing his name, according to Spinelli, the Daily Pennsylvanian reporter, is a plaque in a nondescript study room in the school’s main library; Trump’s name is listed among other donors from the class of 1968 who funded it. Nixon’s presence at Whittier is rich by comparison. There is a small memorial to him near the library; inside the building, the Nixon Room contains gifts he received while traveling the world as vice president, including daggers from Morocco and a 17th-century suit of armor from Japan. A half century is a long time—and perhaps Penn will someday find the right space for the dedication of a Trump Room. Or, depending on how things go, an enormous tower, taller than anything else on campus.



One demand of the striking Oklahoma teachers has gotten a lot of attention: They want higher salaries. Superficially that demand may seem like a somewhat selfish concern—a question of their own bank accounts, not students’ needs. But the teachers’ complaints go far beyond compensation, and when viewed in the context of their other demands, it’s clear that the strike gets at the heart of some of the biggest issues facing America’s children: access to effective teachers, high-quality learning materials, and modern facilities.

Thousands of teachers returned to the picket lines on Tuesday in their effort to secure more education funding from state legislators, forcing the cancellation of classes for public-school students in Oklahoma City and Tulsa. The picketing marked the continuation of a strike that kicked off on Monday, when tens of thousands of educators in about a third of Oklahoma’s school districts walked out, affecting 300,000 of the state’s 500,000 students.

The Oklahoma legislature last week passed a bill raising teacher salaries by $6,000 on average and restoring education funding by $50 million, but educators say it’s not enough given the cuts they’ve contended with in recent years. They are asking for $10,000 more per teacher over the next several years and $200 million in restored education funding. The legislature had been cutting education spending for years, with the amount of per-student funding dropping by nearly 30 percent (when adjusted for inflation) over the past decade, according to the liberal Center on Budget and Policy Priorities. Oklahoma leads the nation in inflation-adjusted cuts to education funding since the 2008 recession.

The situation has gotten so bad that schools have suffered from chronic textbook shortages and dilapidated facilities; some news coverage has recounted stories of severely outdated, damaged teaching materials and school buildings whose broken heating systems leave students shivering in the winter. Alexia Campbell, a reporter at Vox, tweeted photos showing deteriorated textbooks. Many districts have had to shorten their weeks to four days because they can’t keep campuses running all five days.

“Why are we here today?” one teacher, Dionne Liebl, asked a crowd gathered at the Oklahoma City capitol on Monday, according to CNN. “We are here today because our schools, our children need us.”

The Oklahoma teachers’ strike has a lot in common with an earlier strike last month in West Virginia, where classrooms across all of its 55 counties were shuttered for nine school days. Like West Virginia’s teachers, educators in Oklahoma are demanding higher pay and better benefits—but they’re also similarly driven by an underlying mission to improve the quality of public education offered in their state.

That latter goal is key to understanding the Oklahoma teachers’ walkout—which, at least for some districts, is poised to last at least a few more days—as well as that in West Virginia. In these states (and potentially others yet to come), a strike may be the most effective pathway for securing more investment in public schools and creating educational equity.

As Joshua Weishart, an associate professor of law and policy at West Virginia University whose research centers on education law, told me last month, coordinated teacher demonstrations, such as picketing, are emerging as one of the dominant ways for a society to decide what public education will be. Historically, the courts have led the way on that conversation, mandating certain funding levels or desegregation, but the judiciary has in recent decades retreated from that role. “So what do the people do when the courts are reluctant to intervene and the other branches of government have failed them for so long?” Weishart asked. “They either quietly accept their fate or they publicly resist and demand change.”

Other states may soon see similar fights. For example, in Arizona, which according to data from the National Education Association in 2016 reported some of the lowest per-student spending in the country, educators want a 20 percent pay raise and the restoration of funding cuts. But so far state policymakers have shown little willingness to heed the demands. Teachers in Arizona have also been campaigning for a ballot measure that would increase the sales tax for education.

In Kentucky as well, educators have been demonstrating, with teachers across 29 districts staging a sickout on Friday and convening at the state capitol. The protests there have explicitly focused on prospective negative changes to teachers’ retirement benefits, but educators have made it clear that better teacher compensation is intertwined with school quality. A proposal to reform Kentucky’s pension system would reduce benefits for current and future retirees, and the local teachers’ union says the plan would incentivize qualified educators to leave the state. “We are heavy on people that are eligible to retire. And we are heavy on people that have five years or less of experience,” Kentucky Education Association President Stephanie Winkler told the Lexington Herald Leader last fall. “If all those people retire and all those people leave the profession because they’ve had a promise broken to them, there will be nobody left to educate our children if this proposal comes to fruition as presented.”

Indeed, as West Virginia’s educators made clear, teacher compensation can’t be divorced from educational quality; livable wages are needed to attract and retain qualified teachers. Politicians “are fussing about test scores,” Rebecca Lindsey, a kindergarten teacher in West Virginia, told me last February. “Well, you need to put qualified educators in the classroom if you want your test scores to go up.”



For many years, Wisconsin had one of the finest public-university systems in the country. It was built on an idea: that the university’s influence should not end at the campus’s borders, that professors—and the students they taught—should “search for truth” to help state legislators write laws, aid the community with technical skills, and generally improve the quality of life across the state.

Many people attribute the Wisconsin Idea, as it is known, to Charles Van Hise, the president of the University of Wisconsin from 1903 to 1918. “I shall never be content until the beneficent influence of the University reaches every family of the state,” Hise said in an address in 1905. “If our beloved institution reaches this ideal it will be the first perfect state university.” His idea was written into the mission of the state’s university system, and over time that system became a model for what public higher education could be.

But the backbone of the idea almost went away in 2015, when Governor Scott Walker released his administration’s budget proposal, which included a change to the university’s mission. The Wisconsin Idea would be tweaked. The “search for truth” would be cut in favor of a charge to “meet the state’s workforce needs.”

To those outside Wisconsin, the proposed change might have seemed small. After all, what’s so bad about an educational system that propels people into a high-tech economy? But to many Wisconsinites, the change struck at the heart of the state’s identity. They argued that the idea—with its core tenets of truth, public service, and “improving the human condition”—is what makes Wisconsin, Wisconsin.

Walker ultimately scrapped his attempt to alter the Wisconsin Idea, claiming that his administration hadn’t meant to change it, that it was just a “drafting error.” And so the Wisconsin Idea was preserved—at least in an official sense. But though the words survived intact, many Wisconsinites believe that in the years since, the change Walker had proposed has taken place nevertheless. And one of the state’s institutions, the University of Wisconsin at Stevens Point, is the epicenter of that change.

In mid-November, the university announced its plans to stop offering six liberal-arts majors, including geography, geology, French, German, two- and three-dimensional art, and history. The plan stunned observers, many of whom argued that at a time when Nazism is resurgent, society needs for people to know history, even if the economy might not. But the university said it just was not possible: After decades of budget cuts, the most extreme of which came under Walker, Stevens Point no longer had the resources to sustain these six majors.

The state's recent gubernatorial election showed that millions of Wisconsinites want to preserve the values the university system has long embodied. The governor-elect, Tony Evers, won his race in part because he campaigned on reclaiming Wisconsin’s status as a standard-bearer for higher education. But Evers has a fight ahead of him: The state's Republican-controlled legislature has made it abundantly clear that they are not about to cooperate with Evers’s agenda.  Despite Evers’s election, the Wisconsin Idea may not live for much longer.  How Wisconsin got here—and whether it will get out—is a story that reveals the tensions of a state that feels it must choose between the needs of a tech-hungry economy and those of a uninformed civil society, and is going to somehow try and satisfy both.

In November 2017, Lee Willis wasn’t terribly concerned. The chairs of each department at the University of Wisconsin at Stevens Point were assessing their programs ahead of a biweekly meeting with the dean; Willis, the chair of the history department, may not have been feeling great, but he was at least upbeat. “I felt like the department had really diversified its curriculum in a way to shore us up,” he told me. The department offered a history major, and much of the coursework for an interdisciplinary major in international relations and a social-science major for those pursuing a teaching certificate.

The college, alongside the rest of the UW system, was facing major budget cuts. The state was spending nearly 23 percent fewer inflation-adjusted dollars per student than it had a decade earlier, according to the Center on Budget and Policy Priorities (CBPP). On top of that, a tuition freeze was in place—which was good for students, but tough for an institution that somehow needed to fund its programs.

Colleges in this situation have little choice but to start cutting, Michael Mitchell, a policy analyst at CBPP, told me. Many institutions have to consolidate programs, restrict course offerings, stop hiring, furlough staff, transition some faculty from tenure track to adjunct positions, and reduce campus services that students rely on, such as mental-health services or library hours, Mitchell said. Flagship campuses, such as the University of Wisconsin at Madison, are usually safe, but not the Stevens Points of the world.

That’s the position the university found itself in during the 2017 chairs’ meeting. By that point, administrators had already broken down the number of students enrolled as majors in each department—at least those aside from the STEM fields, Willis said. Sure, there may have been signs of trouble for his program before, Willis said, that should have raised his concern, but that meeting was when he thought, for sure: “They’ve got us marked.”

In March 2018, the school’s administration offered a proposal to deal with the deficit. Cuts were necessary, the administration said. Liberal-arts staples such as English, philosophy, political science, and history would have to be eliminated. All told, the university planned to get rid of 13 majors. Not enough students were enrolled in them to make them worth the cost, the university argued. “We’re facing some changing enrollment behaviors,” Greg Summers, the provost and vice chancellor at Stevens Point, told me. “And students are far more cost-conscious than they used to be.”

Instead, administrators wanted to focus the school’s limited resources on the academic areas that students were flocking to and that the state’s economy could use straightaway—though they maintained that the liberal arts more generally would remain central to the curriculum, even if these specific majors were gone. “We remain committed to ensuring every student who graduates from UW-Stevens Point is thoroughly grounded in the liberal arts, as well as prepared for a successful career path,” Bernie Patterson, the institution’s chancellor, said in a message to the campus. The changes would reflect “a national move among students towards career pathways,” administrators argued. The proposal planned to add majors in chemical engineering, computer-information systems, conservation-law enforcement, finance, fire science, graphic design, management, and marketing. By focusing more on fields that led directly to careers, the school could better provide what businesses wanted—and students, in theory, would have an easier time finding jobs and career success.

Faculty members had been expecting cuts, but nothing nearly that severe. “I was personally surprised about the radicalness of the change,” Ed Miller, a political-science professor at the university, told Wisconsin Public Radio. “We do live in a democracy, and universities are supposed to be preparing people to participate in a democracy, besides participate in the workforce, although that’s certainly important.”

But beyond that, Thomas O’Guinn, a professor at the University of Wisconsin at Madison, told me, the changes flew smack in the face of the Wisconsin Idea. “The idea that we would just forsake everything for [career-focused schools] is not a Wisconsin Idea thing at all,” he said.

Fierce backlash to the proposal from students, faculty, and alumni pushed the administration to reconsider its original plan. By the time the final proposal was released in mid-November 2018, it was less expansive, though still forceful. Six programs would be cut, including the history major. The university seemed to be eyeing degree programs with low numbers of graduates, and nationally, the number of graduates from bachelor’s programs in history has had the steepest decline of any major in recent years, according to the National Center for Education Statistics.

If the proposal, which is now in the middle of a public-comment period, is finalized, history classes will still be offered, but Willis said that cutting the major may ultimately lead to a reduction of staff and upper-level courses, such as the spring seminar on the Holocaust and its major’s emphasis on race and ethnicity. To Willis, this isn’t just an educational loss, but a societal one as well. “You never know when a historical metaphor is going to arise,” he quipped, pointing to the recent incident in Baraboo, Wisconsin, where high-school students gestured the Nazi salute in a photo.

The words of the Wisconsin Idea haven’t changed, but the administration is gutting it in favor of career education, Willis said. “I feel like the liberal arts are sort of being asked to line up behind job preparation,” he told me, “rather than studying the liberal arts for the liberal arts’ sake as a public good.”

Greg Summers is an environmental historian by trade. He received his doctorate at Madison, and he has worked at Stevens Point his entire career, starting in 2001. But it wasn’t his own department—the history department—that led him to the university.

Instead, Stevens Point’s renowned College of Natural Resources drew him in. The college produces many of the state’s foresters, wildlife managers, and environmental engineers. “I came here wanting to make sure that every one of those folks that we trained in the College of Natural Resources were going to go out with an understanding that history mattered,” Summers said, “and that it was relevant to their professional work.” Many colleges, he argues, fail to give their STEM grads that broader understanding, due in large part to the general-education curriculum.

“We hear a lot from employers that they don’t want to choose between graduates who have some technical ability versus a graduate who has a liberal-arts major,” Summers said. “They really want both of those things.” He said he’s working to position Stevens Point to provide that balance. “We’re trying to search for ways to better integrate the liberal-arts education that we have always provided into all of our majors,” he said, so that students don’t have to choose between a major in the liberal arts and “a major that doesn’t really engage them meaningfully.” Essentially, he said, selecting a major in the hopes of getting a job shouldn’t prevent a student from receiving a basic liberal-arts education.

But he’s had a hard time getting faculty on board with the administration’s way of achieving that goal. Late last month, more than 100 current and former faculty and staff at the university called for the removal of Summers as well as Chancellor Bernie Patterson. “While Provost Summers was hiring more faculty than he now thinks we can afford, UWSP undertook a lengthy strategic planning process.” they wrote. “But excellent adjectives, no matter how elegantly arrayed, do not constitute a strategic plan. Instead of being guided by a consistent vision, UWSP’s leadership has instead been erratic, misguided, and in some cases even incompetent.”

Summers, however, argues that the strategy isn’t reactive—or inconsistent, for that matter. Instead, he said, the university is trying to think “10 years down the road,” to what the students and the state will need. The demand, Summers said, “is coming from working adults on college campuses who cannot come to campus on Tuesday morning at 10 to attend a three-credit class, and who may not be looking for a full-fledged baccalaureate degree.” Rather, “they might be in need of knowledge and learning and professional advancement,” he told me. Besides, he argued, “too often when people have these conversations, they tend to conflate the value of the major with the value of the discipline.” This isn’t an attack on the liberal arts, he said, but a push to open up liberal-arts courses to more students in significant ways.

Summers, too, lays claim to the Wisconsin Idea, and has proposed an “Institute for the Wisconsin Idea” that will serve as the hub that generates a revamped general-education curriculum. “We want to really give [the institute] first priority at defining the curriculum in the most meaningful way we can for our students and making sure it’s integrated with their chosen professional pathway,” he said.

“We need to make sure that knowledge is relevant, and it’s applied,” he said. The university’s competitiveness in the future higher-education market depends on it.

Both Willis and Summers agree on one critical point: What happens in Wisconsin could become a model for higher education across the country. What divides them is whether that would be a good thing.

One thing is sure, however: Financial realities such as those facing Stevens Point are not far off for many regional institutions. “The reality is that we just can’t be everything to everyone, regardless of the public-good value of some of the coursework,” Summers said. “Those constraints are very real.” There are few encouraging signs—if any—that states will once again pump dollars into state colleges to get them back to 2008 levels and, as Mitchell of the Center on Budget and Policy Priorities notes, those levels still were not enough to make college affordable for most students.

But as much as this is a tale of a resource-strapped institution, it’s also a tale of something else—something that has nothing to do with the school’s budget and everything to do with the state of higher education in the 21st century. And that’s because even if the state were to miraculously open the coffers for state institutions, Summers said he would likely still eliminate the history major and others in favor of more focus on STEM fields bolstered by a broader general-education curriculum.

“If we suddenly received more dollars,” he told me, “we’d have to ask some pretty hard questions about where we’d want to invest those dollars—and again, I’d point to enrollment figures.” If the demand is for the fields with clearly prescribed career pathways, that’s where the resources should flow, he said. “We are obligated to make sure that we’re serving those students in the best way possible, and for that money, we need to focus on the liberal-arts core curriculum of the university,” he told me.

To Willis, this sounds like the manifestation of Scott Walker’s 2015 plan, shirking the “search for truth” in favor of meeting economic needs. “I think that’s what our administration is thinking about,” he said, “that our role here in central Wisconsin is to anticipate what jobs are going to be needed and to develop programs accordingly." The problem, he fears, is that that alone will never be enough.

The national conversation around higher education is shifting, raising doubts about whether the liberal arts—as we have come to know them—are built to survive a tech-hungry economy.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

At least 2,000 children have now been forcibly separated from their parents by the United States government. Their stories are wrenching. Antar Davidson, a former youth-care worker at an Arizona shelter, described to the Los Angeles Times children “huddled together, tears streaming down their faces,” because they believed that their parents were dead. Natalia Cornelio, an attorney with the Texas Human Rights Project, told CNN about a Honduran mother whose child had been ripped away from her while she was breastfeeding. “Inside an old warehouse in South Texas, hundreds of children wait in a series of cages created by metal fencing,” the Associated Press reported. “One cage had 20 children inside.”

On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.

About 65 million years ago, shortly after the time of the dinosaurs, a new critter popped up on the evolutionary scene. This “scampering animal,” as researchers described it, was likely small, ate bugs, and had a furry tail. It looked, according to artistic renderings, like an especially aggressive New York City rat. And it had a placenta, an organ that grows deep into the maternal body in order to nourish the fetus during pregnancy.

The rodentlike thing would become the common ancestor of the world’s placental mammals, with descendants that include whales, bats, dogs, and humans, among many other species. And today, the placenta might hold the key to one of the most enduring mysteries in human medicine: Why do women suffer much higher rates of autoimmune disease than men do?

Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

There’s a moment about 15 minutes into the first episode of Years and Years that made me gasp at its audacity, its prescience, its visual horror. The new six-part series from the British writer Russell T. Davies (Doctor Who, A Very English Scandal) charts the life of the Lyons family over the course of 15 years, starting in 2019 and ending in 2034. It’s a kitchen-sink saga that barrels its way through births and marriages and betrayals, but also through the near-future. In 2024, Stephen Lyons (played by Rory Kinnear), a financial adviser, is at home with his wife, Celeste (T’nia Miller), both rushing their way through the morning routine. When the camera turns to their teenage daughter Bethany (Lydia West), her face isn’t recognizably human. Instead, she looks like a 3-D version of a Snapchat puppy, with vast cartoon eyes, wagging pink ears, and a brown snout. When she talks, her voice is grotesquely distorted, a robotic hallucination of a child’s cadence. “I might have to start limiting filter time,” Celeste says in the same exasperated, noncommittal way that you might think, I really should spend less time on Twitter.



For many students, the path toward enrolling in a for-profit college starts with an advertisement—maybe while browsing online or watching a favorite television show. Either way, the message is usually the same: Get off the couch and do something with your life.

The ads feature compelling and relatable stories: A young—or perhaps middle-aged—African-American stuck in a dead-end job and looking for change. A single mother trying to provide a better life for her children. A military veteran contemplating next steps after returning home. When prospective students stumble upon ads that catch their eye, they might make a quick phone call or send an email for a brochure.

And then they are inundated with messages to enroll: Calls, emails, and maybe even texts. “It’s just a full court press,” Robin Howarth, a researcher at the Center for Responsible Lending, told me. “Even if they were being very clear that they were just in the early stages of thinking about college.”

On Wednesday, the center released an extensive report on how for-profit colleges recruit students to enroll and then often leave them swimming in debt. In nine focus groups, the center had students who took on debt to attend a for-profit college describe their experiences, from enrollment to paying off their loans.  

The focus groups were conducted last summer in Orlando, Florida, and the researchers say that the lingering debt accumulated by these students is partly the result of Florida’s lax regulations on for-profit colleges. An environment, they say, that may reflect where the nation is headed as the Trump administration rolls back Obama-era regulations aimed specifically at reining in abusive behavior in the for-profit sector.

For students, it’s hard to duck the barrage of ads forever. “They bugged the crap out of me,” said one former student. “[They were] so persistent that there is no way I wouldn’t have started.” But it wasn’t just the persistence of for-profit colleges that roped students in. Their degree offerings connected with students’ interests, with the potential to put them on the fast-track to a more lucrative career.

Research has shown that for-profit colleges disproportionately enroll black students, single parents, and older students. On its face, that seems like a good thing, since it means increased access to higher education. But for-profits tend to be more expensive, have lower six-year graduation rates, and lead students to take out more loans that they are more likely to default on. Yet, despite all the red flags, students described the process for enrolling in the institutions as virtually seamless—“frictionless,” even.

Once students were accepted and were given financial aid packages—which, for low-income students, consisted of Pell Grants from the government—they were sometimes encouraged to borrow more than they needed. That extra money, the schools would say, was for computers, audio equipment, or other things that could set the students up on the path for success. Other times, it was so that the student could live—providing for basic needs—while going to school.

But there are federal limits on how much students can borrow and how many times they can receive Pell Grants. So, federal funding can dry up for students who may have previously exhausted a portion of their Pell Grants at a different institution. And that means paying for college out of their own pockets by cobbling together money from relatives or taking out more loans.

At traditional four-year colleges, students typically accumulate debt and then are able to pay it off after they graduate. But as Tressie McMillan Cottom, a sociologist at Virginia Commonwealth University, wrote in this magazine, “The more likely story [at for-profits] is the student who finishes with high debt or more debt than their salary can absorb—say, a nursing assistant. Or, the student who doesn’t finish, is perhaps the most vulnerable of all students. She has debt, no degree, and all the burdens that made her likely to attend a for-profit college in the first place.” The latter, students who have little to show for their time in college besides a pile of debt, were common in the focus groups.

Now, of course, there were success cases. The school leader who was promised consideration for a better job if she went back to college for a credential that an area for-profit was offering, or the store manager whose company promised her a promotion. But even those students wound up with heavy debt burdens.

After students rack up the debt, they often don’t know what to do with it. Several of them reported being unaware of arrangements like income-based repayment, which allow borrowers to repay their loans at a lower rate based on the amount of money they make. And even the students who were aware of income-based repayment were skeptical. They’d received calls from loan servicers, debt consolidation firms, and school default managers, and had a hard time parsing what was legitimate. Besides, they argued, if their loans were in deferment or forbearance—and they were not paying anything at the moment—it’s easier to keep deferring the debt for as long as possible even if that means paying more money in the long term.

For the borrowers who were eager to pay off the debt, paperwork often held them back. “All the paperwork is tiring,” one borrower said, according to the report. “I have two toddlers and I work 10 hours a day and everything is overwhelming.”

That’s how a lot of the students felt, Howarth told me. The debt burden was like a weight, one they hoped they didn’t pass down to their children. They had hoped attending college—getting a degree or credential—would help them out of a intergenerational cycle of low wages and little to no wealth. But they now feared attending college had subjected their kids to just that.



Michael Bloomberg, the billionaire philanthropist, announced a double-take-causing donation to Johns Hopkins University on Sunday. The former mayor said he would be giving $1.8 billion to his alma mater. It’s the largest single donation to an American university in history—and the continuation of a trend for Bloomberg, who has made a habit of donating to Johns Hopkins.

Several reports and observers heralded the gift as transformational, one that would allow the university to go need-blind permanently—meaning a student’s ability to pay would have no bearing on admissions decisions. “I want to be sure the school that gave me a chance will be able to permanently open that same door of opportunity for generations of talented students, regardless of their ability to pay,” Bloomberg wrote in The New York Times, announcing the gift. The donation to Hopkins is earmarked for financial aid for low- and middle-income students. “It will ease the burden of student debt for many graduates,” Bloomberg wrote. “And it will help open up the American dream to more young people.”

But there’s often an asterisk next to large donations to elite institutions such as this one. How transformational can they really be? Johns Hopkins, Harvard, Yale, and other such colleges have incredibly low acceptance rates—and so the transformational donations, no matter how large, can affect only a relatively small number of students.

Of course, what puts Bloomberg’s gift in a class of its own is not only its size but also its intent. In being earmarked for aid for low- and middle-income students, says Ted Mitchell, the president of the American Council on Education, it highlights the need for colleges to support those students. “This gift is identifying the sore points in the system where we need to do better in order to help students succeed,” he says. Not only through philanthropy, but also in public policy.

Yes, donations such as Bloomberg’s help institutions provide aid to low- and middle-income students. And that in turn may enhance the schools’ ability to enroll more of those students. But it’s important to understand the scale of the solution. Johns Hopkins and other selective, elite universities enroll a small proportion of the roughly 13.3 million students attending four-year institutions. Hopkins, for example, enrolled 1,319 new students this fall, and each year, there are roughly 5,500 undergraduate students. Most higher-education students are enrolled in public institutions, where state funding is drying up, and transformational philanthropic gifts are rarer. Perhaps the money could have a bigger impact if it were dispersed among institutions that need it more.

Of course, wealthy people can do what they want with their money. Often big gifts are donated to institutions by alumni. And Bloomberg’s continued philanthropy to an institution whose profile has been raised alongside his giving offers a lesson: that institutions can hit the lottery if they have one graduate who strikes it big. As Walter Kimbrough, the president of Dillard University, wrote in 2015, following another largest donation ever—to Harvard University, from John Paulson: “Paulson and Harvard only need to say that Harvard is his university, nurtured him, and he is blessed to do whatever he can for something he loves like family … This is in fact the best, most succinct and sincere answer they can and should give.”

Still, there are examples of what such a large gift could do for a smaller institution. Rowan University, a public research university in New Jersey, for example, received a $100 million donation from Henry and Betty Rowan in 1992, and has since doubled its enrollment (and changed its name to honor the Rowans—it used to be called Glassboro State College).

Bloomberg’s donation puts Hopkins in a class with other selective institutions, such as Harvard, Yale, and Princeton, in terms of making highly selective education affordable for low-income students. But those institutions that are still struggling—such as the public regional colleges reliant on state funding that is becoming scarcer, and the students who attend them—are still waiting for their transformations.

It’s possible that Bloomberg’s donation will open the door for more philanthropists to best him. But history has shown that such donations have time and again gone to wealthy institutions. Maybe Mark Zuckerberg or Jeff Bezos will sink $2 billion into an institution. But if they donated that money to their alma maters, it’d be much the same situation. Zuckerberg went to Harvard, and Bezos went to Princeton.



There’s a small burst of air that explodes from every clap. And when hundreds of people are clapping in unison, it begins to feel like a breeze—one that was pulsing through the Phelps Stokes Chapel at Berea College in Kentucky. The students and staff that had gathered here were stomping, clapping, and singing along, as they were led in a rendition of the Civil Rights era anthem, “Ain’t Gonna Let Nobody Turn Me Around.”

They had packed into the wood-framed building for a convocation address, where the speaker, Diane White-Clayton, would be talking about “Jesus, the Ultimate Rebel with a Cause.” Berea does not have a sectarian affiliation, but the remnants of its Christian foundation are readily apparent—so much so that, as Alicestyne Turley, a history professor at the college, told me, “we have students who come here who think they’re coming to a Christian college,” à la Liberty University or Notre Dame.

White’s address was dotted with the markings of a Sunday sermon—not the stuffy kind, but the kind I’d heard time and again growing up—the jokes, the whooping, the lessons that come in threes. In her speech, White explained to the students that it didn't take supernatural abilities to do great things—only a purpose—and that all the evidence they needed could be found on the campus where they stood.

Listen to current Berea students sing “Ain’t Gonna Let Nobody Turn Me Around:”



Berea College isn’t like most other colleges. It was founded in 1855 by a Presbyterian minister who was an abolitionist. It was the first integrated, co-educational college in the South. And it has not charged students tuition since 1892. Every student on campus works, and its labor program is like work-study on steroids. The work includes everyday tasks such as janitorial services, but older students are often assigned jobs aligned to their academic program, and work on things such as web production or managing volunteer programs. And students receive a physical check for their labor that can go toward housing and living expenses. Forty-five percent of graduates have no debt, and the ones who do have an average of less than $7,000 in debt, according to Luke Hodson, the college’s director of admissions.

On top of all of that: More than 90 percent of Berea College students are eligible to receive the Pell Grant—often used as a proxy for low-income enrollment. Most of those students, 70 percent to be exact, are from Appalachia—where nearly one of every five people live below the poverty line. And that recruiting pipeline in Appalachia produces a rather diverse class—more than 40 percent of the student body identify as racial minorities.

Every couple of years, Berea College makes national news, often for its tuition-free promise—a promise that has become all the more noteworthy as the national student debt crisis has grown. But late last year, Berea College made headlines for a different reason: a provision in the Republican-led tax reform effort that would have charged colleges with large endowments a 1.4 percent tax on the investment earnings from their endowments.

Berea has a $1.2 billion endowment—which is how it can afford to cover the tuition of every student—and the school estimated that the tax would cost it upwards of a million dollars a year, effectively forcing it to cut back on the number of students admitted. The rebuke came quickly from both sides of the aisle. Democrats argued that it was an example of Republican mismanagement of the entire tax debate, and Republicans painted the debacle as Democrats holding a worthy college hostage. It was a point of order raised by Senator Bernie Sanders, Republicans argued, that prevented Berea from being exempt from the tax in the initial bill. Higher education leaders—even notable Republicans such as the Bush-era education secretary Margaret Spellings—were skeptical of the tax. The tax’s goal was ostensibly to punish colleges for amassing large endowments as the cost of college was rising, and not evenly helping students. By ensnaring Berea, a college that charged no tuition because it has such a large endowment, the logic of the tax broke down.

Ultimately, through a mix of righteous indignation and friends in high places, including Kentucky Senator Mitch McConnell, language was added to the bill saying that a school needs to have 500 “tuition-paying” students to qualify for the tax. That exempted Berea, where no students pay tuition. But the dust-up did raise an interesting question. If Berea can do so much with a $1.2 billion endowment, why can’t the Harvards of the world do the same with their billion-dollar endowments? The answer lies in Berea’s unique history.

Berea College had been around for less than a decade when its founder was run out of town.

John G. Fee, a minister and abolitionist, opened Berea in 1855 on land provided by Cassius Clay—the son of Kentucky’s largest slaveholder—who also happened to be an abolitionist, though one who favored gradual emancipation. The school has a simple motto: “God has made of one blood all the peoples of the earth.” The education of those people, Fee believed, should reflect that.

Needless to say, Fee’s belief in interracial education rubbed the slaveholders in Kentucky the wrong way. In 1859, national tensions over the direction of the country—whether slavery was the future or not—began to boil over. More than 60 armed white men attacked Berea, telling the abolitionist families that they had 10 days to leave the state, or they would be killed. Fee and his family—ardent abolitionists themselves—were among those who left.

So, with his family, Fee fled to Ohio, and the college was forced to cease operation. The winter weather made for a difficult exodus, and his youngest son died from diphtheria. The family carried the young boy’s body back to Kentucky where he was buried. Fee would later write that the ordeal strengthened his, “purpose to return, and my claim upon this, my native soil and field of labor.” But perhaps it strengthened his wife Matilda’s resolve more. During the Civil War, Matilda returned to Berea. John, not to be left behind, followed at the war’s end.

But Fee didn’t come back to Berea alone. He had been devoting the lion’s share of his time to educating—and preaching to—recently freed black people at Camp Nelson, in Kentucky, near the end of the war. He brought dozens of those people with him to reopen Berea College after the war. In the late 1800s, the student body was roughly half white and half black. In 1889, for example, there were 177 black students and 157 white. And all of the students worked on the campus grounds. That had been a central tenet of the college from the beginning. Work, Fee believed, was the great equalizer.

As the school grew, it officially became tuition-free. A new president, William Frost, whose family housed enslaved people who fled captivity during the war, published an advertisement toward the end of the 19th century boasting that the college had “29 teachers and 12 buildings,” that it was endorsed by “Christian Bodies of every name,” and, most importantly, that “Tuition is Free!”

The ad undoubtedly caught the eye of several students, including, potentially, Carter G. Woodson, a plucky young black man who enrolled at Berea in 1897, and a historian who would go on to be known as the “father of black history.” But at the same time, Berea’s interracial education made a lot of Kentuckians uncomfortable. Most notable was Carl Day, a Kentucky legislator, who, lore has it, was taking a train through Berea when he saw two young women—one white, one black—embracing each other. Day introduced a bill in the Kentucky House of Representatives on January 12, 1904, that would prohibit white students from attending school with black students. Schools found to be in violation of that law would be forced to pay a $1,000 fine for each day they were in violation of the law — and teachers could be fined $100 a day. Berea was the only integrated college in Kentucky at the time.

The Day Law, as it came to be known, was passed in 1904, and the college tried to find a way around it. It considered opening  an auxiliary campus, but the law expressly prohibited colleges from operating an integrated campus within 25 miles of their main campuses. They sued, but Kentucky’s high court agreed that the law was necessary to prevent interracial marriage and racial violence. And the Supreme Court of the United States upheld the state’s ruling, citing its decision in Plessy v. Ferguson that it was within a state’s rights to prohibit integration. Only one Supreme Court justice dissented: John Marshall Harlan, a native Kentuckian, who had also dissented in the Plessy case. “Have we become so inoculated with prejudice of race,” Harlan wrote in his dissent, “that an American Government, professedly based on the principles of freedom, and charged with the protection of all citizens alike, can make distinctions between such citizens in the matter of their voluntary meeting for innocent purposes simply because of their respective races?” Loretta Reynolds, dean of the chapel at Berea, perhaps put it best: “It was a sinister law.”

After the Day Law took effect, the college paid for the black students who had been enrolled but had not completed their degree programs to attend historically black colleges and universities. And it split its endowment to open the Lincoln Institute for black students in Simpsonville, Kentucky. But little by little, year by year, students, faculty, and staff began to forget the institution’s history and commitment to interracial education. In some ways, that forgetting was intentional. The college was struggling financially—most of its money had dried up—and it needed to find something that people would support, Turley told me, “and what people would support was the education of poor whites.”

The prospect of educating poor white people from Appalachia for no tuition was something that the community could get behind. And nearly 100 years ago, on October 20, 1920, the board made sure that the college would be able to do so for a long time. According to Jeff Amburgey, the school’s chief financial officer, “The board essentially said, for Berea to sustain its funding model,” any unrestricted bequests—essentially money that someone leaves the institution after they have passed away, that is not tagged for a specific purpose—could not be spent right away. Instead, he says, the money was expected to be treated as part of the endowment, and only the return on that investment could be spent.

The college has followed that policy ever since. In fact, as Amburgey told me, “46 percent of our endowment, as of June 30, 2018, is what we call quasi-endowment, so, roughly $500 million is the current market value of those unrestricted bequests” since 1920.

But as the college was rebuilding its finances, there were no black students. Between 1904 and 1950, the Day Law prohibited black students from attending the college. In 1950, however, the law was amended to allow voluntary integration above the high school level. Two black students, William Ballew and Elizabeth Denney, enrolled that year. And in 1954, the year the Supreme Court ruled segregated schools unconstitutional in Brown v. Board, Jessie Zander became the first black graduate of the college since the Day Law took effect.

The reintegration of the campus was difficult. “The community was gone,” Turley told me. There were still the black people who worked for the school, and lived in the community, but the community of students and faculty had been decimated by the law. The school had to relearn the philosophy of its founder, John Fee, slowly, but surely. Six or seven black students came back in the ’50s. A few more in the ’60s. And, by the ’70s, black students made up roughly 6 percent of the student population.

Each year, the school has built on those numbers, and now black students make up 27 percent, Latino students 11 percent, and international students—who are required to be low-income by the standards of  their own countries—make up another 7 percent. Several people who I spoke with lamented that the numbers sound good, but they’re nowhere close to the 50-50 enrollment Berea once had. However, they’re doing far better than a lot of similarly situated liberal-arts institutions. And it’s tuition-free—something that states are struggling to achieve for their public colleges. It seems like as close to an ideal system for low-income higher education as is possible, but school officials worry it may not last forever.

Jeff Amburgey spends a lot of time thinking about the worst-case scenario. The endowment is what keeps the lights on—literally. About 75 percent of Berea's operating budget comes from endowment investment earnings—the spendable return on the endowment. Another 10 percent of the budget is from charitable giving, another 10 percent is from federal and state grants such as Pell, and then there is other, extraneous income making up the other five percent. The school pays the tuition, $39,400 per student a year, internally.

But having an endowment pay for most of a college’s expenses rather than, say, tuition, can be a recipe for gambler’s ruin. As Lyle Roelofs, Berea’s president, told me, “we’re not the kind of institution that holds the world of finance in disdain. We are dependent on it.”  If the stock market were to dip—lowering the endowment’s return on investment—the college might have to reconsider its tuition promise.

The college has been tested before. In the 1970s, Willis Weatherford Jr., the president at the time, broached the idea of charging tuition as the financial markets went sideways during Vietnam. But the college started accepting federal funds instead—things such as Pell Grants. Following September 11th, the prospect of charging tuition was raised again, and again in 2008 to 2009 when the recession hit. Every time they decided against it. Each of these financial downturns hit the school hard, says Amburgey, but they aren’t close to the the worst of the possibilities he’s considered.

The worst thing that could happen to Berea, Amburgey says, would be a financial market that went down—triggering less than 5 percent returns on their endowment each year (roughly the amount they spend each year to keep the place running)—and stayed that way for a long time. Imagine the worst part of the 2009 financial crisis lasting for a decade. The college has mechanisms built in to help sustain it in such an event. In the 1990s, for example, when the college had a 39 percent return on its investment one year, they stashed money away in a sort of rainy-day fund. But rainy-day funds are useless in a flood.

If something like that were to happen, I asked him, would the college begin charging tuition? He paused, then said first Berea would probably stop renovating buildings except when absolutely necessary. Then, it would cut its operating expenses, as it did in 2009, by eliminating discretionary spending such as travel and conferences. The college would likely put a freeze on hiring and salary increases as they did during the Great Recession. But the students, he said, would be the last to feel it. If Berea started charging tuition—even just a little bit— “we would no longer be Berea,” he says, “we would be just like any other college.”

Berea’s system seems like a solution for the ballooning prices that plague students at many U.S. colleges,  but it’s also something that would be incredibly hard to replicate for most institutions. Berea has been building this model for more than a century—if another college were to switch to this model without an existing financial cushion, a recession could essentially close their institution.

But it’s possible colleges could start by emulating certain elements of the Berea model. Paul Quinn College, a historically black college in Dallas, recently started employing its students on campus, and joined the work-college consortium, a group of federally designated work colleges, in 2017. The institution, which once feared closure, has now announced the opening of a second campus.

But going tuition-free is a bigger ask. Berea College enrolls between 1,600 and 1,700 students in any given year, so scaling a tuition promise like theirs would be a much heavier lift for public regional colleges, and even larger private colleges.  It would be theoretically doable, though, for some highly selective colleges with massive endowments. Some of them, such as Princeton, Brown, and Cornell, have already eliminated tuition for low-income students. But endowments are not like bank accounts where all of, say, Harvard’s $37 billion can be accessed instantly—often some of those funds are earmarked for specific things such as a professorship, or a program, or a specific scholarship. Colleges can not legally break that agreement.

Berea largely owes its success today to the board’s decision, roughly 100 years ago, to make sure there would be endowment funds to spend on students. And to the decades of leaders since who have kept that commitment.

The energy that pulsed through the wooden risers in the Phelps Stokes Chapel was palpable as the students sang. “Just march,” Diane White-Clayton told them, “because some of y’all aren’t singing.” The students laughed, as they stopped singing and clapping and simply stomped. “I want you all to leave here with the determination that nothing,” she exclaimed, “is going to turn you around!”

Higher education in America is plagued by many problems: limited access for low-income and minority students, affordability, etc.—but Berea is different than much of the rest of higher education. But those differences make it fragile. It’s unclear if its model will last forever, but for now, it has a simple purpose. It wants to keep education tuition-free for its students for as long as possible.

“Alright, give me back that bass line,” Clayton told them as the students began clapping again.

“I’m gonna keep on walkin’,” they bellowed, “keep on talkin’. Marching to my destiny.”

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

At least 2,000 children have now been forcibly separated from their parents by the United States government. Their stories are wrenching. Antar Davidson, a former youth-care worker at an Arizona shelter, described to the Los Angeles Times children “huddled together, tears streaming down their faces,” because they believed that their parents were dead. Natalia Cornelio, an attorney with the Texas Human Rights Project, told CNN about a Honduran mother whose child had been ripped away from her while she was breastfeeding. “Inside an old warehouse in South Texas, hundreds of children wait in a series of cages created by metal fencing,” the Associated Press reported. “One cage had 20 children inside.”

About 65 million years ago, shortly after the time of the dinosaurs, a new critter popped up on the evolutionary scene. This “scampering animal,” as researchers described it, was likely small, ate bugs, and had a furry tail. It looked, according to artistic renderings, like an especially aggressive New York City rat. And it had a placenta, an organ that grows deep into the maternal body in order to nourish the fetus during pregnancy.

The rodentlike thing would become the common ancestor of the world’s placental mammals, with descendants that include whales, bats, dogs, and humans, among many other species. And today, the placenta might hold the key to one of the most enduring mysteries in human medicine: Why do women suffer much higher rates of autoimmune disease than men do?

Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.

There’s a moment about 15 minutes into the first episode of Years and Years that made me gasp at its audacity, its prescience, its visual horror. The new six-part series from the British writer Russell T. Davies (Doctor Who, A Very English Scandal) charts the life of the Lyons family over the course of 15 years, starting in 2019 and ending in 2034. It’s a kitchen-sink saga that barrels its way through births and marriages and betrayals, but also through the near-future. In 2024, Stephen Lyons (played by Rory Kinnear), a financial adviser, is at home with his wife, Celeste (T’nia Miller), both rushing their way through the morning routine. When the camera turns to their teenage daughter Bethany (Lydia West), her face isn’t recognizably human. Instead, she looks like a 3-D version of a Snapchat puppy, with vast cartoon eyes, wagging pink ears, and a brown snout. When she talks, her voice is grotesquely distorted, a robotic hallucination of a child’s cadence. “I might have to start limiting filter time,” Celeste says in the same exasperated, noncommittal way that you might think, I really should spend less time on Twitter.



In the 1800s, the University of Virginia rented human beings as a cost-saving measure. These people—mostly men—helped build the institution. Literally. They were mainly put to work constructing buildings on campus. Some of their names are in the university records. Willis, Warner, Gilbert, and so on. It was never a question that renting enslaved people was something that the university would do. After all, several members of the board when the university was founded were “serial renters” of human beings. But the rented laborers weren’t the only enslaved black people on campus. At any given time prior to slavery’s abolition, there were between 125 and 200 enslaved people on campus.

The university recently released a damning report that chronicles the institution’s beginnings, which are deeply and fundamentally tied to slavery. The report—a product of five years of research by the President’s Commission on Slavery and the University, which was established by the institution’s former president Teresa Sullivan—does not mince words. “Slavery, in every way imaginable, was central to the project of designing, funding, building, and maintaining the school,” the reports says. It flowed from the institution’s founder—Thomas Jefferson—on down. “Even in Jefferson’s own imagining of what the University of Virginia could be, he understood it to be an institution with slavery at its core,” the report says. “He believed that a southern institution was necessary to protect the sons of the South from abolitionist teachings in the North.”

One year ago, white nationalists rallied at the Charlottesville, Virginia, institution. They carried torches as they marched through campus chanting things like “Blood and soil” and “You will not replace us.” They marched to the statue of Thomas Jefferson, where they met student counterprotesters. The march to the the statue was symbolic, and it got violent. “They came to claim Thomas Jefferson as theirs,” Kirt von Daacke, a history professor at the university, told me. “At UVA and, I think, in America, we have a mythologized version of [the Founding Fathers] where we’ve sanitized them [of] all the unpleasant things. What we forget is when neo-Nazis marched on our university to claim Thomas Jefferson as theirs,  he is theirs too.”

It’s nearly impossible to read the report without connecting the legacy of racism it paints with the events in Charlottesville last year, which left one person dead and many more injured. For example, the report graphically details an incident in May of 1856, when Noble B. Noland, a white student, yanked a 10-year-old black girl from a boarding house just off campus, savagely beating and kicking her until, crying, she curled up in a ball and passed out. In a parking garage next to the Charlottesville Police Department on August 12 of last year, video shows six men violently kicking and beating DeAndre Harris, a counterprotester at the “Unite the Right” rally.  

For the authors of the report, the incident last year showed that despite progress the university has made, it still has a long way to go. “White supremacist violence here in Charlottesville in July and August 2017 brought into sharp relief just how important this work is,” a cover for the report reads. Marcus Martin, the vice president of diversity and equity at the university, and one of the commission co-chairs, put it to me like this: “It all comes full circle in the fact that this institution has had underlying white-supremacist elements to it from its very beginning.”

For those with even a cursory knowledge of U.S. history, many of the details of the report will not come as a surprise. UVA, like many universities, was built on resources generated from enslaved people. Several institutions—Brown University, Harvard University, Georgetown University—have studied their links to chattel slavery and made steps to atone for this history. UVA is on the path toward doing the same. Over the past few years, the university has hosted a string of events aimed at understanding and addressing its legacy of slavery. Since 2013, it has held a symposium on universities and slavery, named buildings after enslaved laborers, and approved the construction of a memorial to them, Martin told me.

But the report acknowledges that there is still a lot of work to be done. The “racial attitudes that enabled some students here at the University of Virginia to act with inhumanity—that continued through the Jim Crow era,” Martin says. The next step for the university is studying that post-slavery history, and it has formed another commission to pick up where this one left off.

The university, von Daacke told me, is a different place than it was at its founding. It’s a different place than it was during the 1920s, ’30s, and ’50s. The university has different values. It’s committed to creating global citizens and collective learning. But, he adds, “we forget that we may be committed to those things but we’re not that far from the days when those students—[of the ’20s, ’30s, and ’40s]—were the norm.” After all, he continued, two of the leaders of last year’s rallies, Richard Spencer and Jason Kessler, were UVA alumni.



Back in the 1990s, a team of researchers spent two and a half years visiting the homes of close to four dozen families with young children, starting when the kids were 7 months old. Equipped with tape recorders and notebooks, the researchers—led by two Kansas psychologists named Betty Hart and Todd Risley—spent an hour per week in each home, recording every word a child’s primary caregiver said to the child during the sessions. After transcribing each conversation and then analyzing the exchanges as a whole, the researchers (who have both since passed away) discovered major differences in the number of words spoken in middle-class families and in lower-income ones.

The result of their research was a landmark study published in 1995, which maintained that a typical child whose parents are highly educated and working professionals is exposed to roughly 1,540 more spoken words per hour than a typical child on welfare. Over time, they concluded, this word gap snowballs so much that by age 4, children in rich families have been exposed to 32 million more words than children in poorer ones.

The study was a sensation, with the media and policymakers fixating on the so-called “word gap” as a key source of longer-term academic disparities between poor and rich kids. It was immediately embraced by academic researchers, and was cited in more than 7,000 academic publications. It influenced welfare initiatives, government pilot programs, and grant campaigns. The Obama administration championed efforts to close the “word gap,” organizing a campaign to raise awareness of the issue and to encourage parents to talk more to their children.

Now, a new study has failed to replicate Hart and Risley’s findings, further complicating the legacy of this body of research and renewing a long-standing debate among researchers about just how large disparities of language and vocabulary are among different social classes—and how much those differences matter, if at all.

The new study, which was published in the peer-reviewed journal Child Development, reflects the findings of a group of researchers who over the course of two decades studied nearly four dozen families across five different geographic locations in the United States. Three of the communities studied were urban while one was rural; two communities were poor, one was middle class, and two were working class. (One was African American, and the rest were European American.) As with the 1995 study, the researchers recorded conversations between parents and their children, counting the number of words and conducting other linguistic assessments. But they also analyzed the words spoken by all of a given child’s caregivers to that child, as well as those spoken between other people within earshot, even if not directed at the child—an exchange between a parent and older sibling while the child was in the room, for example.

Douglas Sperry—the lead researcher and a psychology professor at Indiana’s Saint Mary-of-the-Woods College—and his colleagues didn’t find a correlation between the socioeconomic status of a child’s family and the number of words that child hears. “There is a lot more language going on in the homes of [low-income] people ... than the Hart-Risley study suggests,” Sperry said. The results were all over the map, with lots of variation within each socioeconomic level.

Other scholars and activists have also critiqued the original word-gap study’s methodology and the way its findings have been interpreted by policymakers. Critics say that policies that grew out of simplistic interpretations of this study were racist, classist, and simply ineffective. Some policymakers and education reformers, they said, blamed parents for the academic gap, instead of acknowledging the other forces at play.

One linguist, Michael Erard, noted in a 2014 Atlantic article that “just as solving climate change isn’t about closing the polar bear gap, and preventing environmental degradation isn’t about closing the tree gap, you can’t increase children’s school readiness by closing the word gap.” One 2017 study published in the Harvard Education Review even found that the word-gap research had the unintended consequence of perpetuating negative stereotypes about the children of Latino immigrants, with teachers in classrooms serving such students resorting to less-sophisticated instruction.

Critics are now taking aim at the methodology of Sperry’s study. Some experts question the value of Sperry’s focus on overheard speech, pointing to research that has found that young children learn best from speech directed at them and not from overheard speech. Some critics also note that the study excluded high-income families, which makes a direct comparison to the original word-gap study more difficult. Sperry and his team have responded to these critiques, citing research to suggest that overheard language does play a role in language development, and arguing that the lack of high-income parents in the study doesn’t negate their finding that their poorest groups outperformed the welfare group in the 1995 study.

These scholars are concerned that Sperry’s study might lead people to believe that family income doesn’t have any bearing on a kid’s exposure to vocabulary, or that a language-rich home life isn’t important. For example, Daniel Willingham, a University of Virginia psychology professor and expert on literacy, pointed in his blog post on the controversy to a body of research that, while not being direct replications of the Hart-Risley study, show a correlation between a parent’s social class and the quantity and quality of words she directs toward her child. Willingham described efforts to discredit the seminal 1995 study as “rash,” and worries that Sperry’s study will compel some people to “go all the way in the opposite direction and throw out all the scientific research.” It’s also worth noting that the academic debate extends beyond the sheer number of words spoken to children; there’s evidence to suggest that parents of different socioeconomic status use different styles of speech and types of language, although scholars have long debated just how real these differences in speech are and how much they matter.

Sperry stressed that his study shouldn’t be used to discourage parents from talking with their children. Rather, he argued, it should inspire policymakers and advocates to redirect resources from simplistic policies that prioritize the English language, like the Providence Talks program (which was created to provide poor mothers with recording devices and case managers to measure conversations with their children), to programs that embrace the diverse language traditions in Latino and African-American homes. As with the recent analysis that failed to replicate the seminal “Marshmallow Test” study, new developments in the word-gap research shows the dangers of relying on easy answers to complex social issues.



A gunman walked into a bar in Thousand Oaks, California, and opened fire last Wednesday night. By the time the gunfire had stopped, 13 people, including the shooter, were dead. It was one tragedy among many in recent weeks, including a shooting at a yoga studio and a massacre at a synagogue in Pittsburgh.

Media coverage of these events tends to follow a familiar script. “You do the day story, and then you do the victim stories, and then you profile the shooter,” Erica Goode, a visiting professor at Syracuse University’s Newhouse School of Public Communications, told me.

By the next week, in most cases, the news cycle has moved on. A review of dozens of New York Times front pages in the days immediately after 10 of the deadliest mass shootings since Columbine found that the script is remarkably consistent. Most of the shootings carried the front page for six days, including the Sunday edition. Cable-news coverage—which tends to cycle through news even faster—charts a similar course, according to a report from Media Matters for America. The report found that after the deadliest mass shooting in modern American history, in Las Vegas, major news coverage of the attack lasted a week.

That consistency is a reflection of a dense news environment, with more major stories nearly every day than can possibly fit on a front page. The extent of coverage is not solely determined by the number of fatalities. The Thousand Oaks shooting, for example, was only on the front page of the Times for one day, as it was pushed off by the deadliest fires in California history, some of which, it so happened, were also in Thousand Oaks.

And there are outliers at the other end of the spectrum, as well. After a gunman killed 17 people at Marjory Stoneman Douglas High School in Parkland, Florida, stories about the shooting were on the front page of the Times for 16 consecutive days. That is in large part due to the student-led activism that emerged in the wake of the shooting, calling for stronger gun-control laws. As Michelle Cottle put it, “Possessed of that blend of innocence and savvy peculiar to teenagers, the Stoneman Douglas survivors indeed have emerged as a rare, perhaps even unique, voice in the gun debate. They are old enough to advocate for themselves, yet young enough to still embody a certain innocence, to retain a certain idealism about how the world should be.”

Goode, too, noted the difference in Parkland—but she also noticed something else: The media had, by and large, started to change how it covered the shootings. Goode worked as a reporter and editor at the Times for 18 years, and covered several mass shootings herself. After Parkland, she observed that one of the regular story genres—the shooter profile—had gotten shorter, and in some outlets, it wasn’t there at all. “What we told people,” Goode says of reporters covering mass shootings, “was that [shooter profiles] would help people understand what causes this, and who these people are.” However, she said she later decided “that’s bullshit.” Far from introducing anything particularly revelatory about the shooters, these stories brand the perpetrators as mysterious lone wolves, something that carries a whiff of coolness or allure. “A profile of the shooter is not going to help anybody understand who these people are,” she says. Instead, it’s going to draw attention to shooters from people who are fascinated by reading about them—“It’s going to make them famous, basically.”

Those stories have been replaced, at least in print, by stories—both local and national—on gun-law reforms and more stories about the victims. Of course, Goode says, it is news organizations’ duty, by definition, to cover the news—and the identity of the shooter is news. But, she said, it is also imperative to cover the news responsibly. By giving less of a platform to shooters, and focusing more on the victims of the shooting and on solutions to potentially preventing the next one from happening, media organizations might beat back some of the likelihood of another shooting, she believes.

The phenomenon Goode’s talking about is known colloquially as a copycat effect, and by researchers who study it as “contagion”: the idea that more media coverage of mass shootings might lead those inclined to commit atrocities to do so. Researchers at Arizona State University led by Sherry Towers, a research professor at the institution, set out to uncover whether or not such an effect existed. For Towers, it was a personal endeavor.

In 2014, Towers was headed to Purdue University in Indiana to meet with her collaborators on a research project, when suddenly the meeting was canceled. A teaching assistant at Purdue had walked into a classroom and killed another teaching assistant. “It occurred to me that day that that was the third school shooting I’d heard about in a 10-day period,” Towers, who has a background in modeling contagious processes, specifically diseases, told me. “And it made me wonder if perhaps there was a contagion effect maybe playing a role.”

Ultimately, researchers found that in high-profile mass shootings, there was a statistically significant contagion effect. “We hypothesize that perhaps widespread media attention plays a role in actually basically informing people who might be at risk of committing one of these acts,” Towers says.

Lately there has been a refrain that the increasing pace of the news cycle—and the frequency of mass shootings—means that tragedies  aren’t covered as vigorously as they once were. In some cases, as with Thousand Oaks, the pace of the news cycle does push the stories off  the front page, but in most cases, they are covered as they always have been: for a week. What has changed isn’t the length of the coverage, but the substance—and for the better.



As a sports doctor for Michigan State University and USA Gymnastics, Larry Nassar assaulted more than 150 young women. Much of this abuse, which spanned more than two decades, occurred in an examination room on MSU’s campus, in a building full of MSU staff. Long before the allegations against Nassar went public, multiple victims described their abuse—how Nassar touched their genitalia during physical-therapy sessions—to MSU coaches, therapists, and administrators. They were told not to worry, that what they’d experienced was “actual medical treatment.” A 2014 investigation into Nassar, conducted by MSU’s Title IX office, found no evidence of misconduct. He was allowed to continue working for the university, treating students on campus, until 2016, when two of his former patients filed additional accusations against him.

After Nassar was sentenced in January to 40 to 175 years in prison, the NCAA launched an investigation into the university’s handling of his case. Victims claimed that MSU had been complicit in the abuse, protecting a doctor well known for his work with the U.S. Olympic gymnastics team. “MSU knew what was being done to these athletes and decided to turn a blind eye to keep their reputation strong and their pockets full,” Olivia Cowan, a former MSU student, said during Nassar’s January sentencing hearing.

Now a new lawsuit that was reported by The Detroit News on Tuesday contains allegations that are even more egregious than those in previous cases. For one, the suit contends that Nassar raped someone—a former MSU field-hockey player who was 18 years old at the time—in 1992 and filmed the act while doing so. For another, it alleges that MSU—and, specifically, George Perles, a current member of MSU’s board of trustees who served as the university’s athletic director at the time of the rape—went “to great lengths to conceal this conduct.” The suit is one of at least a dozen civil complaints filed against MSU and other defendants in federal court on Monday, which marked the last day victims of Nassar’s sexual abuse could sue the university. (State legislation passed in June allows people who allege they were sexually assaulted by now-convicted physicians to retroactively sue up to 90 days after the physician was convicted.)

In response to the lawsuit, MSU provided a statement saying that “sexual abuse, assault and relationship violence are not tolerated in our campus community,” and stressing that the actions cited in the complaint do not reflect university protocol. “We are taking the allegations very seriously and looking into the situation,” the statement continued. Before this flurry of new lawsuits, the university may have thought it was starting to put the Nassar affair behind it—the NCAA recently closed an investigation into MSU, concluding the university hadn’t violated any of the college-sports association’s rules. The university declined to comment on other matters included in this piece, and as of Wednesday, Perles hadn’t responded to a request for comment on the lawsuit.

Since the university was made aware of Nassar’s actions, it has repeatedly bungled its handling of the fallout. Seemingly every other week there is a new development—and a new scandal. Looked at in aggregate, all of these developments—from staffing decisions to secret settlement meetings with Nassar’s victims—add up to a picture of a university in crisis, and show where MSU might go from here. Here is a primer on how that crisis has played out so far:

MSU claimed to launch an “independent” investigation into the school’s handling of the Nassar case—then assigned the case to a university lawyer. 

The same team of lawyers assigned to investigate possible administrative wrongdoing, The New York Times reported in late January, were also responsible for defending MSU against civil lawsuits. “Michigan State led the public to believe that there had been an independent investigation,” Tom Leonard, the Republican speaker of the Michigan House of Representatives, told the Times. “And then as we continued to dig into this, we found out … it was an internal investigation to shield them from liability.” Robert Noto, Michigan State’s longtime lawyer, resigned after the Times publicized his legal team’s conflict of interest.

Many who are accused of enabling Nassar’s abuse continue to work at MSU. 

They include Kristine Moore, the attorney who as a full-time MSU employee conducted the Title IX investigation into a 2014 complaint against Nassar. Moore, who was named in many of the complaints filed Monday, now serves as the university’s assistant general counsel. Title IX protocol requires that all parties receive a copy of the same report summarizing an investigation’s findings, but in January, The Detroit News discovered that Moore had given the victim who had filed the complaint a different report than the one provided to both Nassar and his supervisor at the time, William Strampel. While the report given to the victim cleared Nassar of wrongdoing, the internal version found that the doctor’s methods were inflicting “unnecessary trauma” on his patients. By neglecting to disclose the internal report, Moore effectively put Strampel, then the dean of the College of Osteopathic Medicine, in charge of keeping the serial sexual abuser in check.

Strampel—who has also been accused, in a pending lawsuit, of sexually harassing MSU students, and was also named in many of the complaints filed Monday—allowed Nassar to continue seeing and molesting patients until 2016. When we called Moore’s office for comment, a staff member directed us to the university’s spokespeople, who declined to participate in this story.

Lianna Hadden, an athletic trainer who according to at least two victims was told of Nassar’s behavior but failed to report it, is another alleged enabler still employed by MSU. Hadden was named as a defendant in the federal civil lawsuits related to Nassar’s sexual abuse—lawsuits that MSU in May agreed to settle for $500 million—as well as several of those filed Monday. Another possible enabler still on the university’s payroll is Douglas Dietzel, who oversees the MSU sports-medicine clinic where Nassar served as a doctor. Dietzel—who was also named as a defendant in many of the lawsuits filed Monday, including that concerning Nassar’s alleged rape of the field-hockey player—told law-enforcement officials in 2017 that he was aware Nassar performed some kind of intervaginal procedure but knew few details. The state licensing department earlier this year investigated Dietzel for his involvement in the scandal but closed the probe after concluding he hadn’t violated any licensing policies. As of Wednesday, neither Hadden nor Dietzel had responded to requests for comment.

Many of those who did resign did not at first publicly take responsibility.

Most notably, former MSU President Lou Anna Simon resigned the same night Nassar was sentenced. For months she had refused to do so, despite calls for her removal from students, faculty members, and advocates of sexual-assault victims. In her resignation letter, Simon did not implicate herself, often resorting to the passive voice: “I am pleased that statements have been made … about my integrity and the fact that there is no cover-up,” she wrote. “As tragedies are politicized, blame is inevitable.” She later apologized, saying at a June Senate hearing about abuse in athletics: “To the survivors of Nassar’s abuse, I can never say enough that I am so sorry that a trusted, renowned physician turned out to be an evil predator, and I am sorry that we did not discover his crimes and remove him from our community sooner.”  

Another resignee who declined to take responsibility was Mark Hollis, who served for a decade as MSU’s athletic director after Perles. He resigned in late January, shortly after the NCAA began its probe into the university and just before the publication of an ESPN report that documented an institutional culture in the athletic department that enabled Nassar’s decades-long abuses. In his resignation letter, Hollis wrote: “I am not running away from anything, I am running toward something. Comfort, compassion, and understanding for the survivors and our community; togetherness, time and love for my family.”

Then there is Scott Westerman, MSU’s former associate vice president for alumni relations and the former executive director of the university’s alumni association. Westerman announced his resignation in April amid a pending investigation by the university into his role in the Nassar scandal. It’s not clear whether that contributed to his resignation—he denied that it did—but the timing is noteworthy. “I was recently surprised to learn that I am the subject of an [Office of Institutional Equity] inquiry,” he said in a statement cited by the Detroit Free Press. “It covers a brief period near the start of my tenure, is not a police matter, and, naturally, I am fully cooperating with with investigators.”

The board of trustees has disregarded the wishes of MSU students, faculty, and staff in its handling of the case’s aftermath. 

After former President Simon resigned in late January, the school’s board of trustees was charged with finding an interim president to take her place. When asked to weigh in, the faculty senate, a group that represents the MSU faculty, took a vote and recommended that the board select someone with experience both leading a university and handling issues of sexual assault and harassment. One week after Simon’s resignation, the board chose John Engler, the former governor of Michigan, who has neither. (He has also been accused of ignoring incidents of sexual assault at a women’s prison as governor.) “Every single piece of criteria we provided was ignored,” says Anna Pegler-Gordon, an MSU professor and a former member of the faculty senate. “The board is extremely isolated from the faculty and the students.”

In response, the faculty senate passed a vote of “no confidence” in the board of trustees in mid-February. Around the same time, MSU administrators invited students, faculty, staff, and alumni to air their grievances before the board in an open “listening forum.” Hundreds of people came. But of the eight MSU board members, only one showed up. “It was a cathartic night, opening the floodgates to a lot of frustration and anger and pain,” says Amy Bonomi, a family-studies professor at MSU who attended the event. “But everyone asked, ‘Where are the rest of the trustees?’”

Interim President Engler allegedly asked Kaylee Lorincz, one of Nassar’s victims, to settle with the university in a private meeting.

Lorincz claims that, in a one-on-one meeting in late March, Engler offered her $250,000 to forgo a formal settlement hearing, one month before mediation proceedings between MSU and victims were scheduled to begin. “When I explained that it’s not about the money for me and that I just want to help,” Lorincz told the MSU board of trustees, “he said, ‘Well give me a number.’” Engler also allegedly told Lorincz that Rachel Denhollander, another Nassar victim, had suggested the $250,000 number, which Dollander denies. In May, MSU agreed to pay Nassar’s victims a lump sum of $50 million.

In the months following the trial, another MSU employee with ties to Nassar was accused of sexual crimes. 

That employee was Strampel, who as dean of the College of Osteopathic Medicine served as Nassar’s supervisor. In March, Strampel was arrested on four charges, including criminal sexual conduct and willful neglect of duty. The sexual-misconduct charges respond to allegations that the former dean, who resigned in December 2017 citing “medical reasons,” used his position of authority to proposition and sexually assault young women, including by groping female students. A court affidavit also contends that Strampel stored nude student selfies on his MSU computer. And according to The Detroit News’s summary of a 2015 internal performance review of the dean that the newspaper obtained this past spring, evaluations from multiple female faculty and staff suggest he frequently made comments about women’s appearances, sometimes asking them to wear low-cut shirts to meetings, or otherwise leered at their breasts.

The criminal charges against Strampel were the result of a larger probe by the state attorney general into actions by university officials that may have enabled Nassar’s abuse. Strampel announced in July that he was formally retiring from MSU as part of a settlement with the university that included a payment of $175,000; he denied the criminal accusations when arraigned by video in March. Strampel is also named as a defendant in many of the civil suits filed Monday. The attorney representing the former dean in the criminal case did not respond to a request for comment.

A new lawsuit alleges that Nassar raped a student—and MSU covered it up—back in 1992.

Nassar has been accused of inappropriately touching more than 150 young women, but this latest lawsuit, filed on Monday, is the first accusation of rape. Nassar allegedly drugged Erika Davis before he raped her, and asked a cameraman to film the assault. Davis, a former MSU field-hockey player who was 17 years old when she first met Nassar, says she reported the rape to her coach, who then brought the allegation to other administrators. But Perles, who was then MSU’s athletic director, “intervened” and covered it up, the lawsuit alleges. According to the court documents, “Michigan State University could have prevented hundreds of young girls and women from being sexually assaulted by Defendant Nassar had they only acted appropriately, decently and lawfully in 1992.” At the time, Nassar was an osteopathic-medicine student at MSU working at the university’s sports-medicine clinic, according to the lawsuit and a timeline published earlier this year jointly by the Lansing State Journal and the IndyStar. If these new allegations are true, Nassar’s predatory sexual behavior began even before he graduated and was hired as a physician and assistant professor by the university.

The MSU campus remains bitterly divided by the Nassar case. As the board moves forward with selecting a new president, students, faculty, and staff worry that their feedback will once again be ignored. Whatever happens at MSU next, the university’s handling of the fallout following the Nassar scandal—and of the internal investigations leading up to it—offers a blueprint for the mistakes higher-education institutions can avoid when responding to sexual assault on their campuses.



The fight began with little subtlety. White, wealthy parents in the southeastern corner of East Baton Rouge Parish, Louisiana, an area known as St. George, wanted their own school district. They argued that the schools in East Baton Rouge were routinely named as among the lowest performing in the state, and were unlikely to improve any time soon. So, in 2012, some of those parents went to the state legislature with a proposal: Create what would be called the Southeast Community School District.

The legislature shot it down. The parents needed a two-thirds majority for the creation of a school district, and they couldn’t marshal the votes. A similar push in 2013 was rebuffed as well.

The organizers were discouraged, but undeterred. They needed a new strategy—and they didn’t have to look far. In 2005, a nearby community, Central, was unable to gather support for a school district from the legislature, so it incorporated as a new city. That helped it gain legislative approval to create its own school district, Central Community Schools, which opened its doors in 2007. The St. George supporters launched a petition drive and, in August 2013, registered a new website: StGeorgeLouisiana.com. They would try to create their own city.

A pattern has emerged over the past two decades: White, wealthy communities have been separating from their city’s school districts to form their own. According to a recent report from EdBuild, a nonprofit focused on public-school funding, 73 communities have split to form their own school districts since 2000, and the rate of places doing so has rapidly accelerated in the past two years. St. George, which activists seek to incorporate as a city, is a textbook example.

Oftentimes, in these instances, predominantly white parents are trying to break away from a majority-minority school district, which in turn isolates their property-tax dollars in a new district. (Many public schools rely heavily on property taxes.) The argument, then, is that the parents can better dictate how their money is being spent.

St. George is no different. The proposed area is more than 70 percent white and less than 15 percent black, while East Baton Rouge Parish is roughly 46.5 percent black. St. George supporters decry the violence and poor conditions of the public schools in Baton Rouge. Their tax dollars, they have argued, aren’t being put to good use. (Representatives for the St. George campaign’s organizers did not respond to multiple requests for comment for this article, including several emails, phone calls, and Facebook and LinkedIn messages.)

The parents’ first petition drive to create a city, which ended in 2015, looked as if it would be successful. Supporters of St. George, arguing that the schools in East Baton Rouge Parish were not doing enough for their children, had amassed more than 18,000 signatures, and submitted them to the registrar to be certified. But the same day as they submitted their petition, a group known as Better Together submitted its own forms to the registrar. “We did a withdrawal campaign,” M. E. Cormier, a spokeswoman for the Better Together campaign, told me. “We went door-to-door, told people about the detrimental effects of the creation of St. George, and we were able to get 1,000 people to withdraw their names from the petition.”

When everything was settled, on June 13, 2015, St. George came up 71 signatures short. “It was a squeaker,” Cormier said.

“More than anything, this is shining a light on problems that face this parish,” Lionel Rainey, a spokesman for the proposed city, told The Times-Picayune a week before the final tally was counted. “It’s forcing a very uncomfortable conversation to be had. It’s not something that you want to talk about, it’s not something that anybody wants in the newspaper or on television.”

But it has been, because after the failure, the organizers kept fighting.

For decades, Baton Rouge’s schools operated under a desegregation order, imposed in 1956 after the Brown v. Board of Education ruling. That order meant, in theory, that the integration of the city’s schools was being closely monitored. But in 2003, a federal judge lifted the order; at the time, it was the longest-standing such order in the country. When the order was lifted, the school district was 75 percent black; now it is 81 percent black, and 89 percent minority overall—due in no small part to the three communities that have separated from East Baton Rouge Parish since.

Many of the city’s residents, black and white, argue that the St. George campaign is an attempt to further segregate the public schools, leaving Baton Rouge’s black students with fewer resources and opportunities. Dadrius Lanus, a lifelong resident of East Baton Rouge Parish, was one of the city’s black students not too long ago. He’s a product of the school district, and graduated from Glen Oaks High School in 2007. After high school, he went to Southern University, a historically black college in Baton Rouge, where he earned his bachelor’s, master’s, and law degrees.

Last fall, Lanus ran for school board and won. His campaign was criticized for receiving outside funding, but his central message resonated with voters: The schools in Baton Rouge had been inequitable for too long, and it was time for a change. “If you look anywhere south of Florida Boulevard in Baton Rouge—which is what we call the Mason-Dixon line—that’s where you have the largest disparity in the entire city,” Lanus told me. “Anybody that lives in North Baton Rouge is more of your lower-income, disadvantaged communities, and anything south of Florida Boulevard are your more affluent communities.”

Lanus, alongside other residents who oppose the creation of St. George, is concerned that their breaking away from the parish would simply deepen the inequality in the schools in East Baton Rouge. “We’ve already seen several school breakaways, and we’ve seen how drastically it has affected our school system,” he said. “What happened in Zachary and Central,” two other communities that split from East Baton Rouge, “was because of white flight,” he told me, and “for a city the size of Baton Rouge, it has been devastating.”

St. George organizers, however, see the separation as necessary for their children. “We’ve had enough of failing our children,” Rainey said in 2014. “We’re not going to do it anymore, and we’ll go to the length of creating our own city—to create our own education system—to take control back from the status quo.” In Louisiana, a group hoping to incorporate a city is required to wait two years and one day after an unsuccessful attempt before it can launch another petition drive. So in 2018, activists once again sought to create a new city.

In between the failed 2015 attempt and the new one, they tried to iron out a new strategy. They cut down the geographic area of their proposed City of St. George. The original map was roughly 85 square miles; the new area was 60. It would be easier to gain the signatures necessary for a new community with a smaller area. As soon as the proposed map was released, several people in favor of keeping East Baton Rouge Parish together noted that the new map, coincidentally, carved out several apartment complexes—places where black and low-income families lived.

St. George supporters vehemently denied the suggestion that the map was drawn with any malicious racial intent. “The decision on what areas to include and not include was based exclusively on the amount of previous support for the effort,” they wrote in a post on their official Facebook page. “If a precinct had a small percentage of signatures and clearly did not want to be in the new city, they were not included in the updated boundaries.” But practically, that meant that the proposed area of St. George became whiter and more affluent.

The organizers did something else significant as well, Michael Beychok, a political consultant who lives in what would become the new city, told me: They stopped talking so much about the schools. “They know, and we know, that the school argument is not their best argument to incorporate,” said Beychok, who is one of the organizers of One Baton Rouge, a group opposed to the creation of St. George.

When the focus was primarily on the schools, it triggered a PBS Frontline investigation, and fierce accusations locally about segregation. That made it difficult to get some voters who might have otherwise supported the petition to sign on.

St. George advocates began going door-to-door gathering names to sign their new and improved petition; this time, armed with a list of those who had signed before, it was easier. Businesses, worried about the infrastructure of a new city, requested to be annexed into the city of Baton Rouge, which harmed the potential tax base, but organizers brushed it off. Meanwhile, those who opposed the effort to incorporate St. George commissioned studies about the economic impact of its creation.

On their website, St. George supporters argue that the creation of a new city would not negatively affect the City of Baton Rouge; however, a recent study from the City of Baton Rouge–Parish of East Baton Rouge showed a potential $48 million reduction to the city’s budget.

The nuts and bolts of how St. George would work have led to a circular debate in the parish. But organizers say they’re looking to the suburbs of Atlanta, Georgia, as a model, where in Sandy Springs, only 14 employees are on the city’s payroll. “St. George’s government will be leaner, smarter and more responsive to the needs of a successful 21st-century city,” they wrote on their website. “The organizers of St. George have been inspired in their formulation of its governing strategy by the innovations put in place in Sandy Springs, Georgia—a state-of-the-art suburb of Atlanta.” They argue that they have been the “backbone” of the economy in East Baton Rouge, and that “incorporating a city would reverse this unjust circumstance to an extent.”

Sandy Springs has been successful due, in large part, to the privatization of public expenses, whether that is its call center, public works and facilities, or communications more broadly. The city, however, has a less-than-flattering history. As Sam Rosen wrote in The Atlantic, when the mayor of Atlanta sought to annex Sandy Springs, “he was met with outrage and obstruction. Two spokesmen for Sandy Springs promised to ‘build up a city separate from Atlanta and your Negroes and forbid any Negroes to buy, or own, or live within our limits.’”

St. George supporters are used to fielding calls that their goal to create a new city is racist. “Yes, I’ve been called a racist in no uncertain terms. I’m not a racist. I can’t— you know, I’m not going to try to attempt to defend it,” Norman Browning told Frontline in its 2014 documentary, Separate and Unequal. (Browning did not respond to a request for comment from The Atlantic on LinkedIn. When I called his office, I was put on hold for 30 minutes before the line went dead. Each subsequent call was sent directly to voicemail.) “What I do is I let my actions speak, and how I conduct myself and how I treat people speak.”

In late February, St. George supporters found out they’d gathered enough signatures to force a vote on incorporating the city—the vote is scheduled for October. More than 90 percent of the signatures on the second petition came from white voters in the proposed St. George area.

After his election, Dadrius Lanus ran for vice president of the school board; in January, he lost to Jill Dyason, who has been on the board for 17 years and is its longest-serving member. In July of last year, Dyason signed the petition to allow a vote on St. George. Dyason responded to a request for comment, but as of publication had not granted a request for an interview or commented on her support for the push to allow a vote. (After a leadership struggle, Dyason lost her position as vice president earlier this month.) She told The Advocate, however, that she had considered signing for a long time, but stopped short of doing so on the first petition. She wants a final decision on the matter, she said.

In October, she will get one, when voters in the southeastern corner of East Baton Rouge Parish, Louisiana, will head to the polls, along with the rest of the state. They’ll elect a governor and state senators, municipal officials and other state executives. And then, somewhere toward the end of the ballot, the voters in the area that would be St. George will decide whether they want to create their own city; those in East Baton Rouge Parish do not get a vote, due to state law. What the St. George voters decide will set into motion a series of events that could lead to the creation of a new school district.

If the St. George organizers are successful, they will go to the legislature to get a constitutional amendment to create their own school district. The worst-case scenario for those who oppose its creation, Beychok, of One Baton Rouge, told me, is that “not only our schools, but our community, becomes segregated, and isolated.

“That is not how communities rise up and improve the quality of life for people,” Beychok said. “You don’t do it by separating yourselves from your neighbors.”



In the wake of a tragedy, there’s a race to understand exactly why it happened and what could have been done to prevent it. Maybe local law enforcement could have done more; maybe armed teachers would have helped; maybe the federal government should have been investigating the shooter as a terrorist. The shooting at Marjory Stoneman Douglas High School in Parkland, Florida, last Valentine’s Day, in which 17 people were killed and more than a dozen others were injured, was no different.

The Marjory Stoneman Douglas Public Safety Commission, an investigative panel convened by the state of Florida, was tasked with laying out the facts of what happened in the 78 minutes between when a gunman was dropped off by an Uber near campus and when he was detained by police. In January, it released a 439-page report providing some answers about what went wrong, cataloging breaches of security, chaotic protocols, and a lack of communication systems for teachers to relay the seriousness of the situation across campus.

“School safety in Florida needs to be improved,” the report opens. “All stakeholders—school districts, law enforcement, mental health providers, city and county governments, funding entities, etc.—should embrace the opportunity to change and make Florida schools the safest in the nation.” But often, tragedies are tragedies for a reason; they’re not supposed to happen, but they do—even in the most secure environments.

The report is a searing indictment of the failures that day and those that led up to it, but it also offers several best practices for preventing the next school shooting. For many school-safety experts, the recommendations are all too familiar. “Overall, there were some solid recommendations in terms of best practices that came out of Parkland. That’s the good news,” Kenneth Trump, who runs National School Safety and Security Services, a school-safety consulting firm, told me. “The bad news is they’re the same as the best practices that came out of Sandy Hook, which were the same best practices that were learned after Columbine. So they’re not new.”

Trump, who is of no relation to the president, says that in the wake of high-profile shootings, school districts and legislators will often rush to implement fixes that aren’t ultimately maintained. Cameras are found to no longer be working once the incident has faded; security protocols are forgotten with turnover. School safety isn’t always just the security measures you can see, Trump says, but also the ecosystem on campus that creates an environment that shuns bullying, encourages students to report suspicious behavior, and fosters a healthy school climate.

That’s a difficult thing to explain to parents who fear losing their children in school shootings, which are still extraordinarily rare, Trump says. “You can’t just point to a culture of safety as easily as you can point to a camera and say, ‘Trust us, your child’s school is safer,’ ” he says.

The search for active prevention measures has led some people to believe that the federal government should play a larger role. The Department of Homeland Security and the FBI, among other agencies, are already trying to prevent domestic terrorism, the thinking goes. And many school shootings fit the mold, says Martha Crenshaw, a senior fellow at the Center for International Security and Cooperation at Stanford University, as a “type of violence that shocks or surprises, something that provokes outrage.” That outrage could stem from the nature of the crime or the nature of the victim, she says. “Who could be more innocent than schoolchildren?”

The National Consortium for the Study of Terrorism and Responses to Terrorism, known as START, at the University of Maryland has been tracking terror incidents through the Global Terrorism Database. And there has been a disconnect between the government definition of terrorism, particularly domestic terrorism, and the working definition used by START, Gary LaFree, the group’s founding director, told me. To the organization, an incident of terrorism needs to be intentional; involve violence; be committed by someone other than a government agent; and, perhaps most importantly, have a political, economic, religious, or social goal. Under that definition, school shootings could be considered terrorism in some cases, as Columbine was and as the Parkland shooting likely will be, LaFree says.

The government has a definition of domestic terrorism in the federal code—acts of violence that are intended to influence government policy or “affect the conduct of the government by mass destruction, assassination, or kidnapping”—but there is no federal domestic-terrorism law to back it up, David Schanzer, the director of the Triangle Center on Terrorism and Homeland Security at Duke University, told me. That means the federal government can’t charge people with a violation of a terrorism law; instead, it could charge them with a hate crime, or violations of interstate-commerce laws, or a similar offense. (Murder is a state crime, not a federal one.) “You have to bring a charge that reflects the circumstance of what occurred,” Schanzer says.

But that’s all reactive, the what comes after the shooting. How could the government treating potential school shooters as terrorists help prevent them? That depends on whether potential shooters are flagged for monitoring by the FBI or any other agency, perhaps after a friend or family member reports a potential plot.

Trump noted that after the Columbine shooting, there was a focus at the federal and state level to take a comprehensive look at school safety—“from prevention to preparedness, from threat assessment to prevention, mental-health services for kids, school resource officers, emergency-planning drills and exercises.” These are things that have worked, he says, not only in warding off a school shooter, but in keeping a school safe on a day-to-day basis.

But identifying perpetrators ahead of time is a much harder challenge. Like terrorist incidents, school shootings are rare, tragic, and can only sometimes be explained. After every school shooting, Crenshaw says, “people wonder what happened—missed opportunities and interventions, lost chances” to find shooters before they wreaked havoc. Yet, Crenshaw adds, sometimes school shootings, like terrorist incidents, are virtually impossible to prevent. “If you went back and replayed, it might be just really hard to find that [intervention] point.”



The segregation of America’s public schools is a perpetual newsmaker. The fact that not even 1 percent of the incoming freshman class identifies as black at New York City’s elite Stuyvesant High School made national headlines last month. And New York isn’t unusual. The minority gap in enrollment at elite academic public schools is a problem across America.

But more troubling, and often less discussed, is the modern-day form of segregation that occurs within the same school through academic tracking, which selects certain students for gifted and talented education (GATE) programs. These programs are tasked with challenging presumably smart students with acceleration and extra enrichment activities. Other students are kept in grade-level classes, or tracked into remedial courses that are tasked with catching students up to academic baselines.

Black students make up nearly 17 percent of the total student population nationwide. Yet less than 10 percent of students in GATE are black. A shocking 53 percent of remedial students are black. This disparity across tracks is what social scientists commonly call “racialized tracking”—in which students of color get sorted out of educational opportunities and long-term socioeconomic success.

The level of disparity varies across the nation. A Department of Education Office for Civil Rights report from 2014 called attention to a Sacramento, California, district where black students accounted for 16.3 percent of the district’s enrollment but only 5.5 percent of students in GATE programs. At the other end of the state, in San Diego, 8 percent of students are black, but just 3 percent of GATE students are.

In the South Orange–Maplewood School District in New Jersey, the American Civil Liberties Union stated in a 2014 complaint that racial segregation across academic tracks “has created a school within a school at Columbia High School,” where more than 70 percent of the students in lower-level classes were black and more than 70 percent of the students in advanced classes were white. Though the Office for Civil Rights ordered the district to hire a consultant to fix this, segregation remains an ongoing challenge.

The idea that tracking can create a “school within a school” became a physical reality in one Austin, Texas, school. In 2007, the district moved to split part of the Lyndon Baines Johnson Early College High School into a separate Liberal Arts and Science Academy (LASA), a public magnet high school now ranked the best Texas high school and the 11th-best high school in the United States. The magnet students, who are mostly white and Asian, take classes on the second floor, and the LBJ students, who are majority black and Latino, take classes on the floor below. Yasmiyn Irizarry, a professor of African studies at the University of Texas at Austin whose child attends LASA, wrote that this design was “reminiscent of apartheid.”

The implication is clear: Black students are regularly excluded from schools’ conceptions of what it means to be gifted, talented, or advanced. There are real, systemic factors that fuel the disparity in access to gifted and specialized education. A history of racist policies, such as housing segregation and unequal funding, means that schools with a high proportion of black students often have resource constraints for specialized programs. Teachers’ biases against black students limit their chances for selective advanced opportunities. Admissions into gifted programs and specialized schools are based on a singular standardized test that often ignores qualifications aligned with a student’s training and does not capture black students’ potential. Minority students, particularly black students, are also often over-policed, which can affect their educational opportunities.

But part of the problem also comes from the fact that all parents want the best for their children, and some parents actually have the power to make it so. In an extreme, high-profile example, recently dozens of wealthy parents were caught bribing their children’s way into elite colleges and universities. But even moderately privileged parents have knowledge that benefits their children—they can teach their kids how to negotiate educational opportunities for themselves—asking for an extension on an assignment or talking their way out of punishment for misbehaving, for example.

More important, privileged parents contribute to these racial disparities in advanced education, intentionally or not, when they hoard educational opportunities for their already privileged children.

Privileged parents have the power, autonomy, time, and resources to, for instance, attend school-district meetings to make sure their neighborhood schools aren’t closed or rezoned. They also know how to appeal to principals, making a case for why their child must be placed in their preferred teacher’s classroom. They have the money to hire tutors so their children can stay on top of their classwork and score well on standardized tests. Some even do school-related work on their children’s behalf. These parents do these things for the good of their children, even though they are not good for other people’s children.

Yet privileged parents often feel guilty when they are unable to reconcile being a good parent with being a good socially conscious citizen. The sociologist Margaret Hagerman calls this the “conundrum of privilege.” Despite knowing that doing the best for their children often means leaving other children, often low-income students or students of color, with fewer opportunities, the knowledge doesn’t change their behavior. As Tressie McMillan Cottom writes in her powerful new book, Thick, “They are good people. They want all children in their child’s school to thrive, but they want their child to thrive just a bit more than most.” When it comes to GATE programs and advanced classes where space is limited, privileged parents hoard the opportunity for their own children, especially in racially integrated schools.

Putting the numbers in context with the sociological explanations reveals that black children aren’t included in schools’ conception of gifted and advanced precisely because they are not conceived of as “our” children who deserve the best resources and attention.

As a black parent who now carries socioeconomic privilege, given my husband’s and my own educational status, I, like other black middle-class mothers, find myself in a unique position: a conundrum of constrained privilege. I want to advocate for my black sons, because I only want the best for them. I also know that advocating for my sons to get into GATE or elite academies could move the needle just a bit to increase black representation. But doing this would mean accepting that my already privileged children would receive additional benefits that other black children might need even more.

Instead of having my son take the GATE entrance exam, I decided to use my social capital to advocate for more holistic changes in our district. I spend about six hours a month either volunteering in a second-grade classroom, or discussing school-assessment measures and budgets with teachers and school administration as a member of the School Site Council, or convening with district personnel about citywide initiatives in my position on the District Accountability Committee. My job status allows me the privilege and flexibility to spend my time doing this extra work. But my racial status means this is a necessity. In every single one of these spaces, I am the only black adult. If I am not there advocating for my son and other black students, the data suggest, no one else will.

The education gap cannot be achieved without closing the racial empathy gap. While my individual actions and choices are important, their impact is limited. Until we can develop better admissions tests, or pass legislation banning these tests altogether, or invest more resources in public schools to incorporate GATE-like curricula in all classes, those of us who are willing and able to do “whatever we can” for our children need to expand our idea of who “our” children really are.



Most American kids don’t spend large chunks of their day catching salamanders and poking sticks into piles of fox poop. In a nation moving toward greater standardization of its public-education system, programs centered around getting kids outside to explore aren’t normal.

But that’s precisely what students do at the Nature Preschool at Irvine Nature Center in Owings Mills, Maryland. There, every day, dozens of children ages 3 to 5 come to have adventures on Irvine’s more than 200 acres of woodlands, wetlands, and meadows. These muddy explorers stand out at a moment when many American pre-K programs have become more and more similar to K–12 education: row after row of tiny kids, sitting at desks, drilling letter identification and counting.

Mention how anomalous this seems, though, and the teachers at the Nature Preschool can only express their wish that that weren’t the case: Why is it odd for 4-year-olds to spend the bulk of their time outside? When did America decide that preschool should be boring routines performed within classroom walls?

Today’s kids are growing up at a moment when American childhood—like much of American life—is increasingly indoors and technologically enhanced. Families spend more time indoors and on screens. Smartphones have warped the teenage experience. Perhaps as part of reaction to those trends, the United States is witnessing a budding movement to reintegrate childhood with the natural world. Nature preschools, outdoor pre-K, forest kindergartens—call them what you like: Early-education programs like these are starting in communities all over the country. The Natural Start Alliance, a group advocating for more outdoor experiences in early education, says that the number of “nature-based preschools” has grown at least 500 percent since 2012.

The ideas that underscore these programs trace back, in part, to a 2005 book by the journalist Richard Louv, Last Child in the Woods. Louv argued that American childhood had become overly standardized, overly structured, and overly saturated with technology. He coined a term for the phenomenon: “nature-deficit disorder.” Published just a few years after the adoption of No Child Left Behind—the federal education law that ramped up the emphasis on standardized testing and incentivized schools to focus on math and reading—Last Child received dazzling reviews and was passed around public schools as samizdat. The book helped launch the Children and Nature Network, which describes itself as an “organization whose mission is to fuel the worldwide grassroots movement to reconnect children with nature.”

Louv and fellow advocates present outdoor early education as an answer to a gamut of child-rearing challenges. According to these advocates, a kid who suffers from anxiety doesn’t necessarily need medication, a child who can’t pay attention doesn’t need a computer program to reshape her development, and one who struggles to keep up physically doesn’t need a targeted summer-camp experience to build his muscles. Instead, what they need is more time outdoors. Give young kids the opportunities to engage in hours of free, unstructured play in the natural world, and they develop just as organically as any other creature. They learn creativity as they explore and engage with complex ecological systems—and imagine new worlds of their own. Freed from playground guardrails that constrain (even as they protect), kids build strength, develop self-confidence, and learn to manage risks as they trip, stumble, fall, hurt, and right themselves. Research shows that the freedom of unstructured time in open space helps kids learn to focus. It also just feels good: Nature reduces stress.

And yet, it’s not entirely clear whether or not these programs can deliver on these expectations. Sure, in a generic sense, time outdoors is obviously good for young kids. The hard part is to nail down how much time (and which activities) outside are particularly good for kids—which is to say, what should outdoor education actually look like in practice? Are there particular types of outdoor experiences that kids really need? It’s not clear that anyone knows.

In a sense, outdoor education is right in line with a host of other educational trends. The basic conviction that children grow best when adults grant them space, time, and agency is central to many progressive-education models. Karen Madigan, director of the Nature Preschool at Irvine, says her program draws from a hodgepodge of student-directed pedagogies, including the Montessori, Waldorf, and Reggio Emilia approaches. If these differ in the details, they overlap in the certainty that schools should give kids leeway to explore what they find interesting.

What sets the outdoor-education movement apart, though, is that it also engages certain traditionalist concerns—namely that kids these days are, frankly, getting too damn soft. The pediatric occupational therapist Angela Hanscom attributes the relative physical frailty of today’s children—childhood obesity is up, and overall fitness is flagging—to their increasingly sedentary lifestyles. “When we expect less from our children—instead of holding them to a higher standard—we could be setting them up for failure,” she writes. “Why are our children getting weaker?”

And yet, as research-based as it may be, there is something oddly paradoxical about the whole concept of outdoor early education. For the most part, the ideas that animate the American conversation around early education treat it as a targeted, structured intervention to foster children’s healthy development and eventual success. No wonder outdoor early education—with its counterintuitive promise that children will develop best if adults spend less time trying to intentionally develop them—seems so radical. “I’m constantly having to unlearn my training as an educator … letting go of what I think makes sense,” said Emma Huvos, the founder of Riverside Nature School in Charles Town, West Virginia. “It’s more about giving children the freedom to take control of their own learning.”

Huvos began her teaching career in an urban charter-school pre-K in Washington, D.C., focused primarily on building students’ academic skills. She thrived on building personal relationships with children, but was frustrated to see many flounder when they left her class. “They didn’t have, necessarily, the self-regulation [or] social-emotional skills they needed to thrive once the environment they were in shifted,” she says. So she founded Riverside in an effort to build an early-education program that prioritized those “noncognitive” skills—set on a West Virginia farm that had been passed down through generations in her family.

During a morning visit to Riverside, I saw a red-tailed hawk, a (literal) handful of worms, and the farms’ two pregnant goats. Two boys giggled as they wrestled over a grimy plank of wood they were using as a “pillow” for pretend naps. Other kids were debating whether an insect was a centipede, an earwig, or some other sort of beetle.

They were clearly having fun. But it was also clear why such programs are relegated to the category of “alternative” and accessible almost exclusively to parents who proactively seek them out. It would be hard to make outdoor preschool the rule, the government-sanctioned model, because its benefits are as abstract as its purpose is subjective. When it comes to public funding, it’s much easier to sell programs that promise academic rigor and a neat dovetail with kindergarten.

“[Riverside] is like my laboratory,” Huvos says. Her small, private program serves mostly “somewhat more affluent families.” In West Virginia, where the average monthly cost of center-based child care runs around $560, Riverside’s monthly $400 price tag is relatively steep, since that price only gets kids four days of care per week, and just three and a half hours each day. By and large, Riverside only works for parents who can afford to stop work and be available to pick kids up at 12:30 p.m. (or who have a full-time nanny or relative who can step in).

This bothers Huvos. “It’s become this unique, privileged thing: putting kids outside to play,” she says. Well-heeled parents realize, she says, that “this is what’s going to give your kid an academic advantage. This is what’s going to give your kid life success.” She hopes that if “affluent folks [are] demanding it,” more early education programs will emerge to provide more kids—of all backgrounds—more time outside.

As this happens, getting the details right will be important. How can—how should—early-education programs balance the competing demands of academic development and outdoor play? Most kids could benefit from more time outside, but it’s hard to imagine that they don’t also need time with interesting, vocabulary-rich books.

Figuring out that balance matters even more when schools are welcoming populations that are likely to struggle academically down the line. In the United States, achievement gaps between children from wealthy and low-income families appear well before kindergarten, and evidence suggests that children who start elementary school behind on critical skills tend to stay behind. If children arrive in pre-K with weak language development and academic skills, early educators may rightly feel pulled to focus on these. Sure, skilled educators can integrate math or reading instruction into time spent outdoors, but there are only so many hours in the day, and a recent study suggests that academically focused pre-K programs are particularly good at boosting children’s early math and reading abilities before—and into—kindergarten. It also found that “high-dose academic” preschools were uniquely effective at raising African American children’s math and reading skills.

Is it possible to capture the benefits of unstructured time in nature within the structures of public early education? Mundo Verde, a Pre-K–5th-grade charter school in Washington, D.C., is trying. Its model is defined by three components: student-driven learning, a focus on sustainability, and a Spanish-English dual-immersion program. The school gets kids outdoors by organizing learning into “expeditions”—students dive deeply into a topic, often culminating in an excursion that allows them to expand on what they’ve been doing in class. For example, when Mundo Verde second-graders study rocks, they visit the nearby Luray Caverns and collect fossils at Calvert Cliffs. At the end of a unit on balls, the school’s preschoolers design ball games to play with classmates in a nearby park.

Compared to private programs like Irvine’s Nature Preschool and Riverside, Mundo Verde is expanding who can access outdoor early education. It’s publicly funded, attendance is free, and enrollment is conducted by open lottery. Nearly one-third of its students come from low-income families, and 68 percent are students of color. But those numbers are actually low for a public school in D.C., where over 80 percent of students’ families are low-income and 90 percent are nonwhite.

The program’s executive director and co-founder, Kristin Scotchmer, said that Mundo Verde’s autonomy as a charter school makes it easier to experiment with outdoor education. “What was amazing about founding a school that I think is different from changing a school, is that it was a blank slate,” she said. But Mundo Verde is just one unique school. Its institutional freedoms—inventing a new educational model and experimenting with it slowly, over time—are rare luxuries in public early-education systems, which tend to be enmeshed in mandates governing what students need to learn, the order they should encounter each element, and how most things ought to be taught. “Of course, we are doing reading and math,” Scotchmer said. “It’s fundamental and it’s built-in and baked into what we do.”

Mundo Verde’s challenge—a challenge that many educators across the country are also navigating—largely comes down to conflicting beliefs about what a school should be in the 21st century. Beliefs about where learning should take place and what that learning should look like. But these are debates about something deeper, too: the fundamental question of what childhood should be. That’s not an easy question, and any proposal will have its flaws, but for the kids catching salamanders in the woods of Owings Mills, Maryland, the answer is obvious.

This story is part of our Next America: Early Childhood project, which is supported by grants from the Annie E. Casey Foundation and the Heising-Simons Foundation.



At 10 o’clock on Friday morning, thousands of students across the country commemorated a moment that not one of them was alive to experience: the shooting at Columbine High School in Colorado that killed 13 people 19 years ago today. Kids walked out of their classrooms on Friday to remember and to protest in the latest iteration of the student-led movement against gun violence that burgeoned after February’s Parkland, Florida, school shooting.

It’s fitting that the student who organized Friday’s walkouts—the first protest of its kind pegged to the massacre that happened nearly two decades ago—is a history buff. Lane Murdock, a 16-year-old from Ridgefield, Connecticut, had spent her early life reading about protests and walkouts in history books, she told me, and always wondered what she’d do in the face of injustice. She started a Change.org petition immediately after learning of the Parkland shooting, laying the groundwork for Friday’s demonstration, which included participants from at least one school in every state. Murdock lives 20 minutes from Sandy Hook Elementary School, where 26 children and staff were killed in 2012, but she has no other personal connection to gun violence. In fact, she was motivated by what she worried was her detachment from the problem: “I was desensitized,” she said. “This country was desensitized.”

That Friday’s walkouts were organized by a student with little connection to gun violence shows  how post-Parkland activism has morphed into a thriving national student movement. But as the movement expands, it’s also becoming clear just how hard it is to find a unified student voice. A student’s personal background—including race, class, and past connections to gun violence—shapes his or her relationship with the movement, and youth are navigating the difficult task of finding common ground. A movement that first framed itself as a call to action from young people to adults is now just as much a dialogue among different factions of the country’s youth.

When the post-Parkland movement first sprung up, some observers questioned whether the tremendous attention it garnered was attributable in part to the students’ relative affluence. Friday’s walkouts are another case of large-scale activism organized by students from privileged schools: Fewer than 4 percent of students at Murdock’s Ridgefield High receive free or reduced-price meals. Youth organizers have certainly endeavored to make their protest inclusive, demonstrating their solidarity with communities that suffer from daily gun violence in part by encouraging walkout participants to wear orange, a color that has come to symbolize gun reform after teenagers used it to memorialize a 15-year-old shot and killed in Chicago in 2015. For their part, students in Chicago planned a citywide school walkout in conjunction with Murdock’s campaign. But despite their efforts to involve schools in neighborhoods with varying income levels and racial makeups,  organizers—who attend Walter Payton College Prep, a selective-enrollment magnet school, and the private Francis W. Parker School—struggled to bring the walkout to fruition at most of the city's schools.

Several of the 22 Chicago schools participating in today’s walkouts are located on the city’s South Side, where gun violence is particularly prevalent and poverty is rampant. But hundreds of schools are not on the list of participants. That’s in large part because of the practical challenges of planning a student protest. Many of the schools organizers reached out to, they said, were hesitant to participate because administrators had threatened them with disciplinary action. Organizers encouraged students to stay out of school for a full day following the 13 seconds of silence to remember those killed at Columbine; students at many schools are hosting rallies, speakers, and voter-registration drives throughout the day. The organizers said letters they sent to administrators urging them not to punish students in some cases resulted in schools easing their policies. But the full-day walkout is a tough sell—that’s six or more hours of missed classroom learning. Chicago Public Schools for its part has stated that students won’t be disciplined for holding walkouts or group protests on school grounds, as long as the events follow district guidelines and do not exceed 30 minutes; students whose protesting exceeds that will face disciplinary action.

Practical challenges aside, many students have sought to complicate the narrative attached to the walkouts—including some who've distanced themselves from them—in an effort to raise awareness about the diversity of youth experiences when it comes to gun violence. Yesterday, 20 organizations representing more than 1,000 students of color released an open letter in advance of today’s walkouts, demanding that conversations about school safety take racial-justice issues into account. The letter emphasizes that efforts to strengthen school security affect students of color at disproportionate levels.

Rosa Florez, a 17-year-old student from Oak Ridge, Florida, who helped draft the letter, told me Thursday that she was still deciding whether to participate in Friday’s walkouts. “I feel kind of disconnected from the issue at hand,” she said, stressing that school shootings deserve attention. But she worries that the walkouts could lead to school-safety measures, like more campus police, whose negative consequences disproportionately affect disadvantaged students. “The community that becomes more vulnerable with the legislation that is proposed will be my community,” she continued. “If I walk out, what legislation am I supporting?”

It’s also worth noting that students at Columbine High School are not participating. The school has commemorated the day annually by having students engage in community-service work rather than attend classes—an approach that its principal promoted this year as an alternative to walkouts. Some Columbine students expressed disappointment that the Connecticut organizers chose the anniversary of the 1999 massacre for their national protest. “This is the worst day for our community,” said Kaylee Tyner, a junior who believes in the protest’s cause and helped organize Columbine’s participation in the March 14 student walkouts. “It was like using our anniversary to push this political agenda … It could’ve been on the 19th or something,” she said. A student at Marjory Stoneman Douglas High School in Parkland told The New York Times that MSD administrators are urging students not to walk out out of respect for the Columbine students.

For Murdock, who said many in the Columbine community expressed support for the Friday walkouts, this iteration of the youth movement is ultimately aimed at celebrating today’s students and the movement that’s empowered young people across the country. And perhaps these debates among young people over how and when to make their voices heard are a manifestation of that empowerment.

In discussing last month’s walkouts, the student-activism scholar Dawson Barrett told me that these national youth demonstrations function as a kind of civics education for all students, whether or not they decide to participate. “By May,” he told me then, “every high-school student in the United States is going to have contemplated protesting.”

Now, in April, it seems that students are doing more than contemplating: They are debating, arguing, and reframing the conversation. Maybe that’s a sign that the movement is the most powerful it’s been yet—or maybe it's a sign that it's turning into something less unified and more complicated.



Should Brett Kavanaugh get confirmed as a justice of the U.S. Supreme Court, five of the Court’s nine sitting justices will share an experience that is foreign to most Americans: that of attending one of the nation’s private high schools. Of the court’s conservative block (Justices Roberts, Thomas, Gorsuch, Alito, and presumably Kavanaugh, sooner or later), all but Alito graduated from a private high school. Of the court’s liberals (Justices Ginsburg, Breyer, Kagan, and Sotomayor), all but Sotomayor graduated from a public high school. Just 9 percent of American high-school graduates got their diplomas from a private school, during the 2016-2017 school year, according to the National Center for Education Statistics.

Of course, the Supreme Court is an elite institution, and the lived experiences of the justices are not—and need not be—broadly representative of the American public’s more generally. One hundred percent of the justices, after all, attended elite law schools—not exactly a common experience. There are two additional facts about the justices’ educational backgrounds that are perhaps even more remarkable than the first: All five of the justices (including the would-be justice, Kavanaugh) who attended private school went to schools that were not just private but Catholic. And two—Kavanaugh and Gorsuch—attended the very same school: Georgetown Prep.

Georgetown Prep is not just any private school. It is a private, predominantly white Jesuit high school for boys in a wealthy suburb just outside of Washington, D.C., founded in 1789. Today, its lush and sprawling campus features renovated Georgian-style brick buildings, a glass-roofed campus hub with a full-service café, and stunning athletic facilities including a 200-meter indoor track and an 18-acre golf course, among other amenities. It’s one of the country’s most expensive private schools, costing more than $60,000 per year for the students who board, and just over $37,000 for the students who don’t. That tuition often pays off: Each year, every single one of its 100-plus graduates enrolls in a four-year university, and the school boasts an ever-growing roster of renowned and highly accomplished alumni. In addition to Gorsuch and Kavanaugh, Jerome Powell, who was tapped late last year as chair of the Federal Reserve, attended Georgetown Prep, too.

It was clear from Kavanaugh’s acceptance speech last Monday, as well as others’ reflections, that his own educational experiences have had a significant impact on his life—that he’s someone who loves to learn and be in the classroom, whether as a pupil or a teacher, and that he has a profound appreciation for education’s role in society. He’s taught “hundreds of students, primarily at Harvard Law School” for the last decade or so, he noted, and continues to engage with the education world in his capacity as a father of two young girls, coaching their basketball teams and attending college-level games with them. And his mother, Martha, was an educator before she went on to enroll in law school and become a judge herself—she taught history, he explained in his speech, “at two largely African American public high schools in Washington, D.C.” in the 1960s and ‘70s. Her example, he stressed, “taught me the importance of equality for all Americans.”

Aside from Kavanaugh and Gorsuch, Thomas, Roberts, and Sotomayor also graduated from Catholic high schools. Respectively, they were: the since-closed St. John Vianney Minor Seminary, a boarding school in Savannah, Georgia; La Lumiere School, a college-prep boarding and day school in La Porte, Indiana, that today charges $47,500 annually for those who board; and Cardinal Spellman High School in the Bronx whose current annual tuition is $8,800. (Alito graduated from Steinert High in Trenton, New Jersey; Breyer, from Lowell High, an elite public magnet school in San Francisco; Ginsburg from James Madison High in Brooklyn; and Kagan, from Hunter College High, a publicly funded institution for gifted students in Manhattan’s Upper East Side that’s affiliated with the CUNY institution.)

There are few definitive takeaways to glean from the justices’ similar educational upbringing, however—other than the fact that all enjoyed tremendous success after graduating. Private-school attendance is not a predictor of any political persuasion, for example. Ample evidence suggests that public officials who graduated from the same educational institutions often leave their schooling with vastly different perspectives on the world and the law, and it’s difficult to find any research on whether there’s a correlation between one’s K-12 educational experience and his or her outlook on political and social issues. I’ve written before about the tendency of public officials, particularly those in Washington, D.C., to send their own kids to private schools, and about the “disconnect that often separates public-school classrooms from the people who decide what happens in them.” But even that phenomenon doesn’t mean officials are “in a private-school bubble.” (As an adolescent, I myself attended an expensive, elite private school in Hawaii—Punahou, the same institution that Obama graduated from in 1979.)

One recent Gallup poll, however, did identify certain characteristics that tend to correlate with the kind of school in which parents opt to enroll their kids, some of which are obvious: Affluent families are far more likely than low-income ones to choose private education, for example, with twice as many families with yearly incomes above $75,000 doing so (13 percent) compared with those whose incomes are $30,000 or less; the breakdown is similar for families that attend church weekly compared with those who have no religious preference. The report also found that “Republicans and conservatives are among the groups least likely to have a child in public school,” a trend that it speculated could do with their greater tendency toward religiosity as well as toward disillusionment with the public-school system. A separate Gallup poll found that just 39 percent of Americans who are or lean Republican consider public schools “great” or “excellent,” compared with about half of respondents who are or lean Democratic.

Perhaps more revealing than his own schooling is the fact that Kavanaugh, according to his testimony in his 2004 Senate confirmation hearing, previously helped spearhead school-choice-related outreach efforts for the Federalist Society, a legal organization of conservatives and libertarians. He was also one of the attorneys tapped in 2000 to represent then-Florida Governor Jeb Bush in a long-drawn-out lawsuit that sought to end a highly controversial state school-voucher program that Bush had spearheaded. (The Florida Supreme Court in 2006 ruled that the program was unconstitutional, a decision that observers predicted would have major implications for similar initiatives elsewhere in the country.) According to Politico, Kavanaugh also said in a 2000 TV appearance that he anticipated the U.S. Supreme Court would one day uphold school vouchers.

Should he be confirmed to the Court, his views on these matters could be hugely consequential for the country, in part because of how much influence the Court has over education. “The public school has served as the single most significant site of constitutional interpretation within the nation’s history,” Justin Driver, a professor of law at the University of Chicago, argues in the introduction of his forthcoming book The Schoolhouse Gate: Public Education, the Supreme Court, and the Battle for the American Mind. “No other arena of constitutional decisionmaking—not churches, not hotels, not hospitals, not restaurants, not police stations, not military bases, not automobiles, not even homes—comes close to matching the cultural import of the Supreme Court’s jurisprudence governing public schools.”

A slew of education cases could make their way up to the nation’s highest court in the (near) future, and in particular, affirmative action is almost certain to get another hearing. In its most recent consideration of the issue, the Court found in Fisher v. University of Texas at Austin that higher-education institutions can consider race as one factor among many in admissions decisions. But the issue is, as my colleague Adam Harris has written, far from settled. There’s a pending lawsuit against Harvard that accuses it of discriminating against Asian American applicants, as well as Trump’s recent decision to rescind guidance issued by the Obama administration encouraging educational institutions to consider race as part of efforts to diversify their student bodies, both of which make the future of affirmative action all the more precarious.  

And then there’s affirmative action as it pertains to selective-admissions public high schools, an issue that could foreseeably make its way up to the Court at a time when it’s more clear than ever, as the sociologists Margaret Chin and Syed Ali recently wrote in The Atlantic, that “there aren’t enough great schools and there are too few seats at the best schools.” To address this supply-demand mismatch, those best schools have to get picky about whom among a vast pool of desirable candidates to admit; for some, that could come down to considering applicants’ race. The Supreme Court has generally ruled that in higher education the right to academic freedom enables colleges and universities to factor race into admissions decisions, but it’s hard to say whether that thinking will apply to public high schools. “If anything,” said Rachel Moran, the dean emerita of and professor at UCLA School of Law and an expert on education policy, affirmative-action practices in high schools “are already on a more fragile footing than than colleges and universities.” In one 2007 case, the Supreme Court ruled that a program in Seattle that considered students’ race in determining their high-school assignments was unconstitutional.

That the 2007 case could serve as a harbinger for what’s to come with regards to affirmative action at the K-12 level is a reminder of the power of precedent. As the University of Chicago’s Driver argues, the Supreme Court can have, and has had, far-reaching influence on the country’s education system. And while the Justices share unusual and noteworthy educational experiences, those personal narratives are ultimately less revealing than the legal history itself.



Thirty-five years ago, in April of 1983, Ronald Reagan appeared before the press to publicize a government report warning of “a rising tide of mediocrity” that had begun to erode America’s education system. Were such conditions imposed by an unfriendly foreign power, the authors declared, “we might well have viewed it as an act of war.”

Despite its grave tone, the report, titled “A Nation at Risk,” had little direct impact on policy. It did, however, establish a new way of talking about public education in the United States, a master narrative that has endured—and even subtly changed American education policy for the worse—over the past several decades.

Across that stretch of time, politicians and policy makers have spoken often of the inadequacy of “America’s schools.” In fact, this trope is one of the few things that Betsy DeVos, Donald Trump’s regulation-averse secretary of education, has in common with her predecessors; she and previous education secretaries have regularly discussed the nation’s schools as a cohesive whole. This phrasing is useful shorthand for a national official, but it obscures the fact that the United States does not actually have a national education system. Many countries do. In France, for example, a centralized ministry of education governs schools directly. But in the U.S., all 50 states maintain authority over public education. And across those 50 states, roughly 13,000 districts shape much, possibly even most, of what happens in local schools.

The abstraction of “America’s schools” may be convenient for rousing the collective conscience, but it is not particularly useful for the purpose of understanding (or improving) American education. Consider the issue of funding. On average, federal money accounts for less than 10 percent of education budgets across the country, and the rest of the financial responsibility falls to states and local schools. If local schools are unable to raise what they need, the state is usually well positioned to make up the difference, but states differ dramatically in their approaches. On average, states spend roughly $13,000 per student on public education—but looking at the average alone is misleading. Only about half of states spend anything close to that figure: A dozen spend 25 percent more than the national average, and 10 states spend 25 percent less. The result is significant disparities, and some striking incongruities. New York’s schools, for instance, spend roughly three times as much per student as Utah’s schools—a huge difference, even after accounting for New York’s higher cost of living.

Additionally, some states do much more than others to ensure that each district is properly funded. Local property taxes help fund schools nationwide, but in some places, like Massachusetts, the state steps in to provide additional resources for lower-income areas. In other places, like Illinois, property taxes are simply the primary sources of school funding, which means less money for poor districts than for wealthy ones.

Though states often take similar approaches on curricula and teacher licensure, they tend to differ considerably in policy and practice. Things like early-childhood education, charter-school regulation, sex education, arts programs, teacher pay, and teacher evaluation are anything but uniform across the 50 states. To say that America’s schools are failing students on any of these issues would be a gross generalization—it would obscure all the national variety, like the fact that in Massachusetts, charter schools are tightly regulated, while in Arizona, they’re hardly regulated at all.

It’s longstanding American practice for cities and towns to have a significant amount of power over education. But local control also persists because of the importance of context. What schools need in order to succeed depends significantly on the needs and concerns of the local community, and policy tends to reflect that. Teacher hiring, for instance, is usually done at the local level, and is often shaped only indirectly by state policy. As a result, the process looks quite different from place to place depending on the approaches districts take to recruiting teachers, screening applicants, and making job offers. Further, while curriculum standards are shaped by states, districts determine what they actually look like and which books students carry around.

Districts also decide how to structure “attendance zones,” which determine where students enroll. As with congressional districts, a lot rides on how a district chooses to draw these boundaries, with gerrymandering exacerbating demographic differences between neighborhoods and towns. Many districts, however, allow families to attend any school within the district—a policy that can promote integration if coupled with mechanisms for promoting school diversity. In Cambridge, Massachusetts, for instance, the district uses a “controlled choice” system designed to maintain a balanced mix of students at all schools; in essence, parents can choose any school in the district, with enrollment preferences given to families who help bring the school’s demographics closer in line with the city’s.

Public schools in the United States differ so much from state to state and from district to district that it hardly makes sense to talk about “America’s schools.” In fact, a focus on large-scale national reform can actually do harm, insofar as it must emphasize generic one-size-fits-all solutions that ignore state- and local-level needs. The nationwide push to evaluate teachers using student standardized test scores is a classic example. Strongly backed by former Secretary of Education Arne Duncan, so-called “value added” models of assessing teachers were adopted across the nation despite the concerns of education scholars. Worse, the models have undermined trust in the process of teacher evaluation and driven some successful educators out of the profession.

This is not to say that taking the national perspective can’t be valuable. Troubling patterns do exist across the U.S., and discussions about them can play an important role in shaping both public understanding and education policy. Achievement gaps across race and class, for instance, are an important reminder of broader social and economic inequalities, and advocates have used evidence about those patterns to make the case for universal early-childhood education. Similarly, a national dialogue about the disproportionate punishment of black and brown children in schools has drawn attention to an issue that might otherwise have gone unnoticed. These kinds of broad conversations can generate both political will and policy responses.

But more-abstract national-reform rhetoric has little to redeem it. In a system that affords significant authority to schools, districts, and states, it is ill suited for identifying the actual strengths and weaknesses of schools. And when used to drive policy, such rhetoric can generate support for policies that are at best distracting and at worst detrimental. One major example of this is No Child Left Behind (NCLB), the piece of Bush-era legislation that pushed schools to improve students’ standardized test scores each year. But because the federal government has limited power over schools, it offered little other than punishments, such as staff reassignments or school closures, to induce those gains. States and school districts focused their energies on avoiding such punishments, often ignoring critical issues like school culture and student engagement.

The authors of “A Nation at Risk” concluded their report with a simple claim: “Education should be at the top of the Nation’s agenda.” And in creating a new kind of school-reform rhetoric, they seem to have achieved their aim. The question is, has it done more harm than good?



A former Michigan State University dean—and the former supervisor to the serial sexual abuser Larry Nassar—is now facing his own set of sexual-harassment accusations. William Strampel, who served as dean of the university’s College of Osteopathic Medicine until December 2017, allegedly sexually harassed four MSU students and stored pornography on his university-issued computer, according to a court affidavit. Strampel, who stepped down as dean citing “medical reasons,” was arrested Monday night on four charges including criminal sexual conduct and willful neglect of duty.

The latter charge focuses on Strampel’s obligations as a public-university administrator who oversaw Nassar and allowed him to continue seeing patients even while he was the subject of a Title IX investigation into accusations that he had assaulted a female student. Nassar, the former MSU sports doctor, was in January sentenced to up to 275 years in prison for molesting dozens of young female athletes over his decades-long career. Strampel had been named as a defendant in earlier civil lawsuits against MSU contending the university failed to protect Nassar’s victims. Strampel, who was arraigned by video on Tuesday, is denying the charges, according to news reports.

The new revelations help explain how sexual harassment can fester at higher-education institutions like MSU. Rarely do acts of sexual assault happen in isolation; they proliferate, as The Atlantic contributing writer Marianne Cooper has pointed out, in part because such institutions tend to be “male dominated, super hierarchical, and forgiving when it comes to bad behavior.” To have one harasser in charge of another is a particularly extreme version of this dynamic, practically guaranteeing that harassment will last.

The court affidavit alleges that Strampel leered at and groped at least two students and made sexually suggestive comments to at least four. Investigators in February uncovered roughly 50 photos of “bare vaginas, nude and semi-nude women, sex toys, and pornography”—many of them apparently “selfies” of female MSU students, according to the affidavit. Also uncovered on Strampel’s computer: a video of Nassar performing a “treatment” on a young female patient.

One of the questions that has lingered since Nassar’s high-profile sentencing hearing: How did the one-time USA Gymnastics doctor get away with molesting young female athletes for so long? It’s clear that a lack of accountability at MSU is largely to blame, and the allegations against Strampel offer the latest clue as to exactly how accountability crumbled when it came to punishing Nassar. One victim is cited in the affidavit as saying she “was not surprised Nassar had been able to victimize so many women under the supervision of Strampel.”

In a statement, John Engler, the newly appointed interim president of MSU, said that Strampel’s “failings are unacceptable.” “That is why our work to change procedures, strengthen accountability and prevent sexual misconduct is so important,” continued Engler, who in February began the process of revoking Strampel’s tenure and terminating his employment. “While the crimes of one doctor and the misconduct of his dean do not represent our university, they do demand the scrutiny of everyone in order to assure individuals like these can never be in a position again to harm others.”

MSU’s organizational chart shows an immense university that, like many if not most large higher-education institutions, is highly hierarchical. The College of Osteopathic Medicine—which has numerous departments, its dean’s office alone comprised of more than a dozen executive staff—is one of 17 degree-granting colleges at MSU. Those report to the central administration, which, in addition to the university’s president, includes two executive vice presidents and the board of trustees.

Cooper, in her article for The Atlantic, cited research showing that “male-dominated organizations are more likely to have cultures characterized by aggressive and competitive behaviors and so-called locker-room culture” and that such organizations are more likely than female-dominated ones to condone sexual misconduct in the workplace. This factor may have contributed to the persistence of sexual harassment at MSU’s College of Osteopathic Medicine (where a slight majority of the top executives are men). All but two of MSU’s trustees are men, too.

Cooper also cited a tendency to forgive bad behavior as contributing to sexual harassment in large organizations, and this ingredient is perhaps the most pertinent when sussing out what went wrong at MSU. Nassar was effectively forgiven by MSU officials, including Strampel, until the very end. Strampel allowed Nassar to continue seeing patients before MSU concluded its Title IX investigation. And when MSU’s Title IX office did conclude its probe, it cleared Nassar of wrongdoing, concluding his behavior was “medically appropriate.” Then, Strampel failed to “enforce or monitor” protocols that had been set to govern Nassar’s behavior despite indicating to the Title IX office that he would do so.

For an alleged harasser to have supervised a serial harasser is to put too fine a point on the dynamics Cooper describes. Who in this system was looking out for the students? Who could students have turned to for real, meaningful intervention? Unfortunately, it seems that help, for many, was too far off.



I first learned about periods from a cartoon. Just before I started middle school, my mom handed me a large white book with three cartoon girls on the cover, each wrapped in a towel, dripping wet, as though fresh out of the shower. The book, which was published by American Girl, was called The Care and Keeping of You: The Body Book for Girls. On the opening spread was a letter to readers: “The more you know about your body, the less confusing and embarrassing growing up will seem—and the easier it will be to talk about.”

The head-to-toe guide started by explaining that “everybody” goes through puberty, and then broke down into sections on everything from regular body hygiene to getting your period for the first time. Each page featured smiling cartoon girls of all races and sizes demonstrating everything from how to shave your legs to how to shop for a first bra. As my mom and I read the book together, I remember feeling a little less afraid of what my body would become. But after we finished reading about the difference between training and underwire bras, my mom closed the book. “We’ll read more when you’re older,” she said.

I couldn’t wait. I snuck the book off of her dresser that night, and, crouched next to the night-light in my room, I read about periods and vaginas, and the hormones that would change my body from “little girl to grown-up woman.” I came back to the book many times in the coming years, including when I eventually got my own period two years later.

I wasn’t the only one who found solace in The Care and Keeping of You. The book, which turns 20 years old in September, has sold more than 5.1 million copies since its initial release. And as recently as 2016, it was still spending time on the New York Times best-seller list. It has been embraced by preteens, parents, and sex educators alike for its approachable tone and gentle introduction to big bodily changes.

“In terms of just a good, basic, ‘This is your body and this is how it works, and this is what’s going to happen to it,’ this book is one of the best there is,” says Heather Alberda, a sexuality educator with the Ottawa County Department of Public Health in Michigan.

The book was an immediate best seller, and Barbara Stretchberry, the executive editor at American Girl, who has been with the company for 20 years, remembers letters pouring in from tweens offering thanks for the book. In 2013, the company updated the book, featuring even more diverse illustrations, and released a second book, The Care and Keeping of You 2: The Body Book for Older Girls, which delved more into emotional changes felt during puberty and is meant for readers ages 10 and up. (The original and its updated counterpart are meant for ages 8 and up). American Girl has also released several other advice books on topics ranging from understanding feelings to friendship troubles, and last year it came out with a puberty guide for boys called Guy Stuff:The Body Book for Boys.

But all of the books are meant to be approachable to young readers, which is why the company says there’s no mention of sex. The intended audience, the authors say, is readers “on the front end of puberty.” The majority of girls begin to go through puberty between the ages of 9 and 13. But many medical experts agree that today’s kids are going through puberty at younger ages than before. A study published in the medical journal Pediatrics in 2010 found that about 23 percent of African American girls, 15 percent of Latina girls, and 10 percent of Caucasian girls had marked breast development at age 7.

Early-onset puberty is what inspired American Girl to publish the book in the first place. The company was—and still is—largely known for its expensive dolls and accompanying books featuring young girl characters living in different eras of American history. It has also published a bimonthly magazine for preteens since 1993. After the magazine debuted, the company quickly amassed a giant folder of handwritten letters from young readers inquiring about their changing bodies. Some letter writers asked whether they were pretty. Others wondered why they hadn’t grown breasts yet, or whether they needed to lose weight. Then in 1997, American Girl’s founder, Pleasant Rowland, read a New York Times article about early-onset puberty and sensed an opportunity.

“These are very difficult things for girls to talk about,” says Valorie Lee Schaefer, the book’s author, who had previously been a copywriter for the American Girl Doll catalog. “We were thinking, ‘We can normalize this conversation. We can give girls words to use, we can tell them some of the things they’re thinking about are absolutely normal, all the things that make young girls feel like, I’m a freak.’”

The company held focus groups, and found that tween girls were curious not only about their periods, but also about when they should start wearing a bra and how they should deal with pimples that popped up out of nowhere overnight. Schaefer says the company took this feedback, as well as the letters, and used it to develop the book’s structure, targeting it explicitly toward younger girls about to experience puberty, not preteens already in its throes. It begins with friendly tips on hair care, and then slowly progresses to more advanced physical and emotional changes and other challenges encountered by this age group, including how to identify the onset of eating disorders. “A girl of 7 doesn’t wonder about the same things a girl of 12 or 14 does,” Schaefer says. “So just meeting a girl right at that place—7, 8, 9—was what we tried to do.”

The company consulted a pediatrician to make sure the information was medically accurate, and Schaefer wrote the text in a deliberate, reassuring tone, one she called the “trusted, cool aunt.” “It wasn’t your mom or dad’s older sister,” Schaefer says. “It was probably their younger sister, someone with a few years under her belt, but also someone who wasn’t so out of touch with her adolescence that she couldn’t remember what a confusing time that was.”

That cool-aunt tone was also reassuring to parents. Many parents I spoke with for this article said they chose to give the book to their daughters because they recognized the American Girl name and thought the book was age appropriate. Lisa Goldschmidt, an attorney who has two daughters and lives in Wayne, Pennsylvania, remembers standing overwhelmed in front of an adolescent-health section at a bookstore, looking for a good resource for her then-9-year-old daughter. Some books, she says, were written for parents and were too clinical. Others didn’t seem detailed enough. But The Care and Keeping of You “struck the right note between chatty and serious in an approachable way.” She gave it to her elder daughter, who immediately handed it back to her. She had already read the book and giggled over the illustrations with friends at a sleepover.

Every woman I spoke with who grew up reading the book remembers something a bit different. Jensen McRae, a 20-year-old student at the University of Southern California, first read the book as a 10-year-old and, along with her friends, often flipped back to the breast-development page, which shows five illustrations of a topless girl standing in front of a sink. In the first, the girl is flat-chested, and in the last, she has round, developed breasts. When she learned about puberty at school, McRae remembers her teacher spinning a metaphor about how some students would have “grapes” and others would have “watermelons.” “So the book was definitely more informative than that,” she says.

Danielle Weisberg, a 27-year-old comedy writer living in Los Angeles, remembers the book’s lesson on shaving to this day. “There’s this part that says you don’t have to shave your thighs because that’s ‘an awful lot of leg to shave,’” she says. “And I think about that almost every single time I’m about to shave my legs above the knee.”

The illustrations, clever captions, and factual information are why Alberda, the sex educator in Michigan, continues to recommend the updated versions of the book to parents. Michigan mandates HIV education for school-age students, but lets individual school districts decide how to handle sex education, including lessons on puberty. Across the country, only 24 states mandate sex education, and even in those states it’s likely that many students learn about puberty outside of the classroom.

“When parents think about giving ‘the talk,’ their immediate thoughts often go to genitals and what we do with them,” Alberda says. “And I think The Care and Keeping of You is a great book to get away from the whole sex piece, and focus on what’s going to happen to your body, physically, mentally, and emotionally in regards to puberty in those early stages.”

Still, there were aspects of the book that some found to be inappropriate for its young audience, such as the two-page spread on how to insert a tampon, which broke it down into four steps, and included an anatomical diagram of the vagina. The company received feedback from many parents who felt the diagram was too advanced—if not graphic—for their young daughters. “That section, that spread of the book, is the one that gave everyone the most sleepless nights,” Schaefer, the original author, says. “When I think back on it now, I wonder, why were we so stressed about it? But it was a place many books for girls that age hadn’t gone before.”

Even though in 2013 the company made the decision to split the books by age, they overlap quite a bit, though the “older girl” book goes into more depth about eating disorders and the emotional changes of puberty. (It also features a more descriptive diagram of the female anatomy, including a labeled clitoris, something nearly every sex educator I spoke with noted was missing from the original.) But there’s another noticeable omission in the updated younger-girl book—the tampon spread.

“The tampon information was so critical, but I’m a believer in meeting kids where they are and giving them information they’re ready to take,” says Cara Natterson, a pediatrician and the author of the “older girl” version of the book. “Because when girls start their periods, the vast majority of them use pads, and there was really no pad information in the original book. So it wasn’t to keep the tampon information from the youngest kids. It was just to pace them and give them information for the stage they were at.”

But some sex educators say the books suffer from a pretty big blind spot. Perryn Reis is the associate director of Health Connected, a sex-ed nonprofit based in Northern California. Reis has encountered the book in some of the classrooms she’s visited, and appreciates some things about it. But, she says, the book is heteronormative. At one point, it says readers “may begin to notice boys in a whole new way.” It also frequently refers to changes that will happen to “girls,” a generalization Reis avoids when in the classroom so as to better include transgender students. “The language we use in the classroom is ‘a person born with a female’s body,’” she says. “We go into the difference between biological sex, sexual orientation, and gender in fifth grade. It’s really hard because puberty is about the physical changes of getting a period and growing breasts, but there is a lot of variation and variability in our world, and we want to be inclusive of that, and also careful with our language.”

The Care and Keeping of You was a formative book for many Millennial women who were in the target audience when it was first published, and for younger generations of girls, but it is just one of many such at-home guides to sex and puberty that kids have learned from over the years. The creators of the seminal Our Bodies, Ourselves, published in 1970 and known for teaching women about their anatomy and sexuality, published a teen version of the book in 1998, the same year as the first edition of The Care and Keeping of You. It went in-depth into topics related to puberty, including eating disorders, teen pregnancy, STDs, and relationship violence. Fictional books for teens have also provided some practical lessons over the years — Judy Blume’s classic Are You There God? It’s Me, Margaret., a coming-of-age novel published in 1970, tackles puberty, crushes, buying a bra, and, yes, periods.

Then there are books like It’s Perfectly Normal, which has been frequently banned from school libraries since its release in 1994. Written by Robie Harris, the book is intended for children 10 and up, and covers puberty, pregnancy, STDs, and sexual orientation, while also featuring full-color pictures of naked people. In 1999, Harris published It’s So Amazing, a book for younger children about pregnancy and childbirth. “Those have been controversial, but have some great, accurate information,” Reis says.

Many sex educators I spoke to also recommended Sex Is a Funny Word, a comic book for kids ages 8 to 10 released in 2015 that has reached acclaim for being trans-inclusive, and for using diverse representation across race, ability, gender, and sexuality.

Even with all of these options, Alberda, the Michigan-based sex educator, says The Care and Keeping of You still stands out for the way it focuses on questions tween girls have about their bodies. She believes it helped pave the way for books like The Girls’ Guide to Sex Education, a question-and-answer book published earlier this year, and Puberty Girl, another illustration-heavy guide to growing up. Alberda also recommends HelloFlo: The Guide, Period., an illustrated guide to puberty that talks about periods, and also gives historical context for society’s changing attitudes about ideal breast size and pubic-hair grooming.

Of course, all of these books exist in a world where kids can easily find similar information on Google. But Natterson, the author of The Care and Keeping of You 2, still feels there’s a place for books that are introduced at just the right time. And she’d love to publish a book about sex under American Girl’s brand name. She just doesn’t see that happening yet. “I tell everyone I would love to write that book with American Girl, but that’s not what these books were meant to do,” she says. “It’s funny how this one book is sort of a safe reminder of what it was like to go through puberty. There’s something really comfortable about that.”



The February 14 Parkland shooting that killed 17 people has led to a slew of policy proposals, including the headline-grabbing call from President Trump and others for laws that would arm educators with guns. There have also been appeals for schools to increase the number of armed law-enforcement officers on campus and to fortify their buildings. Trump says he wants schools to be as secure as airports.

One of the questions on the table: school discipline. Do schools need to punish unruly children earlier on and more harshly, in the hopes that doing so prevents larger, more violent transgressions later? In 2014, the Obama administration released guidance that encouraged schools to emphasize “constructive interventions”—victim-offender mediation, for example, or preventative classroom-management strategies—rather than more punitive approaches.

In part because of this directive, schools in recent years have phased out zero-tolerance policies, like automatic out-of-school suspensions even for minor infractions such as swearing, which became popular after Columbine; additionally, many schools have de-emphasized their reliance on campus security and police officers to handle misconduct. Conservatives have questioned whether this shift has made campuses more dangerous, and Trump is now indicating he wants schools to pivot back to a more disciplinarian approach.

After Parkland, Trump announced the creation of a school-safety commission. One of its specific tasks is to review the Obama administration’s 2014 guidance and decide whether it ought to be rescinded. The goal of the 2014 guidance was to eliminate race-based discrimination in discipline practices: Federal data had long shown that students of color were suspended at disproportionately high rates despite evidence suggesting that such students are no more likely to misbehave than are their white peers.

Critics, however, decried the new rules as federal overreach, with some concluding that the policy—which threatens to withhold funding for schools that fail to comply with it—has hampered educators’ ability to ensure their schools are safe and orderly. Some studies have found a correlation between discipline reform and increased rates of reported disorder, while others have associated it with a decline in academic performance for never-suspended students. (Any research on student-discipline practices is limited in its ability to draw causal conclusions, as schools are inherently difficult settings for experimental research and because districts have translated the Obama guidance into local policies in varying ways.)

Now, some policymakers and pundits have started to scapegoat discipline reform as a key factor behind campus massacres. School-based shootings rightly lead to policy discussions, “but to say that we should therefore be on the lookout for more dangerous kids to the point that it feels like fear-mongering—that could exacerbate the problem instead of actually solving it,” said Cami Anderson, the former superintendent of Newark Public Schools and founder of The Discipline Revolution Project.

In a hearing with U.S. House representatives this past Tuesday, Education Secretary Betsy DeVos, who’s leading the White House’s school-safety commission, refused to elaborate on how or why the elimination of the 2014 guidance factored into the commission’s goals, noting that the prospective repeal is part of the administration’s larger effort to review pre-Trump executive regulations. Liz Hill, a spokeswoman for DeVos, on Wednesday stressed that the focus on student discipline is just one item on a menu of potential “common-sense solutions to prevent school violence.” “Everything is on the table when it comes to keeping our nation’s students safe in school,” Hill said in an email, noting that the commission will hear from a range of stakeholders. “No single policy topic nor group’s input will carry more weight than another.”

But conservative think tanks and lawmakers have made it clear that they believe the Obama-era guidance is a key contributor to the likelihood of another Parkland. The House Judiciary Subcommittee on Crime, Terrorism, Homeland Security, and Investigations, for example, scrutinized it at a hearing on school Tuesday morning titled “Preventable Violence in America: An Examination of Law Enforcement Information Sharing and Misguided Public Policy.” And the right-leaning Heritage Foundation recently announced the launch of a robust school-safety initiative, publishing a report that laments the Parkland shooting as a potential consequence “of failing to punish and correct serious wrongdoing by troubled youths” thanks to policies like the 2014 guidance.

Similarly, Florida Senator Marco Rubio, a Republican, earlier this month urged the Justice and Education departments to revise the 2014 student-discipline guidelines on the grounds that they “may have contributed to systemic failures to report [the Parkland gunman’s] dangerous behaviors to local law enforcement.” The Obama administration’s guidance encouraged schools to emphasize “constructive interventions”—victim-offender mediation, for example, or preventative classroom-management strategies—over stringent practices such as out-of-school suspensions and a default reliance on security or law-enforcement officers to handle misbehavior. This directive, Rubio argued, “arguably made it easier for schools to not report students to law enforcement than deal with the potential consequences.”

It’s not that school discipline doesn’t matter: A student whose misbehavior is left unaddressed can certainly put a school at risk, posing a danger to not only her peers and teachers but also to herself. And any discipline policies that are shown to hamstring educators and law-enforcement officials in their efforts to deal with such conduct—which some researchers contend the 2014 guidance has done in isolated instances—deserve scrutiny.

But the discipline practices have been, and continue to be, scrutinized. And despite the limitations of the data and some instances of poorly designed reforms, compelling evidence suggests that replacing them with the traditional punitive approach wouldn’t do anything to prevent school shootings. In fact, the teenager accused in the Parkland shooting had been disciplined repeatedly, including a suspension and more than two dozen other “disciplinary incidents” in middle school and eventually an expulsion from Marjory Stoneman Douglas High. Media coverage indicates the two Columbine assailants had been suspended, too, as had some of the other teens behind school shootings, including some who were never seen by their peers or teachers as a major threat. Many other offenders, meanwhile, had clean disciplinary records.

There’s a general disconnect between school-safety debates in Washington and those happening on the ground, said Anderson of the Discipline Revolution Project. But the disconnect between the federal student-discipline conversation and what’s happening at schools is noteworthy because of how deeply entrenched it is. Not only is the current conversation exaggerating the role of student-discipline policy in determining the likelihood of a school shooting, it is also leveraging and fueling an existing political tug-of-war that has amounted to one of the education world’s most rancorous and gridlocked controversies in recent years. It doesn’t help that the school-safety commission—which Trump specifically tasked in part with addressing discipline—is comprised exclusively of four Republican cabinet members and not a single educator, scholar, or student.

In a Gallup poll of roughly 500 teachers released Thursday, just 2 percent of respondents mentioned “more discipline/accountability for students” as the “one thing that could be done to prevent school shootings from occuring in the United States.” By contrast, 33 percent mentioned stricter gun laws, while 19 percent identified better mental-health care as the key solution. Meanwhile, the Congressional Black Caucus dismissed the effort to dismantle the Obama-era guidance as symptomatic of a larger effort to “criminalize” student behavior.

At the local level, many policymakers are seeking to institutionalize the ideas driving the 2014 guidance: In 2017, for instance, state legislators introduced roughly two dozen bills proposing alternatives to punitive exclusionary discipline. Local conversations have increasingly focused on holistic school-safety measures—those that ensure at-risk kids feel cared for by the adults on campus, for example, or that enable students who act out to be counseled rather than ostracized. Much of the White House’s school-safety commission’s focus is on holistic solutions, too, like improving access to mental-health treatment.

For Washington policymakers to give outsized attention to student-discipline reform is to succumb to ideological precepts that lack empirical support. It is to waste the lessons gleaned from the growing tally of school shootings while reinforcing racial disparities. And it is, most importantly, to fail the future victims of campus violence.



Even before the election, pundits were calling 2018 “the year of the teacher.” The Christian Science Monitor and the Associated Press both said an unprecedented number of educators sought political office this year. “The teacher strikes pushed a record number of educators to run for office,” wrote Vox, in an article noting that “more than 1,000 teachers will be on the ballots across the country.” A few days before that, Al Jazeera reported that 1,450 educators would be vying for state legislative seats, though it noted that many of them weren’t actively working in education. On Friday, USA Today packed all the main points in a single headline: “‘We’re Just Fed Up’: Teachers Running for Office in Record Numbers, Motivated by Low Pay and Education Cuts.”

These claims of a historic trend were sparked by a memo issued last month by the National Education Association (NEA), the country’s largest teachers’ union. In it, Carrie Pugh, the organization’s senior political director, cited “available state campaign data” in claiming that an unprecedented 1,800 educators sought seats in state legislatures this year. The numbers were broadly similar to those from the Democratic Legislative Campaign Committee (DLCC), a group that works to elect Democrats to state legislatures, which concluded that 1,456 educators ran for office this year.

But there are some pretty significant caveats, and together they are reason enough to doubt the overall picture. First: The NEA uses the word educator liberally, counting essentially anyone who currently works in or used to work in an education-related job, such as professors, guidance counselors, and school administrators. Other definitions have yielded drastically different numbers. After the Education Week reporter Maddy Will and her colleagues conducted their own analysis—consulting teachers’-union rosters, thoroughly reviewing news-media coverage, and verifying information they received through online submissions—they concluded that the number of teacher political candidates (meaning people currently working as K–12 teachers) in 2018 was 177—less than a tenth of NEA’s count.

Second: There isn’t a reliable set of data to which the 2018 figures can be compared. In fact, an analysis by the Wall Street Journal reporter Michelle Hackman found that while the NEA asserts that 1,600 educators ran in 2016 (about 200 fewer than this year), the DLCC puts the number at 1,629 for 2016—173 more than it says ran this year. These discrepancies, and the glaring gap between the NEA tally and conclusions drawn by Education Week, may come down to the inconsistent ways in which candidate lists are compiled from state to state and organization to organization.

Nevertheless, it is the case that teachers are having a moment, likely emanating from a series of high-profile walkouts earlier this year. In late February, teachers across West Virginia staged a strike demanding higher wages and better school conditions, inspiring their counterparts in other states to follow suit. Many of the educators had never before engaged in politics. Of the 177 teachers that Education Week tracked, 41 won last night, and most of them were Democrats. (That number could rise to 42, as one race has yet to be called.) The victors include 13 teachers in Arizona, Kentucky, Oklahoma, and West Virginia—four of the states that experienced the most educator activism this year.

Perhaps the hype around the wave of teacher candidates and the assumption that they have shifted the country’s priorities on education were overblown, as the American Enterprise Institute’s Frederick Hess has suggested. In a recent Gallup poll, for example, just 2 percent of voters identified education as the most important problem facing the nation. That being said, evidence of the reach of teacher activism has surfaced in all kinds of ways this year, such as voter opposition to school-voucher proposals, unusually contentious elections for schools superintendent, and a body of survey data showing a spike in support for raising teachers’ pay.

And beyond the teachers turned state legislators, two candidates who are current educators also made history Tuesday night by winning their bid for higher-level office. One was Wisconsin’s Democratic gubernatorial candidate, Tony Evers, the state superintendent of public instruction, who beat the two-term incumbent, Scott Walker, after a high-profile battle in which he leveraged criticism over the quality of the state’s public schools. The other is the Democrat Jahana Hayes, a school administrator and a past Connecticut Teacher of the Year winner, who ran a victorious campaign for Congress in the state’s Fifth District. She put education front and center in her campaign, and her win marks the first time voters in Connecticut will send a black woman to the Capitol. Tuesday night’s outcome, she declared in her victory speech, showed that voters “believe that we have to protect the future that we promise for our kids.” Now voters across the country are expecting Hayes and other newly elected teacher politicians to make good on that promise.



BALTIMORE—Racial inequality in Baltimore’s public schools is in part the byproduct of long-standing neglect. In a system in which eight out of 10 students are black, broken heaters forced students to learn in frigid temperatures this past winter. Black children in Baltimore’s education system face systemic disadvantages: They’re suspended at much higher rates than their white peers; they rarely pass their math or reading tests; their campuses are chronically underfunded.

Yet this stark reality is juxtaposed with a largely unnoticed educational phenomenon underway in the city.

In a brightly painted row house in East Baltimore, Cameren Queen, who’s 13, walked confidently to a colorful trifold poster, cleared her throat, and began to speak. Her oral presentation—“All About Hepatitis C”—was the culmination of two weeks of work. With animated precision, she rattled off common symptoms of hepatitis C, specified risk factors, described prevention strategies, and listed treatment plans. Seated to her right, the instructor—her mother, April VaiVai—listened intently, scrutinizing facts and peppering Cameren with questions. The two of them are part of a thriving community of black homeschooling families, here in Baltimore and elsewhere throughout the country, taking the adage “Parents are a child’s first teacher” to another level.

The homeschooling population in the United States is predominantly white and concentrated in suburban or rural areas. In 2016, black children accounted for 8 percent of the 1.7 million homeschooled students nationally, according to U.S. Department of Education statistics. What federal education data don’t show, though, is what’s driving those 136,000 or so black students and their families into homeschooling. Nor do the data reveal the tenacity and tradition that bond this homeschooling movement—a movement that challenges many of the prevailing stereotypes about homeschooling, which tends to be characterized as the province of conservative Christians, public-school opponents, and government skeptics.

For VaiVai and many other black homeschoolers, seizing control of their children’s schooling is an act of affirmation—a means of liberating themselves from the systemic racism embedded in so many of today’s schools and continuing the campaign for educational independence launched by their ancestors more than a century ago. In doing so, many are channeling an often overlooked history of black learning in America that’s rooted in liberation from enslavement. When seen in this light, the modern black-homeschooling movement is evocative of African Americans’ generations-long struggle to change their children’s destiny through education—and to do so themselves.

VaiVai first considered homeschooling when Cameren, who’d previously attended two Baltimore charter schools, was in fourth grade. By fifth grade, it was a fait accompli. Cameren, who was in agreement, would be taught at home. Driven by a deep connection to black culture, VaiVai infuses her daughter’s homeschool curriculum with histories and knowledge that counter the dominant narrative of black inferiority pervasive in schools and the media—abstaining from European and Anglo-American viewpoints, and incorporating the history of the African diaspora into lessons across subjects.

“The No. 1 thing is to throw out all of those standards that white America will tell you your child should [know],” VaiVai said, referring to curricula and teaching practices that fail to emphasize black excellence—for example, ignoring early accomplishments of Africans and African Americans in math and science. Accepting these standards, VaiVai continued, is what “screwed us up.”

The movement certainly has detractors. Among them are those who take issue with homeschooling more generally, arguing that it is not sufficiently regulated as to guarantee children are getting a quality education. And homeschooling often comes under scrutiny for its perceived limitations when it comes to ensuring kids’ socialization—the ramifications potentially intensified for black kids considering they, as a group, are still contending with entrenched marginalization. (Although, of course, many black homeschooling parents are very attuned to the need to socialize their children to prepare them for the outside world. “We raise our children to understand that it’s a very big world,” said Tanisha Armstrong, a black homeschooling parent. Parents like herself, she continued, tell their kids: “Get out there. Be friendly. Be you. And don’t worry about any of the other little things that may come in and interrupt that.”)  

But the deeper criticisms of black homeschooling come from other black education advocates, some of whom argue that homeschooling black children effectively amounts to an attack on the very values and legacy its advocates espouse. African American critics have argued that black parents who homeschool are shunning their Topeka, Kansas, predecessors who in the 1950s took it upon themselves to put an end to school segregation in Brown v. Board of Education. Taking black children out of public schools and into home-based classrooms, these critics contend, dilutes the landmark Supreme Court case’s symbolic importance and threatens to reinforce the harm African American students experienced when they were banned from attending white schools. Paula Penn-Nabrit, an African American scholar who homeschooled her children in the 1990s, described in her memoir how her middle-class family rejected her choice for this reason. Her circumstances were particularly fraught: Her husband’s uncle argued the Brown v. Board of Education case with Thurgood Marshall. “To other members of their family,” she wrote, “it seemed as if Paula and C. Madison [her husband] were turning their backs on a rich educational legacy.”

That aside, the black-homeschooling movement deserves scrutiny simply because there isn’t much reliable quantitative data on the phenomenon. Is black homeschooling gaining or losing traction? Where? How are these kids faring? All of this is difficult to ascertain. A 2016 journal article on black-homeschooling practices estimated that the number of black youngsters being schooled at home tripled from 1999 to 2007, while federal survey data found no statistical difference in the percentage of black homeschooled students over the four-year period starting in 2012. The discrepancies are due to differences in methodology and the difficulty of measuring this phenomenon.

Similarly, it’s hard to characterize black homeschooling outcomes definitively. A 2015 study in the Journal of School Choice did find that black homeschooled students scored “significantly higher” on reading and math tests than did black students enrolled in public schools; that study, though, was conducted by a researcher at an organization that advocates for homeschooling. Other data, from less partial sources, is scant.

But even without quantitative evidence, the appeal of black homeschooling for many parents is plain—and there are a lot of resources emerging to support them. VaiVai pointed to the flourishing communities of black homeschoolers she’s met in Georgia, Colorado, and Pennsylvania; countless others cited a slew of black-homeschooling support groups, as well as the availability of networking events tailored to such families. “For me and the women that I homeschool with,” VaiVai said, “we’re definitely black first.”

Meanwhile, a growing body of research helps paint a qualitative image of the black-homeschooling population—a population that is, as the Temple University African American studies professor Ama Mazama noted in a 2016 analysis, ideologically diverse, “ranging from Christian fundamentalists to African cultural nationalists and a myriad [of] nuances in between.” Mazama’s conclusions dovetail with those of Cheryl Fields-Smith, an associate education professor at the University of Georgia who is one of the few researchers nationwide to investigate the motivations for black families that do homeschool. Field-Smith’s findings show that a confluence of factors influence the decision, including their perceptions of and experience with conventional schools and their exposure to other home educators.

News stories have largely focused on the phenomenon as a response to entrenched stigmas against and low expectations for African American children in traditional schools. Yet, echoing findings outlined in Mazama’s analysis, imparting black culture “contributed tremendously” to the decision to homeschool for the 54 black home educators interviewed in Field-Smiths’s 2013 study; respondents saw homeschooling as a means of thwarting the negative images of African Americans found outside parents’ homes in television, film, books, and beyond. “[In spite of] all the achievements, all the ways black people have contributed to America, [black parents] are raising children into a world that sees us as less than,” said Fields-Smith, who’s African American and has studied black homeschooling patterns for 12 years. “White people don’t have that problem … that sense of urgency to” ensure their kids overcome notions about their inferiority.

These conclusions are consistent with more-recent research showing black parents’ overwhelming dissatisfaction with the quality of schooling their children receive. A May 2017 survey from the Leadership Conference Education Fund, a D.C.-based civil-rights group, polled 600 black parents and family members across the country on their beliefs about public schools. Close to three in four respondents said the education black students receive is worse than the education delivered to white students. And among parents whose children were taught by mostly white teachers, only 42 percent believed that schools were trying their best to educate black kids—16 percent fewer than the black parents whose children had mostly black instructors.

Yet Fields-Smith made a point of noting the respect black families had for the people running and teaching in neighborhood schools. What these families objected to is the institutional racism that underpins those schools—the tendency to discipline children of color at higher rates than their black peers, for example, and the residential segregation that determines the educational quality and demographic composition of a given campus.

In other words, in opting to homeschool, the parents weren’t necessarily seeking to shelter their children from a learning environment they believed deliberately disenfranchised black kids. They had simply accepted what they see as the unfortunate reality of the country’s public-education system: one comprising well-intended schools that are crippled by America’s racist legacy. To liberate their children from this trap, they were performing an act of extreme self-reliance—taking it upon themselves to provide them an education that was more personal, more engaging, and more anchored in black self-discovery. “Nobody [in my study] bashed public schools as an institution,” Fields-Smith said. But “how long do you try to stay in there … before you realize time is wasting [and] you’ve got to make a change?”

Such racial perceptions and experiences set black homeschoolers apart from their white counterparts—as do black homeschooling’s origins in African Americans’ historical efforts to take ownership over their own education and knowledge. Fields-Smith likened the black-homeschooling movement to enslaved black people’s pursuit of literacy, which they equated with freedom and empowerment. The University of Georgia researcher recounted: “When told we could not be educated, we went out in the woods, we dug a pit, and when somebody learned to read, they’d sneak out at night, go down in that pit with a light, and teach [others] how to read, because it was that important.” Today, for black home educators, “it’s still that ‘each one, reach one’” mentality, she explained. “It looks different, but it harkens back to who we are, who we have been in our educational history.”

Tracing that history yields a better understanding of how black homeschooling emerged—and of how it could continue to evolve. In the 2007 book Self-Taught: African American Education in Slavery and Freedom, the historian Heather Andrea Williams examined black Americans’ perseverance in their pursuit of learning during slavery, the Civil War, and their first decades of freedom. Using enslaved peoples’ narratives and autobiographies, she documented the significance of education “as an instrument of resistance … to gain some control over their own lives.”

During the antebellum period, legislatures across the South—viewing literacy as a direct threat to the institution of slavery—passed laws criminalizing reading or writing for enslaved and free blacks. The movement to oppose black education also extended to northern free states such as Connecticut, where a boarding school founded by abolitionists in 1832 for black girls was promptly banned by the legislature and then set ablaze by local residents.

In the face of the backlash, black people educated themselves. According to Williams, archaeologists excavating slave cabins more than a century after the Civil War found, among the more-predictable artifacts, “the remains of graphite pencils and writing slates, some with words and numbers still written on them.”

Learning was integral to black people’s emancipation and autonomy both before and after the Civil War. During Reconstruction, as the country sought to rebuild and reshape society in the former Confederacy, “the values of self-help and self-determination underlay the ex-slaves’ educational movement,” writes the black-education scholar James D. Anderson in his book The Education of Blacks in the South, 1860–1935.

In the years after emancipation, formerly enslaved men and women established a formal system of schooling for their children, eventually aided by northern white missionaries and the congressionally established Freedmen’s Bureau, which was formed to help transition black people from slavery to freedom. Yet the conflicting interests of northern allies and philanthropists, along with white southerners who regained control of state governments after Reconstruction, suppressed the growth of black education, Anderson concludes, impeding freed people’s ability to mold their children’s education without external forces suppressing their vision.

The notion of self-reliance, present in much of the idealism that motivates black homeschooling, was a unifying theme of African American education from slavery through the post–Civil War era to Jim Crow segregation. The 1964 Mississippi Freedom Schools are a vivid example. Conceived and organized by mostly college-age black civil-rights activists, Freedom Schools counteracted the segregationist practices in Mississippi’s black public schools through their six-week summer program. Central to the Freedom School curriculum was students’ experiences with the Jim Crow racial order—whites-only signs, lynchings, racial epithets, and so on—as recorded in To Write in the Light of Freedom, a collection of newspapers published by black youth.

Some 40 Freedom Schools—held in churches, on porches, and under trees—taught thousands of black students “the rich traditions of black resistance,” according to the collection. As illustrated by a letter from the 11-year-old Freedom School student Lynette Y. of Hattiesburg to then–Mississippi Governor Paul B. Johnson Jr.: “I want to learn about my race … I want to have the opportunity to learn here what I cannot learn in my regular school … And I want to be a first-class citizen.”

For hundreds of years, black people have united to alter the trajectory of their children’s lives through education. It was with that heritage in mind that Pier Penic in 2004 founded Culture at Home, an African American homeschool support group serving families in the Washington, D.C., region. As a child in the mid-1970s, Penic endured eggs, bottles, and rocks thrown at her school bus in response to court-ordered busing in Boston. The violence prompted her parents to pull her out of the public-education system and enroll her in a series of private and parochial schools.

Not until fourth grade at an alternative school with an African-focused curriculum in Boston’s Roxbury neighborhood did Penic feel valued and validated as a black student. It’s a sentiment she’s carried with her through two decades as a homeschooling parent and advocate for the cause. Of the roughly 500 families she’s counseled since 2002, Penic estimates that about 85 percent chose homeschooling primarily to influence how their children think about themselves and their racial group. “Many of them have said [as parents] that they want to incorporate [into their kids’ schooling] the experience and legacy of being an African American in this country … They want their children to understand … that their ancestors were beaten, sold, killed just [for] learning to read one letter.”

It’s this tradition, one that stands somewhat in contrast to the fight for integration, that black homeschooling continues, Fields-Smith wrote in her 2013 study. “This is a notable paradigmatic shift … unlike their forefathers and foremothers, black homeschoolers are standing outside the doors of … public  education, which is the very institution that many civil rights leaders sought equal access to on behalf of black Americans,” she concluded. “The mere presence of black homeschoolers in growing numbers challenges the ‘common-sense’ assumption that access to desegregated schools would automatically bring equity in instruction and opportunity.”

Penic, whose in-laws and black friends cited the Brown v. Board ruling in criticizing her decision to homeschool, echoed the urgency Fields-Smith expressed. “We can’t really contribute to a collaborative effort [of racial advancement] if we are part of a system that sends us to prison,” Penic said. “We get power from knowing that we educated our children, way before we were allowed into the public-school system.” What black homeschoolers have in common, Fields-Smith added, is a willingness to make relatively extreme sacrifices for their children’s education.

That’s certainly the case for Armstrong, a mother of five from Salisbury, Maryland, who embarked on homeschooling nearly a decade ago. She cast aside aspirations of earning a master’s degree and being a classroom teacher so she could nurture her own children to their maximum potential. “We [my husband and I] really looked at it less from a perspective of what the school was or wasn't doing, and [focused on] our end goals for [our kids] and for their education,” she said. “[Black] children are constantly being told what they’re not. We decided we were not going to allow that to happen.”
And that’s what Cameren Queen has experienced. In a light-filled dining room back in East Baltimore, Queen mixed food coloring, water, glue, and Borax detergent to construct a model of a healthy liver, as her mother pulled up a picture on her cellphone for comparison. One motivation for choosing the hepatitis C assignment was family and friends who have died from preventable diseases—notably, black Americans have disproportionately higher rates of hepatitis C infection and illness-related deaths.
As the day continued, her mother transitioned to a lesson on English composition, referring to Maryland’s requirements for home instruction—which stipulate “regular, thorough instruction in the studies usually taught in the public schools to children of the same age” —though naturally VaiVai has adapted it with her own twist: Cameren was reading The Mis-education of the Negro by the black historian Carter G. Woodson, a seminal work on the destructive impact of America’s educational system on black students.



Americans like to imagine the civil-rights era as a single, sustained burst of progress, surging forth in 1954 with Brown v. Board of Education and building to a crescendo before terminating, somewhat hazily, in the late 1960s. But the real narrative of civil rights refuses to yield to this familiar arc.

Nothing illustrates this more than the strange stop-and-start of American school desegregation. The Brown decision dissolved Jim Crow in schools, and wrought real change, but contrary to popular belief, it did not signal the federal government’s intention to wage war on all school segregation. Much of the North remained completely unaffected. The true national push for integration would come 14 years later—after the death of Dr. King, and indeed, after the entire civil-rights movement had come and nearly gone. The critical moment came in a Supreme Court decision—one far less remembered than Brown.

The case, Green v. New Kent County, was decided on May 27th, 1968, 50 years ago this past Sunday. Green marked the beginning of what we now remember as federal school integration, setting up racial conflicts that persist today. But it also announced a profound change in the Supreme Court’s thinking on race. Green quietly embraced a radical view: that the Constitution can sometimes require the government to repair the harms of historic racial injustice, even after it stops explicitly discriminating by race.

The backdrop for Green was the South’s gradual accommodation to the Brown v. Board decision. In Brown, the Supreme Court had declared that districts could no longer forbid black children from attending the same schools as white children. A period of defiance followed, but most districts eventually relented, at least to some small degree. By the late 1960s, southern school districts discovered it was easier to mitigate Brown’s effects than to defy it outright. In many places, a compromise emerged: Token integration of a few black students would be permitted, while large-scale segregation between the bulk of the black and white population was preserved.

By the late 1960s, about 90 percent of southern districts operated using something called a “freedom of choice” plan. Under this system, students were automatically re-enrolled in the same school every year, but had the option to change their enrollment if desired, which meant that a black child could enter a formerly all-white school. The hard racial barrier between schools was now permeable. This satisfied, at least in the most minimalistic sense, the requirements of Brown: No child was prevented from attending any school because of his or her race.

But there was a reason the plans were a popular substitute for Jim Crow schools: In practice, this approach tended to preserve racially divided education. Decades of segregation had left schools racially coded—everyone in a given community knew which schools were “black” and which were “white,” even if the district no longer said so. “Freedom of choice” placed the onus of integration on individual students and parents, who had to opt to cross the color line themselves, facing social stigma, and, in the case of black parents and children, enduring severe discrimination.

Thus, when lawyers from the NAACP Legal Defense Fund filed the Green lawsuit in 1965, seeking to integrate the schools of eastern Virginia’s New Kent County, the county school board responded in an ordinary way. It implemented a “freedom of choice” plan. The rural county, with a population of about 5,300, had previously operated two separate elementary schools, one for white children and one for black children. As the school board intended, the segregation of those schools survived the new choice-based plan: Only 15 percent of black children enrolled in the formerly white school. Predictably, not a single white child enrolled in the formerly black school.

But the lawsuit continued, with the plaintiffs claiming that the county schools had not truly desegregated. A federal appellate court decided in the school district’s favor, declaring the new plan sufficient, but that decision was appealed to the Supreme Court.

At its core, the Supreme Court was being asked to choose between two competing ideas of why racial segregation was harmful.

The first idea, advanced by the county school board, was narrow. In this view, the evil of segregation was the way it relied on racial categories. The solution was simple: stop treating children differently on the basis of race. The “freedom of choice” plan was institutionally color-blind, with the same schools available to everyone regardless of skin color. Therefore, in this view, segregation had been corrected. Because the government was no longer classifying children by race, no further action was needed.

But in Green, the Supreme Court rejected this idea of segregation. Its unanimous opinion, authored by Justice William Brennan, adopted a second, broader view. Instead of focusing on the generic question of whether racially classifying students was harmful or unfair, the Green decision described the far-reaching, systemic nature of segregation as it existed in New Kent County’s schools. In the Supreme Court’s own words: “Racial identification of the system’s schools was complete, extending not just to the composition of student bodies at the two schools, but to every facet of school operations—faculty, staff, transportation, extracurricular activities, and facilities.” The Court described this state of affairs as a “dual system” of schools, a phrase that would persist through decades of civil-rights law.

The Supreme Court was describing something more malevolent than mere racial classifications. It was recognizing the purpose of those classifications: to create a system of tiered education, akin to a caste hierarchy. And the Court was clear who was being targeted by that system: black students, who had been permanently relegated to an inferior role.

These “dual systems” were unconstitutional, the Green court said, and once they were identified, the government was required to fix what it had broken. This meant more than just getting rid of racial restrictions in schools. In the Supreme Court’s evocative language, it meant the harms of segregation had to be eliminated, “root and branch.” Justice required that any existing segregation produced by the dual system be “dismantled,” through the intentional creation of integrated schools.

School districts could select whatever means they thought would be most effective for desegregation, but they couldn’t stick with a method that didn’t work. In the case of New Kent County, the “freedom of choice” plan had proven clearly insufficient. In other places, the Supreme Court acknowledged, choice plans might prove effective, although “the general experience ... to date has been such as to indicate its ineffectiveness as a tool of desegregation.” Regardless, if choice failed, other approaches would need to be used, until integration was achieved and the harm caused by the dual system was scoured away.

An unusual aspect of the Green decision is its reliance on the history of American racial discrimination. Courts sometimes reduce the messy facts of cases to logical abstractions, which makes it easier to see idealized rules of law. Green did not do this. It identifies the narrow act of segregating a school as part of a larger system of white supremacy and racial caste. And it asserted that, to truly vindicate black Americans’ constitutional rights, the government must unmake that system, taking aggressive measures if necessary.

Broadly framed, Green envisioned school desegregation as a reparative process—probably the closest thing to reparations that our court system has ever endorsed.

The Green decision sent a jolt of electricity through the school-desegregation movement. Cases in the South that had stalled were restarted, as civil-rights lawyers carried the new decision into district courts to demand an end to “freedom of choice.”

But there was more. Judges were now looking for “dual systems” instead of explicitly segregated Jim Crow schools—and finding them everywhere, even in the North, where Jim Crow had never set foot. Large cities like Boston, Minneapolis, and Denver had used racially divided neighborhood boundaries, attendance zones, and social pressure to keep their schools segregated. Unexpectedly and suddenly, these places faced judicial desegregation orders.

In fact, it was in northern cities that Green’s mandate proved most challenging. Densely populated, their school segregation was often closely related to long-standing housing discrimination that kept ethnic groups separate. Courts responded by pushing city districts to redraw attendance boundaries, alter transfer policies, and, most controversially of all, to institute busing of students. All these changes inspired white resistance, but busing in particular became the focus of opposition. The most violent episodes of white resistance, like the infamous Boston busing riots, were limited, but they contributed to a political consensus that the Supreme Court’s integrative project was naive to racial realities.

In the end, though, Green stumbled the most because it was undercut by the Supreme Court itself. Although Green has never been overturned, in 1974, the Court decided 5–4 to sharply limit federal courts’ ability to desegregate most suburbs. Four of those five Justices had been appointed since Green by President Nixon. (There is evidence that Nixon had made some of his appointments—including future Chief Justice William Rehnquist—promise to oppose busing.) With the suburbs now available as an escape route from Green’s desegregation mandates, white flight intensified. As residents left, some cities, like Detroit, spiraled into a cycle of deterioration from which they have never fully recovered.

With so much conflict sprouting from Green, it’s not hard to see why modern narratives of school desegregation focus on the unambiguous heroics of Brown v. Board instead. Green’s legacy is painful. Many of its most visible consequences, like busing, remain politically controversial, and suggest that even in modern America schools can’t be integrated without conflict. Meanwhile, Green’s skepticism of “freedom of choice” is uncomfortable in an era where school choice is posed as the solution to many educational problems. It’s a reminder that choice can be used to preserve, as well as erode, existing patterns of discrimination.

But for civil-rights advocates, the Green decision is also cause for hope. It represents the way in which long-stalled battles can suddenly be won. The case forced many southern districts to pursue true integration after years of delay, and in mid-sized southern cities like Raleigh or Louisville, school integration has persisted for decades. Even busing continued in some districts until the 21st century.  

In an era of conservative federal courts, civil-rights advocates sometimes argue that the judiciary is a weak vehicle for change, and that all real progress must pass through the court of public opinion. But 50 years ago, the Supreme Court was not afraid to lead the fight for reparative racial justice, nor afraid to say that the Constitution itself required school integration. The results were incomplete, it’s true—but Green is also still the law.



Activists managed to quash a video game called Active Shooter before it was even released to the public, the culmination of a public uproar over what critics described as the game’s normalization of violence and glamorization of death. This, as it turns out, is not precisely the reason. After all, most video games contain violence, and in many the goal is to kill. What doomed this particular game was the setting of that violence and death—a school—combined with the particular sensitivities of the country at this moment in history.

Active Shooter simulates a school massacre, allowing the player to be a SWAT officer or the gunman himself. In the latter scenario, according to apparent screenshots of the game, the player-as-murderer wields a semiautomatic rifle while traversing school buildings in pursuit of civilians (presumably students and teachers) who are shown huddling in classroom corners or fleeing down flights of stairs.

This isn’t the first school-shooting video game to surface in the aftermath of a high-profile campus massacre. Super Columbine Massacre RPG! came a few years after the 1999 rampage in Littleton, Colorado, created by an undergraduate film student who said he designed it as a critique of how the news media sensationalized the shooting. In May 2007, just a month after the shooting at Virginia Tech, a 21-year-old Australian game creator released V-Tech Rampage, explaining in an interview at the time that he meant for it to be offensive and funny. Several years ago, the same Australian creator made The Slaying of Sandy Hook Elementary, though that time he claimed his intent was to promote stricter gun laws. Its release date was just a month shy of the Newtown, Connecticut, massacre’s one-year anniversary.

Yet while those games similarly stirred controversy and were eventually pulled from popular distribution platforms or otherwise blacklisted, the public’s reaction to Active Shooter sets it apart. In this case, the game was removed from Steam, the largest online storefront for PC gaming, before it was even released to the public. By contrast, it wasn’t until a year after Super Columbine Massacre RPG! was released that it received major public backlash, thanks to extensive media coverage and a subsequent uptick in downloads. The speed with which Active Shooter’s demise happened is in part because of the new political salience school shootings have gained in recent months.

The outcry over Active Shooter—including from the family members of mass-shooting victims and at least one national education-advocacy organization—came to a head last week once the game caught the attention of major news outlets around the world. Last Tuesday, Valve Software, the company that owns Steam and was slated to release Active Shooter in early June, announced that it would no longer be doing so.

(It’s unclear who made the game. Valve alleged in a statement, which was provided to various news outlets, that the creator behind Active Shooter isn’t some major software developer or well-known production company but rather a Russian “troll” whom it had already banned from Steam for abusing customers and publishing copyrighted material. “His subsequent return under new business names was a fact that came to light as we investigated the controversy around his upcoming title,” the company told Vice. But, in an interview with PC Magazine on Wednesday, the so-called troll denied making the game and attributed it instead to another Russian—a 21-year-old self-taught developer whom he’d merely advised and assisted financially. That developer, who also participated in the interview and indicated he may still release Active Shooter elsewhere, contended that he casually started designing the game two months ago and decided to simulate a school campus simply because the 3-D model for doing so didn’t cost as much as that for other video-game worlds and environments.)

Steam dominates the PC-gaming market; by banishing Active Shooter from Steam, experts I spoke with suggest, Valve has nearly consigned the game to nonexistence. Even though Valve implied that its decision was motivated by business concerns and not political ones, the outcome was a victory for those who’d condemned the game as a callous affront to the growing population of Americans directly or indirectly traumatized by mass gun violence; an online petition that called on the company to remove the game from Steam had garnered more than 200,000 signatures within several days and continues to gain traction even though its demand has already been met. Many of the petition’s supporters echoed the myriad social-media posts using the hashtag #notagame to express shock that such a game was created in the first place, let alone initially permitted on Steam.

The backdrop, of course, is a nation in which many activists are more galvanized than ever before on the issue of gun violence in schools. “We have more visible activism around the subject of school shootings than we’ve had in many years. … For many of the kids at Parkland and Santa Fe, Columbine happened before they were born—now they’re the school-shooting generation,” said Danny LeDonne, who was a high-school sophomore in Colorado when the 1999 massacre happened and created Super Columbine Massacre RPG! in his early 20s, partly after realizing how much he, a loner who’d thought of hurting himself and others, had in common with its two gunmen.

“We’re moving into a space now where we have a different way of looking at and engaging with these issues,” LeDonne continued. “The fact that Active Shooter was removed before its release is reflective of a culture that is much more intent on trying to effect change” as well as the rapid-fire pace of news and media consumption.

It’s also reflective of how gun-control advocates and others today are navigating the school-violence problem emotionally. Many critics reacted viscerally to Active Shooter—asserting they had zero tolerance for any video game in which the player is an active shooter at a school on a mission to kill civilians, expressing a combination of shock and disgust, or concluding that Active Shooter would increase school violence by desensitizing players. Few of these critics analyzed the intent behind Active Shooter’s creation or debated the possibility of developing a video game that deals with school shootings and mass gun violence in a constructive way—a reaction that was reasonable given the information available about Active Shooter but that also shows just how raw sentiments have become.

LeDonne sought to do this with Super Columbine Massacre RPG! largely by designing it as a role-playing game that integrated satirical commentary, flashbacks, and primary-source materials such as actual crime-scene photos and eyewitness accounts, among other elements. The goal, he argues, was and still is to give players and the public a more nuanced sense of why the Columbine shooting and similar massacres may have occurred, and to debunk common misconceptions about the gunmen.

Many scholars who study video games emphasize the importance of giving users a chance to try them out before jumping to conclusions. “As someone who designs games for pro-social causes, I wanted to wait until I could play [Active Shooter]” before judging it, said Mary Flanagan, a professor of film and media studies at Dartmouth College who researches and designs games for social change. “I wanted to see whether it actually invests in a larger-picture view of things”—perhaps whether its premise is similar to the one LeDonne described for Super Columbine Massacre RPG!

Flanagan and other observers suggest that Active Shooter didn’t deserve the benefit of the doubt: After Valve pulled the game, the self-identified developer acknowledged in his interview with PC Magazine that while he didn’t intend to glorify violence, he did design it to be entertaining. What’s more, his flippant approach to the whole fiasco—he was incredulous as to why a school-shooting game would be received so poorly and explained that he started designing the game because he was discontent with his “crappy” day job—indicate he gave little thought to its social implications. Then there was his half-baked attempt to recast the game as a productive critical-thinking opportunity, which came off as simultaneously disingenuous and nonsensical.

Several experts who analyzed the limited information they’d gathered on the game confirmed that to be the case. Reiterating the consensus among Reddit users and other industry observers, these experts concluded that Active Shooter is just another shoddy, hastily built game aimed at profiting from controversy.



Applying to college as a legacy is like having a superpower. It has been estimated to double or quadruple one’s chances of getting into a highly selective school, and has been found to be roughly equivalent to a 160-point boost on the SAT. At the most selective institutions in the United States, it’s typical for 10 to 15 percent of students to have a parent who also attended.

These estimates are, of course, rough; colleges generally don’t share specifics on the advantage they give to legacies—or, sometimes, on how they define the term (it can refer to children of alumni or, more broadly, to other relatives of alumni)—so research on the subject has been limited.

Still, given that admissions at selective colleges are more competitive than ever—last week, several of them announced record-low acceptance rates—it’s clear that a preference for legacies benefits alumni and their children. But what does this tradition—which is exceedingly rare outside the United States—do for colleges? And, relatedly, what’s stopping them from getting rid of a policy that gives some applicants an automatic advantage solely because of their lineage?

The most important rationale that colleges cite is a financial one: They tend to believe that giving legacy applicants an edge helps them bring in alumni donations. For instance, at Harvard, a committee formed in 2017 tasked with assessing potential tweaks to the admissions process concluded that scrapping the school’s legacy preference might jeopardize the “generous financial support” that “is essential to Harvard’s position as a leading institution of higher learning” and that helps fund financial aid.

“Colleges have defended the legacy preference by saying it’s necessary for fundraising,” says Michael Dannenberg, the director of strategic initiatives for policy at the think tank Education Reform Now. But he observes that the legacy preference, as a fundraising tool, isn’t very precise. It is, he says, both “overbroad” (it includes applicants whose parents have never donated to a school) and “underinclusive” (it excludes tons of very wealthy applicants who don’t have an association with the school). “It would be more efficient and effective to auction acceptance letters on eBay,” he says.

Dannenberg points to a study that tracked alumni giving from 1998 to 2008 at the top 100 American universities, as ranked by U.S. News & World Report. The study found “no statistically significant evidence” that legacy preferences themselves make any given alum more likely to donate; instead, the study suggested, they simply allow schools to let in more children of wealthy alumni than they otherwise would. So since those wealthy alumni tend to donate more money, the legacy preference does appear to help colleges’ bottom line. But giving these students higher priority doesn’t seem financially vital: Seven schools tracked in the study did away with legacy preferences and didn’t see any large drop-off in donations, though such a drop-off could conceivably occur over a longer time span.

In that regard, Yale is an interesting case study. The school currently gives the children of alumni an admissions bump, but from 1980 to 2010, the proportion of students in its freshman class with a parent who also attended dropped from 24 percent to 13 percent. Yet during that same period, total alumni giving increased. (Yale didn’t provide me with comprehensive annual data about alumni giving from 1980 to 2010, nor would it comment on trends in total giving during that time.) One could argue that decreasing the percentage of enrolled legacies might in fact have prevented Yale from bringing in even more money than it did, but the point stands that the results were far from financially catastrophic. After adjusting for inflation, Yale’s endowment, which is funded in part by alumni donations, grew from just under $2 billion in 1980 to more than $16 billion in 2010, as expressed in 2010 dollars.

College fundraising, it turns out, is more of an art than a science. “I’m not convinced that anybody could prove to you that those people with legacy admissions donate solely [because of a] legacy admission,” says Mickey Munley, a higher-education consultant who previously worked at Grinnell College in fundraising and public relations.

Sometimes the families of legacy admits donate a bunch of money, he says, and sometimes they don’t. “Fundraisers know how critical relationship building is, and they grasp at anything that will help build, sustain, and grow a relationship,” Munley told me, “whether it has any true impact or not.”

Another explanation that colleges offer for the legacy preference is that it can function as an admissions tiebreaker. As a spokesperson for Brown University told The Atlantic last year, “When it comes to choosing among equally strong candidates, one consideration can be the natural affinity for the university that often emerges among children of alumni from Brown’s undergraduate college.”

Dannenberg doesn’t find this usage compelling either. “No two applicants are the same, and the ‘tie’ rarely exists,” he argues. “And regardless, if there were a tie, you’d want to break it in favor of the person who’s overcome more and had fewer advantages along the way.”

Brown’s concept of “natural affinity” connects to another common reason why colleges might keep legacy admissions: It strengthens a sense of community among graduates and current students.

On this front, the aforementioned Harvard committee concluded that the legacy preference is one way of encouraging alumni to “remain engaged with the College for the rest of their lives”—yes, by giving money, but also by giving their time and energy, for instance, in the form of interviewing Harvard applicants. (Harvard declined an interview request, but provided a statement expressing its commitment to letting in students who are “diverse on multiple dimensions,” including in their “academic interests, perspectives, and talents.”)

This notion of lifelong engagement is central to elite colleges’ business model and value proposition, according to Mitchell Stevens, a professor at Stanford University’s Graduate School of Education and the author of Creating a Class: College Admissions and the Education of Elites. He says that schools strive to build “clanlike” emotional connections with students and graduates, “partly so that they might solicit philanthropic contributions, but partly so that wherever in the world those people are, they give some special deference or recognition to others who hold that identity.”

Cultivating this collective identity is not just important for getting alumni to interview prospective students. It fundamentally enhances the value of holding a degree, in the sense that alums often go out of their way to help those with whom they share an alma mater, whether by giving career advice or sharing professional connections. “Legacy admissions,” Stevens says, “have been a central part of the way in which universities have promulgated that sense of identity and fealty.” (On a less palatable note, elite schools first implemented legacy preferences in the early 20th century in order to limit the admission of immigrants, particularly Jews.)

Then there are the forces keeping legacy preferences in place that schools themselves are less likely to publicly articulate. Stevens notes that any school that moves to abolish its policy would expect serious pushback from alumni, who wouldn’t take well to losing a valuable perk. “And remember,” he says, “the most loyal and more generous alumni of an organization are the very same ones that sit on their institutions’ boards of trustees.”

Amy Binder, a sociologist at the University of California at San Diego who studies the culture of higher education, suggested other possibilities. For one thing, letting in legacies—who tend to be well connected—can grant other students access to elite networks, which is a central part of top-tier colleges’ appeal. (Perhaps this is what a Harvard dean was getting at when he said, in testimony during the trial over the university’s affirmative-action policy, that putting students who “have more experience with Harvard” alongside those “who are less familiar with Harvard” can lead to productive exchanges.)

A final reason that legacy preferences persist might be that many legacies don’t represent a major drop-off in academic quality—that their presence isn’t meaningfully damaging campuses’ academic climate. While some research indicates that legacy admits go on to earn lower average grades than their peers, plenty are strong applicants.

Munley, the former Grinnell official, told me that in his experience, the majority of legacy admits fare well enough. “Most parents who are alums of the school have a sense of the school and their own kids, and aren’t going to be too pushy if their kid is completely not qualified,” he said. (Most, he noted, but not all.) And a Harvard spokesperson told me that admitted legacies tend to have higher median test scores and grades than the rest of admitted students. This doesn’t make the admissions advantage that legacies are given defensible, but it’s possibly another reason that the status quo of legacy admissions persists.

That status quo might well benefit (or at least not hurt) colleges that give some preference to legacies—so it makes sense that they would be resistant to abandoning the practice. Their argument, though, is not very strong: Many of the world’s most hallowed universities, including MIT, the California Institute of Technology, Oxford, and Cambridge, say they don’t give alums’ children a leg up, and they seem to be doing just fine.



Updated at 3:52 p.m. ET on May 17, 2019.

Most students’ paths to higher education are shaped by numbers: grade-point averages, class rankings, and infamously, standardized-test scores. Now students taking the College Board’s SAT will have another number thrown into the mix: a “disadvantage level.”

This fall, 150 colleges will start using this new metric, designed to capture students’ socioeconomic status and give context to test scores, according to The Wall Street Journal. The College Board is using a number of environmental factors that influence a student’s home and school life—including neighborhood crime rates, housing values and vacancies, the community’s average educational attainment, and poverty levels—to calculate this disadvantage level, which is scaled from 0 to 100 and is based on census data from each student’s neighborhood. Scores above 50 points indicate that the student has had to navigate more obstacles than average to get an education or have access to college, while scores below 50 signify students who have enjoyed more advantages than most of their peers. While students don’t see or know their score, admissions officers will be able to see an “environmental context dashboard,” which breaks down all the factors that go into the score.

This system has been in development for the past three to four years, according to Connie Betterton, a College Board vice president who led the team in creating the score. A number of college-admissions offices have been involved in the process, telling the College Board what information would be most helpful for them to have. From there, 50 colleges, including Yale and Florida State University, participated in a pilot program to test out how to incorporate the new score into their existing application-review protocol and actually used it to make admissions decisions last year. The team developing the score found that colleges were most concerned about the talent they weren’t seeing, the applicants who might thrive on their campus but who have weaker transcripts due to disadvantage, the College Board CEO David Coleman told me.

“What these years were spent on was examining if the data [on poverty and disadvantage] was looked at together in a really clear way with the SAT, could it help admissions officers find kids they wouldn’t have seen? And do those students go on to flourish?” Coleman said. “And the evidence is that they do succeed, that they are resourceful.”

The addition of this new number marks a shift in how the College Board wants admissions offices to think about SAT scores, which have been criticized as a proxy for wealth and privilege, not intellect or college readiness. Higher test scores correlate with higher family income and education levels, and white and Asian students generally tend to score higher than their Latino or black peers. While one additional metric alone can’t fix these inequities, the inclusion of the disadvantage level is a step in the right direction, Anthony Abraham Jack, a Harvard professor and the author of The Privileged Poor: How Elite Colleges Are Failing Disadvantaged Students, told me.

“It is giving us a look at how poverty and inequality directly affect students’ college destinations, as it relates to [test scores]” Jack said. “When students sit down [to take] the SAT, that doesn’t mean that everybody’s at the same starting line.”

Factoring in the influence of students’ environments has not been done before in such a systematic way, Jeff Selingo, the author of There Is Life After College and an Atlantic contributor, told me. Many admissions offices that do “holistic admissions” will already look at a high school’s profile, a description of the student body and curricular offerings that is provided by the high school and accompanies a student’s application, to get a sense of how a student stacks up against local peers, Selingo said. For example, if a student’s SAT scores fall in a low percentile nationwide, but she is a high-performing outlier at a school with generally low test scores, admissions officers will take that into account. But school profiles don’t include information about students’ home neighborhoods, and thus don’t capture students who commute into wealthier areas to attend well-resourced schools but who live in neighborhoods with high crime, eviction, and home-vacancy rates.

Knowing the constellation of home- and family-related factors shaping a student’s transcript would make admissions more truly holistic, Jack said. He knows this firsthand, as a black scholar who became a first-generation college student after getting a scholarship to attend an elite private high school. Even if students attend high-performing high schools, he said, conditions such as housing instability and family turmoil can influence their lives in profound ways.

“I’ve worked with students who were homeless, who did not know when they left school whether they would have a place to sleep for the night. They had to somehow compartmentalize that kind of insecurity at home, but still focus on what’s going on at school,” Jack said. Of students who have grown up surrounded by gun violence, he asked: “Can you concentrate in the same way in your literature class when you heard three gunshots ring outside your door the night before?”

One of the most notable aspects of the disadvantage-level score is that there’s no explicit mention of race—the scoring system is mainly focused on capturing students’ economic reality. (Though, considering that poverty rates and property values have often been affected by racist policies, the score will likely capture some of the economic disadvantages that fall hardest on people of color.) The omission of race from the score is particularly significant, given that the racial-discrimination suit brought against Harvard by Students for Fair Admissions (SFFA) is ongoing; Selingo said that admissions departments have been bracing themselves for the case to move to the Supreme Court, where a conservative majority could potentially ban the consideration of race in admissions altogether. “I’m feeling that this whole effort, and the reason that [the] College Board has this product, is if there is a day in the future when race can’t be used in admissions,” Selingo said. “This could be used as a tool in the admissions process in a post–affirmative action world.”

This race-blind system was not an accident, Betterton told me, but it wasn’t necessarily a result of the current anti–affirmative action movement. Because states such as California and Florida have banned racial preferences in public-college admissions, the College Board wanted to make sure that all admissions officers and College Board–member schools would be able to use this score.

The new metric has gained a fan in one man fighting against race-conscious admissions. Adam Mortara, the lead trial counsel for SFFA, told me that he thinks this additional score is a much better tool for capturing what he called “true diversity” in students, without factoring in race in a way that SFFA believes disadvantages Asian students. If SFFA is able to bring its case to the Supreme Court and win, he thinks this tool could help schools with less well-resourced admissions offices make holistic, non-race-based admissions decisions less labor-intensive by providing a pre-calculated number.

“No one is better placed than the College Board to do something like this, because the College Board has so much information about the applicant,” Mortara said. And as some colleges have started making standardized tests optional for admission, he also sees the move as an attempt to get people back on board. “It’s just a good marketplace response to say no, [you should] continue to use the SAT to get more information.”

In the end, the College Board is in the business of selling things: the SAT, the SAT subject tests, and test-prep books. The college-preparation agency Top Tier Admissions says that it is “not convinced the College Board has anything besides its own business interests in mind.” David Coleman is aware of this skepticism, but he said that he’s heartened by the actual outcomes. He noted that Yale, one of the pilot-program participants, reported that it was able to admit more Pell Grant–eligible students than in past years.

“Those kind of results to me are what really matters in all of this. We are beginning to help admissions officers find talent that was previously unseen to them, because that was the originating mission of the College Board,” Coleman said. “And I think the College Board is trying to take seriously the claim that SAT scores alone don’t do that. But seen in context, they could be powerful.”

This piece has been updated to clarify the source of the data that go into the disadvantage level.



Over the course of the past three decades, the A has become the most common grade given out on American college campuses. In 2015, 42 percent of grades were top marks, compared to 31 percent in 1988.

This trend of grade inflation—the gradual increase in average GPAs over the past few decades—is often considered a product of a consumer era in higher education, in which students are treated like customers to be pleased. But another, related force—a policy often buried deep in course catalogs called “grade forgiveness”—is helping raise grade-point averages. Different schools’ policies can work in slightly different ways, but in general, grade forgiveness allows students to retake a course in which they received a low grade, and the most recent grade or the highest grade is the only one that counts in calculating a student’s overall GPA. (Both grades still appear on the student’s transcript.)

The use of this little-known practice has accelerated in recent years, as colleges continue to do their utmost to keep students in school (and paying tuition) and improve their graduation rates. According to a forthcoming survey by the American Association of Collegiate Registrars and Admissions Officers, a trade group, some 91 percent of undergraduate colleges and 80 percent of graduate and professional schools permit students to repeat courses to improve a grade. When this practice first started decades ago, it was usually limited to freshmen, to give them a second chance to take a class in their first year if they struggled in their transition to college-level courses. But now most colleges, save for many selective campuses, allow all undergraduates, and even graduate students, to get their low grades forgiven.

The rise of grade forgiveness scans as yet another instance of colleges treating students as customers to be satisfied—similar to campus amenities such as luxurious dorms, palatial recreational facilities, and cornucopian dining halls. Indeed, there seems to be demand for do-overs. “Students are asking for it,” said Jack Miner, Ohio State University’s registrar and executive director of enrollment services. “We’re attracting and retaining stronger students and there’s more competition to get into majors and graduate schools, and a small change in their GPA can help.”

Ohio State expanded its grade-forgiveness policy three years ago to cover all undergraduates instead of just freshmen. Miner says that about 4,500 students—roughly 10 percent of Ohio State’s undergraduate population—take advantage of the policy in any given year. Most students see their grades rise in the second attempt, usually a full letter grade or a full letter and a half, Miner said. Still, about 15 percent of students who receive a failing grade in the first attempt have the same outcome in the second. “That’s a wake-up call for those students that maybe they need to reconsider their major,” Miner said.

Miner is generally optimistic about the promise of grade forgiveness, but others are concerned about what it could do to academic dynamics. “It teaches students that their work in a course doesn’t matter because there’s always another chance,” said Jonathan Marx, a professor of sociology at Winthrop University, in South Carolina.

Marx and his colleague David Meeler, an associate professor of philosophy, have studied grade-forgiveness programs at eight public institutions in an unnamed southern state. What they found in a study published in 2013 is that 5 percent of the seniors they polled at one of the institutions used grade-forgiveness policies to keep anywhere from a quarter to half of all of their coursework from counting toward their GPA. One student highlighted in the study repeated five different courses for better grades, including a math class in which she was eventually able to raise her grade from a D to an A-minus.

“Everyone knows about grade inflation, but this is GPA distortion, and few people looking at a student’s GPA know it happens,” Meeler said. He and Marx told me they have nothing against giving students second chances, but their issue is with the colleges that, say, allow a student to repeat five courses as they please. “Institutions are allowing students to manage their grades to get the highest reward,” Meeler said, as opposed to requiring students to work with faculty members to master the material.

At the University of Colorado Boulder, such concerns led faculty members to eliminate grade forgiveness in 2010. Professors at the time were worried about the fairness of the policy—they noticed that students in some majors were using it more than those in others, and that a freshman-oriented rule was being used regularly by upperclassmen. But now, as other colleges adopt or expand such policies, Colorado is considering reinstating the practice. “We’re weighing how to foster student success to help them achieve their goals,” said Kristi Wold-McCormick, the university’s registrar. “We are not trying to alter academic history. It gives the student a chance to tell their story, about how they overcame a mistake or a struggle.”

College officials also tend to emphasize that the goal of grade forgiveness is less about the grade itself and more about encouraging students to retake courses critical to their degree program and graduation without incurring a big penalty. “Ultimately,” Ohio State’s Miner said, “we see students achieve more success because they retake a course and do better in subsequent courses or master the content that allows them to graduate on time.”

That said, there is a way in which grade forgiveness satisfies colleges’ own needs as well. For public institutions, state appropriations are sometimes tied partly to their success on metrics such as graduation rates and student retention—so better grades can, by boosting figures like those, mean more money. And anything that raises GPAs will likely make students—who, at the end of the day, are paying the bill—feel they’ve gotten a better value for their tuition dollars, which is another big concern for colleges.

Indeed, grade forgiveness is just another way that universities are responding to consumers’ expectations for higher education. Since students and parents expect a college degree to lead to a job, it is in the best interest of a school to churn out graduates who are as qualified as possible—or at least appear to be. On this, students’ and colleges’ incentives seem to be aligned.



Until two weeks ago, T. M. Landry College Preparatory School was the most enigmatic school in America. Small and with minimal resources, this private school was known for one thing: placing an extraordinary number of black, low-income students in America’s most elite colleges and universities. Almost everything else about it was mysterious.

The school’s founders and namesakes, the married couple Tracey and Michael Landry, had promoted it via a series of viral videos. In each of the videos, a young student, usually black, waits in suspense, surrounded by classmates, to find out if he or she has been admitted to a top college—Princeton, Dartmouth, and Yale, among others. Invariably, the student gets a happy answer, and the entire room erupts in raucous celebration.
T. M. Landry is in Breaux Bridge, Louisiana, a high-poverty town of fewer than 10,000. The school’s graduates are overwhelmingly black, poor, or both—a socioeconomic segment that, due to pervasive discrimination, is notoriously underrepresented in higher ed. Statistically speaking, when a poor black student is admitted to a Harvard or a Yale, it’s a minor miracle. The odds of an institution sending graduate after graduate to the Ivy League and similar schools are infinitesimal. Watching T. M. Landry’s viral videos was akin to watching lightning strike the same spot not twice, but over and over again. Had the Landrys cracked the educational code?

At the end of November, in a blockbuster story, The New York Times solved part of the puzzle. The Landrys’ school seems to have been a fraud all along—faking transcripts, forcing students to lie on college applications, and staging rehearsed lessons for curious media and other visitors. According to the Times, an atmosphere of abuse and submission helped maintain the deception, with Michael Landry lording over his flock of children like a tyrant. In the Times story, Landry admitted to helping children with college applications while denying any fraud. The school did not respond to requests for comment for this story.
Still, a mystery remains. Even taking the alleged fakery into account, how did T. M. Landry seem to fool so many of America’s most prestigious universities for years? The work of admissions officers is notoriously secretive, but what little is known about the Landry affair threatens foundational assumptions about American higher education.


The key to the alleged T. M. Landry scam can’t be the quality of the deception, because it was far from airtight. If anything, the story the school told about itself should have sparked immediate skepticism.
This isn’t hindsight speaking; I know from experience. I first encountered the school's viral videos last spring, and as a researcher on race and education, I felt compelled to learn more. What I found immediately raised my suspicions. Outside the videos themselves, the school offered little coherent explanation of how its students managed to win the collegiate lottery so often.

Many aspects of the school were unorthodox. Tuition was modest for a private school, and paid monthly, with students seemingly able to start and stop at any time from kindergarten to 12th grade in an unusual rolling-admissions format. While the Landrys were reliably vague about their instructional methods, the hints they dropped —no homework, no textbooks, and minimal parental involvement—didn’t conform with any successful teaching model I’d ever heard of. Nor did the couple have any prior teaching experience to suggest they should be capable of working educational wonders. Press coverage openly discussed T. M. Landry’s apparent dearth of courses, classrooms, and structured teaching—even while celebrating students’ sophisticated subject-matter specialties and high GPAs. Certain inconsistencies, such as how a school without defined courses could have GPAs, were never explained.

Pictures of the school facility itself raised other questions. It was little more than an empty machine-shop floor, with folding chairs scattered across a barren concrete surface; children of all ages seemed to mingle freely. The single-room schoolhouses of yore looked elaborate by comparison. While academic achievement is not purely a reflection of school resources, this principle does have limits. Children can’t learn high-level subjects without some sort of formal instruction.
But for all the evidence pointing toward fraud, there was a sticking point: the students themselves. After all, how could fake schooling matriculate students at real Ivy League universities? Encountering the question for the first time, I was tempted toward wilder and wilder theories. Maybe the stars of the viral videos weren’t real students at all, and the whole thing had been a scheme for social-media clicks! But no: These were real kids, who really had enrolled in the nation’s top colleges. The institutions themselves frequently shared the videos, and the school'’ Facebook account showed Tracey and Michael Landry hobnobbing with admissions officials on Ivy League campuses.

Frankly, none of the pieces fit together. Still, whatever T. M. Landry was up to, the colleges and universities were fine with it, and presumably the admissions officers were doing their due diligence.
Except it now appears they weren’t.


American higher education is a hierarchy, and the schools at the top wield vast influence, both in academia and in the wider world. Whether they admit it or not, universities like Harvard, Yale, Stanford, Princeton, and Columbia are gatekeepers for the social, political, and economic elite. The T. M. Landry revelations should constitute an extraordinary crisis for these schools. They challenge these institutions’ role as gatekeepers—and perhaps even the need for the hierarchy itself.

How could T. M. Landry allegedly deceive so many? The colleges and universities that admitted the school’s grads aren’t saying publicly. When reached for this story, a number of top-tier institutions only provided brief statements expressing their concern about the situation. In a typical response, Yale stated that it “takes all allegations of fraudulent application materials seriously,” and “when applicable … pursues all cases where potentially misrepresentative application information is brought to our attention.” Princeton emphasized that it was “concerned for the affected students and their families,” and “remain[ed] committed to attracting and supporting talented students, including students from groups that have been underrepresented in higher education.” Admirably, Wellesley College stated its specific and unequivocal support for its Landry graduates, describing them as “thriving and engaged members of the community.” However, none of the institutions contacted—which also included Harvard, Columbia, Stanford, Brown, Dartmouth, Wesleyan, and Syracuse—would offer any public explanation for how they might have gotten tricked in the first place.

But at least in general terms, it’s possible to sketch out the source of the breakdown. Like a lot of scams, the alleged T. M. Landry admissions ploy was convincing not because it was hard to detect, but because it offered something that a lot of people wanted to believe. Their viral videos told a story of black children magically beating the odds, drawing millions of viewers. The school played into this narrative, appending hashtags like #blackexcellence and #blacksuccess to its videos. The faked transcripts told the same story, one that higher education found irresistible.

When it comes to admitting students from underprivileged backgrounds, colleges and universities are facing cross-cutting currents. To start with, most highly selective schools remain committed to promoting racially and economically diverse student bodies. This commitment is sincere, at least to the extent that, all else equal, these institutions would be delighted to admit lower-income students of color who have overcome great hardships.

The problem is, all else isn’t equal. Compared with more privileged children, students from disadvantaged groups often face bigger obstacles, and many live in environments with fewer opportunities for distinguishing themselves. Students who grow up facing discrimination, segregation, and poverty really do tend to have much lower standardized-test scores and briefer résumés, and graduate from less rigorous high schools. This occurs not because these students have lower aptitude, but because the scars of systemic prejudice are real.

This puts an unavoidable choice to colleges and universities fixated on maintaining sky-high academic standards. Black students and poor students remain significantly under-enrolled in these institutions compared with their share of the population. Achieving truly representative college admissions inevitably would mean admitting many students whose qualifications are far from perfect. Meanwhile, schools of Ivy League caliber use their selectivity to maintain their social and political cachet, which would be threatened by lowering admissions standards. These places thus experience inescapable tension between preserving selectivity and enrolling a racially and economically diverse student body.

What T. M. Landry offered was an Option C: all of the above. Its graduates had all the biographical hallmarks of disadvantage. Indeed, the New York Times story describes the Landrys forcing students to lie on their college applications, exaggerating the hardships they faced. But the school also had students whose purportedly strong academic outcomes reflected little of those hardships. A college or university admitting a Landry student didn’t have to choose between diversity and selectivity; it simply had to open the door to someone with an unusual and underrepresented background. It was diversity made easy.

The numbers leave little doubt about how alluring colleges found this prospect. According to T. M. Landry’s own reports, 38 percent of its graduates since 2016 have attended an Ivy League institution or Stanford. The comparable figure for families in the 99.9th percentile of income—America’s very wealthiest—is about 12 percent. Even if the Landry numbers omit a number of students who dropped out before they could graduate, this is a phenomenal success rate.

T. M. Landry shows how hungry our society is for what might be deemed “miracle students.” The Landrys are not the only ones to take advantage of this hunger, although their alleged fraud appears to have been especially egregious. Many other schools implicitly offer the same miracle: students who have endured great hardship and succeeded beyond all expectations. An entire genre of charter schools, often called “no excuses” schools, have adopted a similar rhetorical tack. These schools, explicitly targeted at poor students of color, claim to fuse rigid discipline and intense expectations to achieve an academic transformation. Their advocates often imply that only such a crucible can produce poor and nonwhite college-ready students. Like T. M. Landry, these schools have attracted disproportionate attention from colleges, not to mention media and politicians.

Ironically, the Landrys claimed to be relying on an entirely different pedagogical approach: a Montessori-inspired model with few boundaries and a family-like atmosphere. In the end, the discrepancy didn’t seem to matter, or even attract any notice. Few in education or media seemed to care too much about the exact process through which the school’s low-income black students were ostensibly transformed into academic superstars. Instead, people took solace in the idea that such a transformation was possible, and moved on.

Miracle fixes can excuse complacency, a point the writer Casey Gerald made in a searing op-ed last week. Success stories suggest that, even among the poor children of color who face pervasive societal burdens, the truly deserving can prevail in the end. When inequality is defeatable, it stops feeling so much like injustice. For that reason, many people recoil at attempts to depict segregation, discrimination, and poverty as an inescapable trap, even though, for millions of children, they have proved exactly that.

The seductive myth of the miracle student has other appeal as well. It deceives us about our ability to easily recognize true potential, by telling us that there are bright-line markers for brilliance: high test scores, extraordinary academic dedication, or other exceptional personal virtues. Instead, in most people, individual aptitude and the effects of systemic disadvantage are bundled together. When we go hunting for the former, we often find the latter, and we struggle to tell the difference. Complicating matters further, and contrary to the Landry myth, the students with the greatest potential do not typically congregate in a few select schools, where they can be easily identified.

Cruelly, the burden of the miracle-student myth falls not on the colleges, who will never lack for applicants. Nor does it fall on the schools, whose methods are celebrated. Instead, it falls on ordinary children of color, for whom ordinary levels of hard work and perseverance start to seem wildly insufficient. Why would any top-tier college or university admit a student who is merely good, when there are miracles to be had?

But this is where the T. M. Landry accusations begin to look truly destabilizing, because now its miracles appear to be fictions. Many of its graduates were, by all accounts, hardworking and dedicated, but otherwise merely mortal. And yet, they did not implode the moment they breathed the rarified air of the Ivy League. Some struggled or dropped out, but a number of Landry students—particularly those who had spent more time in traditional schools—simply continued to advance.

This, to be blunt, raises some uncomfortable questions about who belongs in those colleges and universities. These are schools that treat selectivity as a necessary precondition for academic rigor, and then rely on that same selectivity to explain their racially and economically lopsided enrollments. One recent study showed that about 25 percent of graduates from the 99th income percentile attend an “elite” school. The comparable figure for the poorest quintile, even before taking race into account, is one half of 1 percent. Why do the rules seem so different for white students from affluent backgrounds? Surely plenty of them are relatively average scholars, and yet they don’t make headlines when they’re accepted to an elite institution. And, generally speaking, affluent white students aren’t asked to surmount drill-instructor discipline and punishing, all-work-no-play schooling to prove their worth.

America’s supposedly meritocratic system of elite higher education revolves around an intensive search for the most capable students. But if no one seems to know how to find those students when they come from the wrong background, and plenty of other people seem at least sufficiently capable, what’s the point of it all? If relatively ordinary people have a chance of success at Harvard, Yale, and Stanford, why are so many ordinary people kept out—especially those who grow up black and lower-income? When so many suitable Ivy Leaguers can be found in the nonmiraculous town of Breaux Bridge, Louisiana, surely plenty can be found in other poor communities of color, too. One could even start to wonder whether anything would truly be lost if the gates of the elite academy were thrown open to a much wider range of people.

That’s the real mystery of T. M. Landry. But this one might prove too dangerous to solve.



Jason Tabor, the mayor of Santa Fe, Texas, wants you to know that his town cares about school prayer. When he attended Santa Fe High School, back in the late 1990s, the school district “took on the Supreme Court to keep prayer in school.” It lost. But “we fought for it,” Tabor told me, and this is how he wants to see Santa Fe remembered in history books some day.

Being the mayor of a small town like Santa Fe should, in most cases, be a relatively uneventful gig. But Tabor’s term began last May, six days after a 17-year-old student, armed with a revolver and a shotgun, entered the high school and shot 23 people. Ten died. Santa Fe, of school-prayer fame, was now the recipient of a new, unwelcome kind of attention: the kind that follows a school shooting.

Reporters from across the country made their way to the town of 13,000, which sits midway between downtown Houston and the beach in Galveston—“the perfect location,” according to Tabor. They set up outside the wooden crosses at the memorial on the school’s lawn to watch students and family members gather together and cry. Just three months earlier, reporters had done much the same outside Marjory Stoneman Douglas High School, in Parkland, Florida.

But where some activists in Parkland embraced the media attention and even seized on it to advocate for gun reform, Santa Fe wanted the journalists and camera crews gone. “How are they gonna help us heal? No one here wants that attention,” Tabor said when we spoke by phone earlier this month. The nation was prepared to amend its ever-expanding list of mass-shooting sites—Columbine, Sandy Hook, Parkland—but many in Santa Fe didn’t want to be known for that, and didn’t want the media attention. After the shock wore off, the reporters mostly stayed away, even as they continued to focus on Parkland.

The town preferred to take care of itself. People turned to prayer and reflection to think seriously about how to protect their community from another tragedy. “It’s not a group to cry out, like, ‘Oh, why me, someone come,’” Shelby Webb, an education reporter at the Houston Chronicle who has covered the Santa Fe shooting and its aftermath throughout the past year, told me. “It’s, ‘Alright, this is the card we’ve been dealt … Let’s take care of our own and try to figure this out on our own.’”

Many people I spoke with said the town’s attitude after the shooting reminded them of how people felt after Hurricane Harvey, the August 2017 storm that devastated Galveston County, and Hurricane Ike, which did much the same in 2008. These storms had hardened the residents of Santa Fe and nearby towns. For those whose homes had been destroyed by Ike, FEMA administrators had come down and promised them money to help rebuild. Some people are waiting on those checks even now, 11 years later. Many more continue to struggle with the effects of Harvey. “You had people still with their houses flooded dealing with the shooting,” Tabor said. A Houston Chronicle investigation found that nearly 20 percent of students in the Santa Fe Independent School District had been severely affected by Harvey, meaning they either had to relocate after the storm or lacked basic resources for a significant period of time afterward.

Following the shooting, as with the storms, many residents felt that they only had one another to count on, that to expect help from afar was a pointless exercise. “I hate to relate the two together, but it’s kind of the same, because Texas steps up and does what it has to do,” Joe Giusti, a Galveston County commissioner who lives in Santa Fe, told me. “Feds said, ‘Ah, y’all can take care of it, go ahead,’” Giusti said, describing what happened after Harvey. “A lot of people, they pulled up their boots, they went to work … neighbors were helping neighbors with it. And so they didn’t wait around for the federal response.” The same attitude, he said, characterized the town in the wake of the shooting.

Moreover, Santa Fe was, in contrast with Parkland, decidedly not going to be a site of outspoken gun-regulation advocacy. Many people thought the shooting warranted, at most, a community-wide accounting of what went wrong and how Santa Fe might do better in the future. Solutions included upgrades to the school’s security and a public focus on students’ mental health. Students now pass through metal detectors to enter the high school. Giusti, who has worked in law enforcement for 41 years, told me about new equipment that local officers must carry to be prepared for another mass-casualty event. Tabor said people are paying a lot more attention now to kids suffering from depression and anxiety. “We’re pushing really big about suicide-prevention awareness and mental-health aspects,” he explained.

Exactly one parent who lost a child in Santa Fe publicly advocated for major changes to gun policy. It didn’t go well. Rhonda Hart’s 14-year-old daughter was killed in the shooting; Hart told me she knew, from the moment she learned Kimberly was gone, that “this is a policy failure.” She explained: “This was not just [the] city of Santa Fe or Santa Fe High School. This is a system-wide failure.” She reached out to March for Our Lives organizers and joined them in loudly advocating for gun-violence-prevention measures. The backlash came quickly, and it got so bad that she and her son, Tyler, moved to nearby Dickinson, where Hart ran for and lost a school-board race.

“When I first started talking about this, everyone was like, ‘Oh my gosh, she’s some gun-grabbing liberal,’” Hart said. It didn’t help that she’s not from Galveston County, or even Texas. Hart grew up in Alaska, where she lived in 2008, when she got so fed up with Sarah Palin’s candidacy for vice president that she officially changed her party registration from independent to Democrat. Donald Trump’s election in 2016 drove her toward activism. “I started to program the phone numbers for my senators into my phone … ‘Hey Siri, call Ted Cruz, because we need to talk about health care,’” Hart recalled, laughing.

Then Kimberly was shot. Hart started talking about gun reform almost immediately. But people in Santa Fe didn’t see the shooting as a gun issue. It was a “toxic environment,” Hart thought, so she left.

For some survivors of the attack, the prevalence of guns in Santa Fe has made it difficult to heal. “You have people who were target-practicing in their backyards, but then their neighbors might have a kid who was in the band hallway or the art hallway”—the parts of the school where the shooting happened—“and can smell it now whenever they hear gunfire,” Webb said.

When I got in touch with Tabor, he said he would only talk with me if I agreed not to bring up guns. (When I tried asking him anyway, he responded by talking about other issues not directly related to guns.) Giusti pointed out that the shooter in Santa Fe didn’t use an AR-15, so unlike in Florida, there were no calls to ban semiautomatic rifles. “The fact [is] that he did use a pistol and a shotgun, I think, which most households around here have,” Giusti explained. He said measures like the metal detectors are a start, “but there’s always a trade-off”—and, he added, “you can’t prevent everything.” When kids line up outside the school to go through a metal detector, “what keeps somebody from jumping the curb with a truck sometimes and running over everybody standing there waiting to get in?” In this way, Santa Fe seems to have accepted its grim new reality.

On May 18, the anniversary of the attack, a community-wide vigil will take place at the county fairgrounds. School will be optional the day before (because the anniversary itself falls on a Saturday), and those who do attend can partake in art therapy or visit the school’s resiliency center to speak with a counselor. It will all be very Santa Fe: neighbors taking care of neighbors, praying together, hugging, hoping. Not waiting for someone else to come and save them. “I know after the one-year [anniversary] people will forget about Santa Fe, until our five-year, and until our 10-year, and then they’ll kind of come around again,” Tabor said. “That’s why we’re helping ourselves … trying to heal us personally.”

Before Tabor and I hung up, he walked me through the reasons to visit Santa Fe: Barbecue. Rodeos. The beach. School prayer. The knowledge that if your car breaks down, someone will stop and help you, because that’s the kind of community Santa Fe is.

I wished him luck in dealing with the difficult weeks ahead. “It’ll be all right,” Tabor said. “We’ll do what we have to do.”



The evidence is clear: A college degree is, in most cases, the key to more money and a more comfortable standard of living. But that pathway to higher earnings is more available to some than others: A lot of elite colleges do not enroll a lot of low-income students, and as a result they’re not boosting very many students from low-income households into the middle and upper classes.

Dozens of top colleges and universities have more students from the top 1 percent of the income scale than the bottom 60 percent, as The New York Times pointed out last year. And that’s a problem if colleges hope to escape the common critique that they are little more than a finishing school for the elite.

But there are institutions—a lot of them—that have strong track records of improving the socioeconomic fortunes of students. If higher education is supposed to be the great equalizer, these institutions—from community colleges to public regional four-year colleges like Cal State and the University of Maryland, Baltimore County—are the ones that are doing the most work.

Last week in Los Angeles, at the Education Writers Association’s annual seminar, I moderated a panel featuring a handful of people who are thinking a lot about the socioeconomic mobility of students, and more fundamentally, the purpose of higher education. The panel, which included Marvin Krislov, the president of Pace University; Dianne Harrison, the president of California State University, Northridge; and Allan Golston, of the Gates Foundation, had a few recommendations. Colleges should be actively recruiting and enrolling low-income students—and that means more than targeting ads to prospective students on social media. It means a commitment to going where they are—areas that a lot of schools do not typically recruit—and demystifying the process of going to college. Then they should be supporting students with resources when the students get to campus—whether it’s writing centers, generous financial aid packages, or simply empathetic academic advisors who perhaps came from low-income backgrounds themselves. And it is also preparing students for jobs after college and building relationships with businesses that ease the process of finding post-graduation employment for students, especially for those whose parents don’t have their own professional networks.

Pace ranks first among private colleges in catapulting its students from the lowest rungs of the income scale and into the middle and upper class, according to data from the Equality of Opportunity Project, a massive research undertaking on social mobility led by the economist Raj Chetty. “We know that there are a lot of ways in which people of privilege benefit from their college years or having unpaid internships or having the social capital to get certain jobs,” Krislov said. But colleges can fill those gaps, particularly for low-income students, helping students get jobs, or buoying them with programs that help them land paid internships with top companies. “We provide strong networks, not only through alumni, but through faculty and staff as well. And that way we help a new generation, a new, socioeconomically diverse generation, achieve the American dream.”

The suggestions from the panel aren’t particularly novel, though they can be tough to implement at scale. And, it’s getting tougher: Particularly as states continue to cut the budgets of many institutions of higher education, the schools with the most to lose are those best positioned to reach the students most in need.



Two centuries ago, Congress passed a law that kicked into high gear the U.S. government’s campaign to assimilate Native Americans to Western culture—to figuratively “kill the Indian,” as one general later put it, and “save the man.”

The Civilization Fund Act of 1819, passed 200 years ago this week, had the purported goal of infusing the country’s indigenous people with “good moral character” and vocational skills. The law tasked Christian missions and the federal government with teaching young indigenous Americans subjects ranging from reading to math, eventually leading to a network of boarding schools designed to carry out this charge. The act was, in effect, an effort to stamp out America’s original cultural identity and replace it with one that Europeans had, not long before, imported to the continent. Over time, countless Native American children were taken from their families and homelands and placed in faraway boarding schools, a process that was often traumatic and degrading.

The Civilization Fund Act stressed that the boarding schools were only to enroll Native students whose families gave their consent. But as the novelist and historian David Treuer notes in his latest book, The Heartbeat of Wounded Knee: Native America From 1890 to the Present, government workers often coerced Native parents through police seizures and threats. Many others surrendered their kids to these institutions simply because they lacked a better alternative—perhaps they were so destitute that the schools, where child labor and malnourishment were rampant, felt like an improvement. It wasn’t until the late 1970s that Congress outlawed the forced removal of Native children from their families. “The full effect of the boarding school system wouldn’t be understood until decades after the agenda of ‘civilizing the savage’ ground down,” writes Treuer, a member of the Minnesota Chippewa Tribe’s Ojibwe band who was raised largely on the Leech Lake Indian Reservation.

Treuer sees The Heartbeat of Wounded Knee as an antidote to the sort of modern-day writing on indigenous America that he argues relies on pitiful “poverty porn” or romanticized stereotypes of Native Americans. I recently spoke with Treuer about harmful depictions of indigenous people, the legacy of the Civilization Fund Act 200 years later, and 21st-century Native America. An edited and condensed transcript of that conversation follows.

Alia Wong: You write about how Native Americans have often been dismissed as an afterthought in conceptions of the United States’ identity. But you also point to the recent uptick in mainstream attention on and advocacy for their causes, much of which highlights the efforts, over the years, to force assimilation. Against this backdrop, what does it mean to you to be a citizen of the United States—an “American,” if you will—today?

David Treuer: Well, that very question is under assault, and [these debates] are evocative of American Indian history, I think. People tend to read American Indian history as a sideshow to American history; it’s treated, at least in schools today, as a breakout unit that one trots out around Thanksgiving, in November.

But American Indian history is part and parcel of American history: In what became known as America’s first revolutionary act, colonists dressed up as Mohawk Indians and then dumped tea in the Boston Harbor. America has since understood itself as being on the frontier, the advancing edge of global civilization, largely by experimenting and leveraging its unique set of resources. That experiment was conducted in the laboratory of the American landscape, which included us [Native people].

While America has always been engaged in a kind of civil war with itself over the fundamental nature of our country, [this dissonance] is perhaps most clearly seen in relation to the American Indian populations. Are we going to be a country where a person goes to get rich, or are we going to be a country that empowers and emboldens and supports its more vulnerable citizens? What kind of force in the world do we want to be?

Wong: What vestiges of the Civilization Fund Act are still apparent today, and what lessons do you hope the present-day United States takes away from that policy?

Treuer: Education was something that was done to us, not something that was provided for us. And the boarding schools are a great example of that: They were a means by which the government was trying to destroy tribes by destroying families. This is partly why education is such a tricky thing for Native people today. How are you supposed to go to school and learn about Mount Rushmore yet know that each person promoted the killing of Indian people? How are you supposed to say the Pledge of Allegiance to a country that was trying to kill and dispossess you and caused the horrible suffering of your parents and grandparents? How are you supposed to learn in an education system of which your ancestors grew deeply distrustful, and then be told we have to work hard at school to get ahead?

I can speak to this conflict autobiographically. When I was a kid, I remember a teacher on a school trip to the [Minnesota] capitol scowling at a group of Native American activists who were protesting, and saying, “All those Indians are just a drag on welfare; they should just go back to Canada, where they’re from.” I wasn’t the only Indian in class—and that was my high-school teacher.

Things are starting to change, but the changes are long overdue. And those changes trace back to the boarding schools: In many ways the plan succeeded, but in many ways it didn’t, because of various unintended consequences. For example, it took all these Native kids from different tribes who previously knew nothing about, or had been habitual enemies with, each other and put them in schools to suffer together. As a result, when they left school and went back to their homelands to promote the welfare of their individual tribes, they were armed with a network of other like-minded, educated people on whom they could rely. So, in this sense, the policy inadvertently strengthened tribes.

Today the vestiges remain in that many Natives are suffering. But as a Native person, I know that for every kid you find, say, standing in a pile of garbage, there are 20, 30, 50, 100 other kids selling Girl Scout cookies or going to tennis lessons or doing their homework or competing on the math team or getting excited about prom—often while also going to ceremony, for example, and speaking Lakota and engaging in other cultural customs. They’re living their lives—they’re not just exhibiting their pain.

Wong: How are Native youth today living their lives differently than their predecessors in your generation and from the generations subjected to the boarding schools?

Treuer: When I was in college, Princeton was in the process of hiring someone to teach American Indian studies and was debating what role that academic would have. I remember a faculty member turned to me and said, “You can either be a university professor or a medicine man—you can’t be both.” I remember being so upset, thinking, Who in the hell do you think you are to tell me what is possible? But he was expressing a long-held belief that you could be Indian or you could be American, that you could be Indian—which is to say the past—or you could be modern, which meant educated. And as much as I rejected this professor’s comment, it was an uneasy rejection.

Now I look at today’s kids—I look at my own children, other people’s children—and there doesn’t seem to be any tension in being Native and being modern. To them, being Native is not merely or only to be of the past, or to suffer, or to be a victim, or to be less than ideal Americans. They’re happily modern and Native at the same time; they happily switch between things like Fortnite and [tribal] ceremony and don’t see any contradiction between the two. Native kids today are way smarter and better off than I was.



For 25 years, the Emory University professor Vanessa Siddle Walker has studied and written about the segregated schooling of black children. In her latest book, The Lost Education of Horace Tate: Uncovering the Hidden Heroes Who Fought for Justice in Schools, Walker tells the little-known story of how black educators in the South—courageously and covertly—laid the groundwork for 1954’s Brown v. Board of Education and weathered its aftermath.
The tale is told primarily through the life of Horace Tate, an acclaimed Georgia classroom teacher, principal, and one-time executive director of the Georgia Teachers and Education Association (GTEA), an organization for black educators founded in 1878. Later in his career, he became the first African American to earn a Ph.D. from the University of Kentucky; at the time, Georgia still banned black students from state doctoral programs. Walker first met Tate in 2000. Over the course of the next two years, he told her about clandestine meetings among and outreach to influential black educators, lawyers, and community members tracing back to the 1940s. He also revealed black teachers’ secret and skillful organizing to demand equality and justice for African American children in Southern schools. After Tate’s death in 2002 at the age of 80, Walker continued a 15-year exploration, relying on Tate’s extensive archives to expose the full picture of how black educators mounted civil rights battles—in the years preceding and immediately following the Brown decision—to protect the interests of black children.
The resulting account, which features anecdotes about and cites wisdom from prominent black leaders such as Dr. Martin Luther King Jr. and W.E.B. Du Bois, offers an intriguing look at black education and helps inform the ongoing discourse on school desegregation. I recently spoke with Walker about the crucial role black educators played in the evolution of public education in the South. The following interview has been edited for length and clarity.

Melinda D. Anderson: The traditional narrative surrounding the history of school integration is filled with fearless NAACP attorneys, well-timed lawsuits, and national civil-rights leaders. As you write, this history is not incorrect. But in what ways is it incomplete?

Vanessa Siddle Walker: To overturn Plessy v. Ferguson—the 1896 Supreme Court case upholding the separate-but-equal doctrine—you have to have access to the people in the South. But if you’re in the NAACP’s national office in New York, how do you know who in the South will be a plaintiff? How do you launch a movement when you can't really work well in the South because of the hostile climate? At the same time, black teachers in the South have data on school conditions and teaching resources and they know the plaintiffs, but they can’t let it be known that they’re part of the movement or they’ll lose their jobs. So it’s a perfect partnership. Black educators called themselves hidden provocateurs—these are the people figuring out, on a local level, how to provoke change and maneuver to get better facilities and more funding. To have it publicly known would undermine what they were trying to do. The generations of black people who followed learned the script that they wanted us to know.

[Black girls fueled the crusade to desegregate schools]

Anderson: Black citizens who challenged Jim Crow segregation by rejecting racial subordination faced violence, intimidation, and economic ruin. Talk about the personal and emotional costs borne by black educators who were fighting for black children during the civil-rights era.Walker: There are obvious losses—black teachers were fired and demoted. Wonderful black principals were put in charge of running school buses. They were humiliated because they had once been leaders in their communities. Some of them had to relocate and move north. But there are costs that we forget—like losing control over what black children learned.
The black educators taught math and science and everything else as best as they could with the limited resources that they had. You also saw the infusion of blackness in their classrooms. They were teaching black children how to be resilient in a segregated society. They seeded the civil-rights movement with this curriculum.
Those of us who reflect on the civil-rights era naturally think about people losing jobs and status. But to me just as important is understanding that they lost the chance to instill in another generation the ability to think about racial progress. We lost things that were foundational. We have to know the breadth of the costs, to understand both how we got to present-day conditions and how to think about moving forward.Anderson: The implementation of Brown v. Board resulted in what Tate called a “second-class integration”—forfeiting all that sustained black children in all-black schools in the movement for equality. What went wrong, and what was lost in the integration of public schools?Walker: Black educators supported and wanted integration. They imagined an additive model, in which black children would have more than what they already had. They had school climates that taught black students to aspire. They took the negative messages from the larger society, reconstructed them, and made children believe they could be anything they wanted to be. They had black educators working through their powerful organizational networks across the South, advocating on black children’s behalf. What they wanted was access—to newer school buildings and textbooks, bus transportation, science equipment, and playgrounds. They wanted for black children what many white people already had for their children.
It was their expectation that integration would retain the aspiration and advocacy, and they would gain access. Instead, with integration, they closed most of the black schools and fired many of the black teachers—there goes the aspiring school climates. There was a push following the Brown case to merge black and white teacher organizations in the South, to be on board with integration also. But white educational organizations never advocated for what black children needed. Many of the members of the white organizations were the very superintendents and principals who were oppressing black children. You put the two together—the capacity to advocate is lost.

[Black parents homeschool their kids as an act of self-determination]
Ultimately, all we got was compromised access. White southerners pulled their children out of public schools, so the access was never what the black educators envisioned integration—that additive model—would look like. But the momentum to desegregate in the late 1960s and early ‘70s—the good feelings that followed Brown v. Board—was too much of a distraction for mainstream supporters of integration. Nobody could hear black educators’ objections in real time.
Fast-forward to today, and think about the massive data on black children’s educational outcomes. Schools with climates that encourage black students to aspire are relatively rare. The advocacy structures—very tightly networked organizations that had been around since the turn of the century—are gone. And the access that we once had, as scholars have identified, is going backwards. So the question is: Where are we today?Anderson: How did teachers juggle their activism with their job of teaching—and are there lessons for today's educators?Walker: The first thing is that you should not step out alone. I want to be very clear that the advocacy was through GTEA, not individual. It’s an important distinction because if you step out as individuals, you face reprisals from local school boards. If you speak as individuals, or without some sort of community support, then you're vulnerable. You should not step out without knowing the local climate—both that which is spoken and that which is unspoken. You must also recognize that if you step out there could be consequences.
Another lesson: Don’t tell everybody everything. In none of the correspondence in Tate’s archives did black teachers talk about the fact that they were really well-educated. They didn't tell people how they were going back to school and using state money to get master’s degrees from northern institutions. In written records of private meetings they talk about what they’re doing, and how they’re trying to create a generation of black children who will be as educated as they can make them, within the constraints of a segregated world. They told people only what they needed to know.



Abu Dhabi’s Saadiyat Island gleams in promotional photographs. It is all glittering museums and hotels, green-grassed university campuses and golf courses, and smiling Emirati men and women. It is the home to branches of some of the Western world’s premier cultural and educational institutions: the Louvre, the Guggenheim, New York University. Officials in the United Arab Emirates tout the island as an embodiment of their burgeoning cultural influence: “It is no longer sufficient to have military or economic power if you are not able to share your values,” said one Emirati diplomat at the opening of the Louvre last year. “Exchange—this is what soft power is about.”

But a new report, published Thursday, provides ammunition to critics who argue that the Emiratis are interested in importing institutions that provide the veneer of Westernization, but not the values associated with them. The report, written by New York University’s Coalition for Fair Labor, a faculty-student advocacy group, claims that the university may have violated Emirati law by relying on forced labor in the construction of its Abu Dhabi campus.* The report castigates NYU for refusing to reimburse tens of thousands of migrant workers for recruitment fees that they incurred in getting the construction jobs (among other costs), despite, they say, an initial promise to do so, and argues that it failed to put in place adequate measures to protect workers currently employed there.

The author of the report, Sahiba Gill, an NYU law-school student, said that one of the university’s main selling points in establishing its branch in Abu Dhabi in 2009 was that it offered students an education in how to be ethical global leaders. Most migrant workers are forced to pay onerous recruitment fees to be hired in the UAE; NYU said it would reimburse any fees incurred by workers building its campus. However, Gill said, NYU has failed to live up to its own standards. “When NYU is out of the spotlight overseas, where it doesn’t have the constant media attention on it, it has really dropped the ball in the last three years in rectifying major human-rights abuses,” she told me. “And this really calls into question whether NYU is fulfilling its mission of being that global, ethical university that it so wants to be.” NYU disputes the report's findings: “We believe the Coalition for Fair Labor’s assessment is neither right nor fair,” Kate Chandler, a NYU Abu Dhabi spokeswoman, said in a statement. “We disagree with the report’s findings, which are not based on primary evidence.”

The issue of forced labor at NYU’s Abu Dhabi campus came to light after a 2014 New York Times article detailed how migrant workers on the project were housed in dismal conditions, paid lower salaries than they had been promised, and subjected to police brutality upon launching a strike. The vast majority of workers had to pay up to a year’s salary in recruitment fees to get the job in the first place, and had their passports taken by their employer, leaving them trapped and with no choice but to continue working. NYU didn’t reimburse most construction workers’ recruitment fees, interpreting its commitment as applying only to those who paid fees specifically to work on the campus project. Following the New York Times report, NYU released a new set of rules meant to protect workers, and established stronger and more transparent mechanisms for monitoring compliance with its labor standards.

The NYU coalition argues, though, that the measures put in place by the university don’t go far enough. Its report evaluates the changes implemented after the New York Times article, and assesses the risks still facing workers on the university’s Abu Dhabi campus. It faults NYU for continuing to decline to reimburse workers involved in the construction of its campus for their recruitment fees, and alleges that the university has gone back on its commitment to greater transparency. When it comes to workers employed by the university today, the institution guarantees reimbursement only for those who paid recruitment fees within one year of starting work on the Abu Dhabi campus, leaving those workers who have been in the UAE longer—and paid the fees in the past—without hopes of redress from NYU. Meanwhile, a report by an independent monitor on the university’s compliance with its own commitments on labor standards, which NYU promised to make public by 2016, had yet to be completed until this month.

NYU Abu Dhabi officials forwarded the school’s new assessment, conducted by its independent monitor, which found “a good level of compliance among contractors and a high level of satisfaction among workers,” when it came to labor standards. It reported that while auditors found 87 breaches of NYU’s own labor standards—a set of guidelines updated over the course of the project, following UAE labor laws—77 of those breaches had been resolved in follow-up audits. The report monitored compliance only in the period after the campus was operational, so did not include information on alleged labor abuses during the construction process.

Chandler said NYU had delayed issuing a public compliance report because after strengthening its guidelines to protect workers, in 2016, it needed time for the independent monitor to properly assess the effect of the new rules. With regard to its policy to reimburse recruitment fees only for workers who paid fees within a year of starting work on campus, Chandler said the university had been attempting to determine whether any given worker had indeed traveled to Abu Dhabi to work for NYU. For workers who had been employed in the UAE for years before arriving on campus, she said, “We regard a claim to reimbursement as more tenuous, and not appropriate to be directed towards us.”

Tamkeen, the Emirati development authority that works as NYU’s local partner, did not respond to a request for comment.

It is not only with workers’ rights that NYU has struggled, and sometimes failed, to import its principles to the UAE. When the university first opened there, fueled by a $50 million “gift” by Abu Dhabi and the promise of much more, it declared that it would be run as a “cultural free zone”—an area where its standards of academic freedom would be respected. It hasn’t worked out that way: Mohamad Bazzi, an NYU journalism professor, wrote last year that the Emirati government had denied him a visa to work at the Abu Dhabi campus, which he believes was in part because he is a Lebanese Shia, a group that Emirati officials might suspect is sympathetic to Iran. In 2015, the Emirati government barred another NYU professor, Andrew Ross, a specialist on labor issues, from traveling to the UAE to conduct research. Meanwhile, an unknown individual or institution hired a private investigator to gather information on Ross and a New York Times journalist who published the 2014 article revealing labor conditions at the NYU Abu Dhabi campus; the article’s co-author said Emirati security officials approached him with a promise of large payments and immunity from prosecution if he wrote pro-UAE propaganda.

Chandler said that faculty and students on the NYU Abu Dhabi campus enjoy full academic freedom, and that the university considers it “disingenuous” to conflate academic freedom with a country’s immigration decisions. No university, she said, can overrule a sovereign state’s decision on who can enter its territory.  

The abuses that surrounded the construction of the Abu Dhabi campus could have served as a warning for these continued violations of NYU’s understanding with the UAE—but human-rights researchers said NYU ignored it. “I always found NYU to be kind of credulous, really,” said Nicholas McGeehan, who authored Human Rights Watch’s most recent report on workers’ rights in the United Arab Emirates in 2015. “NYU had enormous faith in [the Emiratis], and consistently talked about the fact that their government partners were very sincere about labor reform. And there was a general sense of outrage from them”—toward critics—“when it was pointed out that this was not true.”

The new report outlines how other major multinational companies have worked to eliminate the risk of employing forced labor. Apple, it points out, reimbursed $30 million in recruitment costs to workers after it found itself in a comparable situation. NYU has yet to take such a step—and Gill believes the university still has yet to come to terms with the ethical and legal risks it faces in Abu Dhabi. “NYU has to know what its risks are, and it also has to be a law-abiding institution—that’s essential for its governance,” she said. “What this case suggests is that NYU hasn’t fully thought through the implications of operating in a foreign jurisdiction, particularly on politically sensitive issues like this.”

 * This article originally misstated the scope of the allegations against New York University. We regret the error. 



Princeton is academically rigorous, but too exclusive and hierarchical. MIT has brilliant students, but it’s socially unpleasant. The University of Pennsylvania is altogether too career-minded.

These are some of the opinions that researchers heard when they asked 56 Harvard and Stanford students—most of them still in school, some of them recent graduates—which colleges they applied to and how they decided which one to attend.

The researchers, Amy Binder, a sociologist at the University of California, San Diego, and Andrea Abel, a graduate student there, published their analysis of the students’ sometimes barbed evaluations—recorded in interviews conducted five years ago—in the journal Sociology of Education late last year. Binder and Abel’s focus was on “how students construct a status hierarchy among elite campuses” and what this process has to do with establishing their own (perceived) position at the top of said hierarchy.

In general, the Harvard and Stanford students spoke highly of their own institutions, enthusing about their prestige and the broad assortment of opportunities they provided. One interviewee, a junior at Harvard, said she was won over when, during an admissions interview, she was advised, “You have to go to Harvard because a lot of these other schools are just not going to expand your experience enough.” Another Harvard student was pleased that she could dive into both biomedicine and Arabic without feeling like she was compromising the quality of her education in either subject.

Stanford students were proud, too, especially of their school’s (reputed) laid-back atmosphere. One alum called it “very creative and a little bit hipster.” Another marveled at “certain quirky things,” such as the fact that “[at] graduation they have neon, they’re wearing bikinis. At graduation!” On both campuses, students tended to believe that their schools’ sterling reputations were deserved.

A lot of the praise that students had for their schools, though, came implicitly, in the form of criticizing other campuses. The University of Pennsylvania—and, in particular, its business school, Wharton—was mentioned regularly as an example of what Harvard and Stanford proudly claimed not to be. Penn, in the view of these students, was too preprofessional. “I think people who pursue just a[n undergraduate] business degree, it’s like a signaling effect saying, ‘I don’t value learning for learning’s sake; I value education as a means to an end,’” said one recent Harvard graduate.

Other schools were looked down upon for other reasons—some for being too social, others for not being social enough. Some Harvard and Stanford students said they wouldn’t have fit in as well at Princeton (“It’s stiff”; “Everybody drinks too much”) or the University of Chicago (“Within five minutes, someone was trying to talk to me about Kant and, sort of, philosophy”). Meanwhile, there were plenty of well-regarded schools—such as Johns Hopkins and public universities like the University of California system and the University of Michigan—that none of the surveyed students brought up in conversation.

The colleges that these students had strong opinions about do have their own distinct cultures, but in the big picture, they are not so different. Binder notes that this pool of schools are all “incredibly selective,” “spend a lot of resources per pupil,” and have “very small” and “largely affluent student bod[ies]” who come from across the U.S. and the world. “In terms of how good the education is that students receive, they are basically the same on an objective scale,” she wrote to me in an email.

These interviews do not capture how all students at highly selective colleges generalize about students at similar schools, let alone how all students at just Harvard and Stanford do so. Still, Binder and Abel note that the 56 students’ beliefs were “highly convergent” and more or less consistent across gender, race, and socioeconomic background.

Binder and Abel have a theory for why many of these “elites-in-the-making” engage in such micro-comparisons (and, often, outright stereotyping): “By critiquing other campuses,” they write, “these students subtly elevate their own status and position.” If Princeton is regarded as too stiff, then Stanford is implied to be easygoing by comparison—and thus more deserving of renown.

The impulse to engage in such status elevation speaks to a broader anxiety that many of these students have about attending highly selective and competitive schools. “It’s about having worked all their young lives to get into an outlandishly selective university, knowing at some level that having made the 5 percent [admissions] cut is a matter of luck, but also being told that they got there through their own merit, and using every means at their disposal to bolster their confidence about themselves and the future,” Binder says.

As Binder and Abel suggest, these students may worry that many attendees of other colleges are as capable as they are, so emphasizing differences between schools can help validate them in self-identifying as uniquely brilliant and therefore deserving of the best education and jobs. Further, it’s also possible that these students—having for years devoted themselves fully to the project of becoming standout college applicants—feel the need to justify their past efforts.

The act of comparing may also be a sort of defense mechanism—an assertion on the part of these students that they are not what they fear, deep down, they may be. For instance, one Harvard alum who knocked Wharton for being too preprofessional was himself on the finance-career track that so many Whartonites pursue. When the researchers asked him why preprofessionalism was a relevant differentiator, given his own professional trajectory, he said, “You made a conscious decision to go to a[n undergraduate] business school, whereas I made a decision to get a liberal arts education that was less tailored and more open-ended.”

Binder and Abel also brought up the comments of a Harvard junior with a distaste for campuses that were too careerist. “This negative assessment of career focus was particularly striking since [she], herself, had participated in one of the student-run finance clubs throughout her years at Harvard, was on a path to take an investment banking job directly out of college, and planned to apply to an elite business school two years later and then return to Wall Street with her MBA in hand,” write Binder and Abel. Their research points to an uncomfortable truth about many highly ranked, highly selective schools: They aren’t as different from one another as some of their attendees would prefer to think.



BOSTON—There was a fog over the John Joseph Moakley Courthouse in mid-October. Harvard was headed to court to defend its admissions policies; a coalition of Asian American students, cobbled together by the conservative legal strategist Edward Blum, was there to challenge them. The group, Students for Fair Admissions, alleged that Harvard had discriminated against them. But there was a broader question: Could the case be the first nail in the coffin of the use of race in college admissions?

As the trial wore on, the surge of people in the entrance to Judge Allison Burroughs’s courtroom turned to a slow trickle. Passionate arguments for diversity gave way to murky debates over the validity of regression models. John Hughes, a lawyer for SFFA, tried to clear the muck in his closing arguments. “All of the claims are important,” he told Burroughs. But SFFA wanted to focus on one: that Asian American students face intentional discrimination in Harvard’s admissions process. SFFA’s argument hinged on the personal rating, one of the metrics the university uses to measure applicants, which the group argues is how Harvard adds a plus factor to students of certain racial backgrounds. The personal rating, Harvard says, is generated using a bevy of information, including teacher and counselor recommendations as well as alumni interviews. “You see the substantial preferences for African Americans and Hispanics in the personal score,” Hughes told the court.

The main question is: If race is a plus for some students, is it also a minus for others? The plaintiffs argue that there is a racial penalty for Asian students. And they allege that implicit bias on the part of Harvard’s admissions officers when reviewing applications is the reason for that supposed minus. “Evidence of bias and stereotyping can suffice to show intentional discrimination,” Hughes said.

Over the course of the trial, SFFA ran both a legal and a public-relations campaign. They leaned on several thorny issues that often frustrate the public: Harvard’s legacy-admissions process, preferences for children of donors, and the advantage that recruited athletes get. But none of that mattered on Friday. The personal ratings, and the alleged use of race in them, was the focus.

In its closing statement, Harvard offered a defense of its process, and a defense of Supreme Court precedent. “SFFA began its opening statement by contending that ‘the wolf of racial bias is at Harvard's door,’”Bill Lee, the lead attorney for Harvard, said. “That wolf is not intentional discrimination,” he continued. “That wolf comes in the form of SFFA ... It is those who would turn back the clock,” and eliminate the “not only sanctioned” but “lauded” consideration of race in individual student applications. “The goal of SFFA,” Lee proclaimed, “is to eliminate all race in admissions.”

The university has recently added instructions to its Reading Procedures—which teach admissions officers how to review applications—on how race should be used in the process, which is to say, not at all in the personal rating. SFFA charges that the change is evidence that Harvard recognized built-in discrimination against Asian American applicants. Still, the outlines of Harvard’s defense were perhaps laid bare most clearly by Drew Gilpin Faust, the institution’s former president. “There is no place for discrimination of any kind at Harvard,” she said.

The Supreme Court has four decades of precedent on the use of race in admissions. In 1978, in the case of Allan Bakke, a white student who alleged that UC Davis discriminated against him by denying his admission to the medical school, the court agreed that race could be considered as one of many factors in the admissions process. Diversity, Justice Lewis Powell argued, constituted a compelling government interest, and diverse student bodies improved higher education for all students. But this trial strikes at the heart of Justice Powell’s decision. How much diversity is necessary, and is the use of race necessary to achieve that goal?

Right now, only one person can answer that question: Judge Burroughs, who will issue judgement on the case. (This was a bench trial, meaning there was no jury.) She is under no obligation to issue an immediate decision. But when her decision does come down, it could have major implications for the colleges that use race when considering applicants. Yes, there are four decades of precedent, but the Supreme Court looks very different than it did in the time of Bakke, or even Fisher v. the University of Texas, another major affirmative-action case from 2016. And the majority of the court now appears more skeptical of policies based on race.

The vast majority of colleges do not need to use race in admissions, because they tend to be more open-enrollment institutions. It is primarily the most selective institutions, which carry with them name recognition and powerful alumni networks, that use the practice to diversify their campuses. And several states have banned the practice of considering race in admissions—such as Michigan, where the state’s flagship university has never recovered its black enrollment since the change.

There are a lot of arguments explaining how and why Asian Americans could be discriminated against in the admissions process. There could be discrimination in who receives recruiting mailers. There could be bias in admissions officers’ interpretation of the kinds of occupations Asian American students hope to have. And there could be personality bias in the personal rating. It’s unclear which, if any, of those arguments will stick and potentially force changes to Harvard’s admissions process. If Harvard loses the case, it may not appeal the decision—but if Students for Fair Admissions does, it is almost certain to.

It could be months before we have a decision in this case, and it could be years before it reaches the Supreme Court. It may never appear before the high court, but the high-powered, Supreme Court–tested lawyers in the courtroom arguing the case seem convinced that it will. And if it goes the distance, the future of race-conscious admissions could be very much at risk.



Toren Reesman knew from a young age that he and his brothers were expected to attend college and obtain a high-level degree. As a radiologist—a profession that requires 12 years of schooling—his father made clear what he wanted for his boys: “Keep your grades up, get into a good college, get a good degree,” as Reesman recalls it. Of the four Reesman children, one brother has followed this path so far, going to school for dentistry. Reesman attempted to meet this expectation, as well. He enrolled in college after graduating from high school. With his good grades, he got into West Virginia University—but he began his freshman year with dread. He had spent his summers in high school working for his pastor at a custom-cabinetry company. He looked forward each year to honing his woodworking skills, and took joy in creating beautiful things. School did not excite him in the same way. After his first year of college, he decided not to return.

He says pursuing custom woodworking as his lifelong trade was disappointing to his father, but Reesman stood firm in his decision, and became a cabinetmaker. He says his father is now proud and supportive, but breaking with family expectations in order to pursue his passion was a difficult choice for Reesman—one that many young people are facing in the changing job market.

Traditional-college enrollment rates in the United States have risen this century, from 13.2 million students enrolled in 2000 to 16.9 million students in 2016. This is an increase of 28 percent, according to the National Center for Education Statistics. Meanwhile, trade-school enrollment has also risen, from 9.6 million students in 1999 to 16 million in 2014.  This resurgence came after a decline in vocational education in the 1980s and ’90s. That dip created a shortage of skilled workers and tradespeople.

Many jobs now require specialized training in technology that bachelor’s programs are usually too broad to address, leading to more “last mile”–type vocational-education programs after the completion of a degree. Programs such as Galvanize aim to teach specific software and coding skills; Always Hired offers a “tech-sales bootcamp” to graduates. The manufacturing, infrastructure, and transportation fields are all expected to grow in the coming years—and many of those jobs likely won’t require a four-year degree.

This shift in the job and education markets can leave parents feeling unsure about the career path their children choose to pursue. Lack of knowledge and misconceptions about the trades can lead parents to steer their kids away from these programs, when vocational training might be a surer path to a stable job.

Raised in a family of truck drivers, farmers, and office workers, Erin Funk was the first in her family to attend college, obtaining a master’s in education and going on to teach second grade for two decades. Her husband, Caleb, is a first-generation college graduate in his family, as well. He first went to trade school, graduating in 1997, and later decided to strengthen his résumé following the Great Recession. He began his bachelor’s degree in 2009, finishing in 2016. The Funks now live in Toledo, Ohio, and have a 16-year-old son, a senior in high school, who is already enrolled in vocational school for the 2019–20 school year. The idea that their son might not attend a traditional college worried Erin and Caleb at first. “Vocational schools where we grew up seemed to be reserved for people who weren’t making it in ‘real’ school, so we weren’t completely sure how we felt about our son attending one,” Erin says. Both Erin and Caleb worked hard to be the first in their families to obtain college degrees, and wanted the same opportunity for their three children. After touring the video-production-design program at Penta Career Center, though, they could see the draw for their son. Despite their initial misgivings, after learning more about the program and seeing how excited their son was about it, they’ve thrown their support behind his decision.

But not everyone in the Funks’ lives understands this decision. Erin says she ran into a friend recently, and “as we were catching up, I mentioned that my eldest had decided to go to the vocational-technical school in our city. Her first reaction was, ‘Oh, is he having problems at school?’ I am finding as I talk about this that there is an attitude out there that the only reason you would go to a vo-tech is if there’s some kind of problem at a traditional school.” The Funks’ son has a 3.95 GPA. He was simply more interested in the program at Penta Career Center. “He just doesn’t care what anyone thinks,” his mom says.

The Funks are not alone in their initial gut reaction to the idea of vocational and technical education. Negative attitudes and misconceptions persist even in the face of the positive statistical outlook for the job market for these middle-skill careers. “It is considered a second choice, second-class. We really need to change how people see vocational and technical education,” Patricia Hsieh, the president of a community college in the San Diego area, said in a speech at the 2017 conference for the American Association of Community Colleges. European nations prioritize vocational training for many students, with half of secondary students (the equivalent of U.S. high-school students) participating in vocational programs. In the United States, since the passage of the 1944 GI Bill, college has been pushed over vocational education. This college-for-all narrative has been emphasized for decades as the pathway to success and stability; parents might worry about the future of their children who choose a different path.

Dennis Deslippe and Alison Kibler are both college professors at Franklin and Marshall College in Lancaster, Pennsylvania, so it was a mental shift for them when, after high school, their son John chose to attend the masonry program at Thaddeus Stevens College of Technology, a two-year accredited technical school. John was always interested in working with his hands, Deslippe and Kibler say—building, creating, and repairing, all things that his academic parents are not good at, by their own confession.

Deslippe explains, “One gap between us as professor parents and John’s experience is that we do not really understand how Thaddeus Stevens works in the same way that we understand a liberal-arts college or university. We don’t have much advice to give. Initially, we needed some clarity about what masonry exactly was. Does it include pouring concrete, for example?” (Since their son is studying brick masonry, his training will likely not include concrete work.) Deslippe’s grandfather was a painter, and Kibler’s grandfather was a woodworker, but three of their four parents were college grads. “It’s been a long-standing idea that the next generation goes to college and moves out of ‘working with your hands,’” Kibler muses. “Perhaps we are in an era where that formula of rising out of trades through education doesn’t make sense?”

College doesn’t make sense is the message that many trade schools and apprenticeship programs are using to entice new students. What specifically doesn’t make sense, they claim, is the amount of debt many young Americans take on to chase those coveted bachelor’s degrees. There is $1.5 trillion in student debt outstanding as of 2018, according to the Federal Reserve. Four in 10 adults under the age of 30 have student-loan debt, according to the Pew Research Center. Master’s and doctorate degrees often lead to even more debt. Earning potential does not always offset the cost of these loans, and only two-thirds of those with degrees think that the debt was worth it for the education they received. Vocational and technical education tends to cost significantly less than a traditional four-year degree.

This stability is appealing to Marsha Landis, who lives with her cabinetmaker husband and two children outside of Jackson Hole, Wyoming. Landis has a four-year degree from a liberal-arts college, and when she met her husband while living in Washington, D.C., she found his profession to be a refreshing change from the typical men she met in the Capitol Hill dating scene. “He could work with his hands, create,” she says. “He wasn’t pretentious and wrapped up in the idea of degrees. And he came to the marriage with no debt and a marketable skill, something that has benefited our family in huge ways.” She says that she has seen debt sink many of their friends, and that she would support their children if they wanted to pursue a trade like their father.

In the United States, college has been painted as the pathway to success for generations, and it can be, for many. Many people who graduate from college make more money than those who do not. But the rigidity of this narrative could lead parents and students alike to be shortsighted as they plan for their future careers. Yes, many college graduates make more money—but less than half of students finish the degrees they start. This number drops as low as 10 percent for students in poverty. The ever sought-after college-acceptance letter isn’t a guarantee of a stable future if students aren’t given the support they need to complete a degree. If students are exposed to the possibility of vocational training early on, that might help remove some of the stigma, and help students and parents alike see a variety of paths to a successful future.



When Yale University announced in summer 2018 that the renowned cardiologist Michael Simons had received a prestigious endowed professorship, his colleagues at the university’s medical school did not rush to congratulate him. On the contrary, they were outraged.

“I was appalled,” says Nancy Ruddle, an epidemiology professor. Nina Stachenfeld, another researcher at the medical school, got the news from a friend who had also just received an endowed chair, one of the highest honors a university can bestow. “We were both absolutely shocked,” she recalls.

The reason for their shock was this: In 2013, Simons lost his position as the chief of Yale’s cardiology division after a university committee found that he had sexually harassed a postdoctoral researcher and had publicly derided her boyfriend, a colleague who worked under his supervision. The committee called for Simons to be permanently removed from his cardiology position and barred from other leadership roles for five years. But Yale’s provost, Ben Polak, reduced that punishment to an 18-month suspension from the cardiology job, allowing Simons to keep two other leadership positions. Simons eventually decided not to return as cardiology chief, and he now runs a lab in the medical school’s cardiovascular-research center.

Polak’s decision enraged many of the school’s faculty and made headlines in The New York Times. For years, Yale’s handling of the Simons case has remained an “open wound,” Stachenfeld says. And in early September 2018, more than 1,000 medical-school students, trainees, alumni, and faculty members signed a letter to Yale’s president, Peter Salovey, voicing “disgust and disappointment” with the university’s decision to award Simons the endowed title.

Simons’s appointment sparked a broader conversation about gender equity and sexual misconduct at the medical school, and about what some on campus describe as a culture that tolerates discrimination and harassment. In 1992, women held two of the school’s department chairs in the basic-science and clinical fields. Twenty-seven years later, that number is four out of a total of 28. “There’s a lack of women in key leadership roles at the school,” says Stachenfeld, who co-chairs the university’s faculty-led committee on women in medicine. “Because of that, there’s a problem with sexual harassment and there’s a fear of reporting sexual harassment.”

Despite the backlash against Simons, Yale initially held its ground. Then, on September 21, 2018, less than three months after Simons was given the endowed professorship, the longtime dean of the medical school, Robert Alpern, announced that he would rescind the title, “out of concern for the community’s well-being.” But tensions remained high. In November, the Yale Daily News described a culture of “open secrets” at the medical school, and in late December, amid a swirl of recriminations over his handling of the Simons case, Alpern announced that he would step down as dean.

Last year, for the first time ever, more women than men started medical school. But as the controversy at Yale shows, that milestone does not tell the whole story of women’s experiences in academic medicine. In June 2018, a report by the National Academies of Sciences, Engineering, and Medicine found that 50 percent of female medical students reported having been sexually harassed. And over the past year and a half, high-profile cases such as the sentencing of the former USA Gymnastics team doctor Larry Nassar and the abrupt resignation of the medical-school dean at the University of Southern California amid revelations that he’d been disciplined by the university for sexual misconduct in 2003 have shone a spotlight on harassment and abuse in the traditionally male-dominated field of medicine. (The former USC dean, Rohit Varma, declined to be interviewed.)

Until last summer, Simons had held an endowed professorship named for the former medical-school dean Robert Berliner. But Berliner’s daughter, Nancy Berliner, the chief of hematology at Brigham and Women’s Hospital in Boston, complained to Yale that it was inappropriate for Simons to continue to hold that position, given the accusations against him. In June, the university transferred Simons to a different endowed professorship.

“In making this transfer, the University had no intention to confer a new honor on Dr. Simons,” the university spokeswoman Karen Peart said in a statement to the Yale Daily News.

But in a June 22 letter congratulating Simons on his new appointment, Salovey, Yale’s president, struck a different tone. “Endowed chairs are awarded to those whose scholarship has brought distinction to the university,” he wrote to Simons, whom he addressed as “Mike.” “I am delighted to convey our pleasure in your accomplishments.”

Critics have long argued that Yale’s administration went too easy on Simons in 2013. Alpern, the medical-school dean, did little to alleviate those concerns during a tense meeting in September 2018 with Yale’s committee on women in medicine. As he sought to justify the university’s decision to give Simons a new endowed title, two professors who attended the meeting say Alpern described the superstar cardiologist as “defenseless.”

“This medical school is his house,” says Lynn Fiellin, an associate professor at the medical school, of Alpern. “He is the one who should be able to step up and set the tone and do the right things. Not just say things, not just create committees or town halls or what have you. Actually take the action that is necessary.”

At the beginning of the fall-2018 semester, Alpern, who started as dean in 2004, planned to seek a fourth five-year term as the medical school’s top administrator. But before the holidays, he instead announced that he would leave the position, saying he plans to stay on the faculty and pursue academic interests.

In an email, Alpern declined to comment on his meeting with the women in medicine committee, and on anything to do with Simons, who sued Yale over its decision to strip him of his new professorship. (Simons eventually withdrew the lawsuit, and neither he nor his lawyer, Norm Pattis, responded to requests for comment.) But Alpern defended his leadership of the medical school, emphasizing that he made salary equity a priority of his tenure and that the percentage of female faculty members has increased from 29.5 percent in 2004 to 39.4 percent in 2019. “The Yale School of Medicine does not tolerate sexual misconduct,” he wrote. “We would never allow anyone who has been accused of misconduct to receive special treatment because of their academic accomplishments.”

A Yale spokesman said Salovey, the university president, was not available for an interview. But in a short statement, Salovey said the medical school “has more work to do” in promoting gender equity. “In recruiting a new dean” of the Yale School of Medicine, he wrote, “I will seek an individual for whom advancing gender equity and eliminating sex-based and other forms of discrimination and harassment are the highest priorities.”

Not every faculty member believes the school faces a crisis. Linda Mayes, who runs the medical school’s Child Study Center, calls the Simons controversy a “distraction” from the medical school’s recent efforts to promote gender equity, such as the appointment of a deputy dean focused on diversity and the rollout of a more generous parental-leave policy, among other initiatives. “I understand the feelings,” Mayes says, “but there’s a lot going on that’s very positive.”

In recent years, some universities and medical institutions have taken steps to curb sexual misconduct and to improve gender equity. In April 2018, USC appointed the geriatrician Laura Mosqueda as its medical-school dean, making her the first woman to hold the position. The University of Michigan recently conducted a comprehensive survey to diagnose the extent of harassment in its medical school. And in November 2018, the National Institutes of Health launched an anti-sexual-harassment website that outlines the organization’s policies on misconduct, including a new initiative designed to make harassment easier to report.

But on their own, such initiatives are unlikely to solve the problem, the causes of which are myriad and deep-rooted. Women hold only 16 percent of departmental-chair positions at medical schools, and the strict hierarchical structure of the profession sometimes forces victims of harassment to choose between career advancement and personal safety. When harassment does come to the attention of university administrators, experts we spoke to claimed that officials may be motivated to protect “superstar” doctors who win valuable government grants that fund research and bring prestige to universities. Simons is one such superstar: Last year, he was the principal investigator on four different projects that cost a total of around $3 million in grants, according to the National Institutes of Health.

“We haven’t really made much progress in diversifying the leadership of health care,” says Esther Choo, a doctor at Oregon Health & Science University who wrote an article about sexual harassment for The New England Journal of Medicine. “As long as that is true, it’s likely that none of these toxic cultures will change. But none of it is particular to Yale. I don’t know of a health-care system or a health-professional school that is succeeding in this area.”

At Yale’s medical school, advocates have proposed a number of strategies to elevate women leaders, including term limits for departmental chairs, some of whom have held their position for decades. Ultimately, though, the success or failure of reform efforts will depend on the tone set by the next dean. “There needs to be a strong moral compass and a group of leaders who not only say they believe that sexual harassment and gender harassment should not happen, but they actually take action,” says Fiellin, the associate professor. “That has to come from the top.”

For years, Reshma Jagsi has spent much of her time talking about what happens in the absence of such leadership. Jagsi, a radiation oncologist at the University of Michigan, travels the country giving talks on gender equity in medicine. Lately she’s started arguing that the story of Simons’s endowed professorship illustrates an important lesson from organizational psychology: that the strongest predictor of sexual harassment in an organization is the perception among members that the organization tolerates such behavior.

But when she tells that story, she says, she also emphasizes its ending: a renewed effort by Yale students and faculty members to promote gender equity and curb sexual harassment at the medical school. “The community is coming together in a very heartening way,” Jagsi said. “So I use it as an example of both things—organizational tolerance, and how an organization can come together to change that.”



Nearly all of the world’s 180-plus countries include the term education in their constitution. Most guarantee every child the right to free education, and many make participation in some form of schooling mandatory; some even provide universal access to affordable college. For the remaining handful, the UN’s decades-old treaty on children’s rights, which stipulates various educational protections, serves as a backup, and has been ratified by pretty much every sovereign nation on the planet. Except for one.

That one country is the United States of America, a nation that prizes the idea that anyone should be able to build a better life through education and hard work. Activists have occasionally sought to address this constitutional omission through congressional legislation, grassroots campaigns, and federal litigation, but they’ve never succeeded. Of the few cases that have made it to the U.S. Supreme Court, not a single one has managed to secure a majority ruling in favor of an argument that there is an implied right to an education in the Constitution. Against this backdrop, federal litigation over educational rights has all but disappeared in the past half century. Meanwhile, the nation’s public schools continue to vary significantly in funding, quality, and academic and social outcomes.

A class-action lawsuit, which is being filed in federal court in Rhode Island Wednesday evening and was provided in advance to The Atlantic, argues that baked into the Constitution is an implicit guarantee of high-quality education—in fact, that the constitutional system could not function were this not the case.

If the lawsuit were to succeed in the nation’s highest court (if it even makes it there), it could usher in a major overhaul of the country’s education system.

The 14 plaintiffs in Cook v. Raimondo, all public-school students or parents on behalf of their children, accuse the state of Rhode Island of providing an education so inferior that the state has failed to fulfill its duties under the U.S. Constitution. But given that there is no explicit guarantee of education in the Constitution, the lawyers are making a sort of bank-shot argument: that in denying citizens of Rhode Island a quality education, the state is, in essence, preventing people from exercising their constitutional rights, such as forming a legal assembly (as is guaranteed by the First Amendment) or voting (as is guaranteed by the Fifteenth). That this denial falls unevenly across the population is a violation of the Fourteenth Amendment, which promises people equal protection under the law. As of Wednesday afternoon, none of the defendants offered comment on the suit.

The absence of an explicit right to education in the Constitution is not some mere oversight but is instead the result of the country’s federalist system of government: Schooling in America is not the domain of the federal government, but rather the domain of states, all 50 of which mandate in their individual constitutions the provision of public education. This decentralized approach has its benefits: Local governments control their local schools, and parents in any one place can more easily involve themselves in educational policy than they could if those policies were national. But one consequence, many observers contend, is that school funding varies hugely from region to region, often with those who have the greatest need getting the least. With close to half of education spending coming from local property-tax revenue, a child’s zip code has a huge bearing on the quality of her schooling.

This inequality was the motivation behind a federal suit that some 40 years ago became the closest attempt at persuading the Supreme Court to find a right to an education in the Constitution. In San Antonio Independent School District v. Rodriguez, the plaintiffs—a group of low-income, largely Latino parents in the San Antonio, Texas, area—argued that the glaring disparities in the funding of their school district versus that of the wealthy, predominantly white community nearby amounted to an infringement on their equal-protection rights under the Constitution. The case, like much of the educational-rights litigation at the time, piggybacked off of Brown v. Board of Education, which two decades prior had convinced the Supreme Court that the separation of students by race was unconstitutional.
But in a contentious 5–4 decision, Rodriguez ruled that the equal-protection clause couldn’t be used to challenge school-financing formulas. According to legal scholars, the high court has since avoided educational-rights cases altogether: “The Supreme Court was concerned about opening up a whole new can of worms,” says Columbia University’s Michael Rebell, the lead counsel on the case and an education-law professor at the university’s Teachers College.

Since then, almost all legal battles over school funding or inadequacy have been waged in state courts. Today, educational equity is the most active area of litigation regarding state constitutions in these courts, according to Rebell. Such suits have been brought in pretty much every state, more than half of which—60 percent—have resulted in a finding that there is a right to a high-quality education under the respective state constitution, according to Rebell. Rebell has been involved in more than a dozen of these cases, including a precedent-setting suit in New York that in the early 2000s successfully argued that in underfunding New York City’s schools, the state’s school-spending system had been denying New York City children their right to a “sound, basic education,” which the New York Court of Appeals said was guaranteed by the state’s constitution.

Still, Rebell was as troubled then as he is now about the paucity of civics instruction in schools, which he says has contributed to the present-day resurgence of tribalism, historically low public trust in government, and post-truth politics. He interprets these longer-term, real-world consequences as evidence that the Constitution does indeed guarantee a right to education—hence, Cook v. Raimondo. As for why Rebell and his team chose Rhode Island as their battleground? One reason is that Rhode Island’s Supreme Court has held on two past educational-rights suits that issues around school adequacy and equity are not the province of the state judiciary. The judges have instead determined that the onus is on the state legislature to address the problems, but according to the plaintiffs in Cook, lawmakers have failed to do so.

More than that, though, the lawyers for the plaintiffs identified in Rhode Island’s education system a perfect case study for the modern-day challenges dogging public schools across the country—significant socioeconomic inequality and wide achievement gaps, for example, and a steadily growing population of immigrants, many of them Latino. (The number of Latinos in the state has tripled since 1990; they’re expected to make up 14 percent of the population by 2032.) Rhode Island has some of the worst segregation in the country: One in five schools is at least 90 percent white, while more than one in 10 is at least 90 percent students of color. The way Rebell describes it, the state has failed to support the needs of students who are learning English as a second language, a failure that he argues prevents them from exercising their constitutional rights.

“It occurred to me that you really need the basics of being able to speak English,” Rebell told me earlier this year, “and that [in a place like Rhode Island], you have a long ways to go if you want to say you’re preparing all kids for capable citizenship.”
Another thing that made Rhode Island appealing was not that it stood out for any reason, but that it didn’t: Deficiencies in civics education are common across the country. Like many states, Rhode Island’s social-studies policy is vague; there is neither a required civics course nor a required American-history curriculum. Meanwhile, the position of social-studies specialist in the state’s education department has remained vacant for the past six years, and the vast majority of Rhode Island’s teachers lack training in civics, according to the complaint. And, as is the case in many states, in Rhode Island access to civic skills and knowledge tends to correlate with income, according to Rebell. Take, for example, the fact that the plaintiffs attend schools that have only a small supply of antiquated computers, a dearth that deprives students of the “critical educational opportunities necessary to develop the skills for internet and media literacy,” the complaint contends.

Mark Santow, a Providence School Board member and a professor at University of Massachusetts, Dartmouth who often discusses urban-education history with his students, joined the suit as a plaintiff because he’d long noticed that his 13-year-old son had never had any civics instruction in his public-school classrooms. His son is fortunate in that he can resort to other places to learn civics skills and knowledge, he told me. “Because my son has an American-history professor as a dad, and is growing up in … privilege, he’ll be okay—but as a citizen and a moral being, that isn’t sufficient,” Santow says. “Most of the students around him aren’t receiving the education they need or deserve, and ultimately that means he isn’t either.”

In focusing on civics, the lawyers behind Cook v. Raimondo hope that they can appeal not just to liberals who are more inclined toward the establishment of a national right to education, but also to conservatives who’ve long advocated for improved civics education, which is often touted as a nonpartisan issue. “It’s a creative, shrewd effort to cobble together a coalition of liberals and conservatives,” says Justin Driver, a professor of law at the University of Chicago and the author of the new book The Schoolhouse Gate: Public Education, the Supreme Court, and the Battle for the American Mind. Driver, who wasn’t involved in Cook, pointed to the fact that the retired Justice Sandra Day O’Connor, who was appointed by Ronald Reagan, has dedicated her life after retiring from the bench to promoting civic learning.

Cook v. Raimondo isn’t the only pending suit seeking to get the Supreme Court to decide whether the Constitution guarantees a right to education. A separate case now heading to the Sixth Circuit Court of Appeals, Gary B. v. Snyder, accuses the state of Michigan of violating the Constitution by denying students in Detroit the opportunity to become literate.* Results from national standardized tests suggest that far fewer than 10 percent of the city’s public-school students are proficient in reading. The premise of the Gary B. case is that depriving a child of the ability to read and write pigeonholes her into a life defined by destitution and exclusion. National data show that adults with the lowest levels of literacy are disproportionately unemployed.

Like Rhode Island’s Cook, Michigan’s Gary B. is innovative: It’s the first case in the U.S. to argue that enshrined in the country’s Constitution is the right to become literate—and thus to effectively interpret education as inherent to literacy. And the two suits similarly contend that the school system’s importance lies in its role as a human-capital engine that promotes a functioning democracy. “The court got it tragically wrong when it characterized access to literacy as a privilege, instead of a right held by all children so that they may better their circumstances and meaningfully participate in our political system,” stated Mark Rosenbaum, the lead attorney representing the plaintiffs in Gary B., back in July, when the first judge to hear the case dismissed it. Momentum around Gary B. picked up this week, with a series of organizations and education scholars filing amici briefs in support of the appeal.

But Rebell, who last week filed his own amicus brief in support of the Detroit suit, takes issue with its constrained definition of education, arguing that literacy is just one component of a much broader scope of skills and knowledge that schools ought to teach. The country, Rebell says, finds itself at a “very rare opportunity” to establish a fundamental right to education. The Detroit suit is important, and could achieve critical improvements for its extremely needy student population, but it isn’t taking full advantage of this opportunity, according to Rebell. If the Detroit case eclipses Cook, he argues, “we may no longer have an opening to look at this larger issue [of civics education]—and it’s a larger issue that’s not just for poor African American kids in Detroit but also for the vast majority of American students [who] are not getting what they need to be capable citizens in the 21st century.” Students, by and large, don’t even have a good grasp on the boilerplate stuff. In 2014, fewer than a quarter—23 percent—of eighth graders across the country got a solid score on the NAEP civics exam, a negligible increase from when it was first administered in the 1990s.

Ahmed is a 17-year-old student who’s lived in Rhode Island for a decade, having immigrated to the U.S. from Ghana as an infant. Ahmed, whom we’re identifying by his first name only because he’s a minor, decided to join as a plaintiff in Cook because he feels the civics education he receives has been lacking. “America’s changing,” he says, “and the way we teach people about America and about how they can play a role in America has to change, too.”

Ultimately, Cook faces a very steep road in its effort to act on the legal opportunity that’s been more than 40 years in the making. Rebell finds optimism in the nonpartisan appeal of the suit’s civics focus, and in the work of people like Neil Gorsuch, who is the latest Supreme Court justice to publicly advocate for better civics education. On the other hand, the University of Chicago’s Driver says it’s “highly improbable” that the case would clinch a favorable Supreme Court ruling given the Court’s acutely partisan current composition—and that’s if it arrives there at all. Driver believes that state courts are still a preferable vehicle for pursuing educational equity. But he and others acknowledge that the case unequivocally holds symbolic value. “It’s not like the status quo in many states is a good one,” Driver says, “so even if it’s a long shot, that doesn’t mean it’s one that’s not worth taking.”

For Jessica Marshall, an educator who spearheaded a civic-learning initiative in Chicago Public Schools, Cook v. Raimondo is, at the end of the day, an attempt to return to public education’s civic mission—to interrogate “why and how we [as a country] do school.”
And the suit, she says, illustrates that “that is a conversation that needs to be had not just for the sake of academic performance, but also for what we really do care about in the long run.” As for what that is? Marshall puts it simply: a country in which “our kids know how to discuss and care about things in their community, and they have the resources to do so.”

* This article originally misstated the federal court in which the class-action lawsuit was filed.



Supreme Court Justice Lewis Powell was on the fence in 1978. The Court had before it the case of a 35-year-old white man, Allan Bakke, who had twice been denied admission to the medical school at the University of California at Davis. Bakke claimed that he was unfairly rejected because of the school’s quota system, which reserved 16 seats in the 100-person class for minority students. Powell didn’t know it at the time, but his decision would come to shape the affirmative-action debate for the next 40 years.

Powell’s opinion would buoy the case for affirmative action in college admissions, but some legal scholars argue that it also transformed the conversation about race and equality in America by altering the meaning of one of the Civil War amendments to the Constitution aimed at ensuring equality for recently freed slaves. As Kevin Brown, a law professor at Indiana University, told me, “Powell’s opinion in [Regents of the University of California v.] Bakke becomes the opinion that amounts to the change in the definition of the Equal Protection Clause.” And by shifting its meaning, he says, Justice Powell inadvertently changed how colleges go about recruiting and enrolling racial minorities. That shift may prove consequential as the use of race-conscious admissions at Harvard University goes on trial starting Monday.

The Equal Protection Clause is a short but critical line in the Fourteenth Amendment that states that Americans in similar circumstances should be treated equally under the law. And it’s what Bakke’s case hinged upon. He argued that the quota system at UC Davis infringed upon his Fourteenth Amendment rights and that the university was in violation of Title VI of the Civil Rights Act of 1964, which bars institutions that receive federal funds from discriminating on the basis of race—a lower hurdle toward receiving a favorable ruling than his Fourteenth Amendment argument.

The case had divided the Court: Four justices agreed with Bakke that the university’s affirmative-action strategy violated Title VI because it put a cap on the number of white students who could get in. (Those justices did not take up the Fourteenth Amendment question.) And four other justices argued that the college’s quota system was permissible under both Title VI and the Fourteenth Amendment.

“I suspect that it would be impossible to arrange an affirmative action program in a racially neutral way and have it successful,” Justice Harry Blackmun, one of the supporters of the UC Davis quota system, wrote. “To ask that this be so is to demand the impossible. In order to get beyond racism, we must first take account of race. There is no other way. And in order to treat some persons equally, we must treat them differently.”

That 4–4 split left Justice Powell as the deciding opinion. “Powell’s opinion sort of split it down the middle,” Brown told me. “He concluded that you could use race as a factor in admissions, but that you could not use quotas. And he went on to say that the only justification for affirmative action was the educational benefits of having a diverse student body.” Race, Justice Powell opined, could only be used in coordination with other factors for the purposes of diversity. As Powell put it, “There is a measure of inequity in forcing innocent persons in [Bakke’s] position to bear the burdens of redressing grievances not of their making.”

Powell’s jurisprudence upended the dominant view at the time, Brown says, that the Equal Protection Clause was aimed at helping “discrete and insular minority groups,” including African Americans, Asians, and Latinos. What that means is that “when you applied the Fourteenth Amendment, it should come to a different result if blacks, for example, were going to be the beneficiaries, as opposed to the ones who were disadvantaged,” Brown says.

Still, Justice Powell’s opinion that these institutions could consider race in admissions, but only for purposes of diversity, took hold. But that justification of affirmative action flew smack in the face of the spirit of the practice, Natasha Warikoo, an associate professor of education at Harvard, told me. “Many of these universities had systematically excluded African Americans. And even if they hadn’t officially excluded African Americans, their policies really made them inaccessible to most African Americans,” she says. Affirmative-action policies “were a way to sort of acknowledge that past and to try to be leaders in the movement toward social justice and racial justice in the United States.”

Without the extra push of a rationale rooted in remedying discrimination, minority enrollments stagnated. According to The New York Times, the percentage of black freshmen at elite schools has remained “virtually unchanged” since 1980. “Black students are just 6 percent of freshmen but 15 percent of college-age Americans,” the Times reported.

Since the Bakke case, the court has, time after time, upheld race-based affirmative action as permissible, but the precedent set by Justice Powell’s decision that the Fourteenth Amendment is based on individual rights, regardless of race, provided the window to weaken the practice, Brown told me. Forty years later, the effects of that decision are still being felt on college campuses.



Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

After that announcement, which was also blasted out in an email, about 25 percent of the student body decided to not even come back to campus for the spring semester, according to Chillo. But for the students who did—as well as their professors who stuck around—life on campus had already flatlined by the time they returned in January. As the light-pink blossoms began to sprout from the campus’s weeping cherry trees, Newbury’s nearly eight acres of Georgian-style buildings felt like a shadow of the school it’d been just a few months prior. It was no longer the college that Deborah Mael, an English professor who taught at the institution for most of its existence, remembered; the benches where her now-adult daughters had sat as kids remained empty, as did the dorms where they had relished the opportunity to hang out with older girls.

The dining hall, typically so crowded during peak lunch hours that the lines would snake out onto the neatly manicured quad, was too quiet to enjoy. The gym, which used to resonate with the clanks of athletes at weight machines and the thuds of runners on treadmills, felt abandoned, too. Faculty offices were hollowed out. Classroom attendance was abysmal. Enrollment plummeted from a little more than 600 before the closure announcement to almost half that by the end of the semester. “It hasn’t been much of a dwindling,” Mallory Stefan, who just finished her junior year at Newbury and plans to complete her degree at nearby Lasell College, in Newton, told me in April at a Dunkin’ Donuts, where she was studying for finals before heading off to her part-time job. Rather, “it’s pretty much just been a drop-off.”

Could anything have been done to prevent this ending? “Yes, we should’ve been doing online,” Chillo told me, alluding to the kinds of new-revenue tactics explored by many similar colleges. “Yes, we should’ve been developing a graduate program.

“Fundamentally, though,” Chillo continued, “there was no money for that investment.”

Many students and faculty described the news of the 57-year-old college’s closure as simultaneously shocking and predictable, a dissonance that few had the words to describe. “I think I sensed it [was coming],” Joshua Humphries, one of the 111 members of Newbury’s graduating class, told me. “But I never connected the dots.”             

In many ways, a college’s closure plays out like a business liquidation—the employees get their severance packages, the property goes on the market, the customers are told to move on.

But students and faculty suggested that a college closure cuts even deeper—that the raw pain and the stakes involved in such a shutdown are compounded by the fact that Newbury was also home. And Newbury welcomed many of its students when few other schools would: Compared with nearby private, liberal-arts institutions, Newbury’s students were more likely to be poor, identify as people of color, and/or have parents who did not attend college themselves. (Seventy percent of Newbury’s undergraduates were, according to Chillo, first-generation college students.) For these reasons, the closure feels personal, more like a breakup than a liquidation. The shuttering is for some “a proxy for [their] sense of self-worth,” Mael told me.

Students I spoke with described a grieving process after hearing the news that went from shock to panic, curiosity to nostalgia, heartbreak to acceptance. Stefan, who’s from the Denver area and had finished her finals early last December, was on a cruise celebrating her 21st birthday when news of the closure broke, oblivious due to her lack of reception. Upon returning to shore, her phone lit up with texts from her friends and bosses. Stefan, who’d held a host of roles on campus during her three years at Newbury—an athlete on three sports teams, an RA, and a work-study employee in admissions, to name a few—started applying to other colleges as soon as she got home. She proceeded to spend her entire winter break obsessing—and often crying—over her next steps. “Every day I was like, Oh my God—what am I going to do?!” Stefan recalled. “Newbury was my home away from home.”

As tends to be the case with unanticipated breakups, students and faculty acknowledge that, in retrospect, there were obvious signs that a demise was long in the making. Among the most obvious: the revelation last summer that New England’s college-accrediting agency had put the school on probation for its failure to fulfill certain financial criteria. But many of the students who do recall picking up on the school’s deterioration likely relegated those observations to the back burner as they focused on papers and projects, Pell grant applications and part-time jobs.

Plus, during Newbury’s final chapter, the school almost seemed to be in its prime, reminiscent of its heyday in the 1980s, when it was the largest two-year postsecondary institution in the United States. Newbury owed its onetime glory to a relatively obscure entrepreneur named Ed Tassinari, who in the early 1960s had founded Newbury in Boston’s fashionable Back Bay neighborhood, branding it as a business-oriented school. Tassinari over the years rejiggered that model, including converting the school to a four-year institution, and established Newbury—both the main campus and the series of satellite campuses that he subsequently acquired—as a pipeline to jobs throughout the Boston region.

In recent years, the school had expanded its NCAA Division III offerings. A brand-new men’s lacrosse program, announced in 2017, had been slated to launch this past spring, with a head coach appointed last year. Many of its existing teams had been getting better and better, some making it to the New England Conference championships. This past school year’s freshman class was one of Newbury’s largest, too; the college had to hire more residence staff and rent land from a nearby college to accommodate the growth. Art exhibits, club posters, and event flyers covered the new student center’s walls. On his blog, Chillo touted Newbury’s new degrees, study-abroad programs, business partnerships, and construction projects.

Which is in large part why the closure announcement blindsided students. “When I got the email, I was like, What is happening?” said Humphries, the recent graduate. “When I sent it to my friends, in a group chat, everybody was like, What the heck? Like, how? What is going on? We were all just confused.”

Stefan felt similarly. “We were literally having our best year,” she said. “It was just on the up-and-up—and then, all of a sudden, it wasn’t.”

Looking back, higher-education experts—including Chillo—say the school first started having troubles when it began granting bachelor’s degrees. It couldn’t compete in a market already saturated with four-year colleges—the greater Boston area alone is home to more than 50 such institutions, according to one analysis of the metropolitan’s core and neighboring cities and towns.

National trends, too, signaled a coming reckoning. In 2011, just a few years after the economy had tanked, the writer Clayton Christensen, a Harvard professor of business administration known for his advocacy of “disruptive innovation,” declared in his then-new book that the rise of online education would destroy half of the country’s colleges and universities by about 2030. After a slight uptick, the total did start to decline: At the peak, in 2013–2014, the U.S. was home to 3,122 four-year colleges, according to Education Department data; four years later, the number had dropped by 7 percent, to 2,902.

To be sure, the majority of those shuttered schools were for-profit colleges, a model whose underwhelming outcomes and questionable student-recruitment tactics garnered public scrutiny and government regulation. But recently, as people like Barbara Brittingham of the New England Commission of Higher Education note, certain regions have witnessed this trend encroach on nonprofit colleges in noticeable ways. In some places, such as Vermont, it’s felt as if small, private institutions are toppling one after the other. Southern Vermont College, Green Mountain College, and the College of St. Joseph all announced closure plans within a few months of one another earlier this year.

At the same time, the country’s colleges and universities have experienced a pronounced increase in the number of freshmen applications received over the past 15 or so years, a trend reflected in the U.S. undergraduate population’s dramatic growth, from 16.7 million in 1996 to 20 million in 2016, according to a recent Pew Research Center report. The reason for this makes sense: Personal success in the modern economy, research suggests, is more incumbent than ever on whether one has a college degree (if only because of employers’ growing tendency to treat such a degree as essential).

Yet selective colleges and universities—those that accept fewer than half of prospective students—have enjoyed a disproportionate share of that growth, receiving close to two out of every five applications despite accounting for fewer than a fifth of the country’s higher-education institutions. What’s more, the number of applications doesn’t correlate with the number of students. (The number of applications per high schooler has soared in part thanks to the Common App, which makes applying to additional schools much easier.) In fact, a gradual downturn in U.S. birth rates has led to a decrease in the country’s current high-school population (which remains four-year colleges’ primary source of students). A recent report by the National Student Clearinghouse research center underscores just how dramatically this is playing out. In spring 2019, overall postsecondary enrollment decreased by 1.7 percent, or nearly 300,000 students, from the previous spring.

This has all but the very top tier of colleges and universities—whose prestige effectively serves as a self-perpetuating revenue engine—on edge. But it’s especially nerve-racking for institutions in parts of the country where the aging is more pronounced, which, according to analyses by the Carleton College economist Nathan Grawe, are concentrated east of the Mississippi River—especially New England. Grawe predicted that the number of high-school graduates in Massachusetts, for example, could drop by as much as 15 percent from 2012 to 2032. This is perhaps most devastating for the colleges in these regions faced with the double whammy of demographic change and proximity to brand-name institutions that eclipse them with their practically unlimited resources and academic accomplishments. The kinds of colleges most at risk in this confluence of bad news? Small, less selective liberal-arts institutions that tend to draw primarily from their local populations. Institutions like Newbury.

Against this backdrop, the New England Commission of Higher Education has been especially vigilant in ensuring that federal financial-aid dollars are being used appropriately, says Brittingham, who oversees the body. The commission serves as the region’s college-accrediting agency, describing itself on its website as “the gatekeeper for [students’] access to federal financial aid.” Because this money is all but integral to an institution’s survival—roughly nine in 10 Newbury students received federal student loans—the body plays a significant role in determining whether one of its member institutions thrives or topples.

The closures and mergers are nothing new, Brittingham says. During times of a growing youth population and favorable economic conditions, the agency can focus more on objectives such as quality improvement for accredited schools. But when conditions aren’t so fortuitous, the equation flips: Not only are colleges contending with an inopportune financial climate, they’re also under extra scrutiny to perform. “With the public expecting more of higher education and, frankly, more of accreditation,” Brittingham says, “the commission finds itself spending more time on quality assurance,” by which she means who is getting accreditation in the first place.

Some of the conditions contributing to this perfect storm are of the institutions’ own making, such as their exorbitant sticker price (close to $37,000 on average nationally, which is about the same as Newbury’s tuition and fees, not including housing and other costs), their lackluster educational outcomes (like low graduation rates and gainful-employment results), and a resistance to change on the part of faculty and administrative officials. But most at-risk colleges do seek to remedy their problems; it’s just that they do so too late. By then, many are already losing students, and the accompanying revenue. Meanwhile, they struggle to compete with bigger institutions on offerings such as low faculty-to-student ratios, high-end facilities, and the provision of mental-health services, because these resources cost a lot more per student at smaller colleges, which don’t enjoy the economies of scale of their larger peers.

Trade-offs are inevitable, with many leading to unintended consequences. Colleges focused on equity may have to roll back their financial aid; some, for example, have stopped providing need-blind admissions. Others have created programs—such as online courses or time-consuming course enhancements—that many faculty oppose, arguing that such offerings stray from what they were hired to do. Many tuition-dependent colleges, perhaps counterintuitively, have resorted to steep tuition discounts in an effort to bolster the number and caliber of applicants. This tactic may improve access for much-deserving students, but the colleges take a major hit in revenue. A recent report found that tuition-discount rates have reached record highs at private colleges, with the average among incoming freshmen exceeding 50 percent during the 2017–2018 school year. In an interview with Inside Higher Ed, a former chief financial officer of Bowdoin College described this trend as “a race to the bottom.”

Several students told me they decided to attend Newbury because of its financial-aid packages. Caleb MacDonald, a rising junior who plans to attend Suffolk University in the fall, said scholarship money tempted him into taking a “leap of faith” by attending Newbury. But for many students, it was still a lot of money. Terrance Norvin, one of the few class of 2019 members who ended up graduating in May, remembered being shocked at what his family was expected to pay: about $16,000 a year, even after significant discounts. “My mom could buy me a Toyota!” he exclaimed. (The sticker price for attending Newbury, including housing, was $52,570 for the 2016–2017 school year.)

Some higher-education experts describe the country’s postsecondary landscape as a sort of Darwinian ecosystem in which the weak institutions’ inevitable failure strengthens the structure that remains. “When you have a market, you have to compete”—and given how competitive the higher-education market has become, entities that “overextend” themselves invariably “go out of business,” says Michael Alexander, the president of Lasell College, another small New England school whose small endowment, low enrollment, and middle-tier status similarly put it at risk of demise. “We [small colleges] didn’t create the problem,” Alexander says, “but we have to adjust to it.” Institutions like Newbury simply struggled, then failed, to adjust—or just didn’t want to adjust in the first place.

Chillo said he had an epiphany his first day as Newbury’s fifth and final president, back in 2014. He’d already served in various capacities at the school since 2008, including as its dean of admissions, and at a handful of other small, private colleges (among them Wheelock College, which shut down and merged with Boston University last year). As someone who’d spent his whole career in higher education, Chillo understood—and appreciated—that “every [higher-education] institution has its beauty marks and warts,” he told me.

Having already witnessed the recession’s upending of already vulnerable higher-education institutions, and its particularly brutal impact on small colleges such as Newbury, he knew that presiding over the institution wouldn’t be easy. But on meeting with the board of trustees during his first day as president, he realized just how “crazy” and “challenging” it was going to be. The board, he recalls, explained that Newbury could go in one of two directions.

One: “We blow the heck out of this,” meaning “we rebuild and retool the institution”—Newbury could leverage existing fundraising vehicles and explore new revenue streams. It could ramp up the strongest programs and overhaul the weakest. It could invest in new facilities to improve its application and retention rates, ultimately reversing the vicious cycle of underwhelming enrollment trends and tuition dependence into a virtuous one of growing demand and a diversified financial portfolio.

Two: “If we can’t blow this up and make the institution move, then we have to figure out a way to close it.”

Hence what Chillo described as the “Jekyll and Hyde syndrome” that dogged him throughout his five years as president: “Some days you feel like, This institution’s got a future for the next 50 years,” he said. “And then you have those moments when you’re looking at the balance sheet and going, Okay, we’ve got warts here, and the warts are significant.”

Those more pessimistic moments grew in frequency over his first few semesters as president. By 2015, Newbury was gasping for air. Then came the probation. By Thanksgiving break 2018, Chillo and his team decided that “the only right thing to do” was to pull the plug. The board of trustees voted on December 7 to close the school—a week before it announced the decision publicly. According to Chillo, the primary reason for the delay was to avoid worrying students when they were already stressed out about finals, which were taking place that same week. It also created a buffer during which administrators could finalize agreements with designated transfer institutions—schools such as Lasell, Curry College, Fisher College, Suffolk, and Framingham State that had agreed to customize an admissions pathway for Newbury students into their own programs.

Newbury gave its community notice of the forthcoming closure decision well in advance. Chillo described the December 14 announcement as a financial sacrifice for the sake of morality. He could have disseminated the news once classes resumed in late January and boosted the college’s bottom line by avoiding revenue losses due to dropouts, but he wanted to ensure that faculty members could take advantage of new job opportunities, which for academic positions in the fall tend to be posted in the winter.

“The hardest part was when I sat down and wrote the … announcement,” Chillo told me. That was when he realized the closure was real—that it wasn’t just a private thing for him to agonize over with a small group of executives, but something he had to break to students and faculty, whose lives and plans were all about to be dramatically altered.

Stefan doesn’t regret giving Newbury a shot, even though the transition to Lasell has caused major headaches (turns out, it’s especially difficult to transfer credits if you’re a media-production major), and she’s losing the housing stipend she got through being an RA at Newbury (she’s working three jobs so she’ll be able to afford rent).

In high school back in Colorado, Stefan was shy, socially anxious, unsure of herself. By going to Newbury, she wanted “to become something bigger.” “And that’s what a lot of kids at Newbury are”—or were—“trying to do,” Stefan told me. They probably didn’t have the best GPAs or do many, if any, extracurriculars; some probably didn’t even think they wanted to go to college or had it in them to do so. “They came here for that chance because nobody [else] gave them that chance,” she said. “And that’s what’s going to really suck, because they’re not going to be given the chance that they deserve.”

For better or worse, few people at Newbury have had the opportunity to dwell on the closure. Newbury itself proceeded with a slew of ad hoc solutions as soon as the decision became official: Admissions officers became transfer officers; the college created “curriculum maps,” protocols and tweaks to facilitate a more streamlined academic transition from Newbury. The faculty who remained—like Mael, the English professor—did whatever they could to accommodate their students’ needs.

All that support did help. “I wasn’t worried” about my next steps, said MacDonald, the rising junior who’s transferring to Suffolk. “I was just sad about the connections that I would be losing.”

When we spoke, Mael referenced a message she’d disseminated among students at the beginning of every semester: that they, despite the tough circumstances from which so many of them came, ought to interrogate when and how they could control a given situation. The closure wasn’t a situation they could reverse, she advised the young adults in her final classes; it wasn’t fair. “But what we do have control over is how we live out this semester,” she remembered telling them. “You didn’t cause this; you didn’t do anything wrong … So what are you going to do? And how can we [professors] help you to do that?”

Other small colleges across the country are doing what they can to avoid Newbury’s fate. Hiram College, in Ohio, recently trademarked two new programs—The New Liberal Arts and Tech and Trek—to set itself apart from its peers. Delaware Valley University has included in its strategic plan revenue-driving programs such as summer camps and classes for retired people. Simmons University, a women’s institution, has shifted much of its energy toward online education, its president told me; its graduate programs are now co-ed, too. Lasell has experimented with some version of all the above.

Still, in the years ahead, many will fall. Students will have to say goodbye to the places where they went to become adults, and find somewhere else to take them in, somewhere that promises a bright future—for both the students and the institution.



1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

At least 2,000 children have now been forcibly separated from their parents by the United States government. Their stories are wrenching. Antar Davidson, a former youth-care worker at an Arizona shelter, described to the Los Angeles Times children “huddled together, tears streaming down their faces,” because they believed that their parents were dead. Natalia Cornelio, an attorney with the Texas Human Rights Project, told CNN about a Honduran mother whose child had been ripped away from her while she was breastfeeding. “Inside an old warehouse in South Texas, hundreds of children wait in a series of cages created by metal fencing,” the Associated Press reported. “One cage had 20 children inside.”

On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.

About 65 million years ago, shortly after the time of the dinosaurs, a new critter popped up on the evolutionary scene. This “scampering animal,” as researchers described it, was likely small, ate bugs, and had a furry tail. It looked, according to artistic renderings, like an especially aggressive New York City rat. And it had a placenta, an organ that grows deep into the maternal body in order to nourish the fetus during pregnancy.

The rodentlike thing would become the common ancestor of the world’s placental mammals, with descendants that include whales, bats, dogs, and humans, among many other species. And today, the placenta might hold the key to one of the most enduring mysteries in human medicine: Why do women suffer much higher rates of autoimmune disease than men do?

Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

There’s a moment about 15 minutes into the first episode of Years and Years that made me gasp at its audacity, its prescience, its visual horror. The new six-part series from the British writer Russell T. Davies (Doctor Who, A Very English Scandal) charts the life of the Lyons family over the course of 15 years, starting in 2019 and ending in 2034. It’s a kitchen-sink saga that barrels its way through births and marriages and betrayals, but also through the near-future. In 2024, Stephen Lyons (played by Rory Kinnear), a financial adviser, is at home with his wife, Celeste (T’nia Miller), both rushing their way through the morning routine. When the camera turns to their teenage daughter Bethany (Lydia West), her face isn’t recognizably human. Instead, she looks like a 3-D version of a Snapchat puppy, with vast cartoon eyes, wagging pink ears, and a brown snout. When she talks, her voice is grotesquely distorted, a robotic hallucination of a child’s cadence. “I might have to start limiting filter time,” Celeste says in the same exasperated, noncommittal way that you might think, I really should spend less time on Twitter.



When West Virginia teachers initiated a nine-day labor strike this past winter, they secured national attention and a 5 percent pay raise. Oklahoma and Kentucky educators followed suit, with Arizona teachers threatening to do the same. Amid all this organizing was another strike threat, not previously reported, last week in California: between teachers in online classrooms and the organization that employs them.

Students enrolled in virtual schools (sometimes called “cyber schools” or “virtual academies”) take their classes online. It’s a small phenomenon, representing less than 1 percent of students, but a fast-growing one. According to the National Education Policy Center, about 279,000 students enrolled in virtual schools in 2016, up from roughly 200,000 in 2012. Education experts have been concerned by the growth of virtual K-12 education, especially virtual charter schools, which are publicly funded and privately managed. U.S. Education Secretary Betsy DeVos has touted virtual charter schooling as a particularly ripe area for expansion, emphasizing its flexibility and potential to offer courses that a student’s traditional school might not have. But, in practice, virtual schools, especially charters, have tended to deliver significantly lower academic results than brick-and-mortar ones. “Academic benefits from online charter schools are currently the exception rather than the rule,” wrote the authors of a 2015 report from the Stanford Center for Research on Education Outcomes.

While some teachers gravitate to virtual charters because of the flexibility it offers, salaries can be low, and class sizes are, on average, much larger than in brick-and-mortar charter schools or traditional public schools. (Though virtual teachers don’t have to manage physical classrooms, large class sizes still equate to a heavier workload.) The overwhelming majority of virtual teachers are not unionized. But in 2014, educators at California Virtual Academies (CAVA), California’s largest network of online charter schools with more than 10,000 students and about 450 teachers, decided to create a union, California Virtual Educators United, under the umbrella of the California Teachers Association. After two years of legal battles, CAVA recognized the teachers’ union, and starting in September 2016, the parties began negotiating their first contract over salaries, class sizes, and other issues.

The negotiations represent an important test case of how educators might wield power in a future where online education becomes even more common. According to Brianna Carroll, a high-school social-science teacher in Livermore, California, and president of the teachers’ union, bargaining had been slow-going, especially in recent weeks, when negotiators hit an impasse over class size. Educators said the number of students under their supervision had spiraled out of control, with some teachers stuck overseeing virtual classrooms exceeding forty students, and demanded class sizes be capped. “Either you have teachers who are burning themselves out because they’re trying to meet the needs of everyone, or you aren’t meeting the needs of everyone,” Carroll told me. “It’s really one or the other.”

April Warren, CAVA’s head of schools, declined to comment on many details of the negotiations. “CAVA is dedicated to working together with CVEU to reach a fair and equitable settlement so that we may continue to build upon CAVA’s unique and special achievements in support of the students and families across California,” she told me in an email.

While virtual schools across the country face some of the same struggles roiling traditional public schools, namely decreased state funding per pupil even after local economies have rebounded since the recession, virtual teachers also have to reckon with a newer threat: the involvement of for-profit companies that seek to deliver profits to their investors. CAVA, for instance, is a nonprofit network, but its operations are deeply intertwined with K12 Inc., a publicly traded company based in Virginia. K12, founded in 2000 by William Bennett, the education secretary under Ronald Reagan, and Ronald Packard, a former Goldman Sachs banker, is the nation’s largest supplier of management services and curriculum for virtual charters. The company, according to Education Week, has built a powerful lobbying operation in more than 20 states.

While CAVA describes its schools as independent, Jessica Calefati of San Jose’s The Mercury News, who investigated the arrangement back in 2016, found tax records showing that K12 employees themselves had established more than a dozen online schools in California. CAVA contracts with K12 for all sorts of services: The company provides the schools’ curricula, oversees their budgets, trains teachers, offers technical assistance, and even handles media communications. Calefati wrote, “Accountants and financial analysts interviewed by this newspaper, including several who specialize in school finance, say they’ve never seen anything quite like the arrangement between K12 and the public online academies.” (A CAVA official called The Mercury News investigation a “gross mischaracterization” of the organization’s work.)

CAVA teachers say they organized a union in part to push back on K12’s corporate influence over their schools. “For so long it’s been focused on how to use this charter-school concept to turn a dollar, rather than how to use online tools to support more students,” said Carroll, the union president. “We’re really using the union to push CAVA to have different goals.”

The virtual charter network might benefit from some new goals. In 2016, then-state Attorney General Kamala Harris alleged that K12 and CAVA had used false advertising and inflated their student-attendance numbers to collect extra state funds. Harris also alleged that K12 had trapped the network in debt by saddling CAVA with an unfair contract. CAVA and K12 agreed that year to settle with the state for $168.5 million. K12 emphasized it had admitted no wrongdoing, and said the attorney general “grossly mischaracterized the value of the settlement just as it did with regard to the issues it investigated.” In an email to The Atlantic, the K12 spokesperson Michael Kraft disputed the AG’s characterization of the schools as indebted. Also in 2016, The Mercury News reported that fewer than half of CAVA’s high-schoolers earned diplomas, and almost none were qualified to attend the state’s public universities. (K12 disputes this, noting the state does not always have reliable data for nontraditional schools with higher student mobility rates.) CAVA was also hit with a nearly $2 million fine in 2017 after California’s Department of Education found continued issues with attendance reporting and other practices. (CAVA disputed this, releasing a statement that CAVA schools “demonstrated they were consistently operating in full compliance with all state laws and regulations” and planned to appeal the financial penalty.)

Last fall, faced with a stalemate with CAVA over salaries, workday length, and class size, the teachers authorized a strike: More than 90 percent of the 450-member union voted to back their bargaining team if it called for walking off the job. Shortly after that, CAVA administrators tentatively agreed to some new concessions, according to copies of signed agreements provided by the union: a pay raise, a shorter work year, and fewer employment duties, among others.
Still, the fight around class size remained unresolved. CAVA teachers argued that class-size limits would improve academic quality. Carroll said the charter network maintained during negotiations that caps would hinder their needed flexibility. (CAVA declined to comment on its position on class sizes.) When they were still unable to reach an agreement, following a two-day fact-finding mediation last week, union leaders announced they were preparing for a first-of-its-kind strike. A virtual-charter strike would have meant that all online classes would be canceled, and teachers would meet in person to picket at locations such as the CAVA offices in Simi Valley. The strike was to be held in late April or early May.

But the day after the teachers’ strike announcement, April Warren, CAVA’s head of schools, proposed a compromise resolution: Classrooms could be capped at about 30 students, according to a copy of the signed agreement provided by the union, and if a classroom were to exceed that threshold, the teacher would be compensated accordingly. The teachers agreed. “I think the strike played a huge role in helping us resolve this, because that’s what CAVA was constantly saying—‘well, we don’t want a strike,’” Carroll said. Warren declined to comment on the strike threat, but on Monday, she confirmed the parties had reached a tentative agreement and were “working on a timeline for full ratification.” A spokesman for K12 declined to comment.

Carroll says teachers at other virtual charter networks have been reaching out to her, intrigued by her and her colleagues’ union work. While the West Virginia and Oklahoma teacher strikes demonstrate how educators at traditional public schools can still assert formidable collective power, just 11 percent of charters in the United States are currently unionized, and among virtual charters, that number stands at 9 percent. There are several reasons for this: Most charter-school backers and funders take a relatively anti-union stance, asserting that unions will impede a school’s flexibility, and therefore its ability to deliver the best education possible for students. Unions have also been slow to organize charter-school teachers, long viewing them as scabs who threaten their livelihoods. Labor groups have softened their stance towards charter teachers in recent years, but tensions remain as unions continue to work politically to halt charter-school growth.

A successful contract negotiation for CAVA teachers, though, could help ignite similar efforts elsewhere. The anything-goes approach to virtual education has made it alluring to operators trying to cut costs or make a buck. But if their workers have any say in the matter, online charters’ freewheeling days may be numbered. That would be good not just for educators but for the students entrusted to them.



When the giant Indian technology-services firm Infosys announced last November that it would open a design and innovation hub in Providence, the company’s president said one of the key reasons he chose Rhode Island was its strong network of higher-education institutions: Brown University, the Rhode Island School of Design, and the Community College of Rhode Island.

In a higher-education system that is often divided between two- and four-year colleges and further segregated between elite and nonelite institutions, it’s not often that a community college is mentioned in the same breath as an Ivy League campus. Nor is a two-year college seen as a training ground for jobs in the so-called creative economy, which include industries such as design, fashion, and computer gaming that typically require bachelor’s degrees.

But the Community College of Rhode Island, New England’s largest two-year college with more than 15,000 students, is working hard to change the tired image of two-year institutions as places for high-school graduates who can’t hack it on four-year campuses or for the unemployed trying to figure out what’s next. Led by Meghan Hughes, a relatively new president with an academic background in art history, the college is overhauling its approach to workforce development by better aligning programs with the state’s economic priorities than is currently the case.

“Like many colleges, we tended to be more reactive and slower to respond to training needs,” said Julian Alssid, who started last summer as vice president of workforce development. The college would typically wait for displaced workers to come to the campus to receive retraining instead of intervening before they were laid off. It had advisory groups of employers to provide guidance on certificates and degrees, but they met infrequently, so it would take months or sometimes years to tweak existing programs or start new ones.

Now, the college is in the process of reorganizing its continuing-education division to build ongoing partnerships with companies to keep it current on industry trends and operate training programs responsive to and in sync with the labor market. The alliance with Infosys is a good example of this new strategy as the college works with the company to figure out how the school can help in recruiting and training 500 workers who will make a median salary of $79,000.

The problem with many existing workforce-training programs, Alssid said, is that employers, colleges, and local workforce boards responsible for doling out federal funds “all operate separately, calcified in their own silos.” In this new economy, he added, “those worlds will blend together.”   

The world of work is undergoing a massive shift. Not since the dawn of the Industrial Revolution in the 18th and 19th centuries and the Information Age that followed in the last century has the scale of disruption taking place in the workforce been so evident. An oft-cited 2013 study from the University of Oxford predicted that nearly half of American jobs—including real-estate brokers, insurance underwriters, and loan officers—were at risk of being taken over by computers within the next two decades. Just last fall, the McKinsey Global Institute released a report that estimated a third of American workers may have to change jobs by 2030 because of artificial intelligence.

Previous shifts in how people work have typically been accompanied in the United States by an expansion in the amount of education required by employers to get a good job. In the early 1900s, the “high-school movement” turned secondary schools into a nationwide system for mass education that provided training for life instead of small-scale institutions designed to prepare a select group of students for college. In 1910, just 9 percent of American youths earned a high-school diploma; by 1935, 40 percent did.

This expansion of high schools was the first wave in a century-long broadening of education in the United States in response to the changing needs of the economy. The high-school movement was “truly path breaking,” wrote Claudia Goldin, a Harvard University economist, in a paper published by the National Bureau of Economic Research. “No other country underwent the transformation to virtually universal public secondary education” so early and so quickly. “Without the rapid rise of the high school,” Goldin argued, “America could not have put the GI Bill of Rights … into immediate action after 1944 for American youth would not yet have graduated high school.”

The second wave in expanding education for a changing workforce occurred in the 1960s with the “college-for-all” movement. In 1965, President Lyndon B. Johnson signed the Higher Education Act, which bolstered federal aid for higher education. Meanwhile, states built community college campuses and widened the mission of state teachers’ colleges by adding a bevy of programs in all academic fields. Between 1970 and 2016, enrollment in higher education more than doubled from 8.5 million to 20.5 million students.

Now a third wave in education and training has arrived, argue economists, educators, and workforce-development officials. The level of preparation that worked in the first two waves—adding more time to education early in life—does not seem sufficient in the 21st-century economy. Instead the third wave is likely to be marked by continual training throughout a person’s lifetime—to keep current in a career, to learn how to complement rising levels of automation, and to gain skills for new work. Workers will likely consume this lifelong learning in short spurts when they need it, rather than in lengthy blocks of time as they do now when it often takes months or years to complete certificates and degrees.

With this third wave will come a shift in how workers perceive retraining, said Brent Parton, deputy director of the Center on Education and Skills at the think tank New America. “We tend to think of retraining now as something that follows a traumatic event—a job loss, for instance,” said Parton, who served as a policy advisor in the U.S. Department of Labor during the Obama administration. “We’re entering a stage where retraining will be the day-to-day world that people live in. It will be part of their daily life and a much quieter set of traditions compared with now.”

One big worry, however, is that the arrival of lifelong education will only exacerbate the economic divide that already exists in the United States. Education levels in the U.S. are closely tied to income. Simply put: Rich kids are far more likely to graduate from college than are their poor and working-class peers. There’s no reason not to believe that trend won’t continue in this third wave of lifelong learning. It is likely to help workers who already have high levels of education get the training they need rather than assist underemployed or unemployed workers who need to upskill to keep a job or get a new one.  

Two simultaneous forces in the job market are driving this push toward lifelong learning. The first is automation and the widening divide between the lifetime earnings of high-school and college graduates. While experts predict that few occupations will ever be totally automated, most jobs are likely in the future to have many of their basic activities performed by a computer. In its report, McKinsey estimated that in about 60 percent of occupations, at least one-third of activities could be automated by 2030. “The shift could be on a scale not seen since the transition of the labor force out of agriculture in the early 1900s in the United States and Europe,” the report warned.

The second is the emergence of the gig economy, which is reshaping the traditional employer-employee relationship as more contractors and freelancers fill roles once reserved for full-time workers making good salaries. While the term “the gig economy” conjures up images of popular apps for temporary work, such as Uber and Task Rabbit, the army of professional white-collar freelancers is larger than that encompassing the services we can request on our smartphones. In a 2016 study, two economists, Lawrence F. Katz and Alan B. Krueger, found that all net employment growth in the United States since 2005 appears to have come from what they termed “alternative work”—that is, contract and freelance work, which has ballooned by more than 50 percent over the last decade.

Both trends in the job market have the potential to upend the current federal workforce-training system that is largely run by the government and depends on solid projections about future jobs with traditional employers. Automation adds “much more uncertainty about what jobs are in high demand,” said Harry Holzer, a professor at Georgetown University and former chief economist for the Labor Department. “What might look like a job or skills in high demand today, might not be by the time someone is done training for a new job.”  

What’s more, federal retraining programs deliver funds through local workforce boards, which operate one-stop centers where job seekers go for help largely to prepare for full-time work, not to become independent contractors or entrepreneurs. If more people are employed as freelancers in the future, workforce-development officials worry that it might be difficult for some workers to know when they need a new set of skills to remain employed.  

One role traditional employers have always played is in the professional development of their workers. On a yearly basis, usually through annual performance reviews, employers would advise employees about the skills needed to keep their job or to receive promotion. In many cases, employers would suggest training programs and pay for them. But freelancers get no such guidance nor help on finding or paying for continuing education.

Policy officials maintain that the realities of the modern workplace demand that government-run job-training programs in the future play a different role. Rather than focus on routine skills that can be replaced by technology, job training needs to target key skills that complement technology, such as problem solving, teamwork, and communication.

At the same time, training must occur more regularly and less episodically than it does now in order to keep pace with the increasing churn of jobs. Already colleges are responding to this need by expanding noncredit programs; such courses can be up and running more quickly than credit-based programs can, and they take much less time to complete than do full-fledged degrees and certificates.

But those noncredit programs are small compared to degree programs, and most higher-education institutions still operate with a mentality that it’s not their job to train people for a job, economists say. “What worries me,” Holzer said, “is that the system today is not great at providing training to workers who need it, and the demand is only going to grow in the future with more workers, in more occupations.”

The classic image of job retraining in the U.S. remains that of laid-off blue-collar factory workers learning new skills. But if greater numbers of white-collar workers with college degrees tap into the federal job-training system in the future, it risks collapse trying to take into account their training needs as it is also starved for money. (Federal training dollars have been slashed by 22 percent since 2009, and in his second budget this year, President Trump proposed further cuts.)

Increased funds for federal job-training programs will only come when white-collar workers use the benefits in addition to laid-off blue-collar workers. “It needs to be seen as a benefit for everyone,” said Josh Copus, the chief operating officer of the National Association of Workforce Boards. “If the more advantaged [white-collar workers] don’t use career centers, we’re never going to expand the social capital and networks of those who do use them.”

Experts agree that to adequately serve an increasingly diverse set of workers and industries, the current patchwork of federal training efforts needs reform. An important first step was taken in 2014 when Congress replaced the 1990s-era Workforce Investment Act with the Workforce Innovation and Opportunity Act. Among other things, the new law emphasized “career pathways,” which offer workers a sequence of educational opportunities and credentials that they can earn as they work in progressively more advanced jobs. For example, instead of training to become a nurse, workers could first pursue certificates as nursing aides.

But further reforms are needed for the third wave of education and lifelong learning, so that training isn’t seen as something that happens only when there is a shock to the economy, such as a recession or a massive factory layoff. One idea that has been suggested by economists and workforce-training officials: “work sharing,” which allows employees to retrain while they’re still employed. Work sharing is a program in place in more than 25 states in which employers reduce their workers’ hours and pay and the states make up some of the lost wages. Right now, it’s typically used as an incentive in an economic slowdown to keep skilled workers employed, but it can also provide workers the flexibility to improve their skills while in a job.

If training and education become a lifelong pursuit, the big question is how to pay for it. Many people enter the workforce already in debt from college. Student debt has doubled since 2009 to $1.3 trillion. Given these circumstances, few people have money for further training. In response, some states offer Lifelong Learning Accounts, a 401(k)-like plan that allows employers and employees to contribute to an account for retraining purposes.

Michael Horn, a higher-education consultant who has written extensively on the future of training, recently suggested similar plans that he dubbed “renewable learning funds.” They would be paid for by an alternative form of financial aid called income-share agreements. Such agreements provide students money to cover college costs, and, in exchange, students agree to pay back a percentage of their future income rather than take on a fixed amount of debt.

“Continual education is not just about paying for tuition,” Horn said. “Training carries an opportunity cost in terms of lost wages, and so we need to figure out how to support some of their living expenses, too.”

Faced with a skills gap, employers are increasingly working with community colleges to provide workers with both the academic education needed to succeed in today’s workforce and the specific hands-on skills to get a job in their companies.

In the long race between education and increasing technology in the workforce, education has historically always won, according to Goldin, the Harvard economist. In other words, for much of the 20th century, simply having a college degree and, even better, an advanced degree, was seen as a key advantage in the job market. But it’s unclear whether that dynamic will remain true in a job market undergoing massive changes. A college degree will certainly remain a differentiator in the future, but not just any degree, argues Alssid, the vice president of workforce development at the Community College of Rhode Island.

“While we don’t know what skills will be required for the human-centric jobs of the future [such as health care, management consultants, and financial planners],” said Alssid, who has spent more than two decades in the workforce-development field, “we do know that these jobs will require a highly adaptable workforce that can think critically, creatively, and work collaboratively to find solutions to rapidly developing, complex problems.”

Such skills, often referred to as “soft skills,” are typically seen in liberal-arts graduates, but those individuals often lack the technical skills employers want. Alssid said a hybrid of liberal-arts and technical education is what is most needed in training programs to allow workers to better navigate the ambiguity of the future job market. That’s the goal of his school’s partnership with Infosys—to introduce liberal-arts students to technical fields that they might not have previously considered, while other programs will introduce the flexibility of the liberal arts to technical workers.

More than a century has passed since the universal high-school movement took off in the United States and 50 years since the college-for-all movement began. Those first two waves of education helped the U.S. build the world’s most successful economy. Now it’s clear a third wave in the evolution of education is needed to compete in a new economy in which learning can never end.

This project is supported by a grant from Lumina Foundation.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?



Operation Varsity Blues was full of salacious accusations detailing how wealthy parents allegedly cheated to get their kids into elite schools through hefty bribes and outright lies. But one particular deceit orchestrated by William Singer, the college-consultant fixer at the center of the scam, drew the ire of the disabilities-rights community: the abuse of extended-time accommodations on standardized tests. “All the wealthy families that figured out that if I get my kid tested and they get extended time, they can do better on the test,” he allegedly told one parent. “So most of these kids don’t even have issues, but they’re getting time.”

Time extension is just one of several accommodations that students can apply for when registering for standardized tests—including the SAT, the ACT, the MCAT, and the LSAT—as mandated by the Americans with Disabilities Act. The alternative arrangements run the gamut from food in the testing room to a computer to fill out the test, and take into consideration disabilities both physical (cerebral palsy, muscular dystrophy) and invisible (ADHD, autism, diabetes, dyslexia). Under the ADA, accommodations such as these are meant to help students with disabilities that would significantly affect their capacity to complete the test.

The extra-time accommodation is by far the most common. The amount of extra time that students get depends on the test; for example, the College Board, which runs the SAT, allows extensions of 50 or 100 percent additional time—or even more in rare cases. Though this isn’t the first time that wealthy parents have concocted bogus diagnoses in an attempt to get an edge for their kids, the high-profile indictment has made disability-rights professionals fearful that it could curtail disabled students’ access to conditions in which they can “actually perform at the same level of someone who does not have a disability,” says Kristie Orr, president of the Association on Higher Education and Disability. While the College Board and the ACT did not specifically mention the abuse of extra time in their statements after news of the scandal broke, each doubled down on their commitment to fairness and ensuring a level playing field.

These parents went to such great lengths to get extra time for their kids only because these tests run at breakneck speed—a feature that routinely stresses out test takers of all abilities. Students are often encouraged to be strategic about budgeting their time: how long to spend on a given question, whether to use a calculator or do mental math, when to give up and fill in bubbles at random. A time-limited test is a bad measure of the things that schools theoretically want to see, such as critical-thinking skills and college readiness, says Ruth Colker, an Ohio State University law professor and a scholar of disabilities discrimination.

“Whether you can tell me the answer quickly has nothing to do with whether you, in fact, know the content,” she told me. “And there are some people who, for whatever reason, are pretty quick at things. They don’t necessarily have more depth of knowledge, and depth of knowledge [is] what we should care about for admissions purposes.”

In a paper in the Seton Hall Law Review, Colker makes the argument for eliminating that quick pace altogether. Under the ADA, organizations such as the College Board aren’t permitted to use tests that have a “disparate impact on the basis of disability”—in this case, timed tests that students with disabilities have trouble completing—unless they can prove that those conditions are necessary for a test’s measurement. Colker says that testing organizations haven’t sufficiently shown that the time limit meets that standard. Though the College Board has released research on the impact of extended time on students’ performance on the SAT, finding that “extra time helps medium- and high-ability test-takers with and without disabilities,” it hasn’t released any evidence that the quick pace is indeed essential to the test. A spokesman for the College Board said in a statement that time limits are “necessary logistically,” and cited an assertion by David Coleman, the College Board’s CEO, that the latest version of the test has “43 percent more time per question than any similar exam.”

Colker’s proposed alternative would consist of a test with fewer questions and more time to process the questions and double-check answers, therefore giving students more time to actually demonstrate their knowledge. For example, Colker proposes restructuring the LSAT, the admissions test for law school, which currently has six 35-minute sections—five with 22 to 28 questions, and one essay component—and gives only one break in the three-and-a-half-hour test. It’s an “unbelievably exhausting test,” she says, remembering her one experience as a law-school applicant. Instead, Colker advocates for splitting the test into three 52-minute sections, with a break between each, and 40 percent fewer questions overall. The test would still run three hours, she says, but students of all processing abilities would have more time to answer each question.

A big problem with the current time crunch, Colker says, is that it puts the onus on students with disabilities to prove their need for extra time—to read, to process, to understand what a test is asking of them. Compiling the documents to apply for an accommodation can be costly; if denied, test takers have the option to appeal the decision, but that requires additional documentation and money. Moreover, ability isn’t binary, but the way accommodations currently work treats it as such: Either you get extra time, or you don’t.

Take, for example, a case in which a New York woman sued the National Board of Osteopathic Medical Examiners for denying her extended time on a medical-license test—even though she had previously received extra time for a hearing impairment and dyslexia, which slowed her ability to read. When the plaintiff, Bernadette Bibber, challenged the decision, a court decided that her disability wasn’t severe enough to warrant the alternative arrangements.

To some medical professionals, this kind of scrutiny over who gets accommodations isn’t necessarily a bad thing. “I look at everything but the kitchen sink,” says Marla Shapiro, an Atlanta-based developmental neuropsychologist who helps students apply for testing accommodations. “I want every K-to-12 report card. I want all standardized testing.” The evaluation is rigorous, she says, because she doesn’t recommend accommodations lightly. “Parents are paying three or four thousand dollars for these comprehensive analyses, and they expect something for it, but I’m not one to sell diagnoses,” she says. “It does such a disservice to those who are truly in need to hand it out like candy because somebody’s paying you a lot of money.”

Of course, if the tests were slowed down, other accommodations would still have to be available; getting rid of the quick pace wouldn’t alleviate the need for Braille test booklets or wheelchair accessibility. But extended time has become especially fraught because researchers note that it’s impossible to pinpoint precisely how much time a student with a disability needs in order for a test to be equitable for them. When should a disability require someone to have 100 percent extended time instead of 50 percent? Or 50 percent instead of none at all? Where and how is that line drawn?

That murkiness over who is “truly in need” of an accommodation is one reason that Colker wants to reframe how people think about test accessibility. “I am not making the radical argument that we should get rid of standardized testing altogether,” Colker told me. “I understand it would be difficult to admit students into college and law school if all you have is student grades. But I think we should at least see what would happen if we give every student the extended time.”

In that scenario, all test takers would no longer have to rush through a long test, instead of just those who can navigate the byzantine application for extended time. But for the time being, the alleged fraudster parents implicated in the cheating scandal made clear that the current alternative-arrangements system is far too easy to game—and that’s ultimately to the detriment of students with disabilities who genuinely need the accommodations.



On Monday, Donald Trump’s administration released its budget proposal for the 2020 fiscal year, and the plan isn’t pretty for the Education Department. The proposal requests a roughly $7.1 billion cut in funding for the department compared with 2019, which represents a 10 percent decrease in its budget. The proposed cut is unlikely to go anywhere; like years past, Congress is expected to disregard it for the most part. Instead, more than anything, the proposal is an exposition of the administration’s philosophy on education: It is a state and local issue that the federal government shouldn’t have its hands in.

At a granular level, the budget request looks similar to the ones released by the administration in 2017 and 2018. It would, again, eliminate a range of programs such as the Public Service Loan Forgiveness program, an incentive program that forgives the student loans of public-service workers, and there would be steep cuts to the National Institutes of Health, which funds a lot of research in higher education. And it would cut funding for teacher development under Title II, the part of the law funding preparation and pathways to develop better teachers.

In contrast with the proposed cuts, the budget would increase the amount of spending on federal charter-school grants by $60 million. It would keep funding for historically black colleges and universities level, and expand availability of Pell Grants to short-term credential programs rather than primarily two- and four-year colleges. And this year, as a result of the Federal Commission on School Safety, the administration is asking for $100 million for new school-safety grants. The grants would help schools create emergency plans and improve access to counseling, mental-health services, and similar strategies to improve school climate.

Each year, the budget request is joined by a chorus of reminders from policy wonks and lawmakers that ultimately Congress has the responsibility for setting funding levels. Congress has wielded that power during the past two budget cycles, rejecting the administration’s proposed cuts, and in fact has increased the Department of Education’s budget over the past several years.

For Education Secretary Betsy DeVos and the administration, the main talking point has remained the same. “This budget at its core is about education freedom,” DeVos said in a statement. “Freedom for America’s students to pursue their life-long learning journeys in the ways and places that work best for them, freedom for teachers to develop their talents and pursue their passions, and freedom from the top-down ‘Washington knows best’ approach that has proven ineffective and even harmful to students.”

In past years, both Republicans and Democrats have not taken kindly to the proposed substantial cuts. During Secretary DeVos’s first budget hearing before a congressional committee, Senator Roy Blunt, a Republican from Missouri, excoriated the administration after it requested a $10 billion cut to the department’s budget. The proposal was difficult to defend, he said, adding that “the kinds of cuts proposed in this budget will not occur.”

Still, year after year, the administration makes a similar proposal. “Congress and the administration have not been synced up around the total funding number for the department,” Jim Blew, the assistant secretary of education, told reporters prior to the bill’s release. However, “we’re coming back again asking for a reduction because the administration believes that we need to reduce the amount of discretionary funding for the Education Department.”

The administration is after “fiscal discipline,” Blew added, and there are higher-priority spending needs. That is unlikely to sit well with a Congress that has already shown its willingness to roundly reject the administration’s budgets.



On Thursday President Trump met with residents of Santa Fe, Texas, including family members of students killed in the shooting at the town’s high school last month. The hour-long conversation on Houston’s Coast Guard base was closed to the press, and Trump left without giving comment, heading immediately to a $5,000-a-plate Republican fundraising luncheon at the St. Regis Hotel. The only thing that was evident was that he’d started his day off in high spirits: “We are going to have a little fun today,” he told a gaggle of reporters that morning before boarding Air Force One near Washington, D.C.  

There were two other major Trump administration developments related to school shootings within hours of the president’s Texas visit, and neither helped to clarify what policy direction, if any, the White House is taking on school shootings and gun violence. At a briefing Wednesday afternoon, White House Press Secretary Sarah Huckabee Sanders was vague in her response to a 13-year-old boy in the audience who pushed her to address “what steps the White House [is] taking to fix this issue.” As she held back tears, the press secretary emphasized how much she, a mother of three, sympathized with the boy’s fear of being killed and was determined to make schools safer; she didn’t, however, offer specifics, simply noting that the White House’s school-safety commission would soon be convening to start coming up with a game plan.

Indeed, as Trump spent the day in Texas, that commission—which was formed with the intent of “securing schools” largely in response to the February Marjory Stoneman Douglas High shooting and is being chaired by Education Secretary Betsy DeVos—was embarking on its first field visit. But it’s hard to say what the education secretary and other administration officials in attendance took away from their three or so hours at the Hanover, Maryland, elementary school known for its progressive approach to student discipline. The visit was aimed at learning more about strategies for ensuring positive and supportive campus environments in part as a means of preventing school shootings. That’s a general approach that was endorsed by the Obama Administration, and one that, as I’ve previously reported, the new commission was in part designed to review and potentially phase out.

These past few days were an opportunity for the Trump administration to elucidate how it plans to address the scourge of school-based violence that has both ravaged and roused the country. But, taken collectively, Trump’s blithe remarks and detachment from the country’s latest mass school shooting, Sanders’s refusal to offer specifics even during what was perhaps her most tender moment to date in the White House briefing room, and DeVos’s continued reticence about what she thinks will make schools safer suggest the administration might not do much in the way of substantive policy—at least not anytime soon.

In other words, this past week amounted to the latest iteration of the administration’s style-over-substance approach to school massacres. Coincidentally, that week drew to a close on the fourth annual National Gun Violence Awareness Day. The day kicked off a weekend-long campaign in which advocates across the country—wearing orange, the color hunters wear to protect themselves from gunfire—will be rallying for policy change.

Developing high-quality policy on school shootings certainly won’t be easy, and the process shouldn’t be rushed. There’s little national consensus on what should be done, and much of the research on what works best is extremely mixed. So far, the most the administration has done is backward-looking, though still important: On Thursday afternoon, for example, DeVos approved a $1 million grant for the Santa Fe school district to help it recover from the trauma caused by the shooting. In March, she set aside the same amount in recovery-support aid for the Florida school district that includes Marjory Stoneman Douglas High.

For gun-control advocates, though,Trump’s inaction is made particularly egregious by his occasional flirtation with school-safety models that are unproven at best and absurd at worst. Indeed, never has it been more obvious that existing policy solutions—like increasing the number of law-enforcement officers on campus (one of the many strategies included in Santa Fe High’s award-winning school-safety plan) or arming teachers with guns (a tactic that Trump and other Republicans popularized after Parkland)—have fallen short. For many of those advocates, the president’s casual tone—Trump repeatedly described the gunman as “wacky,” according to several news reports—makes the inaction all the more difficult to bear.



For generations, two numbers have signaled whether a student could hope to get into a top college: his or her standardized test score and his or her grade-point average.

In the past 15 years, though, these lodestars have come to mean less and less. The SAT has been redesigned twice in that time, making it difficult for admissions officers to assess, for instance, whether last year’s uptick in average scores was the result of better students or just a different test. What’s more, half of American teenagers now graduate high school with an A average, according to a recent study. With application numbers at record highs, highly selective colleges are forced to make impossible choices, assigning a fixed number of slots to a growing pool of students who, each year, are harder to differentiate using these two long-standing metrics.

Eighty percent of American colleges accept more than half of their applicants, but at the country’s most selective schools, there is something of a merit crisis: As test scores and GPAs hold less sway, admissions offices are searching for other, inevitably more subjective metrics.

Each year, the professional association representing college-admissions officers asks its members about the top factors they consider when making decisions about applications. Grades, test scores, and the strength of one’s high-school curriculum still remain at the top of that list. But other criteria are playing a larger role than they used to: Students’ “demonstrated interest” in enrolling at a particular school, as measured by their visits to campus or what they say in their application materials, among other things, is critical. In addition, admissions officers at about half of the institutions surveyed said an applicant’s “ability to pay” was of at least “some importance” in application decisions.

“You can’t go to a college fair anymore and say you have these grades and you’re in,” said Eric J. Furda, the dean of admissions at the University of Pennsylvania. While an applicant’s high-school GPA and test scores still carry considerable weight in admissions decisions at Penn, which had 40,000-plus applicants in the admissions cycle that ended this spring, those numbers are what Furda called a “snapshot” of a student’s life—grades from a few years of high school, or how one performed on a test on a particular day.

Furda encourages his admissions counselors to balance the “absolute merit” of grades and test scores with what he calls the “relative growth and trajectory” of applicants. “Our evaluation process looks at where they are right now and what can we expect from them once they come to our campus,” Furda said. Take, for example, applicants from private high schools or top public schools. “We expect them to have high test scores and grades,” he said. “That’s a given. So another way for us to think about merit for those applicants is, what did they do with that opportunity they were given? How far did they travel in their high school journey?”

Applicants will have a far harder time acting on such guidance than if securing admission were as clear-cut as getting a 1500 on the SAT and a 3.8 GPA. It was never quite that simple, but Furda noted that the admissions system has changed drastically in the past few decades: For the high-school graduating class of 1991, Penn accepted nearly half of its applicants. This year it accepted just 8 percent, a record low.

Applying to college has become much more stressful in the intervening years—and it only is becoming more so, as high test scores and GPAs become less certain indicators of acceptance. These days, applicants and their parents demand “absoluteness” in admissions, said Furda, who every April answers complaints from rejected applicants who compare their academic backgrounds to those of accepted students they know. The issue for Penn and other top colleges is that as applicants’ test scores and grades rise, the ability to distinguish among them becomes ever more difficult, if not impossible.

This challenge comes as Penn and other selective colleges are under pressure to increase their enrollment of low-income and first-generation students. Whatever changes they make to their admissions policies, particularly how they weigh test scores and grades, will surely be noted by competitors but also by less selective schools. “The admissions process is what it is because of the top colleges,” said Jon Boeckenstedt, the associate vice president for enrollment management and marketing at DePaul University. “They have the influence to change it.”

Indeed, when I told one admissions dean at an Ivy League school that I’d heard that another selective college might drop its standardized-testing requirement in the coming months, his reaction was one of relief. “That would give me an opening to follow,” he said. “We just can’t be first.”

Some colleges, however, are not waiting on their peers and instead are proactively coming up with different frameworks. “We’re not trying to find some formula that takes 11,000 applicants and lines them up from No. 1 to No. 11,000,” said Andrew B. Palumbo, the dean of admissions and financial aid at Worcester Polytechnic Institute in Massachusetts. “If that were the case, one of our students could create a computer program and put us out of a job. We are trying to find the best fit.”

Worcester, which this spring let in 42 percent of applicants, is one of the many colleges that no longer requires SAT or ACT scores, a decision in 2007 that was surprising given the school’s science and engineering focus. But Worcester puts its students through a project-based curriculum for four years, and to succeed in such an environment, Palumbo said, applicants must demonstrate that once on campus they can apply skills that “standardized tests don’t measure very well, if at all”—the ability to work in teams, communicate, and solve problems on the fly, for example.

More than 1,000 colleges nationwide have come to a similar conclusion about standardized tests, having dropped them as an admissions requirement. That number includes even some selective campuses such as George Washington, Wake Forest, and Wesleyan. There are good arguments supporting these schools’ decisions: for instance, that standardized test scores are highly correlated with family income.

Schools that minimize test scores, however, are often trading one inequitable measure of merit for another. Demonstrated interest has become a popular concept among admissions deans in recent years, but it too likely correlates with wealth—traveling for college visits isn’t free. And one of the best indicators of interest is applying early decision, a process that favors applicants who often don’t need to worry about comparing financial-aid offers from multiple schools.

That is to say, different does not necessarily mean better. Even if colleges are newly emphasizing certain measures of applicants’ excellence, there’s an uncomfortable underlying truth that remains unchanged: When schools with anywhere from several hundred to a couple thousand slots are picking from tens of thousands of applicants, a good amount of deciding who gets in is going to be arbitrary.



Teaching in the United States was once considered a career for men. Then the profession’s gender composition shifted dramatically around the mid-19th century, when the country’s public-school system was born. As schoolhouse doors opened to children of all social classes and genders, so too did the education profession. By the late 1880s, women made up a majority—63 percent—of all the country’s teachers (though men continued to make up most of the high-school teaching force until the late 1970s). Within a few decades, the choice to teach young children was solidified as an inherently “feminine” pursuit; in fact, girls who couldn’t or didn’t want to be homemakers had few other job options.

In the mid-20th century, however, cultural and political shifts prompted a surge in the number of women seeking employment in traditionally “masculine” sectors. These changes also prompted the reverse—albeit to a lesser extent: The number of men seeking classroom careers rose and has grown by 31 percent since the early 1980s.

Yet despite this, the gender distribution in the profession has strangely grown more imbalanced, according to recently released data, largely because women are still pursuing teaching at far greater rates than men. According to the study, led by the University of Pennsylvania professor Richard Ingersoll, the nation has witnessed a “slow but steady” increase in the share of K–12 educators who are women. During the 1980–81 school year, roughly two in three—67 percent—public-school teachers were women; by the 2015–16 school year, the share of women teachers had grown to more than three in four, at 76 percent. (From 1987 to 2015, the size of the teaching force increased by more than 60 percent, from about 2.5 million to about 4.5 million, according to the recent report, which helps explain why the field tipped further female despite the rising number of men in the profession.)

The trend is “odd,” Ingersoll and his co-authors—all education scholars, and most of them former classroom teachers—write in the report. Generally speaking, starting in the 1970s the country’s occupations witnessed a significant decline in gender segregation, as the number of women in the workforce soared. An index that measures how many women or men would need to change jobs to achieve equal gender distribution across occupations fell 26 percent from 1972 to 2002, when it was at its lowest point, according to a 2010 report by the Institute for Women’s Policy Research.

Ingersoll and his research team highlight the rising proportion of women who are, for example, physicians (from 10 percent in 1972 to 40 percent in 2018, according to Bureau of Labor Statistics data and federal surveys), lawyers (from 4 percent to 37 percent over the same time period), and pharmacists (13 percent to 63 percent). Other research shows that fewer female college students are seeking teaching degrees: In the late 1970s, roughly a third of the women enrolled in U.S. colleges were majoring in education; today the share has dropped to 11 percent.

What explains these contradictory trends? Much of it comes down to misunderstandings of what teaching entails and how those assumptions intersect with gender norms. Unlike in many other countries, in the United States, teaching has long been seen as a relatively low-status profession. In 2018, a survey of people in roughly three dozen countries asked respondents to rank 14 different professions—including teaching, medicine, law, social work, and website engineering—by each career’s perceived social status. On the one hand, survey participants in the United States gave teachers a middling ranking, and tended to liken them to librarians; respondents in countries such as China and Malaysia, on the other hand, put teachers in first place, analogizing them to doctors.

This cultural disregard for teaching has a gendered consequence: The status of a given career tends to correlate with the share of men in that profession—higher status equals more men, generally speaking. And that has its own consequence: Research has found that employers place less value on work done by women than on that done by men. These trends reinforce each other in perpetuity.

Within a given field, the more prestigious positions attract more men. Notably, close to half of all principals today, including two-thirds of those serving high schools, are men, as are more than three-quarters of school-district superintendents. Additionally, nine in 10 elementary-school educators are women, according to Ingersoll’s study, compared with six in 10 of their high-school counterparts. Prekindergarten in particular is heavily dominated by women, perhaps because younger kids might be dismissed as requiring little more than “Wheels on the Bus” sing-alongs.

Julio González, a 23-year-old pre-K educator at a public bilingual school on Chicago’s Lower West Side, admitted that he bought into such stereotypes when Teach for America first offered him the job a little more than a year ago, straight out of the University of Texas at Austin. “I made sure to ask people, like, ‘Is this an actual job, or am I just a glorified babysitter?’ ” he recalls. A first-generation Mexican American who dreamed of becoming a lawyer so he could advocate for low-income communities like his own, González eventually realized that teaching might be a more effective way to serve those communities. After all, an individual’s racial and gender biases tend to develop at a very young age.

Prestige is not a merely notional idea, as it tends to correlate tightly with compensation. The fact that prekindergarten classrooms have difficulty “attracting men as early-childhood teachers is hardly surprising,” Marcy Whitebook, who co-directs UC Berkeley’s Center for the Study of Child Care Employment, said in an email, given that work as a pre-K teacher “is seen as a pathway to poverty.”

Teachers overall tend to have pretty meager salaries. The ACT, which every year surveys a pool of test-takers on their career aspirations, found that among respondents who said they were “potentially” interested in a job as a K–12 teacher, as opposed to definitely interested or definitely not interested, low pay was the sticking point that made them unsure. Average teachers’ salaries have remained essentially flat since the 1990s after controlling for inflation, according to a report published last year by the nonprofit Education Resource Strategies (ERS), and grew just 7 percent in the two decades before that. Using a metric developed by MIT researchers, the ERS report found that in most states, K–12 educators’ salaries fall below the living wage. And usually, the younger the students, the lower their teacher’s pay, as a 2018 report on early-childhood educators shows.

Women might be more willing to accept teaching’s low wages because the profession is, in theory, more amenable than other careers to the needs of women. Mothers, for instance, are more likely now than ever before to desire employment, yet still tend to bear most of the child-rearing responsibilities. The school day tends to end two or so hours before that of typical American workers. A 9-to-5 workday, as Kara Voght has reported for The Atlantic, creates a challenge for parents who have to coordinate and pay for child care (or leave their kids unsupervised) during that time gap. The notion that teachers enjoy shortened work days and summers exempt from work-related duties is little more than a myth, but teachers who are parents are often at least on a schedule a little more conducive to their children’s needs.

One effect of the gender imbalance could be that younger students have fewer opportunities to interact with positive male role models. “As a black male teacher, sometimes I feel like a unicorn,” said Charles Jean-Pierre, a D.C. Public Schools art and French teacher. He said the black male teachers he had as a child of immigrants in Chicago motivated him to embrace his passion for art and become a teacher himself. “I think it’s important for students to experience joy, nurturing, and compassion from men … Male teachers embody hope and love for many students who do not see that on a daily basis [from men] in their homes.”

But men who do this work might confront wariness about their abilities, or suspicions about their intentions for working with young children. Ingersoll cited research published in one 1993 book about men in traditionally “feminine” occupations finding that among elementary-school teachers, men who were perceived as too “male” were dismissed as incapable of working with young children, while men who weren’t “male enough” were suspected of being child molesters. “You have to sort of work it out so you’re the right amount of maleness,” Ingersoll told me. “It’s tiresome, and so a lot of the male elementary teachers say after a while, ‘This is just too draining.’ ” Both González and Jean-Pierre said that they’re always aware of the latter concern, ensuring that another adult is always in the classroom and forging strong relationships with parents.

But the fact that male teachers have to consider this at all traces back to the entrenched stereotypes that underpin teaching’s gender imbalance. Given that low pay—and accompanying low social standing—is both a result of and driving force behind men’s underrepresentation in the profession, it stands to reason that salary hikes could help stem the imbalance. A pay bump could in theory spur a virtuous cycle in which greater representation of men in the profession could slowly shift perception, which Ingersoll in 2016 suggested to The New York Times could then beget even greater representation.

That said, some research suggests that pay hikes will only go so far in boosting the share of male teachers—attitudes about caregiving will need to change, too. “Two years ago, if someone had told me that the most important role you can play as a teacher is to be a caregiver, I probably would’ve said, ‘Well, that’s not what I’m signing up for,’ ” González acknowledged.

Today he—echoing Jean-Pierre—embraces the fact that caregiving is, indeed, integral to his responsibility as a teacher, and that it’s just as valuable as all the other parts of his job.



It doesn’t take much to run a survey on the website Pollfish. An email address, a title for the survey, a couple of target-demographic details, and $400 dollars—which buys 400 responses—is all that’s needed. These are the types of surveys that produced the sometimes jarring findings published by the Student Loan Report, a website that was founded in 2016 as “a source for news on the student loan industry, financial aid, and scholarships.”

Based in part on those findings, the website’s founder, Drew Cloud, built a public profile. He wrote columns in local newspapers advising those who had taken out student loans on how to manage their debt. The surveys the site conducted were cited in major news outlets, such as The Washington Post, Fortune, and CNBC—so too was Cloud himself. Mic linked to the site in an article about student loan myths. It all seemed pretty normal, except for one thing: In a digital-age twist, Cloud wasn’t real.

According to a report published earlier this week by The Chronicle of Higher Education, Cloud is a pseudonym that a collection of people who founded LendEDU—a platform that helps borrowers apply to refinance their students loans—used to write posts on, and communicate with journalists on behalf of, Student Loan Report. Even as Cloud was cited in news stories, Student Loan Report never disclosed that it was run by LendEDU. (Had LendEDU offered any one of its real staffers as a source instead of Cloud, the connection between it and Student Loan Report would have likely been discovered.)

What did LendEDU, which purports to have been created to “offer transparency in the student-loan market,” have to gain from this set-up?  The company makes money when people use it to apply for financial products, or are approved for them, including refinancing their student loans, so it makes sense that it would be to the company’s advantage to promote the idea in the media that refinancing is the “best thing” for certain people. This isn't an inherently troubling message—for many people, refinancing is indeed the right move—but the promotional approach was less than forthcoming.

Most companies of course want to get their promotional messages across to the public, but the student-loan industry in particular is one that has a large—and anxious—ready-made audience, many members of which regularly turn to media reports for reliable, objective advice. Oftentimes, people are unaware of their options, including plans like income-driven repayment, which adjusts one’s loan payments based on how much money one makes. The opaque process of managing student debt can be confusing, and LendEDU’s strategy seized upon that confusion to encourage people to consider courses of action, including refinancing, that would make the company money.

The company’s message, delivered via Cloud, was crafted to reassure readers. “The statistics are grim. There is $1.3 trillion in outstanding student-loan debt in the United States, held by 44 million people,” Cloud wrote in a column. But there was hope: “If you’re stuck paying a high interest rate,” he wrote, “you should consider refinancing your student loans.” In a separate column, he wrote, “Debt is a four letter word, and one that can leave you feeling anguished and frustrated,” before again suggesting refinancing to “overcome the challenge of paying these loans.”

Cloud’s stint as a real person ended on Tuesday, when The Chronicle of Higher Education reported that it had tried to speak with him about a suspect survey indicating that some college students were using student-loan money to buy bitcoin. Chris Quintana, a reporter at the Chronicle (and my former colleague) was skeptical of the findings and reached out to Cloud, who responded a day after the news outlet published a story questioning the findings, that he had been traveling and unable to check his email. He signed the response, “—best, Drew.” Quintana, still skeptical, offered to meet Cloud in person and also inquired as to where Cloud had gone to college. His inquiry was met with silence.

At that point, Quintana told me when I interviewed him about the ordeal, the idea that Cloud was fake still seemed absurd. It didn’t seem likely to him that he was a fabrication. After all, there was such an elaborate persona: Cloud had been a staple of education and finance reporters’ inboxes—follow-up after follow-up after follow-up—over the past year. One reporter shared a string of unread emails from Cloud, all pushing various Student Loan Report studies. But if a reporter did respond to a message from Cloud, Cloud seems never to have gotten on the phone. “Drew strictly communicated through email,” Nate Matherson, who runs LendEDU, told me in an e-mail. Still, he always had a strong statement on the results of a survey—things like, “Living on a tight budget, one would think students would spend that money on groceries, rent or school supplies rather than bitcoin and ethereum.” And at least a handful of colleges touted the findings of Cloud and Student Loan Report in press releases.

A day after the story broke, Matherson issued an apology. “We never disclosed that ‘Drew Cloud’ was a pen name that represented a group of us writing these posts. I really regret that,” he wrote in a post that covered the top half of the Student Loan Report’s website. He added that all future posts on the site would use the author’s real name, and that the posts written under Cloud’s name would be retroactively relabeled.

What the apology does not mention, however, is the misrepresentation of the persona to media outlets and the recommendation of student-loan refinancing—LendEDU’s raison d’etre—in articles and interviews with a handful of personal-finance blogs. Perhaps this is the way to make sense of the saga of Drew Cloud: It is a perfectly understandable—if still deeply strange and problematic—occurrence in an industry where customers crave reliable advice, but are all too often unable to distinguish it from all the other information out there.



In a highly anticipated move that for key organizers has been years in the making, more than 30,000 educators on Monday kicked off a strike that’s put regular K–12 classes on hiatus in the country’s second-largest public-school district. A whopping 98 percent of L.A. teachers, who because of stalled negotiations with the district have been working without a contract for more than a year, voted to authorize the strike. They are demanding smaller class sizes and more funding for support staff such as counselors and nurses. They’re also calling for higher pay, though that is less of a sticking point now that the district and teachers’ union are all but in agreement on this front, with the former offering raises that are just 0.5 percent lower than the 6 percent hikes educators are demanding.

Rodolfo Dueñas, an L.A. native and public-school teacher who is picketing, describes this burgeoning movement as a natural next step for the many Latinos like him whose activism can be traced back to the mid-1990s, when thousands of Latino teens staged a school walkout in opposition to an anti-immigrant state-ballot initiative known as Proposition 187. For many like Dueñas in the “187 Generation,” those experiences eventually drove them into teaching. And Dueñas’s generation has been following in the footsteps of the Latino education activists who came before them, during the 1968 walkouts known by some as the Mexican Student Movement.

The L.A. strike is the latest teacher uprising in a string of walkouts across the country over the past year. Strikes took place in Republican strongholds including West Virginia, Kentucky, Oklahoma, and Arizona last spring, all of them generally calling for increased funding and improved school conditions on top of better pay and benefits; smaller-scale walkouts also took place in Colorado and, just last month, Chicago, when teachers at a predominantly Latino charter-school network went on strike to demand things like smaller class sizes and stronger support for immigrant children. While the L.A. strike, which is United Teachers Los Angeles’s first strike in almost 30 years, is the latest installment of a trend driven by exasperated educators, various factors make it unique.

One distinction: the demographic makeup of Los Angeles Unified School District (LAUSD)’s teachers compared with the district’s student body. In Los Angeles, 73 percent of students are Latino and another 15 percent or so are other racial minorities. Latino educators account for 43 percent of LAUSD’s teaching force this school year, district data show, up from 41 percent the year prior, while their white counterparts make up 34 percent. (Black and non-Filipino Asian teachers each account for about 10 percent, while 3 percent of educators are Filipino and just under 1 percent are either Native American or Pacific Islander.)

These statistics are striking when compared with the national landscape: Of the millions of educators who teach in the country’s public schools—where more than half of the nearly 51 million students are children of color—a whopping 80 percent are white. And Los Angeles stands out even when compared with nearby districts such as San Diego Unified, where close to half of all students are Latino compared with only 18 percent of their teachers. Across California, a recent EdSource analysis found, the rate of Latino public-school teachers is half what it is in LAUSD.

Numerous Latino teachers repeatedly told me that a sense of solidarity with their students is what’s driving them to the picket lines—a profoundly personal connection to those children, and a fear that current school conditions are not serving them.

The sprawling school district is the United States’ second largest, enrolling nearly 600,000 K–12 students on close to 1,000 campuses that stretch across the metropolis and dozens of surrounding municipalities. As is the case with other large urban districts, the vast majority of LAUSD’s children are low-income, with more than eight in 10 of them relying on subsidized meals. The handful of LAUSD teachers I interviewed told me how much they relate to their students’ struggles as immigrants who lack documentation, or as impoverished kids who frequently find themselves homeless, or as traumatized children whose lives have been disrupted by gang violence. Rodolfo Dueñas, for one, lost both his brother and sister to gang violence when he was young. It’s impossible to say exactly how many LAUSD teachers relate to students’ lived experiences in this way, and how Los Angeles compares with other urban school districts in this regard, because such data don’t exist. However, both the state and district are actively engaged in diversity-focused teacher-recruitment initiatives—and LAUSD even offers its own accredited teacher-preparation program targeted at people who already live in the community in which they’d teach.

Roxana Dueñas, a 34-year-old ethnic-studies teacher at a high school in Eastside L.A.’s Boyle Heights neighborhood, says her own background as an LAUSD student whose working-class parents immigrated from Mexico was a driving force behind her decision to pursue the profession. “I see myself in my students in both the literal and metaphorical sense,” she says, noting that her sister and cousins attend the school at which she teaches. (Roxana Dueñas and Rodolfo Dueñas are not related.)

This kind of synergy is rare in public education. Despite the growing emphasis in recent decades on racial inequality in the country’s school system, the share of educators of color has hardly budged, growing just a few percentage points over the past three decades, according to an analysis by the Albert Shanker Institute. Research shows that the problem isn’t uneven recruitment of educators but rather uneven attrition: Teachers of color leave the profession at a higher rate than their white counterparts—a trend that’s particularly pronounced among black educators, whose share of the teaching force has declined. According to the Shanker Institute report, teachers of color tend to be concentrated in urban schools serving high-poverty, minority communities, where the working conditions—often, a limited say in decision making and a lack of professional autonomy in the classroom—eventually burn them out. This is one force driving the teacher shortages seen in parts of the country.

The Shanker Institute report highlights Los Angeles as an outlier, because so many of its teachers are Latino. Following nine cities—including Chicago, New York, and Washington, D.C.—over a decade, the report found that despite significant upticks in the Latino-student population, the share of Latino educators overall grew modestly at best but generally remained stable. Los Angeles was the only city that saw a sizable uptick in the share of Latino educators. In fact, turnover rates were lowest for LAUSD’s Latino teachers—with three in 10 of them leaving the profession after three years, compared with four in 10 of their white, black, and Asian counterparts.

But Monday’s walkout demonstrates that LAUSD may not keep up these retention rates for long. Not only have LAUSD’s teachers been working without a contract for more than a year, they argue that they’ve also struggled with a decade of budget cuts that have chipped away at school resources and made it nearly impossible to serve their students adequately. Some classes now have as many as 46 students, surpassing the 39-student limit the teachers’ previous contract stipulated. Meanwhile, many LAUSD schools lack full-time librarians and nurses.

“You’re working in these conditions committed to the students because you get satisfaction knowing you’re making a difference,” says Martha Infante Thorpe, a 48-year-old social-studies teacher who’s joining the strike. Infante Thorpe taught at a high school in South Central L.A. for more than two decades but recently moved and now teaches at a school in a middle-class community, a transition that’s exposed her to just how uneven public-school resources can be. “Then you come to this point when you realize that people are taking advantage of your kind and altruistic nature.”

Of course, while the teachers’ union argues that it is striking to improve conditions for the students, the walkout is leaving many vulnerable kids without a reliable place to go during the day. Schools remain open, serving meals to eligible children and offering before- and after-school programs, and relying on volunteers, substitute teachers, and non-district education employees to offer some semblance of instruction and extracurricular support to students who do show up. But it’s unclear how many will, and either way, the strike is likely creating immense stress for hundreds of thousands of low-income LAUSD parents, many of whom don’t speak English, as they scramble to figure out what child-care options are available in a sprawling city where traffic congestion is rampant and public transportation can be unreliable. The kids, also, could be missing out on valuable learning opportunities that teachers may not have time to revisit once they return to the classrooms; the ad hoc classes being offered to the children who do attend can only go so far.

Some observers challenge the premise that race—and, namely, Latino identity—is a key force behind the strike’s narrative. Critics such as Jeanne Allen, who founded and oversees the Center for Education Reform, which advocates for charter schools, chalks the walkout up to the latest desperate attempt by a teachers’ union to retain its control over a school system amid declining public support for collective bargaining and in the aftermath of a recent Supreme Court decision that limits unions’ fundraising abilities. Janelle Erickson, a spokeswoman for LAUSD, pointed to United Teachers Los Angeles President Alex Caputo-Pearl as the mastermind behind the uprising, citing a speech he made back in 2016 to suggest it’s been more than two years in the making. That most of L.A.’s teachers are people of color, many of whom relate to the students they teach, is noteworthy but coincidental, the thinking goes. Caputo-Pearl’s campaign against charter schools and other forms of “privatization” in education, Erickson argued in an email, is the driving force behind this walkout.

None of the classroom teachers whom I spoke with even mentioned Caputo-Pearl, however, and few of them talked about charter schools. Instead, when asked how their own background may have informed their take on the strike, almost every LAUSD teacher I interviewed used the word “personal.” For many if not most of the middle-aged Latino LAUSD educators today, teaching emerged as one of the few entry points into the middle class, according to Maria Brenes, the executive director of InnerCity Struggle, a nonprofit aimed at enhancing the lives of youth in Eastside L.A. The cost of living in Los Angeles has soared in recent years, leaving many middle-class families, let alone those who rely on a teachers’ salary, unable to afford to buy a home.

But several striking teachers told me that better pay is a relatively low priority for them. Rodolfo Dueñas, for example, says he’s fighting to ensure that the aloof, uninspiring public schooling he received doesn’t repeat itself.

As a teacher in LAUSD today, “it’s almost like you’re looking at your little brother, your little sister, and you’re reliving the traumas of education in the past,” he says. “And you’re like, ‘Dang! Some of these things are still happening.’ It’s almost like you’re fighting for something you wish you could’ve fought for when you were in school.” He doesn’t recall his school doing anything to support him when his siblings were killed; he says no one asked him if he wanted to talk, let alone offered counseling. While LAUSD today offers much more mental-health support to kids than it did in Dueñas’s days, it’s far from enough, he argues. Absent a counselor at school, “they at least have someone like me who they can connect with,” he says, “but I’m not a professional, I’m not trained. I’m still trying to deal with my own trauma.”

Some teachers told me that they’re striking to set an example for their students, so students can recognize their own agency to change things. By striking, Roxana Dueñas says she’s modeling for her students the values that she’d wished she’d learned in school. “I think even our young people have learned to accept and normalize your condition,” she says. Her mission is to inspire her students to question the status quo, to ask: “‘Why is this happening? Why should we accept it?’”



The idea is clear, simple, and generally agreed upon: Colleges need to do more when it comes to enrolling and graduating low-income students. If college degrees are “the great equalizer”—though some research has disputed that characterization—then expanding access to those degrees will help make society more equal. Are any colleges succeeding in doing that?

A new report from Third Way, a center-left think tank, tries to answer that question—and the results for many colleges are not pretty. One of the most common ways to understand how colleges are serving low-income students is by looking at how well they are helping students who are eligible to receive Pell Grants, or need-based federal grants for low-income students. Three-quarters of Pell Grant recipients come from families that make less than $40,000 a year.

The report finds that fewer than half of first-time, full-time Pell students (meaning students who are attending college for the first time, not transfer or return students, who are a slightly different population) graduate at the institution they started at within six years. By contrast, those who do not receive a Pell Grant are doing much better, and nationally are 18 percent more likely to graduate within that time period. This report represents some of the first significant analysis done on Pell-recipient graduation rates, as the federal government had not made these data available until last fall.

But the report found that one system stands out: Schools in the University of California system are doing significantly better than other four-year colleges and universities in the country when it comes to enrolling low-income students and seeing them across the finish line. Of the public and private nonprofit schools with a higher-than-average Pell-awardee enrollment rate (the schools this study examined), the UCs occupy five of the top 10 slots in terms of graduating students. Among only public institutions, they are the top seven.

“Every single time we do these outcome measures, the UC system stands out,” Lanae Erickson Hatalsky, who leads the social policy and politics program at Third Way, told me. A 2016 report from Third Way on outcomes for students at public colleges similarly found that colleges in the UC system fared better than their peers.

Why is that? The state money available for higher education makes a big difference—and the UCs have remained among the better-funded colleges in the country, as institutions in other states have seen sharp cuts.  They devote a good portion of that funding to getting low-income students onto campus in the first place. In recent years, colleges have placed increased emphasis on outreach to low-income communities to diversify the socioeconomic makeup of their student body, including sending recruiters to schools they haven’t traditionally frequented and helping with college counseling.

The UCs do those things, and a bit more. For starters, they provide academic preparation for high-school students at underserved schools to ensure that they meet the requirements to attend the colleges, and hold academic-enrichment programs in the summer. When students are seniors, the UCs help them with their applications and financial aid. That early outreach is crucial for students, Yvette Gullatt, a vice provost of the university system, told me, because it allows them to build a relationship with the university—perhaps making it more likely that they will apply. More than 100,000 students are enrolled in these programs, according to Gullatt.

Representatives from the UCs also go to local high schools and churches to demystify college, which can be an important step. Applying for college can be daunting, especially if one is not from a wealthy family—the sticker price alone is enough to dissuade many students from applying—or if one is the first in the family to attempt to get a postsecondary education. “We explain to them that a family with an income of $80,000 or below is not going to pay tuition at the University of California,” Gullatt said. “That often unlocks the door for families who realize that UC is within their reach financially as well as academically.”

Just as important as getting students to campus, however, is supporting them while they’re there. As Janet Napolitano, the system’s chancellor, told me, “A student needs to have access to whatever support they need in order to help them succeed.” The idea isn’t novel, but when executed properly, the results are clear. According to the Third Way report, the University of California at Los Angeles has an 88 percent Pell-student graduation rate; the University of California at San Diego is at 85 percent, as is the University of California at Irvine. Those numbers are roughly on par with the graduation rates for non-Pell recipients.

Similarly, last year, The New York Times reported that the UCs were among the top colleges in propelling students to higher income brackets. According to data released by the Equal Opportunity Project, UCLA enrolled the most low- and middle-income students among elite colleges. And the University of California at Irvine was fourth among colleges that propelled students from the bottom fifth of the income distribution to the top three-fifths.

Though the UCs are making a concerted effort to enroll and retain low-income students, it is also worth noting that the schools’ efforts are buoyed by a healthy state economy. A recent paper found that labor markets are also a contributing factor in mobility.

“We know that it is possible to succeed with Pell students, which is why our policies must find ways to reward and scale up programs that have proven results with this population,” the report says. But several states have not had such success. In fact, according to Third Way, some states—including Wyoming, Colorado, Mississippi, and Lousiana—have few, if any, institutions that both enroll a high share of Pell students and serve them well. And as the trend of state disinvestment in higher education continues, there are fewer resources for ambitious efforts.



My best friend in kindergarten, Eddie Linton, did not live in one of the spacious houses on the hill in the Boston suburb where I grew up in the 1980s and 1990s, Belmont, which is best known for its stellar schools and abundance of Harvard professors. Eddie, who is black, lived instead in a brownstone in the South End of Boston, alongside his two American-born sisters, plus grandparents and aunts and godparents from Barbados, the country where his parents were born.

Every morning, Eddie would get up at 6 a.m. and get on a yellow school bus that took him and dozens of other black kids from Boston to Belmont. He’d spend his school day in Belmont, surrounded by kids who did live in those spacious mansions, and then, at the end of the day, he’d get on the bus and go home. “It was a long day, but my parents wanted me to have exposure to a better education system,” he told me recently. While he was gazing out the bus window, watching the scenery change from suburban to urban, wealthy to middle- and low-income, thousands of other black kids across Boston were sitting on similar buses that took them to and from schools in other predominantly white suburbs, such as Newton, Sharon, and Wellesley, areas that white families had embraced to escape the city in the 1960s and 1970s.

Eddie was a participant in the Metropolitan Council for Educational Opportunity program, one of the longest-running voluntary school-integration programs in the country. Started in 1966, METCO has bused thousands of students in Massachusetts—at least 200 in the first decade to 3,000 since the 1970s—from predominantly black and Latino neighborhoods in the city of Boston and later Springfield to white, wealthy neighborhoods in the suburbs.

The original idea behind the program was to help black kids access better educational opportunities than those available in Boston, and to give white students in suburbia the opportunity to “share a learning experience with students with differing social, economic, and racial backgrounds,” as program backers put it at the time. Its founders assumed that it wouldn’t be necessary for long—soon, they hoped, housing segregation would dissipate and schools would be places where black and white students were educated alongside one another, without any busing necessary.

I don’t know why Eddie and I became such fast friends. Perhaps I recognized in Eddie, with his wiry frame, oversize glasses, and ears that stuck out a little, a fellow nerd like me. Teachers said we were inseparable and joked that we would someday get married. I remember venturing into Boston to see the rerelease of E.T. in a theater with his family, but the movie proved so terrifying to me that I demanded we leave, and his mother had to wait with me outside the theater until the movie ended.

I spent time in his Boston home, too, though I don’t remember much aside from a linoleum kitchen floor and the smells of home-cooked food. Eddie says my father wrapped a multicolored afghan around him one winter evening on our couch, and he remembers feeling warmed by the evidence that someone who looked different from him cared about him.

Today, Eddie lives in France, where he’s married to a French woman and works as an account manager for a French airline. Eddie’s experiences with “code-switching” as a kid—moving back and forth between his Barbadian family and neighborhood friends in Boston and the WASPy suburb of Belmont—prepared him for a life and career in which he needs to easily transition among languages and cultures, he told me. Going to school in Belmont, where kids would casually talk about skiing in the Rockies over winter break or traveling to Europe for the summer with their family, piqued his interest in travel.

His parents already expected him to go to college, but being surrounded by kids in Belmont, where college was a given for just about everyone, made that path seem readily accessible. “I was exposed to a lifestyle that altered my perspective of how things should be,” he told me. Many kids who grew up in his Boston neighborhood didn’t go to college; among other reasons, they saw it as an expensive way to delay making a living.

METCO is a source of pride for many in Boston, a city known for its violent opposition to mandatory school busing in the 1970s. Famous alumni of the program include Marilyn Mosby, the top prosecutor in Baltimore, and Audie Cornish, the co-host of All Things Considered on NPR. Many METCO kids excel in the well-funded suburban schools: About 98 percent of METCO kids graduate from high school, compared with somewhere between 60 to 70 percent of students who attend schools in Boston, and nine in 10 say they plan to go on to higher education, compared with 59 percent in Boston, according to state data.

METCO is especially important today, as the political appetite for integration—never great—seems to be waning. The Trump administration discontinued a $12 million Obama-era grant to help local school districts boost diversity, and is scaling back federal efforts to enforce fair-housing laws. It is throwing support behind charter schools, which teachers’ unions have argued are a way to undermine integration. Trump’s rhetoric has licensed public displays of racism, and the past year has surfaced politicians trying to suppress the black vote in Georgia, showing up in yearbook photos in blackface and Ku Klux Klan hoods, and warning that their black opponents would “monkey it up” if elected. Black Americans still face discrimination when applying for jobs, buying homes, and seeking medical care.

Massachusetts could be an example, a state pushing back against integration’s demise; it was, after all, where the first law prohibiting segregated schools was passed, in 1855. When METCO was established, suburban districts volunteered seats in their under-enrolled schools; in 1964, white families in Boston participated in a “Freedom Stay-Out,” boycotting segregated schools and speaking publicly about the need for integration. White residents living in wealthy suburbs wrote letters to the mayor of Boston asking the city to end “de facto segregation” of schools and spend more money on inner-city schools.

“Educational leaders in suburban communities both wanted to do something that would benefit black kids in urban neighborhoods, but also, they understood that going to an all-white school was not providing a good education to students,” says Susan Eaton, a professor at Brandeis University’s Heller School for Social Policy and the author of The Other Boston Busing Story, about METCO. This wasn’t just a Massachusetts phenomenon: In New York, “white liberals” picketed in support of school integration in Brooklyn in 1964.

Of course, Massachusetts also had its own significant racial problems, which often manifested around questions of school policy. In 1974, the Boston School Committee was found to have taken actions that intentionally segregated schools in the area. Violent opposition to the court-ordered school desegregation that followed earned Boston the reputation as one of the most racist cities in the country, a reputation that has not died. Racism was most prominent in the city, but it existed in the suburbs, too; letters to local newspapers about METCO in the program’s initial decades indicate that readers were worried about the “raping” of their school districts, city children bringing “inner-city diseases,” and their money being spent on other people’s kids.

It may not be surprising, then, that Massachusetts has turned into another example of a place that once seemed poised to integrate and is now just as segregated as it was decades ago. The housing integration that METCO’s founders thought would soon make the program unnecessary has not come to pass. White, affluent families in Boston self-segregate in wealthy suburbs, and then thwart attempts to build affordable housing developments nearby, despite state laws designed to prevent them from doing so. The median price of a single-family home in Belmont in 2016 was more than $1 million, nearly double the price of a home in Boston. Middlesex County, where some of the Boston area’s wealthiest suburbs are located, is 78 percent white and 5 percent black, according to census data, while Suffolk County, which includes the city of Boston, is 56 percent white and 21 percent black.

In fact, rather than fading away, school segregation has become more intense in recent years, in part because of this residential segregation. About 76 percent of the 54,000 students enrolled in the Boston public-school system are black or Latino.

Segregation is growing within the school district, too, according to a Boston Globe analysis published last year. Sixty percent of Boston public schools are “intensely segregated,” up from 42 percent two decades ago, the analysis found. Students of color fill at least 90 percent of the seats in almost two-thirds of all schools, meaning the white students who do attend Boston public schools are concentrated into just a few places.

By contrast, METCO’s receiving districts are still extremely white. Just  3 percent of students enrolled in Belmont public schools are black, while 85 percent are white or Asian. Public schools in Lexington, Concord, and Wellesley are each about 4 percent black, and Newton is 4.7 percent black, according to state data. (These numbers include METCO students.)

Rather than trying to address this segregation head-on, though, Massachusetts, like many other states, has instead allowed it to persist. METCO is one of the only existing efforts to desegregate Massachusetts schools, and it is simply not up to the task, having stayed exactly the same size even as the suburban school districts that accept METCO students have grown in population. Belmont has 32 percent more students than it did in the 1997–1998 school year, and Lexington, another predominantly white suburb, has 30 percent more students. These numbers are typical of most METCO receiving districts. But there are still exactly the same number of METCO students as there were when the districts were much smaller.

This means that the ratio of METCO students to non-METCO students has fallen. Students get into METCO only if there are seats available, and they’re accepted in the order in which they sign up for the program; parents put their children on the wait list when they are born to get a better shot at admission. (METCO recently proposed a new admissions process, replacing the first-come, first-served system with a lottery, causing deep anxiety for parents who had signed their children up years ago.) The current wait list has 8,000 students on it.

Part of the problem is financial: Funding for the program has stagnated, while the costs of running it have risen. METCO is actually receiving less money from the state than it did in 2007 and 2008. The budget for the 2019 fiscal year provided METCO with 2 percent more funding than it had in 2009, but that equates to less money if you account for inflation. Every year, METCO advocates go to the Massachusetts statehouse and ask for more money for the program. It’s always a challenge, Jay Kaufman, a recently retired Massachusetts state representative from Lexington, who was the head of the Joint Committee on Revenue, told me. Kaufman, who has long been one of METCO’s biggest supporters, has calculated that the program has the same funding level as it did 24 years ago when he was first elected. “It’s kind of sobering to realize that for all the fighting and all the victories, we’re just treading water,” he said.

Much of the problem has to do with the way public schools in America are organized, which is to say largely by geography. As a result, because America’s housing is so racially segregated, so are its schools. There’s little enthusiasm among politicians or voters to overhaul that system.

Cities that have tried to upend it have found little success: The Supreme Court has, in recent years, limited the degree to which public schools can seek to increase racial integration through vouchers or transfers. Places such as the larger Louisville metropolitan area, which tried to preserve a commitment to regional school integration, have faced constant court challenges.

“The resegregation of education is a nationwide phenomenon, because of where people can afford to live and the connection between income and race,” says Lisa Guisbond, the executive director of Citizens for Public Schools, a Massachusetts education-advocacy group. Boston is one of the few places in the country that still has a voluntary busing program; many other districts have phased out such efforts. METCO and programs like it are among the few tools left to desegregate schools in America—and they aren’t doing nearly enough.

METCO officially began in September of 1966, when 220 black students took buses from Boston to classrooms in seven suburban school districts, including Brookline, Lexington, Newton, and Wellesley. As the buses wended through the suburbs, the students gawked at the green grass and manicured trees, according to A History of METCO, a pamphlet by Ruth Batson and Robert Hayden, two of the program’s early leaders.

The program was created as a work-around. The Massachusetts legislature had passed a law in 1965 that made the segregation of public schools illegal, but the Boston School Committee, the governing body of Boston’s public schools, consistently refused to integrate schools, so the state began allowing students living in highly segregated districts to attend schools outside the districts where they lived. Parents were told that METCO would probably go on for three years or so, until Boston schools had straightened out their integration attempts, according to Batson and Hayden.

From the beginning, it was the state, not the receiving districts, that put up much of the money for the program. A bill passed in 1966 mandated that the state provide financial assistance to any town adopting a plan to address racial imbalance in schools, according to Eaton, the Brandeis professor. The program succeeded, at first, because “it was relatively small, districts got money along with the students, and [the receiving students] didn’t really have to have any significant financial or personal hardship,” Matthew Delmont, a history professor at Arizona State University and the author of Why Busing Failed: Race, Media, and the National Resistance to School Desegregation, told me.

Today, many districts still don’t have to put up much extra money to bring METCO to their schools. In some districts, the presence of METCO students brings in more money from the state than is spent on the program, according to Roger Hatch, who recently retired after working as the administrator of school finance for the Massachusetts Department of Elementary and Secondary Education.

On average, the state provides a $4,147-per-student stipend to the receiving district. Districts spend anywhere from $10,000 to $20,000 per pupil on education, but METCO brings in other money too. Some districts receive about $12,000 per student in aid through Chapter 70, a Massachusetts program that seeks to remedy discrepancies between rich and poor districts, Hatch told me. This can mean that the presence of METCO students brings in more money than the district spends on those students. “You could say they’re more than breaking even on the program,” Hatch said.

(Some districts do spend more on METCO from their own budgets than they receive from the state. It can be hard to figure out which ones take in more than they spend. Belmont, for instance, received $9 million in Chapter 70 aid for 2019; its total school budget was about $69 million. When I asked the Belmont school district whether it spent town money on METCO, the superintendent’s office told me that the METCO program is totally funded by the state, and that no part of the town’s general-fund budget goes to the program.)

Some of the funding originally given to districts that accepted METCO students has been phased out over the years. Funding from the state that used to be distributed to districts with state-approved racial-balance plans was eliminated in 2001, according to Eaton. The state also used to pay for 90 percent of the cost of building or expanding schools (as opposed to the 75 percent it usually provides) if that construction was for the purpose of reducing racial imbalance.

Today, the committee that once gave out those incentives appears to have different priorities in mind, according to Eaton: Recent incentives have been available for districts trying to improve energy efficiency, but not for integration efforts. Districts have to rely more on taxpayers for new construction; last year, Belmont voters were asked to approve a ballot initiative that raised real-estate taxes in order to fund the construction of a new high school. The Foundation for Belmont Education raises hundreds of thousands of dollars annually for the Belmont Public School system; it has given about $225,000 a year over the past decade to pay for books, professional development, and enrichment programs, among other things, Chris Kochem, the foundation administrator, told me.

Sometimes METCO has become a scapegoat for taxpayers balking at new taxes. “It is pathetic that state law forbids Belmont property owners from having any say whatsoever as to the propriety of paying to educate young people who do not live in Belmont and who spend hours every day just getting here,” one Belmont resident, Tony Oberdorfer, wrote in a 2013 letter to the Belmont Citizen-Herald as the town considered raising taxes to build new schools.

Over time, as the amount of state money going to address racial imbalance has shrunk, METCO has had a hard time getting more funding for the program. “Everybody loves the program, they think it’s needed, they think it’s doing great things, they think it should be expanded,” METCO’s chief executive, Milly Arbaje-Thomas, told me. “But they’re not willing to give up their [anti-] substance-abuse money or whatever thing they’re fighting for that they really care about.”

Massachusetts schools are already underfunded by about $1 billion, according to the Massachusetts Budget and Policy Center, a left-leaning think tank, and the state hasn’t been able to figure out a way to bring in more cash. It has a flat income tax, and five previous efforts to get voters to amend the state constitution and change this have failed. The flat income tax hamstrings liberal legislators who want to raise taxes on the rich, since raising taxes on the rich will also raise them on poor and middle-income people. Kaufman, the former legislator, had advocated for a “millionaires’ tax” that would have levied an additional 4 percent tax on annual income earners of more than $1 million, but the Massachusetts Supreme Court barred the proposal from the November ballot.

Asking districts to put up their own money, or to open up a lot more seats for METCO students, is probably a nonstarter. When a town faces a tight budget, the METCO program is often one of the first things on the chopping block. Residents assume that since METCO adds additional students to classrooms, it costs them money, not realizing that their town gets state money for participating in the program, according to Jamie Gass, an education expert at the Pioneer Institute, a free-market think tank.

Asking towns to pay to educate the kids of people who live elsewhere has not proved popular in the past. When in 1993 the then-president of the Massachusetts state Senate, William M. Bulger, pushed a school-choice plan that would have allowed students in Boston to attend any public school anywhere in the state, Belmont and other towns objected to the idea, arguing that it would take money away from city public schools, since funding would have followed the students. Asking suburban parents to pay even higher taxes so that more students from elsewhere can attend already overcrowded schools would be a tough sell. “To actually produce more integrated outcomes would require a different reallocation of resources—it would require people to give up something among white families, which is always a difficult proposition,” Delmont told me. “Communities haven’t indicated they’re willing to pay up with local money to expand the program.”

As METCO funding has remained more or less stagnant, new obstacles have emerged for students who participate in the state’s biggest attempt at integration. Districts choose how to spend their METCO money, and, in the face of growing enrollments and limited funding, many are cutting the services that made life easier for METCO kids.

Belmont, for instance, used to have a bus that took students home from the high school; now kids have to take public transportation, which for many of them means two buses and two subway rides each way, each trip sometimes taking as long as two hours. Some districts have reduced the number of late buses, which enable METCO students to play sports or participate in school plays or other arts activities—in one district, a boy had to leave a basketball game halfway through because the last METCO bus was leaving, Claire Jones, the METCO director for Sharon, another suburb, told me. Because districts decide whether or not they have seats available, students will sometimes be told they’ve been admitted to the program and will go on a tour of the new school district, only to be told that the school has decided space wasn’t available after all, Colin Stokes, a METCO spokesperson, told me. “We tell people not to count on METCO until you’ve gotten on the bus,” he said.

As the suburban districts have grown in number of pupils, they are struggling to fit their current students in outdated school buildings, and can’t take on as many outside kids. The crowded state of many suburban schools is a contrast to the early days of METCO, in which those schools were under-enrolled. Today, METCO students make up 2 percent of the Belmont school district’s student body, down from about 3.5 percent in 1997. Some districts, including Belmont, don’t accept METCO students in some early grades if the classrooms are too full. According to a Belmont-district spokesperson, in 2017, because classrooms were so crowded, the district’s first-grade classes only had one METCO student. The district’s ninth-grade classes, by contrast, had 11 METCO students, many of whom had just entered the program.

That means many METCO students in Belmont and elsewhere start attending a white, suburban school in middle or high school, when kids already have hard-and-fast cliques. “My freshman year was very, very hard,” Lisbeth Quintin, a student from Dorchester who started attending Belmont High School through METCO her freshman year and who graduated in June, told me. She’d go home and cry because the academics were so challenging—she had to drop two honors classes—and she found the commute, two hours each way, grueling, she said. Eddie’s experience was different. He told me that when his mother first put him on the big yellow school bus as a kindergartener, he was confused, but didn’t know anything different, and so he soon came to accept it. “I think we became accustomed to doing it at such a young age [and] it just became standard,” he said.

That said, being a METCO participant has never been easy. Anthony Lumley, who is now 54, started attending Belmont public schools through METCO in 1970. When Lumley’s bus pulled up to the high school on the first day, carrying the first class of METCO kids to attend Belmont High, someone had spray-painted “Niggers Go Home” on the pavement. The school’s senior-class president got wind of this and came out to the bus and apologized, but it still shook the students.

In the 1980s and 1990s, when I was in school and the program’s funding was more secure, METCO students nevertheless felt that their position was precarious. Eddie was probably one of the best-behaved kids in the school district. Still, his parents worried that any deviation from his perfect record would have big consequences. “It would be, ‘Let’s make sure you’re not the reason that Belmont stops accepting METCO students,’” he told me.

METCO students in Belmont knew that even a little misbehavior would get them in a huge amount of trouble with METCO staff. Riding the bus as a little kid, “you were almost scared to breathe,” Eddie told me, because kids were so afraid that someone would act up and get the whole bus into trouble. If a student was sent to the principal’s office during school, the METCO bus, before leaving Belmont, would receive a visit from Thelma Burns, then the METCO coordinator for Belmont, whom students described as a mother, a grandmother, a guidance counselor, and a principal all rolled into one. The bus driver would turn off the bus’s motor, and the bus would turn silent with trepidation as students waited for Burns to climb onto the bus and give students a verbal lashing, Eddie and other students told me.

There were other ways students were made to feel like outsiders. Eddie remembers that kids assumed he only had a mom, not a dad, presumably because he was black. Teachers thought he had a speech impediment because of his Barbadian accent, and sent him to a counselor. Kids wanted to play with his hair and told him it looked like a sponge. When he got older and entered high school, Eddie remembers the strangeness of seeing what seemed like every student in Belmont getting a driver’s license—and, in many cases, a car—when they turned 16, while he and other kids from METCO still relied on public transportation.

“Having cars was absolutely not possible for us,” he said, of his family and other METCO students. Parties or social events often happened on the weekends, and he’d have to figure out a way to get back into the suburbs if he wanted to attend. His parents moved to another suburb when Eddie was 10, and though METCO made an exception and allowed him and his sisters to stay in the program, the move meant even longer commutes.

Eddie’s feelings of discomfort were typical of many METCO students sent to the wealthy Boston suburbs. Ramon Hamilton, who attended Belmont schools through METCO from the Boston neighborhood of Dorchester, told me that he experienced culture shock going from his family’s two-bedroom apartment to friends’ houses in Belmont, where small families would live in a home with five bedrooms, a finished basement, and an attic. “It seemed normal that if you were white, that’s how you lived,” Hamilton, whose mother was a Boston public-school teacher, told me. “My thing was always, ‘Damn, it sucks not to be white.’”

This feeling intensified in high school, he told me, when there were a few incidents of kids being called racial slurs in the locker room or during gym class. This continues today, Quintin and other students told me. There are only a few teachers of color in Belmont, she said, which makes METCO students feel even more isolated.

Black students have felt like interlopers in areas beyond Belmont. In 2003, a black boy who lived in the suburb of Wellesley and was not part of the METCO program was loaded onto a METCO bus at the end of the day and sent to Dorchester. In 1999, the superintendent of schools in the suburb of Lynnfield proposed eliminating METCO because he said METCO students were bringing down the district’s average grades. He pointed out that some of the METCO students were getting low grades, but the district’s METCO counselor argued that this was because the students were made to feel unwelcome and teachers set low expectations for them. After significant pushback from students, the district decided to keep the program. Every few years in Belmont and in other districts, black students are called racist slurs, or those slurs are scrawled on school buildings, or some sort of other racist incident happens, and METCO students feel unwelcome once again.

Burns, the former METCO coordinator for Belmont, told me that making METCO work always took a lot of effort. She remembers the years she spent convincing parents on both sides of the benefits of integration: hosting family dinners and picnics to involve both white and black parents; assuring white parents that it was safe to let their kids visit METCO students in Boston. The value of her work was clear then, she said—she remembers the first time she took students to Burbank, one of the elementary schools in Belmont, and they were so happy to see so much grass that they rolled around in it, luxuriating in the greenery.

She told me she was disappointed that Belmont now accepts fewer METCO students in the elementary-school years, a factor that must make it more difficult for students, she said. She wonders whether parents—both black and white—are less interested in integration. “You really have to have the support of the students, the teachers, the parents,” she told me. “I think parents just aren’t as engaged.”

Of course, that METCO exists, and that so many districts are still committed to it after 50 years, suggests that many Massachusetts residents are dedicated to continuing to integrate schools. Many in Belmont believe “that your zip code shouldn’t determine the quality of your education, and this is one small part to that,” Janice Darias, Belmont’s assistant superintendent, told me. A group of residents, called Belmont Against Racism, holds an annual breakfast on Martin Luther King Jr. Day to raise funds; the money pays for programs that support METCO students, such as taxis if they need to stay late for extracurricular activities. Families volunteer to be “host families” for METCO students, serving as a home away from home for students who might sometimes need a place to hang out after school, and who feel more welcomed if they know people who live in town.

METCO has its flaws, but the fact remains that even 60 years after the civil-rights movement, parents of color in Boston know that one of the best ways to guarantee that their kids get a good education is to hope they get into the program so they can attend a white school in the suburbs. “If they have to get up at 5 a.m., and that’s what it takes to be in a school system that has adequate funding and resources, and a better chance at quality educational opportunities, that’s what people are willing to do,” Guisbond, of Citizens for Public Schools, says.

METCO students see the contrast between their neighbors in Boston and their peers in Belmont every day. Both Eddie Linton and Lisbeth Quintin told me that many of their neighbors and friends who attended Boston public schools did not attend college.

Daniel Kelso Irvin, who graduated from Belmont’s public high school the year after I did, left METCO his junior year of high school after attending schools in Belmont since first grade, because he was sick of the commute. His first day at Boston High, a public school that no longer exists, he saw a fight, a drug transaction, and a student in school with a gun, he told me. The academics were nowhere close to Belmont’s—the stuff Boston High students were doing in 11th or 12th grade, he had done in eighth or ninth, he said. He missed Belmont, so he’d take the bus back and hang out with his friends there after school. “It was really just culture shock for me,” he said about switching to Boston High.

Boston’s schools continue to struggle today. Boston Mayor Martin Walsh recently went to the state legislature asking for millions of dollars for the city’s public schools, because they are dilapidated and lack funding for guidance counselors and nurses. An education-reform act in 1993 opened the door for charter schools in the state, and now much of the money that once went to public schools is being diverted to charter schools. $167 million of the $220 million the city received in state aid is going to charter-school tuition, according to The Boston Globe. Boston’s revered exam schools, the prestigious public schools that require students to test in, can only accommodate a fraction of the city’s students; the large majority of exam-school students are white and Asian.

The lesson, for many METCO students like Eddie, is plain: Staying near home offers fewer possibilities than going to a district like Belmont. Eddie, who played violin in the school orchestra and bass drum in the marching band, remembers complaining to his mother about the long commute, the code-switching, and the grueling hours of his school day. His mother got very serious, he told me. “She said, ‘Listen, if you want to be able to excel, and have a guaranteed place in this society, you have to keep doing it,’” he told me. “It’s kind of brutal if you think about it now.”

Of course, the METCO students aren’t the only ones whose lives are shaped by the program. My classmates and I benefited tremendously from sitting next to METCO kids during the school day, and from befriending kids who weren’t all white and upper-middle-class.

The psychology professors Thomas Pettigrew and Linda Tropp say that interacting with those different from oneself can make a person less prejudiced, a benefit they call “intergroup contact theory.” Pettigrew and Tropp have found that children who grow up in multiracial surroundings tend to be less anxious about racial differences, more empathetic and caring about others, and more likely to get involved in social change. They also express more interest in living in more ethnically diverse environments when they become adults. METCO didn’t make Belmont multiracial, exactly, but it was a step toward helping kids like me better understand the diversity of the world around them.

But unlike METCO students, who had to make significant sacrifices to come to Belmont, I had to forgo nothing at all. To be surrounded by all these different kids, to get the great education of a stellar school system, I would walk five minutes to middle school, past centuries-old houses with manicured gardens, or drive my beat-up Toyota Tercel down a big hill to the high school, which had a pond out front. I rarely thought about what Eddie and other students had to go through so that I could meet people different from me. I was so accustomed to METCO that for most of my time in school, I assumed it was a program that happened in every town in America.

METCO’s new executive director hopes that this idea—that students in receiving districts are benefiting from METCO, too—will convince more districts to join the program, and encourage the existing ones to expand. Arbaje-Thomas, who had previously managed anti-poverty programs in Boston, was appointed as the new METCO chief executive in January of last year, replacing Jean McGuire, who had run the program since 1973. She told me that she wants to start talking about METCO not just as a program that benefits the black students who are bused in, but as one that also benefits the white students who have more exposure to diversity than they would otherwise. No new districts have joined METCO since the mid-1970s, but she told me she’s eager to get more on board.

Arbaje-Thomas wants to talk about how METCO makes suburban students “global citizens” who benefit from being around different cultures and life experiences that they otherwise wouldn’t access in their sheltered suburban life. After all, she said, colleges pay for diversity by hiring staff to oversee diversity initiatives. Places of employment and private schools go out of their way to ensure diversity. “Nobody should be getting diversity for free anyway,” she told me. Parents sometimes tell her that they want their children to be prepared for the corporate world, and that means they need to know how to interact with people of all different races. She wants to frame METCO to districts like this: “We’re bringing you diversity, richness, an urban experience, an urban relationship that you wouldn’t otherwise have,” she said.

I see her point: Towns need to be convinced that METCO is so good for their students that they’ll go out of their way to ensure the program continues. But it’s nevertheless striking that the way to sell an integration program to white parents today is all about what they’re getting, not the greater social good. (In fact, during my correspondence with Darias, Belmont’s assistant superintendent, about the costs of the program, she wrote to me, “I hope you’re not trying to say in your article that METCO costs the town money, because I don’t think it does, and I think there is great value in having a diverse student population if we have as a goal raising racially aware students.”)

In November, voters in Belmont approved a “debt exclusion” that will allow the town to increase taxes by almost $2,000 per household by 2025. This will pay for the construction of a $295 million school to house kids in grades seven through 12, eventually accommodating about 900 more students. (The district currently has one middle school and one high school.) Though the measure was controversial, 76 percent of voters supported it. (My mother volunteered for the campaign to pass it.) It will allow the town to build a school for its growing population—and if it wanted, Belmont could also fit more kids from METCO.

But METCO and integration more generally were not mentioned in the run-up to the debt exclusion. The focus is, and will always be, creating more space for kids from Belmont. That’s why people move to the suburbs, after all, paying millions of dollars for houses that are expensive to heat and have long driveways to shovel in winter so they can get into one of the best school districts in Massachusetts.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

At least 2,000 children have now been forcibly separated from their parents by the United States government. Their stories are wrenching. Antar Davidson, a former youth-care worker at an Arizona shelter, described to the Los Angeles Times children “huddled together, tears streaming down their faces,” because they believed that their parents were dead. Natalia Cornelio, an attorney with the Texas Human Rights Project, told CNN about a Honduran mother whose child had been ripped away from her while she was breastfeeding. “Inside an old warehouse in South Texas, hundreds of children wait in a series of cages created by metal fencing,” the Associated Press reported. “One cage had 20 children inside.”

About 65 million years ago, shortly after the time of the dinosaurs, a new critter popped up on the evolutionary scene. This “scampering animal,” as researchers described it, was likely small, ate bugs, and had a furry tail. It looked, according to artistic renderings, like an especially aggressive New York City rat. And it had a placenta, an organ that grows deep into the maternal body in order to nourish the fetus during pregnancy.

The rodentlike thing would become the common ancestor of the world’s placental mammals, with descendants that include whales, bats, dogs, and humans, among many other species. And today, the placenta might hold the key to one of the most enduring mysteries in human medicine: Why do women suffer much higher rates of autoimmune disease than men do?

Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.

There’s a moment about 15 minutes into the first episode of Years and Years that made me gasp at its audacity, its prescience, its visual horror. The new six-part series from the British writer Russell T. Davies (Doctor Who, A Very English Scandal) charts the life of the Lyons family over the course of 15 years, starting in 2019 and ending in 2034. It’s a kitchen-sink saga that barrels its way through births and marriages and betrayals, but also through the near-future. In 2024, Stephen Lyons (played by Rory Kinnear), a financial adviser, is at home with his wife, Celeste (T’nia Miller), both rushing their way through the morning routine. When the camera turns to their teenage daughter Bethany (Lydia West), her face isn’t recognizably human. Instead, she looks like a 3-D version of a Snapchat puppy, with vast cartoon eyes, wagging pink ears, and a brown snout. When she talks, her voice is grotesquely distorted, a robotic hallucination of a child’s cadence. “I might have to start limiting filter time,” Celeste says in the same exasperated, noncommittal way that you might think, I really should spend less time on Twitter.



Every kid has that moment when she realizes that the adults she admires aren’t perfect. Few children ever learn, however, that the same is true for the inventors and intellectual giants whose distinguished portraits permeate their history textbooks.   

As it turns out, recognizing that visionaries such as Albert Einstein experienced failure can actually help students perform better in school. In 2016, the cognitive-studies researcher Xiaodong Lin-Siegler of Columbia University’s Teachers College published a study that found that high-school students’ science grades improved after they learned about the personal and intellectual struggles of scientists including Einstein and Marie Curie. Students who only learned about the scientists’ achievements saw their grades decline.

On Monday, the Teachers College announced the creation of the interdisciplinary Education for Persistence and Innovation Center, which will be dedicated to studying failure’s educational purpose. Lin-Siegler, who’s overseeing the center, will expand on her own research into the failures of successful people, starting by interviewing Nobel laureates. The center will convene researchers from various academic fields and countries in its effort to better understand how failure can facilitate learning and success.

Research on failure as a motivator is limited, though the evidence that does exist suggests that students can grow both from learning about the failures of other successful people and from experiencing failure themselves. Crucially, for failure to “work,” research indicates that educators and parents need to encourage students to figure out what went wrong and try to improve. “Failure needs to give people a chance to regroup and rewind the clock,” Lin-Siegler explained. Her main goal, she said, is to help students realize that failure is a normal part of the process of learning.

The notion that struggle is key to success has become popular in education circles in recent years. As buzzwords like “grit” garnered attention, they also became controversial: Some psychologists and teachers assert that perseverance and passion are invaluable academic skills that can be learned by anyone, while others argue this emphasis on those values disregards the socioeconomic barriers that can hamper certain students’ achievement.

But Lin-Siegler’s research adds a different dimension to the debate, suggesting that there is a much simpler problem at hand: Many kids today see failure as inherently bad, and success as beyond their reach. Her 2016 study, which tested more than 400 ninth- and 10th-graders at four low-income New York City schools, found that many of the kids viewed success as a result of some kind of natural aptitude that they simply didn’t have. The students didn’t tend to think of famous scientists like Albert Einstein as actual, imperfect people like themselves—students who didn’t learn about the scientists’ struggles were more likely to say that those scientists had innate talent and aptitude which separated them from everyone else. This mentality has been shown to be particularly detrimental to students in STEM fields, where droves of kids who originally seemed interested end up dropping out after they struggle in a class or fail a test.

Lin-Siegler emphasized how widespread misconceptions about success and failure can be, citing her personal experiences. Growing up in a remote village in China, she didn’t even attend school for part of her childhood. She eventually became a tenured professor at Columbia, an accomplishment that dazzled friends and family back home who interpreted her success strictly as the outcome of her intelligence. They didn’t know, she said, that one of her studies was rejected by five academic journals before getting published.

Of course, the value of failure can vary depending on the nature of the task—and the center will explore how educational institutions can navigate those nuances. For example, researchers will investigate strategies for helping medical students think about failure given that, for them, failure can mean another person’s death. Lin-Siegler hopes such strategies will empower medical students to fail in smaller ways, for example, and to decide if and when the medical profession isn’t right for them.  

Failure’s value is something of a tough sell in an education system in which the emphasis on test scores puts teachers under immense pressure to prioritize getting things right, right away. “To let kids fail,” Lin-Siegler acknowledged, “is a really hard thing [for teachers] to do.”



Voters think about a lot of things at the polls: immigration, the economy, health care, gun policy, and—more cynically—party affiliation. But education is an issue that doesn’t typically poll near the top of the list, even though it’s often thought of as a bedrock of society. Tony Evers, Wisconsin’s public-schools chief, and the most likely Democratic candidate to take on Governor Scott Walker in November’s gubernatorial election, is banking on the fact that that’s changing.

Evers, 67, isn’t the only educator who says he’s been inspired to seek political office because of the status quo—underfunded schools that have been hit with spending cuts, low teacher pay, and perpetual achievement gaps. Energized by successful teacher strikes in Oklahoma, West Virginia, Kentucky and Arizona, more than 150 teachers—Democrats, Republicans, and Independents alike—are running for state-legislative seats this year, according to an analysis by Education Week. And in New Mexico, as Politico noted, education weighs heavily in the governor’s race. Whoever wins that race will immediately walk into a legal fight over funding for what a judge called “an inadequate system,” and both candidates have vowed to revamp the state’s teacher-evaluation practices.

Each of these candidates across the country is betting that a focus on education policy will be enough to make voters care. The answer to that question has never been quite clear, but in a year marked by teacher and student activism, there is a fresh chorus of optimism that the strategy might work.

Wisconsin, a state where candidates are jumping over each other to highlight the education bonafides of their campaigns, will be a significant test case. In June, Governor Walker told the Wisconsin State Journal that he’s “a pro-education governor … I’m going to continue to be a pro-education governor and build off of that.” He has boasted that the state has frozen tuition at the University of Wisconsin-system campuses for the last six years. And he has a stated goal of getting Wisconsin to have the highest high-school graduation rate in the country by 2023—it currently ranks ninth, down seven spots from 2011. And the Democratic primary field is no different. All the candidates support increased funding for schools, and Kelda Roys, a lawyer running for the state’s highest office, has advocated for guaranteed early-childhood education and free two-year college for all residents.

For his part, Evers has had virtually every school-related job you can imagine: He's been a teacher, principal, and superintendent over his more than three decades in education. Running for governor was the farthest thing from his mind just a short few years ago, he says. But that changed after he won a third term as the state’s superintendent of public instruction. “It was clear to me that as much as I love my job as state superintendent—I think it's a very important one—there are things that I just cannot accomplish for the kids of this state in my present role,” he told me. “And I don't believe that Scott Walker will deliver on any promise he has around education.”

He offered a more blunt assessment of his motivations during his party’s state convention. “I am running for governor because I am goddamn sick and tired of Scott Walker gutting our public schools, insulting our hard-working educators, and destroying higher education in Wisconsin,” he said during his stump speech. According to a recent Marist/NBC survey, Evers is leading Walker by 13 points—and an Emerson College survey has him seven points ahead of the two-term incumbent—and he holds large leads over the rest of the Democratic field.

Since Scott Walker took office in 2011, education policy has become a point of tension for the state. Most critics point to Act 10—which limited public employees’, including teachers', ability to bargain with employers over wages and benefits and was enacted shortly after Walker took office—as the first shot of a seven-year-long battle between the governor and the state’s teachers. As many as 100,000 people took to the streets of Madison in protest. Since the law was enacted, median public-teacher pay in the state is down 2.6 percent, districts ratcheted up health-care costs for educators to recoup the millions of dollars that were cut from the state’s budget, and Wisconsin teachers are leaving the profession at a rate above the national average, according to the left-leaning Center for American Progress Action Fund. Public schools in the state have yet to return to 2011 funding levels, adjusted for inflation.

And citizens of the state appear to be tired of the cuts to schools too. Nearly three out of every five respondents in a June Marquette University poll of Wisconsin residents said that, if given the choice, they would raise taxes on themselves rather than cut funding to public education.

Higher education has not fared much better under Walker. There was the no-confidence vote in the University of Wisconsin system’s board of regents as well as their president. The proposal to eliminate 13 majors at the University of Wisconsin-Stevens Point. Then there was Walker’s 2015 proposal to cut $300 million from the the UW-System; the legislature ultimately voted to cut $250 million and remove some tenure protections. But he did an about-face in 2017, proposing an additional $100 million for the system, which was approved. “There are no clear education goals, and because of that context of not really having a north star, this is how we fumble through education policy in Wisconsin,” Nick Hillman, an associate professor at the University of Wisconsin, told me. (Walker’s office did not return a request for comment on his education policy goals if reelected.)

That’s what Evers wants to change. “We have to have a positive vision for the future,” Evers told me. “And my positive vision is around education.”

Heather DuBois Bourenane, the executive director of the Wisconsin Public Education Network, a non-partisan advocacy group for the state’s public schools, told me she thinks that educators and voters alike are seeing Evers' education background as a welcome change. “People view [Evers’] presence in the race with this kind of comforting feeling of relief that there is a grown-up in the room who gets what's going on with our schools and who will do what it takes to protect them,” she says.

Still, Evers’ rise may be attributable just as much to a name recognition advantage he has over other Democratic candidates as it is to his education platform. Evers has already won statewide office three times, after all. But some say candidates like Evers—those who do not energize the progressive base—have run and lost in the past. Mahlon Mitchell, another  Democratic gubernatorial candidate, for instance, called Evers a “retread” of candidates the Democratic party has run time and again, arguing that though he is a good person, he does not excite voters. And he isn’t sold on the fact that education is a winning issue. “There’s no doubt that we’ve got to shore up our public education, but there are so many issues hurting our state besides education,” he told Buzzfeed News.

According to a recent Marquette poll, more than a third of voters are still undecided about which primary candidate to vote for. However, for public education advocates in the state, whatever is bolstering Evers’ candidacy, it’s a good thing.

“The number one thing I hear most as we go around the state talking to school people and parents is that they're just sick and tired of people playing political games with kids in schools,” Bourenane told me. “They just want a time back when we can all just agree to be good to our kids as a minimum level of civility in this new America. You can have at each other with whatever political games you want, but let's just leave schools out of it.”

People in Wisconsin clearly care about education if they would rather tax themselves than cut school budgets. And the support behind the teacher movements that have swept the country this year show that is the case elsewhere as well. What remains unclear is whether that will be front-of-mind for voters at the polls in November.



The year was not a month old when a 16-year-old allegedly opened fire in a cafeteria in Italy, Texas, injuring one of his classmates on January 22nd. It was the first shooting on a K–12 campus this year. One day later, in Benton, Kentucky, a 15-year-old student allegedly killed two of his classmates and injured 17 others. Over the next three weeks, there were shootings at or near Lincoln High School in Philadelphia, Salvador Castro Middle School in Los Angeles, and Oxon Hill High School in Maryland. And on February 14, a former student at Marjory Stoneman Douglas High School in Parkland, Florida, allegedly killed 17 people and wounded more than a dozen others.

2018 has been indelibly marked by school shootings, and there was concern—at least at the outset—that it would be a year defined by a failure to address the problem, which several political figures, mostly Democrats, identified as access to guns. There had been hundreds of gun laws passed since a gunman killed 26 people, including elementary-school students, in Newtown, Connecticut, and most of them had expanded access to guns. But according to the Giffords Law Center, a gun-violence-prevention advocacy group, “the gun-safety movement experienced a tectonic shift in 2018.”

The law center tracked 1,628 firearm bills in 2018 and compiled a year-end review, which was released earlier this month. In total, 26 states and the District of Columbia enacted 67 new “gun safety” laws. “The growing number of mass shootings and domestic violence homicides, as well as the devastation wrought by guns in urban communities, has culminated in a surging pressure to address this epidemic,” the report reads.

The raft of legislation is significant not least because after so many years of school shootings, it had started to feel like every mass school shooting would be met with a familiar round of “thoughts and prayers” and calls for action, and then another school shooting would come, with little having changed. To be clear, school shootings remain rare, despite the devastating consistency with which they seem to occur. As of EdWeek’s latest tally, there were 24 school shootings with injuries or deaths this year—an average of two each month. But the very act of keeping count has its own complexities, and as my colleague Isabel Fattal wrote in February, “the messiness of counting school shootings often contributes to sensationalizing or oversimplifying a modern trend of mass violence in America.”

Parkland helped cut through the debate about numbers, putting a face and a voice to the violence. The students affected by the shooting took control of the conversation. “They have been through a trauma that would leave most adults curled in a prenatal pretzel under the bed,” Michelle Cottle wrote in The Atlantic.  “But these teens have elbowed their way into one of this nation’s most vicious policy debates, demanding to have their say.” The students energized the efforts that had been laying the foundation to challenge gun laws since the Newtown shooting, and they helped plan a nationwide March for Our Lives, which included a massive rally in Washington, D.C. State legislators set to work rewriting laws. The Trump administration banned bump-stocks, an attachment that makes semi-automatic weapons fire faster. And according to an NPR analysis, gun-control groups outspent gun-rights advocacy groups during the 2018 campaign cycle; in previous cycles, spending by gun-rights groups far outpaced that of gun-control groups.

For activists, 2018 has offered reason for hope. “We are going to be the kids that you read about in textbooks,” Emma González, a Parkland student, said in a viral speech. “Just like Tinker v. Des Moines, we are going to change the law. That’s going to be Marjory Stoneman Douglas in that textbook, and it’s all going to be because of the tireless effort of the school board, the faculty members, and most importantly, the students.”

But as much as some things were changing, there were reminders of how firmly entrenched the shape of the gun debate is. For instance, Trump’s school-safety commission, formed in response to Parkland, said that it wouldn’t focus on guns. Earlier this month, it released its recommendations to “make schools safer.” The report downplayed the role of guns, emphasized mental-health services, focused on Obama-era school-discipline rules, and advocated “no notoriety” for school shooters. All told, the report signaled that even though the conversation has shifted somewhat, the changes are marginal, and for the most part the gun debate in America looks more or less the same.



Last night, at the end of the final round of the annual Scripps National Spelling Bee, a record eight students were still standing, having calmly rattled off the correct spellings of words like psammosere, choumoellier, and Logudorese. The eight—Rishik Gandhasri, Erin Howard, Saketh Sundar, Shruthika Padhy, Sohum Sukhatankar, Abhijay Kodali, Christopher Serrao, and Rohan Raja—now share the title of co-champion. It’s a confusing result in a competition that usually crowns one individual champion, or—as has been common recently but rare historically—two.

Scott Remer, the author of Words of Wisdom: Keys to Success in the Scripps National Spelling Bee and the spelling coach of two of last night’s co-champions, Padhy and Serrao, explained to me just after the competition came to a close why the final round resulted in an eight-way tie. According to Remer, preposterous as it may seem to the average spellers among us, last night’s words were simply too easy, and America’s top spellers are just too good.

It should not be underestimated, Remer said, how truly wild an eight-co-champion result for the National Spelling Bee is. “Ordinarily, people get out,” Remer said with a laugh. “Ordinarily, people misspell words, sooner or later down the line initiating a round where you only have three [or fewer] spellers remaining.” At which point the rules change: In the first round in which only one speller has spelled a word correctly, that speller must also spell the next word on the official word list correctly to win the bee. But before last night’s 92nd annual bee could even get there, Remer said, “the kids exhausted the word list” while eight kids remained in the competition.

There are a few possible reasons that happened, Remer said. For one, the students’ preparation methods have gotten much more sophisticated in recent years: Most of the participating kids now have spelling coaches, and Remer’s book, published in 2010, is now in its fifth edition, pointing to its widespread adoption as a preparation tool. Remer also credits the computer software SpellPundit, which drills kids on past editions of the National Spelling Bee word lists. The program launched in 2018 and was used by that year’s bee champion, Karthik Nemmani, as a study method. “So many spellers use that now, and that certainly has increased their preparation level,” he says. This morning, SpellPundit’s website is boasting that six of the eight co-champions of this year’s bee used SpellPundit to study.

Another factor in the students’ resounding defeat of the dictionary may have been the words given in the final round, which both Remer and the past co-champion Gokul Venkatachalam found to be surprisingly easy (despite what the general public might think). For one thing, Venkatachalam, who won in 2014, wrote to me in a text message this morning that bougainvillea and pendeloque have been used in previous bees, so spellers who used past word lists to study already knew them well.

And for another, “Words such as ‘auslaut’ and ‘erysipelas’ and ‘pendeloque’ all follow basic language patterns for their respective languages or contain roots,” Venkatachalam pointed out. “As a whole, I consider these kinds of words to be much easier than words with unknown origins and ambiguous definitions.”

Remer agrees. Some of the hardest words in the final round, he noted, were Moazagotl, sphaeriid, and tettigoniid. Tettigoniid, the name of a particular species of grasshopper, derives from an unusual root—the Latin word Tettigonia, for a species of insect, derives from the Greek word for “cicada”—which most spellers don’t know, Remer said. Venkatachalam arrived at the same conclusion: “I thought ‘tettigoniid’ was one of the most difficult words asked throughout the whole competition,” he texted me, “as figuring out the prefix of ‘tetti-’ is downright impossible without prior knowledge of … genus names.” (A number of contestants misspelled science-related words during last night’s contest, such as flaser, an “irregular usually streaked lens of granular texture found in a micaceous interstitial mass of rock and produced by shearing and pressure during metamorphism”; hieracium, which is “any plant of a very large and nearly cosmopolitan genus of weedy perennial herbs having simple often basal leaves and heads of yellow or reddish orange ray flowers”; and Chama, which is “a member of a genus of eulamellibranchiate bivalve mollusks of warm or tropical seas having fixed massive irregular inequivalve shells and comprising the rock oysters and extinct related forms.” As Remer points out, some science-adjacent terms can be difficult for spellers to pin down because they are eponymous—built on the names of specific people or places.)

Remer likes to tell the students he coaches that there’s a subtle but crucial difference between a good speller and a great speller. “A good speller has a lot of words stored up in their memory bank, and can retrieve them; a good speller has memorized a lot of words, essentially,” Remer said. Meanwhile, “a great speller not only knows a lot of words, but can basically spell even words they haven’t practiced before—because they understand the logic and the languages, and they’re able to apply word roots to novel words that they run across.”

In other words, being able to deconstruct and reverse-engineer words based on their sound, meaning, and language of origin, Remer said, is basically “the art of spelling.” The odd reality that the National Spelling Bee now faces is that an unprecedented number of young scholars have begun to master it.



On Thursday, the U.S. Justice Department threw its support behind a group of Asian students suing Harvard for racially discriminating against them in admissions, writing in a legal filing that Harvard’s admissions process “significantly disadvantages Asian-American applicants compared to applicants of other racial groups.” The statement of interest, filed by the department’s civil-rights division, builds on a case against Harvard by Students for Fair Admissions, an organization that opposes race-based affirmative action.

In a tranche of legal filings in June, Students for Fair Admissions released documents it claimed supported its claims; one report in particular, by Harvard’s own internal research division, found Asian applicants would comprise 43 percent of the admitted class if only academic performance were considered. In a model that factored in Harvard’s preference for legacy and athlete students, extracurriculars, and personal traits, the number of admitted Asians would fall to 26 percent, while the number of white students admitted would increase. But once “demographics” were factored in, the proportion of admitted Asians and whites would both fall—to 18 percent and 44 percent respectively. The takeaway: Admissions policies that factor in race hurt both Asians and whites.

The case is, on the surface, about discrimination against Asians. But it is one of several recent legal actions that, on a deeper level, call into question the status of a certain subset of Asian Americans by aligning them with white people. (A Harvard spokeswoman said the study released by Students for Fair Admissions had been conducted with limited admissions data, and its results were preliminary and incomplete; a separate analysis that Harvard commissioned found no evidence of discrimination. Regarding the lawsuit, another school spokeswoman said Harvard does not discriminate in admissions and will fight to continue to pursue a diverse student body.)

Early this year, the white male engineer James Damore sued his former employer Google for discrimination on the basis of his race and gender, alleging the company institutes illegal hiring quotas, the results of which, according to his lawsuit, was that “Caucasian and Asian males were not being selected for jobs and promotions due solely to their status as non-females or non-favored minorities.”

In another lawsuit filed in January of this year, a former YouTube employee, Arne Wilburg, who is a white man, also sued YouTube’s parent company, Google, alleging that its hiring practices systematically discriminated against not only against white men, but against Asian men as well. Google will “vigorously defend” itself, a spokeswoman said, adding, “We have a clear policy to hire candidates based on their merit, not their identity. At the same time, we unapologetically try to find a diverse pool of qualified candidates for open roles, as this helps us hire the best people, improve our culture, and build better products.”

Notably, the man who spearheads the organization suing Harvard, Edward Blum, has sued schools before on similar grounds—but in those cases, it was on behalf of white, not Asian, students. In 2008 he helped represent Abigail Fisher, who sued the University of Texas at Austin for allegedly using her white race against her in its admissions process. On the same day Blum’s group sued Harvard in 2014, it also filed a discriminatory admissions lawsuit in a North Carolina district court against the University of North Carolina at Chapel Hill, once again on behalf of white students.

The Harvard and Google cases combine Asians with whites in a seemingly unified cry of so-called reverse discrimination—even though, at 6 percent of the population in 2017, Asians are statistical minorities, and at nearly 61 percent, whites are not.* These legal actions seem to be about race-blind equal opportunity. But in reality, they are making a case that, in the elite echelons of society, Asians are, like white people, a privileged class that is being brought down as other racial groups rise.

The term “Asian-American” refers to a hugely diverse group, comprising dozens of nationalities, religions, and ethnicities, as well as a variety of education levels and socioeconomic statuses. But much of the push to align whites and Asians as similar racial groups, both injured by employment and educational policies that consider race as a factor, ignores the vast diversity that exists among Asian-Americans. While Asians are the highest-earning of any racial and ethnic group in the United States with a median annual income of $51,288 in 2016, income inequality is also the highest among Asians, who have displaced blacks as the most economically divided racial or ethnic group in the U.S., according to a recent analysis from the Pew Research Center. The Google and Harvard cases largely home in specifically on Asians with high educational, socioeconomic, or employment statuses, intimating that the fate of this stratum of Asians is intertwined with that of whites.

This alignment of certain Asians with whites evokes historical instances of ethnic groups migrating from minority status to becoming part of the majority racial group. Sociologists have a name for this phenomenon: “whitening.” It refers to the way the white race has expanded over time to swallow up those previously considered non-whites, such as people of Irish, Italian, and Jewish heritage. In the next wave of whitening, some sociologists have theorized, Asians and Latinos could begin to vanish into whiteness, as some assimilate culturally into white norms and culture, and become treated and seen by whites as fellow whites. “The idea of who is white and which groups belong and don’t belong to it has been malleable and has changed. It is different across place and time,” Jonathan Warren, a University of Washington sociology professor who has written about whitening, told me.

The recent lawsuits echo the process by which whitening previously took place—in part, with the political and legal alignment of non-white groups with pro-white interests. While some Irish Americans once socialized and lived among black Americans and held anti-slavery views, they were courted by and ultimately joined the pro-slavery Democratic party, and came to pride themselves on their newfound whiteness and embrace anti-black stances. Centuries later, they are considered white people in the United States. Class, too, has influenced how minority groups have been viewed over time. According to Matthew Jacobson, a history professor at Yale, the idea of whitening stems in part from Brazil, where there’s a Portuguese phrase that translates to “money whitens.” The idea is that “if you move up the economic ladder you get magically whitened,” Jacobson says. “Some idea like that has been transposed into the U.S.”

Asians as a whole are not, of course, considered white people: The 2018 census form allows respondents to select from a number of Asian ethnicities. And not all academics agree that whitening will take place for Asian and Latino communities—Warren and Jacobson both say it isn’t happening, at least not to the degree it did previously. That’s partly because, as Jacobson notes, Asians and Latinos suffer from racial stereotypes such as the “model math student,” and the “immigration menace,” as he called it, that mark them as foreigners and non-whites.

My own family and I immigrated to the United States when I was a toddler, and I grew up in small towns in the South. I was often the only Asian in my class, and there were times my classmates had no qualms about excluding or ridiculing me for my culture and race. My experience is not that of a white person’s. And there are plenty of ways in which Asians, including those with high socioeconomic status, do not have privilege. They are the least likely of any racial group to be promoted into management positions. They are often little represented or whitewashed in the media, or harmfully stereotyped.

While my parents and I are Taiwanese immigrants who didn’t have much money when we arrived in the U.S., we eventually climbed the economic ladder and became comfortably middle class. As an adult, I consider myself a member of the socioeconomic group that a Pakistani-American friend of mine half-jokingly calls “bougie Asians.” I’m well-educated, with a degree from an Ivy League school, and live in one of the most expensive cities in the world. In the course of reading and writing about these cases, I’ve had to think hard about my own experiences as a Taiwanese-American woman, and whether I’m perceived as a minority—or being pushed by outside forces in the direction of a white person’s status.

When I have asked myself whether or not I have ever been granted white privileges, I have found myself growing uncomfortable. I recounted to a friend strange instances where potential employers made offhand comments about how they could “tell” that I was a hard worker. “How would they know?” I remarked, annoyed. “I don’t even work that hard.” My friend, who is black, paused, then said, “That”—the unearned assumption that I’m a hard worker— “sounds like the kind of thing that would get you a job.”

It’s a fair point. Being in the good graces of white people helped me win plum housing deals. It helped bring me pay raises and perhaps even jobs themselves. This isn’t to say that I haven’t come by my accomplishments honestly. But I do not fear for my life when the police are around. No one has ever crossed the street when I’ve approached or followed me around a store. For the most part, I do not believe I am negatively racially profiled by law enforcement, in housing opportunities or at retail stores. I’m not under any illusions about the way white society perceives me. But the racism and discrimination I face as a relatively privileged East Asian woman is, in some instances, markedly different than that of other minority groups, including Asians of other backgrounds and socioeconomic statuses.

Still, it’s disconcerting to be put in a separate category from other people of color. When I studied at Columbia Business School from 2015 to 2016, the admissions office co-hosted with student groups a recruiting event called Diversity Matters that aimed to “celebrate diversity and inclusion” at the school. It was staffed by student associations representing black, LGBTQ, female, Hispanic, and veteran students. Asian student groups were conspicuously excluded. The message was both subtle and damaging: Asians do not contribute to the diversity of the campus. (Columbia Business School and Columbia University did not respond to requests for comment.) There’s perhaps extra irony in that Columbia University president Lee Bollinger has been a vocal proponent of affirmative action; previously, as the president of the University of Michigan, he argued for student-body diversity in the Supreme Court case Grutter v. Bollinger, in which a white student sued the university’s law school.

In researching the Harvard and Google cases, and the history of whitening, and reflecting on my own experiences, I’m left thinking about the racial future of the United States, and the way ethnic groups align and re-align themselves. When privileged Asian-Americans argue alongside whites that reverse discrimination is taking place, they allow themselves to be used as a wedge group, to divide people of color and position them against each other and, indeed, against less privileged Asian-Americans. Polls have found that more than half of Asian Americans support affirmative action. Asian-American groups such as 18millionrising.org and Asian Americans Advancing Justice are staunchly resisting the wedge dynamic. The latter has gone so far as to file to become participants in the Harvard lawsuit in defense of affirmative action, on behalf of Asian Harvard students and applicants, as well as some black, Latino, and Native American students.

Sally Chen, who will be a senior at Harvard this fall and has joined the Asian Americans Advancing Justice effort, told me, “I think it’s sad to be involved in a reverse kind of gatekeeping,” she says. “It feels like we’re all scrambling for a limited set of spots set aside for non-white people. Comparatively, Harvard is still 49 percent white. What does that say?”

I’ve always been proud of my Taiwanese roots, but lately, I’ve started to question how much of my culture I’ve voluntarily released in the effort to belong in a country dominated by white people. American society is built around what white people like and don’t like. They decide which foreign foods are “in” (bubble tea, burritos) and what’s “gross” or “exotic” (menudo, say, or marinated pig ears). American standards for acceptable behavior—the way people talk, the language they use, the food they eat in a mainstream company—are carefully tailored to the tastes of white people. It makes sense. White people run the country and the vast majority of its institutions. They hold most of the wealth. Perhaps it shouldn’t be surprising that some Asian-Americans are aligning themselves with white people when it comes to university admissions. Appealing to white taste, after all, is a baseline requirement for advancement. But at what price?

 *This statistic has been updated to reflect the share of Hispanic Americans who identify as non-white. 



The college-admissions scandal that led to federal bribery charges against dozens of parents last week unfolded at selective universities that pride themselves on “holistic” evaluations of their applicants. This process typically means that several admissions officers review a file and consider factors beyond grades and test scores, often intangible qualities that aren’t quantifiable and are usually gleaned from an applicant’s extracurricular activities, essays, and recommendations. This approach is nearly ubiquitous among selective schools.

Given this scrutiny of applications, among the questions raised following the Justice Department probe is how the actions of a few rogue coaches and SAT proctors could go totally undetected in these admissions offices. How did the alleged cheater not get caught?

Over the past four months, I have sat with admissions readers and committees at three selective colleges as they chose this fall’s freshman class, as part of research for a book I am writing about the inner workings of the admissions business. (None of the three schools I’m following for the book was named in the investigation.) While readers—as the people who review applications are called—would sometimes raise questions about absent pieces of information or other inconsistencies, the issues were usually minor: unfamiliar acronyms, missing scores for AP tests, or a recommendation that mentioned a school club not listed elsewhere in the file. Even in those cases, the readers usually didn’t have time to search the internet for additional information, so they moved on, assuming, perhaps, that these were oversights and nothing more.

Admissions counselors are not hired to be detectives. An ever-increasing number of applications have swamped admissions offices in recent years, resulting in faster reading of files. Whereas once readers could spend 16 to 20 minutes on a given applicant, the average is now around eight minutes. The high volume of applications and small number of staff leave the process vulnerable to embellishment or outright lying, especially at selective colleges where the competition for a scarce number of seats is fierce. Selective colleges—those that accept fewer than half of applicants—accounted for about a third of all college applications in 2017, but for only 20 percent of undergraduates enrolled in American higher education.

“The entire admissions process is built on trust,” says Michael Steidel, the dean of admission at Carnegie Mellon University. “There is a fear, as application pools grow and as time spent on a review is reduced, [that] there is opportunity for problems.” Moreover, even if deans suspect fraud, federal antitrust laws prohibit universities from exchanging information about applicants.

Admissions deans I spoke with say fraud like that at the center of Operation Varsity Blues—the FBI’s nickname for the investigation—is likely rare, but they readily admit that it’s difficult to track. Some recent incidents give admissions officials cause for concern.

Last year, The New York Times found that a private high school in Louisiana, T.M. Landry College Preparatory School, forged transcripts and fabricated stories for application essays so that students would get accepted into selective colleges, including Yale, Brown, and Princeton. Two years ago, Technolutions, a company that operates a popular database system used by nearly 1,000 universities to organize applications, found that more than a quarter of recommendations provided for applicants to a graduate business school were all written on the same computer. But Alexander Clark, the CEO of Technolutions, told me his company’s system, called Slate, is unable to similarly track the so-called metadata of undergraduate applications because they are transmitted to colleges on platforms operated by the Common Application or its competitor, the Coalition for Access, Affordability, and Success.   

Since the scandal broke last week, one element of the scheme troubling admissions deans is that a few of the schools named in the affidavit were allegedly betrayed by their own athletic coaches. Coaches had allegedly classified applicants as recruited athletes even though they had no experience playing the sport.

How colleges recruit athletes varies widely by school. In general, coaches recruit athletes well before their applications are submitted to the admissions office. At some schools, a specific number of slots are reserved for athletes. (Georgetown, for example, allocates about 158 slots a year to its coaches, according to the affidavit.) Typically, admissions officers “pre-read” the applications of highly rated athletes to see if they can make the cut academically, and most are officially accepted during the early-decision round of admissions in the fall.

“When coaches say that this is a five-rated kid, we trust that,” says Chris Gruber, the vice president and dean of admission and financial aid at Davidson College in North Carolina, which competes at the Division I level. “At the same time, we have processes in place of checks and balances.”

When reviewing applications, Gruber and his staff keep an eye out for inconsistencies. For instance, if a student writes about the illness or death of a parent in the essay, that event is often reflected elsewhere in the application, perhaps in a recommendation. If not, “then you’re left wondering why no one else is talking about these things,” Gruber says.

Short of outright lying, high-school counselors I interviewed say the pressure on applicants to present a perfect picture in their application forces students to at times overstate their accomplishments or stretch stories in their essays. “Every student thinks they need a hook,” says Hannah Wolff, the college and career-center specialist at Langley High School in Virginia, who is also a part-time admissions reader at UC Berkeley. “They have an impression that being in the honor society, doing community service, getting all A’s in AP courses is not enough.”

All this has left admissions officers wondering if the overall application—test scores, grades, recommendations, extracurricular activities, and essays—remains an accurate portrayal of the student who is applying. “The concern I have is not fraud, but the overall fidelity of the correspondence they send us,” says one admission dean at a prominent university, who asked to remain anonymous to talk freely about the scandal. “Grades are inflated, activities are embellished, recommendations lack negative comments, and the standard now is test prep and multiple editors for essays.”

As a result, some admissions deans want to ask for different evidence of an applicant’s potential beyond the usual polished checklist. The coalition application, for instance, gives students a private virtual “locker” to upload materials, such as documents, photos, and videos, that they can later add to their application. For the past three years, students applying to Yale University have taken the option to use the coalition application to submit a document, image, audio file, or video instead of responding to two short essay prompts on the Common Application.

Meanwhile, a group of deans from selective colleges, including Bucknell University, MIT, and Swarthmore College, are examining the use of assessment tools to measure an applicant’s character attributes. “We are not saying throw out testing and replace it with noncognitive measures,” says William T. Conley, the vice president for enrollment management at Bucknell. “But we know that things like persistence and teamwork are important to success in college and afterwards, and they should be part of holistic admissions.”

Inevitably, whenever colleges shift what they want in their application, students change their own behavior in response, or new industries sprout up to assist them. As long as applications to elite schools are abundant and seats scarce, applicants will look for ways—even sometimes those that push up against ethical lines—to stand out. And because admissions officers tend to trust applicants and have neither the time nor the resources of the FBI to check out anything they might question, the only safeguard built into any admissions system (now or in the future) is cultural norms about honesty.



Starting in September of 2020, schoolchildren across the United Kingdom will learn from their teachers how to fend off loneliness.

In January, British Prime Minister Theresa May appointed the first “minister of loneliness.” This week, her administration released an 84-page plan detailing the actions it will take to curb loneliness across the country, including measures that will be enacted in schools. Starting in primary school, students will have mandatory lessons in “relationships education,” and such lessons will also be incorporated into sex-ed classes in high school.

The Brigham Young University psychologist Julianne Holt-Lunstad, one of the foremost scholars on loneliness in the United States, warns that the U.S. has a significant, largely unaddressed loneliness problem of its own—and that schools desperately need to follow the U.K.’s lead and incorporate preventive measures into their lessons.

Indeed, according to a recent report by the health-care company Cigna, nearly half of adults in the U.S. reported sometimes or always feeling alone. Marriage rates and religious-participation rates are also dropping, and both are risk factors for social isolation and loneliness. The prevalence of loneliness seems to be especially acute among young adults: One study last year found that Americans ages 21 to 30 reported feeling lonely on twice as many days as adults ages 50 to 70, despite having larger social networks. The health consequences of loneliness can be severe: Studies suggest chronic loneliness is linked to a variety of health issues, such as decreased immunity to viral infections, poor sleep, and cardiovascular issues like hypertension.

Loneliness and social isolation, it’s worth noting, are often used interchangeably, but the concepts are distinct. Loneliness is a feeling that may or may not depend on how many meaningful confidants a person has—some people feel lonely or suffer from chronic loneliness despite not being socially isolated. Still, social isolation is a leading contributor to loneliness.

The ideal school curriculum for teaching loneliness prevention, Holt-Lunstad says, would target social isolation as well as the cognitive processes that make people feel lonelier—while, of course, teaching students the health risks associated with loneliness. “Recognizing that it’s something that we need to take seriously for our health is a primary and critical step,” she says.

Holt-Lunstad advocates for a sort of “social education”—similar to efforts by schools to provide, say, sex education and physical education—that would be integrated into existing health-education curricula to teach students how to build and maintain friendships and relationships. Learning how to provide the kind of help and support a friend or partner feels a need for is an invaluable social skill that can be taught in the classroom, she adds. For example, when a friend who is broke asks for money but instead receives a lecture on financial management, she isn’t likely to feel she’s been supported in the way she needs.

Of course, Holt-Lunstad isn’t the first to wish students learned more social-support and empathy skills during the school day. Since as far back as 1976, researchers have recommended social education as a way to teach teens how to foster and maintain healthy relationships. In 2000, the academic E. Wayne Ross took a different approach when he wrote for Theory & Research in Social Education that individual teachers, particularly social-studies teachers, should take care to teach history and civics from multiple perspectives to foster empathy and quell alienation among diverse groups of students. Social-skills training has also been implemented in many schools for special-needs students, and some schools have already taken measures outside classrooms to encourage social support among students, such as instituting a “buddy bench,” where kids can sit during recess or lunch to indicate that they could use a friend.

But Holt-Lunstad believes that loneliness-prevention education should not be limited to teaching students how to support others. She also believes that kids should learn early in life how to reframe their own negative responses to social situations. “We’ve all had a situation where you text someone and they don’t respond right away,” she says. “Instead of assuming they’re snubbing you, they’re blowing you off, all of these kinds of negative things that could in turn lead you to respond with nasty comments or become irritated, which is not going to elicit the sort of friendly response you want,” she says, “reframe it as, ‘Perhaps they’re driving.’ ‘Perhaps they’re in a meeting.’ If you’re interpreting others’ social signals as negative, how you behave toward them is more likely to mirror that.” The existing strategies for helping people repackage their thoughts in a more positive way could easily be adapted for a classroom setting.

One big criticism of incorporating social education into the school day is that it could take away time and resources that are currently used for other prevention programs, such as those that target substance abuse, suicide, and bullying. But as Holt-Lunstad told me, loneliness is a risk factor for those behaviors. “Addressing social isolation, loneliness, social disconnection helps us to address those other issues, too,” she says.

What’s most crucial in the development of a school loneliness-prevention program, though, is taking the time to develop a curriculum that works. Some school programs implemented in recent decades haven’t been all that successful: Certain abstinence-only sex-education programs have been linked to higher rates of teen pregnancy, while some drug-abuse-prevention programs haven’t done much to curb drug use. “So this really does need to be evidence based,” Holt-Lunstad says. “We have to be really, really careful about the kinds of interventions we do.”

As loneliness remains a troubling and pervasive problem in America and around the world, teaching preventive skills to students could help create future generations that are healthier and more socially connected. And just as schools have implemented exercise, substance-abuse, and nutrition programs into their curricula to help kids become active, healthy adults, Holt-Lunstad says, loneliness-prevention courses could help ensure that they grow into empathetic, socially connected ones, too.



President Donald Trump had not yet been in office for one month when he took to Twitter to scold a college. “If U.C. Berkeley does not allow free speech and practices violence on innocent people with a different point of view,” he wrote, “NO FEDERAL FUNDS?” The tweet was in response to protests at the institution, and it worried college leaders—not least because as a candidate, Trump was rather reserved in higher-education-policy specifics.

On Thursday, Trump took action along the lines he set out in that early tweet, signing an executive order directing federal agencies to “take appropriate steps” to make sure that colleges receiving research funding from the federal government are promoting “free inquiry.” But the order essentially asks colleges to do what they’re already required by law to do, and it is still unclear whether there will be any enhanced policing of colleges by federal agencies as a result. The order does not have any impact on federal student-aid programs.

“Taxpayer dollars should not subsidize anti–First Amendment institutions,” President Trump said Thursday afternoon during a signing ceremony in the East Room of the White House. “Universities that want taxpayer dollars should promote free speech, not silence free speech,” he said, adding that “if a college or university does not let you speak, we will not give them money.” The president’s speech was a restatement of what has become a common Republican criticism of higher education. And in that way, more than being a significant policy change, the order is red meat for Trump’s base.

In many ways, the administration has been taking direct action on campus speech for a long time. Since Jeff Sessions was attorney general, the administration has intervened in several campus-speech cases, at Georgia Gwinnett College, the University of Michigan, and others. And members of the Justice Department have, time and again, decried the “heckler’s veto” when speakers have been shouted down or disinvited due to protest.

But most of what the executive order does is reinforce what colleges and universities are already doing, Jacqueline Pfeffer Merrill, the director of the Campus Free Expression Project at the Bipartisan Policy Center, told me before the signing. “Colleges and universities are really the best stewards of free expression and academic exchange,” she said. And hopefully, if anything, this is a moment for colleges and universities to reaffirm that commitment to free speech.

At least one portion of the order is likely to see bipartisan praise: The order has colleges reporting outcome data—earnings averages, student-loan debt, default rates, etc.—for specific programs. The Department of Education will publish that data in the College Scorecard, a government site that allows students and parents to compare the cost and value of colleges. Last week, members of Congress reintroduced the College Transparency Act, which would establish a system that would report more robust information on college-completion outcomes, student earnings, and debt.

The Department of Education had previously suggested that it would consider publishing some of this information in the College Scorecard, but the executive order reinforces that commitment, Amy Laitinen, the director of higher-education policy at New America, told me. Still, she said, “the president can push the agency to commit to the College Scorecard, but there’s not much it can do to make colleges report new information.” That would likely require legislation.

In a statement, Senator Lamar Alexander, a Republican from Tennessee and the chair of the Senate Committee on Health, Education, Labor, and Pensions, applauded most of Trump’s executive order, but, as a former college president, he added a note of caution. “I don’t want to see Congress or the president or the department of anything creating speech codes to define what you can say on campus,” he said. He agreed that colleges should stop “coddling students to protect them from disagreeable views,” but added that “conservatives don’t like it when judges try to write laws, and conservatives should not like it when legislators and agencies try to rewrite the Constitution.”

This article is part of “The Speech Wars,” a project supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press, and the Fetzer Institute.



On Tuesday, President Donald Trump’s school-safety commission, which was established following the school shooting in Parkland, Florida, released its much-anticipated recommendations “to advance safety” in schools, including one that would scrap a federal policy urging schools not to punish minority students at a higher rate than white students.

The commission’s recommendation to roll back the Obama administration’s school-discipline guidance does not come as a surprise. Republicans have decried the policy as government overreach since it was released in 2014. The policy advocated “constructive approaches” to school discipline, such as victim-offender mediation, as opposed to harsher penalties such as suspensions or expulsions.

The Trump administration’s discipline recommendation comes alongside several bipartisan common-sense measures in the report, including encouraging teachers, administrators, and parents to be vigilant about reporting information to the FBI; improving access to school mental-health services and counseling; and implementing best practices to curb cyberbullying. The report also advocates that districts create a “media plan” to disseminate information in the event of a shooting, alongside a suggestion to follow “No Notoriety” guidelines to keep the focus in the aftermath of an incident on the victims rather than on the shooter.

The school-safety commission’s recommendations are just that: recommendations. As the report notes, “Implementation of the practices identified in this guide is purely voluntary, and no federal agency will take any action against schools that do not adopt them.” School districts have been slow to respond to such nonbinding recommendations in the past—including school-safety recommendations in the wake of school shootings during both the George W. Bush and Barack Obama administrations.

Given the broad mandate of developing recommendations to address school violence, the administration took to addressing the school-discipline guidelines remarkably quickly. The commission argues that the guidance left schools unable—or at least afraid to—take action against potentially dangerous students. “Policy guidance issued under the Obama Administration placed an emphasis on tracking school disciplinary actions by race,” the report says. “The Guidance sent the unfortunate message that the federal government, rather than teachers and local administrators, best handles school discipline.” The commission argued that the emphasis on avoiding a disparity in which students are disciplined may lead school leaders to let their school-discipline policies be driven by numbers, rather than by teacher input.

Education Secretary Betsy DeVos, who chairs the commission, argued that a one-size-fits-all approach to school safety would not work. “Through the Commission’s work, it has become even clearer there is no single policy that will make our schools safer,” she said in a statement. “What will work for schools in Montana will be different than what will work for schools in Manhattan.”

Still, the administration’s focus on school discipline has been highly contested—primarily because it seems disconnected from the broader issue of preventing the next school shooting. “It is unconscionable to use the very real horror of the shooting at Parkland to advance a preexisting agenda that encourages the criminalization of children and undermines their civil rights,” Vanita Gupta, the president of the Leadership Conference on Civil and Human Rights, said in a statement following the report’s release. Gupta’s statement tracks with months of criticism of the proposal to scrap the school-discipline guidance. Supporters of the Obama guidance argue that it is necessary to counteract the effects of the inequitable doling out of discipline.

Both Obama-era education secretaries, Arne Duncan and John B. King Jr., released a joint statement on the committee’s recommendation on Tuesday. “We put this guidance in place to start a conversation about these harmful practices and encourage advocates and policymakers to look more deeply into why these disparities exist and to intervene when necessary,” they said. In April, the Department of Education released its annual Civil Rights Data Collection report, which showed that black students made up 15 percent of K–12 enrollments nationwide, but 31 percent of expulsions.

Bobby Scott, the top Democrat on the U.S. House Committee on Education and the Workforce—who will become the committee chair next year—put the sentiment of those who prefer to keep the guidance plainly. “Rather than confronting the role of guns in gun violence, the Trump administration blames school shootings on civil rights enforcement,” he said in a statement. “This guidance has no connection to school shootings.”

While advocates and experts of all political stripes are likely to agree with several of the recommendations of the report, the recommendation on school discipline delves, perhaps unnecessarily, into one of the most politically contentious issues in education. As my colleague Alia Wong wrote in March, “For Washington policymakers to give outsized attention to student-discipline reform is to succumb to ideological precepts that lack empirical support. It is to waste the lessons gleaned from the growing tally of school shootings while reinforcing racial disparities.”



There was shock, then backlash. Last week, officials at the University of North Carolina at Chapel Hill announced their plans for the infamous Confederate statue known as Silent Sam, and those plans hardly satisfied anyone.

On Friday, protesters converged outside of the Center for Leadership Development at Chapel Hill as, inside, the UNC system’s Board of Governors met to deliberate on the university’s plan to erect a $5.3 million building on campus to house the monument. The building would also serve as a university history center. Ahead of the meeting, some board members expressed reservations about the proposal. Was there not a building already on campus that could house Silent Sam without having to spend $5.3 million on a new facility? Others argued that moving the statue to any building, but especially the proposed history center—which has all the hallmarks of a museum—might be illegal due to a state law that says prominently displayed monuments can’t be moved to museums.

In the end, the Board of Governors decided to punt. Harry Smith, the chair of the board, announced that they would be denying the plan presented by UNC Chapel Hill’s chancellor, Carol Folt, last week. For reasons of public safety, Smith said, alongside the sheer cost of the recommendation, the board could not support the plan. The board charged five of its members to meet with Folt to review other options for the statue. The deadline for the new recommendations is March 15, 2019.

The vote by the Board of Governors bookends a chaotic two weeks at the flagship institution. Late last week, more than 80 teaching assistants pledged to withhold final-exam grades for the fall semester unless the proposal was withdrawn, though they would make exceptions for students who needed final grades for graduation, job, or immigration purposes. Administrators forcefully responded. There would be “serious consequences” for such a strike, they said. One member of the Board of Governors—equating the action with “violence”—said that he would push for the expulsion of those who would participate in such a protest.

Then there was the striking incident during a faculty-council meeting where a black student, Angum Check, who had earned a Martin Luther King Jr. scholarship, confronted Folt. “I want to tell you, you are a disgrace,” Check said.

On Thursday, members of perhaps the most lauded organization on the University of North Carolina Chapel Hill’s campus, the men’s basketball team—including the alumni and NBA stars Vince Carter, Jerry Stackhouse, and Harrison Barnes, alongside several other former black athletes—sent a statement to university officials expressing “deep concern” about the proposal. “We love UNC but now also feel a disconnect from an institution that was unwilling to listen to students and faculty who asked for Silent Sam to be permanently removed from campus,” they wrote in a letter first reported by Spectacular Magazine, and confirmed by The Washington Post. “The recommendation is embarrassing to us who proudly promote UNC.”

Ultimately, the decision to punt is not surprising, given the consternation the plan has stirred up over the past several days. So, for now, officials will go back to the drawing board, and both Silent Sam’s supporters and those who would prefer him consigned to history will prepare for another battle in March.



Jasmine Lee had finally found something she was happy with and wanted to pursue. She had been working as a medical assistant at an orthopedic center, and she was enjoying it. But she wanted more. So she figured she should check out the certificate program at Virginia College in Birmingham, where she works.

“I'm just trying to better myself, and provide a better life for my kids,” Lee, the 23-year-old mother of two, told me. Last summer, she decided to enroll. She applied to the medical-assistant certificate program, got accepted, and found out she was eligible for the financial aid. Everything happened very fast, she said.

“They quickly had me signing up, they quickly had me trying to take a test,” she told me. She told her enrollment adviser that she wanted to start in August—it would be best for her job—but he advised her that the tuition would go up a significant amount soon, and if she started in July, she could “lock in” the current rate. According to the Virginia College website, tuition and fees for the nine-month certificate program were $16,750. A comparable program at the local community college in Birmingham costs roughly 10 percent of that.

Once she started, Lee enjoyed the program. The people—teachers and staff included—seemed to actually care about the students. “I was getting good grades, I had a good GPA, I found out I was on the dean’s list,” she said. And then, on Wednesday, the school’s parent company, Education Corporation of America, announced that on Friday it would close all of its campuses nationwide. And Lee, five months into her nine-month program, will likely never receive the certificate she has sunk both time and money into.

Lee is one of the more than 19,000 students affected by the abrupt closure of Education Corporation of America, one of the country’s largest private for-profit college operators, which runs Virginia College, Brightwood College, Brightwood Career Institute, Ecotech Institute, and Golf Academy of America. The for-profit operator had been in a precarious position for some time, given a pending loss of accreditation and access to federal financial-aid funds. In a letter to students on Wednesday, Stu Reed, the CEO of Education Corporation of America, said, “It is with extreme regret that this series of recent circumstances has forced us to discontinue the operations of our schools.” The company had tried to “dramatically restructure” itself, including campus closures over time. But the outside pressures, it argued, were too powerful, and it had to accelerate the process of closing schools. But until then, students, by and large, were unaware that the problems were that severe. ECA did not immediately respond to a request for comment from The Atlantic. 

There have been a handful of closures of major for-profit operators over the past few years, most notably the closure of Corinthian Colleges in 2015 and ITT Technical Institute in 2016. In each of these cases, there were thousands of real people, like Lee, who were left wondering how to pick up the pieces after they’d invested valuable resources into an education that suddenly disappeared.

When a college closes abruptly, students can often have their federal student loans discharged, Toby Merrill, the director of the Project on Predatory Student Lending at Harvard, told me. But that doesn’t happen automatically, she says, and students have to apply to receive the funds. Typically, after they apply, the discharge takes roughly a month or two. Historically only a fraction of students who were eligible for such discharges have ever received them. However, the Department of Education recently changed its policies to provide automatic loan cancellation to all eligible students, as long as they do not enroll in another program that uses federal financial aid within three years.

But even though students may be eligible to get their loans discharged, Lee says, they are unlikely to get any credit for the work they’ve already done, and that doesn’t account for the money they spent out of their own pocket. “Signing up for school, they were telling us that a lot of schools do not take their credits,” Lee told me. But she figured it would be worth it because if she finished school there, the credential would follow her for life. Now that the school is closed, though, the consequences of this are more readily apparent: She can’t transfer into another program and would likely have to start from scratch. “I’ve missed out on five months of things with my kids to be in school,” she says. “I only had four more months to go.” And to have that rug pulled out from under her is “discouraging.”

Local community colleges and technical colleges will often try to step in to help students who have been affected by the closures, but their hands are tied in terms of what credits they can allow to be transferred over, Trace Urdan, a managing director at Tyton Partners, a higher-education consulting firm, told me. Since many of the credentials—including certificates—offered by the colleges are essentially one long course broken apart, most regionally accredited colleges can’t use the credits. It’s like taking half of a calculus course, he said.

Lee and other students in the medical-assistant program at Virginia College were still encouraged to take their final exam on Thursday evening. Lee went to class, hoping to learn more about what would happen to the students and their credits. On Friday, she told me that the school had suggested two institutions that may accept their credits. “But the classes are different,” she said, “so the ones who were at the end [of the program] may have to take another class or two.”

All of this is happening to a student body not well equipped to weather major setbacks. Statistically, students at for-profit colleges are more likely to be low-income than those at other institutions, and are less likely to have the resources to draw on to be able to come up with a good Plan B. And so they’ll end this year a little older, maybe a little wiser, and with even fewer options than they had when they started.



Commencement speakers have a routine: a few words of encouragement, a good—or maybe not so good—joke, and a bit of advice. But this year, Robert F. Smith, the billionaire founder of the private equity firm Vista Equity Partners, who delivered the commencement address on Sunday morning at Morehouse College, a historically black college in Atlanta, took a different approach.

“You great Morehouse men are bound only by the limits of your own conviction and creativity,” Smith told the soon-to-be graduates of the venerated HBCU (historically black college or university). Smith then did something astonishing: He did what he could to make that actually true, telling the class that his family would be eliminating the graduates’ student debt. The crowd, as expected, went wild.

The gift, estimated at about $40 million, is expected to clear the debts of nearly 400 graduates in this class—and is the single largest donation from a living donor to an HBCU in history. The gift is, of course, significant in a political sense, coming at a time when candidates for president and other politicians are seriously mulling debt cancellation; but it is also significant for these black men at Morehouse in particular.

According to a report from the Center for American Progress, black students are more likely to take out student loans than their white peers, and nearly half of black borrowers default on their student loans. One Morehouse graduate told the Associated Press that he had $200,000 in student debt, and that when Smith announced the gift, “we all cried. In the moment it was like a burden had been taken off.” By eliminating these graduates’ debt, Smith is very directly changing their future.

The thing about generosity, though, is that it is not a salve for systemic problems. Smith, who has a net worth of $4.5 billion, could eliminate debt for thousands more—and some parents hope that he will. (“Maybe he’ll come back next year,” the father of one Morehouse graduate, who has another son who is currently a junior, told The Atlanta Journal-Constitution.) But one billionaire can only help so many, and more than 40 million people in the United States have student loans. And no graduation gift can help the millions of young people who never complete their degree.

It's for this reason that several Democratic presidential candidates believe that the problem of mass student debt requires a systemic approach and have proposed various “free college” policies. Senator Bernie Sanders, for example, has pushed to make public four-year colleges, community colleges, and trade schools tuition-free. Senators Kamala Harris and Cory Booker have signed on to debt-free college legislation. Elizabeth Warren has called for a fund of at least $50 billion to help historically black colleges in particular, as well as other minority-serving institutions, known as MSIs. And in addition to making public colleges tuition-free, her plan would also allow private historically black colleges, such as Morehouse, Howard University in Washington D.C., or Spelman College, to opt in to the federal tuition-free college program. Republicans argue, however, that injecting more federal money into colleges would simply encourage them to drive their tuition up more.

“This is my class,” Smith told the graduates and their families, “and I know my class will pay this forward.” Perhaps this is the start of a new trend; HBCUs are not used to receiving such large donations from living donors, and now the record—first a $30 million gift to Spelman back in December, now $40 million to Morehouse—has been broken twice in the past six months. Smith said he hopes that “every class has the same opportunity going forward.” But what are the chances? How many Smiths are out there, ready to swoop in?



Marvin Krislov had his hands full in 2003. The University of Michigan was on trial in two cases that challenged its affirmative-action policies. One case, Grutter v. Bollinger, alleged that the law school’s admissions policy was discriminatory; the other case, Gratz v. Bollinger, said the same was true of the undergraduate policy. Krislov, the general counsel of the university from 1998 to 2007, led the defense.

As the current trial against Harvard, which appears poised to head to the Supreme Court and which alleges that the institution discriminates against Asian American applicants, reaches the end of its second week, I spoke to Krislov about one possible outcome: what happens when the Court decides a school’s admissions policies are illegal.

When Krislov joined the University of Michigan in 1998, there were 1,944 full-time black undergraduate students, according to the National Center for Education Statistics, which was roughly 9 percent of the overall campus population. Four percent of the student body was Latino, and that figure had started to tick upwards after a few years of decline. Year over year, for the most part, the university was growing more diverse. And a lot of that diversity, said Krislov, now the president of Pace University, was due to actively factoring in race while considering students for admission.

But looming in the background were the two cases, which had been filed a few years before Krislov arrived. The Center for Individual Rights had led a charge to search for students who believed they had been denied admission to the university on the basis of their race, and they found them. One student, Barbara Grutter, a white woman, had been denied admission to the law school; another, Jennifer Gratz, also a white woman, had been denied admission to the undergraduate school.

The two separate cases at the University of Michigan reflected two separate systems of race-conscious admissions. The law school took the tack that Justice Lewis Powell had lavished praise upon in his 1978 opinion in the landmark Supreme Court case upholding the use of race in admissions. In the Regents of the University of California v. Bakke case, Powell wrote that using race as one of many factors in considering an individual was the ideal way of doing admissions. But the undergraduate school, which was challenged by Gratz, used a point system; the system held that blacks, Latinos, Native Americans, and low-income applicants were assigned 20 points automatically.

Over the course of six years, the cases wound their way through the courts, before arriving at the Supreme Court. And there were two very different outcomes. In a 5–4 decision, the university won in the case brought by Grutter, and the Court upheld the use of race in admissions for the purpose of campus diversity as long as it was used in a “narrowly tailored” way. The same could not be said for the undergraduate college. “It was found to be formulaic and not narrowly tailored,” Krislov told me. In a 6–3 decision, the Court found the undergraduate policy to be in violation of the equal-protection clause of the Fourteenth Amendment.

But Justice Ruth Bader Ginsburg had a different take. In her dissenting opinion, she wrote: “If honesty is the best policy, surely Michigan’s accurately described, fully disclosed college affirmative action program is preferable to achieving similar numbers through winks, nods, and disguises.” Isn’t it better, she asked, to just be honest about what you’re doing in admissions instead of disguising it?

Still, the university was forced by the Court to change its undergraduate admissions policy. In an interview with Judy Woodruff, then an anchor at CNN, shortly after the decision, Mary Sue Coleman, the university’s president at the time, said the shift wouldn’t be that difficult. “What we may do is to fashion our undergraduate policy along the lines of the law-school policy, which the Court said is fine and said that the law-school policy is constitutional,” she said. “And what that means is it’s a more individualized attention to every single application. And we’re happy to do that.”

And that’s what the university did. For the first couple of years after the school made the switch, the undergraduate black and Latino populations hovered around 1,750 (8 percent) and 1,100 (6 percent), respectively. “Then, shortly thereafter, Ward Connerly came to the state,” Krislov says.

Connerly was the political strategist who had ushered Proposition 209, the ballot measure that banned affirmative action in California, through the process. The measure he organized in Michigan, the “Michigan Civil Rights Initiative,” or Proposition 2, passed on referendum in 2006. “The referendum changed the permissibility of considering race at all, and so Michigan has been struggling to try to improve the percentage—particularly of African Americans—that has fallen since the referendum,” Krislov said.

Black enrollment at the University of Michigan dropped by nearly 10 percent in the three years following Proposition 2—from 1,615 to 1,476, according to the National Center for Education Statistics. And according to the university, black enrollment has hovered around 1,200 since 2010—4 percent of the overall campus population. As of 2017, “underrepresented minorities,” including black, Hawaiian, Latino, and Native American students, as well as those with two or more of those characteristics, made up 12.8 percent of the undergraduate population. Universities in California saw similar declines in minority-student enrollment when race-conscious admissions—the use of race as one of several factors for admission—were banned in 1996.

Only a handful of colleges are selective enough to need to use affirmative action in admissions. And the lawyers for Students for Fair Admissions have argued in court that “the future of affirmative action is not on trial” in their current suit against Harvard—though they have made several points that single out race as a potentially unequal consideration in the admissions process at Harvard.

What happened at the University of Michigan—and in California—suggests that if the Harvard case does make it to the Supreme Court and the Court breaks precedent by finding that the use of race in admissions is not legal, underrepresented minority populations on college campuses that have previously considered race will decline. According to David Card, an expert who testified for Harvard, without considering race as a factor in admissions, the percentage of black students on campus would fall from 14 to 6 percent, and the Latino population would drop from 12 to 9 percent.



On the weekend before the opening gavel of what’s being dubbed the Harvard affirmative-action trial, a record-breaking 597 of my fellow members of the class of ’88 and I, along with alumni from other reunion classes, were seated in a large lecture hall, listening to the new president of Harvard, Lawrence Bacow, address the issue of diversity in the admissions process. What he said—and I’m paraphrasing, because I didn’t record it—was that he could fill five whole incoming classes with valedictorians who’d received a perfect score on the SAT, but that’s not what Harvard is or will ever be. Harvard tries—and succeeds, to my mind—to fill its limited spots with a diversity not only of race and class but also of geography, politics, interests, intellectual fields of study, and worldviews.

I loved my four years at Harvard, largely because of the diversity of its student body. I don’t love the fact—now made public through the trial but previously understood by all of us to be true—that the kids whose parents donate buildings are given preferential treatment over those whose parents don’t. But I understand why the development office, which allows the university to give a free ride to any student whose family makes less than $65,000 a year, might encourage such a practice, which is hardly unique to Harvard. I also don’t love the fact that the Harvard fight song is still “Ten Thousand Men of Harvard,” in a school populated by at least as many women as men, and yet hearing its opening notes can still make me deeply nostalgic. Moreover, I am appalled that all-male final clubs—fraternity-like eating clubs in which the sons of America’s privileged class have traditionally gathered—still exist on campus (albeit with sanctions) without commensurate opportunities, with rare exceptions, for women, minorities, and others, but I also call some of their alumni members my closest friends.

Intelligence, it has been said, is the ability to hold two opposing ideas at the same time and still function, and if universities could be said to have one overriding goal as institutions of higher learning, it is to teach its students this critical skill, Harvard no more than others. Seeing the coin from either of its two sides has never been more important, particularly now, in this nuance-lacking era of divisiveness and nationalism. It’s no wonder that in fascist regimes, the intellectuals are always the first to be silenced.

I believe in the benefits of diversity, even if it means choosing an immigrant kid with a lower-than-usual SAT score (for Harvard) but other stellar qualities, like Thang Q. Diep, Harvard class of ’19, whose application has been trotted out by the lawsuit for all to see. And I’m also aware, as a Jew, that Harvard’s diversity initiative was first put into motion as a way to keep the university’s burgeoning Jewish population in check. I can hold both of these truths—diversity is good; the roots of diversity in the admissions process were prejudiced against my own people—and not only still be able to function but also to see that sometimes good results can come from less-than-good intentions.

Because the point of diversity on a college campus, no matter its less-than-honorable roots, is not to count how many brown faces versus how many white and black faces a school has. It is to provide a rainbow of politics and upbringings and thought processes and understandings that might teach us, through our differences, how similar we are.

Though we all went to the same school, and Harvard’s name likely opened doors for many of us, at the end of the day—or at the end of 30 years since graduation, in this case—what was so fascinating about meeting up with my own richly diverse class during reunion was that no matter our original background, no matter our current income or skin color or struggles or religion or health or career path or family structure, the common threads running through our lives had less to do with Harvard and more with the pressing issues of being human.

Life does this. To everyone. No matter if or where they go to college. At a certain point midway on the timeline of one’s finite existence, the differences between people that stood out in youth take a backseat to similarities, with that mother of all universal themes—a sudden coming to grips with mortality—being the most salient. Not that this is an exhaustive list, but here are 30 simple shared truths I discovered at my 30th reunion of Harvard’s class of 1988.



Duoduo “Danny” Ying didn’t pay much attention to the UCLA chancellor’s school-wide memo that arrived in his email inbox last Wednesday. The note, also published on the school’s website, simply seemed to reiterate what he already knew: An unnamed student at the University of California at Los Angeles “had contracted the measles,” the chancellor wrote. Los Angeles County is one of several regions across the United States currently experiencing an outbreak of measles. The number of cases in the country is the highest it’s been since 2000, when the disease was declared eliminated in the United States.

The unnamed UCLA student had, on three separate days a few weeks prior, attended classes while sick in two buildings on the south side of campus. Ying wasn’t overly worried about the incident—he knew he had gotten the measles vaccine.

The university, however, didn’t know that. Ying, 19, is a sophomore majoring in economics and business who, like most underclassmen, lives on “The Hill,” a student-housing village on the western side of campus. He is also enrolled in the same Econ 103 course, and was sitting in the same lecture hall, as his unknown classmate who brought the virus to campus, according to an alert he received early last week via the university’s student-health portal. In retrospect, Ying acknowledges that he must have glossed over a subsequent message from the Ashe Center, the student-health hub, that read, in part, “It appears that you may not have received the measles vaccine.”

While the university had quickly confirmed measles immunity for most of the 500 or so people who’d somehow come into contact with the student carrier, it failed to locate the necessary records for 119 students as well as several staff members. Responding to an initial request for comment, a UCLA spokesman directed me to statements and information posted on the university’s website; he subsequently declined to elaborate.

For most of the 100-plus individuals quarantined at UCLA, record-keeping snafus—not vaccine avoidance—were likely to blame. University of California institutions only recently adopted a policy requiring incoming students to prove vaccination against measles. Only as of fall 2019 are all incoming students at UCLA subject to the requirement. For another thing, health records can be spotty, especially for people who had, say, an unstable or transitory upbringing, who were vaccinated in other countries, or who lack consistent access to health care.

Ying received a call from the Ashe Center around 4 p.m. the Wednesday the chancellor’s memo went out, instructing him to pack up his belongings and show up at Bradley Hall, an administrative building on the fringes of the student village, by 5 p.m. He was now under quarantine, per a legally binding order from the Los Angeles County public-health department.

“The Ashe Center sent a warning to students, like a week ago, from the Ashe portal, saying, ‘Hey, there’s this kid in these two [lecture] halls called Franz and Boelter,’” Ying recalls. “Then it says, ‘If you’re in those halls, please be aware.’ I didn’t think much about it. But after that, I received another email, and then the phone call.” Before he knew it, he was rushing to pack up his “shower stuff” and enough “essentials” to last him a couple of nights so he could make it there on time. “I was pretty shocked [when I got the call],” Ying says. “I was about to hit the gym—quarantine just messed up my schedule.”

UCLA’s quarantine expired once the clock struck midnight on Tuesday, in accordance with the county’s public-health protocols. Elsewhere in Los Angeles County, however, the measles outbreak is still affecting higher education. More than 600 students, employees, and visitors at California State University at Los Angeles were ordered into isolation last Thursday, 70 of whom remained quarantined at least as of Tuesday. According to a university spokesperson, those are the most up-to-date figures available.

One student told me he was released within 30 minutes of his arrival. When we spoke last Friday, he was still incredulous that he’d been flagged for quarantine in the first place: He never had a doubt he’d been vaccinated—plus, he always sits at the very back of Econ 103.

Ying’s stay lasted only a few hours. After he checked in with Ashe Center workers at a table in Bradley Hall, he was assigned to one of four gender-segregated rooms. Once he took his blood test to determine his immunity—the results of which wouldn’t be ready until at least the next day—“there was nothing to do … but just sit there,” Ying recalls. “People weren’t socializing.” The Ashe Center had stipulated that anyone who wasn’t cleared by 8 p.m. that day had to stay overnight. Ying had been vaccinated in China—where he spent much of his childhood and where his parents currently live—so he wasn’t optimistic that he’d be able to get his records in time to escape before curfew.

Some people around him were watching the Rockets-Jazz game while sitting on the hard mattresses provided. Others were eating. There was plenty of food: “pizza, salad, Indian—like naan and all the other stuff—pastries, soda, and everything,” says Ying. He and others were also able to keep in touch with people on the outside—they were free to bring cellphones and laptops into quarantine. Ying used his phone to get in touch with family members and ask them to look for his vaccination records, and to let his UCLA friends know he was fine.

“Before, 10 or 20 years ago, when someone was in quarantine, it was kind of hard to get hold of them,” he says. This time, “people would be texting me and I would update them on what’s happening—especially my roommates. They were like, ‘Hey, any updates? What’s going on?’ And we constantly kept in contact, so there was no aspect of Oh, is he going to be okay?”

Ying also used his phone to lighten the mood and “make the best of the situation,” he says, by making a TikTok video of his quarantine experience. Two of Ying’s buddies—twin brothers who are also in the Econ 103 class—wound up in quarantine, too, and they joined in, tackling each other with hard mattresses and shotgunning cans of Sprite. “We felt like, since it’s boring, why don’t we just make a video to make it seem lit?” Ying says.





Shortly before the 8 p.m. cutoff, Ying’s relative sent him his records, and he was cleared to leave. He would not have to sleep on a hard mattress that night. But he ended up sticking around until 9 p.m. anyway.

Why? “I was still in the process of making that video, so I stayed,” Ying reasoned. “I thought it was worth it.”



The ways in which schools and students think about the possibility of mass violence on campus changed a lot between the 1999 massacre at Columbine High School and the 2018 one at Marjory Stoneman Douglas High School. Dave Cullen’s last book, 2009’s acclaimed nonfiction work Columbine, chronicled the public and private lives of high-school students who survived the 1999 Columbine massacre as they grappled with the question of why this unthinkable horror had happened at their school. Cullen’s newest book, Parkland—about the activism of the survivors of the February 14, 2018, attack that killed 17 students in Parkland, Florida—follows a group of students determined to not let the world forget that of course this horror had happened at their school. Why wouldn’t it have? It was happening everywhere else. These students, unlike those who survived the tragedy at Columbine, grew up under the ever-looming threat of school gun violence, and then it materialized. Still, the Parkland kids’ back-to-school experience looked a lot like the Columbine kids’. They missed their dead classmates; they feared more violence in their classrooms; they had to fight through post-traumatic–stress symptoms to get to calculus on time.

There’s a developing set of protocols for how to handle the process of reintroducing kids to school after a shooting takes place on campus. As I reported last year, there are now “best practices” for how to reopen a school after a shooting, and that’s partly because many administrators at schools where a mass shooting has taken place call the administrators of the school that had the last mass shooting to ask for advice on how to ease kids back into the school setting. It’s one thing to hear about post-shooting protocols from experts, though, and quite another to see them in action through students’ eyes. Parkland, reported over the course of the 10 months after the shooting, mainly focuses on the gun-reform movement that took shape after the Douglas shooting, but it also paints a vivid portrait of what going back to school after a shooting is really like for students.

Douglas students returned to class two weeks after the shooting, on February 28, but on the Sunday prior, the school held an open house. In one of the book’s more heartbreaking scenes, Cullen notes how painful and scary the first reunion between students and their terrorized school can be. The high school that Sunday still felt, in some ways, like a crime scene: Helicopters hovered, capturing video of the school for TV news, and the sound of the chopper triggered anxiety and panic for some of the students who had heard the motors over their school the day of the shooting. One student notes that walking around that day, he and his friends heard a car engine go pop pop pop, “and we all started hyperventilating.”

When classes did resume, though, Cullen describes a school transformed into something more like a rehab center. Classes weren’t really classes at first: “So much Play-Doh, so many comfort dogs,” one student, Daniel Duff, says. (The Play-Doh he found somewhat ridiculous; the comfort dogs he found wonderful.) Another student, Lauren Hogg, describes coming back to school to find “therapists literally everywhere,” even in the school library. Their on-call availability, she says, was immensely helpful for students who were experiencing grief that came in waves, washing over them at unpredictable and sometimes inopportune moments.

The weeks that follow a school shooting, Cullen writes, are shaky. Students’ routines resume, and many find comfort in the returning familiarity and controllability of their days, but many still experience sudden moments of fear, worry, and sadness at school. When Matt Deitsch, the older brother of two of the survivors, tells Cullen about his little sister’s accounts of being at Douglas after the shooting, he says she’s one of many students who get anxious when they use the bathrooms. “She says, ‘Now when I go to the bathroom I think if I take a little longer to wash my hands maybe I’ll survive if it happens again,’ ” Deitsch says. Or sometimes she’ll take the long way back from lunch and wonder if this choice will save her life.

Many of the students Cullen spoke with mention the never-quite-normal presence of empty desks where students killed in the shooting used to sit. One student says sitting next to a slain friend’s empty desk in classes they used to share is “when it hits [him] the worst.” Another finds it haunting that during other periods of the day, “people probably sit there [in the conspicuously empty desk] and they have no idea this desk is the one we all look at in our class.”

Parkland also illustrates all the tiny ways in which the memory of a shooting can find ways to disrupt students’ lives even after their daily schedules and routines have long since picked back up. Before Douglas students performed their much-publicized production of the musical Spring Awakening last May, for example, their theater director had to confront the question of how, or even whether, to portray a fatal gunshot scripted into one of the final scenes. It was necessary to the plot of the show, she told Cullen, but it also seemed like an especially ghastly thing for this particular audience to have to witness. (Ultimately, the directors decided to keep the gun in the scene, but instead of a gunshot sound effect, they simply blacked out the lights.)

Throughout the rest of the school year, Cullen notes, certain events caused the student body’s emotions to flare up again—and they highlight the fact that the school is full of kids who are moving forward at different speeds and in different ways. Hogg, for example, found herself crying at school in April while looking over a special edition of the school paper dedicated to the 17 victims. Other students nearby laughed at her for weeping. Many kids felt bad about enjoying springtime school events such as prom when they knew their dead classmates couldn’t, while others balked at the idea of incorporating a memorial for the shooting victims into their prom event.

“Somebody brought up this idea of having something about the shooting at prom, and we were like, ‘That’s the worst idea you’ve ever come up with!’ ” one student told Cullen. Prom, the student added, needed to be a night when students could feel some modicum of normalcy kicking back in. In the end, prom included a 17-second silent tribute to the victims.

And graduation—“the most conflicted day” of recovery for school-shooting survivors—was a similarly fraught occasion, Cullen writes. To some seniors, it felt like a statement of strength, of fortitude in the face of tragedy. To others, moving forward into their college and adult years without their fallen classmates felt unfair.

Most of how Marjory Stoneman Douglas High School handled the aftermath of the shooting last February, it’s worth noting, tracks closely with what experts consider to be best practices, such as the open-house event before classes resume, the many counselors and therapy dogs stationed all over the building or campus, the slow easing back into academics in the classroom, and the heads-up to teachers that kids will be moody or upset or weeping on particular days for the rest of the school year. Cullen’s Parkland offers a rare and vital glimpse into what all these measures look like in action—and a reminder that no matter how many active-shooter trainings or lockdown drills have been implemented, no matter how many school-reopening protocols are in place, these tragedies cannot be prepared for before they happen or quickly resolved after they do.



Editor's Note: In the next five years, most of America’s most experienced teachers will retire. The Baby Boomers are leaving behind a nation of more novice educators. In 1988, a teacher most commonly had 15 years of experience. Less than three decades later, that number had fallen to just five years leading a classroom. The Atlantic’s “On Teaching” project is crisscrossing the country to talk to veteran educators. This story is the fifth in our series.

On a late February afternoon, Angela Crawford, an English teacher, stood in front of about three dozen Philadelphia educators—mostly young, black women—as they all swapped stories of small victories and challenges in their classrooms. Dressed in a “Black Lives Matter” T-shirt and slim black slacks, Crawford, at one point, reflected on what has helped her remain resilient while working in some of the nation’s least resourced and most segregated classrooms for 23 years.

“Black women are caretakers of everyone else but ourselves,” she said. “You need daily rituals for your mind, body, and soul to stay in this profession. No one is going to move me from my daily workout and sleep. Block out weekly time for yourself: sit in silence, read for pleasure, buy yourself a nice dinner and flowers. That’s how I will have energy tomorrow to honor, listen, and uplift my students.”

As a veteran black teacher, Crawford is an outlier in her hometown of Philadelphia—and in the country. Just 24 percent of Philadelphia’s public-school teachers are black, down from a third in 2001, in a district in which 53 percent of students are black. That mirrors a national pattern: Between 2003 and 2012, a net 26,000 black teachers disappeared from American classrooms, while the overall number of teachers grew by 134,000.

Crawford has observed firsthand the rise and fall of black teachers in the city. When she was a student in Philadelphia in the ’70s, the city’s schools were desegregating and federal and state governments were pouring extra resources into buildings serving black students to compensate for a long history of racial exclusion. A decade before that, black students and educators in the city led one of the largest youth walkouts of the civil-rights era, which resulted in more integrated schools, more black teachers, and the addition of African American history to the school curriculum.

Today, Martin Luther King High School, where Crawford has taught since 2014, is highly segregated: Ninety-three percent of its students are black and only 1 percent are white. It’s one of roughly 6,700 schools nationwide in which 1 percent or less of the student body is white. And it’s also in a state with one of the country’s most unequally funded education systems: Pennsylvania ranks near the bottom of the country in the state share of education funding, making districts such as Philadelphia reliant on property taxes to fund its schools, which deepens the inequities between rich and poor districts. Pennsylvania is also one of 14 states that send more money to their wealthiest districts than their poorest ones.

As fellow black colleagues have left the profession, Crawford has doubled down on organizing as a way to improve the quality of education for her students. She is a member of the racial-justice committee of the Caucus of Working Educators, a local chapter of the Philadelphia Federation of Teachers union. The group brings together teachers, students, and parents calling for the recruitment and retention of more black teachers, fewer police officers, and anti-racist training for teachers.

Crawford and her fellow organizers have been pushing back against the presence of police officers at schools, metal detectors and body scanners for children, punitive rules, and classrooms focused on standardized tests—which they believe lead teachers to behave like police officers rather than educators. While such approaches are meant to improve the safety of students, studies have linked them to increases in harsh disciplinary tactics and out-of-school suspensions, which disproportionately affect black students. “This climate is dehumanizing and creates obstacles to forming the kind of relationships that promote intellectual engagement,” Crawford said.

As a result, Crawford often tells young educators that sometimes they must resist policies they consider pedagogically inappropriate in their classroom. Crawford insists on foregoing worksheets and multiple-choice questions geared toward state tests in favor of assessments that she views as more rigorous and relevant for success in work and life: open-ended writing, speaking, listening, presentations, and performances.

As an adolescent, she earned the nickname of “professional student” for always carrying around half a dozen books in her backpack—most of which came from her home library. Crawford’s mother spent much of her time and limited money building a large library, with books from authors such as Marcus Garvey and James Baldwin. “Everything I learned about black history and culture before college came from home,” said Crawford, who spent most of her school years in predominantly white Catholic schools. “In our home, the most common directive you heard from my mother was, ‘Go read a book.’”

That bookishness led to success at school, but didn’t inoculate her from jeering classmates. In her elementary school, Crawford was one of just three black students in the building. These were some of the toughest years of Crawford’s childhood, filled with racist slurs and abusive comments from classmates about her big, thick-rimmed glasses. In third grade, Crawford’s teacher told her that she wasn’t smart enough to be in her school and should consider finding another one.

By sixth grade, Crawford was plotting her first act of protest. “I don’t like how you are treating me,” she told a teacher. “I’m not coming back.” Soon after, Crawford’s mother transferred her to another Catholic school with more black students.

In the last year of middle school, Crawford transferred to the majority-black neighborhood school. There, for the first time, Crawford experienced both high academic expectations and a sense of belonging as a student. At E. Washington Rhodes Middle School, Crawford had her first experience with veteran black teachers in the classroom. “These women put on their best clothes to school every day: stilettos, dresses, beautiful coats,” she told me. “They loved their jobs. They loved the kids. And they pushed you to do your best work every day in a disciplined, no-nonsense way.”

Around this time, Crawford decided that she wanted to become a teacher, so that she could help create the kind of classrooms that allowed her and her black classmates to thrive in school. She noticed that veteran black teachers—and many of their white colleagues who learned from them—ran rigorous, well-structured classrooms, but also got to know their students’ personal lives and intellectual interests. They knew when a student needed a push, cheering up, or help calming down. They knew how to organize adults in the school and enlist help from a student’s community to ensconce each child in a supportive web of high expectations and warm relationships. “My college counselor reminded me of my grandmother,” Crawford said. “These women were your mama, auntie, disciplinarian, coach, and your biggest cheerleader.”

In 1997, after becoming the first in her family to graduate from college, Crawford returned to E. Washington Rhodes Middle School as an English teacher. By then the school had fewer black teachers, but most were still veterans who coached younger teachers and established a school climate of high expectations and relationships that resembled familial bonds. Crawford’s alma mater still had arts and music programs, many student clubs, a library, a gym, and a robust maintenance staff to keep the building in pristine shape.

Two decades later, because of school resegregation and chronic budget cuts that have accelerated in recent years, most of those student clubs and electives have largely disappeared. Martin Luther King High School has no library. The school employs twice as many school police officers as it does counselors, and students have to pass through metal detectors before entering the school. As pressures to deliver higher test scores have increased, public displays of individual student outcomes on multiple-choice tests have replaced the student essays and art that used to adorn many classroom walls.

With so relatively few veteran black teachers, Crawford feels a unique responsibility to show her African American students that their lives, interests, and culture really do matter. Behind Crawford’s desk, underneath a large “Education Is Liberation” poster, are pictures of black icons that students read in her classes—James Baldwin, Malcolm X, Martin Luther King Jr., Angela Davis, and Octavius Catto, a local anti-segregation organizer and teacher murdered for his activism in 1871. In Crawford’s English classes, she includes many historic texts by black authors to highlight the intellectual and cultural contributions of African Americans, as well as narratives of black triumph over racism.

Crawford told me that culturally relevant content promotes students’ engagement in their work and reduces the number of disaffected students—and the reliance on suspensions as a way to manage them. Most importantly, Crawford believes that black authors help students develop an understanding of why racial disparities persist—even among black students earning high test scores or living at the top of the economic ladder—and help kids see how critical thinking through writing can challenge the power structures that maintain such disparities.

“Ms. Crawford finds books that connect to our lives,” says a senior in one of her classes who is not being identified by name since he’s a minor. “In other English classes, we read textbooks, and study metaphors and similes from copied articles. Here, we study ideas, learn our history, and prepare for the real world.”

Crawford told me that her generation of educators is fighting to continue this tradition centered on black culture and relationships—at a time when the need for such support has only multiplied. Today, Philadelphia struggles with higher rates of poverty than when Crawford was a student in the ’70s, and schools have become more segregated since Crawford began teaching in 1995. Half of Philadelphia’s poor residents are black—and 29 percent of them live in racially isolated areas of concentrated poverty, many in West and North Philadelphia, where Martin Luther King High School is located.

Her students often have a lot to deal with outside of school: Gun violence and public brutality are rampant, as are foster care and homelessness. “Some of the things our children face today, I would never have had to deal with as a kid myself,” Crawford told me. “Many of my students have witnessed their friends being shot; some live with grandparents because their parents struggle with various hardships; others are homeless.”

Right below the portraits of Dr. King and Angela Davis, Crawford keeps a memorial box for the names of her students’ lost family members and friends, surrounded by electric candles and African mud cloths—which Crawford uses as symbols of the resilience and creativity of people in the African diaspora. Recent studies suggest that caring relationships—rather than reactive punishment, such as out-of-school suspensions—can help buffer children and teens against the long-term health effects of chronic stress and trauma.

“At the beginning of the school year, I tell students, ‘If you want to pay homage to someone, put their name in the basket,’” she said. “I want them to know that if they are hurt, angry, or grieving, I understand that and will create space for that. When students feel that they won’t be judged, that they can bring their full selves—intellectually, emotionally, spiritually—they are much more likely to trust the learning process and take intellectual risks.”



Updated at 3:04 p.m. ET on October 30, 2018.

Besie Katz runs an Orthodox Jewish day school in Northeast Philadelphia. During Sunday classes this week, her students were confused and saddened by the shooting that had taken place at a synagogue the previous day on the other side of the state of Pennsylvania. “The overriding question” they had, she says, “was, in different iterations, how could somebody do something like this? How could this have happened? And of course, that’s the hardest question to answer.”

She told her students at Politz Hebrew Academy that “hatred consumes people like a fire,” and she stressed that Saturday’s killings were the awful result of someone who had given up on compassion, kindness, and empathy. “They seemed comforted by that,” she told me, “as much as you can be.”

Over the weekend and into the week, Katz and other educators at Jewish schools around the country have been considering how best to help their students make sense of the actions of a gunman who reportedly yelled “All Jews must die” upon entering the synagogue. In speeches, smaller group discussions, and all-school gatherings, they attempted to explain the Pittsburgh shooting, even as they sought answers themselves.

Jonathan Kroll, a rabbi and the head of school at Katz Yeshiva High School of South Florida, convened his roughly 350 students before classes started on Monday. Saturday’s shooting was particularly resonant on the Katz Yeshiva campus because it’s only a 15-minute drive from the city of Parkland, where earlier this year 17 students and staff died in a shooting at Marjory Stoneman Douglas High School. “Unfortunately, we had a little bit of practice last [school] year talking about this and addressing it in the wake of the Parkland shooting, not from an anti-Semitic perspective but from a school-safety perspective,” Kroll told me.

After he and his students prayed together, he delivered remarks about the synagogue shooting. “I said, ‘We have to be vigilant and careful and realize that anti-Semitism is not a relic of the past. It’s not something that lived in Europe 70 years ago’ … But I tried to reassure our students that we really have a very safe environment here, and they should be vigilant but feel confident and not scared.” Additionally, he reminded them that “the vast majority of people are good people who care about us, who wish us well.”

Kroll’s audience was made up of high schoolers, and educators elsewhere also calibrated their messages about the shooting based on students’ ages. Ari Leubitz, a rabbi and the head of the Atlanta Jewish Academy, a modern-Orthodox school, sketched for me a rough timeline of students’ readiness. Because the academy “runs from newborns to high school,” Leubitz had thought a lot about what was age-appropriate. “Infants through fourth grade … we don’t bring it up,” he told me. This was in line, give or take a year, with what other school leaders told me.

Around fifth or sixth grade, Leubitz said, students start to have questions and reflect on their emotions, so they’re readier to discuss tough subjects. By seventh and eighth grade, “they want to be able to talk it through and come to a solution,” Leubitz said. “When you get to high school, then it shifts from the ‘what happened’ to the ‘why it happened’ … At that age, I want to fix it. What am I going to do to fix it?”

That was a question that students had at Golda Och Academy, in West Orange, New Jersey. “Our 12th graders, they’re angry,” Adam Shapiro, the head of school, told me after meeting with them. “They’re angry about the environment of the world they’re living in right now, where hate is becoming so prevalent. They were looking at me and saying, ‘We want to act—we don’t want to be passive.’” He noted that many of them will be voting for the first time next week.

All the Jewish-school leaders I spoke with said that their minds went to campus security—something that is in their control—after the Pittsburgh shooting. “It’s hard to get much more secure than we [already] are,” Kroll said. “We definitely had something of a wake-up call after the Parkland massacre last year.”

Leubitz, of the Atlanta Jewish Academy, said that another issue on his mind was how he was going to give his staff (and himself) the time and space to process and mourn, so that they would be able to do the same for their students. “I think it’s very hard for [teachers and parents] to not have the answers,” he told me. “We want to say ‘There’s an answer to this,’ and it really hurts because we can’t say ‘It’s going to be okay,’ because many of us don’t believe that.”



The Newseum was in dire financial straits, and needed a way out. Johns Hopkins University had four buildings in Washington, D.C., and was looking to expand its presence in the capital while consolidating into one space. That the Newseum’s prime property is located within blocks of the U.S. Capitol only helped. On Friday, the university announced that it would be buying the 250,000-square-foot building; the museum is now looking for a new home.

In an interview, Ronald Daniels, the president of Johns Hopkins, told me that the purchase is an opportunity to position the university, literally, to better contribute its expertise to national- and international-policy discussions. He emphasized that the school won’t be decamping from its main campus in Baltimore, but that the purchase will give it a more pronounced presence in D.C., which several colleges, including New York University, Arizona State University, and others, have sought to leave their mark on.

Making this acquisition possible is a string of wealthy donors that the university has been cultivating for some time. Daniels confirmed that Michael Bloomberg, the billionaire philanthropist and a Johns Hopkins alum, will be contributing to the purchase. The remainder of the money will come from the university’s budget and the sale of the institution’s other four properties in the city. Daniels did not disclose how much financial support the university will be receiving from Bloomberg, who has donated billions of dollars to Johns Hopkins over the years and announced a $1.8 billion donation to the school in November. (His contribution to this project will be separate from the November donation.) Daniels did add, however, that Bloomberg is not the only philanthropist who will be financially supporting the purchase.

“This was a difficult decision, but it was the responsible one,” Jan Neuharth, the chair and CEO of the Freedom Forum, the organization that runs the Newseum, said in a statement. “With today’s announcement, we can begin to explore all options to find a new home in the Washington, DC area.” As the deal is ironed out and finalized, all of the Newseum’s artifacts will be archived. The sale of the Newseum, a shrine to journalism, comes as more than 1,000 journalists have been laid off across the country this week. Several writers, most notably Jack Shafer, have argued that instead of purchasing the behemoth space back in 2008, the Freedom Forum should have used its money to hire, fund, and advocate for journalists.

The deal is not yet final, as the university needs to get approval for government permits to convert the space for academic use. But in a letter to the campus community, Daniels wrote that “Johns Hopkins’ acquisition of the building also provides financial support for the Freedom Forum’s vitally important First Amendment mission.” The School of Advanced International Studies, which has been located in D.C. for decades, will anchor the university’s offerings in the city. “This is a great moment for us” to really add to the public-policy debate, Daniels told me. But it is also a power move for a university that ping-pongs in and out of the top-10 rankings—one that may lead more students to salivate over the school, and improve its status.



When Eric Ushiroda moved to a tiny Japanese village in the mid-1990s to work as a teacher, there was one thing he learned almost immediately: His middle-school students in this chilly, forested town were obsessed with L.L. Bean backpacks. A recent graduate of the University of Hawaii who’d applied for the teaching job as part of an exchange program, Ushiroda didn’t own winter clothing. Mail-order catalogs were the easiest way for him to get what he needed, living in a rural town. So he ordered some thermal underwear and fleece jackets from L.L. Bean.

He also bought the “Original Book Pack,” and, naturally, got his name monogrammed on it. Might as well, he thought. It was free.

Little did he know that his seventh-through-ninth-graders would instantly become infatuated with it—something about the shiny reflective strip, the monogram, and the polyester material made it inherently cool in the ’90s. So Ushiroda got the school to purchase a bunch more—in red, navy, and black—for his students. Now a 46-year-old human-resources director who lives in Cleveland, he still remembers their excitement.

In the ’90s, L.L. Bean backpacks weren’t just cool in Japan, where the company had long enjoyed a cult following, but in American schools as well. “That's just what I understood a backpack to be. Like how a [Band-Aid] is a bandaid,” Abby Reisner, a 25-year-old New York City-based food writer, explained in a tweet. It was, Reisner admitted, also her go-to bag simply because her mom would hand her the catalog and say “choose.” She typically opted for a pink one with both her monogrammed name and an extra butterfly patch.

When I asked on Twitter last week whether people had an L.L. Bean backpack when they were kids, I got many similar nostalgic responses from young adults who were in school in the late ’80s and ’90s. About half of the roughly 100 respondents to my unscientific poll said “yes,” while the other half said “no”; only 1 percent said they didn’t remember. Popular colors included lime green, eggplant, and blue camouflage.

It’s little wonder people feel such an emotional connection to their old backpacks. Backpacks are one of the most ubiquitous and constant material items in a kid’s life. Unlike workbooks and crayon boxes, which have a lifespan of just a single school year, a backpack often travels with a kid from grade to grade, sometimes parting ways with its owner only after she decides it’s no longer her style or after its foam straps have disintegrated and its wax-coated canvas is riddled with holes. At school, kids have other opportunities to personalize their learning space, by decorating cubbies or lockers, but backpacks travel with them—to sports practice and after-school tutoring and on the school bus. Backpacks bridge the distance between school and home, shuttling homework and lunchboxes and beloved toys for show-and-tell in between the two most important places in a kid’s life.

“We change our clothes each day. But for most of us, the bag remains the same,” Andy Fallshaw, a cofounder of Carryology, a bag-review website that is funded by an Australian bag-and-wallet company, said in an email. In that sense backpacks are similar to shoes, watches, and sunglasses, other accessories that are seldom changed and which often also serve as status symbols. But Fallshaw contends that backpacks are a “bigger and more expressive canvas”: “You can fail to notice a watch,” he said, “but it's hard to not notice a backpack, and it's the same one each day.”

Backpacks are, for better or worse, integral to the popularity hierarchy, and to “tribe signalling,” as Fallshaw put it. In the earlier grades of the K-12 saga, the trendy backpack tends to feature whichever superhero or cartoon hero children like most, he said. But things get more complicated in adolescence, when the brain grows more dramatically than at any other point in life and kids become more self-aware, and, sometimes, self-conscious. Backpacks’ ubiquity and constancy gives them more social signaling power than, say, a cool shirt that a kid wears for one day.

It’s not only the backpack itself that signifies coolness or nerddom, but how one carries it. “Most [high-]school kids will want to release the straps right out so the bag hangs low, bouncing around their butt in a way that breaks every ergonomic principle,” Fallshow says. These trends come and go as well. According to a 2013 Slate investigation, for decades, the cool thing to do was to sling one of its straps over your shoulder—“one-strapping,” as Channing Tatum put it in a scene from 21 Jump Street.  But in the mid-1990s, according to Slate, “two-strapping” began to take over, and by the mid-2000s had solidified its cultural dominance. The way Fallshow sees it: High school is when kids navigate their identities and decide whether to tilt toward “conformity” or toward “rebellion.” And for him, this instinct can be leveraged for good: It’s an opportunity to explore their growing independence.

Backpacks are “an extension of personality,” says Rico Pasqualini, the president of JanSport, though popular styles evolve, and the backpack’s coolness has ebbed and flowed over the years. It was briefly eclipsed by items like messenger bags and satchels in the mid-2000s. Right now, according to Pasqualini, it's having a bit of a renaissance in the U.S., in part thanks to heightened interest in “festival bags,” small backpacks that have become trendy at Coachella and other music festivals. A little under a decade ago, bold colors and prints were popular in the teen market, Pasqualini says; today, preferences tend to be more conservative, with more teens opting for solid colors.

Still, the backpacks kids initially choose are often just canvases that they then customize even more—with Sharpie-scrawled song lyrics and keychains, patches and pins—to show their idiosyncrasies and signal their tribes. Perhaps that’s one reason there was so much backlash to the idea of transparent backpacks earlier this year, when news spread that students at Marjory Stoneman Douglas High, the site of the February Parkland massacre, would have to use them for safety reasons. It was a violation of students’ privacy, many said at the time. The fact that this invasion was centered on backpacks—one of students’ most personal, intimate possessions—likely intensified people’s reactions. After all a backpack goes through with a kid, Pasqualini says, it “becomes a partner in life.”



When I return to my parents’ house and the neighborhood where I grew up, the tension between sameness and difference is disorienting. The gym is still there, but the bookstore where I hung out after school is now a Target. There are new neighbors renovating the house next door. My parents might turn one of our childhood bedrooms into a study. I see versions of my old self in local kids, running around the back alley or aimlessly browsing our local Sephora. They make me feel both nostalgic and relieved to be an adult.

That’s when I find myself reaching for a comforting set of pastel-colored spines on my childhood bookshelf: L. M. Montgomery’s classic Anne of Green Gables series. My mom first read it to me when I was a toddler, and I’ve been rereading it ever since. For many years, the main draw was Anne’s love interest, Gilbert Blythe, whom I had a crush on. But now I read it more for the compelling female friendships—“bosom friends,” as Anne would call them—and the gorgeous descriptions of the jewel-toned countryside. Most of all, Anne’s home of Avonlea, animated by Anne’s idealism and exuberance, feels like a refuge from the real world, where those traits can be hard to find.

People’s favorite childhood stories often stick with them throughout their lives. When the book-centric social media site Goodreads tracked the books most reread by its users, many of them were children’s books, including J. K. Rowling’s entire Harry Potter series, C. S. Lewis’s The Lion, the Witch, and the Wardrobe, and Antoine de Saint-Exupéry’s The Little Prince.

For many, having kids of their own provides an opportunity to share these beloved stories with the next generation. But revisiting them alone as adults can also provide comfort, relaxation, and the pleasure of rediscovery. Not only do rereaders rediscover the story, but they may also rediscover themselves.

Rereading “reminds us that we can experience something intensely and not be seeing everything at the time. And going back, we see something different,” says Jill Campbell, an English professor at Yale. “It’s a way of thinking more about a book that’s had an impact on you, but it’s also a way of thinking about your own life, memories, and experiences. The continuities and the differences.”  

The literary critic J. Hillis Miller once wrote about revisiting a beloved childhood book, Johann David Wyss’s The Swiss Family Robinson, much later in life. The book tells of a family shipwrecked on a desert island, where they must fend for themselves in the wild. Miller was immediately brought back to “that wonderful, safely uninhabited, tropical island, teeming with every sort of bird, beast, fish, tree, and plant,” he writes.

The experience also brings him back to his childhood, transcending the passage of time. He remembers camping trips with his family, where “equipped with no more than you could carry on your back, you could ‘set up camp,’ cut some fragrant balsam boughs for bedding, make a camp fire for cooking and heat and, in short, create a whole new domestic world in the wilderness,” he writes. “I can still remember the pleasure of falling asleep in the open-fronted lean-to with the other children, wrapped in my blanket (no sleeping bags then), smelling the balsam, and listening to the murmur of the adults’ voices as they sat talking by the dying campfire.”

There is an allure to the repetition of rereading, submitting to the rhythms of a narrative, place, and characters you know well, and the familiar emotions they evoke. Rereading also has a different pace. I tear through a book on the first read, to find out what happens next, but rereading feels mellower and more leisurely, even while relearning the parts I’ve forgotten.

The takeaways are often different too, when reading a book through the lens of adulthood. Rosalie Knecht, a writer and licensed therapist who writes Literary Hub’s “Dear Book Therapist” advice column, has carried her copy of William Steig’s Dominic, inscribed to her uncle and dated “Christmas 1973,” with her through many moves. Dominic follows a dog on an adventure, which ultimately ends in a garden that feels like home, though he’s never encountered it before.

“What it is is: He’s found love,” she says. That didn’t mean anything to her as a child, she says, “but when you’re an adult it’s like, ‘Oh, wow, it is like that.’”

Those adult pleasures can also be comingled with disappointment if the book doesn’t live up to the sentimental memory you have of it. Campbell, the Yale professor, still owns her childhood copy of E. B. White’s Charlotte’s Web. She read it to her son when he was young, and recalls it was the first book that ever made him cry.

To this day she says she admires the writing, humor, and characters of the classic, and she even includes it in the curriculum for a class she teaches about children’s books. But she and her students have noticed that the character Fern, who as a young girl saves and cares for Wilbur the pig, grows up to prioritize a crush on a boy instead.

The book is “about the kinds of powers children have, their powers to listen and attend, to care and fight for things,” Campbell says. It also “has this limited view of what girls can do when they grow up. But I think you can have both those experiences of reading at the same time.”

Another potential disappointment is that rereading can reveal how your childhood canon excludes other perspectives, Campbell notes. She’s added Gene Luen Yang’s graphic novel American Born Chinese and Louise Erdrich’s The Birchbark House to her syllabus, books for young people that respectively center around Asian American and 19th-century Native American characters. And she says she’s found that many of her students are reading them for the first time in her class—they weren’t exposed to these stories growing up.

When childhood favorites retain their magic though, they can serve as an anchor over the course of one’s life. Well-loved books stay the same even as so much else changes. That constancy can be comforting. In another childhood favorite of mine, Tamora Pierce’s Trickster’s Choice, I know exactly how the protagonist Aly’s life is going to shake out, even if I don’t know exactly how mine will. She will overthrow the colonial regime every time, install a female ruler, and then marry her boyfriend—once he turns from a crow into a man.

In a 2012 study that looked at why people reread books, rewatch movies, and revisit the same places, the researchers interviewed 23 participants about which experiences they chose to repeat, why, and how they felt during it. They found that repeat experiences “allow consumers an active synthesis of time and serve as catalysts for existential reflection.” Childhood books offer an opportunity to sit down in the river of time, if just for a moment, and ponder the full scope of one’s life. For one woman in the study, who often rewatched the 1999 romantic drama Message in a Bottle, the movie helped her process an upsetting breakup.

Knecht, the writer and therapist, says of rereading that “when you’re feeling stagnant, like you’ve made no progress, it gives a shape to that experience and suggests it will pass.” In that way, it can be therapeutic because “therapy is about telling your story and having someone challenge you sometimes about the way you’re telling that story,” she says, “until you get it into a shape that you can live with and move forward with.”

For the literary critic Miller, rereading The Swiss Family Robinson seemed to remind him of why he chose his profession in the first place. Like the family Robinson did on the island, “the reader of the book creates within his or her imagination a new realm,” he writes, a world that is “more real, and certainly more worthy to be lived in, than the ‘real world.’” Rereading the book for the first time in about 65 years, he writes, “I have been as enchanted, or almost, as I remember myself being at my first reading, or about the age of ten.”



BOSTON—In the days leading up to the trial accusing Harvard of discriminating against Asian American applicants, supporters of the university worried that the group behind the litigation, Students for Fair Admissions (SFFA), would turn the case into a broader attack on affirmative action and race-based admissions policies. It’s one thing to say the use of race in admissions is negatively affecting a minority group to the benefit of white students, but a completely different thing to say that the advantage is going to other minority groups.

On Monday, the first day of the three-week-long trial, their fears were realized as the plaintiffs presented their opening arguments in a nondescript Boston courtroom. “The future of affirmative action is not on trial,” Adam Mortara, the lead attorney for the plaintiff, said. After all, the Supreme Court has been clear that colleges can consider race in admissions as a way to create a diverse class. But Harvard had gone beyond that, he told Judge Allison Burroughs.

The first 15 minutes of Mortara’s monologue were a broad outline of the ingredients that Harvard uses to judge applicants—among them, academic rating, athletic ability, extracurricular involvement, and personal rating. Students are assigned a score for each characteristic. SFFA alleged—and Harvard disputed—that all these characteristics, besides personal rating, are based on objective markers, such as SAT scores and grades for academic ability. And in every objective category, Asian Americans score higher than white applicants. “What we’re saying is that Asian Americans do better than white applicants on every single objective rating, outside of the subjective personal rating,” Mortara said. The personal rating, he continued, is what is most suspect about the school’s admissions process.

By this point, Mortara had spent most of his time comparing white and Asian American applicants. But then suddenly, it seemed, his speech shifted. Asian Americans, he argued, do “dramatically and shockingly” worse than both African Americans and Latinos in the personal ratings.

Then the speech shifted back to a traditional argument that SFFA has been making for months: The university’s admissions system discriminates against Asian Americans because of the gigantic incentives that are given to mostly white groups, such as recruited athletes, of whom roughly 80 percent of applicants are admitted, and so-called legacies, students whose close relatives attended Harvard. But sandwiched between that argument, in a statistical analysis compiled by SFFA’s expert witness, was another nod to how other minority groups, not just white students, are benefiting from Harvard’s admissions policies. A chart compiled by the plaintiffs showed how students with certain characteristics were much more likely than Asian Americans to get into Harvard: High personal ratings, African Americans, and legacy students were the top three.

As the lawyers for the plaintiff shifted back and forth on who is the beneficiary of Harvard’s allegedly discriminatory admissions policies, the university toed the line that it is not treating Asian American applicants unfairly. “Harvard never considers an applicant’s race in the negative. If it considers race, it’s always considered in the positive,” said William F. Lee, the lead trial lawyer for the lawsuit against the university. “The fact that it considers race in a positive doesn’t mean it’s negative in another case.”

But SFFA contends that Asian Americans do have a negative penalty—and it’s keeping qualified applicants out. The shift toward a broader argument against the use of race in admissions is quick and subtle, but it’s there. The case has always hinged on the notion that Asian Americans are being discriminated against, but the answer of who SFFA believes is the undeserving beneficiary was made clear. And the lawyers answered the question of how they would transition to a broader critique of affirmative action: slowly, then all at once.



Like most other college presidents, R. Gerald Turner, the head of Southern Methodist University, where my son is a student, sends correspondence only when something goes terribly wrong. When I received a mass email from his office this week, I assumed the school had gotten caught up in the fallout of Operation Varsity Blues, the college-admissions cheating and bribery scandal that came to light last week.

But Turner’s missive turned out to be preemptive instead of apologetic. The scandal offered SMU “an opportunity to add to the ongoing review of our process,” he wrote. The university, he explained, must rely on the accuracy of materials submitted by students, including SAT scores. Turner announced that the university intended to review the records of any students associated with “The Key,” the college-counseling firm run by William Singer, the alleged fixer who is accused of paying bribes, facilitating cheats, and creating fraudulent materials to help wealthy parents get their kids into elite schools such as Stanford, Yale, and the University of Southern California.

The message was defensive. “Our goal in conducting this review is not to cast doubt on any student’s qualifications for admission,” he wrote, “but to safeguard the reputation of the admission process for all of our students.”

When Singer’s operation was exposed, it was met with widespread shock and dismay. The frustrating realization that a different set of rules applied to the wealthy was only temporarily alleviated by the schadenfreude of watching those rich people, including famous actresses, get indicted for felonies.

But a week later, academia is already entrenching to defend its admissions practices, as the SMU president’s email exemplifies. For Turner and other leaders of elite colleges, the scandal is more than embarrassing; it is existential. If colleges such as USC and Stanford can’t prove that their admission process is uncompromised, then the value of that acceptance—and the credential that comes with it on graduation day—is put at risk. That risk trickles down too. SMU isn’t Stanford or Yale, but it has called USC, which was caught up in the scandal, an “aspirational peer”—that is, an institution whose reputation it longs to match.

Operation Varsity Blues is being called a “cheating scandal,” but that name lets the entire process off the hook, as if a few dozen bad actors had sullied an otherwise operative and noble system. In truth, the alleged criminals who swindled SAT scores, faked athletic records, and bribed university officials might actually show a better way forward, despite their ultimately corrupt approach. The only way to make college admissions equitable is to reject how the process is currently conducted. This scandal opens the door to that demand, but it’s up to students, parents, and educators to burst through.

College admissions have been a mess for a long time, but Operation Varsity Blues attached names and faces to the problem. It’s always easier to dole out blame to particular people rather than abstract groups such as one-percenters (or nine-percenters). Singer’s clients were real people, some of whom you probably already knew: They are lawyers, financiers, fashion designers, and, yes, famous Hollywood stars. It didn’t hurt that the law brought the hammer down on these transgressions of the wealthy. Some of the perpetrators were indicted for fraud. College employees lost jobs for allegedly taking bribes. Netflix dropped Lori Loughlin from the Full House reboot. When misdeeds finally catch up with rich folk, it’s easy to celebrate their downfall.

But criminal indictments might let the college-admissions racket off the hook too easily. It’s certainly more illegal to bribe and swindle your child’s way into USC or Yale by cheating on college-entrance exams or faking athletic prowess. But is it less moral to cheat brazenly like that than it is to donate millions to a target university, or to pay tens of thousands of dollars for preparatory private school each year, or to spend thousands of dollars on test-prep tutors, or to ferry your kids from soccer practice to orchestra lessons to bulk up their profiles as college-worthy? These are but a few common methods for the wealthy to help their children “earn” a place in elite universities. As Shamus Khan, the author of a book on the subject of elite scholastic privilege, put it after the scandal broke, “Rich parents spend millions on their children to make them ‘better’ than others.”

When it comes to vice, it seems self-evident that spending money on legal services is more virtuous than spending it to commit fraud. But if admissions are already rigged for the well-off, then the moral scales might tilt differently. If the system is unfair, then defending it against those who might reject it only serves to enshrine the system as fundamentally virtuous.

Take college-entrance exams such as the SAT and the ACT. These exams hold currency because the overwhelming majority of institutions use them as a critical part of the admissions process. The tests are called “standardized” because they are supposed to work the same for everyone. But in practice, that’s hardly the case. There’s a cottage industry of books, classes, and private tutors that offer practice exams and test-taking tricks to help the well-to-do gain an advantage. Even if relatively little money is spent, being able to commit a lot of time to take practice tests or to acclimate oneself to the weird, artificial conditions of the exam’s format can go a long way. Just taking the test a few times pays dividends—which wealthier kids, more so than others, can afford to do.

These and other factors make it possible, even if not easy, to approach a test such as the SAT as an opportunity to be maximized, rather than as an evaluation of performance. Over time, anyone can become better at something with practice. Students who improve at the SAT certainly demonstrate a kind of adeptness. But their score might or might not represent their aptitude to do anything other than take the test.

But the impact of the SAT and the ACT does not end upon admission to a college. Test scores are sometimes used to qualify admits for merit-based scholarships. They can persist in other ways too. At the Georgia Institute of Technology, where I teach, someone found that one factor could accurately predict whether computer-science students would struggle: their SAT math score. There are good and bad ways to use that information, but it might surprise some students to learn that their test scores continue to affect their educational experience long after admission.

The well-off families who pay small or large sums to game the SAT legally do not commit fraud in so doing, which is good. But they do buy into the concept of testing, accepting their fates as pawns in the larger game of meritocracy. By contrast, the fraudster parents who paid to falsify or doctor SAT or ACT results opted out of that game. They did so from a position of massive wealth and privilege, of course, and only for personal gain. Even so, they point the way to a more equitable and moral approach to college admissions: one that rejects the current system at its foundation, rather than accepting it as righteous and necessary, but temporarily compromised.

Writing at The Washington Post, Valerie Strauss wondered whether the scandal means it’s time to get rid of the SAT and the ACT entirely. Every year, more colleges and universities go “test optional” or “test flexible,” meaning that their admissions process relaxes the role of standardized tests. That approach can benefit students who just don’t test well, so long as they appear worthy in other ways. But those “other ways” might also come with strings.

Some schools are text-flexible in name more than deed, replacing test scores with other metrics, such as grade-point averages or high-school class rankings. Others require the SAT, but use it only if those other, numerical data don’t reach a particular threshold. Still others require test scores only from out-of-state students, a way to reward the families who are tax-paying citizens of their home state. And some schools don’t require test scores at all, relying instead on more qualitative methods of evaluation for acceptance. That works well for smaller, more exclusive schools, but it’s hardly an answer for everyone.

But neither is digging in heels and doubling down to protect the sanctity of the existing system, as Turner, SMU’s president, did. “I know that you have been concerned about the scope of this fraudulent scheme, as I have been,” he wrote to me and other parents. It was an appeal to vanity as much as righteousness. When Operation Varsity Blues produced 50 indictments, some parents felt wronged because a slot claimed by fraud might have gone to their own son or daughter. It’s an infuriating idea, but also an affirmation of general satisfaction in the system—provided it works in one’s own favor.

The College Board, which administers the SAT, issued a statement after the investigation and charges came to light, shirking responsibility for the wrongdoing of test proctors, who are selected by local schools, and affirming its commitment to preventing cheating on the tests. The organization also noted that SAT practice is available for free online via Khan Academy, although those lessons still require reliable access to a computer and an internet connection—not to mention knowledge that the practice is available in the first place.

Standardized tests are only one component of the admissions process too. Grades and class rankings are also important, and so are extracurriculars such as sports and music and volunteering, since every applicant is expected to be “well rounded” as a teenager. Fulfilling that demand has incited an arms race. The stakes get higher, and everyone who has a shot feels the need to rise to meet them. That creates a cycle in which college students gain an advantage based on their parents’ wealth, and then repeat the process with their own kids years later.

Educators, students, and parents have waved indignant fists at these cheaters, but have then gone right back to the grind in order to play the admissions game in earnest again. Singer’s clients may have wronged their children and the institutions that were their victims, but there’s some inspiration to draw from them nevertheless: They opted out of the racket—even compared with their wealthy peers, who hustled to buy their advantages indirectly and over time.

Let’s not praise these alleged crooks too eagerly, of course. It’s easy to sidestep the college gantlet when your parents are multimillionaires, like most of the families implicated in Singer’s scam. But it’s also pathetic to scoff at the rich fraudsters just to return to the hopeless scramble that already tilts the scale toward the rich. Unless the public demands change in the wake of Operation Varsity Blues, elite colleges and the wealthy families who can afford them will harness the scandal’s energy to insulate themselves. That process has already begun.



New York City’s specialized high schools are a model of opportunity. They have stellar academic records, and, being public, they are free to attend. Their alumni tend to go on to elite colleges and prestigious careers. Together, the schools serve close to 18,000 students each year, and at eight of the nine schools, admission is determined based on how middle schoolers do on a standardized test.

That test—called the Specialized High Schools Admissions Test, or SHSAT—has been the sole admissions criterion for eight of the nine specialized high schools for a couple of decades (and even earlier for some, as mandated by a 1971 law). (The ninth, LaGuardia, is a visual and performing arts school that grants admission based on auditions or portfolio reviews, but not the test.) And earlier this month, New York City’s mayor, Bill de Blasio, put forward a radical proposal: Get rid of the test.

The problem, as he and many others see it, is one of equity: There are very few black and Latino students in the specialized schools. The three highest-status schools—Stuyvesant, Bronx Science, and Brooklyn Tech—have black and Latino student populations of 4, 9, and 13 percent, respectively, far below the 70 percent in public schools citywide. What would replace the SHSAT? A system that would admit the top 7 percent of students at every public middle school in the city, which by the mayor’s reckoning would make the collective student body at the specialized high schools roughly 45 percent black and Latino.

Some aren’t pleased with the idea. Their view is that it would kill off a straightforward assessment of merit that applies across schools—the test is an objective measure, they say, and can’t be gamed the way interviews or grades can be, which can reward kids who are richer and/or white.

More specifically, de Blasio’s proposal has upset many Asian parents in particular and a great number of (though certainly not all) alumni and current students. Asian parents’ opposition to scrapping the test probably has something to do with the fact that, as data provided to us by the city’s Department of Education shows, 30 percent of Asian applicants in 2018 received offers to a specialized school, accounting for more than half of all offers. (And Asians are the minority group with the highest poverty rate in the city.) And there are plenty of elite public high schools across the country, but none are test-only, and none have the reputation nationally or internationally that New York’s specialized high schools do; many of the opponents of getting rid of the test believe—probably not incorrectly—that these schools’ reputation is in part a function of the formidable test.

The disagreement over admission to these elite schools is perhaps best interpreted as a consequence of a system that has over a million students, and not enough—as well as not widely distributed enough—resources for the brightest ones. What sets up the conflict in the first place is that there aren’t enough great schools and there are too few seats at the best schools—and students (and their parents) correctly sense that getting into a specialized school can make all the difference in life.

In the United States, if a child’s parents are poor, he or she is generally likely to grow up to be poor, or a little less so. But, as we’ve found in our research among Stuyvesant graduates, New York’s specialized schools obliterate that correlation. For a book we’re working on called The Peer Effect, we’ve done more than 70 interviews (and counting) with adult alumni who graduated from Stuyvesant between 1946 and 2013. (Part of our interest in the school stems from the fact that we both graduated from it in the ’80s.) Many of the people we’ve interviewed grew up poor, and/or were black, Latino, or Asian. Some of the graduates we interviewed from earlier years were from poor or working-class Jewish families. We also interviewed a lot of former students who were brought up in white, middle-class families.

Nearly all of these kids went to college, often selective ones, and most went on to do well professionally. The poorer students became middle or upper-middle class, and the middle-class students often did better than their parents. And they were happy—most (though not all) felt that Stuyvesant had had a big effect on their lives. For instance, Elizabeth Reid Yee, a white 1985 graduate who grew up poor in Greenpoint, Brooklyn, fully credits Stuyvesant with keeping her from a life of poverty. We heard many stories like this. In short, these specialized schools are transformative, and parents and kids know it.

What makes these schools so good? The general consensus is the academic rigor. But what’s come out clearly in our interviews with Stuyvesant graduates is something arguably more important: a peer-driven expectation of achievement. What Stuyvesant does is take 3,000 pretty bright kids and put them in a building together. Then magical things happen. They push each other, they strive to be like each other, they learn from each other. Abraham Baumel, a former principal at the school, laid out the dynamic nicely: “The fact is, if the teacher is not delivering at a place like Stuyvesant, the kids will find the answers from one another, from books, and from other classes. They will find a way to learn the material, and the teacher thinks he is responsible for that marvelous achievement.”

There are a lot of kids who enter Stuyvesant with what sociologists refer to as social capital, and those without it acquire it from the ones who have it—something that often happens at private schools, but can happen at public schools, too. Students develop a sense of how the world really works, and they begin to learn to navigate it.

This peer effect is critically important for understanding how Stuyvesant alums turned out, and has a simple lesson for all schools: If there is a critical mass of achievement-oriented kids (and it doesn’t have to even be the majority at a school), it’s going to have a positive impact on the rest of the student body. There’s a student-driven culture of achievement at Stuyvesant—one that is independent of parents, teachers, and administrators—that raises everyone’s game. Carlos Moya, a Puerto Rican 1993 graduate who grew up working-class in Hell’s Kitchen and is now a computer programmer, told us that it wasn’t socially acceptable to be a screw-up: “You don’t want to be that guy.”

This culture of achievement contributes to the schools’ sterling reputation. A few black Stuyvesant alumni have told us in interviews that even though they went to elite colleges, when people learn they went to Stuyvesant, it gives them immediate gravitas, and they felt that the suspicions that maybe the reason they got so far in life was because of affirmative action suddenly disappear.

In the current debate over representation at specialized schools, it’s often forgotten that three decades ago, there were sizable numbers of black and Latino students at Stuyvesant, Bronx Science, and Brooklyn Tech—in the 1989-90 school year, black and Latino students made up about 10 percent, 22 percent, and 51 percent, respectively, of these schools’ attendees.* Once upon a time, these schools looked more like what de Blasio says he wants.

The Racial and Ethnic Composition of Specialized New York Public High Schools, by School Year

DATA: NATIONAL CENTER FOR EDUCATION STATISTICS / NEW YORK CITY DEPARTMENT OF EDUCATION

What changed? One of the reasons there are so few black and Latino students in these schools today is because of a change that took place in the early 1990s that limited the opportunities available to high-achieving black and Latino students. New York’s elementary and middle schools are highly segregated, and until roughly three decades ago, nearly every middle school in New York City had an honors program. Kids in these programs got a great education. While black and Latino students in segregated schools may have missed out on certain educational and cultural benefits of learning alongside more white and Asian peers, these honors classes had the benefit of putting all the smart kids together so they could push each other. Many of them tested well and then ended up at a specialized high school.

But by the mid-’80s, tracking—separating students into different classes by academic ability—had fallen out of favor nationally, especially when it came to isolating students of lower ability. In the early ’90s, New York City largely did away with its tracks, including those honors programs. (There are still some honors classes offered here and there, but not nearly to the extent that they once were.) As a result, the top students at many of today’s segregated schools aren’t getting the kinds of opportunities that could launch them into a specialized high school.

Now, instead of tracking within schools, there is effectively tracking between schools, with parents vying to get their children into “good” elementary and middle schools and keep them out of the bad ones. Getting into these schools used to be a simple matter of which school’s zone a student lived in, but Mayor Michael Bloomberg, with the goal of prioritizing “school choice,” led a push to change the system so that, starting in 2004, parents could apply to schools from anywhere in the city. As a result, 40 percent of all New York City kindergarteners today go to schools other than the one they’re zoned for. This leaves “unwanted” schools under-enrolled and struggling.

Around the same time that formal tracking programs were phased out, students coincidentally began preparing for the SHSAT like never before. Hardly anyone we interviewed who went to Stuyvesant before the late 1980s did a test-prep program; by the early 1990s, few people didn’t do one. (The expense of test prep is one of the reasons de Blasio says he wants to discard the SHSAT.) Additionally, the numbers of black and Latino students at these schools dropped, reflecting a large influx of Asian immigrants and their children to the city in the mid-1990s.

Meanwhile—and this is another underappreciated fact in the conversation de Blasio has sparked—the ranks of white students have thinned dramatically. One of the reasons white kids went to Stuyvesant, up through the 1990s, was that so many of the local, zoned high schools were seen as low quality, and considered dangerous for nerdy white kids. In The Fortress of Solitude, a novel by Jonathan Lethem set in pre-gentrification 1970s Brooklyn, one white kid says to the other, “Just pass the test. Your life depends on it. If you don’t get into Stuyvesant, or at least Bronx Science, you’re dead … Brooklyn Tech’s a last resort. Sarah J. Hale or John Jay”—two neighborhood schools—“those places are practically like prison.”

The white population at Stuyvesant hovered around 40 percent from the late 1980s until the early 2000s, according to the National Center for Education Statistics. Around 2003, when Bloomberg became mayor, the number of white kids at these schools dropped as the number of schools that screen for academic criteria like grades or exams, or require an audition or interview, more than doubled.** This selectivity increased the pool of schools that were considered “good,” which diverted many white students away from the specialized schools and into these newly prestigious schools.

Whatever the merits of de Blasio’s proposal, it would have a limited effect on the system-wide problem of school inequity he’s interested in fixing, as specialized high schools only account for about 6 percent of seats in the city’s public high schools. (It may, however, have a larger impact on diversifying the city’s middle schools, in that it could incentivize parents to choose “worse” schools for their kids, where those kids might have a better shot at finishing at the top of their class and thus gain entry to a specialized high school.)

What, then, would make a difference in high schools more broadly? There are other schools in the city—about a third of public high-school programs, in fact—that screen incoming students and that also don’t reflect the city’s wider demographic. These “screened” schools—which are basically lesser-known, but still competitive, magnet schools—generally have more black and Latino students than the specialized schools, but they still tend to be predominantly white and Asian.

Overhauling these screened schools would have a bigger impact than doing away with the SHSAT. As Stuyvesant demonstrates, having a student body that is racially and economically diverse can mean that everyone wins: Poor and minority kids do better academically, and top-performing white kids do just as well, while getting the enrichment of being around a wider variety of peers. In other words, what needs fixing is the system more broadly.

Indeed, dozens of school systems around the country are considering students’ household income when assigning them to schools. To get rid of the SHSAT, de Blasio would have to win a change in state law, but he could easily reform screened schools on a large scale in a way that wouldn’t require such a change—just the resolve to stand up to the richer, typically white parents of kids in popular screened schools. Perhaps his proposal represents a recognition that it’s easier to fight state lawmakers and immigrant Asian parents than to fight rich white parents.

*Because of errors in the data kept by the National Council of Education Statistics, this article originally stated that black and Latino students made up 16 percent and 67 percent of the student bodies at Stuyvesant and Brooklyn Tech, respectively, in the 1989-1990 school year. This article, including its charts, has been updated to reflect corrected data from the NCES. A separate error in the chart for Bronx Science, in which the wrong percentage of Asian students was given for the 1989-90 school year, has also been corrected.

**Because of errors in the data kept by the National Council of Education Statistics, this article originally stated that the white population at Stuyvesant peaked in the 1989-1990 school year at 63 percent, and that the number of white students shrunk significantly in the early to mid-’90s. This article, including its charts, has been updated to account for those errors in the data set.

We regret the errors.



“Twenty-one, mental. He’s a mental,” a university police officer said into his radio as his car approached Charles Thomas, a fourth-year student at the University of Chicago, on Tuesday night after reports of possible burglary and damage to buildings. Three campus police officers had responded to the call. Thomas, who according to police was holding a metal object, began walking toward the officer, as body-cam footage released by the university shows. “Drop that weapon,” the officer, who had stepped out of his squad car, said, pointing his gun at Thomas, according to the video. A little over a minute passed, and Thomas began charging at the officer before the officer allegedly fired his gun, hitting Thomas in the shoulder. (Thomas faces charges of aggravated assault of a police officer with a weapon and criminal damage of property.)

Circumstances aside, the fact of a shooting by a campus police officer—believed to be the first at the university in more than 30 years—comes as national attention is trained on questions of school safety; one proposal that has dominated the conversation is to arm teachers and provide more resources for elementary- and secondary-school officers. College campuses faced a similar question in the 1960s and 1970s, amid widespread student unrest—in part the result of desegregation and the Vietnam War—and the police response to it. And college students today continue to protest the result: armed campus police forces.

Though many students have opposed having armed police on campuses, administrators have been reluctant to reassess arming the officers. Now, with the political climate changing in the wake of the tragedy in Parkland, Florida, this debate may shift. Last week, students at Howard University managed to wrest promises of reform from the administration, including taking a look at the necessity of armed campus police officers. Other campuses may soon find themselves in similar positions.

The establishment of armed campus police grew out of a concern, some 60 years ago, that local and state police officers were not sufficient to deal with discord on campuses. The number of campus police departments exploded from there. The latest federal data on the campus police departments at public and private higher-education institutions is from the 2011–2012 school year, but it still hints at the current situation. Seventy-five percent of campus law-enforcement agencies have armed officers, according to a Bureau of Justice Statistics survey. Nine in 10 public campuses had “sworn” officers, meaning those who can carry a gun, have arrest power, and wear a badge; four in 10 private campuses did.

Colleges are generally safe places, but that can change in an instant, Randy Burba, who was until very recently the president of the International Association of Campus Law Enforcement Administrators, the leading trade group for campus public-safety officers, told me. Campuses are both constituent parts of larger towns and cities and communities in their own right, with issues and quirks that those who police them should know well. If an active shooter were located on the third floor of an English building, a trained campus police force could respond quickly, know exactly how to get there, and also have some knowledge of layout of the building—knowledge the city police force might not have.

Campus police officers, he continued, face a similar set of issues that off-campus police forces experience. “It’s kind of like being prepared for an earthquake,” Burba says. “They tell you, ‘Nail your bookshelves to the wall.’” The earthquake may never come, but if it does, the precaution was worthwhile.

By the same coin, it only takes one error—say, a cellphone that is mistaken for a gun—on a campus police officer’s part for a tragedy to occur. Some have argued that the forces are a virtually unchecked power—often with jurisdictions that extend beyond the campus, as is the case at the University of Chicago—and should be abolished.

Further, as my colleague Vann Newkirk wrote last week, “In a country currently in the grip of what appears to be an overdue reckoning with its epidemic of gun violence, it’s worth noting that police shootings are also an epidemic of gun violence.” Arming more campus-security forces—broadening the group of people with guns policing college students—risks exacerbating an ongoing national crisis.

Still, Burba—far from suggesting that all campuses arm their police officers—notes that campuses must make decisions about arming security forces for themselves after assessing the dangers their institutions face.

Portland State University found itself grappling with such a decision in 2013. The top two reported crimes on campus at the time, according to federal data, were liquor-law violations and burglary, and the institution did not have an armed police force, only unarmed campus security officers. The institution’s president formed a task force to make recommendations to address safety concerns and “improve the response to criminal activity on campus.”

The university was facing a set of circumstances quite different from several decades ago. The campus now covers much more land than it did in the late ’70s. The number of buildings on campus has doubled since then, and so has the campus’s population. After several conversations with students, faculty, and staff across campus, the task force came to the conclusion that the college could do more to protect students, and that an armed campus police force would help do that—despite students being split on the idea.

“The most ideal campus safety staffing model is one that allows PSU access to dedicated professionals who are part of the PSU ethos and community, who have sworn police status,” the task force wrote in the final report. The armed police force was approved within a year, and was charged with monitoring the campus as well as its surroudings. (No data seems to be available on how often campus police officers discharge their weapon, so parsing the effectiveness—or need—of firearms in preventing crime on campus is difficult.)

Ever since the decision, student activists have been organizing to disarm the police force on campus. In 2016, students staged a walkout in protest. Similarly, after the killing of a student, Scout Schultz, by campus police at Georgia Tech last fall, the student union released a statement about the “dangers of armed forces on college campuses.”

College administrations are in a difficult position. To maintain armed security forces means to take on the risk that something will go terribly awry, that a student or someone else will be wrongly shot. But to not maintain armed security could mean that students and professors lack adequate protection. The current preference tends to be to arm campus police officers, but administrators may soon find that preference more untenable as the political dynamics around guns shift. One clue as to the contours of the debate ahead: Many colleges and universities have implied their support for emboldened high-school student activists—particularly those who have been vocal in support of gun control. Will those students find their administrations remain warm to their views once they arrive on campus?



A famed professor. A student claiming they were sexually harassed. A months-long internal investigation.

Many of the particulars of the case against Avital Ronell, a professor of German and Comparative Literature at New York University who an internal investigation found responsible for sexually harassing Nimrod Reitman, a former graduate student of hers, are familiar. Reitman accuses Ronell of kissing and touching him repeatedly, as well as sending inappropriate email messages, among other things. After its investigation, the university found that Ronell’s conduct was “sufficiently pervasive to alter the terms and conditions of Mr. Reitman’s learning environment,” according to The New York Times, and suspended her for the upcoming academic year.

In the #MeToo era, versions of this story have played out with other prominent academics. But the twist here is that the alleged harasser is a woman, when so often these cases involve male professors, and a feminist who’s the target of a complaint filed under Title IX, a federal policy created to advance gender equity. But the responses to Reitman's accusations against Ronell from her fellow academics in some ways echoed the defenses that male scholars, from MIT’s Junot Díaz to Boston University’s David Marchant, have gotten when faced with similar accusations, and is a striking example of the power structures at work in academia.

Among those who rallied to Ronell’s defense were a host of prominent philosophers, led by one of the country's most notable feminist scholars, Judith Butler. They wrote a letter to the university asserting Ronell’s innocence and arguing that Reitman harbored malice towards the professor. “We deplore the damage that this legal proceeding causes her, and seek to register in clear terms our objection to any judgment against her,” they wrote. In a draft of the letter, which was published by Brian Leiter on his philosophy blog, Leiter Reports, the professors admitted that they did not know all of the details of the case. But Joan A. Scott, a signatory and professor emerita at the Institute for Advanced Study, a research center in Princeton, New Jersey, told The Chronicle of Higher Education that “many people who signed the letter knew more than they could say.”

Ronell did not respond to a request from The Atlantic for comment. In a statement to the Times, Ronell said: “Our communications—which Reitman now claims constituted sexual harassment—were between two adults, a gay man and a queer woman, who share an Israeli heritage, as well as a penchant for florid and campy communications arising from our common academic backgrounds and sensibilities. These communications were repeatedly invited, responded to and encouraged by him over a period of three years.”

This is not the first time a group of academics have come to the aid of a prominent intellectual accused of sexual misconduct. When Díaz, who in addition to teaching at MIT is a Pulitzer Prize-winning author, was accused of forcibly kissing one female writer and verbally abusing others—the university ultimately cleared Díaz after an investigation—a handful of academics wrote an open letter, published in The Chronicle, excoriating the press and social media users for its treatment of the writer:

We do not intend to dismiss current or future accusations of misconduct by Díaz or any other person. We also acknowledge the negative and disturbing effects of verbally or psychologically aggressive acts or toxic relations on the women who experience them.

Instead, they argued, they were taking issue with the way the accusations were being characterized and situated in the broader #MeToo conversation. (A response to that letter, also published in the Chronicle, argued that by publishing the letter criticizing the media, the group of faculty was sending “the very message they claim they do not want to convey”—that they were endeavoring to protect Díaz. )

While it’s unclear how much demonstrations of support from one’s colleagues determine the outcome for the person accused of misconduct, there have been several examples of powerful men in academia who faced disciplinary action but were allowed to stay on the job. In some cases, male professors managed to skirt punishment altogether for years, even as egregious allegations of sexual harassment mounted.

It’s hard to know exactly how the social dynamics and power structures of any given university affect the handling of harassment allegations. But research that has mapped the strange caste system academics inhabit could offer some insight into the dynamics that might lead them to band together in support of a prominent colleague.

One factor: Universities are hierarchical. At the apex is the chief executive officer—often a president or chancellor—and under that person are the deans of individual schools within the university; then there are the heads of the school’s often-decentralized academic departments, who typically enjoy immense influence over departmental decisions, from salaries to curriculum. Less officially, tenured professors hold a great deal of sway, determining their own research and teaching priorities while getting some say over departmental decisions. At the bottom: the untenured academics—hourly wage adjuncts, grant-funded researchers, contracted instructors, and the like. Overseeing all this are a school’s governing bodies—boards of trustees, for example—which are often composed of leaders from outside the university who come with their own set of financial interests, political beliefs, and personal networks. This leads to a tendency toward tribal politics, in which professors tend to be loyal to their discipline and department.

In his 1998 book on the dynamics of higher education in the U.S. and around the world, the Australian social scientist Brian Martin argued that in academia, like any other hierarchy, “people exercise power not by virtue of their personal talents but by virtue of the position they occupy.” With some exceptions, he suggested that a professor's position on the university pyramid—and their “informal alliances”—determine the extent to which the individual can escape accountability for his or her actions. Academics in lower tiers “are very dependent on the good graces of their supervisors” and others with influence over promotional decisions. If an academic in the upper echelons of the power structure commits some wrongdoing, his or her subordinates might feel pressured to disregard it or to come to the professor’s defense. This dynamic also, according to some adjuncts, enables bullying.

What effect, if any, this hierarchical system has on internal investigations such as NYU's of Ronell, it's impossible to know. But it is a feature of universities—present in other organizations, but seldom as pronounced—that is important to consider whenever complaints are alleged, buried, and/or disputed. And it isn't hard to see how when someone toward the top of the pyramid is accused of sexual misconduct, the other people making up the pyramid might be more concerned with the position of the accused than the details of the case.

There's a persistent phenomenon in academia, known as Sayre’s law, which in one version goes, “academic politics are so vicious precisely because the stakes are so small.” Various political scientists, including Henry Kissinger, a former Harvard professor and Secretary of State, cited this idea when expressing frustration with academic politics. Some scholars argue that the exact opposite of Sayre’s law is true, with viciousness in higher education owing itself not to low but to high stakes—the threat of a lost promotion, for example, or of exclusion from an academic “tribe.” Few stakes could be higher than professors being accused of harassing students, so it makes sense that, in such a situation, the vicious, ever-present tribal dynamics could be inflamed.



Every year, scores of gifted students have their college prospects hampered by life circumstances. Imagine a teenager attending a high school where few of his peers make it to graduation, much less college. This student, however, is a high achiever. His grade-point average and test scores show it. In fact, they’re good enough to get into some of the best institutions in the country. But he doesn’t go to any of those institutions—let alone apply for them. Actual high-schoolers like this hypothetical student and the issues they face are very real.

The phenomenon—in which students do not attend the most selective colleges their qualifications suggest they could—is called “undermatching.” Few theories have garnered as much attention from the higher-education crowd as quickly as undermatching has. As Matthew Chingos, a policy expert at the Urban Institute, puts it, perhaps the chief problem with undermatching is that it disproportionately happens to low-income and minority students. A range of benefits comes with attending an elite institution: name recognition, more financial resources, and oftentimes an alumni network connected to powerful places. And by undermatching, capable students with unique perspectives on the world might miss out on those advantages—exacerbating a trend in which affluent students dominate the pipeline of those positioned for leadership roles.

A recent paper illustrates the extent to which undermatching dims the prospects of already-disadvantaged students: Those who undermatch—who are predominantly low-income and students of color—are less likely to graduate within four years, as well as within six years, than their peers who did not. Chungseo Kang and Darlene Garcia Torres, both education-policy scholars at State University of New York at Buffalo, used longitudinal U.S. Education Department data to create a national sample of nearly 5,000 students who enrolled in four-year institutions within a year of high-school graduation.

The researchers found that undermatching was highest among black students, at 49 percent. And the phenomenon seemed to have the most acute effect on Hispanic students: After controlling for various characteristics, the six-year graduation rate for those who undermatched was 28 percentage points lower than it was for those who didn’t.

Minority and low-income students undermatch for countless reasons. They may not have been made aware of their college options, some because they didn’t have a guidance counselor to do so. Those who did learn about their options may have received the information after the application deadline. Then there’s the fact that college recruiters tend to look for students at high-achieving high schools. And sometimes students may feel—or have been told—that selective colleges, or college more generally, is simply out of their league. Or that those selective schools are cost-prohibitive—even though such institutions tend to be more generous with financial aid than less-selective ones.

Chingos admits that highly selective colleges enroll a miniscule portion of the higher-education population, and that policymakers and the media may give these institutions outsized attention. A study published in the Journal of Labor Economics last year highlighted the importance of increasing access to public, 4-year colleges, a practice that substantially increases degree-completion rates. However, it is clear that many highly selective institutions could be doing more to socioeconomically diversify their student bodies, and that the benefits of attending them could have a profound impact on the leadership pipeline. Still, a 2016 Jack Kent Cooke Foundation report found that selective colleges had since 2000 hardly increased the number of students who receive Pell grants, which are reserved for low-income students.

There’s no doubt that undermatching occurs—but solutions to the problem are far less clear. One idea that has bounced around, including in the Cooke Foundation report, is for college-admissions offices to give extra weight to the applications of low-income students—a “poverty preference,” as the foundation called it. Colleges already give preference to other hopefuls, including recruited athletes and, perhaps most infamously, students whose relatives are alumni. So, the logic goes, why not do the same for low-income applicants?

In 2016, two senators proposed a bipartisan bill that would hold highly selective institutions accountable for enrolling and graduating more low-income students, penalizing those that repeatedly fail to boost their numbers with a fee. Experts such as Wil Del Pilar, of the advocacy group Education Trust, say this idea—the creation of an accountability system that requires institutions receiving federal dollars to have some minimum caps for low-income students—could increase diversity on these campuses. And in 2014, the Obama administration pinpointed undermatching as a national concern.

It’s worth noting that the need for extra support at the higher-education level for disadvantaged students tends to extend beyond the admissions process, particularly at elite colleges which tend to be less socioeconomically—and oftentimes racially—diverse. There are myriad stories of students who have found on elite campuses an environment where they feel isolated. Sometimes that frustration boils over into protest, but other times it could lead to a student falling behind. In fact, the focus on undermatching has drawn some ire from those who argue that attention should shift toward devoting more resources to improving graduation rates at less-selective institutions like community colleges and public, regional four-year institutions, which enroll the majority of low-income or minority students, rather than elite colleges.

But as long as attending an elite college continues to yield benefits, reducing the prevalence of undermatching will remain imperative. After all, it’s hard to ignore the fact that, as of 2016, more than 40 U.S. Senators and Representatives were Harvard alumni, making the Ivy League institution the most common alma mater in Congress. The No. 2 spot, meanwhile, went to Georgetown, while Yale was No. 3.



At Texas Tech University’s medical school, just 4 percent of students are black; 13 percent are Hispanic. And those numbers might soon shrink. Research has shown that’s what happens when schools stop considering race in admissions, and that’s what the school plans to do.

In late February, Texas Tech University reached an agreement with the U.S. Department of Education to end its use of race in admissions to its medical school. The resolution, first reported by The Wall Street Journal, brought to an end a 14-year federal investigation into the school’s affirmative-action practices. The complaint had been filed following the Supreme Court decisions in the Michigan affirmative-action cases Grutter v. Bollinger and Gratz v. Bollinger, where the Court decided race could be used in admissions, but only in a “narrowly tailored” way. Texas Tech had stopped using race in admissions at its pharmacy school in 2008, and at its undergraduate college in 2013, but not at its medical school. There, the school argued, it needed to use race as a factor to ensure a diverse class of future doctors, and there was no other way around it.

The law, as interpreted by the Supreme Court in affirmative-action cases over the past 40 years, requires schools to show that they have exhausted all other, race-neutral options to achieve a diverse student body before using race as an admissions criterion. Most schools are able to show that they are using race in admissions in the narrowly tailored way that the Supreme Court has said, time and again, is legal. But Texas Tech was not periodically reviewing those race-neutral alternatives, or, at least, could not show that it was. That’s why it’s hard to read too much into what this means for the future of affirmative action, Scott Schneider, a higher-education attorney with Husch Blackwell, told me; the details of the case were specific to Texas Tech.

In a letter to the Department of Education’s Office for Civil Rights, Eric Bentley, the general counsel for the Texas Tech University system, said that the school could prove that it was using race in an constitutionally accepted way, but that Texas Tech would voluntarily agree to drop the practice anyway. Still, he wrote, the medical school “strongly believes that diversity in academic medicine is not only a necessity at the [School of Medicine], but is a necessity nationally as well; therefore, we continuously strive to enhance the diversity of our student body.” But diversity in medical schools, broadly, has been difficult to achieve—especially without the use of race in admissions.

Many minority groups—particularly blacks, Hispanics, and Native Americans—are significantly underrepresented at medical schools, Liliana Garces, an associate professor at the University of Texas who has studied the effects that affirmative-action bans have had on student representation, told me. And according to a recent report from the Association of American Medical Colleges, positive increases in racial diversity are few. For example, the number of black matriculants to medical school rose by 4.6 percent last year, to 1,856, and the number of American Indian or Alaska Native matriculants rose by 6.3 percent, to 218.

These numbers could yet get smaller. Research shows that banning affirmative action—eliminating the use of race in admissions—leads to a decline in the enrollment of those underrepresented students. This is just as true at medical schools as it is at undergraduate institutions. For example, the number of black and Chicano students enrolled at University of California medical schools from 1996 to 1997 declined by 38 percent and 29 percent, respectively, following the state’s affirmative-action ban.

The lack of diversity isn’t a problem merely for young black college graduates hoping to become doctors someday, but for many of their would-be patients as well. Research has shown that health outcomes are improved when black patients have black doctors; they’re more likely to go for treatment and to be more satisfied with the care they receive. Those facts make the continuing lack of diversity in medical schools even more acute, and the potential for a decline in enrollment more threatening. “For health care and medical schools in particular to be in a situation where we might be likely to have fewer black doctors creates real implications for the type of care and treatment that black patients are likely to receive,” Adia Harvey Wingfield, a professor of sociology at Washington University in St. Louis, told me.

Wingfield’s new book, Flatlining: Race, Work, and Health Care in the New Economy, explores how changes in work affect black medical professionals. Black doctors, she finds, end up doing an extra level of work—the attentiveness to black patients, the added attention to caregiving—that is part of why black patients have better health outcomes with doctors who look like them.

With fewer black doctors, those who are already doing more work would be stretched even thinner. “If we’re talking about practitioners who are going to be servicing communities that are only going to become a larger and larger part of our society,” the goal, Wingfield says, should be to boost the ranks of those underrepresented minorities in medical professions.



Children should have equal access to a high-quality education. It’s a popular talking point among both the left and the right because it’s non-objectionable—yet it’s far from the reality of American primary and secondary education. As the landmark Reagan-administration report, A Nation at Risk, put it 35 years ago, “If an unfriendly foreign power had attempted to impose on America the mediocre educational performance that exists today, we might well have viewed it as an act of war.”

Advocates for so-called school choice, however, argue that they have a solution: If you provide students and families with a broad range of options—including charter schools, private schools, and traditional public schools—they can choose the one that best suits them. In theory, the schools would compete with one another, vying for students, and the competition itself would spur them all to improve, as Peter Bergman, a professor of economics and education at Columbia University, told me. Ideally, that competition is open to all students equally, as it is that sort of open free-for-all that ought to produce the best results.

Of course, for this to work, parents need to know about the options available to them. Research has shown that there are significant barriers to choice, among them access to transportation, enrollment issues, and a lack of information about the schools. A new working paper from the National Bureau of Economic Research adds another dimension to this problem: Schools themselves may play a role in encouraging more “desirable” students to enroll, meaning that often it’s more the schools choosing the students than the reverse.

The study, authored by Bergman and Isaac McFarlin, a professor of education at the University of Florida, examines the beginning of the school-choice process: inquiries about how to apply. In a randomized test, the researchers sent emails from fictitious parents to more than 6,000 charters and traditional public schools in areas with school choice. “Each email,” Bergman and McFarlin wrote, “signaled one of the following randomly-assigned attributes about the student: their disability status, poor behavior, high or low prior academic achievement, or no indication of these characteristics.” The pair wanted to see whether schools provided the same information to all parents, regardless of any difficulties alluded to in the emails.

Ultimately, Bergman told me, they found that the schools they emailed are less likely to respond to students who are perceived as “harder to educate.” The charter schools, he added, were “particularly less likely to respond to students with a particular [individualized educational plan]”—meaning students who have a special need that would require them to be taught in a separate classroom. This “cream-skimming,” or providing information only to high-value students, is a “key source of potential inequality,” Bergman said.

An easy takeaway from the report, McFarlin told me, would be that “charter schools discriminate against special-needs kids,” but that would be an incomplete assessment, since the schools they emailed replied to the parents of any student with any disadvantage—behavioral issues, low grades, or special needs—at similar rates. Now that researchers know whether schools responded to the emails, the next step is digging into the responses to see if they are actively discouraging certain students from applying.

In the meantime, Bergman and McFarlin hope that this sparks a conversation about how the subtle discrimination of not responding to an email can create an information gap for families in the application process. School choice, with a goal of equitable access, could work, they say, but only if it truly allows the students to choose schools, rather than allowing the schools to choose students.



Most people probably take their bathroom privileges for granted, heading to the toilet in their home or office whenever the need arises without thinking much about it. But at school, children don’t always have that luxury.

A recent survey by the Society for Women’s Health Research found that schools often disregard kids’ restroom rights, often by failing to have a bathroom rule on the books and provide staff with education on bladder health. Absent official policies, parents and doctors tell me, many teachers come up with their own regulations, which anecdotes suggest can border on the absurd. I heard about a teacher who allegedly stipulated that her students could only go to the restroom during class time once every two months, for instance, and read about some school districts routinely locking restrooms at lunchtime or after school to discourage misbehavior.

Schools seek to minimize the amount of time kids spend in the bathroom during class to ensure that they get the most out of their instruction, and generally restrict students’ access to prevent misconduct in the restrooms, where kids tend to be unsupervised. Well-intentioned yet overburdened teachers might adopt such rules to avoid disruptions and ensure that all their students are accounted for. But treating bathroom use as a discipline issue can have serious health implications, especially when a kid needs to go, but can’t.

A majority (84 percent) of respondents in the recent survey, which was distributed among school nurses serving all grade levels nationwide, said students often have ulterior motives when they ask to use the bathroom—maybe they don’t have to go and just want to meet up with a friend, for example, or perhaps they intend to skip the bathroom altogether and cause a ruckus in the hallway. A little more than half reported that kids misbehave in the bathroom. Underlying these assumptions is the fact that few schools have written policies on students’ bathroom use—just 8 percent of nurses said such rules existed, while fewer than half said students on their campus can use the bathroom whenever they please, with permission required only as a formality.

And the survey’s results suggest that such realities persist despite growing recognition of the health consequences. More than a third of respondents expressed concern about the adequacy of kids’ bathroom-break time—and three in four said they were aware of bladder or bowel problems among kids at their school.

A separate 2015 study underscores the disconnect between discipline-focused bathroom policies and kids’ health. While 81 percent of the more than 4,000 elementary-school teachers said they allow kids unlimited access to water, 88 percent also said they encourage their students to hold their pee; 36 percent of participants, meanwhile, indicated they had a “protocol in place to encourage students not to use the bathroom during class time.” Also notable: About eight in 10 of those educators said bullying, misbehavior, vandalizing, or other negative behavior happens in the restroom.

Some experts point to bed-wetting—which according to the American Academy of Pediatrics affects 20 percent of 5-year-olds and can be a symptom of an acutely dysfunctional bladder—as attributable largely to kids holding in their urine or feces. This “voiding dysfunction,” as medical practitioners refer to it, can have severe, long-lasting physiological consequences—a swollen colon can damage the nerves feeding into the bladder, for example—not to mention psychological ones.

Despite the growing body of empirical research showing that holding it is bad for kids, schools’ mind-sets don’t seem to have changed much. This is the case even though awareness among campus officials appears to be growing, if only slightly. In a 2012 survey, fewer than half of the 600 school nurses who responded suspected that children with frequent urination or bladder and bowel accidents were suffering from an underlying health problem. Roughly a decade earlier, in 2003, that number was even smaller when similar questions were asked of teachers. Fewer than one in five participants in a survey of Iowa educators suspected that children who demonstrated frequent urination or accidents were suffering from an underlying health problem. A third of them said they’d ordered at least one student requesting bathroom access to wait.

Christopher Cooper, a pediatric urologist at the University of Iowa who co-wrote the 2012 and 2003 studies, began researching the issue after noticing a high frequency of UTIs and higher rates of voiding dysfunction among his young patients. “It started to seem like, if for eight hours a day you [as a teacher] are the primary caregiver for these children, you’re missing a potential opportunity to pick up on some abnormal things going on,” he says. It’s hard for a kid to advance academically and develop socially and emotionally if she is constantly distracted by her bladder troubles. “Wetting your pants at school is one of the most stressful things a child can face or even imagine,” Cooper says.

One mother in the Seattle area, Maija Brissey, says she will never forget the day her son, who struggles with urinary accidents because of a rare medical condition, came to her at the age of 6 and asked her if he had a disease. Apparently, his classmates had convinced him that he did because he kept peeing his pants. Over the years, Brissey says her son started disengaging from classes and from his neighborhood friend group, retreating to his room right after school rather than playing with his buddies. “We’ve got to do a better job of making using the bathroom more comfortable for kids,” says Brissey, a nurse.

When they’re in elementary school, kids’ bladder systems—and the psychological responses to these physiological sensations—are at a crucial point of development. According to Cooper, children are “very good at ignoring [their bladder] signals” after being regularly denied the opportunity to go when they feel the urge. And the side effects—from incontinence to recurring urinary accidents—can put stress on the bladder, which is a muscle, and thus make it stronger and overactive. Cooper cited the high rates of bladder cancer among truck drivers, who often hold their urine on long drives.

Suzanne Schlosberg, a health and parenting writer based in Bend, Oregon, started advocating for policy reforms and greater awareness after experiencing similar issues with her child. A few years ago, Schlosberg teamed up with Steve Hodges, a pediatric-urology professor at North Carolina’s Wake Forest University, to create an online resource for parents, therapists, teachers, and others seeking to help children who suffer from toileting problems. One of the inevitable challenges of this issue is that many people don’t want to talk about bathroom issues. As universal and mundane as they are, they can be embarrassing to discuss—not only for kids, but also for the adults who care for them. These days, Hodges says he often finds himself writing letters to schools demanding bathroom freedom on behalf of his patients.

Schlosberg says she has often had to contend with teachers whose bathroom policies encouraged her son to resist the urge to go. One teacher, she recalls, relied on the popular classroom-management strategy of rewarding kids for good behavior, in this case through the use of fake money. If students wanted to use the restroom during class, according to Schlosberg, they had to pay a “fine.” “My kid wanted to save his money, so he was having to decide between using the bathroom and saving his earnings,” Schlosberg says. Upon learning of her son’s issues, the teacher was quick to exempt the child, but stopped short of changing the class policy.

On K–12 campuses across the country, children’s bathroom needs are left in limbo because schools seldom have established policies, and teachers lack the training on how best to balance discipline concerns with kids’ needs. Just one in five respondents in the 2015 study of more than 4,000 teachers, for example, said they’d participated in “professional development” on bathroom regulations for kids. This lack of awareness, combined with sometimes-valid fears about misbehavior and academic disruption, leads to a patchwork of inconsistent rules that teachers might devise themselves.

What’s ironic is that most teachers are familiar with students’ bathroom woes—they seldom have the opportunity to relieve themselves during the school day, either. In fact, in a 2015 survey that asked teachers about the quality of their work life, its 30,000 respondents listed this problem as one of their biggest sources of everyday stress.



This week, America got another reminder of the fear that its schoolchildren must make sense of every day. On Tuesday afternoon, nine students were shot—one of them fatally—at STEM School Highlands Ranch, near Denver.

Though the two suspects are teenagers, STEM School Highlands Ranch is K–12, meaning that some young children were exposed to the violence. Among them was a second grader who told a New York Times reporter that he’d gone through lockdowns and active-shooter drills since kindergarten. That’s close to half his eight years of life.

His familiarity with potential crisis scenarios makes him part of an enormous group: In the 2017–2018 school year, more than 4.1 million students participated in a lockdown or lockdown drill, according to an analysis by The Washington Post.

These lockdowns can be scarring, causing some kids to cry and wet themselves. Others have written letters bidding their family goodbye or drafted wills that specify what to do with their belongings. And 57 percent of teens worry that a shooting will happen at their school, according to a Pew Research Center survey from last year. Though many children are no strangers to violence in their homes and communities, the pervasiveness of lockdowns and school-shooting drills in the U.S. has created a culture of fear that touches nearly every child across the country. In postwar America, have kids ever been so afraid and so regularly prompted to imagine their own suffering?

When I put that question to Paula Fass, a historian at UC Berkeley and the author of The End of American Childhood: A History of Parenting From Life on the Frontier to the Managed Child, she brought up two eras as analogues. The first was the early stages of the Cold War—the 1950s in particular—when fears of nuclear bombs had schoolchildren across the country doing duck-and-cover drills underneath their desk.

Surveys of children who grew up in this era indicate that 60 percent of them reported having had nightmares about atomic bombs. Fass herself lived through nuclear-prep drills, and while she said that they weren’t all that scary for her—they became rote, like reciting the Pledge of Allegiance—she recalled one night during the Cuban missile crisis, in 1962, as particularly anxiety-inducing for a high schooler: “I remember going out that evening on a date, and as we parted ways on the New York subway, we said to each other, ‘We may never see each other again.’”

The second period when families felt a looming threat, Fass said, was the 1980s and ’90s, when there was a “pervasive fear” of kidnapping among parents and kids alike. They received constant reminders of children who had disappeared—their faces were on TV, billboards, mailed flyers, and milk cartons. Some of the missing were from small towns, and others were from big cities. “It didn’t seem that there were any protected places,” Fass told me.

Fass, who wrote a book about child abductions called Kidnapped in 1997, said she heard of police officers showing up at schools in a push to record kids’ fingerprints, “not because they would be able to locate them that way, but because if they located their bodies, they’d be able to identify them.” All this scared children: A 1987 poll found that their most common fear was being kidnapped.

These widespread panics took a psychological toll—were they proportional to the actual risk? In the case of the Cold War, it’s hard to say, because while the United States never experienced a nuclear attack, there was a real sense that one might occur. (And some evidence indicates that ducking and covering might actually have been a wise tactic for these kids, at least compared with doing nothing at all.) The kidnapping panic, meanwhile, seems overblown in retrospect. In 1997, for instance, only about 100 of the 71 million children in America were abducted by strangers.

This isn’t to say that kidnappings and nuclear blasts wouldn’t be devastating—just that they are exceedingly unlikely. Shootings, too, seem to fall under this category of threat. Starting with Columbine, according to the Post, school shootings have claimed some 150 lives, including both children and adults. That’s 150 too many, but as a percentage of all the students and teachers who have been in a school in the past 20 years, it’s quite small. (The number of children estimated to have experienced gun violence at school during that period—roughly 230,000—is also much too high, but still a tiny minority of the tens of millions of American children in school at any given time.) Lockdown drills are schools’ attempt to protect kids from an unpredictable threat. But, across the country, children are being trained to anticipate an outcome that is both terrifying and extremely unlikely to happen to them.

While all of these threats—bombs, kidnappings, and shootings—are existential, what has changed over time is by what means people perceive the danger. In the 1950s, Fass said, television wasn’t yet pervasive—news typically came in 15-minute, once-a-night installments (and, of course, via radios and newspapers). “Certainly anyone who was awake knew about the Cold War, but they might not have been reminded of it in a daily way on television,” she noted.

The ’80s and ’90s were much different. By then, reports of missing children were omnipresent. “If you didn’t watch television,” Fass said, “I suppose it’s possible that you didn’t imagine this was going on. But if you had a TV, as 95 percent of all Americans did, it was impossible to escape from.”

A few decades later, news of school shootings is similarly inescapable. The latest tragedy is delivered not via milk carton but push notification. Parents and children in previous generations also feared for what might happen during the school day, but today, reminders of the danger come at an unprecedented volume and pace. When the news of another lockdown or another shooting could interrupt kids’ days at any moment, is it any wonder they’re so afraid?



BACK ISLAND, ALASKA —   “Oh my god, I feel like a murderer,” exclaimed 13-year-old Bonnie Bright. “I’ve killed so many things on this trip.”

Sporting pigtails, glasses, and Xtratufs—the brown neoprene boots affectionately called “the Alaskan sneaker”—Bright didn’t look like a serial killer. Yet in her hands was her latest victim: a chubby sea cucumber the color of burnt umber. Bright cleaved the slippery echinoderm down the middle, then removed several white slivers of meat and cooked them over a fire she’d built. It was time for breakfast.

All around her, on the rocky gray beach, 19 of Bright’s classmates were performing similar drills. In total, the Coast Guard had dropped 103 Schoenbar Middle School students—the majority of Ketchikan, Alaska’s eighth graders—on six nearby uninhabited islands to survive for two days and nights last May. I’d accompanied Bright’s group to Back Island, where, like the rest of their classmates, students had each brought nothing more than a 10-by-15-foot sheet of plastic, a sleeping bag, clothing, and whatever additional supplies (rice, knives, foil, twine, matches) they could fit into a 12-ounce metal coffee can.

“The survival trip,” as it’s known in this isolated island community, has occurred annually for 45 years. It serves not only as the students’ final science exam but also, more importantly, as preparation for growing up in the unforgiving wilderness they call home.

Sitting at a square table in Schoenbar’s library last year, Stephen Kinney, the mind behind the trip, told me that he had no idea it would become such a long-standing tradition. The amiable retired educator said his main goal had simply been for students to enjoy school (because growing up, he never had).

“Learning should be fun,” Kinney, 77, explained. (He and everyone else in this story are identified with their age as of last year’s survival trip.) “There needs to be some kind of a hook. [Students] need to be involved in their education.” He recalled the time he found a dead sea lion and brought it to his science class for dissection; decades later, students still mention it when they see him around town. “That’s a really critical piece of education: to catch students’ imagination, to grab them,” he said.

Kinney, who grew up in Maine, moved to Ketchikan in 1965 to teach eighth-grade science at the brand-new Schoenbar Middle School. The lifelong outdoorsman was surprised by how many of his students didn’t know basic survival skills, such as how to build a shelter or start a fire. So in 1973, along with a fellow teacher, Don Knapp, he brought a group of eighth graders to Settlers Cove, a state recreation area 18 miles north of Ketchikan. “Our goal was to have them live off the land,” Kinney said. “To realize that the land provides if you understand it.”

That was the Ketchikan students’ very first survival trip. In the years that followed, more students and teachers joined. When Kinney and Lyle Huntley, another eighth-grade teacher who’d become the trip’s co-organizer, both transferred to the seventh grade, they brought the concept with them. They launched an annual two-night camping trip that taught basic outdoor education in preparation for the big eighth-grade trip the following year.

Today, both grades spend the last six to eight weeks of the school year on a Southeast Alaskan science unit—environmental science in seventh grade, and safety and survival in eighth grade—that culminates with each grade’s much-anticipated overnight adventure. (While students aren’t required to go on the trips, the majority do. The school does not allow students who have significant behavioral issues or who are failing three or more classes to attend.) Other teachers integrate the themes into their curriculum at the end of the school year, too: For their final English project, for example, the eighth graders must choose a book set in Alaska.

“It’s so Ketchikan,” Kinney says. “I mean, Ketchikan is living outdoors, is hiking, is fishing, is boating, is being out there. And so learning to do it safely makes a lot of logical sense, but also was a lot of fun.”

On a crisp sunny day last spring, the U.S. Coast Guard ferried Ketchikan’s eighth graders to their respective islands. Each group consisted of approximately 20 students (separated by gender), one teacher leader, and three or four parent chaperones. (For safety, the adults had access to cellphones and radios—the kids did not.)

On Back Island, the leader was 29-year-old Jamie Karlson, a sprightly music teacher with a pixie cut and a quick laugh. Right away, she directed the students to find shelter. In groups of four, they headed to the woods and employed techniques they’d learned in class: draping plastic sheets over twine strung between evergreens, and wrapping rocks along the edges to weight them down. Shelter secured, they played cards, gossiped, and hid from one another during a round of sardines, exhilarated with the freedom of being outdoors on a school day.

Later in the afternoon, Karlson blew her whistle three times, signaling the students to assemble on the beach. “You have 10 minutes to collect tinder, kindling, and fuel, and then it’s time to gather food,” she said.

Karlson wanted the students to begin searching for food several hours before that evening’s 8:08 p.m. low tide, explaining that “it’s best to forage things as they're getting uncovered.” Since Southeast Alaska has some of the biggest tides in the world, changing as much as 25 feet in six hours, each year’s survival trip is timed around lower-than-average “minus tides,” which provide the best opportunities for foraging.

The girls scattered, gathering wood and old-man’s beard, a pale-green lichen that makes a good fire starter. One of the chaperones, Tony Yeisley, approached his daughter Savannah. In his hands was an unruly clump of dried moss, cedar, and seagrass. “That’s going to light up like a Roman candle,” he told his daughter with a grin. An easygoing plumber who plays the electric guitar, Yeisley had already been on four survival trips: his own, 34 years prior, and three of his four older children’s. This trip, with his youngest, could be his last.

When it came time to forage, the students seemed unsure how to begin. They cautiously fanned toward the tideline, scanning for anything that looked edible. Gabriella Mas decided to look for limpets, tiny marine snails that cling to intertidal rocks. But about 15 seconds into her hunt, she shouted, “There’s none!” Karlson called out, “They’re tricky; look closer to the water.” A few moments later, Mas exclaimed to her partner, “Oh my god, there’s so many here. There’s like a million—use your knife!”

Limpets, easy to spot and pry from their perches, turned out to be the protein of choice for many students’ first meal. Most of the girls boiled them with rice and bouillon cubes from their coffee cans, along with a variety of sea lettuces salvaged from the shore. (One lettuce called “sugar rack” was unanimously declared to sound better than it tasted.)

On the horizon, seals peeked out of the water, and a humpback whale swam by with her calf. Enormous bald eagles skirred overhead. The girls relaxed quietly around the fire, or in their shelters, before tucking into their sleeping bags at 10 p.m., just as the last rays of light faded from the sky.

The first Alaskan city along the famed Inside Passage, Ketchikan is known for several things: commercial fishing (77 million pounds of salmon, halibut, and other seafood passed through its docks in 2017, according to the National Marine Fisheries Service), rich Native American culture (it’s home to the biggest collection of totem poles in the state), and cruise ships (more than 1 million passengers visit each summer).

It’s also famous for its “liquid sunshine.” Located in the 16.8 million acre Tongass National Forest, the largest remaining temperate rain forest in the world, the region’s lush mountains and streams are fed by an average of 152 inches of rain each year. (By comparison, neighboring Seattle averages 37 inches.) Strong winds are common too; in 2018, a winter storm clocked gusts of 112 mph.  

While the land area of the Ketchikan Gateway Borough (Alaska’s administrative equivalent of a county) is larger than Connecticut, it has just 13,754 residents. When considering both land and water, a mere 0.1 percent of the borough is inhabited, according to Jonathan Lappin, an associate planner for the borough.

This combination of extreme weather and extreme remoteness is why many view survival education as a vital part of Ketchikan’s curriculum. Sam Pflaum, a 29-year-old electrical worker and commercial fisherman, told me that the eighth-grade trip was “the most useful thing” he did in school, saying: “It probably has saved my life.”

He cited the night of December 27, 2012, as an example. While he was on his way home to Ketchikan, the pull cord snapped off his boat’s engine. It was nearly dark, so Pflaum and his companion decided to spend the night on the beach. In the 15 minutes of daylight that remained, buffeted by wind, rain, and snow, they managed to light a fire and set up a shelter—skills Pflaum had learned a decade prior. Despite experiencing 50-mile-per-hour gusts, a foot of snow, and hypothermia, they made it through the night.

To Pflaum, the survival trip is an indispensable part of growing up in Ketchikan. The skills acquired, he explained, are “not something that just grows dust in the back of your brain”; they’re something many residents use. “[In] a lot of places, the wilderness is somewhat canned—it’s in a park or whatever—but up here this place is still pretty wild,” he said. “It’s the most beautiful place on Earth, but it will kill you.”

The sun rose at 4:30 a.m. on the survival trip’s second day. At 7:30 a.m., Karlson roused the students; low tide was a little more than an hour away, and they needed to scavenge their breakfast. Hungrier and more confident than they’d been the day before, the girls were ready to expand their boundaries beyond limpets. The husky sea cucumbers were tempting, but the young survivalists had no idea how to turn them into food.

The chaperone Brett Summers took charge. Summers, a lifelong Ketchikan resident who was there with his daughter Piper, wore Dickies jeans under his Xtratufs and a baseball cap over his black ponytail. As several students gathered around, he pulled a knife from his belt loop and cut a six-inch cucumber open. A gush of seawater poured out, revealing its spindly guts. The girls peppered Summers with questions and concerns: “Ugh, why is that happening?” “Is that his butthole?” “It looks like spaghetti!” “Does that hurt?” His response: “Eat it—it won’t kill you.”

Hunger, indeed, soon vanquished squeamishness. Pairs of girls ventured off to different parts of the island; within 10 minutes, they pranced back to camp with their prey draped across their arms.

Karlson, who jokingly referred to the cucumbers as her “breakfast bacon,” fluttered between groups, answering questions and observing dynamics. She would, eventually, have to grade each student in 10 categories, including fire building, shelter arrangement, staying dry, cooking food, common sense, and attitude. “It’s fun to see them out here in a totally different environment,” she told me. “They have to work together in ways they probably never would in a classroom.”

All told, the morning’s haul was impressive: In addition to limpets and sea cucumbers, the girls tracked down gumboots, rock scallops, urchins, red rock crab, and tiny shrimp. They had also grown more adventurous with their recipes; one group even created seaweed “wraps” filled with rice and sea cucumber. One student, Makena Johansen, admitted that foraging was easier than she thought it would be, and that the sea cucumbers tasted better than she’d imagined. “Yeah,” added Wileena Baghoomian, another student; “At first they were gross, but now they’re kinda good.”

The rest of the day was spent on a fire-building contest, a hand-built stretcher race, a talent show, and, of course, more foraging. Despite their growling stomachs, the students’ morale remained high. Many conversations centered around food—one student, Julia Spigai, said she’d never again forgo a box of leftovers at a restaurant—but they didn’t complain much.

They seemed to understand that the discomfort was part of the 45-year-old rite of passage their friends, siblings, and parents had all completed. “They’re preparing you for living in Alaska so you know you’re not gonna die,” Savannah Yeisley said matter-of-factly. “A lot of people don’t think they could get stranded, but it happens.”

Around the campfire that night, the chaperones actually lamented the unusual abundance of sun; they worried the good weather was making the trip less challenging for the kids. “It’s not as much of a survival trip in this weather,” said Todd Bright, a stay-at-home dad who had been on two prior trips (his own, in 1987, and his older son’s). “Out here you’re not going to starve—it’s the rain and cold you’ve got to worry about.”

That tough Alaskan attitude permeates the culture of the survival trip, and is shared by students, parents, and even those responsible for orchestrating the event. “You can’t help but think of all the things that could go wrong—but they haven’t,” says Sherilynn Boehlert, the principal of Schoenbar Middle School. “They’re going to be hungry, and they’re going to be fine.”

In this age of helicopter parenting and standardized exams that require teaching to the test, it is hard to believe Ketchikan’s survival trip has, well, survived for so long. Yet despite the massive commitment involved—especially on the part of teachers, who aren’t paid extra for their time—no one seems to question the importance of the trip, or the likelihood that it’ll continue for another four decades.

Talk to people from Ketchikan for long enough, and they will invariably recall their own trip: the rain and wind, the sweet Dungeness crabs, the after-dark incidents that caused the trips to stop being coed (everyone wants to take credit for that). Kinney, who’s probably been on more survival trips than anyone, tells vivid stories of eighth-grade girls skinning an octopus on a tree branch, the chaperone who brought—and slaughtered—a chicken one year, or the time it snowed “three to five” inches during the trip. In this town, the survival trip is education, yes, but it’s also history, community, and tradition.

“Education constantly needs to go back to where the real world is, and tie what you're learning into what really life is all about,” Kinney said. “That's a part of why the survival trip strikes such a rich chord with people. Students learn by doing—by seeing life.”

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

At least 2,000 children have now been forcibly separated from their parents by the United States government. Their stories are wrenching. Antar Davidson, a former youth-care worker at an Arizona shelter, described to the Los Angeles Times children “huddled together, tears streaming down their faces,” because they believed that their parents were dead. Natalia Cornelio, an attorney with the Texas Human Rights Project, told CNN about a Honduran mother whose child had been ripped away from her while she was breastfeeding. “Inside an old warehouse in South Texas, hundreds of children wait in a series of cages created by metal fencing,” the Associated Press reported. “One cage had 20 children inside.”

About 65 million years ago, shortly after the time of the dinosaurs, a new critter popped up on the evolutionary scene. This “scampering animal,” as researchers described it, was likely small, ate bugs, and had a furry tail. It looked, according to artistic renderings, like an especially aggressive New York City rat. And it had a placenta, an organ that grows deep into the maternal body in order to nourish the fetus during pregnancy.

The rodentlike thing would become the common ancestor of the world’s placental mammals, with descendants that include whales, bats, dogs, and humans, among many other species. And today, the placenta might hold the key to one of the most enduring mysteries in human medicine: Why do women suffer much higher rates of autoimmune disease than men do?

Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.

There’s a moment about 15 minutes into the first episode of Years and Years that made me gasp at its audacity, its prescience, its visual horror. The new six-part series from the British writer Russell T. Davies (Doctor Who, A Very English Scandal) charts the life of the Lyons family over the course of 15 years, starting in 2019 and ending in 2034. It’s a kitchen-sink saga that barrels its way through births and marriages and betrayals, but also through the near-future. In 2024, Stephen Lyons (played by Rory Kinnear), a financial adviser, is at home with his wife, Celeste (T’nia Miller), both rushing their way through the morning routine. When the camera turns to their teenage daughter Bethany (Lydia West), her face isn’t recognizably human. Instead, she looks like a 3-D version of a Snapchat puppy, with vast cartoon eyes, wagging pink ears, and a brown snout. When she talks, her voice is grotesquely distorted, a robotic hallucination of a child’s cadence. “I might have to start limiting filter time,” Celeste says in the same exasperated, noncommittal way that you might think, I really should spend less time on Twitter.



Neuroscientists describe the adolescent brain—that is, the human brain from ages 10 to 24—as a sort of lawless, hedonistic place: Throughout those particular years of development, “the brain’s region-specific neurocircuitry remains … vulnerable to impulsive sex, food, and sleep habits,” according to researchers. It’s hard to imagine a better place to observe all three of those phenomena simultaneously at work than at any institution open 24 hours near a college campus.

When the national media turns its eye to college campuses, it often focuses on the ways the college experience has evolved in recent years—with regard to, say, free-speech issues, or campus safety, or matters of misconduct and prevention. So it’s easy to overlook the fact that one of college’s most beloved features—a round-the-clock culture of frivolity and togetherness—has barely changed at all. College students, especially those who live on or near the campuses where they attend class, are uniquely suited to the 24-hour–hangout lifestyle, and that fact has sustained a cottage industry of open-all-hours locations, usually food-centric, kept afloat by students’ boundless appetite for friendship and flirting (also, fries). After all, undergrads, being generally around the age range of 18 to 22, are just young enough to consider a 1 a.m. study break with burgers or burritos an appealing, gastronomically nonthreatening possibility, and just old enough to be able to go out into the night to pursue it unsupervised.

Of course, not every college town or campus has a vibrant after-midnight social scene. Students at the University of Hawaii at Manoa, for example, described a party scene that mostly consists of happy-hour specials followed by hangouts in dorms and apartments. But despite the convergence of several forces that threaten the future of the 24-hour college hangout spot—some schools have begun to close certain institutions at night and emphasize the importance of sleep for a healthy lifestyle, while elsewhere bars and restaurants popular among college students have recently been sites of mass gun violence—in many university towns across America, it lives on. Almost every student I spoke with for this story could name without a moment’s hesitation where that place was, where everybody just sort of winds up at the end of the night. I’ve profiled a sampling of those places from across the country below, featuring photos from student photographers at each university.

When wintertime comes to the Kerrytown neighborhood in Ann Arbor, Michigan students often stand in line “commiserating” out in the cold at night while they wait for a table at the Fleetwood Diner, says Jonathan Hull, a senior acting major. During the week, people sometimes wind up at Fleetwood after evening classes, Hull says. But on the weekends, the “small, cramped space” gets a little rowdy late at night as students wander in in search of the diner’s famous Hippie Hash: hash browns with mixed vegetables and a generous helping of melted feta cheese.

It’s a decently satisfying dinner when you’re in an upright state of mind, “but it definitely tastes better when you’re drunk. Oh, it tastes way better,” Hull emphasizes. (When I spoke with Hull on a Sunday for this story, he was still recovering from a trip to Fleetwood the night prior. After a friend’s 22nd-birthday party—“so much tequila” was consumed—they’d wound up at the diner around 3 a.m.) Fleetwood’s cozy nature, coupled with the noise levels of its weekend clientele, often makes for a chaotic environment, which Hull says is deftly policed by the waitresses on staff. “When you’re just a hammered student, they’re trying to get you in and out as fast as possible,” he says. “They don’t have time for bullshit.”

Morehouse College’s most reliable late-night tradition is one it shares with plenty of other communities across the southern U.S.: “Across races, across religions, across sexualities, any demographic in the South—we all end up at Waffle House,” says Chad Rhym, a senior studying sociology at Morehouse. For students at Morehouse, as well as at the neighboring Spelman College, Clark Atlanta University, and Georgia Tech, “it’s the after-party, I think is the best way to put it.”

Waffle House is, all things considered, a more respectable choice for sober dining in the daytime than some of the other open-all-hours spots near campus. At the nearby fast-food chain Cook Out, for example, the line of arriving Ubers gets “crazy” around 2 or 3 a.m. on weekends, “but would I ever, like, ask somebody to go to Cook Out with me before 11 p.m.? Absolutely not. That would tarnish my image,” Rhym laughs. “You don’t go unless you’re inebriated.”

Still, Rhym says that Waffle House’s prime time is “the real grimy, grungy hours” after midnight. At Morehouse, where much of the party scene consists of student house parties, the “pilgrimage” to Waffle House takes place as a party winds down. “We get our food, but it’s also a space to get to know each other, and to kind of convene and deliberate about the party. Talk about Did you get a girl’s number? and Who’d you dance with?” It can also be a pretty good place to finish up any unfinished business from said party: “You get to see other people who might have gone to that party go to that Waffle House, so you get an opportunity to get someone’s number that you didn’t get from the party,” Rhym says. “It’s the bonus round.”

In Lauren Gold’s hometown in northeastern Virginia, “everything closes at, like, nine,” she says. So when Gold made her first late-night visit to the 24-hour Burger King just south of Northwestern University in Evanston, Illinois, during her first week on campus as a freshman, “I was like, Oh. So this is college,” she says. It was a busy night at BK, she recalls, and she’d trekked over with a group of other freshmen from her dorm. “No one knew anyone. It was a lot of young people talking to, essentially, strangers,” she remembers.

Two years later, many of the theater major’s fondest, goofiest memories of college have taken place at the Evanston Burger King. Around 5 a.m. one Halloween, after campus celebrations had wound down, Gold was closing out the night at Burger King with a few friends when Cyndi Lauper’s “Girls Just Want to Have Fun” came on over the speaker system. “I was like, ‘I have to dance to this song!’ and my friends said, ‘You know, you should probably stand on a chair,’” she remembers. “I was like, ‘You’re right.’” Another time, she showed up to get a Frozen Coke in cocktail attire after attending a formal at the Willis Tower in Chicago.

And while Gold appreciates that BK is just about the cheapest meal near campus, it’s not the food itself that keeps her coming back regularly: Gold, a pescatarian, usually orders just fish sandwiches. “Really not their specialty at all, I know,” she says.

During the daytime, Florida State’s Sun Stop Urban Market convenience store is where students like Dani Palazzo, a 2018 FSU graduate and a current FSU masters student in sports management, go to pick up a toothbrush, a six-pack, or maybe a cheap southern-style fast-food lunch between classes. But it moonlights as the place on campus where you’re most likely to spot tipsy FSU students in sopping wet, chlorine-scented clothes.

Sun Stop opened in the summer of 2018 and has already established itself as a popular place for students to grab food on weekend nights after football tailgating. “It’s loud, everyone’s talking over each other, everyone’s talking to each other even though they don’t know each other,” Palazzo says.

But between 1 a.m. and 3 a.m. on, well, just about any night of the week (“I swear people find a reason and a way to go out every single night here”), Palazzo says Sun Stop fills up with students in search of late-night eats after partying at the bars in the nearby College Town neighborhood of Tallahassee. One of those bars is Recess, a rooftop club with a pool. Which used to have a cover over it, Palazzo thinks—but for one reason or another, it seems to have vanished. “Any given night you’ll see people swimming in the pool fully clothed,” she chuckles. “It’s a nightmare.”

At Brown University in Providence, Rhode Island, one of the few places where students can hang out around the clock is the basement of the university’s Science Library—or, as it’s commonly known to students, the SciLi basement. Separated into sections demarcated by acceptable decibel level, some areas are designated for group work, other areas are for semi-quiet work, and the no-decibels zone is “like, dead quiet,” says Subhanik Purkayastha, a sophomore majoring in computational biology.

While the SciLi basement isn’t the only study space that’s open all night, it’s “a lot more chill” than some of the other places students can go to read, or write, or do problem sets, or … watch a quick TV episode or two on Netflix. On nights during midterms and finals season, especially, “it’s impossible to get a table,” Purkayastha says—so some students park there for hours-long stretches, sometimes in their sweats or pajamas, and take their study breaks right there in the library. “A person will have five cups of coffee, snacks, sweatshirts, all these papers everywhere,” he says. “People settle down and they’re in it for the long haul.”

The SciLi is also, however, a place where students socialize and even flirt. The group study rooms tend to get noisy when conversation eventually strays from homework, and sometimes, Purkayastha says, pairs of students get together to study or do a problem set at the SciLi as a gateway to a real date or social hangout later on. Or sometimes even right after the homework gets done: As Purkayastha says, sometimes an all-nighter at the SciLi can end in a groggy early-morning breakfast at the off-campus, early-hours breakfast cafe Louis’. “Everyone has bags under their eyes, everyone looks so sleepy,” Purkayastha says, “but seeing all the nice breakfast food in front of everyone, they’re all so happy.”

The most popular 24-hour spot on the Williamsburg, Virginia, campus of the College of William & Mary holds a few unusual distinctions: For one thing, it’s a freestanding Wawa, unattached to a gas station. For another, it’s a site where hungry college kids and on-break Revolutionary War reenactors routinely cross paths. “It’s not unheard-of to see people dressed in full colonial garb waiting in line during the day,” says Leonor Grave, a senior studying English. “It sort of feels outside of space and time in that way. It’s the twilight zone of the William & Mary campus.”

According to Grave, the desirability of particular on-campus dormitories is heavily influenced by their proximity to the Wawa. “It’s sort of a campus institution,” she says. “The water from the water fountain is free, and people like to joke that it’s magically the best water in the universe.” All day long, students stop in to fill up 44-ounce plastic cups with the enchanted “Wawater.” But after midnight, the Wawa—which offers no seating—gets “absolutely packed” with William & Mary students hungry for the local Wawa specialties: macaroni and cheese (served with optional Old Bay seasoning) and quesadillas. While students stand around waiting for greasy, cheesy treats, Grave says, “you run into everyone you’ve met during your time at college and even forgot that you’ve met.”

It’s been a long time since the popular “GHeav” in New Haven, Connecticut, was actually named anything even remotely related to “GHeav” (pronounced JEE-hev). In 2015, the name of the grocery and sandwich shop changed from Gourmet Heaven to Good Nature Market when new management took over. (The previous owner was charged with wage theft.) But like any good college nickname, it’s stuck around longer than most people’s memory of how it originated.

On most nights of the week, GHeav is populated by a potentially uneasy mix of Yale students, some of whom are sober and trying to get work done in the upper seating area and others of whom have reached “the level of insobriety where all you really want is a gross fried something-or-other sandwich,” says Jacob Middlekauff, a senior history major. When Middlekauff finds himself in the former group, he often packs up and heads to the library. And he knows which nights of the week are no-gos for studying at GHeav: “I would not want to be working there at 1 a.m. on a Saturday,” he says.

On Wednesdays, when GHeav gets particularly “rambunctious,” students wait upwards of 15 minutes in line to order bacon, egg, and cheese sandwiches—the quickest-assembled option on the menu, Middlekauff notes. And generally, that’s the last stop of the night for students: Whether you’ve been pulling an all-nighter of the studious variety or otherwise, “you eat your sandwich, and then you go to bed.”

When Paul Moler opened the Fuego Tortilla Grill in College Station, Texas, in 2010—the first of what’s now a three-location taco franchise—he knew he had an opportunity on his hands. The first time that Moler, now 60, visited the town where more than 53,000 Texas A&M undergraduates go to school, “it was October, middle of football season; a cold front was just starting to move in. I’m driving down University Avenue, and there’s just this sea of kids,” he remembers. “We called them and said, ‘Hey, we want to do the deal.’”

His hunch that a 24-hour taco joint on a college campus might be a hit was correct. These days, Fuego is where many a Texas A&M student goes after a football game or at the end of a night out, “just to get some sort of food in us,” chuckles Samantha Mahler, an agricultural communications and journalism major. “We get a taco, we split a bowl of queso. We end up just talking about our night, weird things we experienced while we were out.” (Moler says the College Station location goes through some 120,000 pounds of cheese every year making the restaurant’s famed queso dip.)

Fuego’s popularity on campus seems inextricably linked to the school’s powerhouse college-football program. “When football players come back to A&M after being [on the road], you can typically find them at Fuego,” Mahler says, and friends often inform each other of who they’ve recently spotted getting Fuego tacos. “We love our football players. They’re like family to us.”

On game days, Moler says, “it’s stupid. The line starts at 10 in the morning and never stops until three in the morning. We’ve done as many as 4,000 people in a day through that place,” he adds. And in 2017, when the NFL first-overall draft pick Myles Garrett wrote in a farewell letter to Texas A&M that one thing he’d miss terribly about College Station was Fuego, Moler’s phone blew up with congratulatory phone calls from all around the state.

“I kept saying, ‘Okay, great. We’re not the story, but great,’ and I’d hang up,” Moler says. “But, I mean, it is God’s grace times 20. College Station is such a blessing.”

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

At least 2,000 children have now been forcibly separated from their parents by the United States government. Their stories are wrenching. Antar Davidson, a former youth-care worker at an Arizona shelter, described to the Los Angeles Times children “huddled together, tears streaming down their faces,” because they believed that their parents were dead. Natalia Cornelio, an attorney with the Texas Human Rights Project, told CNN about a Honduran mother whose child had been ripped away from her while she was breastfeeding. “Inside an old warehouse in South Texas, hundreds of children wait in a series of cages created by metal fencing,” the Associated Press reported. “One cage had 20 children inside.”

About 65 million years ago, shortly after the time of the dinosaurs, a new critter popped up on the evolutionary scene. This “scampering animal,” as researchers described it, was likely small, ate bugs, and had a furry tail. It looked, according to artistic renderings, like an especially aggressive New York City rat. And it had a placenta, an organ that grows deep into the maternal body in order to nourish the fetus during pregnancy.

The rodentlike thing would become the common ancestor of the world’s placental mammals, with descendants that include whales, bats, dogs, and humans, among many other species. And today, the placenta might hold the key to one of the most enduring mysteries in human medicine: Why do women suffer much higher rates of autoimmune disease than men do?

Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.

There’s a moment about 15 minutes into the first episode of Years and Years that made me gasp at its audacity, its prescience, its visual horror. The new six-part series from the British writer Russell T. Davies (Doctor Who, A Very English Scandal) charts the life of the Lyons family over the course of 15 years, starting in 2019 and ending in 2034. It’s a kitchen-sink saga that barrels its way through births and marriages and betrayals, but also through the near-future. In 2024, Stephen Lyons (played by Rory Kinnear), a financial adviser, is at home with his wife, Celeste (T’nia Miller), both rushing their way through the morning routine. When the camera turns to their teenage daughter Bethany (Lydia West), her face isn’t recognizably human. Instead, she looks like a 3-D version of a Snapchat puppy, with vast cartoon eyes, wagging pink ears, and a brown snout. When she talks, her voice is grotesquely distorted, a robotic hallucination of a child’s cadence. “I might have to start limiting filter time,” Celeste says in the same exasperated, noncommittal way that you might think, I really should spend less time on Twitter.



In the late 1960s, almost all prime-working-age men, typically defined as 25 to 54, worked—nearly 95 percent. That figure had dipped to 85 percent by 2015—a decline most acutely felt among men without college degrees. The trend of men dropping out of the labor force, particularly non-college-educated men, has been building for more than six decades. It has been a slow withdrawal, but a steady one—a flow that began with a sharp decline in opportunities for men who dropped out of high school, and grew to include those who earned a diploma but not a degree.

It’s become something of a ritual to debate the value of a college degree, but as Current Population Survey data show, there has been a sharp decline in employment among non-college-educated men compared with those who have college degrees—or even those who have spent some time in college. As a recent report from the U.S. House Education Committee shows, “Two out of three jobs are filled by individuals who have at least some college education.”

Economists have been working to understand the roots of the decline, and have come up with a cadre of theories: Perhaps it’s a case of insufficient wages for jobs that don’t require a degree; or maybe rising incarceration rates are the real culprit (people with criminal records have a harder time getting jobs); or it could be that more jobs that did not require a degree in the past do now.

A recent working paper from the National Bureau of Economic Research suggests that maybe it’s all of the above and then some—a complex combination of low wages for non-college-degreed jobs; incarceration rates, which are higher among men without degrees; and a sharp decline in marriage rates among less educated men, which may remove an economic incentive to work—all wrapped up into a slowly rolling ball that’s knocking more and more men out of the workforce. Sure, these issues are affecting college-educated men as well, but each of them is felt more acutely by those without degrees.

The researchers, Ariel Binder, a graduate student, and John Bound, a professor of economics, both from the University of Michigan, poke at the incomplete explanations one by one. First, there are the low wages. “The market will pay you a certain wage to do a job, and if you like that wage, you take the job,” Binder told me. As the wage gap has grown between those with college degrees and those without, economists have suggested that men aren’t as interested in taking some of the less lucrative jobs. “This explanation doesn’t seem entirely sufficient,” he says. Wages for men without college degrees, adjusting for inflation, haven’t changed that much since the ’60s. “It’s hard to see why fewer and fewer men seem willing to seek work at wages that aren’t very different than wages faced by earlier cohorts,” he added.

Then there is the rise in incarceration rates. A 2014 poll found that 34 percent of nonworking men ages 25 to 54 had criminal records. Still, the decline in labor-force participation started in the ’60s, before the rapid rise of the prison population. That may enhance the trend, but it can’t, alone, explain it.

Finally, there was a boom in enrollment in Social Security disability-insurance benefits from the ’60s to the ’90s, Binder says, though the trend slowed more recently. More men took advantage of those benefits, when in the past they might have been forced to work through their injury. But that would primarily affect men ages 45 to 54, he says—it can’t account for younger nonworking men.

The holes in each theory led the researchers to a new potential explanation: the dramatic change in family structure since the 1960s, and “the tremendous decline in the share of nominally less-educated men forming and maintaining stable marriages.” As family dynamics have shifted and more women have gone to work, an important labor-supply incentive has been removed. Men might not have families to take care of, or if they do have families, their wives might be doing more of the providing.

Each of these trends is a puzzle piece that can partially, but not fully, explain the men missing from the workforce. The study authors openly acknowledge that there is not yet a complete answer, though they’re attempting to piece together a more complete picture. “This is really quite a complex phenomenon, and even though it started 50 years ago, we still don’t fully understand it,” Binder says. However, one thing is abundantly clear: Each of these trends is amplified by the lack of a college degree.



The numbers are staggering: White Americans with a college degree are on average three times as wealthy as black Americans with the same credential, and in families whose head of the household is employed, white families have 10 times the wealth of black ones. One estimate on the conservative end suggested that this wealth gap could take two centuries to close.

And the thing about wealth, says Tatjana Meschede, a researcher at the Institute on Assets and Social Policy at Brandeis University, is that it’s “sticky”: It tends to stay with a family. That has serious repercussions for how much money people accumulate over the course of their lives, regardless of whether they attend college—something that is usually thought to make a significant difference financially.

A forthcoming study from Meschede and Joanna Taylor, also a researcher at Brandeis, in the American Journal of Economics and Sociology, makes the point clearly. Building on a 2017 study of theirs that examined wealth accumulation among college graduates—as well as “intergenerational financial transfers,” like when a parent helps a recent college grad out with rent or, say, gives her $1,000 a month to spend on whatever she pleases—the two looked specifically at how family inheritances, which are usually larger and tend to come all at once, factor into building and maintaining wealth.

The two researchers focused specifically on inheritances among families where at least one parent has a college degree. They looked at families like this in order to test the notion that higher education is a great equalizer.

The differences that they found between black and white families were stark. “Among college-educated black families, about 13 percent get an inheritance of more than $10,000, as opposed to about 41 percent of white, college-educated families,” Taylor said in a release announcing the new research. More specifically, white families that receive such an inheritance receive, on average, more than $150,000 from the previous generation, whereas that figure is less than $40,000 for black families.

Meschede and Taylor focused on inheritances of more than $10,000 because, they say, these qualify as “transformative” assets—meaning, they could significantly alter the course of a life. As Mark Huelsman, a policy analyst at Demos, an advocacy group, tweeted earlier this week after seeing Meschede and Taylor’s study, “the average family inheritance to a white college grad can pay off the average undergrad debt balance”—more than $30,000—“and have enough left over for a 20 percent down [payment] on a $575,000 home.” (And that’s assuming the inheritor has student debt to begin with.)

That head start on wealth provides lifelong momentum, Taylor told me in an interview. The median wealth held by black families with a college degree and student loans by the time the head of household is 65 years old, she said, is about $61,000, versus roughly $422,000 for white families under the same circumstances.

Getting a college degree can, in some cases, help close the income gap—meaning annual earnings—and, as I have written, can do wonders for socioeconomic mobility. But the enduring legacy of slavery, and centuries of de jure and de facto segregation have led to a wealth gap that is practically insurmountable. As my colleague Ta-Nehisi Coates wrote in 2014, the wealth gap “puts a number on something we feel but cannot say—that American prosperity was ill-gotten and selective in its distribution.”

There have been proposals, including systems of reparations such as baby bonds for black families that are scaled to family wealth, to get kids started on an equal level. Those ideas seem to be on the right track—a college degree alone certainly can’t make up the difference.



Carol Folt had to make a decision, and none of the options was great. The University of North Carolina at Chapel Hill chancellor was caught between a conservative Board of Governors that seemed to favor returning a monument of a Confederate soldier, known as Silent Sam, to the pedestal from which it had been yanked last fall and a student body that heavily favored its permanent removal. The stakes—her job, but also the security of UNC’s campus—were high.

In a letter to the campus community on January 14, Folt announced that she’d made up her mind. She’d be stepping down at the end of the semester, and she’d be taking down what was left of Silent Sam, immediately. “The presence of the remaining parts of the monument on campus poses a continuing threat both to the personal safety and well-being of our community and to our ability to provide a stable, productive educational environment,” she wrote. “No one learns at their best when they feel unsafe.”

Folt’s choice highlights the tightrope that university leaders walk between ideologically driven boards and their campus constituencies. “When you get right down to it, the relationship with the board—and the extent to which the board is separate from campus, and doesn’t necessarily have a full appreciation for the different views that may exist on campus—that disconnect puts presidents in an incredibly difficult position,” Michael Harris, a professor at Southern Methodist University who has studied the turnover of college presidents, told me. That difficult position may be one that fewer qualified candidates for college leadership are choosing to take. One survey noted that in the past decade, more current college presidents have been sidestepping the traditional pathways to leadership and, anecdotally, even some of those nontraditional candidates have turned down potentially tumultuous positions. But if leaders with higher-education experience won’t do the job, who will?

The Board of Governors was, predictably, furious with Folt’s decision. “We are incredibly disappointed at this intentional action,” Harry Smith, the board’s chair, said in a statement. “It lacks transparency and it undermines and insults the Board’s goal to operate with class and dignity.” The board met the next day and accepted Folt’s resignation, but not effective at the end of the semester. Instead they gave her two weeks.

The accelerated ouster was the culmination of years-long tension at the university between the ideologically conservative board and university leaders. Margaret Spellings, the president of the UNC system, who announced she’d be resigning this year as well, had her own tensions with the board, including over her decision to ask the state governor for help in deciding Silent Sam’s fate. She had been hired after Tom Ross, the former system president, was himself forced out by the board in 2016. The rapid cycle of hiring, resignation, and removal creates a problem for the university. “I don’t know who would want that job right now, given the board and its ideology. And I worry about who they would find palatable enough to put in the position,” Harris told me. “One of the great university systems, and one of the great universities, is going to be damaged by this process.”

That tension between a college’s board and its president isn’t one exclusive to the UNC system. A few years ago, following a string of athletic scandals, Harris wanted to know whether more college presidents had been fired in recent years—or whether they had their resignation accepted on an accelerated schedule. Two years ago, he and Molly Ellis, a graduate student, published what they had found. Yes, the study said, over the past two decades presidents had been getting fired more often. But the why was perhaps more interesting: Boards have always had the responsibility of “hiring and firing” a president, but “there’s a sense of activism among boards now,” Harris said. “Historically there has been a little more deference than boards are willing to give now.”

Of course, it isn’t just board oversight that could make the job of college president seem unappealing. Provosts, or even deans, who may have been groomed for the position might balk at the fundraising and politics associated with it. And these days, many open college presidencies come ready-made with crises. John Engler recently became the second president to leave Michigan State University in one year. The University of Oklahoma’s president, Jim Gallogly, is trying to navigate instances of racism at the institution, notably, a Snapchat video of students wearing blackface and saying the N word that went viral this month, which follows another racist viral video at the institution in 2015. There’s also an ongoing crisis at Baylor University, which is dealing with the fallout from a sexual-assault scandal.

“The number of qualified candidates is probably on the decline due to the job being less attractive, and I think we have boards trying to look for outside-the-box hires that more often than not don’t tend to work out,” Harris said. Those outside-the-box hires could look like Rex Tillerson, the former secretary of state, who was courted to be the next chancellor of the University of Texas system; or like Mick Mulvaney, Donald Trump’s acting chief of staff, who met with the University of South Carolina’s board before ultimately deciding that he was not interested in the position of president.

A board has a responsibility to a university, one that can be corrupted when political ideologies are introduced, Harris said. “That fundamentally damages a university, and that can take generations to recover from,” he said. He pointed to the damage that politics have done to the University of Wisconsin system as an example. It’s a public higher-education system that was admired by the world, but it’s been hampered by controversy after budget cut after controversy over the past decade, and, in short, it’s suffering. It’s the kind of situation that UNC is hoping to avoid, but one that it, and other institutions, may be on a collision course toward as boards become more ideologically driven—and if qualified candidates continue to shy away from university leadership.



A question that leads most conversations about historically black colleges goes something like this: The purpose of black colleges was clear before Brown v. Board of Education, but now that black students can attend any college, why are these schools still necessary?

A few statistics give a rather clear answer. Despite the fact that black colleges (often referred to as HBCUs, or historically black colleges and universities) account for just 3 percent of four-year nonprofit colleges, their alumni account for roughly 80 percent of black judges and 50 percent of black lawyers and doctors, and their students account for 25 percent of black undergraduates who earn degrees in STEM (science, technology, engineering, and mathematics). Even so, many of the institutions are struggling financially. Bennett College, an HBCU for women in North Carolina, recently launched a successful  flash-fundraising drive to fight to retain its accreditation, which was ultimately rescinded anyway. (The university filed a lawsuit against its accreditor and retains accreditation while the case works its way through the courts.) The institutions often struggle to marshal the so-called transformational donations that other institutions receive, and public HBCUs, in particular, have been historically underfunded by state governments.

But the sector is not a monolith. Some institutions are private and have fewer than 1,000 students; and then there are the institutions such as North Carolina A&T, a public historically black college in North Carolina, with more than 11,000. On Tuesday, during the The Atlantic's Education Summit in Washington, D.C., Wayne Frederick, the president of Howard University, one of the nation’s most storied black colleges, spoke with me about why people still question the relevance of these institutions, what HBCUs can do to advocate for themselves, and, in light of a recent controversy involving white people walking their dogs on Howard’s campus, how gentrification is affecting the black college in the nation’s capital. The conversation that follows has been condensed for length and clarity. You can watch the full discussion here.

Adam Harris: In light of the statistics [about how essential HBCUs are to black achievement in America,] why do people still question their relevance?

Wayne Frederick: Because unfortunately they probably don’t know the data that you just pointed out. The question isn’t why [HBCUs] still exist; the issue is really, how excellent can we be? We are an essential part of the fabric of higher education because of the contribution we make to diversifying many fields. Clearly, the outcomes from the HBCUs speak for themselves. So what we have to do is make sure they’re as strong as possible so they can fulfill and continue to fulfill that role as strongly as possible.

I’ll give you two data points to further that argument: The National Science Foundation has this study that looks at the past decade. The question was: Who was producing African American undergrads who go on to get STEM Ph.D.s? Howard University was the number-one producer, and the top-10 schools were HBCUs. [Howard] produced 220 in that period of time studied. Stanford, Harvard, MIT, and Yale produced 221. The endowment of those four schools—I think the market is doing a little bit better today based on some tweets—so the endowment of those schools is probably $90 [billion] to $100 billion, and Howard’s is $750 million. So, out-punching your weight class is really the hallmark of HBCUs.

Harris: I’m going to circle back to the question of funding in just a minute, but you were talking about being more excellent. What does it look like for HBCUs to be more excellent?

Frederick: What’s necessary is first to really find areas where we can have the biggest impact and make sure that we do that extremely well. That does require some focused funding in particular areas, but as I mentioned to you before, we have to think a bit out of the box. Miles College, for example, is a small college in Alabama that has Farsi as one of its strengths. Think of our intelligence agencies: I’m not sure how many employees of color we have, and I certainly don’t know how many we have that speak Farsi, but I’m sure that could be very useful to the intelligence community. Then you combine that skill with cybersecurity education and you have a winner. So finding where we can differentiate ourselves is going to be key.

And then when you get to an institution like the one that I’m running and you look at the fact that in 1978 there were more African American males who applied to medical school than in 2014, and Howard University is the number-one producer of African Americans that go on to medical school, the country has to invest in that for us to have better health outcomes. You want to have people who are culturally competent taking care of the population, and you want disparities to close because really, that’s where we spend our health-care dollars. The fact that the maternal mortality rate for African American women is as high as it is partially because you don’t have as many African American physicians taking care of them, or at least participating in the overall ecosystem of health that takes care of them and makes their issues a prominent source of concern.

Harris: One of the things that differentiation requires is the funding to do it; look at Bennett College—a place that had a rush to raise $8 million in 50 days—but over that same time you had more than a dozen non-HBCU institutions that received $5 million donations on their own. So, with what HBCUs are producing, what is preventing large-scale charitable fundraising?

Frederick: Part of this is historical. If you look at the ecosystem around HBCUs, our grads give back in other ways that are not necessarily financial. They tend to go back to lower-income parts of the United States—or their home countries—and they tend to give back in spades in service. If you look at graduates of Morehouse School of Medicine, Meharry Medical College, and Howard School of Medicine, those graduates are more likely to serve in underserved areas. That means that their income levels are going to be lower as a result; and there’s still significant income inequality and discrimination in what African American women would get paid compared to what a white male would get paid. And then when you look at unemployment rates, it’s still almost twice that for African Americans than it is for the rest of the population. So what that means is that the actual amount of dollars that they can give back themselves is a bit suppressed.

We, as in the HBCUs, have to make an argument to the broader society as to why we are important, and to allow people to see the fact that though they may not have attended an HBCU, or they may not be somebody who is African American or comes from a circumstance where they may not have had all the opportunities, why it’s important for these institutions to be strong and to thrive. That’s where we have to make the argument.

Harris: Senator Elizabeth Warren has proposed a $50 billion fund for HBCUs and other MSIs (minority-serving institutions). You talked a bit about the historical underfunding of the institutions; do you think it’s a federal and state responsibility to address it?

Frederick: I have to admit that I’m not usually of the proclivity to suggest that you need the federal and state support, especially for private institutions. In this circumstance, though, I do think it is a responsibility because the diversity of what the 102 HBCUs are providing is so strong that the federal and state governments have an interest in seeing them thrive. [Take] the issue of black doctors as an example. Or if you look at black dentists: Forty percent of the black dentists in this country are produced by two schools—Howard and Meharry. So as far as I’m concerned, the federal government should take an interest in making sure that those schools thrive so that we can boost that.

The other reason is because there’s an outsized burden that you’re putting on these institutions. I’m a surgeon; I trained at Howard. Howard has probably produced more African American women surgeons than any other institution in this country. And since 1970, we’ve probably produced 50 to 60 of those young women. You think about that in a country of 300 million, for one institution to do that and that’s the largest number for any one institution, is a problem. What happens if Howard goes away? All of a sudden we take a crisis and we turn it into an extinction in terms of seeing certain faces in certain fields. So I would think federal and state governments do have a responsibility to do that.

Then when you put it in context of where that funding is now: We have the largest endowment of all HBCUs at $750 million. The institutions that we’re competing with for students are in the Ivy League, and you’ve got Ivy League schools with endowments between $20 billion and $40 billion. If they take 5 percent of their endowment and put it into operating expenses, which is what most of our endowments do, they will be spending $2 billion. With $2 billion, you run my institution with $750 million of operating revenue; you double my endowment with another $750 million; and the other $500 million is gravy; you probably build five buildings. That’s just to put it into context, what spending 5 percent of their endowment in one year would do to Howard, and Howard is at the extreme in terms of financial resources of all the HBCUs. It is a danger to the national interest to not invest in these institutions.

Harris: Let’s switch gears and talk about the town/gown relationship. Howard is in an interesting position where, as D.C. gentrifies, you still have this legacy institution there. How do you manage that relationship as the area around Howard gentrifies?

Frederick: When I became president, I had a meeting with the [Advisory Neighborhood commissioners], the faculty, students, and staff of Howard in the boardroom of the university. I did that every month to make sure everyone was educated about why this 150-year-old institution was there in the first place. Sometimes in our society we just assume that people are going to move into this city, move into this neighborhood, see this university there, and just assume great things. And that’s just not the society we live in. Most of those people would move, take the train, and never even walk on that campus or pick up the news and figure out that this place has produced more black physicians than any other place in the country. So you really have to have an interaction; that’s one.

Then I think we need to look at some of the gentrification differently. I’ve recently been in a discussion with the city about potentially moving Howard University’s hospital to the St. Elizabeth’s campus, and building out our health-sciences complex with the four health sciences—nursing, pharmacy, medicine, and dentistry—around there. That way, you put 1,100 to 1,200 African Americans there who can interact; it could create jobs for the people in that neighborhood. You have 170,000 citizens there and you have no acute-care hospital where a woman can deliver a baby. You have two grocery stores.

We talk about gentrification, but the subplot there is a racial issue, and we unfortunately leave that elephant in the room and talk around it by putting the word gentrification around that elephant. But the truth of the matter is, we should be looking at [the question of]: How do we empower people in that neighborhood so that they can raise their income levels and raise their quality of life?



Every two years, education-policy wonks gear up for what has become a time-honored ritual: the release of the Nation’s Report Card. Officially known as the National Assessment of Educational Progress, or NAEP, the data reflect the results of reading and math tests administered to a sample of students across the country. Experts generally consider the tests rigorous and highly reliable—and the scores basically stagnant.

Math scores have been flat since 2009 and reading scores since 1998, with just a third or so of students performing at a level the NAEP defines as “proficient.” Performance gaps between lower-income students and their more affluent peers, among other demographic discrepancies, have remained stubbornly wide.

Among the likely culprits for the stalled progress in math scores: a misalignment between what the NAEP tests and what state standards require teachers to cover at specific grade levels. But what’s the reason for the utter lack of progress in reading scores?

On Tuesday, a panel of experts in Washington, D.C., convened by the federally appointed officials who oversee the NAEP concluded that the root of the problem is the way schools teach reading. The current instructional approach, they agreed, is based on assumptions about how children learn that have been disproven by research over the last several decades—research that the education world has largely failed to heed.

The long-standing view has been that the first several years of elementary school should be devoted to basic reading skills. History, science, and the arts can wait. After all, the argument goes, if kids haven’t learned to read—a task that is theoretically accomplished by third grade—how will they be able to gain knowledge about those subjects through their own reading?

The federal No Child Left Behind legislation, enacted in 2001, only intensified the focus on reading. The statute required states to administer annual reading and math tests to students in grades three through eight and once in high school, and attached hefty consequences if schools failed to boost scores. The law that replaced No Child Left Behind—the Every Student Succeeds Act, enacted in 2015—has eased the consequences but has hardly weakened the emphasis on testing.

What is tested, some educators say, gets taught—and what isn’t doesn’t. Since 2001, the curriculum in many elementary schools has narrowed to little more than a steady diet of reading and math. And when test scores fail to rise after third grade—as they often do, especially in high-poverty schools—subjects like history and science may continue to be relegated to the far back burner through middle school.

To some extent, it does make sense to focus on reading skills in the early years. One component of reading is, like math, primarily a set of skills: the part that involves decoding, or making connections between sounds and the letters that represent them.

But educators have also treated the other component of reading—comprehension—as a set of skills, when in fact it depends primarily on what readers already know. In countries that specify the content to be taught at each grade level, standardized tests can test students on what they’ve learned in school. But in the United States, where schools are all teaching different content, test designers give students passages on a variety of topics that may have nothing to do with what they’ve learned in school—life in the Arctic, for example, or the disappearance of Amelia Earhart. The tests then ask questions designed to assess comprehension: What’s the main idea of the passage? What inferences can you make?

On a daily basis, teachers have their students practice skills and strategies like “finding the main idea” or “making inferences.” And teachers select books that match the given skill rather than because of the text’s content. Rarely do the topics connect: Students might read a book about bridges one day, zebras the next, and clouds the day after that.

Cognitive scientists have known for decades that simply mastering comprehension skills doesn’t ensure a young student will be able to apply them to whatever texts they’re confronted with on standardized tests and in their studies later in life.

One of those cognitive scientists spoke on the Tuesday panel: Daniel Willingham, a psychology professor at the University of Virginia who writes about the science behind reading comprehension. Willingham explained that whether or not readers understand a text depends far more on how much background knowledge and vocabulary they have relating to the topic than on how much they’ve practiced comprehension skills. That’s because writers leave out a lot of information that they assume readers will know. If they put all the information in, their writing would be tedious.

But if readers can’t supply the missing information, they have a hard time making sense of the text. If students arrive at high school without knowing who won the Civil War they’ll have a hard time understanding a textbook passage about Reconstruction.

Students from less educated families are usually the ones who are most handicapped by gaps in knowledge. Another panelist—Ian Rowe, who heads a network of charter schools serving low-income students in New York—provided a real-life example during his remarks. A sixth-grader at one of his schools was frustrated that a passage on a reading test she’d taken kept repeating a word she didn’t understand: roog-bye. The unfamiliar word made it hard for her to understand the passage. When Rowe asked her to spell the word, it turned out to be rugby.

The implication is clear. The best way to boost students’ reading comprehension is to expand their knowledge and vocabulary by teaching them history, science, literature, and the arts, using curricula that that guide kids through a logical sequence from one year to the next: for example, Native Americans and Columbus in kindergarten; the colonial era and the American Revolution in first grade; the War of 1812 and the Civil War in second grade, and so on. That approach enables children to make sense of what they’re learning, and the repetition of concepts and vocabulary in different contexts makes it more likely they’ll retain information. Not to mention that learning content like this can be a lot more engaging for both students and teachers than the endless practice of illusory skills.

Another panelist—Timothy Shanahan, an emeritus professor at the University of Illinois and the author or editor of over 200 publications on literacy—went on to debunk a popular approach that goes hand in hand with teaching comprehension skills: To help students practice their “skills,” teachers give them texts at their supposed individual reading levels rather than the level of the grade they’re in.

According to Shanahan, no evidence backs up that practice. In fact, Shanahan said, recent research indicates that students actually learn more from reading texts that are considered too difficult for them—in other words, those with more than a handful of words and concepts a student doesn't understand. What struggling students need is guidance from a teacher in how to make sense of texts designed for kids at their respective grade levels—the kinds of texts those kids may otherwise see only on standardized tests, when they have to grapple with them on their own.

That view was endorsed by Marilyn Jager Adams, a cognitive and developmental psychologist who is a visiting scholar at Brown University. “Giving children easier texts when they’re weaker readers,” she said during the panel discussion, “serves to deny them the very language and information they need to catch up and move on.”

The failure to build children’s knowledge in elementary school helps explain the gap between the reading scores of students from wealthier families and those of their lower-income peers—a gap that has been expanding. More affluent students may not learn much in elementary school, but compared to their disadvantaged peers their parents tend to be more educated and have the money to provide knowledge-boosting perks like tutoring and trips to Europe. As a result, those wealthy children are far more likely to acquire knowledge outside of school. Poorer kids with less-educated parents tend to rely on school to acquire the kind of knowledge that is needed to succeed academically—and because their schools often focus exclusively on reading and math, in an effort to raise low test scores, they’re less likely to acquire it there.

The bottom line is that policymakers and advocates who have pushed for more testing in part as a way to narrow the gap between rich and poor have undermined their own efforts. They have created a system that incentivizes teachers to withhold the very thing that could accomplish both objectives: knowledge. All students suffer under this system, but the neediest suffer the most.

The NAEP is a valuable educational barometer, but it’s important to understand that while standardized tests can identify a problem, they can’t provide the answer to it.

While some elementary teachers have embraced the approach advocated by the NAEP panel, it’s clear that most have been trained to in methods that aren’t supported by research, and that many are resistant to change. The University of Illinois’s Shanahan noted that when he speaks to teachers around the country, they’re aghast at the idea of giving struggling readers grade-level books—even when their state’s literacy standards call for doing so.

Still, schools in some parts of the country are embracing the kinds of insights offered by the panelists. Louisiana has not only created its own curriculum but has also asked the federal government for permission to give tests based on that curriculum rather than passages on a variety of randomly selected topics. If that movement spreads, the National Assessment of Educational Progress may finally live up to its name and the American education system may at last be able to unlock the untold potential of millions of students.



In recent years, the common wisdom has been that girls are dominating when it comes to academic achievement. In reading in particular, girls have consistently outperformed boys. Some studies have also found that in a typical U.S. school district, girls have all but caught up in math—a subject in which they had historically underperformed and from which they’d been discouraged thanks to persistent stereotypes about their academic interests. Take away the burden of challenging stereotypes and discriminatory beliefs and practices, the thinking goes, and girls will do just as well as boys in the STEM fields.

But now, a new study by a team of researchers led by the Stanford education professor Sean Reardon finds that girls’ dominance in school isn’t the case across demographics. Yes, the study confirms: Overall, in the average U.S. school district, girls and boys are performing about the same in math. But the study finds that in communities in which most families are affluent and white, and in which adult men far outearn women in income, girls continue to lag behind their male peers in math achievement. In some of these districts, boys on average outperformed girls in math by two-fifths of a grade level.

Described as the most comprehensive analysis of its kind to date, and drawing from roughly 260 million standardized-test scores from close to 10,000 U.S. school districts, the study looked at data from seven school years, starting in the fall of 2008. Overall the analysis found that, while girls maintain their edge in reading regardless of their geographic location, they either tend to significantly outperform or significantly lag behind boys in math.

“We set out saying that some districts are going to have more stereotypical gender achievement gaps—larger math gaps favoring boys, larger reading gaps favoring girls—and others that are maybe less stereotypical,” said Erin Fahle, who co-authored the study and earns her Ph.D. in education policy from Stanford this month. “Instead what we found was that districts tend to advantage boys or advantage girls.”

At the other end of the affluence spectrum, a near-opposite phenomenon is playing out: In poor communities of color, namely those where families are predominantly black or Latino, girls on average outperformed boys in math by one-fifth of a grade level, in addition to significantly outperforming them in reading. The new study lends credence to claims that boys in low-income black or Hispanic districts deserve some of the closest attention as policymakers, educators, and parents strive to eliminate gender disparities. “We focus so much on female children’s opportunities in STEM, which is really important and has a large potential economic consequence,” Fahle said. “But we also have to realize that boys’ opportunities are constrained by gender, too.”

The researchers couldn’t draw definitive conclusions from the data as to what explains these dueling phenomena, but they came up with various hypotheses that they hope future studies will examine. One theory: Wealthy areas where men are typically the main or sole breadwinners may implicitly or even explicitly promote the message that math is for boys. Another factor could be that gender stereotypes are inadvertently bolstered in wealthy families when parents respond to, say, a son’s early interest in robots, or a girl’s early interest in dress-up by paying to send the former to an after-school science club or the latter to a theater class. As an example, Fahle cited a study that analyzed the conversations of a sample of families as they observed a science exhibit at a museum. While parents were equally likely to talk to their sons and daughters about the exhibit, they were three times more likely to explain the science to the boys.

“It may be easier for parents to reinforce stereotypical patterns in affluent places because they have more money to do so,” explained Reardon, the study’s lead author, in a statement. “In less affluent places parents can’t spend the same kind of money and, therefore, may not reinforce those patterns as much.”

As for the findings in the poorer districts, Fahle pointed to research suggesting that the norms of masculinity prevalent in many low-income black and Hispanic communities downplay the importance of academic achievement. “Boys subsequently disengage with school somewhat,” Fahle said, “and that could be a pattern that fits with our data.”

Taken collectively, the findings offer critical insight for any endeavor seeking to chip away at the achievement gaps that continue to dog the country. They show the extent to which gender plays a role in determining a child’s long-term academic success—as well as the extent to which that role varies depending on where and among whom that child grows up.



Even as new enrollments of international students at colleges in the United States have declined over the past two years, the number of American students studying abroad continues to grow. Some 332,700 students studied overseas in the 2016–17 academic year, up 17 percent from five years ago and 27 percent from a decade ago.

But one group of students is underrepresented in the surge of undergraduates going overseas: men. In 2016–17, women accounted for more than two-thirds of American students studying abroad, a proportion that has remained constant for more than a decade.

Colleges have long blamed the gender disparity on the simple fact that women outnumber men on campuses and tend to major in disciplines that historically have accounted for a large share of overseas programs, such as the humanities, the social sciences, and foreign languages. Meanwhile, fields dominated by men, mostly STEM (science, technology, engineering, and mathematics) disciplines, have a reputation for being less hospitable to overseas study because of demanding degree requirements.

But STEM majors now represent the largest group of students abroad, making up a quarter of all undergrads overseas. Business, another major popular with men, comes in a close second, at 21 percent. Both academic fields have surpassed the social sciences, which led the pack until 2012.

And while women account for 56 percent of the 19.3 million undergraduates enrolled at U.S. institutions, up from 42 percent in the 1970s, administrators who run study-abroad programs say the gender gap in overseas study predates the shift in overall enrollment. Part of that is historical. In the early 1900s, women in college went abroad for art and culture before they got married; parents also perceived study abroad as a safe way for their daughters to travel.

Today, even in colleges that enroll a majority of men, those who study abroad are disproportionately women. Take Purdue University: Men account for 57 percent of the student body but only 41 percent of undergraduates who go abroad, according to a university spokesperson. Since 2013, the number of Purdue undergraduates studying overseas annually has doubled, to about 2,600, as part of a university-wide effort to increase global awareness among its students. The percentage of men going abroad, however, has remained the same.

What’s puzzling to campus administrators is that the numbers aren’t budging, even as they pitch study abroad as necessary for future employment to students who, more so than in past years, are worried about their job prospects. “Having a significant experience abroad is critical to understanding the world they’re going to work in after graduation,” says Michael Brzezinski, Purdue’s dean of international programs.

That focus on employability is one reason the composition of majors studying abroad has shifted toward STEM and business—just not the men in those majors. As a result, study-abroad leaders have started to focus on another explanation for why men don’t go abroad: complacency. Simply put, they don’t want to leave their friends and their comfort zone. A study of 2,800 students at two- and four-year colleges found that the more male students interacted with their peers—for example, the more they spent time with a friend or dorm hall mate—the less likely they were to go abroad. But peer interaction did not have such an impact on women, the researchers found.

Samantha Brandauer, who runs Dickinson College’s study-abroad office, told me she has experienced this firsthand. In her past job at Gettysburg College, she teamed up with a colleague to convene student focus groups on why men didn’t go abroad and what the college could do about it. What she discovered was a “bro mentality” among men in college—a culture in which male students don’t want to leave their friends to study abroad and are heavily influenced by their classmates in making choices about what to do in college. “Part of this is a messaging problem, because the way we talk about study abroad as a transformative experience just doesn’t resonate with college-age men,” Brandauer says. “They don’t want to be transformed.”

As at other schools, only about one-third of Dickinson students who study abroad are men, Brandauer told me. When male students do go overseas, she says, they are often encouraged by a trusted coach or mentor on campus, or they study abroad with a group of their friends. “The key is attracting those students who have some inclination and then lowering barriers and creating incentives,” she added.

To persuade men to study abroad, some campuses are making programs more explicitly about employability, appending internships to existing ones and adding options in locations such as China and the Middle East, where students might picture themselves working someday. Building study-abroad programs into the fabric of the undergraduate curriculum helps lower the perceived barriers, says Purdue’s Brzezinski, so that male students don’t view going away as an added burden on top of planning their coursework each semester.

Others schools are opting for a different route: Susquehanna University, a liberal-arts college in Pennsylvania, requires students to “study away” before they graduate. (About 90 percent of the university’s 2,100 undergraduates choose to travel abroad versus study domestically.) Scott Manning, the school’s dean of global programs, says that male students prefer going on short-term tours rather than spending an entire semester in a foreign locale. Nationally, short programs, often led by faculty members, are the way most Americans study abroad now, instead of the traditional semester-long programs.

Manning has led a study trip to New Zealand in two of the past three years during winter break, and both times, men accounted for two-thirds of the students in the group. Winter trips are more popular with men, he says, because they want to save their summer breaks for internships, and short trips tend to emphasize experiential, hands-on learning rather than sitting in a classroom.

Manning has noticed another thing about male students studying abroad: They tend to wait until the last possible moment to fulfill the graduation requirement. “Men are heavily represented on winter trips in their senior year,” he told me. Indeed, men seem to study abroad only if they find the time in college, while many women arrive on campus with a plan to do so. As a result of all this, colleges can make more programs that cater to these patterns, but for now, the outcome is that many men are missing out on what for many is one of college’s most gratifying and memorable experiences—and one that can help them land a job after graduation too.



When Isabella started playing lacrosse in the first grade, she would wake up before sunrise and count the minutes until she could hop the chain-link fence that separated her house from the field where her team practiced. Her deftness with a lacrosse stick made her an early standout, and she soon gave up basketball and soccer to focus on the sport. By the time Isabella was a high-school sophomore, she had already been recruited by an elite, Division I college and was signing autographs in her lacrosse-obsessed hometown. “Lacrosse was a way to get attention—it filled that need,” says Isabella, who is being identified by her middle name to protect her privacy.

But during the summer before her junior year, Isabella pivoted awkwardly during a game and fell to the ground in pain. She had torn her ACL. For eight months, she couldn’t return to the field. “It was my worst year ever,” Isabella told me. While her teammates competed in tournaments, she worried about falling behind in the sport. While her friends mingled after school, she was stuck at physical therapy. Without lacrosse, Isabella felt restless and out of sorts. She started eating more and soon developed an eating disorder. “I’d grown up playing lacrosse, and I had no other hobbies,” Isabella said. “So when you don’t have it, you’re like, What am I going to do?”

Mental-health challenges are not unique to competitive student athletes like Isabella, of course: Nearly half of American youths struggle with a mental illness before turning 18, while 12 percent have experienced a bout of depression. But even though playing sports on a regular basis can boost physical and mental health, for some serious high-school athletes—many who train year-round and might need an athletic scholarship to afford college tuition—sports can be a key contributor to depression and anxiety.

“The professional consensus is that the incidence of anxiety and depression among scholastic athletes has increased over the past 10 to 15 years,” says Marshall Mintz, a New Jersey–based sports psychologist who has worked with teenagers for 30 years. As one 2015 study by the National Athletic Trainers’ Association found, “Many student-athletes report higher levels of negative emotional states than non-student-athlete adolescents.” Though parents and coaches are often best positioned to remedy the problem, they also often make it worse.

One reason for this trend is that high-school sports have begun to copy the training methods and intensity levels of college sports. This “sports professionalization” says Timothy Neal, a professor of health and human performance at Concordia University Ann Arbor, is a trickle-down effect of big-time sports, from professional to college and now to high school. More students are specializing in only one sport and playing it beyond one season, sometimes competing on multiple teams throughout the year. The American Academy of Orthopaedic Surgeons found in 2017 that high-school, college, and professional athletes trained in a single sport for a comparable number of months each year. As “intensive parenting” has become the norm, parents in recent decades have pressed upon their kids the idea that endless practice is the route to athletic mastery. Private clubs and teams, which need income year-round to stay in business, have also urged this devotion to one sport.

This professionalization has led to overtraining and exhaustion, which is central to the mental-health problems of competitive high-school athletes. “The biggest problem is sleep loss—all these kids are sleep-deprived,” Mintz says, “and this becomes a major contributor to anxiety and depression.” Long practices and multiple daily workouts mean that athletes have less time than before for other activities, which can amplify the pressures of high school. “Do they need two and a half to three hours of practice?” asks Lonnie Sarnell, a sports psychologist in Millburn, New Jersey, who works with high-school athletes. “That extra hour of practice adds so much stress when you have four hours of homework to deal with.”

All that extra time practicing makes players more vulnerable to injuries, which can be another emotional challenge, especially for those whose identity is closely tied to the sport they play. Some athletes who drop other interests and activities to focus on a sport, and whose self-worth is linked to their performance, can feel lost when they’re sidelined; it’s the rudderless feeling Isabella experienced after tearing her ACL. On top of these strains, teenage athletes have to contend with ordinary frictions that come with being on a team—worries over playing time, making mistakes, and working with difficult coaches. These challenges are only more fraught for players with grand athletic goals.

Parents bear some responsibility for the tension kids feel. Children suffer when mothers and fathers insinuate that every competition or game is vitally important and that the only path to athletic excellence is through relentless training, says Lisa Damour, a psychologist and the author of Under Pressure: Confronting the Epidemic of Stress and Anxiety in Girls. “The situations where sports cause more stress than relief is when there’s a bad fit between the coach and the player or between parents and coaches,” she told me. High-school athletes can also sometimes feel the burden of their parents’ athletic history—what Damour called the “ghosts on the sidelines.” Some parents get their ego needs met through their kids. Fixated on their child’s athletic achievements, they can overlook the young person in front of them. For some parents, Mintz says, “it’s about getting A’s and making the all-star team.”

Parental pressure doesn’t have to be overt or heavy-handed for it to have an effect on a high-school athlete’s mental health. Aware of how much their parents have sacrificed in time and money, some teenagers will persist in playing a sport long past the time they enjoy it, even continuing to practice and compete while injured, says Jay Coakley, a sports sociologist at the University of Colorado at Colorado Springs. If players do finally quit, they sometimes feel like failures for letting their parents and teammates down, which can contribute to self-destructive behavior.

Apart from parents, though, belittling by coaches can be another strain. Riley, who is being identified by her middle name so that she can speak openly about her mental health, told me how her high-school coach erupted at runners when they underperformed, and sometimes ignored them for days as punishment. He encouraged teammates to compete against one another, shunned less talented athletes, and drummed in the need for “mental toughness,” she told me. “We accepted the intense anxiety before races and practice as a necessary side effect.” By her junior year, Riley was deeply depressed and struggling with suicidal thoughts. She ended up transferring to another high school.

But getting parents and coaches to chill out about high-school sports will only go so far in improving athletes’ mental health. Teenagers sense that the country has split into winners and losers, and believe that getting into the right college is a ticket to future security, says Victor Schwartz, the chief medical officer at the Jed Foundation, a nonprofit that works to protect the mental health of young people. Just as getting a B on a test can trigger panic, flailing on the basketball court or striking out during an important game can seem more consequential than it is. “Kids have come to feel that the stakes are higher and higher, and that there’s less room for mistakes,” Schwartz told me.

Colleges might give some insight into how to fix this problem. After the National Collegiate Athletic Association’s chief medical officer discovered in 2014 that mental-health worries topped the list of student-athlete concerns, college-sports programs started to address the problem by adding therapists to athletic offices, screening players for anxiety and depression, and educating staff about how to identify mental-health issues.

These steps could ratchet up the pressure on high schools to follow suit, says Shane Murphy, a sports psychologist based in Danbury, Connecticut. “What happens at the college level will trickle down to high school,” he told me. “Over the next decade, we’ll see much more priority given to the mental health of high-school student athletes.” For coaches, this might mean training in “mental-health first aid” so that they are better able to read and respond to signs of emotional distress among their players. Jolee Paden, a high-school cross-country coach in Washington, D.C., took an eight-hour class on addressing players’ mental health and told me that it helped her unpack the stereotypes surrounding mental illness and develop a vocabulary for addressing the problems she sees. Paden now feels confident that she’ll know what to do if one of her players starts to struggle. “I walked away with some actual tools for responding rather than far-off theories,” she said.

Now a junior in college, Isabella plays intermittently for her university’s lacrosse team. She’s no longer a star, but neither is she unmoored. The emotional turbulence she experienced during high school jolted her into thinking about what she wants out of life beyond success on the lacrosse field. “I still don’t know what I want to do career-wise,” she said. “Now I’m putting more emphasis on that. I’m trying to figure out what I like, and what kind of person I want to be.”



Updated at 5:30 p.m. ET on May 17, 2019. 

It is a sacred academic tradition: Every year, before spring turns to summer, the relatives and loved ones of soon-to-be college graduates journey great distances and congregate in stadiums or on greens in order to … hear someone they don’t know recite the names of hundreds or even thousands of total strangers.

These gatherings are known as graduation ceremonies, and they have gotten really, really long. Commencement speakers tend to get the most attention during graduation season, but the widespread practice of reading every graduate’s name eats up a lot more time on ceremonies’ agendas. Given that it can take hours to get through every name, is this really a good use of everyone’s time?

The Atlantic reached out to the top 50 universities in the U.S. News & World Report rankings, and all 45 that responded said they read graduates’ names. Most do so at school-specific ceremonies—for example, engineering graduates will have their names read at the engineering-school ceremony—and not during a university-wide commencement.

The reasons for calling out every graduate’s name are simple: It’s a way for a college to honor a student personally. Even at an event that often feels rote and stale, there is room for genuine emotion, such as when a mother and son received their degrees at the very same ceremony earlier this month. And for first-generation college students as well as their families, the reading of a name at graduation can be the jubilant end to a long and uncertain journey.

The problem, though, is that everyone in the audience cares about one graduate’s brief moment of glory—and no one else’s. When the name of a loved one isn’t being called, the audience might as well be listening to someone read from a phone book.

George Loewenstein, a behavioral economist at Carnegie Mellon University, suggested to me that graduation ceremonies are designed for long-term meaning-making, at the cost of short-term discomfort. He invoked a theory outlined by the Nobel-winning behavioral economist Daniel Kahneman that describes how people retroactively assess “extended episodes.” The basic idea is that people’s memories of an experience are shaped most by its peak—the most emotionally intense part—and its ending. The peak of these ceremonies (which certainly qualify as “extended”) is usually the moment the graduate walks across the stage, and the ending is often a celebratory tossing of hats. According to this model, when audience members and participants reflect back on graduation ceremonies, memory should downplay the dullness and focus on the triumph, however brief.

Perhaps that dullness is even useful. “It’s true that these are excruciatingly boring,” Loewenstein says of graduation ceremonies. “But maybe the boredom serves a kind of function—that is, your child walking across the stage becomes a more peak moment against the backdrop of the boredom. That’s about as generous as I can be.”

Still, “it’s worth the wait,” says Loewenstein. “How often do you get such an extreme emotional experience of seeing your offspring bookending an important period of their life?”

There might be a long-term logic to graduation ceremonies, but that still leaves the discomfort of the present. The name of every student at Rice University, in Houston, used to be read at the school-wide commencement, but after the student population grew in the mid-2000s, this became unsustainable.

“It’s Houston, it’s May, we do our ceremony outside,” says Marcia O’Malley, a professor at Rice and its commencement’s chief marshal. “And as the number of students got larger and larger, our ceremony, which was starting at about 8 or 8:30 in the morning, was going until after 11 a.m. We were having some issues of students in these black robes sitting out in the sun. We were having EMS cases of people fainting. It’s a long time.”

The organizers of Rice’s commencement started analyzing video of past ceremonies to see what might be streamlined without compromising the “real sense of community” that O’Malley says characterizes Rice and arises in part from reading every graduate’s name. “There's only so much shortening you can do—you have to say the person's name and they've got to walk,” she observes. So, as of 2014, like at many other colleges, the names of Rice graduates are read at smaller ceremonies, but not at the university-wide commencement.*

Tyler Mullins is an expert on shortening graduation ceremonies. Mullins is the president of MarchingOrder, a 16-year-old company that provides nearly 300 schools with technology that, among other things, puts graduates’ names on a screen as they collect their diploma. This year, he estimates, about 800,000 students will walk across a stage at a school that uses a MarchingOrder service of some kind.

MarchingOrder talks with colleges about their graduation-ceremony needs. “In all cases,” Mullins says, “people do want to find out, ‘What can we do to make this—especially the name-announcement component, but really the entire ceremony—happen in a way that feels quick, doesn’t drag out, and doesn’t cause the audience to start getting restless?’”

Mullins told me that “there are only a few options” for speeding ceremonies up. One is to get rid of the processional (when graduates and faculty march in together) or to have it take place before the official start time of the ceremony. Another is to get rid of some speeches—say, from a chancellor or a dean. “Sometimes you have to make tough cuts,” Mullins says. “I think the magic number is two hours—anything two hours or under, people feel pretty good about. When you get to three hours, that's tough.”

The other important variable—the one Mullins can help tweak—is how quickly names are read. “Three seconds [per name] is a fast ceremony,” he says. “A lot of big schools, that's their target—they’ll say, ‘We want to get a grad every three seconds.’ Five seconds is a more comfortable pace.”

In Mullins’s experience, the setup most conducive to speed is using prerecorded names (so that there’s no fumbling of graduates’ name cards) and having students line up on only one side of the stage. Sometimes, schools with a large student body prefer two lines, which can make it easier to organize students offstage. Onstage, two lines can also make live reading go faster, but, Mullins says, it takes “a little more choreography” to ensure “nobody’s colliding or anything.” “With just one side,” he says, “you can set it up to really fire through.”

Some schools have happily reported to Mullins that they come in under time, clocking in at 2.7 seconds or 2.8 seconds per graduate. The fastest I came across in my research, though, is MIT, which told me it gets through roughly 2,400 students’ names in about an hour. That works out to a swift 1.5 seconds per name, probably the most efficient name-reading can get without being disrespectful. (MIT uses two lines and doesn’t prerecord names.) “Surveys of students and alumni consistently show that they greatly value our tradition of reading each name and of receiving their actual diploma from the president or provost onstage,” says Eric Grimson, an MIT professor and the chair of the school’s commencement committee.

Schools themselves probably like it too: “The university of course is concerned about future donations, and future donations are going to be based on memories,” Loewenstein, the behavioral economist, notes. Besides, it would probably be hard to let go of a tradition that seems to date back to the earliest days of American colleges. When I asked Roger Geiger, a historian of higher education at Penn State, how long schools had been reading graduates’ names, he told me, “I assume it’s forever.” (Other scholars I spoke with suggested that name-reading, like other academic rituals, could have been derived from European traditions.)

In earlier eras, the practice wasn’t so burdensome: American universities used to be tiny. In the 18th and 19th centuries, Geiger says, the total number of students at a college was “rarely more than 100.” Even a larger school at that time would have had a graduating class of 50 or so students.

A spokesperson for Northwestern University said the school believes that names were read at its first commencement ceremony in 1851. There were only “five young gentlemen” graduating that year, according to a historical account, so the name-reader really could have taken his time.

American high schools, also small for much of their history, have probably been reading names at graduation since they were founded, too. "The reason why it was perfectly reasonable to imagine you could read everyone’s name is that so few students actually graduated,” says William Reese, a professor of educational-policy studies and history at the University of Wisconsin–Madison. According to Reese, only 6 percent of American adolescents in 1890 are estimated to have attended high school, and only a quarter of attendees actually graduated. Given how rare it was get a high-school diploma, the least schools could do was read people’s names.

Reading out names is not overly time-consuming at most high schools these days, but colleges’ student bodies have grown at a much faster clip. “Things go up substantially with the GI Bill—enrollments would often double and triple with the influx of veterans,” says John Thelin, an education scholar at the University of Kentucky. This midcentury jump, Thelin says, made it hard for colleges to treat graduating classes in the “unified, intimate” way that they used to. And colleges kept growing: In 1940, about 200,000 bachelor’s degrees were conferred nationwide; by 1970, that figure was approaching 1 million. Which is to say, colleges have grown so much that it makes sense some of them might hire someone like Tyler Mullins to keep an eye on the clock at graduation.

Commencement has changed in other ways too. Geiger and Thelin both note that in the early centuries of American higher education, one common component of graduation festivities was hours-long oratorical showcases, in which students recited speeches they’d written, sometimes in Greek or Latin. (Classes were often suspended in seniors’ final term so that they could prepare for these and other graduation proceedings.)

This means that at graduation ceremonies of the past, people had to listen, for hours on end, to strangers delivering speeches in languages few audience members understood. Maybe today’s attendees don’t have it so bad.

Amal Ahmed contributed reporting to this article.

* This article originally stated that Rice University reads students' names at school-specific ceremonies.



Before the automobile, before the Statue of Liberty, before the vast majority of contemporary colleges existed, the rising cost of higher education was shocking the American conscience: “Gentlemen have to pay for their sons in one year more than they spent themselves in the whole four years of their course,” The New York Times lamented in 1875.

Decadence was to blame, the writer argued: fancy student apartments, expensive meals, and “the mania for athletic sports.”

Today, the U.S. spends more on college than almost any other country, according to the 2018 Education at a Glance report, released this week by the Organization for Economic Cooperation and Development (OECD).

All told, including the contributions of individual families and the government (in the form of student loans, grants, and other assistance), Americans spend about $30,000 per student a year—nearly twice as much as the average developed country. “The U.S. is in a class of its own,” says Andreas Schleicher, the director for education and skills at the OECD, and he does not mean this as a compliment. “Spending per student is exorbitant, and it has virtually no relationship to the value that students could possibly get in exchange.”

Only one country spends more per student, and that country is Luxembourg—where tuition is nevertheless free for students, thanks to government outlays. In fact, a third of developed countries offer college free of charge to their citizens. (And another third keep tuition very cheap—less than $2,400 a year.) The farther away you get from the United States, the more baffling it looks.

This back-to-school season, The Atlantic is investigating a classic American mystery: Why does college cost so much? And is it worth it?

At first, like the 19th-century writer of yore, I wanted to blame the curdled indulgences of campus life: fancy dormitories, climbing walls, lazy rivers, dining halls with open-fire-pit grills. And most of all—college sports. Certainly sports deserved blame.

On first glance, the new international data provide some support for this narrative. The U.S. ranks No. 1 in the world for spending on student-welfare services such as housing, meals, health care, and transportation, a category of spending that the OECD lumps together under “ancillary services.” All in all, American taxpayers and families spend about $3,370 on these services per student—more than three times the average for the developed world.

One reason for this difference is that American college students are far more likely to live away from home. And living away from home is expensive, with or without a lazy river. Experts say that campuses in Canada and Europe tend to have fewer dormitories and dining halls than campuses in the U.S. “The bundle of services that an American university provides and what a French university provides are very different,” says David Feldman, an economist focused on education at William & Mary in Williamsburg, Virginia. “Reasonable people can argue about whether American universities should have these kind of services, but the fact that we do does not mark American universities as inherently inefficient. It marks them as different.”

But on closer inspection, the data suggest a bigger problem than fancy room and board. Even if we were to zero out all these ancillary services tomorrow, the U.S. would still spend more per college student than any other country (except, again, Luxembourg). It turns out that the vast majority of American college spending goes to routine educational operations—like paying staff and faculty—not to dining halls. These costs add up to about $23,000 per student a year—more than twice what Finland, Sweden, or Germany spends on core services. “Lazy rivers are decadent and unnecessary, but they are not in and of themselves the main culprit,” says Kevin Carey, the author of The End of College and the director of the education-policy program at New America, a nonpartisan think tank.

The business of providing an education is so expensive because college is different from other things that people buy, argue Feldman and his colleague Robert Archibald in their 2011 book, Why Does College Cost So Much? College is a service, for one thing, not a product, which means it doesn’t get cheaper along with changes in manufacturing technology (economists call this affliction “cost disease”). And college is a service delivered mostly by workers with college degrees—whose salaries have risen more dramatically than those of low-skilled service workers over the past several decades.

College is not the only service to have gotten wildly more expensive in recent decades, Feldman and Archibald point out. Since 1950, the real prices of the services of doctors, dentists, and lawyers have risen at similar rates as the price of higher education, according to Feldman and Archibald’s book. “The villain, as much as there is one, is economic growth itself,” they write.

This all makes sense, if we just focus on the U.S. But what about the rest of the world? These broader economic trends exist there, too. So why does college still cost half as much, on average, in other countries?

One oddity of America’s higher-education system is that it is actually three different systems masquerading as one: There is one system of public colleges; another of private, nonprofit institutions; and one made up of for-profit colleges.

The biggest system by far is the public one, which includes two-year community colleges and four-year institutions. Three out of every four American college students attend a school in this public system, which is funded through state and local subsidies, along with students’ tuition dollars and some federal aid.

In this public system, the high cost of college has as much to do with politics as economics. Many state legislatures have been spending less and less per student on higher education for the past three decades. Bewitched by the ideology of small government (and forced by law to balance their budgets during a period of mounting health-care costs), states have been leaving once-world-class public universities begging for money. The cuts were particularly stark after the 2008 recession, and they set off a cascading series of consequences, some of which were never intended.

The easiest way for universities to make up for the cuts was to shift some of the cost to students—and to find richer students. “Once that sustainable public funding was taken out from under these schools, they started acting more like businesses,” says Maggie Thompson, the executive director of Generation Progress, a nonprofit education-advocacy group. State cutbacks did not necessarily make colleges more efficient, which was the hope; they made colleges more entrepreneurial.

Some universities began to enroll more full-paying foreign and out-of-state students to make up the difference. Over the past decade, for example, Purdue University has reduced its in-state student population by 4,300 while adding 5,300 out-of-state and foreign students, who pay triple the tuition. “They moved away from working to educate people in their region to competing for the most elite and wealthy students—in a way that was unprecedented,” Thompson says.

This competition eventually crept beyond climbing walls and dining halls into major, long-term operating expenses. For example, U.S. colleges spend, relative to other countries, a startling amount of money on their nonteaching staff, according to the OECD data. Some of these people are librarians or career or mental-health counselors who directly benefit students, but many others do tangential jobs that may have more to do with attracting students than with learning. Many U.S. colleges employ armies of fund-raisers, athletic staff, lawyers, admissions and financial-aid officers, diversity-and-inclusion managers, building-operations and maintenance staff, security personnel, transportation workers, and food-service workers.

The international data is not detailed enough to reveal exactly which jobs are diverting the most money, but we can say that U.S. colleges spend more on nonteaching staff than on teachers, which is upside down compared with every other country that provided data to the OECD (with the exception of Luxembourg, naturally).

In addition, most global rankings of universities heavily weight the amount of research published by faculty—a metric that has no relationship to whether students are learning. But in a heated race for students, these rankings get the attention of college administrators, who push faculty to focus on research and pay star professors accordingly.

Likewise, the new data show that U.S. colleges currently have a slightly lower ratio of students to teachers than the average for the developed world—another metric favored in college rankings. But that is a very expensive way to compete. And among education researchers, there is no clear consensus about whether smaller classes are worth the money.

In the beginning, university administrators may have started competing for full-freight paying students in order to help subsidize other, less affluent students. But once other colleges got into the racket, it became a spending arms race. More and more universities had to participate, including private colleges unaffected by state cuts, just to keep their application numbers up. “There is such a thing as wasteful competition,” Charles Clotfelter, a Duke University professor and the author of Unequal Colleges in the Age of Disparity, wrote me in an email.

All that said, it’s also true that state budget cuts were uneven across the country. Today, in-state tuition in Wyoming is about a third of the cost of Vermont, for example. In places where higher education has not been gutted and the cost of living is low, an American college degree can still be a bargain—especially for students who don’t mind living at home and are poor enough to qualify for federal aid. Taking into account living expenses, says Alex Usher of the consulting firm Higher Education Strategy Associates, a student at a public university in Mississippi will likely end up with similar out-of-pocket costs as a student in Sweden.

Usher, who is based in Toronto, is one of the few researchers to have looked carefully at the costs of higher education globally. And much of what he finds is surprising. In 2010, he and his colleague Jon Medow created a clever ranking of 15 countries’ higher-education systems—using a variety of ways to assess affordability and access. Reading the report is like peeling an onion. The first layer focuses on the most obvious question: the affordability of college based on the cost of tuition, books, and living expenses divided by the median income in a given country. By this metric, the U.S. does very poorly, ranking third from the bottom. Only Mexico and Japan do worse.

But the U.S. moves up one place when grants and tax credits are included. “Your grants are actually really generous compared to everybody else,” Usher says. Tuition is higher in the U.S., so the grants don’t fully cover the price, but 70 percent of full-time students do receive some kind of grant aid, according to the College Board. From this perspective, sometimes called “net cost,” Australia is more expensive than the U.S.

Next, looking only at our public colleges, the U.S. rises higher still, ranking in the middle of the pack in Usher’s analysis, above Canada and New Zealand. This data is from 2010, and things may look less rosy if he were to redo the study now, Usher cautions. But still, he sounds weirdly hopeful. “The public system in the U.S. is working as well as most systems,” he says. “Parts of the U.S. look like France.”

The problem, of course, is that other parts of the U.S. look more like a Louis Vuitton store. America basically contains 50 different higher-education systems, one per state, each with public, private, and for-profit institutions, making generalizations all but impossible. The U.S. does relatively well on measures of access to college, but the price varies wildly depending on the place and the person. Somehow, students have to find their way through this thicket of competition and choose wisely, or suffer the consequences.

The more I studied America’s baffling higher-education system, the more it reminded me of health care. In both spaces, Americans pay twice as much as people in other developed countries—and get very uneven results. The U.S. spends nearly $10,000 a person on health care each year (25 percent more than Switzerland, the next biggest spender), according to the OECD’s 2017 Health at a Glance report, but our life expectancy is now almost two years below the average for the developed world.

“I used to joke that I could just take all my papers and statistical programs and globally replace hospitals with schools, doctors with teachers and patients with students,” says Dartmouth College’s Douglas Staiger, one of the few U.S. economists who studies both education and health care.

Both systems are more market driven than in just about any other country, which makes them more innovative—but also less coherent and more exploitive. Hospitals and colleges charge different prices to different people, rendering both systems bewilderingly complex, Staiger notes. It is very hard for regular people to make informed decisions about either, and yet few decisions could be more important.

In both cases, the most vulnerable people tend to make less-than-ideal decisions. For example, among high-achieving, low-income students (who have grades and test scores that put them in the top 4 percent of U.S. students and would be eligible for generous financial aid at elite colleges), the vast majority apply to no selective colleges at all, according to research by Caroline Hoxby and Christopher Avery. “Ironically, these students are often paying more to go to a nonselective four-year college or even a community college than they would pay to go to the most selective, most resource-rich institutions in the United States,” as Hoxby told NPR.

Meanwhile, when it comes to health care, low-income Americans tend to be less familiar with the concepts of deductibles, coinsurance rates, and provider networks, according to a variety of studies, which makes it extremely difficult to choose a health-care plan. “These are both sectors where consumers are too poorly informed and societal costs and benefits too great to leave decision-making entirely in the hands of individuals,” as Isabel Sawhill at the Brookings Institution has written.

Ultimately, college is expensive in the U.S. for the same reason MRIs are expensive: There is no central mechanism to control price increases. “Universities extract money from students because they can,” says Schleicher at the OECD. “It’s the inevitable outcome of an unregulated fee structure.” In places like the United Kingdom, the government limits how much universities can extract by capping tuition. The same is true when it comes to health care in most developed countries, where a centralized government authority contains the prices.

The U.S. federal government has historically been unwilling to perform this role. So Americans pay more for pharmaceuticals—and for college classes. Meanwhile, more and more of the risk gets shifted from government onto families, in both sectors.

At the very least, the American government could do a better job sharing information about the quality of colleges in ways everyone can understand, Schleicher says. “You can’t force people to buy good things or bad things, but they should be able to see what the value is.”

Spending a lot of money can be worth it, if you get something awesome in exchange. “America has the best colleges and universities in the world!” President Donald Trump exclaimed at the World Economic Forum in Davos, Switzerland, earlier this year. Former President Barack Obama said the same thing before him.

But is it actually true? No meaningful data exist on the quality of universities globally. America does have a disproportionate number of elite colleges, which accept fewer than 10 percent of applicants, and these places do employ some brilliant scholars who do groundbreaking research. But fewer than 1 percent of American students attend highly selective colleges like those.

Instead, more than three-quarters of students attend nonselective colleges, which admit at least half of their applicants. No one knows for sure how good these colleges are at their core job of educating students. But in one of the only careful, recent studies on adult skills, the OECD’s Program for the International Assessment of Adult Competencies, Americans under age 35 with a bachelor’s degree performed below their similarly educated peers in 14 other countries on the test of practical math skills. In other words, they did only slightly better than high-school graduates in Finland. America’s college grads did better in reading, performing below just six other countries, but dropped off again in another test, scoring below 13 other countries in their ability to solve problems using digital technology.

If American colleges are not adding obvious and consistent academic value, they are adding financial value. Americans with college degrees earn 75 percent more than those who only completed high school. Over a lifetime, people with bachelor’s degrees earn more than half a million dollars more than people with no college degree in the U.S. In fact, no other country rewards a college degree as richly as the United States, and few other countries punish people so relentlessly for not having one. It’s a diabolical cycle: Colleges are very expensive to run, partly because of the high salaries earned by their skilled workers. But those higher salaries make college degrees extremely valuable, which means Americans will pay a lot to get them. And so colleges can charge more. As Carey, the End of College author, summarizes: “Students are over a barrel.”  

Still, the return varies wildly depending on the college one attends. One in four college grads earns no more than the average high-school graduate. Associate’s degrees from for-profit universities lead to smaller salary bumps than associate’s degrees from community colleges, which are cheaper. And two-thirds of students at for-profits drop out before earning their degree anyway, meaning many will spend years struggling with debt they cannot afford to pay off—and cannot, under U.S. law, off-load through bankruptcy.

This convoluted, complicated, inconsistent system continues to exist, and continues to be so expensive because college in America is still worth the price. At certain colleges, for certain people. Especially if they finish. But it doesn’t have to be this way, and almost everywhere else, it isn’t.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

At least 2,000 children have now been forcibly separated from their parents by the United States government. Their stories are wrenching. Antar Davidson, a former youth-care worker at an Arizona shelter, described to the Los Angeles Times children “huddled together, tears streaming down their faces,” because they believed that their parents were dead. Natalia Cornelio, an attorney with the Texas Human Rights Project, told CNN about a Honduran mother whose child had been ripped away from her while she was breastfeeding. “Inside an old warehouse in South Texas, hundreds of children wait in a series of cages created by metal fencing,” the Associated Press reported. “One cage had 20 children inside.”

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

About 65 million years ago, shortly after the time of the dinosaurs, a new critter popped up on the evolutionary scene. This “scampering animal,” as researchers described it, was likely small, ate bugs, and had a furry tail. It looked, according to artistic renderings, like an especially aggressive New York City rat. And it had a placenta, an organ that grows deep into the maternal body in order to nourish the fetus during pregnancy.

The rodentlike thing would become the common ancestor of the world’s placental mammals, with descendants that include whales, bats, dogs, and humans, among many other species. And today, the placenta might hold the key to one of the most enduring mysteries in human medicine: Why do women suffer much higher rates of autoimmune disease than men do?

Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.

There’s a moment about 15 minutes into the first episode of Years and Years that made me gasp at its audacity, its prescience, its visual horror. The new six-part series from the British writer Russell T. Davies (Doctor Who, A Very English Scandal) charts the life of the Lyons family over the course of 15 years, starting in 2019 and ending in 2034. It’s a kitchen-sink saga that barrels its way through births and marriages and betrayals, but also through the near-future. In 2024, Stephen Lyons (played by Rory Kinnear), a financial adviser, is at home with his wife, Celeste (T’nia Miller), both rushing their way through the morning routine. When the camera turns to their teenage daughter Bethany (Lydia West), her face isn’t recognizably human. Instead, she looks like a 3-D version of a Snapchat puppy, with vast cartoon eyes, wagging pink ears, and a brown snout. When she talks, her voice is grotesquely distorted, a robotic hallucination of a child’s cadence. “I might have to start limiting filter time,” Celeste says in the same exasperated, noncommittal way that you might think, I really should spend less time on Twitter.



On Saturday, April 27, at Swarthmore College in Pennsylvania, a group of students calling themselves the Coalition to End Fraternity Violence seized the fraternity house of the campus’s Phi Kappa Psi chapter, one of two fraternities on campus.

Earlier in April, according to The Philadelphia Inquirer, internal documents from the frat that were leaked to campus news outlets included Phi Kappa Psi members’ “derogatory comments about women, minorities, and LGBTQ people” and “crude jokes about parties, illegal drugs, and sexual assault.” In response, the newly formed coalition organized a sit-in at Phi Kappa Psi to demand that the college ban fraternities from campus. (Swarthmore’s Phi Kappa Psi chapter is not affiliated with the national Phi Kappa Psi organization.)

According to the Inquirer, as recently as Monday protesters were “sitting and sleeping … inside the [Phi Kappa Psi] house—in the very room where parties were typically held.” Protesters also hung up signs outside the house reading This house is ours and Close the rape attic, a reference to a passage in the leaked documents that described a secluded upper room in a different fraternity house at Swarthmore as such. (On Wednesday, the two fraternities on Swarthmore’s campus both announced that they would voluntarily disband.)

Some might argue that individual students’ misconduct is more to blame for sexual assault than any frat house or party hot spot. But according to a new study published in the Journal of Studies on Alcohol and Drugs, party locations do play a role in increasing the frequency of sexually aggressive behavior. The study followed the partying and hookup behaviors of more than 1,000 straight men over four semesters, from the beginning of their freshman year. It found that men’s attendance at “drinking venues”—that is, bars and parties—was a better predictor of their sexual aggression than simply binge-drinking or enthusiastic attitudes toward casual sex.

According to Michael Cleveland, a professor of human development at Washington State University and the study’s lead author, research on campus sexual assault has long found that heavy alcohol consumption is linked to sexual aggression. But researchers weren’t exactly sure of the mechanism behind that link. “A lot of research has shown that once you account for personality differences or individual differences, then the link between alcohol use and sexual aggression or assault kind of disappears,” Cleveland says. Only in recent years have longitudinal studies been able to examine what aspects of binge-drinking culture are most likely to cause sexually aggressive behaviors. In a separate study last year,  he and his colleague Maria Testa began to notice that attending a drinking hot spot, not heavy drinking itself, was more strongly correlated with sexual aggression, which led them to design their newest study to focus on that in particular.

That being said, personality differences do seem to play a role in who ends up at certain drinking spots. The more recent study also found that the men who were more likely to hang out at bars and parties were also more likely to engage in heavy drinking and casual sex than their peers who reported hanging out at bars and parties less often.

To some, these findings may seem a little obvious. “I think if you survey college women, [they] know that when you go to a frat house, you hopefully [think to yourself], Okay, I need to be on edge. This is a danger zone,” says Rory Newlands, a graduate student at the University of Nevada at Reno and the lead author of a critical review of  some sexual-violence-prevention programs on college campuses. “If you’re at home drinking alone, you’re probably not going to perpetrate against someone,” she says. “But [it’s different if] you’re going to this environment where you’re already primed to be thinking, like, This is a hookup hot spot, and I’m drinking, so I’m going to have sex.”

This is an example of what Newlands calls “alcohol expectancies,” or the mind-sets that result from imbibing. Research has shown that in laboratory settings, “even sober people who’ve been duped into thinking that they’ve been drinking will still be slower to pick up on [others’] rejection cues and will engage more creepily,” she says.  

Still, she notes that while it was known among researchers that binge-drinking had something to do with sexual assault, it couldn’t be said to directly lead to it. So having hard data to illustrate the link may be instructive in how campuses prevent sexual assault. The news Journal of Studies on Alcohol and Drugs study suggests as much: “Although most college sexual assault prevention efforts have focused on reducing the vulnerability of women, our results suggest efforts that focus on potential perpetrators’ behaviors may also be fruitful.”

Jacquelyn Wiersma-Mosley, a professor at the University of Arkansas who studies sexual-violence victimization and perpetuation, told me that while some colleges and universities have begun implementing “bystander intervention” programs—that is, programs that train men, and in some cases women, on what sexual assault looks like and how to intervene to prevent or report it—most are indeed geared toward educating women on how to protect themselves. But Wiersma-Mosley believes that institutions could focus more on educating men specifically: “The ones that we need to focus on in prevention [are] actual perpetrators (mainly men),” she said in an email. In her own research, she has found that the “biggest predators” on college campuses—and as she pointed out, the ones who are known for heavy drinking and frequent attendance at parties and bars—are men involved in Greek life.

Cleveland, Wiersma-Mosley, and Newlands all agree that the findings of this new study point to the need for better supervision—and enforcement—on the parts of bar owners and university administrators. Bystander-intervention training is useful, but it has limitations, Cleveland says—people are less likely to intervene effectively when they’ve been drinking themselves. And thus, “providing safe interventions may require some individuals to not be drinking, or bars could have staff and members of the establishment be trained to intervene in situations like this,” he says. “Fraternity parties and other parties like that may have to increase the chances that someone is there who’s … not drinking, to maintain that level of vigilance.”

For the universities that are grappling with what they can do to prevent sexual assault on campus, general safety training may help, but this new research suggests that they could focus on certain venues to have an even bigger impact.



The college-affordability crisis can at times feel like a problem with a million responses but no clear solution. Students often graduate with thousands of dollars in debt, or, even worse, they drop out of college and are still left with debt to pay off.

As the student-debt bubble continues to grow—it is now estimated at more than $1.5 trillion—policy makers are poking around for that solution. One that has been proffered is “free college,” whether that’s tuition- or debt-free. But an alternate solution has taken hold in North Carolina, and perhaps it’s the simplest of all: Just lower tuition. And it’s getting students who have dropped out back into the classroom.

This fall, the state launched a program called NC Promise that sets tuition at a flat rate—$500 a semester for in-state students, and $2,500 a semester for out-of-state students—at three public universities in geographically disparate parts of North Carolina. To fund the program, the state legislature has set aside $51 million. And its goal is self-evident: Make college affordable enough to boost the number of students who enroll, while ensuring that they aren’t saddled with debt that could affect whether or not they graduate. And, for all intents and purposes, it’s working. The three institutions—UNC Pembroke, Western Carolina University, and Elizabeth City State University—have seen immediate enrollment jumps of 14, 6, and 19 percent, respectively.

But perhaps more interesting than the enrollment jumps themselves is how the promise program has affected so-called “readmits”—students who drop out of college and then reenroll. Pembroke, in particular, has seen a 60 percent increase in its readmit population so far this fall. “We certainly anticipated an increase,” David Ward, the provost and vice chancellor for academic affairs at Pembroke, told me, “but I’m not going to say that we foresaw the size of increase that we did.” Overall, the institution had an 838-student increase—including readmits, transfers, and new enrollees—from the last school year.

To put the NC Promise program into perspective, the estimated cost of attendance for a commuter student at UNC Pembroke last year was $8,495. But this year, the cost dropped to $5,893, an amount that, for low-income students, can be covered in full by Pell Grants. Of course, students still have to pay for basics like housing and food on their own. But, Ward told me, the reenrollment rates are encouraging, and they signal that lowering tuition is having its intended effect. “The reality is that many of our students are one car breaking down, one [broken] transmission away from not being able to complete a semester,” he said. “Lowering the cost directly to the student is a great incentive.”

In fact, so many students are enrolling at Pembroke that administrators are concerned about capacity. So the college has started a program called “BraveSteps” that creates a pathway to the institution, allowing students to attend a local community college for a year before transferring to the university.

But the problem of capacity gets at a larger point: The three institutions, though they have missions to serve historically underserved populations—ECSU is a historically black college and Pembroke is a minority-serving institution—only enroll a tiny fraction of the total number of college students in North Carolina. That means that if and how the NC Promise program is scaled is important, and right now, there’s no clear answer.

“This isn’t a solution at the scale that the state would see big increases in the proportion of people attending higher education,” William Doyle, a professor of higher education at Vanderbilt University, told me. It’s a valiant start, he says, but equally important is making sure that college is affordable for students where they live. That’s because nearly 60 percent of incoming freshmen at four-year public colleges attend schools within 50 miles of their permanent residence. For this solution to have a broad effect on college-going culture, it will need to be available at more schools.

Luckily for North Carolina, it may not be so heavy a lift. “North Carolina as a state has some of the lowest net prices for students attending [research] institutions of any state,” Doyle told me, particularly for low-income students at UNC Chapel Hill, the state’s flagship university. Perhaps, as opposed to thinking about how to scale up the NC Promise program, the state should be thinking about how to scale up some of the initiatives already at work at its best-known public university.

For now, however, Pembroke is focused on helping the new students it has enrolled and those who have made their way back to campus. The retention rate at the institution is up 5 percent, and Ward told me that they’re on their way toward the ultimate goal. “Perhaps somewhere in the future we’ll see the number of readmits go down,” he says, “because they don’t leave us.”



In decades past, students needed little more than paper, pencils, and time to get their schoolwork done. For the vast majority of students, that's no longer the case. Most schoolwork these days necessitates a computer and an internet connection, and that includes work to be done at home. One federal survey found that 70 percent of American teachers  assign homework that needs to be done online; 90 percent of high schoolers say they have to do internet-based homework at least a few times a month. Nearly half of all students say they get such assignments daily or almost daily.

Yet despite the seemingly ever-growing embrace of digital learning in schools, access to the necessary devices remains unequal, with a new report from the Pew Research Center finding that 15 percent of U.S. households with school-age children lack high-speed internet at home. The problem is particularly acute for low-income families: One in three households that make below $30,000 a year lacks internet. This is despite an emerging reality in which poorer students are attending schools that evangelize technology-based learning while their more affluent counterparts, as The New York Times reported this past weekend, are “going back to wooden toys and the luxury of human interaction.”

It’s a glaring irony that’s also a major force behind class- and race-based discrepancies in academic achievement. In what’s often referred to as the “homework gap,” the unequal access to digital devices and high-speed internet prevents 17 percent of teens from completing their homework assignments, according to the new Pew analysis, which surveyed 743 students ages 13 through 17. Black teens are especially burdened by the homework gap: One in four of them at least sometimes struggle to complete assignments because of a lack of technology at home. And close to half of teenagers in the bottom income bracket have to do their homework on a cellphone occasionally or often.

From a history-class assignment on the political debate over immigration to required participation in an online discussion board for AP Environmental Science, access to a functioning computer and high-speed internet is all but a prerequisite for success in high school. This is becoming especially true as schools gravitate toward software where students file assignments and papers virtually, as well as schools that equip each student with a laptop or tablet; one 2017 survey found that half of U.S. teachers have one device for each of their students, up 10 percentage points from the year prior. Close to two in three teachers use technology in their classroom daily, according to a separate 2017 survey.

The homework gap can have major consequences, with some studies suggesting that teens who lack access to a computer at home are less likely to graduate from high school than their more technologically equipped peers. The “challenge to complete homework in safe, predictable, and productive environments can have lifelong impacts on their ability to achieve their full potential,” wrote John Branam, who runs an initiative to provide lacking teens with internet access, in an op-ed for The Hechinger Report last year.

Although the big telecom providers offer subsidies to low-income families, these programs are generally underused. And while disadvantaged students can resort to public libraries and other venues that offer free Wi-Fi, such alternatives are still major obstacles to finishing homework every night. “Your aunt has internet access [at home] but she lives a 40-minute bus trip across town,” Branam wrote, illustrating the roadblocks for teens without internet access. “The public library does, but it has a 30-minute computer use limit and, as a young woman, you don’t feel comfortable there late at night. McDonald’s has free Wi-Fi but it’s noisy, you have to buy food and you can’t linger there forever.”

With a team of researchers, the University of Texas at Austin professor S. Craig Watkins spent a year and a half observing and interacting with high schoolers to better understand the digital divide. The researchers’ forthcoming book, The Digital Edge: How Black and Latino Youth Navigate Digital Inequality, chronicles the ways low-income students of color get around not having access to the internet and a computer. In what Watkins calls “social hacking,” students often “reengineer their socioeconomic circumstances in order to get access to technology that they otherwise would not have access to.” For example, the researchers observed that students without such resources at home were adept at developing relationships with teachers who could, say, give them special weekend access to laptops and software for use at home. They also tended to rely on other needy classmates to find work-arounds, sharing with one another smartphones and tablets that more affluent students often take for granted, for instance. “It was an inventive way of cultivating social capital,” Watkins says, “but it also created a kind of sharing economy.”

Watkins says the digital divide is an “institutional blind spot” for many school leaders and policy makers. “I suspect that people a pay grade or two above teachers likely don’t understand the depth at which this access- and participation-gap divide still exists,” he says.

While embedding technology into the curriculum is all the rage in some schools, “oftentimes there’s a lack of clarity and vision in terms of what learning should look like with technology,” Watkins says. “There’s this assumption that just by providing access to technology you’re somehow creating a better learning future for kids, but that is not always the case.” After all, technology in schools is going to be of limited success if kids don’t have access to the internet and a computer once the final bell rings.



In certain parts of the United States, it’s getting more and more likely that rather than a game of dodgeball in gym class or a round of Heads-up, Seven-up as a break between lessons, students will instead find themselves doing downward-facing dog. The internet is saturated with yoga-based lesson plans, teacher-training courses, and “mindful” music playlists designed for schools, while programs for certified yoga instructors who want to bring their practice onto campus have also gained popularity.

While up-to-date data on the prevalence of school-based yoga is hard to come by, a 2015 survey led by the New York University psychologist Bethany Butzer identified three dozen programs in the United States that reach 940 schools and more than 5,400 instructors. School-based yoga programs, Butzer and her co-authors concluded, are “acceptable and feasible to implement.” The researchers also predicted that such programs would grow in popularity.

The trend, however, seems to have been accompanied by an uptick in vocal pushback against the idea. In 2016, an elementary school in Cobb County, Georgia, became the subject of heated controversy after introducing a yoga program. Parents’ objections to the yoga classes—on the grounds that they promoted a non-Christian belief system—were vociferous enough to compel the district to significantly curtail the program, removing the “namaste” greeting and the coloring-book exercises involving mandalas. A few years before that, a group of parents sued a San Diego County school district on the grounds that its yoga program promoted Eastern religions and disadvantaged children who opted out. While a judge ruled in favor of the district, the controversy resurfaced two years ago amid concerns that the program was a poor use of public funds in already strapped schools. Meanwhile, just last month the Alabama Board of Education’s long-standing ban on yoga caused some ballyhoo after a document listing it as one of the activities prohibited in “gym class” was recirculated, grabbing the attention of a Hindu activist.

Proponents tend to cite studies underscoring the benefits of mindfulness-based therapies such as yoga for kids’ development. A 2009 study published in the Journal of Child and Family Studies, for example, found that mindfulness-based cognitive therapy, which teaches children how to divorce themselves from harmful thoughts or emotions, was linked to reduced anxiety and increased attention levels. Other studies suggest that “mindful movement” such as yoga helps to enhance kids’ executive functions—skills such as working memory, attentional control, and cognitive flexibility. Some studies have gone as far as concluding that yoga has a positive effect on students’ academic performance or engagement, particularly among students who’ve struggled with traumatic experiences such as poverty and struggle with self-regulation as a result. After all, decades of research have shown that it’s hard for a child who hasn’t learned how to respond to stress to do well in school.

But some observers question the research on yoga’s benefits. Amy Wax, a University of Pennsylvania law professor who specializes in social-welfare policy, in a 2016 Atlantic story criticized some existing studies on yoga and mindfulness as being of “low quality and dubious rigor.” Julia Belluz, a senior health correspondent for Vox, has noted that despite a drastic increase in recent decades in the number of studies on yoga, the research tends to rely on small numbers of participants and imperfect comparisons, among other limitations. And some parents argue that yoga’s potential benefits aren’t enough to justify the spending at a time when public schools already struggle with limited funding.

The most vocal opponents tend to cite yoga’s Hindu and Buddhist roots, arguing that the line between those origins and secular practices is often blurry. Yoga encompasses all kinds of approaches and techniques, some more spiritual than others, but those roots often filter into even the most innocuous of mindful-movement routines. Religious influences are, arguably, even baked into elements as simple as “om” chants, poses with Sanskrit names, and, as the controversy in Georgia attests, collective “namaste” greetings.

In the Cobb County case, some parents felt that the school was using a double standard in allowing yoga classes yet banning other forms of religious practice in schools. “No prayer in schools. Some don’t even say the Pledge [of Allegiance], yet they’re pushing ideology on our students,” one mother, Susan Jaramillo, told a journalist for the area’s NBC affiliate. “Some of those things are religious practices that we don’t want our children doing in our schools.” Yet the school’s principal, who did end up apologizing for and revising the yoga curriculum, argued that much of the parents’ criticism rested on false assumptions about the program—a parent cited by The Washington Post worried, for instance, that the school was promoting a “Far East mystical religion with crystals and chants to be practiced under the guise of stress release meditation.”

In reality, school-based yoga typically focuses on physical exercise or on relaxation and mindfulness. Some schools integrate it via in-classroom lessons that have kids engage in a few exercises at their desk during short breaks throughout the day. Other schools adopt yoga as an in- or after-school elective, while some incorporate it into regular PE classes.

“Many original forms of yoga are practiced in a religious or spiritual manner,” acknowledges Marlynn Wei, a psychiatrist, therapist, and certified yoga teacher who’s written about yoga’s educational uses. Still, religion-infused yoga often pursues the same ends as its secular counterpart: For example, they both emphasize being in the present. By removing yoga’s more superficial aspects (such as Sanskrit words and symbols), yoga can still have mindfulness and be appreciated for its benefits beyond physical exercise, Wei says.

“The minute you put Sanskrit into a curriculum … some parents are going to freak out,” agrees Jai Sugrim, a yoga instructor who’s taught in schools.

Adoption of these programs has been uneven across the United States—yoga in schools is far more common in some regions than in others. Programs are, according to Butzer’s 2015 survey, based primarily in big cities on the coasts, such as Los Angeles and New York City. Areas known for their New Age–y enclaves—such as Colorado and the Northwest U.S.—account for many of the programs, too. Where they’re all but unheard of, Butzer’s data suggests, is in America’s heartland.

Big cities and liberal strongholds generally tend to be vanguards when it comes to implementing “progressive education” policies, such as the movement to replace zero-tolerance discipline with conflict resolution or the movement to eliminate homework. What’s more, much of the research on school-based yoga focuses on its benefits for “urban youth,” a high percentage of whom contend with trauma such as poverty, community violence, and exposure to drug abuse that takes a toll on their ability to manage stress. It’s easy to take this stuff for granted in areas such as parts of the West Coast and the mid-Atlantic, where, according to a 2016 survey, one in five people practices yoga. But in a state like Alabama, where school-based yoga has long been banned and where according to that same survey just 10 percent of the population has taken a class, it’s conceivable that many might see yoga as bizarre and inappropriate in a school setting. Notably, the same survey found that many people who hadn’t tried yoga before perceived it to be exclusive to young women or those who are already flexible, athletic, or spiritual.

Ironically, proponents argue that the value of yoga in schools is its inclusiveness —its promise to help boys who don’t know how to contain their outbursts, students with physical disabilities, children who struggle with obesity, and teens who lack direction. Perhaps the biggest obstacle faced by school-based yoga comes down to the fact that everyone has his or her own way of thinking about it. Religious versus secular, meditation versus exercise, exclusive versus inclusive—it’s little wonder that two people might see the same kid doing a warrior pose through completely different lenses.  



A coast-to-coast FBI probe alleges that a network of celebrities, business executives, and other powerful figures is at the center of a massive bribery scheme to secure admission into some of the country’s most elite colleges, according to court documents unsealed earlier today.

Among the defendants are nearly three dozen parents whom federal prosecutors are charging with conspiracy and other crimes for allegedly using hefty sums of money to get their children into schools such as Yale, Georgetown, and the University of Southern California. Specifically, the newly unsealed court documents contend that these high-rolling parents—some of them public figures such as the actresses Felicity Huffman and Lori Loughlin, as well as Loughlin’s husband, the fashion designer Mossimo Giannulli—paid hundreds of thousands, and sometimes millions, of dollars per child to a fixer who would then use that money to allegedly bribe certain college officials or other conspirators to help secure the child’s admission.

The country’s elite have long used their wealth to get their kids into top colleges via legal and widely recognized means—legacy and athletic admissions tend to favor the wealthy, and those who can pay for test prep and expensive sports get an additional leg up. In extreme cases, wealthy parents make hefty donations to schools, or, for example, pay for new campus buildings. The 33 parents now being charged allegedly opted instead for organized conspiracy. The alleged bribes were certainly cheaper than a building, and much simpler than paying for years of sports training. But the children of wealthy parents unwilling to risk jail time still get thumbs put on the scale for them in elite admissions offices every day.

That alleged fixer behind the scheme described by the FBI is a business owner named William Rick Singer, who this afternoon pleaded guilty to all the charges against him, including several counts of conspiracy as well as obstruction of justice. The government accuses him of setting up a sham charity to launder the money he collected and spent while perpetrating two primary forms of bribery. One involved third-party individuals fraudulently taking the SAT or ACT on behalf of his clients’ children; the other involved paying coaches to recruit and admit students with made-up “impressive” athletic resumes, a federal official contended at the Tuesday press conference. Many of these so-called profiles, according to the court documents, were replete with staged (or Photoshopped) images and fabricated narratives. He did not immediately respond to a request for comment submitted by The Atlantic through his admissions-advising company.

Charges are also being brought against 13 college coaches, including Yale’s head women’s-soccer coach, who allegedly accepted a $400,000 bribe to admit a student as one of his recruits even though the student had never played competitive soccer.

The biggest victims of this epic alleged scheme, of course, are the higher-caliber students whose prospective tickets to the prestigious colleges were given instead to these teens, whose parents had the savvy and gall to break the rules. But what’s even more disenchanting is that these revelations, sensational details aside, underscore a fact of American life: that the elite-college admissions system is broken.

“When federal prosecutors indicted Hollywood celebrities and other wealthy individuals for paying bribes to have their children admitted to selective colleges, we saw the logical culmination of a more subtle practice that has been going on for decades,” said the education scholar Richard Kahlenberg, who studies legacy admissions and is a prominent critic of them, in an email.

In the Tuesday press conference, the U.S. attorney perhaps unintentionally emphasized this irony when he said: “We’re not talking about donating a building … We’re talking about fraud.”

His comment highlighted the mundanity of admissions favors for upper-crust children—when executed legally. Sometimes these favors are given through a practice known as “legacy admissions,” in which elite colleges give preference to an applicant who, say, is the child of an alumnus. A common denominator tends to be wealth, particularly if the applicant is otherwise underqualified. A parent may offer a college a handsome donation (and, sometimes, a namesake building) to boost her child’s admissions prospects.

“Every year, alumni contribute to their alma maters with the expectation of special treatment for their children,” said Kahlenberg, who’s involved in a separate pending lawsuit over Harvard University’s consideration of race in admission. “This more genteel form of bribery is considered perfectly legal. Not only that, the donors get a tax break to boot, undercutting the fundamental legal principle that a charitable donation should not enrich the donor.”

A famous example involves Jared Kushner, President Donald Trump’s son-in-law and senior adviser, whose father, then a wealthy real-estate developer, in 1998 pledged $2.5 million to Harvard. Kushner—who, the investigative reporter Daniel Golden notes in his 2006 book, The Price of Admission, was described by administrators at his high school as a mediocre student—was admitted to the school shortly after that. A spokeswoman for Kushner Companies told Golden in 2016 that Kushner’s admission to Harvard had nothing to do with his father’s gift to the institution, and noted that the family had donated extensively to numerous universities.

Today, legacy students account for an estimated 14 percent of Harvard’s undergraduate population, and applicants who enjoy such alumni connections are accepted at five times the rate of their nonlegacy peers (a nearly 34 percent acceptance rate, versus just under 6 percent for those lacking connections). Surely not all of those legacies’ families made huge donations to the school, but students with a family history at an elite institution are likely to come from wealthy backgrounds that confer various other advantages.

It’s unclear how Harvard’s legacy numbers stack up against those at other elite colleges—the Harvard data were publicized because of the affirmative-action lawsuit—but a separate national survey in 2018 found that nearly half of private higher-education institutions consider legacy status in acceptance decisions. While colleges err on the side of keeping mum about their practices, they tend to acknowledge that such applicants have at least a slight advantage.

At elite colleges, athletic recruitment is arguably another form of affirmative action for the wealthy. As my colleague Saahil Desai has written, Harvard’s admissions office, for instance, gives a major boost to athletes with middling academic qualifications. Athletes who score a four (out of six) on the academic scale Harvard uses to judge applicants were accepted at a rate of about 70 percent, Desai reported; the admit rate for nonathletes with the same score was 0.076 percent. And research suggests that these athletic recruits tend to come from middle-class white families. Julie J. Park, an education professor at the University of Maryland, concludes in her 2018 book, Race on Campus: Debunking Myths With Data, that as many as 40 percent of Harvard’s white students are legacies or recruited athletes.

Fraud and bribery are shocking, yes. But fraud and bribery’s lawful cousins—legacy preferences, athletic recruitment, and other admissions practices that lower the bar for progeny of the rich and famous—are ubiquitous.



In the spring, Yale sent the last of its rejection letters to more than 35,000 teenagers who had applied for one of the roughly 1,550 slots in its freshman class. Like other top colleges, Yale is extremely selective: Just 6 percent of students who vied for admission in the class of 2022 were accepted.

On Wednesday, The Wall Street Journal reported that the U.S. Justice and Education Departments are investigating Yale for allegedly discriminating against Asian American applicants. The announcement comes just weeks before opening arguments in a court case that similarly accuses Harvard of bias, and is part of a heightened effort on the part of the Trump administration to crack down on race-based affirmative action at the nation’s elite colleges.

How these investigations will play out has yet to be determined—both Harvard and Yale fervently deny the charges. But regardless, one thing is already self-evident: Elite-college admissions are in need of reform—a radical rethinking of the process by which these institutions pick whom to admit and turn away. Elite colleges don’t have to be so selective that ultimately the way they choose applicants comes under so much public (and legal) scrutiny.

These affirmative-action-related complaints wouldn’t have garnered this much traction had the country’s top colleges endeavored to be less, not more, selective. Had they not sought to keep their admissions rate consistently low—well beneath 10 percent throughout most of the Ivy League—despite a growing U.S. population and rising college-attendance rates. Had they not, directly or indirectly, conspired to thrive off of and fuel a higher-education culture that, in the words of The Atlantic contributor Matthew Stewart, is a “brand-obsessed system.”

The total number of applications received by some schools has soared in recent years, and acceptance rates at the country’s top 50 colleges have correspondingly dropped from an average of about 36 percent in 2006 to roughly 23 percent today. In the Ivy League, which continues to set record-low acceptance rates with each admissions cycle, the increase in application numbers parallels the rising number of high-school graduates, which grew from 3.1 million in 2009 to an estimated 3.6 million in 2016. Yet the enrollment at Yale and other Ivies has remained virtually stagnant over the same period: In the 2005–06 school year, the university enrolled 1,321 undergrads, and in 2016–17, that number jumped only marginally to 1,367 students.

Why are elite colleges so hesitant to add students? Part of the reason is the pursuit of selectivity, tied to the quest to top the U.S. News & World Report rankings, which factor in a school’s acceptance rate. Stewart warned of this trend in his story for The Atlantic, too. “Plummeting admissions rates of the very top schools,” he wrote, have meant that 50 colleges are as selective today as Princeton was in 1980.

But rankings aren’t the sole culprit, of course—consumer demand also helps insulate elite colleges from efforts to become less selective. Perhaps assimilating the messages they get from college rankings, many students want to go to a school precisely because it is so selective—students at Yale, for example, are able to boast that they’re one of the 6 percent of applicants accepted to the university. As the former Harvard law professor Lani Guinier once wrote, the American notion of meritocracy tends to “associate selectivity with excellence.”

Yale President Peter Salovey addressed this very phenomenon this past June on a panel at the Aspen Ideas Festival. “There’s a general belief by the American public—typically in cities, but really throughout the country—that even though there are 3,500 or so colleges, it’s only eight of them worth going to,” he said. “And that’s something I think all we education leaders have to push against.”

And Yale is making small efforts to expand access by aiming to grow the size of its freshman class by about 200 students, Salovey explained.

Still, that Yale’s admissions practices have come under such intense scrutiny is a reflection of the the institution’s selectivity—and of its neglect to accept more students.



On Wednesday, Walmart announced that it would offer to pay, at least in part, for its 1.4 million employees in the United States—part-time, full-time, and salaried—to go to college, with some restrictions. Though it is not the retailer’s first foray into the world of subsidizing education for its employees, it makes it the latest big employer to publicly declare it wants to help its employees get a degree, following Starbucks, JetBlue, UPS, Cigna, Fiat-Chrysler, and others.

Here’s what Walmart’s plan looks like: Employees will be able to earn their associates or bachelor’s degrees in either business or supply-chain management, and Walmart will pay for any upfront costs after financial aid, including tuition, books, and fees, which they say will eliminate the need for a loan. Recipients can attend any of three institutions selected for, according to Walmart, their emphasis on adult students: the University of Florida, Brandman University in California, and Bellevue University in Nebraska.

For their part, employees will have to pay the equivalent of $1 per day to Walmart as a sort of co-pay and there does not appear to be any requirement for employees to stay with the company once they have completed their degree—a feature of several other employer-sponsored tuition-assistance programs. “Investing in the personal and professional success of our associates is vital to Walmart’s future success,” said Greg Foran, the CEO of Walmart’s U.S. branch. “We know training and learning opportunities empower associates to deliver for customers while growing and advancing in their careers.”

The move to help its employees go to college looks good for a company that has been pilloried over the years for its low wages, lack of room for career growth, and stingy benefits. That cocktail has made it hard for the mega-chain one-stop shop to retain its workers. But it has tried to change in recent months, boosting its base-pay by $2 to $11 per hour and expanding its family benefits—maternity leave, in particular, which went from six to 10 weeks of paid leave. Offering tuition assistance to employees is another step toward making the company more worker-friendly.

Robert Kelchen, assistant professor for higher education at Seton Hall University, put it like this: “What this shows is—while it’s good PR for Walmart—it’s getting more difficult for companies to keep employees with the economy improving and they’re looking for ways to both keep talented employees and build up goodwill among the public.”

But Kelchen says Walmart and the employees aren’t the only actors that stand to benefit: The program will also be a good thing for the colleges—as partnering with large employers, for skills that the employers want—is important to higher education’s long-term viability. As Kelchen told me, “higher education needs to do a better job of helping students stay connected to higher education while working full-time.”

As for Walmart’s aim, there’s evidence that helping employees go to college pays off. As the economy improves, companies have to work harder to attract and retain workers, and hiring new people is expensive, but these programs can help with retention. As Mikhail Zinshteyn reported in 2016, Cigna posted “a return on investment of 129 percent for its more than 2,200 workers who took advantage of the company’s education-reimbursement program from 2012 to 2014.” That means that for every dollar the company spent on educating an employee, it not only gained that money back, but saved $1.29 on talent-management costs. And employees who took advantage of the program—entry-level and mid-management, in particular—saw their wages jump by 43 percent over that period compared to their colleagues who did not. On top of that, turnover declined by 8 percent, which saves companies a lot of money. And soon there will be more data about how well it does, as Walmart is partnering with the Lumina Foundation to measure the impact and effectiveness of the new offering.

Maybe Walmart’s new program, as Kelchen says, shows that the company has learned from the successes and failures of other employer-sponsored tuition programs, or, more cynically, it’s a chance to change the narrative about how it treats its employees. But one thing is for sure: There are a lot of employees who stand to benefit.



Last May, several dozen young men gathered on the steps of the courthouse in Baraboo, Wisconsin, to take pictures before their high-school prom. It’s not clear what was going through each of their heads—though one could guess—when the majority of them extended their right arms, mimicking the Nazi salute as a parent snapped a picture. The students dropped their arms and proceeded to prom.

But six months later, after the image was posted on Twitter, their gesture became a matter of national fascination and horror. “Regardless of the details of the photo or the intentions in the hearts of those involved,” wrote the Baraboo school superintendent, Lori Mueller, in a letter to parents two weeks ago, “the truth is this is an image that has rightly been described as hateful, frightening and disappointing.”

Hateful, frightening, disappointing—but ultimately unpunishable. That’s what the Baraboo School District concluded after an investigation into the incident this month. In another letter, Mueller said that students’ actions were protected under the First Amendment, explaining that “we are still unclear about some key details” and reiterating that “we cannot know the intentions in the hearts of those who were involved.” (Neither the district nor the high school responded to a request for an interview.)

Is a school really not able to discipline its students for, whatever their intentions, making the same gesture that Nazis did (and do)? Catherine Ross, a professor at George Washington University’s law school, says when considering students’ First Amendment rights, it’s important to gauge whether what they’re doing or saying could be confused with their school’s official stance on a certain issue. In the case of Baraboo, Ross notes, the photographer wasn’t hired by the school and the students weren’t wearing anything that represented the school.

And before schools punish symbolically hateful speech or actions, Ross told me, the school’s case is stronger if it can cite related incidents that disrupted the learning environment in the past. (For instance, it’s much easier for a school to ban displays of the Confederate flag if it can point to a history of violence against black students.) “I haven’t heard anything about this school that suggests that they’ve had violent anti-Semitic or anti-LGBTQ incidents—the sorts of things that Nazis arrested people for just because of who they were,” Ross says.

Another law professor, Michigan State’s Kristine Bowman, says that because the photo was taken in the lead-up to a school event, Baraboo High School did have jurisdiction over the students’ behavior. “But that doesn’t mean that the school can necessarily punish them,” she says.

Bowman says that one difficulty when punishing symbolic speech is establishing students’ intent. “On one hand, I could see someone looking at the picture and saying, ‘Well, we understand exactly the message,’” she says. “And yet, I also can understand why the school officials [were] trying to figure out a whole lot more about what was going on.”

Some of the details reported about the Baraboo photo underline Bowman’s point. One boy in the photo (who didn’t raise his arm for it) told a reporter that the photographer instructed the group “to make the sign” and snapped the picture before he had a chance to duck out of the frame. Another boy said that the photographer asked the group for a “high-sign” and many in the group complied by sticking their arms out. Speaking for himself, the photographer, a parent named Peter Gust, maintains that he instructed the group to “wave,” bidding their parents goodbye before the dance; he calls those who read hate into the picture “dead wrong.”

Perhaps all of the boys with raised arms understood what they were doing. Perhaps only a few of them did, and the others played along. Perhaps they were, every last one of them, baffled by an unclear instruction from a parent. Perhaps they thought it funny to respond with something offensive. Perhaps it isn’t possible to be certain of “the intentions in the hearts of those involved.”

But it is possible to make some deductions. Either they didn’t know what they were doing (which seems a failing of education), knew but meant the gesture as a joke (which would be inexcusably flippant), or knew and meant the gesture to convey its hateful meaning (which would be self-evidently awful). At any rate, if someone showed me their middle finger and told me they meant no disrespect, I probably wouldn’t believe them.

Still, those are moral objections, and as far as the law is concerned, Bowman says, what matters is whether a student’s speech would “materially and substantially interfere” with a school’s educational process. That was a standard set by the Supreme Court in 1969’s Tinker v. Des Moines, which upheld multiple Iowan high schoolers’ rights to wear black armbands to school in protest of the Vietnam War. What constitutes interference, though? “That is a great question, and honestly that is something that courts have been struggling with for decades as they have tried to apply the Tinker standard,” Bowman says.

Bowman adds that because students at public schools are “effectively a captive audience”—all states have laws that require kids to attend school, public or otherwise—schools have more license to shape the community environment, and thus more power to restrict speech, than the government might in contexts where attendance is not compulsory. For instance, the Supreme Court has ruled that a student can be punished for making statements that promote the use of illegal drugs.

Just where that line is when it comes to symbolic speech is something schools struggle with, too, and some have punished students for far less than an apparent Nazi salute. For example, four years ago, a Wisconsin high school suspended two black basketball players for one game after their hand signals in a photo were interpreted as gang signs, though the punishment was soon reversed. And last year, in the midst of the NFL protests against racial injustice, the superintendent of Bossier Parish Schools, a district in Louisiana, said that schools’ football “players and coaches should stand when our National Anthem is played in a show of respect”; a letter from one high-school principal explained that offending students could risk playing time or their spot on the roster. (A spokesperson for Bossier Parish Schools told me that the district issued its statement only after a reporter asked about its policy, not because any students actually kneeled.)

I asked Ross, given schools’ policies on all sorts of other matters (such as students’ clothing and appearance), whether a free-speech doctrine that permits a pre-prom Nazi salute to go unpunished is misguided; she responded with a firm no. “Public schools are not only bound by the Constitution, they have an obligation to teach students that constitutional rights are real, not a sham, not something from the days of the founders but for them too,” she wrote in an email. “This is how students can learn (under constructive faculty supervision) to exercise their rights as active citizens.” (Private schools, for the record, have more leeway to punish student speech because they are independent from the government.)

“I realize that recent events in the U.S, and the rise in hate crimes tempt many to rethink these foundational principles,” she went on. “But hate crimes, violence and the like are conduct, not protected speech.”

Still, as Bowman and Ross both pointed out, even if a school can’t punish something like the Baraboo incident, there are other things it can do. Bowman says that the school is allowed to take the opportunity to establish that it doesn’t condone anti-Semitism. “I think the best response is for the school to take that as a teaching moment and to say, ‘These students, your peers, had a right to do this, and here’s why it’s a bad idea,’” Ross says.

The Baraboo School District appears to be planning something along those lines. Mueller, the superintendent, said the school was going to implement “restorative practices” to bring the community back together, and to take steps to directly address hate. Baraboo may be constrained when it comes to punishing students, but it’s not when it comes to educating them.

This article is part of “The Speech Wars,” a project supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press, and the Fetzer Institute.



Every year, the Department of Education issues billions of dollars in student loans. And every year, outside companies are contracted to collect on those loans. The loans themselves are the subject of fierce debate among the higher-education crowd—but how they are collected tends to draw the most ire.

Borrowers have reported that these outside companies—loan servicers, they’re called—have lost their paperwork, made it harder than it should be to to zero out their balances after becoming totally disabled, and incorrectly calculated their income when registering for a repayment plan based on it, resulting in higher payments than they can afford.  

Lately, several states have taken notice of these practices and are trying to impose stricter regulations on loan servicers, in order to, they say, protect students from being exploited. On Wednesday, in a unanimous vote, the Massachusetts State Senate passed a bill—a student bill of rights, of sorts—with this in mind. But the bill’s passage puts Massachusetts on the path towards a major fight with the Education Department, which has recently told states to lay off when it comes to oversight of loan servicers. (The department’s position doesn’t impact how states regulate the companies that collect privately issued loans.) 

Massachusetts won’t be alone in the fight. Since 2015, a handful of states have passed, or are at least considering, some version of a bill of rights for student borrowers that stiffen requirements for loan servicers—for instance, making sure servicers meet certain standards in order to get accredited, and empowering state officials to investigate and take action against the servicers for unfair practices. States, well aware of the rescission last year of several Obama-era consumer regulations by Education Secretary Betsy DeVos, have been moving to put their own rules in place. Removing regulations, as Devos’s department wants, can harm students, and its latest endeavor to block states’ attempts to police loan servicers has left many wondering: If the department won’t do more to protect students, who will?

Under Obama, the department tried to improve loan servicing from students’ perspective, aiming to make servicers communicate more with borrowers, reform the process of eliminating loan debt for those who are totally and permanently disabled, and create rules for loan servicing that are consistent across the country. When the Trump administration reneged on those aims a year ago, it raised concerns that the department was overlooking borrowers’ interests. Sure, the Obama-era rules weren’t perfect, Jennifer Wang, of the Institute for College Access and Success, an advocacy group, told me, but there was a lot that borrower advocates liked. However, she says, if the department did not have its own reforms, that shouldn’t prevent states from having them.

Loan servicers, for their part, disagree, insisting that the federal government is right to call states off. They argue that inconsistent policy across states—along with the fees that state-level guidelines might require them to pay—will make it harder for them to serve students. Last month, the Education Department made it clear that it largely agreed with them. The department issued a “notice of interpretation,” saying states were overstepping their boundaries by putting restrictions on companies that were servicing federal student loans. The notice stated that it is the department’s job to police the companies, and that states should defer to it. (The Education Department, which is in the process of an overhaul of the student loan–servicing system, declined to comment for this story.)

States immediately fought back. The bipartisan National Governors Association condemned the move, and two Democratic attorneys general immediately hinted that they would disregard the guidance. Meanwhile, after pressure from state lawmakers, two state-backed loan agencies—Massachusetts and New Jersey—resigned from a national loan-servicing lobbying group, the National Council of Higher Education Resources, which supported the department’s move.

Higher-education leaders have also expressed concern. As Janet Napolitano, the president of the University of California system, who was formerly an Obama Cabinet official, as well as a state attorney general, put it, “to take the state AGs out of the picture, who do a lot of these financial-fraud type of cases to the benefit of the residents of their states, I think is an overuse of their preemption power”—a reference to the question of whether states or the federal government should hold sway. (It’s a curious showdown not least because it has state-level Democrats arguing passionately about states’ rights.)

Eric Lesser, a state senator in Massachusetts who championed the state’s bill, told me that the department’s announcement of this stance prodded him to action. The legislation had been introduced in January of 2017, but has seen increased momentum since the March interpretation. Having passed on Wednesday, the bill now heads to the state House of Representatives, where companion legislation is under consideration. Maine followed suit, passing a bill through its state’s senate on Thursday. “Three words for Betsy DeVos and Donald Trump: Bring it on,” Lesser tweeted on Wednesday. “Here in Massachusetts, we will stand up for student loan borrowers if they won't.” The states are inviting a fight—and given how much the current system can hurt students, it’s one worth having.



Bennett College needed to collect $5 million to survive. The historically black women’s college in Greensboro, North Carolina, was appealing a decision to revoke its accreditation—based largely on its feeble financial situation—and wanted to show that it could raise funds. The school gave itself 50 days to prove its case.

Donations dribbled in from everywhere: $10,000 from a local credit union; $40,000 from Mount Zion Baptist Church; $1 and $10 and $50 donations from students; $500,000 from Papa John’s, which has been trying to rehab its image with the black community after its founder made a racist remark on a conference call; $77.25 from students at the Erwin Montessori elementary school. The money trickled in and the clock ticked as the school raced toward its February 1 deadline to raise the money. With two days left, Bennett was only 62 percent of the way to its goal; one day left, 65 percent; 14 hours, 72 percent. Then, a $1 million lifeline from another institution, High Point University. One hour, 95 percent. When the clock ran out, money still needed to be counted, so the college extended its deadline to do so.

The valiant effort, and the accompanying headlines, overshadows the fact that one large donation could have solved the school’s problems. Black colleges rarely receive transformational donations, the ones that get glowing press releases and New York Times–worthy rollouts. Papa John’s, for example, could have donated $5 million, and the rest of the funds raised by the college could have been put away in a rainy-day fund—or built into the school’s endowment. Spelman College, the only other historically black women’s college, received a $30 million donation in December 2018, which is the largest gift to an HBCU from a living donor in history. But that gift is the exception, not the rule. According to The Chronicle of Philanthropy’s database of large charitable gifts, more than a dozen donations of $5 million or more were made to universities in the first month of 2019 alone—none of which went to an HBCU.

Black colleges—which were founded, primarily after the Civil War, to educate black people who were shut out of most higher education—have been underfunded for decades. That they are now overlooked for big donations in favor of wealthier schools seems like insult on top of injury.

Of course, financial woes like those Bennett is dealing with aren’t limited to black colleges. Small liberal-arts institutions are struggling, too—and those troubles have led some schools to close or merge with other colleges in the past several years. According to Alvin Schexnider, a former chancellor of Winston-Salem State University who now operates a higher-education management-consulting firm, any institution that has a high tuition-discount rate, is located in a rural area, has fewer than 1,000 students, or has a small endowment will likely face existence-threatening struggles in the coming years.

The risk is amplified at black colleges, where even less existence-threatening challenges such as taking on debt to pay for building improvements on campus are more expensive. The lack of transformational gifts means that they rely on smaller donations year after year. And when they are on the ropes, they often have to consider fundamentally restructuring their business model, whereas some other institutions—most notably, Sweet Briar College, whose alumnae raised $21 million in three months to help keep the institution open—are able to marshal resources in a serious pinch.

Getting large donations is “like getting a small-business loan,” Schexnider told me. Donors, he said, are asking, “Where else does this lead us? Are we going to be back here, being asked for money again, two, three, four years down the road?” The goal, of course, is to build a consistent stream of private gifts, but donors would prefer not to provide bailout funds on an ongoing basis.

In 1986, Hugh Gloster, a former president of Morehouse College, offered a prescient assessment. “History has shown that the private black college experiences a very slow death,” he said. “You will have an increasing number of weak private colleges lose accreditation, and they will lose enrollment, and then they will lose financial stability.” He stopped short of saying that the institutions would die off, but he foreshadowed the fate of several HBCUs in the following three decades.

The Southern Association of Colleges and Schools, or SACS, Bennett’s accreditor, will review the school’s appeal on February 18. Though the school may have been able to marshal the $5 million, it does not guarantee that its accreditation will be restored. The college will maintain its accreditation while the appeal process is ongoing. If its appeal is unsuccessful, administrators have said the college will sue SACS, and maintain its accreditation while the lawsuit works its way through court. Meanwhile, the school has applied to another accreditor, the Transnational Association of Christian Colleges and Schools.

Black colleges are historically important institutions that still produce more than 25 percent of black STEM-degree holders, and a quarter of black education-degree holders. But the private ones are dealing with the issues small liberal-arts colleges also face—low enrollments, smaller endowments—and many of them are doing so without the safety net of wealthy donors who can bail them out in an emergency.



The Government Accountability Office did not mince words in the top line of a 1980 report to Congress on inequitable treatment of women in prison: “Women in correctional institutions are not provided comparable services, educational programs, or facilities as men prisoners.”

Incarcerated women had been filing lawsuits—and they had been winning. Their conditions, they argued, violated their constitutional rights: Indifference to medical needs was cruel and unusual punishment, courts found. In some instances courts found that male guards’ contact with women constituted an extreme invasion of privacy. And at a more fundamental level, courts said that failing to provide parity in vocational programming was a Fourteenth-Amendment violation. Those victories forced the government to take notice. That unfair treatment, the GAO said, required action.

Today, nearly four decades after that GAO report, the disparity in educational offerings between women and men is still immense. The Texas Criminal Justice Coalition (TCJC), an advocacy group, released a report last week on the treatment of women in Texas’s criminal-justice system showing how the needs of incarcerated women continue to go unmet. One of its findings: The state offers 21 job-certification programs for men, and just two for women. The programs are as different in kind as they are in number. Men are offered programs such as construction carpentry, electrical technology, and advanced industrial design. Meanwhile, women are offered office administration and culinary arts.

Prison programs that reinforce gender roles have been around as long as women have been a part of the prison population, Brenda Smith, a law professor at American University, told me. “In the earliest prisons,” she says, “women washed, sewed, cooked, and cleaned—more often than not for the male staff, and also for male inmates.”

The number of women in state prisons has ballooned since the late ‘70s, but it is still small compared to the amount of incarcerated men. The fact that there are fewer women than men does contribute to the difference in programming available, according to Smith. After all, it makes financial sense to offer the bulk of programs to those who makes up the majority of the prison population. However, by not offering similar educational programs at women's facilities—particularly those that provide skills that are useful to potential employers—women's prospects once they are released from prison are hampered. So advocates argue that prisons should come up with another approach, perhaps, at the very least, allowing women to take vocational courses at the men's prisons.

But critics have argued—in court, and elsewhere—that it would be dangerous to have women go to men’s facilities to participate in vocational coursework. As a former warden of one of the men’s prisons in the District of Columbia, Vincent Gibbons, put it to the court in the early ’90s when incarcerated women in D.C. filed a class-action lawsuit against the district, it would be “an absolute nightmare” for women to be escorted to the men’s prison for educational programs. His main objection was, he said, the security concerns that come with the mixing of men and women. However, when remarking upon his staff’s reaction to the presence of women at the facility for vocational training, Gibbons said, according to court records, everyone was “very impressed with how few problems there have been.”

Still, the inequity in men’s and women’s educational offerings in prison has persisted—and not only in Texas. In Louisiana, men are offered certificate programs such as collision repair and carpentry, while the women’s prison offers marketing management and upholstery, among others. And in Mississippi, men are offered 13 programs, while women are offered five, including one exclusively for them called “family dynamics.” According to the Mississippi Department of Corrections’ website: “The focus is similar to a Home Economics class, but the curriculum is broader.”

The differences in educational programs in prisons is not only bad for women, Smith told me, but it is also bad for men. For example, many men would benefit from parenting programs, but they rarely have access. A report last year found that just 15 percent of men took parenting classes while incarcerated.

It was clear to the GAO nearly 40 years ago that prison reform needed to work towards eliminating inequities between men and women’s facilities, including in educational offerings. And government-funded research has shown that prison education has a significant impact on whether or not someone will return to prison. But there has been little targeted action to fix the problems, and, as the TCJC report shows, that means not much has changed.



Purdue University. The University of North Dakota. Auburn University. The University of Oregon. Brigham Young University. Xavier University. Oklahoma State University. These are just a handful of the schools in America that have had blackface scandals—not, as one might presume, in the long-distant past, but in the past two decades.

This blackface resurgence dates to late 2001, when Alabama’s Auburn University found itself in the throes of a crisis that made national news. One fraternity, Delta Sigma Phi, had cast out two of its members who had been photographed in front of a Confederate flag. One student was wearing a makeshift Ku Klux Klan robe; the other was wearing blackface and had a noose around his neck. Within the same week, another fraternity on campus, Beta Theta Pi, suspended 13 of its members who had been photographed at a party wearing blackface and wigs.

Greek organizations across the country raced to condemn the incident at Auburn. The North American Interfraternity Conference ran an ad campaign imploring students to show their true faces next Halloween. There was a diversity rally on campus. There were calls for reforms of the Greek system. Then, several months later, in May of 2002, there was another incident, this one at Syracuse University: A student and member of the Sigma Alpha Epsilon fraternity dressed in blackface, covering his arms and hands in the black paint as well. He went around to several college bars. He was, he explained, dressed as Tiger Woods.

In the days that have followed revelations that Virginia Governor Ralph Northam dressed either in blackface or in a KKK robe—or neither, but a photo somehow ended up on his medical-school yearbook page—a national reckoning of sorts has taken place. People have combed through other college yearbooks and found more racist images. Blackface and nooses ad infinitum. But these yearbooks are from the ’50s and ’60s and ’70s, leading to the impression that blackface on campus is a thing of the past. And that’s just not the case.

“We haven’t been talking about it, but this hasn’t gone away. This has been happening,” Walter Kimbrough, the president of Dillard University and an expert on fraternity and sorority life, told me. “And there’s an incident practically every year.”

Just weeks ago, in January, two students at the University of Oklahoma were filmed in a video laughing as one of the students wore blackface, painted down to the palms of her hands, and said the N-word. At least one of those students was expelled from her sorority, Delta Delta Delta.

The incident at the University of Oklahoma came only four years after another video, showing members of the university’s chapter of Sigma Alpha Epsilon chanting, “There will never be a nigger at SAE,” roiled campus and forced a reappraisal. “This video signals to me that we have much more to do to create an environment of equity and respect,” said Jim Gallogly, the university’s president, who was facing calls for resignation after mere months on the job. “We must be purposeful to create authentic measures to address and abolish racist experiences for our students, faculty, and staff.”

What it meant to be purposeful to create authentic measures wasn’t exactly clear, but universities have been trying for years to grapple, in particular, with racism, both contemporary and historical. Across the country, institutions—Brown, Harvard, UNC-Chapel Hill, Duke, Georgetown—have formed commissions to understand their links to slavery. The University of Virginia, for example, recently released a report detailing how its beginnings are intrinsically, fundamentally tied to slavery. “Even in Jefferson’s own imagining of what the University of Virginia could be, he understood it to be an institution with slavery at its core,” the report reads. And yet these issues are not merely in the past. The university today says it’s committed to the ideals of “creating opportunities for global citizens” and fostering collective learning, but the avowed white nationalists Richard Spencer and Jason Kessler, two of the organizers of the 2017 rallies in Charlottesville, are alums of the institution.

When blackface or racist incidents keep happening, Kimbrough says, “it’s a feature, not a defect.” Colleges are reflections of the nation; as the nation’s problems go, so too do universities. “There are a lot of campuses that need to truly have that conversation to say: ‘What’s going on?’” he told me. “It’s not, ‘Let’s have a diversity program or a Martin Luther King program’; it has to be much deeper than that.”

“They scapegoat and say, ‘Oh, that was just back then, and people didn’t know better,’” Kimbrough says. “No. It’s happening right now.” On Thursday, Auburn City Schools in Alabama announced that they would be investigating a photo of a student at Auburn High School who wore blackface. The photo is overlaid with the caption, “is this what being a nigger feels like.”



Tariq Habash was in the market to buy a home in 2016, and he knew there were a couple of factors that the banks would be looking at to figure out whether he would get a loan, for how much, and what the terms would be. There was his credit score, his down payment, and his assets. Then there were his liabilities: credit-card debt, car payments, and student-loan debt. But he found something troubling when lenders were calculating his student-loan debt payments: They were saying he owed a lot more than he actually had to pay.

Why was that? Habash, who was a 25-year-old living in Washington, D.C., at the time, was in an “income-driven repayment” plan, which allows borrowers to pay a reduced amount for their student loans each month based on their income and family size. The mortgage lenders Habash was going to did not look at that lower monthly payment, and instead calculated monthly payments based on the size of his loan.

Habash, a senior policy analyst at the Century Foundation, was ultimately able to work his situation out with lenders, and get a mortgage that was reasonable. But others without his sort of expertise are often stuck unable to get a mortgage. Income-driven repayment plans are meant to help people who might otherwise struggle to repay student-loan debt—mostly people who earn between $20,000 and $60,000, according to Kristen Blagg of the Urban Institute. If a borrower makes regular payments of the agreed-upon amount for 20 to 25 years, based on a specific income-driven repayment plan, the outstanding debt will be forgiven. But lenders did not take the discounted payment amounts into consideration, which at times led to the bank surmising that a borrower had too much debt to be able to make their monthly payments—and ultimately to a mortgage denial.

In April 2017, the federally controlled mortgage giants Fannie Mae and Freddie Mac, after heeding calls to change how they assess potential borrowers who use income-driven repayment plans, changed their rules, allowing borrowers to use their actual monthly payments for student loans as opposed to an arbitrarily calculated payment. That meant borrowers enrolled in income-driven repayment plans would potentially have lower debt-to-income ratios, and could qualify for better mortgages.

But those two companies are only part of the home-loan market. The Federal Housing Administration, a branch of the Department of Housing and Urban Development, which oversees FHA loans—government-backed loans intended for low-income borrowers—has not followed suit. (Critics of Fannie Mae and Freddie Mac argue that their baselines of credit score and down payment are still prohibitive for many potential homebuyers, even if they were able to make monthly payments.) As a result, low-income borrowers in search of even the most modest home loans might be left wanting.

“When you’re in active repayment, you don’t need to make some sort of calculation, because the reality is: You have a student-loan payment amount,” Habash told me, “and that should be factored in.” FHA loans are often used by people who have higher levels of debt, and who don’t have top-notch credit scores, he says. But when the government is inflating the debt-repayment amount, the would-be-borrowers who might need to use FHA loans the most are left out. It’s a case of two government policies, both intended to help low-income people, that are not communicating well.

Brian Sullivan, a spokesman for the Department of Housing and Urban Development, told me that despite calls to revisit considering income-based repayment, the department would be hard-pressed to do so. “We’ve been asked to revisit this issue, and we’ve been taken to task by those who wish we would revisit this issue, but we’re not.” In 2013, the Federal Housing Administration, for the first time in its history, had to request a bailout from the Treasury—a mandatory appropriation of $1.7 billion dollars. “In the climate we face today, and with people being very keen on avoiding risk here,” Sullivan said, “nobody ever wants that to happen again.”

“In the treatment of student debt, we made a policy decision not that long ago to treat deferred student debt as debt all the same, and in the case of your question—whether we would forecast timely student-debt repayment that might ultimately lead to the forgiveness of a portion of that debt—our rules just don’t contemplate that.”



On Thursday, as he testified in front of the Senate Judiciary Committee, the Supreme Court nominee Brett Kavanaugh responded to more questions about beer than he probably would have liked.

At one point, Senator Sheldon Whitehouse pursued a line of questioning about the “Beach Week Ralph Club,” a phrase that appeared in Kavanaugh’s yearbook next to his senior photo. Kavanaugh told Whitehouse that “Ralph” probably referred to vomiting, something that Kavanaugh attributed to his “weak stomach, whether it’s with beer or with spicy food or anything.” Whitehouse asked if the “Ralph Club” reference had to do specifically with alcohol, and Kavanaugh responded:

Senator, I was at the top of my class academically, busted my butt in school. Captain of the varsity basketball team. Got in Yale College. When I got into Yale College, got into Yale Law School. Worked my tail off.

It was a deflection, but the particular shield he raised was telling. His response seems to suggest a belief that a prestigious education stands as evidence of moral rightness.

He offered the same defense when Senator Mazie Hirono brought up the fact that Kavanaugh’s freshman-year roommate recently remembered him as “a notably heavy drinker, even by the standards of the time.” First, Kavanaugh questioned his former roommate’s motives for saying such a thing. But then he said, “Senator, you were asking about college. I got into Yale Law School. That’s the number-one law school in the country. I had no connections there. I got there by busting my tail in college.”

In those two exchanges, Kavanaugh treated his education as a magic wand, something that could be waved to dispel questions of his conduct. Indeed, Americans have a particular fondness for meritocratic narratives, frequently conflating achievements and hard work with human worth. And as deserving as they tend to think the wealthy and accomplished are of their money and success, it’s likely that luck gets underrated as a cause of them, as the economist Robert Frank has argued. (The word meritocracy was actually coined satirically, in an attempt to show how cruel the world would be if the intelligent and accomplished received preferable treatment.)

It should go without saying, but there are all sorts of bad actors who have attended prestigious universities. The convicted insider trader Raj Rajaratnam, the former Enron CEO Jeffrey Skilling, and the convicted killer Lyle Menendez were all admitted to Ivy League institutions. The Unabomber, who killed three and injured 23 with letter bombs in the ’70s, ’80s, and ’90s, went to Harvard. That doesn’t mean that Kavanaugh is among them, but it is a reminder that attending a prestigious school isn’t in and of itself revealing of anyone’s moral character in any direction. It is telling, however, that Kavanaugh pointed to his credentials when trying to prove his own.



The past few months have been busy for the student activists of March for Our Lives, an advocacy group founded after a gunman killed 17 people at a Parkland, Florida, high school earlier this year. In anticipation of the midterm elections, organizers toured the country encouraging young people to vote for candidates who support stricter gun-control laws. That didn’t quite pan out exactly the way they had hoped on Tuesday night, as their favored Senate and gubernatorial candidates in Florida didn’t win outright, and those elections are currently still being contested.

And then two days after the election, they woke up to yet another mass shooting, as at least 13 people were gunned down during college night at the Borderline Bar and Grill in Thousand Oaks, California, which was frequented by students from the nearby Pepperdine University, California Lutheran College, and California State University Channel Islands.

Matt Deitsch, the older brother of two Parkland survivors and a member of the Marjory Stoneman Douglas High School class of 2016, is the chief strategist for and one of the founders of March for Our Lives. He spoke with me on Thursday about what happened in Thousand Oaks, the push March for Our Lives has been making for stricter gun control, and how the group plans on responding to the latest shooting.

Natalie Escobar: I want to start off by acknowledging that today must be hard. Could you tell me about what’s on your mind?

Matt Deitsch: I had a thought of being back to those horrific moments [right after I learned about the shooting at Marjory Stoneman Douglas]. I also thought about how before the midterm elections, politicians were talking about things that weren’t really a threat to American citizens [instead of talking about gun violence], and now after the election, mass shooters are still in the headlines. We’ve had over 300 this year, and it’s not going to slow down until we do something about it. I think now we have a Congress that will at least potentially take the conversation beyond where it’s stalled for so long.

Escobar: Reportedly, two of the people at the bar last night were there celebrating their 21st birthday—that detail hit a lot of us in the newsroom pretty hard. It’s supposed to be a milestone of adulthood, and I’m wondering if you think that how young people feel about coming of age has changed at all in a time when events like this keep happening.

Deitsch: We understand that we have a long life ahead of us, and we don’t want to live a long life in fear. And so we’re going to do something to stop this horror. I turned 21 last month. We hear about all the young people with so much potential gunned down, and we have to stop it, because the future is suffering and our youth are traumatized.

Escobar: March for Our Lives has recently been focused on the midterms and getting young people to the polls. What was your Election Day like? Can you tell me about the things you were doing in the hours before results came in?

Deitsch: A week and a half before the election, we did a tour of 25 colleges around the country. We came to Parkland for Election Day, and we created a “war room” with local students. In the war room, we set up a phone bank and called 18-to-21-year-olds across the state of Florida, and we made over 9,000 phone calls in one day. Then we went to a viewing party at night. The Florida numbers weren’t surprising, but it definitely reminded us where we are in Florida. The youth turnout was the highest it has ever been in American history, so it’s a huge step in the right direction.

Escobar: Are the election results going to change your strategy at all? What are you planning next?

Deitsch: Our organization has never really been candidate-centric or policy-centric. We hope to expand the electorate of the people who care about this issue, and understand the urgency of putting this issue first. We’re going to keep doing what we’re doing and create a blueprint for young people to have more of a force in the electoral process. Elected officials now know that they’re going to need young people to win these close races.

Escobar: I’m wondering what you observed in your Parkland community on the night of the election and if you’ve seen people change since February.

Deitsch: There’s a reason it takes you three times voting to become a lifetime voter, because you understand the wins and the losses and what’s necessary to be a part of the system, to feel your own power. I think Parkland is starting to see its own power. I felt really hopeful, and there’s so much to celebrate.



