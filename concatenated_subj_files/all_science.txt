Something weird is happening in American politics: People are excited about climate policy again.

Since November, progressives have rallied around a Green New Deal, a package of policies aiming to slash carbon emissions while renewing the U.S. manufacturing sector. Though its finer details remain hazy, think tanks have begun to explore how it might work, and Democrats with White House ambitions have rushed to endorse it.

At least a decade has passed since climate change commanded so much political attention in the party. “If your 2020 platform doesn’t include a Green New Deal, are you really running for president?” teased Representative Alexandria Ocasio-Cortez a few weeks ago. 

Yet for every imaginative proposal or boisterous protest, there is an unavoidable truth: Passing a Green New Deal is going to be really, really, really hard.

The reason for this difficulty is so simple and straightforward, it feels almost silly to mention. Success will require Democrats to control the White House, the House of Representatives, and the Senate—and then find a policy that will pass all three.

That is, of course, how you pass a law. But Democrats could very well find legislating a Green New Deal to be more arduous than achieving other progressive goals, such as Medicare for all or a wealth tax on super-millionaires. Not once, during the modern era of climate politics, has a major emissions-cutting bill made it through this gauntlet. And a Green New Deal has an urgency distinct from other party aspirations: The sooner it’s in place, the more time it will have for the marathon work of attacking emissions.

Thirty-one years have elapsed since the NASA scientist James Hansen told Congress that global warming was under way. Democrats controlled both the White House and Congress during four of those years, and twice—in 1993 and 2010—passed an ambitious climate-related bill out of the House only to see it die in the Senate. “The Senate,” concluded the writer David Roberts, “is where dreams go to die.”

In the next six years, immutable political facts will make passing anything out of the Senate especially difficult. Yet the next six years are the period that Green New Deal advocates must care most about. They have explicitly adopted the goal of limiting Earth’s temperature rise to 1.5 degrees Celsius, which would require global carbon emissions to be cut almost in half by 2030. That already appears next to impossible. It will be risible fantasy if no law is on the books by 2025, if not much earlier.

Below, I’ve described one path that Democrats must walk to turn any ambitious climate policy into law. It will require the party to make an unlikely journey. It might require mainstream Democrats to endorse far more aggressive governance than they would have ever once considered. But if the past few years have shown anything, it’s that the unlikely, the aggressive, and the unprecedented can come to pass.

What must Democrats do to pass a Green New Deal in 2020?

1. A Democrat must win the White House in 2020.

If Republicans retain control of the executive branch, the next opportunity to pass a Green New Deal would not come until after the 2024 election. It could still do much good then, but the window for policy to prevent 1.5 degrees Celsius of warming would have likely closed.

2. Assuming a Democrat is president, Democrats must retain control of the House of Representatives in 2020.

3. Democrats must also win the Senate in 2020. Because the vice president is a Democrat in our thought experiment, the party will need to win at least 50 seats to control the 100-member upper chamber. (The vice president can vote in the Senate in the event of a tie.) Thirty-five senators who caucus with the Democrats are not up for election in 2020. To control the Senate, the party must win at least 15 seats.

Where do those seats come from? Democrats are considered a lock to win seven states in deep-blue territory. Four more races in bluish states (Virginia, Minnesota, Michigan, and New Hampshire) will feature popular Democratic incumbents. And figure that Democrats win Colorado, which broke for Hillary in 2016.

That’s still only 12 seats, and Democrats need at least three more. So they will likely try to capture at least three of the following eight states: Arizona (where a Democrat won in 2018), Alabama (where the incumbent Democrat Doug Jones is running), Maine (against the popular GOP senator Susan Collins), Georgia, North Carolina, Iowa, Texas, and Montana. With the exception of Maine, Trump won all those states in 2016 with at least a 3.5-percent margin.

Yet those eight states are crucial only to winning back the Senate, not the presidency. If Democrats regain their usual footing in the Great Lakes—as they already did in the 2018 midterms—then they could still win 270 electoral votes without making a dent in the Senate. But then hope for any legislative Green New Deal would be dashed: The GOP Senate majority leader could simply decline to bring any Democratic proposal to the floor.

4. Let’s say Democrats pull it off—but just barely. By January 2021, a Democratic president is addressing a joint session of a Democratic House and a meager, 51-person Democratic Senate majority. Now it is, at least, possible to pass a Green New Deal. But party leaders must be willing to play hardball.

Under current Senate rules, most federal legislation must receive at least 60 votes to pass out of the chamber. This is not due to some constitutional requirement—any simple majority can pass a bill—but due to the filibuster, which requires a 60-vote “supermajority” to end debate on a measure. Because the filibuster is enshrined only in the Senate rules, not in the Constitution, Democrats could repeal it with 51 votes. The Senate has already repealed the filibuster when voting on Cabinet nominees and federal judges, but has so far preserved it when considering new legislation.

In our thought experiment, the Senate will not have 60 Democrats, period. And party leadership will struggle to find nine Republicans who will vote to end debate on a Green New Deal package. So if Democrats want to pass it, they will likely have to choose to end the legislative filibuster. 

But will Democrats have the stomach for doing so? It’s not clear. “If you don’t have 60 votes, it just means you haven’t done enough advocacy,” the senator and Democratic primary candidate Kirsten Gillibrand said on a recent episode of the podcast Pod Save America. (She also refused to say that she would push for its repeal as president, though it’s quite possible she was noncommittal only so she could ding Republicans if they repeal the rule first.) 

5. Democrats do have one way to try to work around the filibuster. They might try to pass a Green New Deal through “budget reconciliation,” an odd loophole that allows roughly one bill per fiscal year to pass out of the Senate with a simple majority of votes. But reconciliation can only be used to pass a bill that directly pertains to the federal budget—and it cannot be used to do anything that would significantly increase the federal deficit in 10 years’ time. So the most ambitious Green New Deal ideas would likely be ruled too broad to qualify for reconciliation. (Though the policy scholar Mike Konczal has suggested that passing Medicare for all in reconciliation could free federal funds for climate policy.)

6. But suppose Democrats ditch the filibuster. Then they must advance a Green New Deal bill that wins the support of every Democratic member (assuming that they only hold 50 seats). The party’s caucus will likely include several newly elected moderate Democrats—and it will almost certainly include Senator Joe Manchin of West Virginia. Manchin, who has deep ties to the coal industry, has not been a friend to climate policy. When he first ran for Senate in 2010, he cut a campaign ad where he shot a hole through President Barack Obama’s favored climate bill. Yet he would need to support any party-line vote with a 51-member Democratic caucus.

7. Winning over Manchin explicitly for a Green New Deal is not the party’s only option: Democrats could change their own math in the Senate. Assuming they repeal the filibuster, Democrats would only need 51 votes to add a new state to the union. Luckily for them, two Democratic-leaning states would love to join: the District of Columbia and Puerto Rico. If Congress and the White House welcomed both D.C. and P.R. to the Union, Democrats could immediately pad their majority with as many as four new senators. And those senators could even be seated immediately. But this plan would also require the support of Manchin and any new moderates like him.

Or maybe every contingency here will fall through in 2021. Say that Democrats choose not to ditch the filibuster, not to use reconciliation, and not to add D.C. and Puerto Rico as states. Instead, they look ahead to the 2022 Senate election, possibly the most favorable cycle for Democrats in years. It offers the chance to seize some purple seats that Republicans won in 2016, with elections in Florida, Pennsylvania, Wisconsin, Georgia, North Carolina, and Ohio. Democrats finally enhance their majority.

Yet Democrats might come into their new Senate majority exactly as it becomes legislatively useless. Assuming a Democrat holds the White House, history suggests that the party could stand to lose dozens of House seats in 2022—and possibly control of the chamber, too. As Gallup wrote before the 2018 election: “The president’s party almost always suffers a net loss of U.S. House seats in midterm elections.”

With that loss, the Green New Deal will meet the same fate as Democratic climate policies before it. It will fail. The United States will neither cut its emissions via policy nor pour hundreds of millions into clean-energy R&D. And the planet’s temperature will keep soaring, well past 2 degrees Celsius.

Or maybe not—I’ve only given one scenario here, after all, and reality could differ in countless ways. Every additional Senate seat that Democrats take in 2020 could help them pass a Green New Deal. Sudden demographic change—such as a surge in enthusiasm among young voters—could push electoral math in Democrats’ direction. And if a Green New Deal fails, the party could also make a “second go” at climate policy before the 2022 election—trying for something like the carbon-fee-and-dividend scheme endorsed by many Democrats, some Republicans, and most oil companies.

The technological outlook could also shift. In 2007, few predicted that the sudden success of fracking would alter the next president’s energy policy. Yet it did. A breakthrough on a technology like carbon capture—which is financially supported by many oil firms—could rapidly scramble the partisan politics of climate change, making the GOP more willing to negotiate on a round of federal spending.

Yet none of these possibilities changes the basic fact that a Green New Deal will be really, really, really hard to pass in the coming years. And if we want to avert disastrous climate change, the coming years are the most important ones we have.



  An “ice tsunami” killed a herd of musk oxen in February 2011 and kept their bodies perfectly entombed for seven years.

  Ten thousand years ago, the people who lived in Europe had dark skin and blue eyes.



When an ocean sunfish washed ashore in Australia a few days ago, the people who found it couldn’t help but gawk. The ocean sunfish is fundamentally bizarre, and the weirdest thing about it isn’t the teeth in its throat. It isn’t the way it plays dead on the ocean surface. It isn’t even the way its googly eyes make it perpetually look as if it’s just realized it left the stove on at home.

The strangest thing about an ocean sunfish, at least to Natasha Phillips, is its shape. Phillips, who studies the creatures at Queen’s University Belfast, called them a “giant pancake of a fish,” because they can grow to more than 5,000 pounds. Essentially, ocean sunfish look as if somebody began building a fish, added enormous vertical fins just behind its head, and then started laughing too hard to continue. And for scientists, these fish, with their unusual shape and inscrutable life, remain a “big bag of mysteries,” Phillips says.

Ocean sunfish, also called mola, are a genus of bony fish. They have a pair of normal, side-to-side fins that they can use to hover when they’re just chilling, but the true stars are their dorsal and anal fins, which protrude vertically from the fish’s body. Those majestic, ridiculous flappers can stretch up to 14 feet from tip to tip.

Despite their ungainly appearance, those fins are the mola’s primary way of getting around the ocean and can actually be a rather speedy mode of transportation. Ocean sunfish have been recorded swimming as fast as 21.6 feet (6.6 meters) per second over short periods. That’s fast enough to rival the cruising speed of more conventionally shaped (read: unoriginal) swimmers like yellowfin tuna.

What’s unclear is exactly how the fish manage this dashing feat. It’s been suggested that those big fins work like wings, Phillips says, but that’s not yet accepted as scientific fact. She also says the fish’s clavus—that still giant but oddly truncated butt where a tail should be—seems to function like a rudder, but researchers are trying to figure out its exact function.

Just last year, Phillips and other scientists discovered that the muscles that drive the fish’s fins are also connected to a layer of gelatinous mystery meat that lies just under its skin. That layer is called the capsule, and Phillips says it functions as “a wetsuit and a life jacket and a skeleton all in one.” She and her team found that the exoskeleton-like nature of the capsule helps the ocean sunfish move, but precisely how is anyone’s guess. It could make the fish’s strokes more powerful, Phillips said, but it could also just be an “evolutionary quirk.” (“Evolutionary quirk,” coincidentally, is a description that could apply to the entire Mola genus, not just its squishy super-suit.)

Part of the reason scientists still know so little about how the fish moves is that, despite its coquettish looks, the animal is notoriously shy. Marine biologists, including Philipps, have managed to tag and track a few over the years, but tagging can only reveal so much.

Researchers haven’t yet figured out how the ocean sunfish’s dorsal fins counterbalance when they’re moving at different times. They’re not sure how many different species there are, or even how many individual fish. Scientists don’t know how much the fish eat, how long they live, or how to distinguish juveniles from adults. It’s a riddle how and why the ocean sunfish’s pufferfish-like ancestors moved into the open ocean. And it remains to be seen where the fish go to breed, and where their normal ranges are. “They’re being found in places we didn’t expect,” Phillips says. That includes the Australian specimen, a member of a species that rarely shows up in that part of the world.

It seems odd that the fish continue to grab the world’s attention, despite the fact that different ocean-sunfish species are found pretty much everywhere except the poles and the equator, and humans have known about them for thousands of years. Phillips blamed the proliferation of smartphones: Fisherman’s tales are now accompanied more often with proof. But I suspect that these things are so purely weird that, perhaps, we’ll never get tired of being excited by them.

Of course, it’s not the ocean sunfish’s fault it’s so weird. Like most of us, it seems to have its family to blame. “When you start with the normal body plan of a pufferfish” and plunk it in the open ocean, Phillips says, “this is kind of as good as you’re going to get.”



The economic thinker who most influenced the Green New Deal isn’t Marx or Lenin. No, if you want to understand Alexandria Ocasio-Cortez’s bid to remake the economy to fight climate change, you need to read Hamilton.

Yes, Alexander Hamilton. Long before he was associated with theatrical hip-hop, former Treasury Secretary Hamilton called for policies that sound familiar to us today. Like Representative Ocasio-Cortez, he wanted massive federal spending on new infrastructure. Like Donald Trump, he believed that very high tariffs can nurture American manufacturing. And like Elizabeth Warren, he was willing to bend the Constitution to reform the financial system.

Hamilton, in short, successfully used the power of the federal government to boost manufacturing, to pick winners and losers, and to shape the fate of the U.S. economy. He is the father of American industrial policy: the set of laws and regulations that say the federal government can guide economic growth without micromanaging it. And the Green New Deal, for all its socialist regalia, only makes sense in light of his capitalistic work.

In the days since Ocasio-Cortez debuted the Green New Deal, consensus has hardened: It is legislation by listicle. “An aspirational climate policy wish list,” writes the democratic socialist Ryan Cooper. “A needlessly long wish list,” says The New York Times’ David Leonhardt. “An untrammeled Dear Santa letter without form, purpose, borders, or basis in reality,” adds National Review’s Charles C. W. Cooke, in Buckleyan reverie.

Even its supporters seem to concede that the Green New Deal is a binder of climate policies duct-taped to an Easter basket of socialist goodies: Its individual parts may be great, but you have to admit that it looks like it might teeter over. Its critics, meanwhile, ominously suggest that it prizes ideology above science—something I have also warned of.

But both views are, on the whole, incorrect. Ocasio-Cortez’s proposal is not only a set of progressive nice-to-haves, nor is it a full-on assault on capitalism. The Green New Deal has a coherent economic philosophy and a compelling theory of change—and pundits don’t have to like them to bother understanding them.

Above all, the Green New Deal is a leftist resurrection of federal industrial policy. It is not an attempt to control the private sector, according to its authors; it is a bid to collaborate with it. And it draws on a set of ideas with a rich American history, extending long before the great World War II mobilization to which the Green New Deal is regularly compared.

“This goes back to Hamilton, the daddy of it all,” says Stephen Cohen, a professor of city and regional planning at UC Berkeley. He argues that industrial policy has birthed the transcontinental railroad, the cookie-cutter suburb, the home appliance, and the computer—nearly every major American economic transition since 1776.

In short, the Green New Deal’s supporters hope that industrial policy can now bring forth another transition—to cheaper energy, faster trains, and an altogether more climate-friendly economy. “The core of the Green New Deal, if you just look at the projects, is just like industrial policy, industrial policy, industrial policy,” says Rhiana Gunn-Wright, a policy researcher at the think tank New Consensus who helped draft Ocasio-Cortez’s proposal. “It’s very, very, very central. The Green New Deal is one of the largest interventions in U.S. industrial policy in a long time.”

Ocasio-Cortez’s love of industrial policy did not come from nowhere. In the past few years, a group of scholars has revived an old school of economic thought that says a strong manufacturing policy is an absolute necessity for large, developed nations. They argue that the United States has neglected its domestic manufacturing sector since the 1980s, a move that risks national failure.
This new school is central to the Green New Deal. Omitting it is like ignoring Milton Friedman when discussing President Ronald Reagan’s policies. And discarding it is throwing out what makes the Green New Deal so interesting. For more than a decade, the biggest progressive ideas about curbing climate change have relied on technical or narrow market mechanisms. They have required regulators to make emitting carbon dioxide costly. By prescribing industrial policy, the Green New Deal goes in a different direction: It throws all of American government and industry behind an attempt to make renewable energy cheap.

This move could revolutionize U.S. climate politics. Ocasio-Cortez has a chance to recast one of Trump’s economic intuitions—that the decline of industry has broken something fundamental in the U.S. economy—as climate policy. She may be squandering it.

Last fall, a number of activists and policy scholars from the same network of leftist groups as Ocasio-Cortez founded a new think tank. They called it New Consensus. Since then, the group has done little public work beyond helping to formulate the Green New Deal. Its website has only four pages. But it has published a reading list written by Demond Drummer, its founder, that functions as a manifesto of sorts.

The list does not cite a single angry issue of Dissent or postmodern rant by Slavoj Žižek. Instead, it contains a bunch of self-described pragmatists: Vaclav Smil, a scientist who Bill Gates says is his favorite author; Brad DeLong, a UC Berkeley economics professor who served in Bill Clinton’s administration; Carlota Perez, a scholar who calls herself a “radical centrist”; and Mariana Mazzucato, an economist so mainstream that the Financial Times recently profiled her love of swimming.

Drummer says that the books lay out a new and coherent view of “how economic progress really happens.” Many of the books argue that wealthy countries became wealthy in the first place by supporting, protecting, and investing in strategic industries. A nation’s other policies—around trade, infrastructure, even education—were ultimately designed to serve these chosen industries. “A nation must deliberately and constantly invest in its means of making a living,” Drummer writes. “Nations that ‘[let] the free market decide’ what they should do for a living decline to the bottom of the economic food chain.”

No wealthy country developed without going through this process, the books argue—especially not the United States.

“From its very beginning, the United States again and again enacted policies to shift its economy onto a new growth direction—toward a new economic space of opportunity,” argues Concrete Economics, a book by Cohen and DeLong that appears on the reading list. “Yes, there was an ‘invisible hand’ … But the invisible hand was repeatedly lifted at the elbow by the government, and re-placed in a new position from where it could go on to perform its magic.”

Speaking from his office in New York, Cohen walked me through this retelling of American history. Hamilton sought to move the country away from its agrarian economy, so he fought for infrastructure, high tariffs, and a muscular financial system. After he died, his successors emphasized an “American system” of infrastructure projects such as the Erie Canal and the manufacturing of products from standardized parts. During and after the Civil War, the U.S. government freely gave away huge tracts of western land to spur specific types of economic development. In particular, rail companies got land to form the transcontinental railroad.

This industrial fervor extended well into the 20th century. When we think of large-scale industrial policy today, we think of the New Deal and World War II. But President Dwight D. Eisenhower, who built the interstate-highway system, encouraged mass production and suburbanization, and he preserved an enormous defense R&D budget. “Almost all of the technology we think of in terms of Silicon Valley and the like—computers, telecommunications, semiconductors—came directly out of that government R&D budget,” Cohen says.

Cohen and DeLong argue that our industrial pragmatism ceased in most sectors around 1980. They claim that policy makers grew too ideological: They read too much Friedman, deregulated the financial sector, and adopted a gospel of free trade. These actions allowed East Asian countries to overwhelm American manufacturing. In 1979, manufacturing made up 21 percent of U.S. GDP; by 2007, it had fallen to 12 percent.

The Green New Deal’s authors see their proposal as a remedy to this crisis. It is an attempt to bring back both U.S. manufacturing and the commonsense industrial policy that originally made that sector strong. “The economy, as it’s structured right now, is not working … and that’s not just because of the 1 percent, not just because of Wall Street,” Gunn-Wright told me. “We’ve stopped making things. We’ve stopped investing in the real economy.”

Saikat Chakrabarti, Ocasio-Cortez’s 33-year-old chief of staff and former campaign chair, has endorsed both the reading list and the thinking behind it. “Economics is a social system. It is not a science,” he tweeted in January, before linking to the New Consensus page. “To understand ‘basic economics,’ … you need to read economic history.” (Both Chakrabarti and Ocasio-Cortez’s office did not respond to an interview request before publication.)

Some mainstream economists aren’t as convinced that industrial policy could transform the future of the United States. Many of the ideas in the books have not been “closely vetted” theoretically and may lack empirical evidence, according to Michael Greenstone, an economics professor at the University of Chicago who previously worked in Barack Obama’s White House. And he worries that many of the books distract too much from a central lesson of labor economics: that people basically get paid for their skills. While granting that some recent data suggest that workers’ share of GDP is declining in developed countries, compared with that taken by investors and capital owners, he argues that unemployment and wage stagnation have been concentrated among those with fewer skills. In this view, education policy—not industrial policy—is primarily failing Americans.

Ocasio-Cortez has taken to saying that the Green New Deal is our generation’s moonshot, and this is usually understood as an invocation of John F. Kennedy–esque vigor: When America sets its mind to it, it can do anything. But in the context of New Consensus’ reading list, the moonshot reference reads as an allusion to another economic thinker—Mariana Mazzucato, the director of the University College London Institute for Innovation and Public Purpose. 

Mazzucato argues that the private sector cannot innovate without the public sector giving it purpose and direction. In fact, innovation depends on the state. First, the public sector defines a challenge. Then it asks—or demands—that the private sector address itself to that challenge. She cites the Apollo program as a perfect example.

“How to get to the moon was a result of 300 different homework problems that had to be solved, and most of them failed,” Mazzucato told me recently. The sheer difficulty of the Apollo program generated those problems, which ranged widely across sectors, touching even nutrition and fashion. After the challenge was set, the government used the inspirational power of its leadership and the extensive power of its purse to nudge companies, universities, and labs into identifying those problems and solving them.

Mazzucato asserts that the state should yoke the mission of fighting climate change to every aspect of its purchasing power. Whether the government buys a company’s product, offers it a research grant, or loans it money should depend on its willingness to adopt certain Green New Deal goals. “You don’t pick the winners; you pick the willing,” she said. “The question should be: Who’s willing to engage across any sector—big firms, small firms, any size—to engage with Green New Deal strategies?” These strategies might include a renewable-energy requirement or a reduction in the physical amount of material needed to make a product.

Mazzucato’s ideas are all over the Green New Deal. She has met with Ocasio-Cortez in person more than once; their staffs have consulted; they even Skyped together. Mazzucato has a fact page about the Green New Deal on her website. Yet Mazzucato is no radical. When we talked, she had just returned from Davos, and her books are more likely to be feted by the Financial Times than by Jacobin. “Mazzucato is a pretty mainstream, market-failure-correcting economist, in terms of industrial policy,” says Constantine Samaras, a professor of engineering at Carnegie Mellon University. So why has the Green New Deal been cast as such a radical proposal?

Look, and you’ll find Hamiltonian ideas served thickly throughout the Green New Deal resolution—even if they sometimes appear between slabs of progressive talking points. When the proposal lists “several related crises” that endanger the United States, it mentions “deindustrialization” as well as income inequality. It demands a “massive growth in clean manufacturing.” It calls for investment in “local and regional economies.” And it calls for “enacting and enforcing trade rules … and border adjustments” that will “grow domestic manufacturing in the United States.”

The Green New Deal’s wide-ranging vision faces down a politically inconvenient reality: Fighting climate change will mean remaking the economy. In the United States, most climate policies have focused on only the electricity or transportation sector. But those two sectors account for only 56 percent of U.S. greenhouse-gas emissions. Heavy industry accounts for almost a quarter of the country’s carbon pollution, and we still have little idea how to deal with that. There’s still no way to make steel without fossil fuels. The Green New Deal states as a goal—and little more than a goal—the need for “removing pollution and greenhouse gas emissions from manufacturing and industry as much as is technologically feasible.”

In fact, the entire document is just a list of goals. “What the resolution did is outline some challenges,” Samaras told me. “There’s no policy yet. These are just principles. I think that’s getting lost.”

Into that policy vacuum, many commentators have hallucinated an entire regime. “The government would put sector after sector under partial or complete federal control,” asserts David Brooks. He begs, “Exactly which agency would inspect and oversee the renovation of every building in America? Exactly which agency would hire every worker?”

This does not match what Ocasio-Cortez has actually said. Speaking with Chuck Todd earlier this month, she speculated about different ways to get the Green New Deal done. “It could be Tennessee Valley Authority–style public programs, but it could also be public-private partnerships,” she said. “It can work down on a municipal level. There could be some potential contracting involved … It’s not as though the federal government’s going to wave a wand and say, ‘We’re going to do it all ourselves.’ ”

A spike in government contracting? Public-private partnerships? What kind of fiat government takeover is this?

“Ocasio-Cortez is a socialist, and she wants worker collectives. But that distracts us from the core of the plan,” says Daniel Aldana Cohen, a sociologist at the University of Pennsylvania who helped edit coverage of the Green New Deal for Jacobin, a leftist magazine. “The original New Deal, when you read about it, is super practical. The biggest mistake is to see activist government … as ideological. It’s just a super practical approach to problem-solving. If you want to solve problems on a huge scale, then let’s actually put some public institutions to work.”

And arguments for the Green New Deal can even feel a little … Trumpy. When Gunn-Wright talks to people about the Green New Deal, “they get really excited about the thought of making stuff again,” she says. “That they’ll not just be a cashier, but that they’ll make wind turbines.” Gunn-Wright also riffed on the need to make wind turbines domestically (they’re too big to ship overseas), and why border adjustments may be required to protect some nascent U.S. green industries. (Trump actually imposed a tariff on solar panels in 2017.)

Viewed in a certain light, you can start to see the potential for a certain kind of play here: an attempt to integrate Trump’s working-class nostalgia with the urgency of remaking the economy to fight climate change. “Skilled crafts­men, and trades­people, and fac­to­ry work­ers have seen the jobs they loved shipped thou­sands of miles away,” the president has said. “This wave of glob­al­i­za­tion has wiped out our mid­dle class. It doesn’t have to be this way. We can turn it all around—and we can turn it around fast.” Would Green New Dealers really disagree with any of this?

Yet Ocasio-Cortez only ever approaches that rhetoric at a slant. “Today is a big day for people who have been left behind,” she said when announcing the Green New Deal. “Today is a big day for workers in Appalachia. Today is a big day for children that have been breathing dirty air in the South Bronx.” She referred to her proposal not as a plan to resuscitate American industry, but as a “comprehensive agenda of economic, social, and racial justice.”

“This is an investment,” she said. “For every dollar we spend on infrastructure, we get more than a dollar back for that investment.”

That’s weak, compared with the ambition wound up inside her own proposal. Investment and infrastructure are such Normal Democrat Words that they lose the special nostalgic charge of industrial policy. No wonder the Green New Deal was understood as a wish list, even by its supporters. Not that Ocasio-Cortez helped her case here either: On the day of the announcement, her office published, then retracted, a sometimes juvenile FAQ document that talked about farting cows and supporting people “unwilling to work.”

Gunn-Wright told me that her team doesn’t talk about the Green New Deal as industrial policy first, because people misunderstand it. Trump’s economic message is linked to his racist rhetoric, perhaps irretrievably so. Say the word manufacturing, and people hear a paean to the white working class. “We haven’t talked about the decline of manufacturing outside of cultural terms,” she said. “It’s really weaponized in terms of race. That also makes people back away from it.”

And it is legitimately tricky to talk about the history of U.S. industrial policy, especially on the left. Sure, the government has guided the invisible hand throughout American economic history—but it has also guided the bayonet and the lash. In the 1790s, Hamilton’s prized financial system counted enslaved bodies as a type of commodity, alongside cotton and wheat. In the 1860s, the government had western land to “freely” give away because it violently seized it from indigenous people first. In the 1950s, suburbanization enriched America, but it did not enrich black Americans, who were systematically prevented from obtaining federal-backed mortgages. Much of the Green New Deal’s racial-justice agenda reads as an attempt to deal with this legacy—and to ensure that people of color are not left out of the next great redirection of the American economy. Hence the policies aimed at spreading the wealth: the paid medical leave, the job guarantee, the promise to honor tribal treaties.

But the sum effect has been that Ocasio-Cortez and her team shout about equity while whispering about the economy. If the word manufacturing is now a racial dog whistle, who better than a popular leftist congresswoman to reclaim its whine? It may be too much to hope for a cross-partisan climate policy in the United States, but every climate policy must have some kind of crossover appeal. The U.S. economy will eventually be remade to fight climate change. Ocasio-Cortez and her team must decide whether they will lean into their policy’s promise or make it seem like more of the same. 



The planets may get top billing in the solar system, but they are far outnumbered by the moons. There are hundreds, and they come in all kinds of varieties, like a cosmic tray of assorted chocolates. Our own moon is a barren, rocky world coated with craters. Enceladus, of Saturn, and Europa, of Jupiter, are frozen, shrouded in a thick layer of ice with a liquid-ocean center. Io, another moon of Jupiter, is molten, its surface constantly redrawn by flowing lava.

Astronomers have observed these and other moons for centuries, first with homemade telescopes and now with million-dollar spacecraft. Many moons are well studied, their features documented in astounding detail. They feel as familiar as the planets they orbit. But there is still more to discover.

In 2013, astronomers found something new around Neptune, in a manner that would make Marie Kondo proud. Mark Showalter, a scientist at the SETI Institute, noticed a mysterious white dot in observations of Neptune taken by the Hubble Space Telescope, NASA’s best eyes on the solar system and beyond. To investigate, he dove into a cache of photographs, five years’ worth, examining each one to see if it had that spark of intrigue. The dot showed up time and time again. It was a moon.

Now the moon has a formal name: Hippocamp, after the mythological sea creatures that galloped alongside the Roman god Neptune.

Hippocamp is one of 14 moons orbiting Neptune. Showalter and his colleagues reported new observations of the moon, published Wednesday in Nature, that provide a better measure of its size and orbit. At 21 miles, or 34 kilometers, across, Hippocamp is about the size of a metropolitan city and the smallest of Neptune’s moons. It orbits close to its moon sibling Proteus, another Neptunian moon, and completes one trip around Neptune about every 23 hours.

The astronomers suspect that Hippocamp formed as some other moons in the solar system did, including ours—through a violent collision. The team believes that the moon is a chunk of Proteus that broke off after a comet struck.

So where does Hippocamp fit among the diverse assortment of moons in the solar system? That’s up to the imagination. The moon is too far from Earth to tell; scientists have said that Hippocamp is roughly 100 million times fainter than the faintest star that is visible to the naked eye. Even to Hubble, an extremely powerful instrument, the moon appears as a fuzzy dot in photographs.

The moon christening is another milestone in the centuries-long study of Neptune’s moons, which bear the names of mythological figures. The first and largest, Triton, was found less than three weeks after Neptune itself was discovered, in 1846. More than a century would pass until the next moon, Nereid, was detected, in 1949. The rest were discovered in the past 40 years or so, via powerful ground-based telescopes and the Voyager mission, the vaunted NASA program that launched two probes on a tour of the solar system’s farthest planes. Voyager 2 spotted six small moons orbiting close to Neptune in 1989. Hippocamp orbits there, too, but the spacecraft missed it.

Other moons are likely lurking out there, waiting to be found. Astronomers certainly have a more intimate understanding of our cosmic home than they did centuries ago. But they are still finding new neighbors. Last summer, astronomers announced the addition of 10 new moons around Jupiter, bringing its total to 79, the most in the solar system. Like Hippocamp, the objects appear as tiny glints of light in telescope observations. The smallest was about half a mile wide. Their names are still being considered, and will be approved by the International Astronomical Union’s Minor Planet Center, the organization in charge of confirming such discoveries.

The search for new moons extends beyond the solar system, to other stars and planets. Moons are not exclusive to our own. The universe may be swimming with them. Astronomers think they may have already found their first exomoon, as they’re called, orbiting a planet about 8,000 light-years away from Earth.

At that distance, the moon doesn’t show up in telescope images at all; it is seen instead in the slight wobble of the planet it orbits, tugging at it as it goes. Its discoverers believe that it isn’t a rocky or icy world like the moons we’re used to, but a massive, swirling ball of gas about the size of Neptune. The menagerie of moons in our solar system is rich and wondrous, but it’s only a taste of what else is out there.



The most distant object that NASA has ever investigated up close, 2014 MU69, orbits near the edge of the solar system, well beyond Pluto. Because of the desolate conditions out there, it’s remained virtually unchanged since the beginning of the solar system. Less than five years ago, astronomers didn’t even know it existed. Now they know what it looks like, thanks to images captured by a passing spacecraft.

The New Horizons spacecraft arrived at 2014 MU69—4 billion miles away from Earth—on New Year’s Eve, snapped hundreds of photographs, and then continued on, headed even deeper into space. On Wednesday, NASA released the first set of photographs.

Seen from Earth, 2014 MU69 looks like a tiny speck of light. Up close, it resembles, delightfully, a snowman.

2014 MU69 is so far away, details like this could never come into focus from Earth.“There’s no way to make anything like this, this type of observation, without having a spacecraft there,” Cathy Olkin, the deputy project scientist, told reporters at a press conference on Wednesday.

In 2015, New Horizons flew past Pluto and revealed a stunning icy world with towering mountains, smooth plains, and a feathery atmosphere. The probe had enough fuel to keep going after the encounter, and 2014 MU69 turned out to be along its path.

Nicknamed Ultima Thule, Latin for “beyond the known world,” the object is a contact binary, a cosmic configuration in which two separate objects become joined together. “They obviously came together at such a gentle speed—maybe a mile an hour, or a few miles an hour,” said Jeff Moore, the head of the geology team for New Horizons. “They really are sort of resting on each other.”

The snowman description is fitting for the conditions in the Kuiper Belt, where frozen bits and pieces left over from the formation of the solar system 4.6 billion years ago abound, receiving very little sunlight. It’s an incredibly cold place: The surface temperature of Pluto, the largest object in the region, is nearly –400 degrees Fahrenheit. If you could somehow build Frosty the Snowman out there, he’d last forever.

Unlike typical snowmen, Ultima Thule is red, roasted and darkened over time by cosmic radiation. Below, the photo on the right is a composite image from two of the three cameras aboard New Horizons. (The color looks more like iced coffee with a little half-and-half to me, but by planetary-science measures, it’s red.)

There’s more than one kind of ice in the universe, and the flyby data haven’t yet revealed the composition of Ultima Thule. The object may be made of water ice, nitrogen ice, or methane ice.

Ultima Thule is frozen another way—in time. The frigidness of the Kuiper Belt has kept Ultima Thule in pristine shape. The New Horizons data will describe the very material that shaped Earth and the other planets, and scientists hope the spacecraft’s scientific instruments collected some new information about this chapter in our cosmic history.

The newly released images are the first of many still to come. These were taken about a half hour before New Horizons made its closest approach to Ultima Thule, and at a moment when sunlight struck the object head-on. As the spacecraft flew past, the illumination shifted, and shadows emerged. It’s these shadows, scientists say, that will soon reveal whether Ultima Thule has hills, ridges, or craters.

It takes some time for data from New Horizons to reach Earth from a distance of 4 billion miles. Scientists will reveal the best, highest-resolution photographs in the coming weeks and months.

An uncomfortable question, unrelated to the science, hovered over the New Horizons team’s presentation on Wednesday. On Tuesday night, a Newsweek story from March prompted discussion on social media about NASA’s decision to use the name Ultima Thule, which arose out of a public naming contest. The term was coined more than 2,000 years ago by the Roman poet Virgil and has appeared frequently in literature as a descriptor for distant, mythical lands. Newsweek pointed out that the term was also adopted by the Nazi party as the name of a mythical Aryan homeland.

NASA officials were aware of this historical usage when they chose Ultima Thule and decided its ancient meaning outweighed the troubling connotations. “I think New Horizons is an example, one of the best examples, in our time of raw exploration, and the term Ultima Thule—which is very old, many centuries old, possibly over 1,000 years old—is a wonderful meme for exploration,” Alan Stern, the lead investigator of the New Horizons mission, said in response to a question from a reporter. “And that’s why we chose it. And I would say that just because some bad guys once liked the term, we’re not going to let them hijack it.”

But this shadow couldn’t dampen the jubilance in the room as the scientists shared the shape of their new discovery. To anyone used to the smooth, rounded architecture of planets and moons, this distant world might look funky. But the solar system is flush with oddly shaped clumps that don’t fit into neat schemes.

Billions of years ago, some of the material hurtling around the sun began to collide together. The gentler collisions allowed clumps of material to grow with each merger. Small clumps led to big clumps, and if they grew large enough, gravity tugged at their edges and collapsed them into spheres. Ultima Thule, about the size of a city, is too small for this effect.

“Most of the small bodies in the solar system are highly elongated,” Hal Weaver, the New Horizons project scientist, explained recently. “They just don’t have enough mass to form themselves into a perfect sphere.”

New Horizons is now headed deeper into the Kuiper Belt. The spacecraft left Earth in 2006 and, despite a few malfunctions along the way, remains healthy. Stern predicts it could keep going for another 15 to 20 years and plans to submit a new exploration proposal to NASA leadership. With Ultima Thule in the rearview, the spacecraft may set its sights on another target, prepared to extend humanity’s reach into the cosmos even further.



A peacock’s tail is so ostentatious that you could easily miss other parts of its anatomy that, on any other bird, would be unmissable. On the heads of both male and female peafowl, there’s a crest of stiff, spatula-like feathers that resemble the helmet of a Roman centurion. It’s a flamboyant, standout trait that, under the circumstances, is just another decoration among many equally eye-catching ones.

But Suzanne Amador Kane, a physicist from Haverford College, has found that the crest is much more than a mere adornment. It’s also a sensor. Its feathers are tuned to vibrate at the exact same frequencies at which a displaying peacock rattles his tail. When a male shows off his trademark fan, the female he’s courting doesn’t just see him. She also feels him, in her head.

When Kane’s collaborator Roslyn Dakin first studied peafowl crests in 2011, she thought they might act as a signal. By looking at their length, thickness, or color, other peafowl could potentially judge the health or attractiveness of potential mates. But when Dakin analyzed the crests, she found that they’re not varied enough to be a reliable signal. “We couldn’t figure out a function for them,” says Kane.

Then they heard about the auklets.

Auklets are bizarre, puffin-like seabirds that nest in huge colonies, sound like trumpets, and smell like tangerines. Their heads are topped with striking, forward-facing ponytails that scientists had long seen as sexual ornaments: The bigger the crest, the sexier the auklet. But in 2010, Sampath Seneviratne and Ian Jones showed that the crests also act like a rat’s whiskers. The auklets use them to sense the walls of the rocky crevices in which they nest; when Seneviratne and Jones taped down these feathers, the birds were more likely to bonk their heads.

After Kane read about this discovery, “the next time I looked at peafowl crests, I saw them very differently,” she says. Peafowl don’t live in rocky crevices, so their crests are clearly not collision detectors. But perhaps, Kane reasoned, they could be vibration­ detectors. When male peacocks fan out their tails, they also shake them at high speeds—about 26 times a second. This creates a stunning visual illusion in which their eyespots seem to hover against a shimmering background. It also creates a rattling noise, and a wave of pressure that could conceivably vibrate the crest of a watching female.

To test this idea, Kane and her colleague Daniel Van Beveren acquired several peafowl crests from online vendors and zoos. “A lot of the specimens I got in very strange ways,” says Kane. “One bird was a zoo peacock that had the bad luck to fly into the polar-bear enclosure.”

On closer inspection, the team found that the crest has the right equipment to act as a sensor. At the base of each plume, there’s a tiny companion feather called a filoplume. These are also found in other birds, and they’re known to be mechanical sensors: Something shakes the big feather, the big feather nudges the filoplume, and the filoplume triggers a nerve cell.

Next, the team mounted the crests on mechanical shakers and showed that the constituent feathers resonate when shaken 26 times a second—the exact frequency at which displaying peacocks shake their tail feathers. Only the crest feathers behave like this; when the team tested feathers from other peafowl body parts, or from other big-crested birds, none of them resonated at that precise frequency.

Kane was astonished. “Something the length of a peacock tail feather should have a much different resonant frequency to these tiny crest feathers,” she says. “It’s as if you had a bass that sounded like a violin. It just can’t be a coincidence.”

As a final test of the sensor hypothesis, the team used speakers to play various noises at the crest feathers. White noise did nothing. Pop songs, such as “Staying Alive” by the Bee Gees, had little effect. But a recording of an actual peacock’s tail-rattle made them vibrate.

“The study is rigorous,” says Gail Patricelli, an evolutionary biologist from the University of California at Davis, but “there is still a great deal we don’t know.” For example, “given that peafowl have ears that can hear across a wide range of frequencies, what’s the advantage of having this extra low-frequency channel for communication? Perhaps males and females use it as a private channel that doesn’t attract the attention of predators.”

If that’s the case, “what are they saying to each other?” Patricelli adds. “I’m big and healthy? I’m sexy? Or both? I’m imagining that males who are able to cause the feathers on a female’s head to literally vibrate may have had a significant advantage in sexiness!”

And don’t forget the peahens, says Kane. “There’s a long-standing idea males are the ones who are communicating, but if you actually observe them, the females frequently do these displays to each other, to the males, and to their young,” she says. “They could be taking part in the mating displays. Or issuing threats. Or encouraging the young to do mating displays.”

To better understand the significance of these vibrations, Kane wants to film the crests of living peafowl to see if they actually shake in response to each other’s displays. That’s easier said than done, since both the displaying bird and the watching one move around a lot during courtship. To begin, the team might blindfold peafowl to see whether they react to waves of air that mimic a rattling tail. They could also change the crest’s resonant frequency by stiffening it with varnish, then see whether a peafowl reacts differently to a tail display.

Kane also wants to study other birds, whose larger crests might be easier for a camera to follow. At least 35 candidate species have flexible crests and some kind of shaking display. These include the secretary bird (a “ninja eagle on stilts”), the Victoria crowned pigeon (a giant blue dove with a feather-duster head), the Himalayan monal (an acid-trip pheasant), and the hoatzin (a prehistoric-looking punk rocker that smells of cow dung). Perhaps these species, though already dramatic and eye-catching, are also walking around with secret sense organs, hidden in plain sight.



In 2014, 23andMe tests revealed a decades-old secret in Indianapolis: A local fertility doctor named Donald Cline had secretly used his own sperm to impregnate his patients in the ’70s and ’80s. As the popularity of DNA tests grew over the next few years, so did the count of his known biological children. They now number more than 50. And they have all learned—to their surprise—that no law in Indiana specifically prohibited Cline from using his own sperm in patients.  

On Sunday, Indiana’s governor signed the first such law in the country. “Indiana’s taking a stance—that behavior is not appropriate,” says Matt White, who discovered that he was Cline’s biological child in 2016. White’s mother, Liz, had gone to Cline for infertility treatment, using what she thought was an anonymous sperm donor in the 1980s. The Whites, along with several of Matt’s newfound half siblings, initiated the push for the new Indiana fertility-fraud law. (I wrote about their story in the April issue of The Atlantic.)

Cline’s case is just one of several uncovered in this new era of DNA testing. In Texas, after finding out her biological father is her mother’s fertility doctor, a woman named Eve Wiley is advocating for a bill that would make a doctor’s using his own sperm criminal sexual assault. The bill has passed the state Senate. There are also ongoing lawsuits in Idaho, Vermont, California, Canada, and the Netherlands, all brought by former patients or their children against doctors accused of using their own sperm.

One genealogist told me she has seen so many cases of fertility doctors secretly acting as donors  that “when I see these large groups of half siblings, it’s actually the first thing I think about now.” Not all of the patients or their children are angry with the doctors, but those who are have had to contend with the question of what exactly the doctors did wrong, legally speaking.

In the 1990s, federal prosecutors pursued a case against Cecil B. Jacobson, a fertility doctor in Virginia also accused of using his sperm to artificially inseminate his patients. Prosecutors allege that he fathered as many as 75 children this way, but they could not prosecute him for doing so. “However morally questionable those actions are,” wrote The New York Times in 1992, “there are no laws prohibiting a doctor from donating sperm to a patient or impregnating an unwitting woman with his sperm.” Jacobson was ultimately convicted of 52 counts of perjury and fraud, including mail fraud for bills he sent to patients he deceived and wire fraud for phone calls to them.

When local prosecutors looked into Cline’s case 20 years later, they found no Indiana laws that prohibited the secret use of a doctor’s own sperm either. And because it all happened more than 30 years ago, they had no records. “If it happened today,” the prosecutor on Cline’s case told me, “I think there would be opportunities to pursue theories of prosecution that didn't exist here.” Ultimately, Cline was charged with two counts of felony obstruction of justice, for letters he had sent denying the allegations when he was first informed of an investigation. The doctor, who was already retired, lost his medical license and was fined $500.

White felt that Cline got little more than “a slap on the wrist.” When I met him, his mother, and several of his half siblings in Indianapolis last fall, they were busy writing letters and meeting with state legislators. White sent me regular emails about new hearings and new co-sponsors  throughout the winter. The bill, now signed into law, makes fertility fraud a felony, but the criminal determination will not apply to Cline retroactively. However, the bill does allow patients, their spouses, and their children to sue in civil court. “We got this law to protect people more so going forward into the future,” White says, but he is also open to pursuing additional actions against Cline in civil court.

The state of California has a general fertility-fraud law, but Indiana’s is the first law to single out fertility doctors using their own reproductive material. “It has huge symbolic value,” says Jody Madeira, a law professor at Indiana University who advocated for the legislation. She told me several more people—in fertility-doctor cases that have not yet become public—have contacted her to ask about pursuing legal action.



Give us your DNA. Help catch a criminal. That’s the message of a recent ad from the genetic-testing company FamilyTreeDNA. The video stars Ed Smart, whose daughter Elizabeth Smart was abducted at age 14, exhorting viewers to upload their DNA profiles to the company’s website.

Not so long ago, DNA-testing companies were known only for their promise to unlock medical secrets or trace family histories. What’s changed is the arrest of the alleged Golden State Killer. Since police tracked down a suspect in the notorious case by uploading crime-scene DNA and finding distant relatives on a genealogy website, the same technique has led to dozens more arrests for rapes and murders. Forensic genealogy has become, if not exactly routine, very much normalized.

The Ed Smart ad is, implicitly, an argument that consumer DNA databases should be used for law enforcement. FamilyTreeDNA came under fire in January when BuzzFeed News revealed that the company had been quietly working with the FBI. FamilyTreeDNA sells at-home DNA test kits, but it also allows people to upload genetic profiles from competitors such as 23andMe and AncestryDNA to its website. In late 2018, the company’s CEO later told Forensic Magazine, it discovered that the FBI was trying to upload genetic profiles from crime scenes. Rather than fighting the FBI, FamilyTreeDNA changed its terms of service to allow law-enforcement use in cases of “violent crimes”—without notifying its customers, until BuzzFeed News started asking.

Genealogists were shocked that FamilyTreeDNA would keep this secret. (Investigators in the Golden State Killer case and others had used the same methods with another genealogy database, called GEDmatch, which became aware of their involvement at the same time as the public.) But on the underlying question of law enforcement using genealogy databases at all, genealogists have had fewer qualms. A poll of 639 genealogists by Maurice Gleeson last year found that 85 percent were “reasonably comfortable” with law enforcement using GEDmatch to identify serial rapists and killers. And in October, bioethicists at Baylor College of Medicine published the results of a more generalized survey: Of the 1,587 respondents, 91 percent supported forensic genealogy for violent crimes, and 46 percent for nonviolent crimes.

So instead of backing off, FamilyTreeDNA appears to have leaned into the controversy. (The company did not immediately respond to a request for comment.) While other major players in DNA testing, such as 23andMe, AncestryDNA, and MyHeritage, have resisted law enforcement, FamilyTreeDNA now allows investigators to upload the suspect’s DNA profiles to find potential relatives. Their access to full DNA profiles of everyone in the database is restricted, though, and customers can opt out of law-enforcement matching. Forensic Magazine reports that less than 1 percent of U.S. customers chose to opt out after one week. GEDmatch did not see an exodus of users after the Golden State Killer case either.

Americans, it seems, are not that concerned about sending a relative to prison. In most cases, the suspect’s DNA profile will match only distant relatives, such as second or third or fourth cousins, who might not even know each other. (A distant-relative match, in combination with social media and public records, can be enough to ultimately ID the suspect.) A woman in Washington State recently found out her DNA on GEDmatch had led to the arrest of her second cousin twice removed for murder in Iowa. Before she shared her DNA, her brother had worried about getting a family member arrested. But now, she told The Gazette of Cedar Rapids, “I feel OK about it … I want someone to have to do time if [he/she] did something like that. I don’t regret it now.” She had never met and did not know the man arrested.

Christi Guerrini, an ethicist at Baylor who co-authored the October survey, told me she had been surprised to see such high support for law-enforcement use of genetic genealogy. The survey is prefaced by a description of the Golden State Killer, and she acknowledged that mentioning such a “notorious” case could bias respondents.

On the other hand, that is exactly how the American public as a whole was introduced to forensic genealogy. Genealogists told me they feared a public backlash to other possible test cases—such as identifying a baby abandoned by his mother. Arresting a suspected serial killer who murdered at least 13 people and raped at least 50 made the technique a much easier sell.

Erin Murphy, a law professor at NYU, says it’s common to see new, potentially controversial forensic techniques tested in cases that will bring out the most public sympathy. She points to the example of law enforcement building their own DNA databases in the 1990s, which have expanded considerably in scope since then. “DNA databases did not start with collecting DNA from people at traffic stops,” she says. “They started with collecting DNA from repeat sexual offenders and people convicted of serious crimes.” Now some local police departments are using “stop and spit” to build largely unregulated DNA databases.

The victims in the cases solved by genetic genealogy are often very young, often female, and often white. There are practical reasons for this: The victims of rapists who left behind their DNA are likely to be women. The people in genealogy databases are disproportionately white. And the forensic genealogy work can run thousands of dollars, so law enforcement is submitting cases deemed the highest priority. This means that law-enforcement use of genealogy is being sold to us with the victims who arouse the most attention in the media and among the public.

That’s true of the victims of the Golden State Killer, who terrorized California suburbs. It’s also true of Elizabeth Smart, whose blond-haired, blue-eyed face was all over the news before and after she was found in 2003. These are the cases, perhaps, easiest for Americans to get behind—even if it means giving up a measure of privacy.



In 2010, when Lilli Holst scraped a lump of soil from the underside of a rotting eggplant, she had no idea that this act would help to save the life of a British teenager, eight years later and 6,000 miles away.

Holst, an undergraduate at the University of KwaZulu-Natal, in South Africa, was participating in a project in which students search through local soil samples for new phages—viruses that infect and kill bacteria. Holst found several, and gave them all names. In a worm farm, she discovered Liefie. In an aloe garden, Lixy. And from that decaying eggplant, Muddy. All three viruses infect a common bacterium called Mycobacterium smegmatis. And all of them were new to science.

Samples of Muddy and the other phage viruses made their way to the lab of Graham Hatfull, a phage expert at the University of Pittsburgh. He stored them in a freezer, along with at least 10,000 others that had also been discovered and named by students: Mariokart, TGIPhriday, Chupacabra, Benvolio, ChickenNugget, IAmGroot, and more. They were sitting there, in the cold, when in late 2017 Hatfull got a call from doctors at Great Ormond Street Hospital, in London.

The London team, led by the pediatrician Helen Spencer, had been treating a 15-year-old girl with cystic fibrosis—a genetic disorder that leads to persistent lung infections. To prepare for a double lung transplant, the girl had been taking drugs to suppress her immune system, and these allowed an already present microbe called Mycobacterium abscessus to run amok through her body. She had new lungs, but also heavy infections in her liver, limbs, buttocks, and torso, and in the surgical wound on her chest. Antibiotics weren’t working, and the outlook was grim. The team put her on a palliative-care plan.

But Hatfull has spent decades studying phages that attack mycobacteria, the group to which the girl’s life-threatening microbes belonged. Her doctors wanted to know whether he had anything in his arsenal that might kill those particular strains. He looked in his database—and found Muddy.

In laboratory tests, Muddy efficiently destroyed the exact strain of M. abscessus that was itself destroying the London patient’s body. “It was good that we found one,” Hatfull says. “But it was bad that we only found one,” because bacteria can easily evolve to resist any single phage.

His team eventually found two more phages— BPs and ZoeJ—that had the potential to kill M. abscessus, but weren’t doing it very well. Some phages kill the bacteria they infect by reproducing frantically and bursting out in fatal fashion, but others opt for a more tranquil existence of harmlessly hiding in their hosts. BPs and ZoeJ naturally go for the latter path, so Hatfull’s team modified them by deleting the gene that keeps them peaceful. Unrestrained, these modified microbes could kill M. abscessus as well as Muddy.

Last June, the London team started injecting all three phages—one natural and two modified—into the patient. She didn’t experience any major side effects, and after a month of twice-daily doses, the infection in her chest began to disappear. Shortly after, her liver cleared up. After six months, almost all the other lesions had faded. “It’s not like she’s out of the woods, in the sense that she has cystic fibrosis and a new set of lungs,” Hatfull says, “but she’s in very good general health.”

As with any single case of medical success, it is impossible to truly know whether the supposed treatment was what eventually saved the patient: That’s why doctors run clinical trials. But Benjamin Chan of Yale University says that this “fantastic” study “very nicely shows a probable impact of the phages.” After all, the patient’s infections clearly weren’t going away on their own, and they weren’t responding to other treatments.

Phages were commonly used to treat infections in the 1920s, and though they’re still used in Russia and parts of eastern Europe, they largely fell out of favor in the West. But they’ve stepped back into the limelight after a growing line of dramatic success stories. The most famous case involves Steffanie Strathdee, an epidemiologist who led the hunt for phages that ultimately cured her husband, Tom Patterson, of a life-threatening infection. Such successes have prompted a renewed interest in phage therapy, especially in the era of antibiotic-resistant superbugs.

The London patient’s case is a milestone—she is the first person to be treated with phages that have been genetically engineered. “It requires trust to take a leap off the edge into completely unknown medicine,” says Hatfull, who appreciates that many people might be unnerved by his team’s work. “The idea of using a virus in the first place is challenging, let alone messing around with it,” he acknowledges.

He clarifies that his team simply deleted a gene that both BPs and ZoeJ would switch off naturally, when they eventually decide to flip from passive stowaways to active killers. The team also didn’t add any genes from other organisms into the phages—an important distinction, which meant that, under UK and European Union regulations, the viruses didn’t count as genetically modified organisms.

This case also represents a second milestone: It’s the first time phages have successfully treated a mycobacterial infection in a human. That’s huge. These microbes include the one that causes tuberculosis. They also include a group of more than 100 species called the NTMs, which often hit people with cystic fibrosis. M. abscessus and other opportunistic germs belong to this group.“Treating NTMs is a big deal,” Chan says. “It’s a very unmet need in the cystic-fibrosis community.”

But Muddy, ZoeJ, and BPs aren’t cure-alls for these infections. M. abscessus is incredibly diverse, and a phage that kills one strain might do nothing against another. The London team learned that the hard way. It treated a second young girl with cystic fibrosis, who also had a double lung transplant, and who came down with a different strain of M. abscessus. And against that strain, Hatfull struggled to find any effective phages, despite his extensive collection. By the time he identified one, it was too late. The second patient had died.

To reliably treat any given NTM infection, scientists will need much larger phage libraries. “That’s not the case for many other bacteria, like E. coli or Staphylococcus aureus, where strains are more broadly susceptible to commonly isolated phages,” Chan says.

But even in those cases, it’s time-consuming to identify, grow, and perhaps even modify the right virus for every single case. “The challenge is whether you could ever make phage therapy broad enough so you could have an off-the-shelf set at your disposal, which you knew could infect any strain that was out there,” Hatfull says. He doubts that’s possible for M. abscessus, or indeed for most infections. That’s probably why at least one trial, in which doctors tested the same cocktail of 12 phages in patients with infected burn wounds, was a bust.

“For the many infections where you have this great variability, it’s going to be hard to figure out how to get phages to span it all,” he says. And without that consistency, it might also be hard for phages to get significant investments from pharmaceutical companies, and to go from the stuff of individual miracles to the stuff of generalized medicine.



We humans have always experienced an odd—and oddly deep—connection between the mental worlds and physical worlds we inhabit, especially when it comes to memory. We’re good at remembering landmarks and settings, and if we give our memories a location for context, hanging on to them becomes easier. To remember long speeches, ancient Greek and Roman orators imagined wandering through “memory palaces” full of reminders. Modern memory-contest champions still use that technique to “place” long lists of numbers, names, and other pieces of information.

As the philosopher Immanuel Kant put it, the concept of space serves as the organizing principle by which we perceive and interpret the world, even in abstract ways. “Our language is riddled with spatial metaphors for reasoning, and for memory in general,” says Kim Stachenfeld, a neuroscientist at the British artificial-intelligence company DeepMind.

In the past few decades, research has shown that for at least two of our faculties—memory and navigation—those metaphors might have a physical basis in the brain. A small seahorse-shaped structure, the hippocampus, is essential to both those functions, and evidence has started to suggest that the same coding scheme—a grid-based form of representation—might underlie them. Recent insights have prompted some researchers to propose that this coding scheme can help us navigate other kinds of information, including sights, sounds, and abstract concepts. The most ambitious suggestions even venture that these grid codes could be the key to understanding how the brain processes all details of general knowledge, perception, and memory.

On September 1, 1953, Henry Molaison, a 27-year-old man the world would come to know as “Patient H.M.,” went under the knife in a risky, experimental bid to cure a debilitating case of epilepsy. A neurosurgeon removed the hippocampus and surrounding tissues from deep within H.M.’s brain, alleviating some of his seizures but inadvertently leaving him a permanent amnesiac. Until his death more than half a century later, H.M. couldn’t encode new memories: not what he’d had for breakfast, nor the most recent news headline, nor the identity of the stranger he’d been introduced to just a few minutes earlier.

H.M.’s story, though tragic, revolutionized scientists’ understanding of the role the hippocampus plays in how the brain organizes memory.

Years later, another hippocampus-centered revolution transpired and earned its pioneers a Nobel Prize: the discoveries, decades apart, of two types of cells, which made it clear that the hippocampal region’s fundamental functions included not just memory, but also navigation and the representation of two-dimensional spaces.

The first of these discoveries came in 1971, when researchers uncovered “place cells,” which essentially fire to indicate one’s current location. John O’Keefe, a neuroscientist at University College London, and his colleagues monitored the brain activity of freely roaming rats and observed that some of their neurons fired only when they were in specific parts of their cages. Some became active as a rat sniffed around, say, its enclosure’s northeast corner, but otherwise remained quiet; others fired in the cage’s center. That is, the cells encoded a sense of place (“you are here”)—and together, they created a map of the entire space. (When the rat was put in a different cage or room, these place cells “remapped,” encoding different local positions.)

These findings inspired the proposal that the hippocampus might be creating and storing “cognitive maps” (an idea first put forth by the psychologist Edward Tolman in the 1940s to explain how rats could suss out new shortcuts to rewards in mazes) beyond spatial ones. At the very least, the hippocampus seemed like a promising place to start looking for hints of such maps.

That work eventually led a then-married pair of scientists at the Norwegian University of Science and Technology, May-Britt Moser and Edvard Moser, to direct their attention to the entorhinal cortex, located just next door to the hippocampus. The region provides major inputs to the hippocampus—and is also one of the first areas of the brain to deteriorate in Alzheimer’s disease, which affects both navigation and memory. There, the researchers found what they called “grid cells,” which experts now think might be the most compelling candidate for cognitive mapmaker.

Unlike the place cells, grid cells do not represent particular locations. Instead, they form a coordinate system that’s independent of location. (As a result, they’re popularly known as the brain’s GPS.) Each grid cell fires at regularly spaced positions, which form a hexagonal pattern. Imagine the floor of your bedroom is tiled with regular hexagons, all the same size, and each hexagon is divided into six equilateral triangles. As you walk across the room, one of your grid cells fires every time you reach a vertex of any of those triangles.

Different sets of grid cells form different grids: grids with larger or smaller hexagons, grids oriented in other directions, grids offset from one another. Together, the grid cells map every spatial position in an environment, and any particular location is represented by a unique combination of grid cells’ firing patterns. The single point where various grids overlap tells the brain where the body must be.

This kind of grid network, or code, constructs a more intrinsic sense of space than the place cells do. While place cells provide a good means of navigating where there are landmarks and other meaningful locations to provide spatial information, grid cells provide a good means of navigating in the absence of such external cues. In fact, researchers think that grid cells are responsible for what’s known as path integration, the process by which a person can keep track of where she is in space—how far she has traveled from some starting point, and in which direction—while, say, blindfolded.

“The idea is that the grid code could therefore be some sort of metric or coordinate system,” says Jacob Bellmund, a cognitive neuroscientist affiliated with the Max Planck Institute in Leipzig and the Kavli Institute for Systems Neuroscience in Norway. “You can basically measure distances with this kind of code.” Moreover, because of how it works, that coding scheme can uniquely and efficiently represent a lot of information.

And not just that: Because the grid network is based on relative relations, it could, at least in theory, represent not only a lot of information but a lot of different types of information, too. “What the grid cell captures is the dynamic instantiation of the most stable solution of physics,” says György Buzsáki, a neuroscientist at New York University’s School of Medicine: “the hexagon.” Perhaps nature arrived at just such a solution to enable the brain to represent, using grid cells, any structured relationship, from maps of word meanings to maps of future plans.

“We’ve been thinking about how the hippocampus and entorhinal cortex machinery could have a more general purpose,” Stachenfeld says. “It’s a really powerful idea, that you can have a [grid cell] representation of structure in general, and apply it more rapidly to new situations.” That, in turn, would allow one “to behave more efficiently, to learn a lot faster.”

Because researchers usually could not take direct measurements of individual neurons in their test subjects, they had to get clever with their methodology. In 2010, for instance, neuroscientists figured out a certain kind of signal to look for in functional magnetic resonance imaging (fMRI) scans of the brain as an indirect signature of grid cell activity. This “hexadirectional” signal emerges in subjects navigating a virtual environment. As it turns out, it also characterizes other tasks, some spatial, some not so much.

One of the earliest examples came with behavior that fell somewhere between the two: the navigation of visual space. When monkeys, with their heads fixed in place, tracked images with just their eyes, researchers found evidence of grid cell activity in the entorhinal cortex. More recent work in humans has uncovered the same hexadirectional signature, and some experiments have even pinpointed other, more direct properties of the grid code already observed in physical navigation tasks.

Similar principles might also guide how the brain encodes time. The hippocampus has already been found to contain place cells that also behave as “time cell” neurons in certain situations, activating to indicate successive moments in time (rather than successive positions in space). Rats would run through a maze, in which one section involved trotting in place on a wheel or treadmill for some predetermined number of seconds before continuing onward. During the interval when the rats ran in place, their actual location held constant, but cells fired in their hippocampus to track their temporal progression: Some neurons were active for the first few seconds, others for the next few, and so on. The finding “brings time as a different dimension into the equation,” Bellmund says.

More recently, work published in Nature last summer turned up evidence for a coding system that uniquely represents time in the context of memories or experiences. A team of researchers, led by the Mosers, uncovered a coding scheme for time that spanned multiple scales, from seconds to hours. Although no explicit link has yet been drawn between temporal organization and grid cells, scientists have seen hints of a connection: Grid cells signal elapsed time in rats running on treadmills, for instance.

Last year, a team of scientists at Princeton University brought yet another potential dimension into the mix: sound. They monitored brain activity in rats that were pushing a lever to change the frequency of an emitted tone to match one they had previously heard. Their observations hinted that the rats might be mentally navigating through an “acoustic space” in their minds to find the desired tone.

Perhaps most tantalizing of all, an experiment conducted in 2016 introduced a far more abstract context for grid cell behavior. Researchers led by Timothy Behrens, a computational neuroscientist at the University of Oxford, had people watch the silhouette of a bird on a screen as the length of its neck, the length of its legs or both were stretched and compressed. The hexadirectional signal arose in their fMRI data, in several areas of the brain; it varied just as if the test subjects were navigating a two-dimensional “bird space,” where one axis denoted neck length, the other leg length.

The finding suggested that the brain processes trajectories through physical spaces and conceptual spaces in much the same way. Now researchers including Behrens, Bellmund, and the neuroscientist Christian Doeller propose that all knowledge can be plotted this way, in terms of features of interest—that different objects, different experiences, and different memories can be organized and traversed with the grid code.

“It seems to be quite arbitrary, what dimensions it can map,” Bellmund says. “What’s interesting is that it seems to be so general across domains, but the mechanism seems to be preserved.”

This work, adds Thomas Wolbers, a cognitive neuroscientist at the German Center for Neurodegenerative Diseases, calls into question the idea that grid cells simply constitute “a pure location signal”—hardwired and specialized. “So far, we’d only seen it in space because we’d only looked at navigation tasks and paradigms,” he says. “It may be much more ubiquitous.”

One area that’s seen some intriguing preliminary results is in social behavior. We think of society in spatial terms all the time: There are social ladders to climb, networks to build and expand, people we consider “close” or “distant.” Now some research groups are probing social relationships for evidence of the grid code.

One recent study built up a two-dimensional space not unlike the bird experiment: People played a computer game, interacting with characters in ways that could change their levels of power or affiliation. The researchers found that the hippocampus seemed to track the positions of the characters in that space, relative to the test subject. Although the experiment did not determine whether the hippocampus is navigating that social information in a grid-like way, Matthew Schafer, a graduate student at the Icahn School of Medicine at Mount Sinai currently working on the project, expects to find the telltale hexadirectional signal. (He and others are now studying how that navigation might be disrupted or otherwise affected in people with conditions such as autism spectrum disorder.)

These ideas could make it worthwhile to pursue clues hidden in other kinds of spatial metaphors, too: Neurons beyond place cells and grid cells, after all, might also have something to contribute. There are head direction cells that fire when an animal points its head in a particular direction, and speed cells that indicate the rate at which one moves through space, and even boundary cells that represent the location of walls or other environmental borders.

Studying these neurons in more abstract contexts might yield new insights. For instance, boundary cell activity has been reported for not just the borders of a physical space, but also the borders between separate events in a temporal sequence. Could these neurons also play a role in forming borders between concepts, in creating distinct domains of knowledge in the brain? Or could head direction cells help one orient oneself within a given topic? The potential for such analogies is enormous.

The same goes for gaining a better understanding of diseases and other states. Wolber studies aging, and in one recently published paper, he and his colleagues examined how the spatial-navigation grid code changes in elderly people. They found that the signal became less stable, with the grid fluctuating between orientations—and that people with less stable grids were also much less adept at keeping track of their relative location when blindfolded and led along a circuitous course. Wolbers suggests that if the grid code is used to process many kinds of information and memories, it’s possible that a pathology that destabilizes the spatial grid system might have a more general effect on the stability of memory and other areas of cognition.

Still, “at this stage,” he warns, “the available data is scarce. We have to be cautious.”

Kate Jeffery, a behavioral neuroscientist at University College London, agrees. Sure, the brain might use a common system to encode spatial and nonspatial knowledge, if the latter can be represented as varying continuously on a two-dimensional scale. But it’s also possible that some cognitive tasks are so complicated and unnatural that the brain is forced to rely on a spatial analogue as a crutch to get through them. Perhaps the experiments on sound frequency and stretched birds tapped into this feature, Jeffery says.

To further cement the grid code’s broader applications, then, researchers first hope to figure out how these cells might be working in more than two dimensions, given that higher-level knowledge tends to involve far more than pairs of qualities, like neck length and leg length, or power and association. This is something that’s currently being examined in flying bats, which navigate through three dimensions rather than just two.

Some researchers are making even bolder claims. Jeff Hawkins, the founder of the machine-intelligence company Numenta, leads a team that’s working on applying the grid code not just to explain the memory-related functions of the hippocampal region but to understand the entire neocortex—and with it, to explain all of cognition, and how we model every aspect of the world around us. According to his “thousand brains theory of intelligence,” he says, “the cortex is not just processing sensory input alone, but rather processing and applying it to a location.” When he first thought of the idea, and how grid cells might be facilitating it, he adds, “I jumped out of my chair, I was so excited.”

Imagine closing your eyes and wrapping your hands around an unidentified object: in this case, a coffee cup. Hawkins posits that the brain takes in information about the position of each patch of skin touching the cup’s surface, relative to the cup itself—much as the grid code allows you to know your body’s position in space, relative to the room you’re in. Each patch of skin generates an independent model of what it might be touching; all of those models then get cross-referenced to reach the conclusion that the object is indeed a coffee cup.

Hawkins thinks the same logic can apply to anything with a structured framework. “Everything we do—planning, mathematics, physics, language—would be based on the same principle,” he says. “I think we’re on a cusp here, where all of a sudden we’re going to have a new paradigm for understanding how the brain works.”

While the hypothesis has piqued interest among other researchers, they remain skeptical that grid cells will be found beyond the vicinity of the hippocampus, and say that Hawkins and his team have a long way to go to prove the power of their model.

Still, it provides a good starting point for thinking about how to improve artificial intelligence. If the grid framework is indeed a general one, it could be mimicked to build machines that are far more flexible, creative, general, and powerful.

The field is just starting to grapple with these notions. For now, researchers are continuing to probe the activity of the hippocampus in a slew of different contexts, in hopes of finally uniting its memory and navigation functions once and for all. “When conceptual and cognitive ideas really start to connect with the very low-level neural data,” Stachenfeld says, “it’s really very satisfying.”

This post appears courtesy of Quanta Magazine.



CAPE CANAVERAL, Fla.—The stars were out over the marshlands near the launchpad. Crickets trilled a steady melody, interrupted by the occasional squawk of a bird flying low over the water. Except for a few pops of lightning, the sky was a very deep blue, almost black. It was, by all appearances, nighttime.

Then came a burst of blinding light.

A SpaceX rocket ignited its engines just before 3 a.m. ET on Saturday and rose like a ball of fire against the sky. A gold-colored glow spread across the horizon, like a racing sunrise in the middle of the night.

For the first time, a commercially built spacecraft designed to carry humans has launched to the International Space Station.

There are no people on board, but the hope is that the next such flight will carry a crew. The United States hasn’t sent people to space from American soil since the Space Shuttle program ended in 2011 after three decades of operation. To reach the International Space Station, where they live and work for six months at a time, NASA astronauts travel to Kazakhstan and launch inside a Russian capsule, atop a Russian rocket, snuggled close to Russian cosmonauts. To break its reliance on this arrangement, which costs more than $80 million per seat, NASA hired SpaceX, along with the aerospace company Boeing, to develop a crew-transportation system.

The successful launch of SpaceX’s Dragon spacecraft on Saturday is a meaningful milestone for NASA. An expensive arrangement with a diplomatic rival is not ideal. If the rest of the spacecraft’s journey goes well, NASA astronauts could fly on Dragon in time for the 50th anniversary of the Apollo moon landing in July.

It’s a significant achievement for SpaceX too. Returning human spaceflight to American shores would boost the company’s prestige, and on top of that, SpaceX managed to edge out Boeing. Both companies have experienced schedule delays and technical issues, but SpaceX has gained a decisive lead.

Jim Bridenstine, the NASA administrator, said that he is “100 percent confident” a crewed mission will launch this year.

Elon Musk, the SpaceX founder, is optimistic too. “So far, it’s looking quite promising,” Musk said.

The Dragon spacecraft is now in orbit, but the mission is far from over. The spacecraft must fire its engines to lift itself higher and move toward the ISS. As it approaches the station, Dragon will prepare for a maneuver that it has never attempted.

SpaceX has flown a different version of the Dragon spacecraft, designed to carry only cargo, to the ISS. These capsules were captured by a powerful robotic arm attached to the station and operated by an astronaut inside. This time, the Dragon spacecraft will rely on its autonomous-navigation systems to dock to a port.

This attempt may be more nerve-racking than the launch itself. SpaceX has mastered rocket launches and booster landings—the booster on this flight returned to Earth and gently touched down on a ship off the coast of Florida, a feat SpaceX perfected only a few years ago. But it has never tried to attach a spacecraft to a space station traveling 17,500 miles per hour. Russia’s space agency, Roscosmos, which operates half of the ISS, was even hesitant to formally approve the plan.

If SpaceX sticks the docking, the crew of the ISS—an American, a Russian, and a Canadian—will be able to enter the Dragon spacecraft and welcome its contents: 400 pounds of cargo, and a mannequin in a spacesuit that SpaceX has named Ripley, for the protagonist of the Alien films, portrayed by Sigourney Weaver. After five days, Dragon will detach, reenter Earth’s atmosphere, and parachute down to the Atlantic Ocean, where SpaceX recovery crews will be waiting.

More tests of the system’s soundness will follow after Dragon returns. If everything checks out, the next spacecraft will carry two NASA astronauts, Doug Hurley and Bob Behnken, both alumni of the Space Shuttle program. Hurley and Behnken watched the launch unfold alongside Musk and engineers at Kennedy Space Center, inside the room where mission control once gathered for the launches of space shuttles. Hurley, a veteran pilot who tested aircraft in the Marines before he joined NASA, told reporters, “I can’t begin to explain to you how exciting it is for a test pilot to be on the first flight of a vehicle.”

NASA says SpaceX must resolve some technical concerns before the agency is ready to replace the mannequin with astronauts. But its first passengers say they feel ready, and they’re not nervous.

“Part of the reason that we’re in the job that we’re in is that we tend to get nervous kind of after the fact rather than in the moment,” Behnken said. “They do their best, from a training perspective, to try to beat that all out of you by giving you a lot of experiences before you jump into the actual spaceship and ride it into space.”



In the quest to fend off forgetfulness, some people build a palace of memory.

It’s a method for memorizing invented in ancient times by (legend has it) the Greek poet Simonides of Ceos, more recently made popular by multiple best-selling books (and the “mind palace” of Benedict Cumberbatch’s Sherlock Holmes).

Memory palaces provide imaginary architectural repositories for storing and retrieving anything you would like to remember. Sixteen centuries ago, St. Augustine spoke of “treasures of innumerable images” stored in his “spacious palaces of memory.” But 21st-century scientists who study memory have identified an important point to remember: Even the most luxurious palace of memory needs trash cans.

“There are memories that we don’t want and we don’t need,” says the neuroscientist Maria Wimber, of the University of Birmingham in England. “Forgetting is good, and an adaptive thing.”

Traditionally, forgetting has been regarded as a passive decay over time of the information recorded and stored in the brain. But while some memories may simply fade away like ink on paper exposed to sunlight, recent research suggests that forgetting is often more intentional, with erasure orchestrated by elaborate cellular and molecular mechanisms. And forgetfulness is not necessarily a sign of a faulty memory. “In fact,” Wimber says, “it’s been shown over and over in computational models and also in animal work that an intelligent memory system needs forgetting.”

Far from signifying failure, forgetting may be the brain’s frontline strategy in processing incoming information. Forgetting is essential, some researchers now argue, because the biological goal of the brain’s memory apparatus is not preserving information, but rather helping the brain make sound decisions. Understanding how the brain forgets may offer clues to enhancing mental performance in healthy brains while also providing insights into the mechanisms underlying a variety of mental disorders.

Memory itself is still something of a mystery, but it basically consists of physical changes in the brain that encode a representation of past experiences. Those memory traces—known as engrams—can be accessed to reconstruct the past, albeit imperfectly. Many experts believe that engrams are built by strengthening synapses—the sites where signals are transmitted between nerve cells, or neurons. Recalling a memory reactivates a pattern of nerve-cell signaling that mimics the original experience.

“The prevailing view is that the formation of an engram involves strengthening of synaptic connections between populations of neurons … that are active during an event,” Sheena Josselyn and Paul Frankland write in the current Annual Review of Neuroscience. “This increases the likelihood that the same (or similar) activity pattern within this cell assembly can be recreated at a later time.”

Engrams obviously do not save every detail of every experience. Some records of activity patterns do not persist. And that’s a good thing, says Wimber.

“An overly precise memory is maybe not really what we want in the long term, because it prevents us from using our memories to generalize them to new situations,” Wimber said in San Diego at a recent meeting of the Society for Neuroscience. “If our memories are too precise and overfitted, then we can’t actually use them to … make predictions about future situations.”

If your memory stores every exact detail of getting bitten by a dog in the park, for instance, then you wouldn’t necessarily know to beware of a different dog in a different park. “In fact,” Wimber says, “what we might want is a more flexible and more generalized memory, and that would involve a bit of forgetting of the details and more the development of a gist of a memory.”

Such “streamlined” memories are not side effects of flaws or constraints on memory power, Frankland and Blake Richards point out in a 2017 paper in Neuron. Such simplification “is an essential component of adaptive memory,” they write. “Simple memories that store the gist of our experiences and avoid complicated details will be better for generalizing to future events.”

Getting the gist, and just the gist, is therefore valuable as an aid to making smart decisions, say Frankland, of the Hospital for Sick Children in Toronto, and Richards, of the University of Toronto. In fact, they believe it is wrong to think of memory “simply as a means for high-fidelity transmission of information through time.” Rather, they propose that “the goal of memory is to guide intelligent decision making.”

Getting just the gist is especially helpful in changing environments, where loss of some memories improves decision making in several ways. For one thing, forgetting can eliminate outdated information that would hamper sound judgment. And memories that reproduce the past too faithfully can impair the ability to imagine differing futures, making behavior too inflexible to cope with changing conditions. Failure to forget can result in the persistence of unwanted or debilitating memories, as with post-traumatic stress disorder.

Forgetting’s great value implies that it doesn’t happen accidentally. In some cases, forgetting may simply reflect an inability to recall a memory trace, even if the engram encoding it remains intact. But a growing number of researchers believe that can’t be the whole story. As Ronald Davis and Yi Zhong point out, the brain’s remarkable storage ability suggests that it possesses an efficient information-management system, equipped with data-disposal methods. “Because of the extraordinarily large number of memory engrams that can accumulate in the brain across time, it seems logical that the brain must have … mechanisms to remove memories that become unused,” they wrote in 2017 in Neuron.

Psychologists have considered the possibility of active forgetting for more than half a century, but only in the past 15 years or so have researchers accumulated substantial neurobiological evidence on the issue. While the neuroscientific study of forgetting is still in its infancy, scientists have begun to discern some of the brain’s tactics for information erasure. In their paper in Neuron, Davis, of Scripps Research Institute Florida, and Zhong, of Tsinghua University in Beijing, described various studies in the past few years on mechanisms that may implement the forgetting process.

Some forgetting does appear to be “passive”—a result of either natural decay of the biological material forming engrams or the loss of ability to retrieve them—Davis and Zhong noted. But many forms of forgetting are more like running a program that wipes data off your hard drive. New stimuli can actively interfere with old memories, for instance. Recalling parts of a memory can induce loss of other parts of it. And “forgetting cells” might actually signal the brain to sweep memory traces away, Davis and Zhong suggested. “We posit that … the brain also has the inherent biological capacity to erode memory traces using signaling systems” similar to those used in acquiring memories and storing them. In fact, forgetting could be the brain’s main strategy in managing information.

“I would speculate that forgetting might be the default system of the brain,” Davis said at the neuroscience meeting. “We might have a slow chronic forgetting signal in our brains that basically says, ‘Let’s erase everything,’ unless a judge … comes to intervene and says, ‘This memory is worth saving.’”

In various experimental studies, Davis and others have amassed ample evidence for the role of biochemical processes that actively erase memory. Studies in fruit flies, for instance, implicate the well-known chemical messenger molecule dopamine.

Flies can remember to avoid an odor that has been accompanied by an electric shock, a memory managed by nerve cells known as mushroom body neurons. Shocks activate other neurons that transmit dopamine to the mushroom body cells, initiating biochemical reactions that store a memory linking the shock to the odor. But that memory is soon forgotten (typically by the next day). Something erases it, and the evidence suggests that dopamine is responsible for the forgetting, too.

Dopamine’s dual role is not fully understood. But mushroom body neurons possess two distinct molecular antennas that respond to dopamine; one of those antennas (or receptor molecules) initiates memory formation, and the other promotes erasure. Whether dopamine promotes or erases memory may depend on the context, including prevailing biochemical conditions and how active the mushroom body neuron is at the time.

In any case, the erasing process involves a protein known as Rac1, which plays a part in structuring synapses. Restructuring synapses in response to Rac1 may be responsible for weakening engrams, some studies indicate. Blocking Rac1 activity, for example, helps to extend how long memories persist.

Rac1 may also be involved in a second forgetting mechanism, driven by the birth of new nerve cells (the process known as neurogenesis). Studies in rats have found that new neurons integrated into existing neural circuits can restructure the circuitry. Such changes in connections might make memories harder to access, Frankland said at the neuroscience meeting. Animal studies have shown that disrupting neurogenesis preserves memories, while high levels of neurogenesis drive forgetting. Whether that form of forgetting is important in humans remains unknown, because the amount of neurogenesis in adult humans is still an unsettled question.

In any case, the evidence suggests that many types of “forgetting cells” must be involved in erasing engrams. “Dozens of molecular and cellular pathways likely exist to erode memories,” Davis and Zhong wrote in Neuron.

How and when those processes operate can depend on various factors, such as physical activity, stress, and sleep. Sleep is known to enhance memory in humans and other animals, presumably by providing a time when memories can be stored (or “consolidated”) in the brain. But sleep may also aid memory by suppressing the processes that drive forgetting, Davis and Zhong point out. A 2015 study published in Cell found evidence that sleep inhibits release of the dopamine forgetting signal to mushroom body neurons.

If forgetting is the key to how the brain successfully processes the massive data input it encounters each day—as research accumulated so far suggests—then flaws in the forgetting process could plausibly contribute to brain disorders, Davis and Zhong note. Deficits in the ability to forget may be involved in autism spectrum disorders, for instance. Certainly the powerful and debilitating memories of post-traumatic stress disorder reflect an inability to forget disturbing experiences. Unwanted, repetitive invasive memories are a feature of some psychiatric disorders, such as schizophrenia. And the inability to forget cues associated with addictive drug use impairs recovery from substance abuse.

On the plus side, better insight into the biology of forgetting could help identify drugs capable of enhancing needed memories while disposing of undesirable ones. But such benefits may appear only after much more research, Davis said at the neuroscience meeting—speaking at a rather sparsely attended session.

“We’re at the very, very beginning of trying to understand the neurobiology of active forgetting,” he said. But he expects that the field will rapidly attract more attention.

“I guarantee you, five years from now this room will be filled,” he said. “Hordes of neuroscientists will start invading this field.” If he’s right, future meetings on forgetting might best be convened at a spacious palace—with plenty of trash bins and perhaps even a Dumpster.

This post appears courtesy of Knowable Magazine.



In a medieval cesspit in central France, archaeologists dug up a small, hard grape seed. They believed it to be 900 years old, based on the artifacts found nearby. When geneticists crushed up the grape seed, extracted its DNA, and compared it with modern grapes, they found a perfect genetic match in Savagnin Blanc—a grape still grown, still picked, and still made into wine in Europe today.

This grape, it turns out, has survived unchanged for almost a millennium. In a time that has spanned the Hundred Years’ War, the Enlightenment, the French Revolution, Napoleon, and two world wars, someone has always thought to take cuttings of Savagnin Blanc to keep planting into the ground anew.

This technique is called vegetative or clonal propagation, and it’s a way to take a desirable variety and “freeze it across space and time,” says Sean Myles, an agricultural geneticist at Dalhousie University, who was not involved in the Savagnin Blanc study. Historical evidence suggests that viticulturists have been propagating grapevines this way for thousands of years, and the genetics now bears this out.

Nathan Wales, an ancient-DNA researcher at the University of York, and his collaborators came across the 900-year-old Savagnin Blanc among 28 grape seeds excavated from nine different archaeological sites around France. The seeds dated back to the medieval period, the Roman era (100 B.C. to 500 A.D.), and in one case even the Iron Age (500 B.C.). The team found six separate pairs or groups of genetically identical seeds, sometimes hundreds of miles apart. The clones had almost certainly spread through vegetative propagation by humans.

One group of these Roman-era grape seeds were genetically similar, but not identical, to a modern variety called Mondeuse Blanche. In fact, Mondeuse Blanche appears to be the direct offspring of the Roman-era grapes. In other words, Wales says, “in 2000 years, there’s been one reproductive cycle between the Romans and today.” Grapevine varieties have stayed remarkably stable over the centuries.

The 900-year-old Savagnin Blanc—not to be confused with the more famous variety Sauvignon Blanc—is also notable because it is related to and probably even the parent of many modern varieties: Pinot Noir, Riesling Bleu, Verdejo, Sylvaner, Trousseau, and so on. “Savagnin, which to the general wine drinker is a very obscure minor grape, has this really important genetic history, and now we can take it back 1,000 years and put it in the middle of France,” says Jon Bonné, a wine writer and the author of the forthcoming The New French Wine. He likens the variety to the “Johnny Appleseed of all these other varieties.”

Savagnin Blanc is also known as Traminer Weiss, and it is still grown in a few European countries. But it is perhaps most famously used to make vin jaune or “yellow wine” from Jura in France. Vin jaune comes in a squat bottle called a clavelin and it has taken on a bit of a cult status. “It is probably the weirdest wine you’ll ever have,” Bonné says. “It is intensely yellow-colored. The best way I can describe it, it has almost no fruit characteristics. It’s nuts, almonds, and walnuts, and this very distinct, slightly acidic tang, too.”

While the grapes are genetically identical, Bonné says vin jaune is almost certainly not the same as the wine being made from Savagnin Blanc 900 years ago. The wine’s exact origins are lost to history, and vin jaune only became an official designation in the 20th century. “Despite some crafty marketing by the Jurassiens”—people of the Jura region of France—“it’s just hard to know what the historic expression of the wines really was,” Bonné added in an email.

The art of wine making—or perhaps wine selling—rests on the appeal of tradition. This is why grape varieties have continued to be propagated, frozen in name, time, and evolution. Meanwhile, the pathogens that prey on grapes have continued to evolve, leading to major pesticide use. “We could probably be breeding new grape varieties and not just relying on 1,000-year-old grape varieties,” Myles says. But, he adds, “it’s hard to go to Burgundy and say, ‘Here’s Sean’s new super grape.’ Are you going to strip out all your Pinot Noir and start planting Sean’s new super grape?” What’s the romance in that?



In the 1990s, virologists in New York learned of a genetic mutation that would become one of the most famous ever discovered. They found it in a man who could not be infected with HIV. He turned out to be missing just 32 letters in a gene called CCR5, and remarkably, it was enough to make him resistant to the virus killing so many others. About 1 percent of people of European descent carry two copies of this mutation, now known as CCR5-Δ32.

In 2018, a Chinese scientist named He Jiankui made the mutation infamous when he attempted to use CRISPR to edit CCR5-Δ32 (pronounced “CCR5-delta-32”) into human embryos. He chose this mutation, he said, because the babies’ father was HIV-positive, and he wanted to make the resulting twin girls resistant to the virus. CCR5-Δ32 is also, after all, one of the most studied mutations.

He’s work immediately provoked outrage among scientists, who knew enough to know how much they did not know about the risks of altering CCR5. And now a new study suggests that CCR5-Δ32 is indeed harmful overall.

The girls’ CCR5 genes were altered, according to data He presented, but they do not exactly match the 32-letter deletion; it’s unclear whether either of them is actually resistant to HIV. Even if they were unable to get HIV, a body of research already suggested that CCR5-Δ32 made people more vulnerable to the flu and West Nile virus. A “good” mutation in the context of HIV can be “bad” in another context. No one knew, exactly, the net effect of a CCR5-Δ32 mutation.

However, the new study, by Rasmus Nielsen and Xinzhu “April” Wei of UC Berkeley, shows that people with two copies of the mutation are 21 percent more likely to die at the age of 76, with a mortality rate of 16.5 percent, compared with 13.6 percent for those who have only one or zero copies. Only recently, Nielsen told me, have genetic databases even become big enough for these effects on mortality to be apparent.

The effect of CCR5-Δ32 on mortality is ultimately subtle, but it follows from what’s already known about this gene. CCR5 usually codes for a receptor on the surface of white blood cells, and it plays a role in normal immune responses. HIV co-opts CCR5 as a way to get into white blood cells. So to block HIV is, ironically, also to eliminate a small piece of the normal immune system.

“If you think about what these people are with Δ32, they’re like human knockouts for a fairly important gene in immune response,” says Bill Paxton, a microbiologist at the University of Liverpool who helped discover the role of CCR5 in HIV. “It’s not wholly surprising you [would] read a paper like this, and the finding is there.”

After HIV researchers made CCR5-Δ32 famous, scientists in other fields got interested in the mutation, too. Flu researchers who studied it found that it predisposes people to fatal outcomes with flu. West Nile virus researchers found the same with that disease. Neurobiologists have found evidence that CCR5-Δ32 actually enhances recovery from stroke. But this process of understanding the full scope of CCR5 has been piecemeal, essentially limited by what scientists think to look for.

Geneticists have proposed more systematic ways to understand all the effects of a single gene. Instead of picking a disease and looking for associated genes among a large group of people, geneticists can pick a gene of interest and look for associated traits. This is called PheWAS, or phenome-wide association study, where phenome refers to the set of observable traits. The idea is to look for links “that we just never knew to look for before,” says Marylyn Ritchie, a geneticist at the University of Pennsylvania who uses PheWAS in her research. Crucially, PheWAS requires not just DNA from volunteers but rich and detailed health data from those same volunteers—everything that could be conceivably linked to a gene, from height to brain volume to white-blood-cell count. PheWAS studies are necessarily limited by what health data have been collected.

Nielsen and Wei told me that they also tried to see whether CCR5-Δ32 was linked to other traits in the U.K. Biobank, and they found a few additional expected associations, such as white-blood-cell count. But their results are restricted by the health data scientists thought to begin collecting back in 2006, when the U.K. Biobank project began.

And despite its size, the U.K. Biobank is not representative of all people in all situations. In a population with more non-British ancestry and in a part of the world where certain viruses are more prevalent than others, CCR5-Δ32 could be more harmful or less beneficial. It depends on the environment, and the environment could also change in the future. A new epidemic could emerge, and so could new treatments.

That is ultimately what makes the proposition of editing genes like CCR5 so tricky. It can be hard to predict what the net effect will be, in a future we do not yet know, and harder still when all of the trade-offs today have not even been fully studied. In May, scientists launched an international commission on gene editing that will discuss these concerns, including how to balance the benefits and harm to not just a gene-edited child but also “subsequent generations.”



Updated at 5:06 p.m. 

Natural-history museums are research centers, public attractions, and stores of natural treasures. But many of them are also event spaces that command a hefty price for weddings, award ceremonies, gala dinners, and conferences. These two roles can seem like Janus’s faces: inseparable, but looking away from each other. Often, that’s not a problem. Sometimes, it very much is.

The American Museum of Natural History came under fire this Thursday, when news emerged that on May 14 it would serve as the venue for a black-tie gala dinner honoring Jair Bolsonaro, Brazil’s newly elected, ultranationalist president. Since 1970, the Brazilian-American Chamber of Commerce has bestowed a person-of-the-year award upon two people—one Brazilian and one American—for being “particularly instrumental in forging closer ties between the two nations.” For at least the past two years, the honorees have picked up their accolades beneath the gaze of the AMNH’s blue whale. And this year’s planned event would have attracted little notice outside the international business community, had it not involved Bolsonaro.

Elected in October 2018 and in office since January, Bolsonaro quickly moved to undermine protections for the Amazon rainforest, open it up for agriculture and mining, and wrest control of land from indigenous communities. He has compared those communities to chicken-pox spots, promised to forcibly integrate them, and praised America’s historical extermination of native peoples. He recently froze almost half of Brazil’s science spending. His statements have frequently been racist, misogynistic, and homophobic.

According to the Brazilian newspaper Folha de São Paolo, tickets for a table of 10 cost $30,000, and sold out quickly. Brazilian scientists such as the herpetologist Henrique Costa and the ecologist Ana Carnaval drew attention to the report last month, but the issue truly heated up on Thursday after a story in Gothamist reached AMNH scientists. Alexandra Walling, a graduate student who studies viruses, said that she was “outraged but not surprised” in a widely shared Twitter thread. “AMNH claims to care about biodiversity and climate change—they certainly employ scientists who study these things—but they’ll take the money of people who would see the whole world burn to line their pockets,” Walling wrote.

Other AMNH scientists were similarly appalled. “It was a jaw-dropping shock when I saw the Gothamist piece,” adds Susan Perkins, the museum’s curator of microbial genomics. “Bolsonaro is the opposite of what I care about. To have someone like that being in our space makes my skin crawl.” Several graduate students (and other signatories) have written an open letter to the administration, and some of the museum’s research associates have threatened to resign. There’s some talk of protests at upcoming events, including a big anniversary party and the Earth Day celebration this weekend. “As a Brazilian scientist working at the museum I’m embarrassed that this event is happening here,” says the evolutionary biologist Marcelo Gehara.

The controversy also comes as others are calling on the AMNH to confront its own colonial legacy. Since 2016, the activist group Decolonize This Space has organized annual protests to highlight the white-supremacist views of Teddy Roosevelt (who is memorialized in a key hall), the museum’s historical support of eugenics, and its “deeply colonial and faulty representations of culture.”

Anne Canty, an AMNH spokesperson, sent a statement saying: “The external, private event at which the current President of Brazil is to be honored, was booked at the Museum before the honoree was secured. We are deeply concerned, and the event does not in any way reflect the Museum’s position that there is an urgent need to conserve the Amazon Rainforest, which has such profound implications for biological diversity, indigenous communities, climate change, and the future health of our planet. We are exploring our options.”

The AMNH has come under similar fire before. Like many other museums, it has been criticized for taking money from the Sackler family, whose fortunes were built on sales of the highly addictive painkillers behind the current opioid crisis; the Sackler name graces the AMNH’s institute of comparative genomics. In 2015, scientists protested the museum’s ties with the billionaire oil magnate David Koch and urged it to “cut all ties with the fossil fuel industry and funders of climate science obfuscation.” Koch later resigned from the museum’s board for reasons allegedly unrelated to the protest; his name still graces the museum’s dinosaur wing. In 2018, protesters levied similar objections about the conservative heiress Rebekah Mercer, who has also funded groups that deny climate science, and who also sits on the museum’s board.

Critics have cast some of these protests as attempts to exclude people with conservative political views from scientific spaces. But that would be an unfair portrayal of the objections to the Bolsonaro gala: His views on the environment and indigenous communities are not merely right-wing, but diametrically opposed to the museum’s goals. As the wildlife photographer Lee Jaszlics noted on Twitter, the museum’s collections include tens of thousands of specimens and fossils from Brazil—“objects that represent an investment in the country's biodiversity and cultural wealth.” “This is why you cancel the event,” she added. “Bolsonaro’s policies are utterly antithetical to the trust the museum holds.”

“I think it’s very important to engage with people even when they have firm opposition to things we believe in, but this is strongly off the charts,” says Emilio Bruna, an ecologist from the University of Florida who works in Brazil. “I simply cannot imagine a person who is more antithetical to what my colleagues at the museum or my Brazilian collaborators are working towards.”

The decision to host Bolsonaro also contravenes the code of ethics of the American Alliance of Museums, says Beka Economopoulos, an activist who directs a traveling pop-up museum called The Natural History Museum. The code states that “it is incumbent on museums to ... foster an informed appreciation of the rich and diverse world we have inherited [and] preserve that inheritance for posterity.” Given that mission, “it is wrong to offer space to a right-wing dictator who wants to mow down the Amazon and kill indigenous peoples,” Economopoulos says.

In the wake of similar controversies, other museums have played up the separation between their roles as institutions and their roles as spaces for events. After the murder of the journalist Jamal Khashoggi, London’s Natural History Museum was criticized for hosting a reception by the Saudi embassy. The museum noted that the event had been booked months before, and such commercial events were “an important source of external funding.” In a statement, they added: “We hold a wide variety of commercial events and it is made clear to any host that doing so is not an endorsement of their product, service or views.”

That delineation might exist in the minds of decision makers, but it doesn’t actually exist, Economopoulos says. “The department involved in rentals is a part of the museum,” she says. “There are parameters for which entities you confer legitimacy upon by offering your venue and your name. If you are going to host something, you are tacitly in support of that thing.”

“These are complicated questions for museums,” she acknowledges, “but this one for the AMNH is not complicated.”



Robert Macfarlane has spent the past two decades becoming a nature writer for the Anthropocene. His new book, Underland, culminates a first-half-of-life project in which he has worked to understand the mind’s encounter with nature. What do we look for when we go out to meet landscapes and nonhuman things? What do we find, and how does it change us?

In Mountains of the Mind (2003), Macfarlane explored the lure of high places, and the ways Romantic literature helped to transform high altitudes from the terrifying and disgusting places medieval Europeans saw them as to the pilgrimage destinations they are today. The Wild Places (2007) described some of the least human-dominated places in the British Isles, guided by Henry David Thoreau’s theme that “wildness” is a quality of the imagination as much as of the world, and that being in the wild means adjusting the mind’s eye as well as strapping on crampons. The Old Ways (2012) followed paths and sea routes around the British land and coasts, stripping away the overlays of maps and GPS to find the feeling of navigating by stories and pictures held in the mind. Landmarks (2015) rummaged through the word-hoards of Britain’s regional dialects, finding terms such as pallag (on the Isle of Man, a hilltop seen from the sea) and allan (in Cumbria, a piece of land almost completely surrounded by water). The aim of Landmarks was to recover words so particular that they tell you where you are: in what landscape, perhaps at what time of day, in which stage of the seasons and the place’s cycle of work. In 2017, Macfarlane co-published a beautifully illustrated children’s book, The Lost Words, that wove nature terms into spells for reenchanting a world that had lost some of its old magic. It became a best seller in the United Kingdom.

Macfarlane is a seemingly effortless master of two popular genres, travel literature and nature writing. Their perfect blend forms the surface appeal of his books. Like the winsome Bruce Chatwin or the acerbic V. S. Naipaul, he takes you with him from place to place, feeding you the best bits of conversation with the odd and sometimes revelatory characters he meets. Like Annie Dillard and Barry Lopez, he is an extraordinary observer who, every few pages, will draw you shockingly near to a single stone, the meltwater torrent running through a glacier, or a patch of Cambridgeshire hedge, making it so vivid that, if you are reading attentively, for a few seconds nothing else is in your mind. Both genres often depend on nostalgia (the last this, the vanishing that­) and exoticism (I went to this place where they do, well, you won’t believe). In a world collapsing into mass extinction and growing more globally homogenous every year, the you won’t believe is usually also the last of something. Macfarlane knows the appeal of nostalgia and exoticism, but he also knows that they are dead ends. They fundamentally portray the world as becoming less interesting, less worth working to preserve, less worth the passion of an eager explorer.

Underland makes clear what Macfarlane has been aiming at all along. He wants to do for the broken, fouled, and remnant landscapes of the Anthropocene what his Romantic predecessors did for the high mountains. He is trying to find in places of disgust, indifference, or terror a quality that can answer some new need in the mind, some cultural hunger. And what we need now, he reckons, is a new (or renewed) way of experiencing the richness and strangeness of a damaged world. He is out to model that way of seeing, of reenchanting.

In going underground, Macfarlane is entering more explicitly mythical territory than in his earlier books. The underland is home to Hades, fairy kingdoms, and many other realms of spirits and the dead, from Mesopotamia and Ireland to the indigenous cosmologies of some Native Americans and the Sámi of Finland.

Going there carries risks: The thing about living in disenchanted times is that you can’t conjure just by using old conjuring words. (One of J. R. R. Tolkien’s writing-group members is said to have captured this difficulty when he exclaimed, in response to a new chapter in the master’s epic, “Not another fucking elf!” You don’t say that if you think elves might be real enough to sicken your cow or kidnap your boyfriend.) In an implicit response to this difficulty, Underland rests its ideas on things.

Macfarlane travels with scientists, laborers, and spelunking adventurers in their explorations of underground places: the catacombs of Paris, potassium and rock-salt mines that branch for miles under the North Sea from their entrances in Yorkshire, the blue caverns that meltwater cuts into the glaciers of Greenland. Every descent suggests, contrary to the common Romantic conceit that science kills magic, that the more we learn about the world, the more wondrous it becomes. The more we understand, the more we realize what we do not know, as if the horizons of mystery expand outward, beyond the circle of secure knowledge.

Take those potassium mines under the North Sea. Macfarlane goes banging around down there, far from the “noise” of cosmic rays and other surface disturbances, with veteran miners because scientists are also using the deep mines. They’re looking for traces of neutrinos and other “ghost particles” that might enable us to observe the dark matter that physicists estimate makes up about 27 percent of the universe’s mass, but that almost entirely refuses to interact with the kind of matter that forms us and everything we can touch or observe directly. Particles of dark matter must swim through us, like light through air, or small fish through broad nets.

The underground is mythically associated with another world pulsing just behind this one, sometimes interacting with ours in uncanny ways. That pulsing ended, mostly, with the elves and fairies. But here is the presence of that world again, streaming across the cosmos to make itself fleetingly known in the recesses of a deep mine. A scientist tells Macfarlane how he feels knowing that 100 trillion neutrinos pass like ghosts through his body every second: “When I’m out for a walk with my wife, along the cliff-tops near here, on a sunny day, I know our bodies are wide-meshed nets, and that the cliffs we’re walking on are nets, too, and sometimes it seems, yes, as miraculous as if in our everyday world we suddenly found ourselves walking on water, or air. And I wonder what it must be like, sometimes, not to know that.”

In Paris, Macfarlane finds urban spelunkers who are making literal the novelist Italo Cavino’s famous idea that beneath every city exists an “invisible city” (or a series of such cities) that corresponds to it, yet is in some way essentially different. Every act of functional construction makes a new mystery that haunts the final product. The catacombs of Paris were created by quarrying, as the building-up of the great city aboveground produced emptied-out spaces below, a material photo negative of progress. The catacombs have served as resting places for the bones of the dead, as marching routes for prisoners during insurrections, and as extra classrooms for the Paris School of Mines, which has forgotten about an entire display room of mineral samples that Macfarlane’s friends lead him to, a cabinet of wonders accessible only by crawling on your belly through cuts in stone. Today the catacombs serve, too, as gathering spaces for a demimonde of adventurers who hold dance parties, or just wander quietly, where day and night give no shape to time.

The point of going into an alien space underground has usually been to return from it changed, and that change is a great deal of what interests Macfarlane. When you surface, the world is given back to you, but it is not quite the same. “Green is a new color again,” he writes of reemerging in Paris. Coming out of a tiny crawl space beneath an unimaginable weight of stone in the English Mendips, a cave region threaded with ancient burials, “warm air is rolling around me, and my bones grow again in the storm of light … I sit laughing, knowing for those few moments that to understand light you need first to have been buried in the deep-down dark.” He’s describing a kind of ecstasy, even something mystical, that returns our everyday experience to us transformed.

Some of Macfarlane’s destinations are straightforwardly extraordinary: a cave off the stormy coast of Norway, reachable only by a dangerous trek and an overnight wait for the tides to yield, where one can just glimpse a millennia-old painting of dancers; the deep crevasse of a Greenland glacier, which could be the nave of a cathedral in a world carved from blue light. But these places have a meaning beyond being rare and strange. They are bridges across time, where one can feel that thousands of years have collapsed into the space of a tomb, or are held in a hand that touches ancient layers of glaciation or sedimentary stone. For Macfarlane and some of his scientist-informants, rock has a kind of vitality: It is a piece of deep time that you can brush with your finger. Ancient ice is an even more profound and almost living messenger. Like stone, it gathers the past thousands or millions of years, but it disappears into water within days of surfacing to be touched and seen. The depth of time is one of this old world’s most astonishing qualities, but we constantly lose awareness of it, because time is always now. In underground materials, Macfarlane finds palpable pieces of time.

In other portions of Underland, Macfarlane is interested in how it might be possible to move between the upper and lower worlds more easily, or even to hold both together in our minds. In an essay closely aligned with Richard Powers’s Pulitzer Prize–winning novel, The Overstory, Macfarlane wanders London’s Epping Forest with a mycologist fortuitously named Merlin, meditating on the consciousness of trees. We have learned in the past two decades, thanks to pioneering work by the forest ecologist Suzanne Simard, that the forest minds of Tolkien’s ents and Hayao Miyazaki’s Princess Mononoke may be not entirely fantastical. Trees share food, warn one another of threats, and are generally linked by webs of roots and fungi, which symbiotically carry chemicals from one root crown to another. The meaning-makers and ideologists that we are, people have already hastened to paint these “wood-wide webs” as proof of nature’s inherent socialism, or of rational markets in goods and services among tree species. But an honest assessment has to stick at the uncanniness of it. We know something is there, hundreds of millions of years older than us, and that it is behaving rather like a nervous system, a brain, a seat of consciousness. Does it make meaning? Does it have experience? If it does, could we ever know it, or does it pass through our world like neutrinos ghosting through our livers and brains? “Walden, is it you?” Thoreau asked, meaning roughly, Can I ever know what you are? Macfarlane’s scientists show him that is not an inapt question to ask of a place. Whether to expect an answer is another question. If only your mind were a slightly greener thing, we’d drown you in meaning, Macfarlane imagines the forest saying, over and over, to ears that cannot hear but that should maybe listen anyway, out of respect for the something that is there, just underground.

Macfarlane is the least portentous of prophets, and Underland is not, in the usual sense, a political book. He is a listener and observer, always careful to position himself as the slightly hapless but eager tagalong to someone else’s revelatory work. He is careful to acknowledge his sources, and gives special attention to the words of women and indigenous people, notably the botanist Robin Wall Kimmerer, a member of the Citizen Potawatomi Nation, whose Braiding Sweetgrass is a striking treatment of the ways language can cultivate a sense of community with living things that are not human. But Underland has a project that is quietly prophetic and political.

This age of rolling ecological crisis poses all kinds of hard questions. Will rich nations fall into petro-nationalism of the Russian and Trumpist variety, or achieve the deep decarbonization that is currently being called the Green New Deal? Do we face resource wars and a new colonialism aimed at securing food and water for the powerful, or will new regimes emerge to share wealth and burdens? And in a world where humans are the agents and victims of environmental catastrophe (though not always the same humans, at least not during the same decades), how will we think about our place in the world? Macfarlane’s writing is a gamble that the answer to this last question will matter for the others, too.

Human identity is never far from a picture of what kind of world this is—hostile or welcoming, ancient or young, eternally abiding or speeding toward doomsday. Our identities are rooted, too, in how we suppose we fit into this world: as sojourners on the way to heaven, as masters of a creation that we can use up as freely as builders at a lumberyard, or just as things among things, woven from the same humus and stardust as the mushrooms and the anthracite coal. Who we believe ourselves to be is closely bound up with what we will fight to preserve, and what we are capable of loving.

Past a point, resources are zero-sum. But the richness of experience need not be. The value of our lives depends intensely on material wealth, but wealth is not enough, and for some purposes it is not even necessary. In a more meaningful world, some of us might be satisfied with less, or just be more satisfied. We might rage less, be less restless, listen less to everyone with something to sell, from national politicians to advertisers. If only your mind were a slightly greener thing. Macfarlane’s gamble is that we can make our minds greener, more attuned to deep time, more aware of all the strange reality that pulses around and through us, and might make the world enough for us, and worth fighting to preserve. We might feel more solidarity with other humans who, like us, have surfaced for a moment in deep time.

The underground has always been threatening and empowering, a place of interment and transformation. It is where mourning comes to rest, and where life mysteriously returns. It is where we bury what we hope to never see again—and where the past waits to return to us in strange new ways. Macfarlane and his companions watch a glacier calve in Greenland and see “a whole city of white and blue” collapse into the sea, followed by “a black, shining pyramid … thrusting and glistening, made of a substance that has to be ice but … has come from so deep down in time that it has lost all color, and we are dancing and swearing and shouting, appalled and thrilled to have seen this repulsive, exquisite thing.” In an age of ecological catastrophe, the surface world and the present are full of these mixed things, blending the exquisite and the horrible. Any decent way through this time will need to find, in the exquisite and the horrible, reminders of the utter preciousness of ordinary places and things. Underland shows that the world is not disenchanted, and that our minds need not be either. Mystery abounds, and grows with knowledge. Maybe, like dark matter, it makes up more of the universe than the parts we know. We have to learn to go out and meet it, together.



Go beyond Earth and deeper into the solar system, past the craggy terrain of Mars and the shape-shifting storm of Jupiter, through the delicate rings of Saturn, beyond the silky clouds of Uranus and Neptune, and you will find a mysterious zone of small, icy objects. They number in the millions, some half the size of the continental United States, others as small as cities. They form a ring around the solar system, silent sentries guarding the blazing sun, which is so distant that it looks like any other star would.

Back in the day, about 4.6 billion years ago, the solar system was little more than a cloud of cosmic dust spinning around a newborn star. Gravitational forces pulled and smoothed some of the dust into spheres—the planets and moons. The small bodies here, in a region known as the Kuiper Belt, were left out in the cold, and have remained virtually unchanged all this time.

This year, NASA stopped by. The New Horizons spacecraft flew past one of these objects, snapping pictures and collecting scientific data as it went. No space mission had ever visited a target so far away, and NASA even held a New Year’s Eve party for scientists and engineers to count down to the historic pass around midnight.

The public had many questions for them. What does this thing look like? What’s so cool about it? And why does it share a name with a term used by Nazis?

Scientists had nicknamed the object Ultima Thule, a centuries-old phrase with roots in Latin literature. For most of its long history, Ultima Thule, or the word Thule alone, has been used to describe places beyond the limits of the known world, such as hard-to-reach Arctic lands.

But the name picked up more sinister associations in recent history. During the rise of Hitler, members of the Nazi Party in Germany imagined Ultima Thule as a land of Aryan purity. In the late 1990s, white-supremacist inmates in Portland, Oregon, produced a newspaper called Thule that printed racist and anti-Semitic articles. The Swedish rock band Ultima Thule, a group popular with right-wing listeners and once sponsored by a neo-Nazi movement, released its latest album in 2015.

The reporter Meghan Bartels first turned up some of these troubling associations in 2018, when NASA announced the nickname. But most people, including some of the New Horizons scientists and engineers themselves, didn’t know of them until Bartels’s story in Newsweek resurfaced around New Year’s Eve. The public reaction was swift and critical, and the message was explicit: Don’t give NASA missions names with Nazi ties.

Alan Stern, the lead scientist on the New Horizons mission, defended their use of the name.

“I think New Horizons is an example, one of the best examples, in our time of raw exploration, and the term Ultima Thule—which is very old, many centuries old, possibly over 1,000 years old—is a wonderful meme for exploration,” Stern said at a press conference after the flyby. “And that’s why we chose it. And I would say that just because some bad guys once liked the term, we’re not going to let them hijack it.”

Words are malleable in this way, and language once used to disparage and discriminate can be reclaimed and repurposed. Taking back a phrase with negative associations is a form of power, especially when the shift is led by people that a slur once targeted. And perhaps Stern would have a stronger case if the negative valence of Ultima Thule had faded over decades, and the “bad guys” were a thing of the past. But Nazis and white supremacists are not yet confined to history books; they can still be found today in 4chan message boards or street protests in Charlottesville, Virginia, and even in European parliaments.

In the scientific community, Ultima Thule is officially called (486958) 2014 MU69, a designation generated from standard naming practices for distant space objects. A small, icy object 4 billion miles from Earth, it is shaped like a snowman and flat as a pancake, with a rich texture and no atmosphere. After NASA selected it as a flyby target, the agency decided to give the object a spicier nickname and asked the public to send nominations online and vote. NASA does this pretty often, for all sorts of targets and missions.

“Nomenclature is an important way of communicating from scientists to the nonscientific public, and how we choose names, what we choose to name, is a sign of what we think is important or interesting or exciting,” says Keith Noll, a planetary astronomer at NASA.

Ultima Thule placed seventh. (Mjölnir, the hammer of the mythical god Thor, was first; I blame Thor: Ragnarok, which premiered a month before the poll opened in 2017, for this.) “I had never heard the term Ultima Thule before we had our naming campaign,” Mark Showalter, a planetary astronomer at the SETI Institute and the New Horizons scientist who led the process, told Newsweek last year.

Showalter uncovered the Nazi associations as he went through the list, Bartels reported. But he and other scientists liked the original meaning of Ultima Thule, and it seems that the term’s long, dreamlike history outweighed the more recent, troubling connotations. “‘Beyond the limits of the known world’—that’s such a beautiful metaphor for what we’re doing this year,” he said to Newsweek. (Showalter did not respond to requests for an interview.)

And so NASA ran with the name, promoting it on social media and merchandise. Journalists (myself included) adopted it, too; after all, Ultima Thule is far more approachable than something that reads like a SKU code. Meanwhile, many scientists, on the New Horizons team and elsewhere, referred to the object exclusively as MU69. They knew that someday, MU69 would get a real name, arbitrated and approved by an international organization responsible for naming objects in the universe, from little asteroids to big stars.

The New Horizons team is already thinking about it. “We haven’t proposed a formal name yet, but we will later this year,” Stern told me this week.

Stern can’t propose the name himself. According to the International Astronomical Union, the duty rests with the discoverer of an object. In the case of MU69, that would be Marc Buie, an astronomer at the Southwest Research Institute and a New Horizons member who has spent a decade studying the object. Brainstorming the name is a team effort, but Buie must be the one who submits their final pick. And thanks to the public backlash against Ultima Thule, the process may be more difficult than usual.

“I’ve got naming rights on like 400, 500 other Kuiper Belt objects, and I just haven’t gotten around to them yet,” Buie told me. “I just have to get around to it and say, ‘I like this name,’ and just send it in, and it’s done, and there’s no drama. But that’s because nobody cares one way or another what name I give it. But here you’ve got something that’s in the public eye, it’s getting a lot of clicks, a lot of eyeballs, and everybody treats that pretty seriously these days.”

The controversy taps into a long-standing problem in space exploration. Humankind’s ventures into the cosmos are steeped in the same language that characterized their journeys on Earth; astronauts and spacecraft are cast as pioneers brave enough to conquer wild frontiers and perhaps colonize new worlds. NASA has mostly moved away from such terminology, but it remains in use, including, to give one recent example, by the vice president, who described the United States as “a nation of restless pioneers ever striving to explore uncharted territories” in a speech this week.

“Even the word ‘exploration’—as opposed to investigation, study, etc.—alongside ‘pioneer,’ ‘mariner,’ ‘clipper’ in mission names, bears a specific, heavy history that most of the world population directly relates to European colonialism,” wrote Divya M. Persaud, a planetary scientist, in a comprehensive exploration of the complicated language of space science.

A name, in particular, is a powerful thing. “The act of naming determines its social life, how everyone else will know it,” says Valerie Olson, an anthropologist at the University of California at Irvine who studies science experts, political leaders, and others who shape different environments. “Only certain people have the power to designate space place names, and each object’s name connects it to some kind of history or place.”

Yes, outer space is distant and cold and mostly empty. But after centuries of study and exploration, it is brimming with artifacts of our culture, politics, and other traditions. It is naive to think that space science—that any science, really—exists in a realm untouched by terrestrial opinions.

“The really interesting thing to me is, something so far away can be given a name that makes people upset here on Earth,” says Alice Gorman, a space archaeologist who studies the heritage of human-made objects in space. “It’s a really clear message that this stuff is not just space science. These things have an impact. Naming things in the solar system and naming celestial bodies actually reflects a version of Earth back to us.”

Buie said the group has considered several names, but declined to say what they were. The rules of the International Astronomical Union vary by object. Moons of Jupiter, for example, must be named after mythological figures who were either descendants or lovers of Jupiter, the Roman equivalent of Zeus. (Yes, astronomers are still finding new moons around Jupiter.) For stars, the shorter the name, the better. Kuiper Belt objects like MU69 should derive their name from mythology.

Ultima Thule might fit this requirement, should the team decide to go all in. But it could snag on other rules. The organization stipulates that names should be “non-offensive,” a determination for the committee to make. Names associated with political activities can’t be proposed unless 100 years have passed.

“You could argue that, well, we want to reclaim the name now,” says Noll, who is a member of the International Astronomical Union committee that decides the names for small bodies. “But unfortunately, it’s being used currently by white-supremacist groups ... That, to me, constitutes current political activity.”

Plus, there’s already a celestial body named Thule, an asteroid discovered in the 1880s. “We don’t normally use the same name twice for two objects,” Noll says. “And putting ‘ultima’ in front of it is sort of like saying ‘super.’”

Some scientists wish the New Horizons team never came up with a nickname in the first place, and for reasons unrelated to Nazis. “My biggest concern is writing scientific papers about this object,” Buie said. “Twenty years from now, somebody wants to search to find old work on it, and if I’m not using the name known to history, then people aren’t going to be able to find my work.”

I asked him what would happen if he doesn’t like the name everyone else—including Stern and other parties whose opinion would carry significant weight, such as NASA headquarters—gets behind. Given the weight this name now carries, would he really have a choice? “It doesn’t seem like it, but I don’t know,” he said. “If they come up with something and I say, ‘I can’t stand this; don’t do it,’ are they going to listen to me? Until it happens, I can’t know.”

If the team suggests—and the committee approves—something other than Ultima Thule, NASA will have to unleash a fresh round of publicity for the object. And it might be difficult to wrench away the current label after spending so much time trying to get the public to care about it. “People are going to connect that title to the object just because it was used in the public arena, in the flyby, no matter what we rename it,” says Susan Benecchi, an astronomer at the Planetary Science Institute and a New Horizons member.

Naturally, the scientists I spoke with hope that the public pays more attention to the findings from the New Horizons mission. The first batch appeared in the journal Science this week and found, among other things, that MU69 has remained in pristine condition since the tumultuous formation of the solar system billions of years ago. The International Astronomical Union gives discoverers 10 years to submit name proposals, but Buie and others are anxious to get this one done sooner rather than later.

“It was just an amazing find and an amazing investigation that’s going to rewrite textbooks for years to come,” he said.

We’ll have to see what those textbooks call it.



It is a truth universally acknowledged among virologists that a single virus, carrying a full set of genes, must be in want of a cell. A virus is just a collection of genes packaged into a capsule. It infiltrates and hijacks a living cell to make extra copies of itself. Those daughter viruses then bust out of their ailing host, and each finds a new cell to infect. Rinse, and repeat. This is how all viruses, from Ebola to influenza, are meant to work.

But Stéphane Blanc and his colleagues at the University of Montpellier have shown that one virus breaks all the rules.

Faba bean necrotic stunt virus, or FBNSV for short, infects legumes, and is spread through the bites of aphids. Its genes are split among eight segments, each of which is packaged into its own capsule. And, as Blanc’s team has now shown, these eight segments can reproduce themselves, even if they infect different cells. FBNSV needs all of its components, but it doesn’t need them in the same place. Indeed, this virus never seems to fully come together. It is always distributed, its existence spread between capsules and split among different host cells.

“This is truly a revolutionary result in virology,” says Siobain Duffy of Rutgers University, who wasn’t involved in the study. “Once again, viruses prove that they’ve had the evolutionary time to try just about every reproductive strategy, even ones that are hard for scientists to imagine.”

FBNSV is one of several “multipartite viruses” that split their genes among different capsules. These oddballs were first discovered in the 1940s, and though they account for about 20 percent of known viral species, they’re still rather obscure. Blanc thinks that’s because they almost always infect plants and fungi, and only two have been found in animals—one in a moth and one in a mosquito. “I lecture on several virology courses, and even people in Ph.D. programs haven’t heard of them,” he laments. “They’re everywhere, but because they’re mainly on plants, no one cares.”

These viruses have always been baffling, even to virologists who knew about them. Everyone assumed that they could only reproduce if all the segments infected the same host cell. But the risk of losing a piece, and so dooming the others, skyrockets as the number of pieces goes up. In 2012, two researchers calculated that the odds of successfully getting every segment in the same cell become too low with anything more than three or four segments. FBNSV, with its eight segments, “should never have evolved,” Blanc says. Its mere existence suggests “that something must be wrong in the conceptual framework of virology.”

Perhaps, he realized, these viruses don’t actually need to unite their segments in the same host cell. “If theory was saying that this is impossible, maybe the viruses just don’t do it,” he says. “And once we had this stupid idea, testing it was very easy.”

His colleagues Anne Sicard and Elodie Pirolles labeled pairs of FBNSV’s genes with molecules that glowed in different colors—red for one segment, for example, and green for another. Then, they simply looked down a microscope to see whether the colors overlapped in the same cells. They almost never did. When the team first saw that, “we were jumping and running around the lab,” Blanc says. “But we were also scared about it being a [mistake]. We took six years to verify it.”

For example, they showed that the levels of one segment aren’t tied to the levels of another, as you would expect if they were replicating in the same host cell. Instead, in any one infected plant, the different segments seem to accumulate at different rates.

But that discovery raised another problem. Each of the eight segments carries a gene with its own vital role. One makes the proteins that copy the virus’s DNA once it gets inside its hosts. Another creates the proteins that form the virus’s capsules. See the problem? If these segments end up in different cells, the DNA-copying one shouldn’t be able to make capsules, the capsule-making gene shouldn’t be able to copy itself, and both of them would be stuck.

That doesn’t happen, the team discovered, because the virus’s genes might be stuck in neighboring cells, but the proteins created by those genes can move. The capsule-making protein can get into a cell with the DNA-copying gene, and cover it. The DNA-making protein can get into a cell with the capsule-making gene, and copy it. Think of the eight segments as factories in different cities, shipping assembly robots to one another so that each site can manufacture its own separate product. It is within this expansive trade network that the distributed virus truly exists.  

It’s not clear how this network operates, but many scientists have found that plant proteins can voyage between cells, even over long distances from root to shoot. Some researchers who study multipartite viruses have even suggested that they could make use of these botanical highways. But Blanc’s team has now found clear and unambiguous evidence that they do. Perhaps, he says, “this is why multipartite viruses don’t exist so much in animals. Maybe it’s harder for our proteins to travel between cells.”

“The work is very important … and very carefully done,” says Marilyn Roossinck of Pennsylvania State University. For decades, she has been studying a different multipartite virus that affects cucumbers, and though she has seen some of the patterns that Blanc’s team did, “these were never published, as their significance wasn’t clear,” she says.

“This report challenges a fundamental assumption of virology,” adds Rodrigo Almeida of the University of California at Berkeley, who studies plant diseases. “I am not aware of any similar example in biology, where genetic information appears to be split among host cells.”

The closest example I can think of exists in cicadas. These noisy insects rely on a bacterium called Hodgkinia, which lives inside their cells and provides them with nutrients. But this one bacterium has fractured into several daughter species, each of which contains just a few of Hodgkinia’s full set of genes. None of these partial microbes can survive on its own; they only function as a set. But these daughter species are all still locked within the same cell, so they’re not truly distributed as the virus is. They are also problematic: If any of them were to disappear, the rest would also die out, as would their cicada host. Hodgkinia’s fragmented existence is a looming disaster—“a slow-motion extinction event,” according to John McCutcheon, who described it.

By contrast, multipartite viruses are clearly very successful, so their bizarre distributed existence must have some benefit. And Blanc thinks he knows what that might be.

His team has shown that when FBNSV infects a plant, the frequency of each segment is very predictable. Some of them are common and others are rare, but their relative proportions are constant, at least within a given species of plant. If the virus infects a different plant species, those proportions change—to a different, but still predictable, pattern. Blanc calls these “genome formulas”—ratios of genes that FBNSV uses for different hosts.

The virus’s use of these formulas reminds Blanc of the ways in which animals and other complex organisms adapt to different environments by tweaking the numbers of important genes. In very rough terms, the more copies you have, the more effectively that gene can do its thing. But viruses are tiny entities, whose capsules only have room for small genomes. There’s not enough space for them to just wantonly double their gene counts.

Multipartite viruses don’t have to. If they want to emphasize the use of a certain gene, they just need to get the segment carrying it into more host cells. “This lifestyle allows the virus to adjust its gene copy number without mutating,” Blanc says. It’s as if FBNSV has found a way to have the flexibility of a much larger and more complex genome, while still keeping the unflinching efficiency of a virus.

These discoveries could also change our understanding of other more traditional viruses. Influenza’s genome is split into eight segments, and unlike FBNSV, all of these are packaged into the same capsule. Researchers typically assume that every capsule contains the full octet, but in 2013, Christopher Brooke of the University of Illinois showed that 90 percent of them are missing at least one segment. Influenza virus “exists primarily as a swarm of complementation-dependent, semi-infectious virions,” Brooke wrote.

Three years later, a different team showed that the same is true for the virus behind Rift Valley fever: Only a minority contain all three of the virus’s gene segments, and most are missing one. “Perhaps the boundary between these viruses and the multipartite ones isn’t so clear,” Blanc says.

Many viruses also produce capsules called “defective interfering particles,” which … well, the clue’s in the name. They’re defective because, for some reason, they’ve lost part of their full genome. They’re interfering because, though they’re defective, their parent viruses will still make copies of them, flooding the total pool of capsules with noninfective deadbeats. “These things have been known for a century, and they’ve long been considered as junk,” Blanc says. “But they are very efficiently maintained in any viral infection. Maybe they can profit from the system we have identified.”



The experiment really shouldn’t have worked. Several years ago, Laura Duvall from Rockefeller University decided to feed mosquitoes with experimental drugs designed to suppress the appetite of humans. Perhaps these chemicals might also reduce the insects’ appetite for blood? And, by extension, stop them from biting people and spreading diseases?

“The whole thing started off as a joke,” says Leslie Vosshall, who led the study. “The assumption was that the human drugs would kill the animal or have no effect. It was a stupid thing.”

So imagine her surprise when it worked.

The Aedes aegypti mosquito, which spreads dengue and Zika, is an exceptional human hunter, drawn to our body heat, odors, and exhalations. When a female finds and bites a person, she doubles her body weight in blood, before lapsing into a days-long food coma. During that time, while she slowly digests the blood and converts it into eggs, “her interest in human cues is dialed down to zero,” Vosshall says. “You can put your hand in a cage of blood-fed females and you won’t get a bite.”

That switch between relentless hunter and disinterested layabout is so stark that about a decade ago, Vosshall started wondering if she could control it. She focused on a small protein called neuropeptide Y, or NPY. Among its many roles, it acts as a universal appetite controller, influencing feelings of hunger across the animal kingdom. Its exact effect varies among species: It drives flies and humans to eat but, as Duvall found, it does the opposite in mosquitoes, suppressing their appetite.

NPY acts by sticking to receptor proteins, and the pharmaceutical industry has tried to develop appetite-controlling drugs that target these receptors. Duvall got her hands on some of these drugs five years ago, and fed them to Aedes mosquitoes. She then put the insects in a trap that was baited at one end with a stocking that she had worn on her arm. Normally, unfed mosquitoes would “go toward eau de Laura,” Vosshall says. But after swallowing drugs that stimulate NPY receptors, their attraction to her scent fell by 80 percent. They hadn’t drunk any blood, but they were behaving like mosquitoes that had.

By contrast, drugs that block NPY receptors had the opposite effect. “This was the first time we’d ever seen a blood-fed mosquito getting up off the floor of its cage, staggering around with a full belly, and trying to bite someone,” Vosshall says. “Surprises and successes in biology are few and far between, so that was a good week for us.”

Humans have only four NPY receptors, but Aedes mosquitoes have 49. Duvall found that the human drugs act primarily on just one of these—lucky number seven, as it happens. She then searched for other drugs that hit that seventh mosquito receptor more effectively, and, crucially, don’t work on the four human ones. She found several, the best of which she simply referred to as compound 18.

As a final test, Duvall placed anesthetized mice in cages with three groups of mosquitoes that were, respectively, unfed, blood-fed, or dosed with compound 18. (She distinguished between the three groups by first shaking them in bags filled with red, blue, or yellow paint powder.) After 15 minutes, most of the unfed females had bitten the poor rodents, while the others had largely ignored the meal on offer. Compound 18 had successfully duplicated the satiating effect of a blood-filled stomach, and stopped the mosquitoes from biting.

This study “is [a] tour de force of techniques and ingenuity,” says Zainulabeuddin Syed from the University of Kentucky. “It is a significant milestone in research on mosquito sensory biology,” which builds on decades-old foundations laid by researchers such as Mark Klowden of the University of Idaho, who showed that blood-fed mosquitoes don’t bite.

Vosshall thinks it should be possible to bait mosquito traps with NPY-targeting chemicals to dose the insects in more realistic conditions. “There are already surveillance traps that work by attracting mosquitoes,” she says. “We’d just need to engineer a feeding cup where we can put in our drug.”

Such traps don’t lure beneficial insects, so the drugs have little chance of unintentionally getting into, say, pollinators such as bees or butterflies. And since NPY receptors are so similar across species, Vosshall thinks that the same approach could help to control other vector-borne diseases. “I got Lyme disease earlier this year, so I’m very interested in that,” she says. “We know these drugs work on Lyme vectors, so you’d just need a different tick-specific delivery system. It’s all in the art of the trap.”

Compound 18 and other such drugs aren’t ready for widespread use, though. The team still needs to optimize these chemicals so that they work at low doses. Even then, “the drugs would need to be cheap enough to deploy in the field, and stable enough to sit out for six months,” Vosshall says. “You can’t have someone change the traps every day.”

Another hitch: For now, the appetite-suppressing effect wears off after just two or three days. That’s the biggest limitation, says Lisa Reimer from the Liverpool School of Tropical Medicine. The drug could also have unintended consequences. “Is it possible that mosquitoes with temporarily suppressed blood-feeding might live longer?” she asks.

Still, Reimer adds that she’s “enthusiastic” about the new study, as is Nsa Dada from the Centers for Disease Control and Prevention, speaking in a personal capacity. “As mosquitoes have become increasingly resistant to insecticides, we are continuously seeking other, easier, and safer alternatives for mosquito control,” Dada says. “This work is therefore important and very timely.”

Other scientists are looking to kill mosquitoes with fungi, or to load the insects with bacteria that stop them from carrying viruses, or to reduce their numbers with the gene-editing technique called CRISPR. None of these is a panacea, but given how many people are affected by mosquito-borne diseases, new ideas are always welcome. Suppressing their hunger is “a fresh look at how we can deal with this problem,” Vosshall says.



When vine-curious Brooklynites walk into Tula Plants and Design—a small houseplant shop in Greenpoint with a vibrant Instagram presence and a profusion of leaves on every available horizontal surface—the employees know what questions to expect.

There are two, according to Ariel Ries, an employee at the store. The first is, “Will this plant kill my pet?” The second is, “What kind of plants are best for cleaning the air?”

Of all the 1970s trends that have enjoyed a resurgence in recent years—astrology, Fleetwood Mac, and special-counsel investigations among them—few have shown the explosive growth of houseplants and indoor gardening. “More American households are gardening than ever before (77 percent),” bragged a recent press release from the National Gardening Survey, “and increasingly the gardener is a young man.”

As a young man, I can vouch: I am increasingly the gardener. (I own seven plants.) Of the 6 million Americans who took up gardening in 2016, 5 million were Millennials like me, according to the survey, an annual poll conducted by a nonprofit advocacy group. Gardening is now a $47 billion industry in the United States, with the average gardener household spending a record $503 on plants and materials annually. (I have spent $63.)

Houseplants have much to recommend them. They’re fun to care for, they look good on Instagram, and they express environmental angst through interior design. But one of houseplants’ most commonly repeated virtues holds that they’re not only living tchotchkes, but also little HVAC machines: Houseplants, allegedly, filter the air. The Sill, an online plant store that communicates its Millennial bona fides through chunky serifs and large splotches of white space, lists plant species by the airborne toxins they are best at removing. (Philodendrons filter formaldehyde.) Yet interest in this particular plant benefit is not limited to the self-care set. The same question has landed listicles in the patrician This Old House, the nerdy Lifehacker, and a doomsday-prepper blog.

For several years, research really did suggest that houseplants might cleanse the air of certain pollutants. But now most scientists say that’s not right.

“It’s such an alluring and enticing idea,” Elliott Gall, a Portland State University professor, told me. “But the scientific literature shows that indoor houseplants—as would be typically implemented in a person’s home—do very little to clean the air.”

“My view is even harsher than that,” Michael Waring, an engineering professor at Drexel University, told me. “I do not think that houseplants clean the air.”

“A resounding ‘no,’” agreed Richard Corsi, a longtime air-pollution researcher, in an email. Houseplants do not clean the air “any more than an old pair of socks or baseball cap that I would hang on the wall.”

Why the confusion? Big Succulent isn’t lying to you, though at this point the houseplant industry is cherry-picking data. But for plants to actually improve the air, even in a compact apartment, you’d need a concentration of houseplants that only the most dedicated plant lovers can actually achieve.

In the late 1980s, the NASA scientist Bill Wolverton investigated whether common houseplants could remove a certain type of air pollutant, called “volatile organic compounds,” or VOCs, from the air. VOCs are regularly released by common household products such as drywall, house paints, nail polish, shampoo, and almost anything with a scent. Their harmful effects can range from an itchy throat to nasopharyngeal cancer.

Unlike other types of air pollution, such as soot or particulate matter, VOCs can’t be filtered out of the air with a fine-grade filter. This means that they can build up in hermetically sealed environments … such as laboratories or spacecraft. The problem for NASA was obvious. So Wolverton, a former military scientist who began his career studying whether plants could break down Agent Orange, now examined whether houseplants could absorb VOCs.

His 1989 report announced a cheerful answer. Plants were “a promising, economical solution to indoor air pollution,” it declared. “If man is to move into closed environments, on Earth or in space, he must take along nature’s life support system.” The report—jointly funded by NASA and the Associated Landscape Contractors of America, a trade group—was picked up by the media. The idea gained even more currency in 1996, when Wolverton published How to Grow Fresh Air: 50 Houseplants That Purify Your Home or Office. (Wolverton did not respond to a request for comment.)

That study provides the scientific basis for almost all the plant-and-air-pollution content you see online. “I’ve seen it on so many pop internet sites—‘researchers from NASA’ is the common phrase you see,” Waring, the Drexel professor, said. He told me that there’s nothing especially wrong with Wolverton’s 1989 study. Its results “fall right in line with other stuff that’s been measured in the literature.”

But taking its results at face value significantly overstates the power of plants, he said. Wolverton measured whether houseplants could remove VOCs from an airtight laboratory environment. But a home is not a hermetic chamber. It has open windows and doors, drafts and leaks, and much more clutter.

Recently, Waring and his colleagues reanalyzed all 195 studies that have examined whether houseplants can filter the air. They found that some types of plants can remove higher amounts of VOCs than others. But once you factor in the effects of working in a large room, none of the plants are able to do much.

Waring told me to imagine a small office, 10 feet by 10 feet by eight feet. “You would have to put 1,000 plants in that office to have the same air-cleaning capacity of just changing over the air once per hour, which is the typical air-exchange rate in an office ventilation system,” he said. That’s 10 plants per square foot of floor space. Even if you chose the most effective type of VOC-filtering plant, you would still need one plant per square foot, Waring said.

Or as Waring (who owns 10 to 20 houseplants) recently put it in a presentation for the National Academies of Sciences, Engineering, and Medicine:

But maybe scientists have been researching the wrong pollutant. Several years ago, a team of researchers examined whether houseplants could remove ground-level ozone. Ozone’s effects are often described as “sunburn inside your lungs,” and can cause painful breathing, asthma attacks, and even the chronic lung disease COPD.

More than 107 million Americans live in areas with unhealthy amounts of ozone, according to the Environmental Protection Agency. Unfortunately, houseplants can’t do much about that, either. The researchers found that even the most effective plants barely reduced the level of ozone in indoor spaces. “If ozone levels were 30 parts per billion in your home, then you might reduce them to like 29.7 parts per billion,” said Gall, the Portland State professor and a co-author of the study. (He owns no houseplants. “When I did a postdoc in Singapore, we had two big houseplants we were excited about and loved, but then we had ant problems for the next two years,” he said.)

Houseplants are just outcompeted. Gall told me to look at the surface area of houseplants in your home, and then to consider the surface area of every other object in your home—the walls, the spray bottles, the couch cushions, everything. “The surface area of any vegetation is just very, very low compared with everything else that could function as a source or a sink” for air pollutants, he said.

To start to even marginally reduce indoor ozone, Gall estimated that you would need at least one houseplant for every 20 square feet of floor space. “And there are downsides to that,” he said. “You wind up having a living system in the space, and that might raise indoor humidity and cause other problems.”

Hilton Carter enjoys having a living system in his space. Carter is a filmmaker and designer whose plant-focused Instagram account has more than 163,000 followers. He told me he keeps about 185 plants in his 950-square-foot apartment in Baltimore, roughly one plant for every five square feet. “You can feel the difference in a space that’s filled with plants as opposed to a space that isn’t,” he said. “Right now, my home feels a bit more humid than it would without those plants in there.”

This humidity, while great in the winter, did somewhat limit his decoration options. “If you want to have furniture in there, it probably wouldn’t be as wise,” he said. But it’s worth it: He loves the feel of a space with plants, even if they don’t purify the air as he thought.

Yet even Carter’s apartment did not meet the strict quota for VOCs. Not even Instagram-famous plant density can cleanse a room. In fact, I found only one place that achieved one plant per square foot: Tula Plants and Design. Ries told me that the 800-square-foot store will regularly have more than 800 plants for days after a delivery. (On the day I called, it had 750.)

And Ries, as it happened, was familiar with the original Wolverton study. The store regularly shows it to customers who ask about the best air-purifying plants, she said, though employees also warn them that the study measured something very specific and was “definitely different than how it would be in our real environment.” Often, patrons walk away with peace lilies. I asked whether the newer science might change Tula’s recommendations.

“I guess I could imagine putting peace lilies all over the place. Then your home would be very full of peace lilies,” Ries said. “But unless you really loved peace lilies and snake plants, it might not be something that brings you joy.” And joy, not marginal air pollution, is the real reason to own a plant. I said that I still loved my new plants, even if they didn’t make my apartment’s air any cleaner.

“Bringing plants in, bringing greenery in—it’s about having something near you that’s alive, that you’re caring for, that brings you joy and happiness,” she said. “And that affects your mood, whether or not it’s giving you more oxygen to breathe or something.”



In 2008, scientists working in Denisova Cave—a cold site in Siberia’s Altai Mountains—uncovered a strange pinky bone, broader than a typical human’s. The DNA within that bone revealed that its owner belonged to an entirely new group of ancient hominins, distinct from Homo sapiens or Neanderthals. That group became known as the Denisovans.

Researchers have since decoded the Denisovan genome. But still, no one can say what they looked like. Every known Denisovan fossil would fit in your palm—that pinky, three teeth, and a remarkable bone sliver from a Denisovan-Neanderthal hybrid. And all of these remains came from the same cave.

But now, an international team of scientists has announced the identification of another Denisovan fossil, from a site 1,500 miles away. It’s the right half of a jawbone, found some 10,700 feet above sea level in a cave in China’s Xiahe County, on the eastern edge of the Tibetan plateau. The Xiahe mandible, as it is now known, is not only the first Denisovan fossil to be found outside Denisova Cave, but also the very first Denisovan fossil to be found at all. It just took four decades for anyone to realize that.

The mandible was discovered by a local monk in 1980 and donated to Lanzhou University. There, it lay unstudied until 2010, when a team led by Fahu Chen and Dongju Zhang—a climatologist and an archaeologist, respectively—began examining it in earnest. The world learned about the existence of the Denisovans at around that time, and though fossils had only been recovered from Siberia, it was clear that these hominins likely existed throughout much of East Asia. Smatterings of Denisovan DNA still persist in the genes of living people in this region and beyond, and how else could it have made it into the genomes of modern Tibetans or Melanesians? Still, “I never imagined that [the Xiahe mandible] could be a Denisovan,” Zhang says.

“If it was one, we’d be so lucky,” she adds.

The mandible itself is very thick and sturdy. It has no chin, which rules out modern humans. The teeth within it are exceptionally large, and different in shape and size from those of Neanderthals, Homo erectus, and other known hominins.

The molecules in the specimen were especially telling. The team couldn’t detect any traces of ancient DNA, but it did find the next best thing—fragments of ancient collagen proteins, still lurking in one of the teeth. These fragments closely resemble the proteins of Denisovans, more so than those of Neanderthals, modern humans, or other great apes.

But Katerina Douka of the Max Planck Institute for the Science of Human History notes that methods for analyzing ancient proteins are relatively new, and less well tested than those for studying ancient DNA. Researchers should use both techniques on other specimens to check that they give the same results, Douka says. But for now, based on the data that exist, she agrees that the Xiahe mandible most likely belonged to a Denisovan.

“It confirms that the Denisovans were perhaps widely distributed through East Asia,” Zhang says. For years, scientists had suspected as much. After all, people across East Asia and Melanesia (the region that includes New Guinea and its neighboring islands) have Denisovan DNA in their genes. This pattern—the product of ancient sexual encounters between Denisovans and humans—shouldn’t be possible if the Denisovans were just confined to a small Siberian cave. Instead, it seemed that they were already living in much of East Asia by the time ancient humans also spread through the region.

Indeed, the Xiahe mandible, which is 160,000 years old, is by far the earliest hominin fossil from the Tibetan plateau. Researchers used to think that Homo sapiens was unique in adapting to the Himalayas, but the Denisovans were successfully living on the roof of the world at least 120,000 years earlier. They must also have adapted to extremely thin air—after all, the mandible was found in a cave that’s some 8,000 feet higher above sea level than Denisova itself. “Their presence that high up is truly astonishing,” Douka says.

This helps to explain a remarkable finding from 2014. Back then, Emilia Huerta-Sanchez and her colleagues showed that most Tibetan people carry a mutated version of the EPAS1 gene, which helps them cope with high-altitude air that has 40 percent less oxygen than what most people breathe. And that mutation, the team showed, came from Denisovans. By having sex with these hominins, ancient Tibetans picked up a useful genetic trait that their descendants still benefit from.

That result was surprising, because Denisova Cave is so far from Tibet, and so much lower in altitude. The new mandible resolves that discrepancy. Although it’s unclear whether its owner had the same EPAS1 variant that the other Denisovans did, it at least shows that Denisovans were in the right part of the world. “I was thrilled that they found a Denisovan-like jawbone at high altitude,” Huerta-Sanchez says.

“The new discovery is an important step in understanding the Denisovans, but the big question still remains to be solved,” says Yousuke Kaifu of the National Museum of Nature and Science, Tokyo. And that is: If Denisovans were spread throughout Asia, why do Melanesians have so much more of their DNA than anyone else—5 percent, compared with just 0.2 percent in East Asians, and nothing in other groups?

To answer that question, scientists will need to find more Denisovan bones. Douka and her colleagues have started a project called Finder to do exactly that, by rapidly analyzing small, unidentifiable slivers from various sites in Asia. More intact specimens might also be lying around in museum collections. For example, the Xiahe team notes that its mandible has many similarities to the Penghu 1 mandible, which was fished out of the ocean near Taiwan in 2008. (“I agree that there are some similarities,” says Kaifu, who led the team that analyzed Penghu 1 in 2015.)

China has a long list of similar hominin fossils that have been hard to assign to other species. “Some of those may already be Denisovans,” Zhang says.



Sue Smrekar wishes she could be on Mars right now.

Specifically on Elysium Planitia, a smooth plain in the planet’s northern hemisphere, where a NASA spacecraft called InSight resides. InSight touched down on the surface last November and used its robotic arm and five-fingered hand to unpack. The cider-colored ground was soon littered with scientific instruments, like a well-arranged picnic spread. Once the spacecraft had settled in by late February, one of the instruments, a probe designed to burrow deep into the Martian ground, started hammering away.

Then, suddenly, it stopped. After traveling 300 million miles to Mars, the probe got stuck just inches below the surface. It has remained wedged there since, but NASA hopes a delicate rescue operation could soon free it.

“We’d hoped to be well into the ground by now,” Smrekar, the deputy principal investigator of the InSight mission at NASA’s Jet Propulsion Laboratory, told me.

NASA dispatched InSight to Mars to study the interior of the Red Planet, which, even after many decades of missions, scientists still know little about. The mission would help scientists determine what Mars is like on the inside, and whether its guts resemble another rocky planet—our own.

The probe, made up of a spike and a sensor-studded tether, is designed to burrow nearly 16 feet into the surface. That’s deeper than previous instruments have gone “on any other planet, moon, or asteroid,” according to NASA (excluding Earth, of course). The tether was supposed to follow the spike down and measure the heat coming from the planet’s interior. The machine only made it 12 inches. “It initially was making fabulous progress, and then just abruptly stopped moving forward,” Smrekar said.

The team was stunned. Maybe the instrument had hit a rock, they thought. The scientists and engineers of the InSight mission had prepared for such a scenario; during testing before launch, the heat probe, which they call “the mole,” had shown it could break some rocks and even maneuver around others. The team instructed the mole to keep hammering, in case the force shattered the obstacle, but that didn’t help.

Scientists now suspect another culprit: the Martian soil itself. As the probe hammered, loose dirt was supposed to swirl around it, providing friction for its back-and-forth movements. But the soil might have clumped together instead and moved away from the instrument. Eventually, a moat of empty space could have emerged between them. “Some friction is essential for the mechanism to work, as the recoil produced by the mechanism during hammering needs to be absorbed,” says Matthias Grott, a scientist at the German Aerospace Center’s Institute of Planetary Research, which built the instrument for NASA. Without that friction, the probe just bounces in place.

Spacecraft have never encountered such difficult soil on Mars before, and the probe wasn’t designed to handle it. Scientists have since recreated these conditions back on Earth, with a replica of the heat probe and stickier sand; the experiment, in an outcome that is both reassuring and disheartening, showed that the probe could indeed become stuck like this.

The circumstances are certainly unexpected, but not insurmountable. The team could generate some friction by using a scoop on the robotic arm to drop some soil into the space around the probe or apply pressure to the ground.

If only they could see anything.

InSight’s cameras can take pictures of its surroundings to send home, but they don’t have eyes on the problem. The probe arrived in a cylindrical case that holds it steady until it drills itself free, but only made it out so far before becoming stuck. The case now blocks InSight’s view of the probe and the surrounding regolith.

So the InSight team has devised a rather clever plan. They will use the robotic arm to lift the case, little by little, to get a better look at the probe beneath.

It’s a risky operation. If they end up pulling the probe out of the ground, they can’t stick it back in. InSight’s robotic arm was designed to clutch the case, not handle the probe. So they will command the spacecraft to move carefully, like a stop-motion animator adjusting clay after every take: Lift a little, back off, take a picture, beam it home. The spacecraft is scheduled to attempt this maneuver for the first time tomorrow, raising the case a mere five inches. More attempts are planned for next week. With a better view, the team can confirm the problem and determine a fix.

Here’s a look at the robotic hand unfurling in preparation for the procedure, seen in shadows across the Martian surface:

For now, mission staff are trying to look on the bright side. InSight’s other instruments are working fine; in April, the seismometer detected, for the first time in history, a Marsquake. It has even pitched in to provide data about the probe’s unlucky surroundings, recording the rumbling that resulted from its failed hammering attempts. And besides, it’s better to have a jammed probe now, when one end of it is still sticking out of the ground and within reach, than after it goes subterranean. “If the mole were in the ground and hit a rock, there’s nothing we could do to help,” says Troy Hudson, a scientist and engineer at the Jet Propulsion Laboratory. “The arm isn’t powerful enough to excavate it.”

And the team has already learned something new about the Martian landscape. “If you asked somebody, ‘What’s the soil on Earth like?’ Well, it depends greatly on where you are. Is it beach sand on Hawaii or loamy soil in Arkansas?” Hudson says. “Mars is a lot more homogenous than Earth, but it’s still an entire planet and soil types are going to be different in different locations.”

InSight’s heat probe is not yet lost, but if the rescue mission goes south, it won’t be the first NASA spacecraft to succumb to Mars and its surprises. In 2009, the Spirit rover became trapped in a sandpit and was unable to reach a slope from which to charge its solar-powered panels. Last year, Opportunity, Spirit’s sister rover, met a similar fate when a dust storm of unprecedented size swept across the planet and blocked sunlight from reaching its panels.

Any time a mission doesn’t go exactly as planned, there are scientists and engineers worrying and troubleshooting and pacing back home, wishing they could be there to help. Before Opportunity was declared dead, Keri Bean, a science planner on the mission, told me she dreamt about saving it. “Sometimes I’ll have dreams in the middle of the night. I’m standing there on Mars next to her, and wiping the dust off her lenses,” she said.

The reality is far more frustrating. This week, at a meeting of InSight scientists in Paris, Smrekar listened to a colleague describe a recent test with a replica of the heat probe. It had rained, and a box of sand, playing the role of Martian soil, became damp and sticky. The instrument couldn’t move, so the scientist pressed a finger to the probe, applying a hint of pressure to get it going again. That’s all it took—on Earth. On Mars, NASA needs a breakthrough.



Almost two years ago, with no regard for safety precautions or protocol, President Donald Trump faced the sun head-on. As the rest of us watched the solar eclipse through specially purchased glasses or cereal boxes outfitted with X-acto-knifed slots, President Trump squinted unblinkingly into the bright, unfiltered sunlight and emerged unscathed. Then, on Friday, he came for the moon.

Less than three months ago, Vice President Mike Pence announced that the Trump administration’s goal of sending a crew to the moon by 2028 would be accelerated by four years; in the past month, the president has said that he wants an additional $1.6 billion dedicated to that aim. But in a tweet sent Friday afternoon, the president chastised NASA for doing exactly the job he’d instructed it to do. “NASA should NOT be talking about going to the Moon,” he wrote. “They should be focused on the much bigger things we are doing.”

For all of the money we are spending, NASA should NOT be talking about going to the Moon - We did that 50 years ago. They should be focused on the much bigger things we are doing, including Mars (of which the Moon is a part), Defense and Science!

The moon, Trump’s tweet seems to imply, is a boring destination. Too old-school, too small potatoes, too … reachable. Trump isn’t the first president to suggest a return to the moon, and he’s also not the first to suggest skipping that costly, time-consuming, already-made trip in favor of putting a foot on Mars. But he’s the first to muddle both plans in quite this way. (When he noted that the moon is a part of Mars—it’s not—he may have meant that many see a moon base as a stepping-stone to a Mars mission.)

The backtracking implied by Trump’s tweet carries enormous weight for a government agency that’s all too familiar with the bait and switch of being redirected halfway through a project. NASA has a long legacy of being hampered by presidential turnovers, which can hinder any worthwhile, groundbreaking project from making it to fruition. NASA’s most important accomplishments have spanned presidencies and required agreement across administrations. Barack Obama spent his time in office pushing for a decades-away Mars mission—exactly what it appears Trump, who cut Obama’s plans off at the pass with his moon-and-militia fixation, now wants.

Since it was established by President Dwight Eisenhower in 1958, NASA has had to weather the blows of presidential whims time and time again: Trump’s swing from Mars to the moon and back again is only the latest iteration of an ongoing pattern.

John F. Kennedy: Mars—No, Wait, the Moon

Before John F. Kennedy wanted to go to the moon, he wanted to land on Mars. But NASA’s associate administrator, Robert Seamans Jr., insisted that the moon was a more achievable goal, and warned Kennedy against laying out a plan destined to fail. It was during the Kennedy administration that the idea of the moon as a necessary step to human arrival on Mars first emerged, but ultimately the moon was promoted to the more realistic destination of choice.

Kennedy’s famous call for lunar ascendancy drove NASA’s feverish agenda in its early years. In 1961, when work on the Apollo program began, NASA’s budget was increased by 89 percent. Getting to the moon was of unwavering political importance.

Lyndon B. Johnson: The Moon

During his years as Senate majority leader, Johnson had helped spur the creation of NASA by putting pressure on President Eisenhower to respond to Russian space activity. He continued to nurture the Apollo program throughout his presidency, but the attention and money diverted toward the Vietnam War meant that little planning was done for any continued space exploration. The moon landing, scheduled for the end of the decade, was still the goal.

Richard Nixon: The Moon (We Made It!)

Nixon presided over the celebrated 1969 moon landing, but his attitude toward the rest of the cosmos remained reserved and flatly unambitious. NASA wanted to launch a 20-year Mars mission; the president refused to discuss the possibility.

Gerald Ford: Earth Orbit Only

During Ford’s three-year tenure, a U.S. Apollo module docked with a Soviet Soyuz spacecraft during the 1975 “handshake in space”—part of the Russian-American Apollo-Soyuz Test Project. Ford, a longtime NASA supporter, continued to develop the Space Shuttle program, which aimed only to reach Earth orbit. He made no public plans for a return trip to the moon or anywhere beyond. One lunar landing was enough.

Jimmy Carter: Earth Orbit

In 1979, when the Space Shuttle program ran into technical challenges, President Carter considered shutting it down, though he ultimately decided not to. Human spaceflight fell by the wayside during Carter’s administration. Privately, though, Jimmy was a dreamer: According to multiple accounts, he expressed abstractly a belief that human civilization would one day extend beyond Earth.

Ronald Reagan: Earth Orbit

President Reagan energetically supported human spaceflight and enjoyed the grandiosity of Space Shuttle launches. He wanted commercial interests involved in spacefaring, with satellite placements and other innovations. But even reaching Earth orbit started to seem fraught after the Challenger disaster in 1986, which left the administration shaken and hesitant to push other planned launches forward.

George H. W. Bush: The Moon and Mars

Bush took office ready to champion NASA into a new era of human spaceflight. On the 20th anniversary of the Apollo 11 landing, he announced an ambitious Space Exploration Initiative with two clear goals: Put a man back on the moon, and put a man on Mars. Bush talked a big game, but his far-reaching plans were dead on arrival: NASA’s resources were already stretched thin by the Space Shuttle program and the creation of a space station.

Bill Clinton: Earth Orbit, Again

Clinton had none of his predecessor’s starry-eyed ambitions for space exploration. Though he kept the space-station program alive, against the advice of his budget director, Clinton said that a crewed mission to Mars was too expensive to even consider. He was keen to search for evidence of life there—but only if robots were doing the work.

George W. Bush: The Moon and Mars

Once again, a new president meant a pivot for the executive branch’s aspirations beyond Earth. In 2004, Bush laid out his Vision for Space Exploration, which, much like his father’s preferred plan, imagined a moon landing—this time for 2020—as a stepping-stone for a future Mars mission. Work was to begin after the completion of the space station and the subsequent retirement of the Space Shuttle fleet in 2010—after Bush’s term.

Barack Obama: Mars

Less than a year after being sworn in, President Obama canceled the plans Bush had set in motion for a crewed moon mission. Instead, the president began to push the idea of skipping the moon altogether and instead allocating funds to begin construction on landers for a 2030s trip to Mars.

Donald Trump: The Moon—Or, Maybe, Mars? 

When he first came into office, Donald Trump knew he wanted to send astronauts to some other spot in the solar system—he didn’t seem too hung up on the exact destination. But, perhaps because he wants to witness a NASA milestone before leaving office, soon he was talking about reaching the moon before 2024. Putting together a crewed lunar mission in the next few years was always going to be hard; perhaps the president now understands that NASA might as well be dreaming bigger and on longer timelines.



Think about the dreaminess of twilight, when the sun has slipped below the horizon, and the darkening sky is streaked with dusky purples and blues. There, among the emerging stars and the silvery moon, lustrous as a pearl, you see it—an ad for a soda company.

This was the future envisioned by PepsiCo, specifically the corporation’s division in Russia. According to a recent story by Futurism’s Jon Christian, the branch planned to launch an “orbital billboard,” a cluster of small satellites flying in formation, like migratory birds that want to sell you something. The ad would orbit more than 250 miles above Earth, at about the same altitude as the International Space Station. In the early morning and evening, little sails on the satellites, made of reflective Mylar, would catch the light of the sun and become visible to the ground. The artificial constellation, blinking a logo, would promote Adrenaline Rush, a PepsiCo Russia energy drink aimed at gamers.

A Russian company has already tested a prototype using a helium balloon that carried one of its reflectors into the stratosphere, a layer of Earth’s atmosphere far below the edge of space, Futurism reported. But that’s apparently as far as this effort is going to get; this week, a PepsiCo spokesperson in the United States shot down the idea, saying there had been a miscommunication between Russian and American PepsiCo employees, perhaps because of a “language issue.”

No one has ever put a billboard of satellites like this into orbit. But companies have proposed advertising in space for decades, even on the surface of the moon. They want as many eyes on their ads as possible, and they’ll fill up blank spaces where they can find them, from the sides of skyscrapers to the in-flight maps on airplanes. What’s a better blank space than, well, space?

Pepsi’s obsession with decorating the skies actually goes back decades. The fascination began years before man or satellite left Earth, in the 1920s. Pilots started running paraffin oil through their planes’ exhaust pipes and zigzagging through the clouds, leaving fluffy trails of white smoke behind them. Skywriting, risky and mesmerizing, was “considered the future of advertising,” as Adrienne LaFrance wrote in The Atlantic in 2014. Companies lunged at it, Pepsi hardest of all. In 1940 alone, it paid for about 2,225 writings over 48 U.S. states, Mexico, Canada, Cuba, and South America, according to the Smithsonian’s National Air and Space Museum. The corporation became one of the longest-running contractors in the skywriting business.

Then NASA came along, and after a few missions to the moon, the agency started sending astronauts to space on the Space Shuttles in the early 1980s. The effort garnered tremendous media attention and public interest. Brands, naturally, wanted in. In 1984, Coca-Cola asked NASA to take a can of soda along on a shuttle flight. When Pepsi heard about it, it offered one of its cans, too.

The rival companies designed cans that would work in weightlessness, with special valves to dispense the soda. According to a New York Times story, the Coke can cost $250,000 to develop. The Pepsi can cost—are you ready?—$14 million, according to the company. The cans flew on the shuttle Challenger in 1985. NASA, a federal agency that has avoided advertising anything since its inception, stressed that it considered the cans an engineering demonstration, a test of beverage containers for future thirsty astronauts. Coca-Cola and Pepsi, as you might expect, treated the mission like a commercial.

A decade later, the makers of fizzy drinks were at it again. Coke sent another custom-made dispenser on a flight of the shuttle Endeavour in 1996. Pepsi went even bigger, with the help of another space agency. It paid for Russian cosmonauts to pose with a four-foot-tall replica of a Pepsi can while they conducted a spacewalk—a routine but dangerous procedure—outside the former Mir space station. The company refused to say exactly how much the stunt cost, but said it was in the seven figures.

Unlike their American counterparts, Russians don’t mind advertising opportunities, especially lucrative ones. Over the years, Russian astronauts have filmed commercials for Pizza Hut, RadioShack, and an Israeli brand of milk while in space. And the country has had a special relationship with Pepsi since the Sputnik days.

In 1959, the U.S. and the Soviet Union took turns showing off their culture and innovation to each other. The Soviets came to New York City, and the Americans to Moscow, where they put on display their best products and, by extension, their distinct ways of life. At the American exhibit, the chairman of Pepsi asked then–Vice President Richard Nixon to get the Soviet premier to have a sip.

He was eager to break into the Soviet market before a rival, Coca-Cola, did. The resulting moment—Nikita Khrushchev with a cup of Pepsi in his hand—was captured on camera and spread widely. “This was the best advertisement that a company could possibly want in the Soviet Union at that time,” writes Ksenia Zubacheva in Russia Beyond.

By the 1970s, Pepsi was funneling syrup into the Soviet Union to be diluted and bottled in newly built factories. The arrangement involved a rather unusual payment scheme. Zubacheva explains:

Soviet rubles could not be internationally exchanged because of Kremlin currency controls, which made it illegal not only to trade them internationally but also to take the currency abroad. Therefore, a barter deal was made whereby Pepsi concentrate was swapped for Stolichnaya vodka and the right for its distribution in the U.S.—liter per liter.

Pepsi has invested in operations in Russia since.

The corporation’s thirst for advertising in space has persisted, too, in Russia and beyond. In February, Pepsi shared a clip of a spacesuited figure, complete with the iconic shiny gold visor on the helmet, stretching against a pole. “Gotta stay loose,” a caption said.

Soda makers are known for advertising their beverage as something you can have any place you like—“anywhere in the world / no matter where you are,” according to the song Coca-Cola hired Mark Ronson and Katy B to produce in 2012. In a boat in the ocean, near a menacing shark? Obviously. In the Arctic, with a bunch of polar bears? Of course. In the midst of a tense standoff between Black Lives Matter protesters and police officers? Why not. By these measures, outer space fits the bill.

There is one catch: Soda sucks in space. Without the reliable tug of Earth’s gravity, gas bubbles don’t rise to the top and escape, crackling as they go. Astronauts end up consuming more gas than they would back home, which means they’ll need to burp more. When we drink and eat on Earth, gravity pulls the liquids and solids down to become digested, while gases float back up and flee our bodies as burps. In microgravity environments, like on the International Space Station and the now-retired Space Shuttles, everything floats together like, as Canadian astronaut Chris Hadfield put it so colorfully, “chunky bubbles.” Burping doesn’t occur naturally. If it did, you’d “throw up into your mouth.”

Astronauts who have had Pepsi and Coke in space weren’t wowed. “Results were mixed, and NASA did not add either company’s product to the Shuttle food pantry,” the National Air and Space Museum reports about the 1985 test. The Coke can from 1996 “sputtered, leaked and failed to fill their zero-gravity drinking bags,” according to the Chicago Tribune.

No matter. Soda companies don’t need astronauts anymore. They have satellites, like the ones that PepsiCo Russia planned to use for its energy-drink campaign. Once big and clunky, satellites now come in small sizes that are cheaper to launch.

Brands don’t have to rely on national space agencies, either. The commercial space industry has flourished in the past decade, and firms can pay rocket companies to launch stuff for them—or use rockets of their own. U.S. law prohibits regulators from granting licenses for “obtrusive space advertising,” but officials have approved payloads that were just for show. Elon Musk launched a Tesla on a SpaceX rocket. A company called Rocket Lab launched a shiny spherical satellite called a Humanity Star to promote interest in the cosmos. An artist, with help from SpaceX, launched a reflective sculpture shaped like a diamond.

These payloads irritate some people, specifically astronomers and researchers who study the space around Earth, home to thousands of satellites, some operational and others defunct. The astronomers say the artificial objects could disrupt telescope observations. Orbit conservationists say they pollute an already crowded place.

“Most of us would not think it cute if I stuck a big flashing strobe-light on a polar bear, or emblazoned my company slogan across the perilous upper reaches of Everest,” Caleb Scharf, the director of the Columbia Astrobiology Center, wrote in a post on Scientific American last year. (This sentiment has been around since the days of skywriting, a practice The New York Times once called “celestial vandalism.”)

But flashy spheres, shiny sculptures—these are short-lived things. The low-Earth environment, where the space station and many satellites orbit, still has enough air particles to slow down moving objects. Satellites without engines and fuel can’t lift themselves higher into orbit and escape the drag. The Humanity Star, for example, succumbed to Earth’s gravity and plunged into the atmosphere two months after launch.

The Pepsi billboard would have met the same fate. Unlike one of the Pepsi cans from the 1980s, which sits in a collection inside the Smithsonian, the first floating ad in space would splinter into pieces and vaporize as it hurtled back toward Earth. The return, fiery and fast, might resemble a shimmering meteor shower from the ground. Given its history, Pepsi might try to advertise that, too.



On Ariana Grande’s new album, among the kinds of titles you’d expect from an ultra-successful pop star singing about the highs and lows of love—“needy” or “ghostin”— there’s this single, all-caps track: “NASA.”

Yes, one of Grande’s new songs is named for the U.S. government agency that runs the space program.

For Grande, the song is another catchy tune about self-empowerment in romantic relationships. For NASA, it’s free publicity; the agency tweeted a cheesy message at Grande on Friday, complete with a link to its own website. For music writers, such as my colleague Spencer Kornhaber, it’s a chance to celebrate a “top-tier bop.” For The Atlantic’s science desk, it is an opportunity to get nerdy about the astronomical facts alluded to in the lyrics.

The song opens with a reimagining of Neil Armstrong’s famous line: “This is one small step for woman / One giant leap for womankind.” The intro segues into an addictive jam sprinkled with outer-space buzzwords: Stars, orbit, gravity.

“You know I’m a star / Space, I’ma need space,” the chorus goes. Grande insists to her paramour that she needs some time apart because she needs some “me” time. She imagines herself as a star, and also “the universe / and you’ll be N-A-S-A.” (We’ll leave the sleuthing about which ex-boyfriend NASA represents to someone else.)

As far as pop-song metaphors go, this is a pretty good one.

The universe is vast. The distances between stars are so tremendous that they are measured not in measly units like miles or kilometers, but by how fast light can cross them. If Grande needs some space from a partner, she’ll find it here.

The closest stars to our own orbit are in a trio known as Alpha Centauri, located about four light-years away. It is considered “close” only on cosmic scales. How long would it take us to reach Alpha Centauri? Kurtis Williams, an astronomy and astrophysics professor at Texas A&M University, worked out the math. Light travels at about 186,000 miles per second. Let’s say a spaceship travels at 20,000 miles per hour, a little faster than the U.S. space shuttle, which flew at 17,500 miles per hour. At that speed, it would take people 137,000 years to reach the stars. Plenty of time for some self-care away from the boyfriend.

Even across astronomical distances, though, it’s possible to see stars with some clarity. Celebrity journalists have to use tiny clues to try to understand the lives of their subjects, and so do astronomers. Telescopes, on the ground and in space, gaze out and absorb stars’ light. Astronomers split that light into different wavelengths, in the same way a prism spreads light into a rainbow of colors. The wavelengths can reveal certain properties of stars, such as composition and temperature. Astronomers have used this technique to explore a variety of stars in the cosmos.

If Grande wanted to get a little specific about the kind of star she is, she has several options.

All stars form in the same way, from within clouds of cosmic dust. Dust twists into knots that grow until they collapse under their own weight, leaving behind clumps that become super hot and radiant. But stars, as eternal and unyielding as they might seem to us, transform through the course of their lifetime.

Most stars in the universe are main-sequence stars, including the sun and our neighbors in Alpha Centauri. These stars are in the prime of their life, fusing hydrogen to create helium to produce their blinding radiance for billions of years. (At 25, Grande arguably is in the prime of her career, with years of blinding radiance to come.) The smallest stars, known as red dwarfs, emit a tiny fraction of our sun’s energy. The most massive, known as hypergiants, exude hundreds of thousands of times more energy.

A big star like Ariana might see the fate of space-bound stars as a warning, too: A star’s fuel is finite, and the more massive it is, the faster it will burn out. Longevity favors the smallest.

When stars run out of their hydrogen supply, they metamorphose into something else. Their new appearance depends on their mass. The biggest stars explode in dazzling explosions called supernovae and leave behind dense remnants known as neutron stars. (I’m not a music producer, but “Supernova” sounds like Grande’s next hit.) Our own star will expand and cool into what’s known as a red giant. Eventually, it will shed its outer layers to space and expose an extremely dense core. After that, it’ll be known as a white dwarf.

Sun-like stars, red dwarfs, white dwarfs, red giants, hypergiants—any star in the universe, though, has plenty of the space Grande craves. Last year, astronomers working on the Hubble Space Telescope announced the discovery of the most-distant star to date, a hypergiant nicknamed Icarus, about 9 billion light-years away. The light traversed the cosmos for 9 billion years before reaching the telescope.

The most distant stars are some of the most interesting to astronomers. The farthest stars are also the earliest stars in the universe. Astronomers study them because they want to know what the cosmos was like at the very beginning, which is a mysterious period in astronomy. This may be where Ariana Grande and astronomers diverge. Grande sings that maintaining some mystery will only strengthen her bond with her suitor. For astronomers, the mysteries that distance creates cause only pain.



“There were arms everywhere,” Drew Harvell recalls. “It looked like a blast zone.”

It was 2013, eight days before Christmas. Harvell and her colleagues were walking along Seattle’s Alki Beach, sweeping their headlamps over wet gravel exposed by a receding tide. Wherever they looked, they saw dead and dying sea stars. Some had disintegrated into white mush. Others were still alive, their body riddled with sores and their arms twisting at grotesque angles. Yet others seemed to be pulling themselves apart. “There were arms separating from sea stars, arms walking off by themselves,” says Harvell, an ecologist at Cornell University who studies marine diseases. “That was my first experience of the magnitude of it.”

Similar omens had been accumulating all fall. Harvell had received emails about a mysterious disease outbreak afflicting sea stars in British Columbia. She had read blog posts about “a huge mortality event” that was littering the seafloor with disintegrating arms. She had heard reports that even captive sea stars in the Vancouver Aquarium were dying. This unprecedented phenomenon, known as sea star wasting disease (SSWD), ultimately affected more than 20 species. Similar die-offs had occurred before, but never at this scale. All along the western coast of North America, from Alaska to Mexico, the stars were blinking out.

Harvell and her colleagues considered a laundry list of possible causes, including storms, pollutants, and radiation from the Fukushima nuclear disaster. But the syndrome always looked like an infection, and in 2014 the team identified a possible culprit—a virus that it called sea-star-associated densovirus, or SSaDV. The virus doesn’t cause SSWD in every affected species, though, so there’s still a lot of uncertainty about the syndrome’s cause (or causes). Its impact, however, is undeniable.

In a new analysis, Harvell collated data from more than 10,000 surveys carried out by trained citizen scientists diving off the Pacific Coast. Their observations showed that SSWD has brought one especially susceptible species—the mighty sunflower star—to near-total ruin.

The sunflower star is the starfish equivalent of a Tyrannosaurus—a huge, voracious, unmistakable alpha predator. With a three-foot diameter, up to 26 arms, and hundreds of tubular feet, it runs down clams, sea urchins, and snails at a top speed of six inches a second. “This thing was as common as a robin,” Harvell says. “You would go on a dive and always see sunflower stars.” But since 2013, the sunflower star has largely vanished from most of its former 2,000-mile range; only in Alaska do appreciable populations still remain. In just a few years, an emerging disease has caused the continental-scale collapse of a once-common species, and has started to remake the underwater world.

“Some people have said that maybe they migrated to deeper water and they’re down there somewhere,” Harvell says. But data from the National Oceanic and Atmospheric Administration have snuffed out that hope. They show that from 2013 to 2015, the sunflowers completely disappeared from the deep waters off of California and Oregon, and declined by 99.2 percent near Washington. In 2016, NOAA researchers couldn’t find a single individual in almost 700 trawls. This past summer, they saw just one. “That shocked everyone, including me,” Harvell says.

The loss of any species is a tragedy. But the loss of the sunflower is especially devastating because it’s a keystone predator—a creature that has a disproportionately large influence on the world. The legendary ecologist Bob Paine coined the keystone concept in 1963, after yanking starfish from a Washington beach and hurling them into the sea. A year later, the mussels that the starfish would have eaten had overrun the shoreline, displaced the creatures that had formerly lived there, and remodeled the landscape.

SSWD is effectively carrying out the same experiment, but on an epic scale. In the absence of the sunflowers, the sea urchins they hunt are running amok, eating their way through the Pacific’s kelp forests. Kelp is a tagliatelle-like seaweed whose meter-tall fronds shelter vast communities of marine life. If the kelp forests fall, an entire ecosystem will fall too, including several commercially important species such as abalone, crab, and countless fish.

Such changes have already begun, and particularly in places where the other major predator of sea urchins—the sea otter—has also declined. Once-lush worlds of green and yellow foliage are now “urchin barrens”—desolate domains of purple spines and chewed stumps. “Kelp forests along the West Coast have been hit hard, and are likely to diminish further as these sunflower-star predators become extremely rare,” says Carol Blanchette from the University of California at Santa Barbara.

“Things are currently not looking great,” says Melissa Miner from the University of California at Santa Cruz. “But from talking to researchers and divers, my understanding is that [the sunflowers] are still present throughout their entire range; you just need to look harder for them now. My hunch is that this is a fast-growing species, which might have the potential to recover quickly if whatever is causing SSWD subsides. I think there is hope.”

But disease is only part of the story. Harvell’s team found that the sunflower’s decline coincided with abnormally strong heat waves, and the higher temperatures rose above their usual levels, the more likely the stars were to disappear. Harvell suspects that warm waters could have either boosted the growth of whatever microbe is behind SSWD or stressed the sunflowers, making them more susceptible to infections. “The warming didn’t necessarily trigger the outbreak, but I think it increased the impact of the disease,” Harvell says.

This may be the norm in the future. In Harvell’s upcoming book, Ocean Outbreak, she documents several cases in which infections have wreaked havoc on coral, abalone, salmon, and other marine creatures. In some cases, the changing climate has worsened these contagions.

Land-living animals face the same double whammy. While the sea stars were disintegrating, on the other side of the world two-thirds of the world’s population of saiga—a bulbous-nosed Asian antelope—dropped dead. They died without warning, in a few days, over an area the size of Florida. And they seem to have been killed by a normally harmless nasal bacterium that, thanks to an unprecedented spell of heat and humidity, infiltrated their bloodstream and poisoned them. Climate change plus contagion equals mass mortality: It’s a chilling equation for a changing world.



One of the scariest scenarios for near-term, disastrous sea-level rise may be off the table for now, according to a new study previewed at a recent scientific conference.

Two years ago, the glaciologists Robert DeConto and David Pollard rocked their field with a paper arguing that several massive glaciers in Antarctica were much more unstable than previously thought. Those key glaciers—which include Thwaites Glacier and Pine Island Glacier, both in the frigid continent’s west—could increase global sea levels by more than three feet by 2100, the paper warned. Such a rise could destroy the homes of more than 150 million people worldwide.

They are now revisiting those results. In new work, conducted with three other prominent glaciologists, DeConto and Pollard have lowered some of their worst-case projections for the 21st century. Antarctica may only contribute about a foot of sea-level rise by 2100, they now say. This finding, reached after the team improved their own ice model, is much closer to projections made by other glaciologists.

It is a reassuring constraint placed on one of the most alarming scientific hypotheses advanced this decade. The press had described DeConto and Pollard’s original work as an “ice apocalypse” spawned by a “doomsday glacier.” Now their worst-case skyrocketing sea-level scenario seems extremely unlikely, at least within our own lifetimes.

Yet their work—and the work of other sea-level-rise scientists—still warns of potential catastrophe for our children and grandchildren. If every country meets its current commitment under the Paris Agreement, the Earth will warm about 2.7 degrees Celsius by the end of the century compared with its pre-industrial average. In their new research, DeConto and his colleagues say that there’s a tipping point, somewhere between 2 and 3 degrees Celsius of temperature rise, after which the West Antarctic Ice Sheet will slip into rapid and shattering collapse.

Their new research also raises the marginal risk of disaster. Officially, the Paris Agreement aims to keep global warming from exceeding 2 degrees Celsius, though many experts consider that goal fanciful. And even in that extremely optimistic scenario, West Antarctica still switches into unavoidable collapse about 10 percent of the time, according to the new research.

Their short-term revisions also barely change their long-term forecast of West Antarctic disintegration. If emissions keep rising, they warn that global sea level could rise by more than 26 feet by 2300.

These new results have not yet been peer-reviewed. DeConto, a professor at the University of Massachusetts at Amherst, presented them to other scientists last month at the fall meeting of the American Geophysical Union, the largest annual conference of Earth scientists in the world. He and his colleagues declined to comment for this story in keeping with an academic custom not to discuss new work with the press before its publication.

The new results inform one of the biggest outstanding questions—and most fervent debates—concerning how climate change will reshape our world: How much will the seas rise, and how fast will that upheaval occur? DeConto and several other American glaciologists—including Richard Alley, a professor at Penn State and a co-author of the new research—represent something like the vanguard of that discussion. They champion an idea called “marine ice-cliff instability,” or MICI, which maintains that West Antarctic glaciers will eventually crumble under their own weight. By the middle of next century, they warn, this mechanism could send ocean levels soaring at a rate of several feet per decade. For reference: Along the U.S. East Coast, the Atlantic Ocean has risen by only about a foot over the last 12 decades.

While “marine ice-cliff instability” might be clunky, the idea is cinematic. It holds that warm ocean waters will eventually chew away the floating ice shelves that gird Antarctic glaciers today. With these ice shelves gone, the glaciers will stand naked on the seafloor: towering, fragile cliffs of ice. Imagine a 300-foot-tall shard of sapphire rising from the ocean and stretching for miles in both directions, and you will have a sense of the awesome prospect of this new geography. You will also have a sense of its dangerous physics, because ice cannot support itself at such heights. As MICI kicks in, those sapphire walls will crack, buckle, and begin rapidly birthing hundred-foot splinters of frozen freshwater into the sea. And thus the oceans will rise.

Other researchers find this possible future somewhat fantastic. “We, as European modelers, are slightly more skeptical of the marine-cliff idea,” Frank Pattyn, a glaciologist at the Free University of Brussels, told me. “It has not been observed, not at such a scale.”

Yet even MICI’s skeptics agree: Our understanding of sea-level rise is rapidly growing more ominous. In its last major report, in 2014, the Intergovernmental Panel on Climate Change projected that oceans could rise two feet by 2100 if greenhouse-gas emissions continue on a worst-case trajectory. That number will almost certainly worsen in the IPCC’s next report, which is due in 2021, Pattyn said. “We are facing sea-level rise that is obviously going to be higher in the mean than what the IPCC’s ‘Fifth Assessment Report’ showed,” he said.

“Nobody’s debating that sea-level rise is happening. It’s back to how much, how fast,” Helen Amanda Fricker, a glaciologist at Scripps Institution of Oceanography, told me. Even the most optimistic scientists have recently increased their low-end estimates, she said. “It’s healthy to have this debate.”

There is only one place in the world where MICI is definitely happening: Jakobshavn Glacier, on the west coast of Greenland. (Locals call it Sermeq Kujalleq.) In the 19th century, Jakobshavn was a long river of ice that snaked out of its fjord to meet the surrounding, frozen bay. Now, the bay rarely freezes, and Jakobshavn has retreated miles back into its canyon, forming a tall, brittle cliff face that regularly births icebergs as tall as a house. (Some of those icebergs are so enormous that they get stuck leaving the fjord.) All that ice has to come from somewhere: These days, Jakobshavn empties ice from the center of Greenland twice as quickly as it did during the last century.

Last month, in a large hall at the same AGU conference, several hundred researchers gathered to see a set of presentations billed as a series of updates on new glacier and ice models. It was far closer to a proxy debate on the ice-cliff question. Several of the talks had “marine ice-cliff instability” in the title, and I had heard more than one group of glaciologists gossiping about it days in advance.

Alley, the Penn State glaciologist, addressed the sapphire-colored elephant in the room immediately after taking the dais. As he sees it, it’s just common sense that Antarctic glaciers will develop problematic ice cliffs. The Jakobshavn Glacier, only a few miles wide, has not significantly changed the rate of global sea-level rise. Pine Island Glacier in West Antarctica, on the other hand, is more than 30 miles wide. It holds enough ice to raise sea levels worldwide by about five feet. “What we’ve always relied on is that unzipping one fjord does not affect the global ocean,” Alley said. “What’s different is that here and here and here”—he pointed to glaciers in West Antarctica—“unzipping one fjord will matter a lot.”

In this scenario, he warned, “We will not have analogues … We are going to move outside the instrumental data that we use to calibrate our models.”

Then came the skeptics. Dan Martin, a computational scientist at Lawrence Berkeley National Lab, argued that his and his colleagues’ work showed that ice cliffs might simply be a product of running a computer model of ice physics at a too-low resolution. Eric Larour, a physicist at NASA, presented the possibility that the physics of the Earth itself might slightly counteract some rapid ice-cliff collapse. As the ice sitting on West Antarctica melts, the bedrock below it will bounce back up.

“When ice melts or thins, you can think that the Earth [below it] is going to rebound,” he said. That bedrock will rise, lifting the glacier partly out of the water. Such a mechanism could buy humanity some time, he said, giving us a “23 to 30 year delay” in the total collapse of West Antarctica. This effect might hold off the collapse of West Antarctica until 2250 or 2300, but then the ice sheet would disintegrate as fast as ever.

The meeting arrived at no clear conclusion. “It still doesn’t look good,” Brad Lipovsky, an Earth scientist at Harvard, told me. “That’s what I saw in the talks today. We’re still seeing that sea-level rise is going to be a major problem for coastal communities around the world.”

MICI remains a young idea, first proposed only six years ago. It need not be rejected simply because scientists haven’t arrived at hard conclusions yet, Fricker, the Scripps glaciologist, said. Marine ice-cliff instability remains a worrying possibility: a low-chance, high-danger tail risk of climate change. It’s just one of the many gambles that humanity is placing on its own future—and it’s not even the only mechanism that could cause West Antarctica to collapse. Researchers are also investigating another mechanism, “marine ice-sheet instability,” that could target some of the same fragile glaciers.

“It might not happen,” Fricker said. “But if there’s a chance that it could happen, then shouldn’t you involve that in your planning? If you’re hosting a picnic and it might rain, you don’t necessarily move the whole event, but you probably do make a Plan B. If you’re planning a city … you might as well keep this in the back of your mind.”



Because we’ve been sitting on the same rock for thousands of years, sometimes our language can tend to be a little Earth-centric. The word earthquake, for example, feels universal, as if it can be applied to any shaking ground. But zoom out beyond our tectonic plates, and the vocabulary shifts.

Mars, for instance, has marsquakes.

They sound too silly to be real, as if a Netflix show about future Mars settlements made up a scary natural disaster. But tremors on Mars are a thing, and right now scientists believe they have detected a quake on Mars for the first time.

Scientists know this because they sent a seismometer to our planetary neighbor. The instrument arrived last year, on board a NASA lander called InSight. The seismometer, small and dome-shaped, has sat on the brick-colored surface since, waiting for hints of movement below the surface. On April 6, it caught something, a “quiet but distinct” signal, scientists said. A rumble from the depths.

“We’ve been waiting months for our first marsquake,” Philippe Lognonné, a geophysicist at the Institute of Earth Physics of Paris who leads the seismometer team, said in a statement this week.

Scientists have suspected for decades that they’d find this phenomenon if they had the right tools to look. Unlike Earth, Mars lacks tectonic plates that glide over its mantle, jostling the ground when they touch. But like Earth, Mars has three distinct layers—a rocky crust, a mantle, and a metal core—and it’s still cooling from its fiery formation out of a primordial cloud of cosmic dust. Even now, billions of years later, heat radiates from its center and can be strong enough to crack the surface and escape. The fracturing sends seismic waves streaming in all directions.

Marsquakes can help scientists study the interior of the planet. Seismic waves move like beams of light in a hall of mirrors; as they propagate throughout the planet, they bounce around. Different materials redirect the waves in different ways. Data from seismometers allow scientists to track the zigzagging of the waves and determine the composition of the stuff they strike.

While scientists are thrilled about the detection, they wish the rumble were stronger. The quake measured about 2.5 on the Richter scale, too weak to draw a path within the depths. If a tremor like that happened on Earth, you wouldn’t feel it. If you were standing next to the InSight lander at the moment of detection, you wouldn’t know either. “We are waiting for the big, big one,” says David Mimoun, a scientist at France’s Higher Institute of Aeronautics and Space and a member of the seismometer team. Researchers expect to detect dozens more, some as powerful as 5.5 magnitude.

The marsquake provided some information about the lander’s surroundings, though. It lasted 15 minutes, a relatively long time for such a weak rumble. This suggests that the ground beneath the InSight lander doesn’t have much water, which is known to exist on Mars mostly as ice. “When there is water, it dampens the quake,” Mimoun says.

Some of the earliest missions to Mars sought to find evidence of marsquakes. A pair of Viking landers touched down on the surface in the 1970s with seismometers in tow. But the instruments were mounted on the spacecraft rather than set on the ground, and only one actually worked. Under these circumstances, it was difficult to tell whether rumblings originated from the depths or from the hardware shuddering against a strong wind. In 1976, a seismometer on one of the landers felt some shaking on a not-too-windy day. But the spacecraft recorded measurements of the wind speed only 20 minutes before the mysterious rumbling and 45 minutes after. Scientists couldn’t rule out a wind gust in that missing window.

This time, they’re more certain. With the seismometer firmly on the ground, it’s easier to pick out the gusts from the tremors. “We’ve seen a lot of wind previously, and we know that this is something different,” says Ingrid Daubar, a scientist at NASA’s Jet Propulsion Laboratory and a member of the InSight team.

While scientists have ruled out wind as a potential cause, they haven’t fully investigated the possibility of a meteor impact, which can cause the surface to rumble. Daubar says the team will compare images of the InSight lander’s surroundings from before and after the detection and look for evidence of any fresh craters.

Earth and Mars share their shaky properties with another celestial body: the moon. During the 1970s, seismometers placed on the lunar surface by Apollo astronauts detected hundreds of moonquakes. Some reached a magnitude of 5.5. Scientists suspect several sources, including churning in the moon’s interior caused by Earth’s gravitational tug.

Back on Earth, NASA has converted the latest Mars crackling into audio:





First, there’s a low, steady hum, the voice of the wind sweeping across the surface. Then, something higher pitched and urgent—the quake. At the end, the whirring of the lander’s robotic arm, maneuvering to take pictures of the scene.

The sound of the quake is the big draw here. But it’s the noise of the robotic arm, a hollow cooing, that is my favorite. To hear the vibrations of a quake on another planet is a beguiling experience. But the sound of the delicate movements of the machine that captured them, that humankind somehow managed to dream up and deliver to Mars in one piece, is somehow a little sweeter.



Updated at 1:45 p.m. ET on March 2, 2019. 

Alan Jamieson remembers seeing it for the first time: a small, black fiber floating in a tube of liquid. It resembled a hair, but when Jamieson examined it under a microscope, he realized that the fiber was clearly synthetic—a piece of plastic. And worryingly, his student Lauren Brooks had pulled it from the gut of a small crustacean living in one of the deepest parts of the ocean.

For the past decade, Jamieson, a marine biologist at Newcastle University, has been sending vehicles to the bottom of marine trenches, which can be as deep as the Himalayas are tall. Once there, these landers have collected amphipods—scavenger relatives of crabs and shrimp that thrive in the abyss. Jamieson originally wanted to know how these animals differ from one distant trench to another. But a few years ago, almost on a whim, he decided to analyze their body for toxic, human-made pollutants such as polychlorinated biphenyls, or PCBs, which have been banned for decades but which persist in nature for much longer.

The team found PCBs galore. Some amphipods were carrying levels 50 times higher than those seen in crabs from one of China’s most polluted rivers. When the news broke, Jamieson was inundated with calls from journalists and concerned citizens. And in every discussion, one question kept coming up: What about plastics?

The world produces an estimated 10 tons of plastic a second, and between 5 million and 14 million tons sweep into the oceans every year. Some of that debris washes up on beaches, even on the world’s most isolated islands. About 5 trillion pieces currently float in surface waters, mostly in the form of tiny, easy-to-swallow fragments that have ended up in the gut of albatrosses, sea turtles, plankton, fish, and whales. But those pieces also sink, snowing into the deep sea and upon the amphipods that live there.

Brooks eventually found plastic fibers and fragments in 72 percent of the amphipods that the team collected, from all six trenches that they had surveyed. In the least polluted of these sites, half of the amphipods had swallowed at least one piece of plastic. In the 6.8-mile-deep Mariana Trench, the lowest point in any ocean, all of the specimens had plastic in their gut.

Does a single fiber really matter amid all the sediment and detritus that amphipods regularly swallow? Jamieson thinks so. For a start, PCBs and other toxins can stick to plastic, turning fibers into sinks for other contaminants. Also, many of the pieces that his team found were relatively huge. “The worst example I saw was a purple fiber, a few millimeters long, tied in a figure-of-eight in an animal no longer than a centimeter,” Jamieson says. “Imagine if you swallowed a meter of polypropylene rope.”

If trenches from places as distant as Japan, Peru, and New Zealand can be contaminated, it’s likely that humanity’s plastic fingers have stretched into every part of the ocean, including habitats we have barely begun to understand. No marine ecosystem is untouched. “It builds upon a growing body of evidence suggesting that the deep sea, by far the largest habitat on the planet, may very well be the largest reservoir of plastic waste on the planet,” says Anela Choy from the University of California at San Diego.

“It’s not a good result,” Jamieson adds. “I don’t like doing this type of work.”

When he submitted his findings to a scientific journal, the researchers who reviewed the paper reasonably asked how he could tell that the fibers were actually plastic. “Our response was, ‘Some of it’s purple!’ ” Jamieson says. “There’s bits of pink in there. This doesn’t come from animals.” To satisfy the critics, his team chemically analyzed a subset of the fibers and found that all of it was synthetic.

They also took steps to ensure that they hadn’t inadvertently introduced plastic into the trenches. The landers that they used to collect the amphipods have some plastic parts, but they are all bright green and yellow, and no such colors were found in the specimens. Even if the amphipods had eaten plastic from the landers (or from the bait used to attract them), the team only dissected the last of the creatures’ several stomachs to avoid sampling their most recent meals. And they performed those dissections within a special chamber, where continuously rising air stops fibers from their equipment or clothes from settling in the samples. Given these precautions, Jamieson is confident that the fibers he found had sunk into the abyss on their own.

Other scientists have also found plastic litter in the deep; just last year, one team documented a plastic bag at the bottom of the Mariana Trench. Until now, no one had shown that abyssal animals were actually eating those fragments, but in retrospect, it seems obvious that amphipods would. They are exceptional scavengers that excel at finding food. By deliberately pumping water over their body, they can detect the faintest plumes of odor, and with taste buds on their legs, they can forage with every footstep. When a morsel hits the ocean floor, amphipods turn up in droves. “We can catch 10,000 in one day with just a pipe, some bait, and a funnel,” Jamieson says.

Food is scarce in the deep, so amphipods can’t afford to be fussy. They’ll eat pretty much anything, which makes them particularly vulnerable to plastics. And since they sit at the bottom of the trench food webs, their catholic appetite can doom entire ecosystems. “They’re like bags of peanuts,” Jamieson says. “Everything else eats amphipods—shrimp, fish—and they’ll end up consuming plastics, too. And when the fish die, they get consumed by amphipods, and it goes round and round in circles.”

“What you put in the trench stays in the trench,” he adds. Which means that the plastic problem “is only going to get worse. Anything going in there isn’t coming back.”

That’s a hypothesis the team can test in later studies. If Jamieson is right, then amphipods from deeper parts of the same trench should have higher levels of plastics than those from higher up. But Choy says, “We certainly don’t need decades of further scientific study to necessitate more responsible behavior and policies now.”

“I imagine pollution in the Mariana Trench is an abstract concept for most people, but for those of us living in the Mariana Islands this has consequences for what ends up on our dinner plates,” says Angelo Villagomez, an indigenous Chamorro from the Mariana Islands who works for the Pew Bertarelli Ocean Legacy Project. “So what can we do? The International Union for the Conservation of Nature recommends we protect 30 percent of every marine habitat to address human impacts, but that will only help if we’re also sustainably managing the remaining 70 percent, reducing carbon emissions, and limiting the pollution being dumped in the ocean in the first place.”



Almost 150 years ago, on an October afternoon, Burt Green Wilder was strolling through the woods outside Ithaca, when he stumbled across a strange spider web attached to a hemlock branch. It was triangular, as if a wedge had been cut from a full web. And “instead of hanging loosely from the twigs, it was upon the stretch, as if constantly drawn by a power at one or the other end,” Wilder later wrote.

Wilder had many talents: He was a Civil War surgeon, a pioneering neuroscientist famous for his vast collection of preserved brains that included, eventually, his own, and a zoologist whose fondness for spiders led him to create a device that milked them for silk. Upon encountering a bizarre triangular web, such a person was almost guaranteed to prod it.

When he did, he was amazed that the structure “loosened with a snap,” and the triangle shot forward as if whatever was holding it taut had let go. A moment later, as Wilder watched, it started slowly stretching back to its original state. It was being pulled by a single strand extending from its tip, and by following that line, Wilder found the web’s creator—a tiny spider, no bigger than a grape seed, and camouflaged to resemble a tree bud. Hyptiotes cavatus. The triangle weaver.

Hyptiotes (pronounced HIP-tee-oh-tees) had been discovered a few decades earlier. But Wilder was the one who worked out how it builds and uses its web—an extraordinary, spring-loaded trap that allows it to rapidly ensnare large prey.

Spinning at night, it makes four radial spokes that converge at a point, an apex line that connects that point to a nearby branch, and sticky capture threads that run across the spokes. Once finished, it sits on the apex line, cuts it, and uses its own body to bridge the two separate threads. Its front legs grab the end leading to the web. The silk-making spinnerets on its backside grab the end anchored to the branch. Then, by walking its back legs along that anchor line, as a person hauling along a rope, it slowly winches the web taut. If an insect hits the web, Hyptiotes lets go with its back legs, allowing the web (and its body) to spring forward.

Thanks to this springing action, several of the sticky capture threads slam into the insect. And since Hyptiotes is still holding on to the anchor line with its spinnerets, it can repeatedly recock and relaunch the web. Again and again, the triangle pulls back and springs forward, each time entangling the insect even more. Finally, when the victim is well and truly trapped, the spider scampers over and starts to feed.

Wilder described all of this in 1875, and while others have studied Hyptiotes since, no one had studied the physics of its attack. Sarah Han from the University of Akron did so recently using high-speed video cameras, and the numbers she got came as a shock.

When the spider releases the anchor line, its body accelerates at 770 meters per second squared (more than 2,500 feet per second squared)—almost 80 times greater than a free-falling object, and 60 times greater than a sprinting cheetah. That’s only possible because the spider stores energy in its stretched web. If it tried to accelerate that hard on its own power, it would need 20 times its body weight in muscle.

Many animals use special energy-storing structures in their body to amplify the power of their muscles. Fleas compress a springy pad when they cock their legs, and the energy released when that pad expands powers the insects’ incredible jumps. Mantis shrimps—a group of aggressive crustaceans—use a similar structure in their arms to deliver the world’s fastest punches. Chameleons launch their super-fast tongue strikes by pulling the tongue back as if drawing an arrow on a bow, and then releasing it.

In all these cases, energy is stored within the animal’s body. By contrast, very few animals store energy in an external tool. Humans, with our bows, slingshots, catapults, and ballistae, are one. Hyptiotes, with its spring-loaded web, is another. The ray spiders (aka slingshot spiders) can also join the club: They spin traditional circular webs and then stretch the center back to create a spring-loaded cone. Symone Alexander from Georgia Tech, who studied one of these spiders, showed that they can achieve even greater accelerations than Hyptiotes. And “though Hyptiotes face their web, slingshots face away, indicating that there are perhaps some differences in prey-sensing and web-release strategies,” Alexander says.

“Spider webs have to intercept, stop and retain prey and each of these functions might be served by slightly different mechanical properties,” says Natasha Mhatre from Western University. Hyptiotes, however, has evolved a web that can “very rapidly transition between two very different states that each serve their functions really well—a tense web to stop prey and a looser web to entangle it.”

These traps only work if the spider can hold its web taut for hours—maybe days. Wilder noted as much, writing that “her powers and her endurance are, in proportion to her size, quite beyond what we are familiar with.” But even though Hyptiotes does have buff legs, which almost certainly help it to pull the web into place, it can’t possibly just be tensing its muscles for hours on end. It probably has a catch system to hold its limbs in place without effort, much as fleas and mantis shrimps do. But “we haven’t seen that anywhere,” says Han. “There must be something going on internally, and we plan on investigating it further.”

Another mystery: Why have these spiders evolved a triangular web in the first place? How does that improve over the basic circular models? Han suspects that speed is a factor: Most web-building spiders have to run over and attack their prey when they feel the right vibrations, but Hyptiotes can instantly ensnare its victims just by letting go. And most spiders subdue their prey with venom, but Hyptiotes belongs to a group called the uloborids that have lost their venom glands. By using its web to thoroughly entangle a snared victim from afar, “it doesn’t have to encounter prey that might hurt it in a struggle,” says Han.

But then, without venom, how does it actually finish off the insect? Other uloborids have resorted to extreme measures: One species crushes its prey to death by wrapping it in up to 140 meters of silk. (That’s almost 460 feet, and not a typo.) Does a Hyptiotes victim also die from constriction?

“I’m not exactly sure what is killing it,” Han says. “It might just die slowly as they start to feed on it.”



Does the country’s most popular climate policy actually work?

A controversial new study suggests that a type of state policy—usually called a “renewable portfolio standard,” or RPS—may impose large hidden costs on Americans. But a wide range of experts, including engineers, political theorists, and economists, aren’t sure the paper can actually make its case.

As Congress and the White House have failed to do much of anything about climate change, state standards have come to define U.S. climate law. Since 1991, 29 states and the District of Columbia have required that a portion of their electricity come from renewable sources. These RPS policies usually mandate that the state’s power grid use a certain amount of wind and solar energy by a certain year.

RPS standards look like climate policy that can actually win. Just look at Washington State. Last November, voters there overwhelmingly nixed a carbon-tax ballot proposal. But Governor Jay Inslee signed a 100 percent clean-power RPS into state law this Tuesday.

“Among our carbon policies, probably the biggest one we have in the country are RPSes,” Michael Greenstone, an economics professor and the director of the Energy Policy Institute at the University of Chicago, told me. Today, renewable standards already cover about half of the national power grid and about 18 percent of all U.S. emissions. Carbon pricing, meanwhile, only applies to about 9 percent of national emissions, he said.

Yet RPS policies have flourished without much sense of their cost. That’s the question that the new study seeks to answer.

The study, still in draft form and not yet peer-reviewed, finds that renewable standards tend to make electricity more expensive. Seven years after a state passes an RPS, the price of electricity rises by about 11 percent, and a standard unit of power—a kilowatt-hour—becomes about one cent more costly.

“There is a clear upward turn in prices once a state adopts an RPS, and it just kind of marches upwards as the standards get more stringent,” said Greenstone, who co-wrote the paper with Ishan Nath, another economics researcher at the university.

An RPS does lead to a moderate decline in carbon pollution, the study finds. But Greenstone and Nath argue that this reduction comes at a steep price. They say that, under an RPS, it costs at least $130 to prevent a ton of carbon pollution from entering the atmosphere. That’s far more expensive than the $50-per-ton carbon tax that Barack Obama’s administration once calculated.

The paper’s title is, “Do Renewable Portfolio Standards Deliver?” Its answer seems to be no—or at least, no, when compared with a carbon tax.

The study was first covered by Axios last month, and lawmakers have already cited it in debates about a state RPS. But the paper has become a flash point. In the days after its release, several experts have raised questions about the scope of its argument.

I spoke with five outside researchers for this story, including two economists. All of them took some issue with the paper’s purported scope: While the research was impressive, they said, it should not be taken as the last word about RPSes. Several of them also argued that the study confused too many different state laws, that it left out important benefits of an RPS, and that—above all—it couldn’t actually answer the most relevant question about RPS policies.

The authors freely admit to some of these difficulties in the paper. But some of the experts held that, even with those admissions, the paper could still be misused by enemies of all climate policy.

The controversy points to some of the larger questions haunting the academic study of global warming: What do we really have to know to fight climate change? What can economics tell us about some of the toughest questions raised by the climate crisis? When the fate of the planet is at stake, should we care about saving every marginal dollar?

The big critiques of the new Chicago paper fall along three lines. First, some experts took issue with the aspects of RPS policies that the authors tried to measure. Second, some experts take issue with what the paper didn’t measure. Finally, most of the experts worried about what the paper can’t measure.

Leah Stokes, a political-science professor at UC Santa Barbara, is very much in the first camp. She is writing a book about state standards, and the most important thing to know about them, she told me, is that it’s very rare that state lawmakers actually passed an RPS by itself. 

Instead, states tended to adopt RPS policies as part of a package of bills about the power grid. Starting in the 1990s, as the wave of Reaganite deregulation overtook the electricity sector, environmentalists often succeeded in slipping a small RPS into an omnibus power bill. After passage, multiple provisions in the new law would all take effect at the same time.

“These things were negotiated agreements,” Stokes said. “They’re not these beautiful stand-alone RPS bills.”

That negotiated history makes it harder to tease out the effect of any one RPS by itself. Plus, no two states passed exactly the same standard. The differences can be significant: By 2021, North Carolina needs its grid to be 12.5 percent renewables, while South Carolina only needs 2 percent renewables. States also defined “renewable power” in very different ways. Massachusetts and Ohio have long allowed nuclear power to count against their RPS mandates; other states generally have not. 

The Chicago study tries to control for some of these variables, accounting for national changes to electricity pricing and for other state power policies. “[The authors] do, to my mind, as solid an analysis as you can do,” Ken Gillingham, a Yale energy economist who did not work on the paper, told me. “They have the caveats that I would demand to feel comfortable.”

But ultimately, the answer that the paper finds—that RPS policies increase electricity prices while somewhat reducing carbon emissions—describes only the average effect of the 30 different statewide policies.

“These things are extremely messy laws,” Stokes told me. “If you go and talk to people in certain places about what was happening on the ground [when RPSes passed], you would discover that there’s a lot of heterogeneity and complexity and politics happening. The model is not going to account for that very easily.”

“Yes, each of the RPS policies is like a snowflake,” Greenstone said. “But when you wake up in the morning after a bunch of snowflakes have fallen, there’s snow on the ground.” RPS policies, he reminded me, are the most substantive U.S. climate policy on the books. “To the extent that we want to understand how we’re doing with carbon, knowing the average effects across the 30 seems self-evidently informative,” he said.

But in addition, experts raised questions about what the paper didn’t measure. Many RPS laws had several intended benefits. They may have aimed to help local solar or wind companies. They might also have reduced toxic air pollution, which can carry enormous public-health costs.

“The title of the paper is, ‘Do Renewable Portfolio Standards Deliver?’ That’s a pretty provocative title,” Gillingham, the Yale economist, said. “They do a lot of work to answer that … [but] I’m not sure they fully answer the question.”

Instead, the paper focuses on only one benefit: prevented carbon pollution. Yet even some of those methods can be controversial. The paper estimates the cost of carbon pollution by using a figure called the “social cost of carbon,” which attempts to compute the damage wrought by greenhouse gases between now and 2100. The paper estimates that every ton of carbon deals $50 in cost to society. But some economists doubt the utility of that figure.

“The empirical work on the social cost of carbon is better than nothing. It helps us to do things like say that the social cost of carbon is bigger than zero,” Noah Kaufman, an energy economist at Columbia University, told me. But he doubted that the social cost of carbon represented a precise, meaningful, per-ton estimate of all the damage wrought by climate change. Without a social cost of carbon, it’s impossible to say that an RPS costs more than its benefits. (That said, not every economist is as skeptical of the social cost of carbon as Kaufman.)

For these reasons, the two economists said that the paper could not render a final judgment about the overall value of RPS policies. Yet it seems to do so, at one point saying directly: “It appears that the current costs of RPS programs exceed their benefits.”

“You can’t really say that,” Gillingham said. “It is not a cost-benefit analysis. It is a cost-effectiveness analysis.” Such a sentence would probably be removed during the peer-review process, he said. Greenstone agreed. “That sounds like it needs to be edited,” he said.

And that points to a quirk of economics as a discipline. In the physical sciences, researchers do not discuss their work in public in any way until after a paper has been peer-reviewed and published. Scientists are free to share drafts with colleagues, or present early results at a conference, but they are essentially barred from talking about them on the record with journalists.

But in economics, researchers discuss working papers with the press all the time. Blockbuster results regularly receive major coverage before they are peer-reviewed. This makes sense: Many economists study real-life policies, and they wish to get their conclusions in front of policy makers as quickly as possible. Economists have also told me that the peer-review process in their field is slower and more arduous than it is in other disciplines.

Sometimes this working-paper approach can backfire: In 2010, two Harvard economists published a non-peer-reviewed paper that suggested high levels of public debt could depress a country’s economy. The paper was immediately cited to help justify widespread and painful budget cuts in the European Union. But three years later, a 28-year-old graduate student discovered that a coding error in an Excel spreadsheet had distorted the paper’s results. The data did not justify the same policies.

No one suspects the RPS paper of brimming with similar issues. And it’s not like the peer-review process keeps mistakes in other fields from making it to print: A high-profile, peer-reviewed Nature paper was corrected after publication last year. “People’s opinions about using working papers are like opinions about process crimes—if you’re likely to dislike the paper’s findings, you’re likely to distort what the working paper means,” said Kaufman, the Columbia economist.

“I like the economics approach,” he added. “It’s like a societal peer review. Everyone digs into them, and within a few days we have a sense of what a lot of well-qualified experts think.”

With the new paper, a bunch of well-qualified experts agree on a final criticism—that the most important benefit of an RPS may be totally unmeasurable. Even the paper itself repeatedly mentions this shortfall. Here is the problem: Economics has no way of knowing whether RPS policies reduced the global price of renewable energy. But depending on who you ask, that was the entire point of RPS policies in the first place.

Take Oregon, where Jesse Jenkins, an energy-systems engineer and a researcher at Harvard Kennedy School, helped pass an RPS law early in his career. State lawmakers never designed that policy solely to cut carbon pollution, he told me. Instead, they hoped to prompt cost-reducing innovation in the solar and wind industries. The standards “were designed to incubate and kick-start the nascent renewable energy industry—to take what was then called alternative energy and make it mainstream,” Jenkins said.

Even the most advanced statistical methods have a notoriously hard time of capturing this type of innovation, known as “learning by doing.” They struggle to tease out the effects of any one policy on the global marketplace. As such, the paper doesn’t measure them. It admits this flaw several times, even printing it in the abstract. “We say eight ways to Sunday in the paper that we do not, and are unable to, make progress on RPS’s ability to drive down costs,” Greenstone said.

What we know is that—in the years that many RPS policies have been active—solar and wind costs have fallen. Over the past decade, both solar and wind energy have plunged in cost. Solar energy is now 38 times cheaper than it was in 2010; renewable energy is now cheaper than coal across much of the United States. Economists know that American state-level RPS laws, Germany’s national solar policy, and cheap Chinese manufacturing all played a role in these incredible declines—but they have not distilled the exact relationship between all three of these.

“I don’t think we really have the tools right now to isolate the impact that one RPS in particular has had on the decline in costs of solar and wind in the last few decades,” Kaufman said. “It’s fair to say it matters, and it’s certainly not the only thing that matters.” Greenstone took a more agnostic approach to the question: “Just because you can name that that might happen doesn’t mean that it is so. I don’t know if [RPSes] do [reduce costs] or if they don’t. I don’t think you can run around and assert that those benefits are large.”

The question is what this lack of evidence means for the paper’s overall approach. Can an RPS, which aims to spur innovation, be fairly compared to a carbon tax, which aims to cut carbon? “In a way, it’s asking the wrong question if it’s trying to compare a carbon tax directly to an RPS,” Kaufman said. He believes that the policies work best together. “My sense is what you want is deployment policies like RPSes to help technologies along in their early stage of development, and then you want a policy like a carbon tax to more cost-effectively incentivize the low-cost mature technologies.”

Gillingham, the Yale economist, echoed that critique. “If the policy maker’s goal is purely to reduce CO2 emissions at the short-run lowest cost—and I personally don’t see why that should be the policy maker’s goal—then this way of making the comparison makes sense,” he said. “Otherwise, if it’s a long-run problem that has innovation involved, you have to be careful making this comparison.”

He added that he does trust the fundamental results. Greenstone and Nath’s findings closely match those in a 2017 study from Louisiana State University. It too found that power costs rise after the passage of an RPS.“But that doesn’t mean [RPSes] are a bad policy,” Gillingham added. It means that they are not cost-free and have some hard-to-measure benefits.

This distinction may be lost on some of the study’s consumers. Days after the Chicago study was posted online, a Republican state lawmaker in Ohio cited it approvingly during a hearing on the local RPS policy. Republicans there are currently pushing to repeal the state renewable standard, replacing it with a bailout for two local nuclear plants. The lawmaker, State Representative Dick Stein, directed special attention to the RPS paper’s title.

The paper “talks about whether renewable portfolio standards deliver—do they deliver a value to the customers?” he said. “When I see the metric cost of a ton of carbon at $130, and we’ve been told in the past that was something in the neighborhood of $50 … it seems like those two don’t get together.”

“Many of the folks … today testified to the fact these standards work, but at what cost?” he asked. “The question is, are these really ideal policies?”

The paper would reply that no, RPSes are not ideal policies when compared to a carbon tax. But Stein was not advocating for a carbon tax; he was advocating for junking the RPS altogether. With or without the paper, it seems likely that GOP lawmakers in his state will soon ditch Ohio’s renewable standards.

That repeal could snap renewable standards’ winning streak. Since 2016, four states have adopted 100 percent clean-energy standards. This success has pushed some observers and activists to change their mind about the policy. “I used to favor starting with a carbon tax or cap-and-trade program, because they seem to be the most efficient way to attack climate change. But they’re not efficient if they never pass,” wrote David Leonhardt of The New York Times this week. He now favors sector-by-sector standards, like those used in an RPS.

Greenstone believes that this new approach is gravely mistaken. “I don’t want to lose sight of the fact … that the enemy is carbon,” he told me. “Society should be trying to identify, ruthlessly and relentlessly, what are the least expensive ways to get rid of carbon?” Before the paper, he said, we didn’t know the effects of the average RPS. Now we do. “Why is it that—28 years after the first RPS passed—we didn’t have plausibly credible evidence on the effects of RPS policies on electricity prices and carbon emissions? How is that possible? And how were we better off not having answers to those questions?”

“I just think the climate problem is so important that we should have the facts in front of us on the least expensive ways to do something,” he said. “It’s an iron law of economics—when things cost more, people buy less. So if we really want to make progress on the climate challenge, I’m confident we’re going to do much more if we find cheaper ways to address it.”

None of the paper’s critics would, I think, disagree with this assessment. “There are a lot of people out there who say, Forget about carbon taxes, and let’s focus on policies that can pass, like RPSes. And they’re just not substitutes,” Kaufman said. Stokes called for open-mindedness: “I think we should all be open to the fact that these things are expensive,” she said. And like every other expert I talked with, she was effusive in her praise of Greenstone, calling him one of the top energy economists on the planet. “He’s a good guy, working in really good faith,” she said. “I don’t think he’s trying to game a certain answer.”

So the dispute over the paper seems to raise a more philosophical question. In recent U.S. history, the political capital for climate policy has been a far scarcer resource than monetary capital. Once a new climate-friendly program passes, it tends to get funding, even from a GOP-controlled Congress. The passing, it seems, is the hard part, because massive political force will always be arrayed on the side of doing nothing about climate change at all.

Given that situation, how should researchers talk in public about second-best policies, like an RPS? How should they discuss results when a field’s best methods can’t answer one of the most urgent questions about a given policy? There is no guidebook here, and no all-purpose answers.

Almost a decade ago, Greenstone was an economist in the Obama administration. He watched as the Senate voted down the Waxman-Markey climate bill, the last credible attempt to put a price on carbon in the United States. “What I took away from that is that the politics are hard, period,” he said. And the politics will be hard no matter the strategy: Three years before the Obama bill fell, Congress voted down a national RPS.

“In the face of politics being hard in all of its forms … I don’t get the case for focusing on more costly approaches to carbon,” he said. “I’m clear-eyed about my role here in all of this. Policy makers make policy. Economists do not make policy. What would be nice is if facts had a seat at the table with policy makers.”



Accidents happen during home-improvement projects, even in space.

The mishap unfolded on the International Space Station, which orbits about 250 miles above Earth, circling the planet every hour and a half. Earlier this month, NASA astronauts had gathered in the bathroom to install a pair of stalls for an extra enclosure that would provide some more privacy. As they worked, they twisted off a metal bit that connects a water unit to a hose that astronauts use for toothbrushing, bathing, and other hygiene routines. And that’s when two and a half gallons of water came bursting out.

The crew responded as they would on Earth: They grabbed a bunch of towels and scrambled to mop up the water. They attached a new bit to the unit and completed their work.

The incident was detailed in one of NASA’s daily dispatches that describe events on the ISS. History has treated astronauts as nearly mythical figures, but their day-to-day activities are usually quite tedious. The thought of them frantically trying to stop a leak in the bathroom makes them wonderfully relatable.

But a plumbing accident in space has little in common with one on the ground.

For starters, there’s the feeling of weightlessness. (Technically, astronauts are subject to 90 percent of the gravity that we feel here on Earth, but the station’s brisk traveling speed of 17,500 miles per hour keeps everything on board in a constant free fall that resembles zero gravity.) The ISS is equipped with handrails and footrests so that astronauts can push themselves around the station or stay in one place while they’re working on something. Tools can drift away and out of reach.

So can water. Unleashed in weightlessness, water behaves like soap bubbles blown from a wand. Water molecules are more attracted to one another than molecules of another substance. They like sticking together. On the ISS, that means water molecules pull themselves together into a shape with the least amount of surface area: a sphere. But unlike its soapy counterpart on Earth, this kind of bubble doesn’t pop and vanish.

There is no photographic evidence of the leak, according to a NASA spokesperson. To imagine how it may have transpired, I reached out to Tom Jones, a former NASA astronaut and the author of Ask the Astronaut: A Galaxy of Astonishing Answers to Your Questions on Spaceflight. Jones flew on the Space Shuttle four times before the program ended in 2011, and spent a week helping assemble the station during his last mission in 2001. He has experienced firsthand the strange phenomena of water in microgravity.

“If it was a slow leak, it would have built up into a big, undulating blob that would have drifted off or crept along the wall with surface tension,” Jones says. “If it was under a higher pressure and it was coming out at a fast rate, it would spray and make droplets go flying across the cabin.”

Jones says the first scenario is preferable. It would be easier to chase after fat globs of water than tiny beads.

Water, like most earthly comforts, is a precious resource on the ISS. The loss of two and a half milk jugs’ worth of water seems concerning. But none of the liquid was actually wasted. The crew left the soaked towels out to dry, and the water eventually evaporated. The systems that control the station’s temperature and humidity sucked up the moisture and dumped it back into a mechanism that produces potable water.

It is thanks to water’s unpredictability in space that there are no faucets or showerheads on the ISS. Astronauts use squirt-gun–like hoses to dispense and carefully distribute water onto washcloths and toothbrushes. Showers are a distant daydream. There’s no toilet flushing, either. Contrary to some news reports about a leaky toilet, the toilet system on the ISS doesn’t use water.

Astronauts urinate into a hose with a special funnel on top. (Don’t worry, everyone gets a personal funnel.) They flip a switch to activate a fan in the tube, and the liquid is suctioned away. For solid waste, astronauts stick their feet into stirrups and sit down on a plastic seat, with a chute below. Urine is recycled in the station’s life-support systems and converted into drinkable water. The rest takes a rather dramatic journey: Solid waste is sealed in plastic bags or metal containers. Astronauts eventually transfer the waste, along with other trash, to departing cargo ships. The ships undock from the station and fall back to Earth, where they burn up in the atmosphere like a meteor shower.

Astronauts upgraded the bathroom area this month as they wait for a brand-new toilet to arrive in 2020. Their current commode is a Russian-designed system that the United States bought from its partner on the ISS for $19 million in 2007. NASA promises that the new toilet, designed by an American company, is “simpler to use” and “provides increased crew comfort and performance.” The agency also wants the model to work in other, future space habitats.

Using the new toilet will likely require some preparation. Astronauts throughout history have received extensive training on the myriad spaceflight systems, the lavatory included. In the Space Shuttle days, astronauts had to practice using the toilet before they launched. The simulator came with a video camera at the bottom of the bowl, pointing up. Astronauts plunked down on the bowl, peered at a television monitor in front of them, and watched themselves, in real time, wiggle around and rehearse the proper placement.

“You had to be serious about it, because if you didn’t get those fundamentals down, then you’re going to make a mess for you and your crewmates up in space,” Jones says.

But it was still awkward. “The constant fear we all joked about was that that screen of your bottom being displayed on the simulator was also being piped over to mission control,” he says.

As far as leaks go, the recent watery fiasco is pretty tame. Last summer, crew members discovered a small hole in the Russian section of the ISS that had leaked air out into space, temporarily causing the air pressure inside the station to drop slightly. The incident drew considerable interest from the public, especially when the head of Russia’s space agency suggested that the hole may have been drilled deliberately, before or after that segment launched to space. NASA dismissed the sabotage rumors. Officials have yet to provide an explanation.

The crew wasn’t in any danger. The Russian cosmonauts patched up the opening soon after it was found, using sealant and gauze on board—just another instance of some DIY in space.



In 1996, a group of European researchers found that a certain gene, called SLC6A4, might influence a person’s risk of depression.

It was a blockbuster discovery at the time. The team found that a less active version of the gene was more common among 454 people who had mood disorders than in 570 who did not. In theory, anyone who had this particular gene variant could be at higher risk for depression, and that finding, they said, might help in diagnosing such disorders, assessing suicidal behavior, or even predicting a person’s response to antidepressants.

Back then, tools for sequencing DNA weren’t as cheap or powerful as they are today. When researchers wanted to work out which genes might affect a disease or trait, they made educated guesses, and picked likely “candidate genes.” For depression, SLC6A4 seemed like a great candidate: It’s responsible for getting a chemical called serotonin into brain cells, and serotonin had already been linked to mood and depression. Over two decades, this one gene inspired at least 450 research papers.

But a new study—the biggest and most comprehensive of its kind yet—shows that this seemingly sturdy mountain of research is actually a house of cards, built on nonexistent foundations.

Richard Border of the University of Colorado at Boulder and his colleagues picked the 18 candidate genes that have been most commonly linked to depression—SLC6A4 chief among them. Using data from large groups of volunteers, ranging from 62,000 to 443,000 people, the team checked whether any versions of these genes were more common among people with depression. “We didn’t find a smidge of evidence,” says Matthew Keller, who led the project.

Between them, these 18 genes have been the subject of more than 1,000 research papers, on depression alone. And for what? If the new study is right, these genes have nothing to do with depression. “This should be a real cautionary tale,” Keller adds. “How on Earth could we have spent 20 years and hundreds of millions of dollars studying pure noise?”

“What bothers me isn’t just that people said [the gene] mattered and it didn’t,” wrote the pseudonymous blogger Scott Alexander in a widely shared post. “It’s that we built whole imaginary edifices on top of this idea of [it] mattering.” Researchers studied how SLC6A4 affects emotion centers in the brain, how its influence varies in different countries and demographics, and how it interacts with other genes. It’s as if they’d been “describing the life cycle of unicorns, what unicorns eat, all the different subspecies of unicorn, which cuts of unicorn meat are tastiest, and a blow-by-blow account of a wrestling match between unicorns and Bigfoot,” Alexander wrote.

Border and Keller’s study may be “bigger and better” than its predecessors, but “the results are not a surprise,” says Cathryn Lewis, a geneticist at Kings College London. Warnings about the SLC6A4/depression link have been sounded for years. When geneticists finally gained the power to cost-efficiently analyze entire genomes, they realized that most disorders and diseases are influenced by thousands of genes, each of which has a tiny effect. To reliably detect these minuscule effects, you need to compare hundreds of thousands of volunteers. By contrast, the candidate-gene studies of the 2000s looked at an average of 345 people! They couldn’t possibly have found effects as large as they did, using samples as small as they had. Those results must have been flukes—mirages produced by a lack of statistical power. That’s true for candidate-gene studies in many diseases, but Lewis says that other researchers “have moved on faster than we have in depression.”

Marcus Munafò of the University of Bristol remembers being impressed by the early SLC6A4 research. “It all seemed to fit together,” he says, “but when I started doing my own studies in this area, I began to realize how fragile the evidence was.” Sometimes the gene was linked to depression; sometimes it wasn’t. And crucially, the better the methods, the less likely he was to see such a link. When he and others finally did a large study in 2005—with 100,000 people rather than the 1,000 from the original 1996 paper—they got nothing.

“You would have thought that would have dampened enthusiasm for that particular candidate gene, but not at all,” he says. “Any evidence that the results might not be reliable was simply not what many people wanted to hear.” In fact, the pace at which SLC6A4/depression papers were published accelerated after 2005, and the total number of such papers quadrupled over the next decade. “We’re told that science self-corrects, but what the candidate-gene literature demonstrates is that it often self-corrects very slowly, and very wastefully, even when the writing has been on the wall for a very long time,” Munafò adds.

Many fields of science, from psychology to cancer biology, have been dealing with similar problems: Entire lines of research may be based on faulty results. The reasons for this so-called reproducibility crisis are manifold. Sometimes, researchers futz with their data until they get something interesting, or retrofit their questions to match their answers. Other times, they selectively publish positive results while sweeping negative ones under the rug, creating a false impression of building evidence.

Beyond a few cases of outright misconduct, these practices are rarely done to deceive. They’re an almost inevitable product of an academic world that rewards scientists, above all else, for publishing papers in high-profile journals—journals that prefer flashy studies that make new discoveries over duller ones that check existing work. People are rewarded for being productive rather than being right, for building ever upward instead of checking the foundations. These incentives allow weak studies to be published. And once enough have amassed, they create a collective perception of strength that can be hard to pierce.

Terrie Moffitt of Duke University, who did early influential work on SLC6A4, notes that the candidate-gene approach has already been superseded by other methods. “The relative volume of candidate-gene studies is going way down, and is highly likely to be trivial indeed,” she says. Border and Keller disagree. Yes, they say, their geneticist colleagues have largely abandoned the approach, which is often seen as something of a historical embarrassment. “But we have colleagues in other sciences who had no idea that there was even any question about these genes, and are doing this research to this day,” Border says. “There’s not good communication between subfields.” (A few studies on SLC6A4 and depression have even emerged since their study was published in March.)  

The goalposts can also change. In one particularly influential study from 2003, Avshalom Caspi, Moffitt, and others claimed that people with certain versions of SLC6A4 were more likely to become depressed after experiencing stressful life events. Their paper, which has been cited more than 8,000 times, suggested that these genes have subtler influences, which only manifest in certain environments. And if bigger studies found that the genes had no influence, it’s probably because they weren’t accounting for the experiences of their volunteers.

Border and Keller have heard that argument before. So, in their study, they measured depression in many ways—diagnosis, severity, symptom count, episode count—and they accounted for environmental factors such as childhood trauma, adulthood trauma, and socioeconomic adversity. It didn’t matter. No candidate gene influenced depression risk in any environment.

But Suzanne Vrshek-Schallhorn of the University of North Carolina at Greensboro says that Border’s team didn’t assess life experiences with enough precision. “I cannot emphasize enough how insufficient the measures of the environment used in this investigation were,” she says. “Even for measures that fall below gold-standard stress-assessment approaches, they represent a new low.” By using overly simple yes-or-no questionnaires rather than more thorough interviews, the team may have completely obscured any relationships between genes and environments, Vrshek-Schallhorn claims. “We should not get starry-eyed about large sample sizes, when measure validity is compromised to achieve them. We need to emphasize both quality and quantity.”

But Border argues that even if there had been “catastrophic measurement error,” his results would stand. In simulations, even when he replaced half the depression diagnoses and half the records of personal trauma with coin flips, the study would have been large enough to detect the kinds of effects seen in the early candidate-gene papers.

Similar debates have played out in other fields. When one group of psychologists started trying to reproduce classic results in much larger studies, their peers argued that any failures might simply be due to differences between the new groups of volunteers and the originals. This excuse has eroded with time, but to Border, it feels familiar. “There’s an unwillingness to part with a previous hypothesis,” he says. “It’s hard to wrap your head around the fact that maybe you were on a wild goose chase for years.”  

Keller worries that these problems will be used as ammunition to distrust science as a whole. “People ask, Well, if scientists are publishing crap, why should we believe global warming and evolution?” he says. “But there’s a real difference: Some people were skeptical about candidate genes even back in the 1990s. There was never unanimity or consensus in the way there is for human-made global warming and the theory of evolution.”

Nor, he says, should his work be taken to mean that genes don’t affect depression. They do, and with newer, bigger studies, researchers are finally working out which ones do. If anything, the sordid history of the candidate-gene approach propelled the development of better methods. “I feel like the field of psychiatric genetics felt really burned coming out of the candidate-gene era, and took strides to make sure it won’t happen again.” That includes sharing data openly, and setting standards for how large and powerful studies need to be.

Dorothy Bishop of the University of Oxford argues that institutions and funders that supported candidate-gene work in depression should also be asking themselves some hard questions. “They need to recognize that even those who think they are elite are not immune to poor reproducibility, which leads to a huge amount of waste,” she says.

“We have got to set up a system, or develop a culture, that rewards people for actually trying to do it right,” adds Keller. “Those who don’t learn from the past are doomed to repeat it.”



The rovers moved like migratory birds.

Opportunity and Spirit arrived on Mars within days of each other, at different locations along the planet’s equator, in January 2004, equipped with instruments to study the rust-colored soil. During the Martian winter, engineers directed the rovers to north-facing slopes, so that their solar panels could soak up as much sunlight as possible each day. When one of Spirit’s wheels stopped working, it kept going by driving backwards, dragging the defunct wheel behind it.

But in 2009, the rover’s wheels broke through some crust and slipped into a sand pit. Engineers tried maneuvering the wheels this way and that, but the rover was stuck. For the first time, Spirit couldn’t make its way to a sunny slope.

“We saw it coming,” Steve Squyres, the principal investigator for the NASA mission, told me. “I knew from day one, if Spirit has to spend a winter on flat ground, that was going to be Spirit’s last winter.”

Spirit entered hibernation mode and never woke up. The mission was declared over more than a year after the rover’s last message to Earth and months of attempts to restore contact.

Now it could be Opportunity’s turn. The rover hasn’t called home in 237 days.

Last June, an enormous storm swept across the planet, clogging the atmosphere with sunlight-blocking dust, and the rover, unable to charge its batteries in the darkness, slipped into a deep sleep.

“I haven’t given up yet,” Squyres said.

But the end seems closer now than before. The team has attempted to contact Opportunity more than 600 times since it stopped communicating with Earth last June. At NASA, engineers operate in a realm with the motto “Failure is not an option,” and the agency has a long record of successfully repairing and reviving missions, from Apollo capsules to robotic probes. But the silence feels heavier with each passing day.

Dust storms are common during Martian summer, and Opportunity, about the size of a golf cart, had weathered a similar tempest about a decade earlier.

This time, as the Martian sky darkened, the rover automatically shut off nearly all functions to preserve energy. Engineers suspected that when the storm passed, Opportunity would recharge and awaken with a chirp sent back to Earth. But the skies cleared in September, and the rover didn’t wake up.

The team was not deterred. A season known for dust devils would soon begin on Mars. Perhaps Opportunity’s solar panels were coated in a thick layer of dust, and the wind gusts would wipe it away. But that season ends soon, and Opportunity remains silent.

Last week, NASA’s Jet Propulsion Laboratory, which operates Opportunity, announced that engineers would send a new set of commands to the rover in the next several weeks. The instructions assume some worst-case scenarios for the rover’s systems. “We have not exhausted all the possibilities yet, but we’ve exhausted quite a few of them,” Squyres said.

I asked Squyres whether the team had any more ideas for how to command the rover awake, in case their latest strategy doesn’t work. “No,” he said.

After that, the final call regarding Opportunity’s fate is up to NASA leadership. If the news is bad, the Opportunity team will join a grim club in space exploration: engineers and scientists who have said goodbye to spacecraft after years, sometimes decades, of effort and devotion. Some have known when the end would come, even deliberately planned for it. Others had no warning. In either case, letting go is painful.

The attempts to communicate, the wait, the uncertainty—these can be excruciating when the loss is unexpected, as Jim Spann, a chief scientist at NASA’s Marshall Space Flight Center, knows. In 2005, Spann was working on a spacecraft called IMAGE, or Imager for Magnetopause-to-Aurora Global Exploration, when it suddenly stopped talking to Earth.

Its stewards, stunned, scrambled to troubleshoot. String after string of commands went unanswered. After a year of silence from IMAGE, NASA concluded that it had been knocked out by the cosmic radiation that permeates space. Its hardware had suffered a particularly direct and unlucky hit.

The team remained hopeful. They waited for a solar eclipse in 2007, when IMAGE would be in Earth’s shadow. The spacecraft was designed to reset its computers when its solar-powered battery drained, and perhaps some time in darkness would help. But it didn’t work. “It took me a while to be able to say, ‘Okay, I’m going to close the door on that and work on the next thing,’” Spann says.

The team took some comfort in the knowledge that IMAGE had exceeded expectations. The spacecraft had performed so well after its first two years in orbit that NASA decided to extend the mission. “You’re sitting on maybe, hopefully, years of data that needs work, so that’s what you’re going to do, is just go focus on the data,” says Thom Moore, a scientist at NASA’s Goddard Space Flight Center, who worked on the mission.

Julie Webster knew exactly when her spacecraft would die, seven whole years in advance. Like all spacecraft, Cassini launched to Saturn with a finite amount of fuel. In 2010, Webster, the operations manager, and her colleagues mapped out its final years around the ringed planet. Webster was responsible for flying Cassini and, when the time came, crashing it into Saturn’s atmosphere. The loss didn’t sink in until then.

“I never know exactly how I’m going to feel about something until I get there,” Webster says. “When it was over, the whole team went around in a funk for about six months. It was just like, Oh my God, oh my God, it’s over.”

Webster has bid farewell to other spacecraft in her career, and her reaction has depended on the circumstances of their demise. She wasn’t too torn up about the Magellan spacecraft, a mission launched in 1989 to map the surface of Venus. Magellan was scraped together using spare parts from several other NASA missions, and Webster said team members wore the spacecraft out trying to get as much data as they could. “We were always trying to keep it going, so by the time it was ready to go, it was really ready to go,” Webster says.

The loss of Mars Observer, on the other hand, was traumatic. Engineers lost contact with the spacecraft just three days before it was scheduled to arrive on Mars in 1993. Investigators believe that an explosion in the hardware spun the probe out of control, but no one knows for sure what happened. Webster says it still hurts to talk about Mars Observer.

When a mission ends, scientists and engineers part with more than their spacecraft. They move on to new jobs, on new missions, and their camaraderie, sharpened over years of late nights and stressful moments, dissipates. The mission, vivid and urgent in their mind for so long, fades into a fuzzy memory. And sometimes, even then, it’s still not over.

Last year, IMAGE came back.

An amateur astronomer scanning the skies for radio transmissions detected something broadcasting at the same frequency that IMAGE once used. The former members of the mission, now scattered across different programs, confirmed the signal. After 13 years, IMAGE was awake and calling home.

The data revealed that IMAGE was, miraculously, in good health. Its stewards were overjoyed. But they soon realized that the spacecraft could only receive commands, not act on them. Engineers marked their calendars for upcoming solar eclipses, hoping, as they did years earlier, that a dose of darkness could restart the system.

IMAGE emerged from the most recent eclipse, in mid-January, in the same state. “A successful and lasting recovery is probably unlikely,” says Rick Burley, the engineer leading the recovery effort. Now, more than a decade after the first goodbye, the IMAGE team faces another.

Opportunity and Spirit were never meant to live long lives—they were designed to last just three months. Their years-long sojourns across the Martian surface have produced a rich catalog of data that scientists never imagined. But their minders have also had plenty of time to become attached. If Opportunity remains silent, the time will have come to mourn its end. No delight in discovery comes without some pain.



They passed around a bottle of Malibu rum as gunshots bellowed into the desert night. A trio of young men had set up camp near the unincorporated town of Crystal, 80 miles outside of Las Vegas, Nevada. As recently as 2005, the tiny town hosted two brothels, but by April 2016, it was pretty much empty, ideal for carefree camping on a moonlike stretch of desert, the perfect place to pass around a bottle and a shotgun for some bunny blasting.

As often happens on a night like that, things went downhill. Drunk on rum and the roar of the gun, the three men fired up an off-road vehicle and drove away from camp. Riding in back was Trent, a chestnut-haired, bearded 27-year-old, who carried the shotgun and blasted away at road signs as they tore across the Amargosa Valley and Ash Meadows National Wildlife Refuge. They headed toward a remote unit of Death Valley National Park: Devils Hole, a deep pool inside a sunken limestone cavern. The area’s surrounded by 10-foot-tall fencing, a fortress erected to protect an endangered species of pupfish found there.

Trent shot at the gate to the pedestrian walkway area and then shot the surveillance camera and yanked it from its mount. Then he and one of his companions, Steven, stumbled into the enclosure. Steven was so intoxicated that it took him multiple tries to clear the fence. Inside the enclosure, he paused to empty his bladder.

Filled with mischief, Trent lunged toward his partner and punched him in the crotch with a left hook. Then, as Steven stumbled over to a large boulder to vomit, Trent dropped the shotgun, stripped off his clothes, and slipped into the deep warm water of Devils Hole. He didn’t know it yet, but that would prove to be his worst mistake of the night.

Sixty thousand years ago, a narrow fissure opened up in the Amargosa Valley, releasing water pooled deep in the earth and creating Devils Hole, the opening to an underwater cavern. Scientists disagree over just how it happened—whether by way of underground tunnels, ancient floods, or receding waters—but several desert fish were separated from the larger population and trapped in Devils Hole. There, a tiny subpopulation—the Devils Hole pupfish (Cyprinodon diabolis)—evolved in extreme isolation for tens of thousands of years, eventually, according to scientific consensus, becoming an entirely new species.

Today, visitors to Devils Hole get a rare window into one of the Mojave Desert’s vast aquifers. Steep limestone walls surround a tiny opening into turquoise water. Divers have descended more than 400 feet into the cave without reaching the bottom. The water is so deep that earthquakes on the other side of the world cause it to slosh, shocking the fish into spawning.

The environment in Devils Hole is so remote and extreme that scientists have long puzzled over how the pupfish can live there at all. Still, a modest population has managed to survive on a shallow, sloping rock shelf that gets just enough sunlight—only four hours a day at its peak—to allow algae to grow for the fish to eat.

The Devils Hole pupfish are truly unique. The males are a bright blue, the females a subdued teal, and they’re only about an inch long. They are more docile and produce fewer offspring than their cousins, which are found in pockets ranging from the Southwest toward the Gulf of Mexico. The Devils Hole pupfish lacks the pelvic fin that enables its kin to be vigorous swimmers. But it is able to thrive in temperatures far warmer than similar species can tolerate. Trapped by geology in a consistent 93-degree womb, Devils Hole pupfish have nowhere to go. In fact, they have the smallest geographic range of any known vertebrate species on Earth.

The pupfish were among the first species to be protected under the Endangered Species Preservation Act of 1967—along with the American alligator, the California condor, and the blunt-nosed leopard lizard—and that protection was carried over to the Endangered Species Act of 1973. At the time, about 220 survived in Devils Hole, but since the 1990s, the species has been in significant decline, sinking to just 35 fish in 2013. Today, there are modest signs that the population is growing; the last population count was 136.

The tiny fish has become an icon for those looking to protect endangered species and their habitats, but it’s a target of deep resentment in Nevada, and particularly in Nye County, where, according to critics, the interests of an obscure fish are pitted against the livelihood of local agricultural families. The issue has tested water rights in this arid part of the American West and raised questions about how far officials should go to save a handful of imperiled fish. The drunken invasion of its habitat in 2016 was not unprecedented: Dozens of trespasses have been documented throughout the decades. But such crimes are difficult to investigate and rarely prosecuted.

This time, however, would be different.

On Monday, May 2, 2016, Kevin Wilson, an aquatic ecologist and the manager of the Devils Hole research program, arrived at the Pahrump, Nevada, National Park Service outpost, a beige, low-key building in the middle of anti-fed country.

“We have some news you won’t like,” one of his research associates told him, gesturing toward a surveillance video playing on her computer screen. Wilson peered at the images just as one of the three trespassers tried—and failed—to clear the fencing before barging his way in on the other side of the enclosure.

“As I watched the surveillance footage, I could tell they had definitely been drinking,” Wilson told me when I visited in February. “But it was really just the one guy that had actually gotten in the pool that concerned me the most.”

Wilson, who is 51 with dark-gray hair and bright blue eyes, wears his green uniform comfortably, a slight potbelly protruding above his belt. He jokes often, but the deep wrinkles in his face, tanned from years in the unforgiving Nevada sun, give him a stern appearance.

Normally, the nocturnal visitors would have been caught by a motion sensor that triggered a loud alarm. But a barn owl roosting in the area had caused too many false alarms, and rather than spook the bird, officials had disabled the device. So once the men broke in, they felt no real urgency to leave. Little did they know that multiple cameras captured their every move.

A small earth tremor that occurred over the weekend had prompted Wilson’s staff to review the footage. “Obviously, we saw much more than we had been expecting,” Wilson said, raising an eyebrow.

The video continued to play in Wilson’s office. As one man swam, another remained at the edge of the water, while the drunkest one leaned against a rock. The swimmer climbed out of the water, dragged himself over the algae-covered shelf, and got dressed. Then the party fled on their off-road vehicle.

Wilson paused the video and backed it up. The man who fired the shotgun and plunged into the pool had left a few things behind—his wallet and cellphone. The next morning, in the fog of a hangover, he broke in to Devils Hole to retrieve them, ignoring the empty beer cans and his underwear, which was still floating in the water.

Wilson reviewed one particular piece of footage, a view from an underwater camera, over and over: A foot plunged through the placid, algae-filled water onto a shallow shelf—the only breeding area in the world for the Devils Hole pupfish. The man had waded in at the most inopportune time possible, in late April, the peak breeding period for the pupfish. “I couldn’t immediately tell if any fish were harmed,” Wilson told me. “But I decided to do a site visit to find out for sure.”

That morning, Wilson, his research team, and a bevy of law-enforcement officials assessed the damage. The area reeked of vomit; beer cans were scattered around and Trent’s underwear still floated in the water. The group huddled around for a closer look. In the pool, a single bright-blue pupfish was also floating on the surface—dead.

In February, Wilson took me to the scene of the crime. Wilson has dedicated a good portion of his life to pupfish. He first visited Devils Hole in the 1970s, when he was just 8 years old, tagging along with his geologist mother. Those early visits to national parks and camping trips with his family helped inspire his postgraduate work: the first-ever holistic study of the Devils Hole pupfish. And then the perfect job opened up at the perfect time. “As soon as I defended, this permanent position to study the Devils Hole environment and the pupfish opened up. I’ve been here ever since,” Wilson told me as we stood near the edge of the pond, cold raindrops beginning to fall. Just paces away, pupfish flitted through the water.

The 2016 trespass swiftly activated an intricate legal-enforcement network designed to protect the fish. After reviewing the footage and finding that a pupfish had indeed died as a result of the incident, Wilson notified the National Park Service at Death Valley and in Washington, D.C., as well as the U.S. Fish and Wildlife Service, Nevada Department of Wildlife, and the Nye County Sheriff’s Office.

A team called the Scorpion Task Force was assembled. Its leader was the Park Service Investigative Services’ Paul Crawford, a seasoned Brooklyn-born detective with a constellation of freckles across his face. In 2012, he was the lead detective investigating the murder of the ranger Margaret Anderson in Washington State’s Mount Rainier National Park.

Based in Boulder City, Nevada, and nearing retirement in 2016, Crawford decided to make the trip to Devils Hole. He would supervise two other men: Morgan Dillon and Josh Vann. Dillon, a detective for the Nye County Sheriff’s Office, jumped at the chance to work on the case. “I was excited that I might have an opportunity to go all the way down to the pupfish pool and see the fish,” Dillon told me. “I originally went to college to be a wildlife biologist. I’ve always been passionate about that and still like to read scientific articles on the pupfish. Me, personally, though—I wasn’t smart enough to be a scientist, so I became a detective instead.”

Vann, a ranger at Death Valley National Park, worked alongside Dillon. At Devils Hole, they gathered three empty beer cans as well as two empty boxes that had held shotgun ammunition, two live rounds, and multiple spent shotgun shells. Dillon attempted to fingerprint the beer cans and swabbed them for DNA evidence. He even collected the underwear and entered it into the case file.

Abundant surveillance footage gave the detectives clear images of the three suspects’ faces. “We see you, and now we’re going to find out who you guys are,” Crawford remembers thinking. The four-wheeler stood out most: a blue Yamaha Rhino, with flamboyant stripes along its doors. “It was altered with a second seat, extended roof, skid plates up front. It wasn’t something these guys bought and just drove off the lot,” Crawford said. “Those are a dime a dozen. We would have never found them.”

On May 6, Crawford put out a crime-stoppers tip form. Meanwhile, back at the Nye County Sheriff’s Office, Dillon showed his colleague, Sergeant Thomas Klenczar, an off-road aficionado, video stills of the customized vehicle. “We were really just BS-ing about it,” Dillon said. “But he’s into OHVs and is always on Craigslist, so he decided to take a look.” Minutes later, Klenczar and Dillon found the vehicle on Craigslist. It had been listed for sale just one day prior to the drunken break-in. “The fact that the vehicle was so unique and that we were able to quickly find it on Craigslist was the one and only piece of this that allowed the case to move forward,” Dillon said.

Dillon used the phone number from the Craigslist ad and a house number in one of the photos of the Yamaha to come up with the owner’s name. A photo of the man—Steven Schwinkendorf of Pahrump—matched one of those on the Devils Hole footage.

The early 20th century was an anxious era for the National Park Service. The fledgling agency hemmed and hawed over its identity and whether or not it included a responsibility to protect wildlife and wild spaces.

From the 1920s through the 1940s, the Park Service managed land mostly for tourists to enjoy. In one of the agency’s founding documents, Interior Secretary Franklin Lane described developing the parks as a “national playground system.” The prevailing attitude at the time was that protecting a rarely viewed species such as the Devils Hole pupfish was a project “better left to another agency,” according to Kevin Brown, an environmental historian who authored a 2017 Park Service book on the history of Devils Hole.

With no entity charged to oversee Devils Hole and the pupfish, the deep cavernous pool gained fame among locals. The area, with the pupfish swimming serenely within it, was subject to constant trespass. To this day, locals often refer to Devils Hole as the “Miner’s Bathtub.”

In 1950, an ichthyologist named Carl Hubbs excoriated the Park Service for its refusal to protect Devils Hole. Early the following year, Lowell Sumner, a Park Service biologist, visited Devils Hole and did a pictorial study of it. He argued that it was in the national interest to include this geological wonder in Death Valley National Monument. In 1952, President Harry Truman added the Devils Hole unit to Death Valley National Monument under the Antiquities Act, specifically mentioning the “peculiar race of desert fish,” and declaring that all of the species and ecosystems of Death Valley would be protected. “It was incredibly forward-looking at that time,” said Patrick Donnelly, the Nevada state director for the Center for Biological Diversity. “That was really what began this saga of the role that pupfishes ended up playing in battles down the road.”

On May 9, 2016, the Scorpion Task Force—Dillon, Klenczar, and Vann—drove through Pahrump, Nevada, to meet their first suspect in person. The harsh beauty of the desert around Pahrump clashes with the severity of the city’s neon glow. Under the surrounding Black Mountains, the desert’s sage seems greener, the needles of its barrel cactus redder, and the flash of the nearby casinos, motels, and fast-food chains even brighter. One street is named Unicorn, another Tough Girl. “Don’t Tread on Me” flags wave above many front doors. The locals elected the brothel owner Dennis Hof to the state assembly, a month after the self-proclaimed pimp and so-called Trump of Pahrump died of a heart attack on his 72nd birthday, at a bash attended by the notorious Arizona Sheriff Joe Arpaio and the porn star Ron Jeremy.

The detectives located the suspect’s home and walked to the door. Steven Schwinkendorf, dark-haired, six feet tall, and topping 200 pounds, answered it, facing Dillon, his arms crossed. A small boy, Schwinkendorf’s son, peeked around his legs. Dillon showed the photos from the surveillance video and asked him if the vehicle was his. Schwinkendorf admitted that it was and explained that he had already traded it in as part of a deal for a new four-wheeler.

“Is this you?” Dillon asked, pointing to one of the men on the video, according to investigation transcripts. Schwinkendorf said it was. The other two suspects had come to his house for a barbecue before they went camping, he said. “We had been drinking quite a bit,” Schwinkendorf admitted. He told the detectives that the trio then went to Ash Meadows to shoot rabbits. Schwinkendorf said he had only vague recollections of being at Devils Hole, though he remembered vomiting; his friends had teased him about it.

Schwinkendorf identified his companions—Edgar Reyes, a Las Vegas local, and Trenton Sargent, the skinny-dipper—and gave Dillon their phone numbers.

The next day, Dillon called the other suspects. He first dialed Reyes, who didn’t answer, though he quickly phoned back. Dillon remembers Reyes saying he was scared. “I woke up, and my face is plastered all over everywhere on the internet,” Reyes said. He admitted to the trespass and confirmed that the shotgun belonged to him, but he said that all three of them had been shooting it. “Not long after speaking to him, I got a call from his attorney,” Dillon told me.

But Dillon had yet to reach Sargent. “I was afraid that Schwinkendorf and Reyes would get to Sargent and spook him. I felt like I was running out of time.”

That afternoon, Dillon called Sargent. “He told me that he heard I was looking for him,” Dillon said. “He was very cooperative and forthcoming.” The crime-stoppers tip had gone viral, and in the days since it went public, Sargent told Dillon he had received “hundreds of messages” and even a few death threats. He admitted that he had taken off his clothes and gone swimming in the pool. “I was showing off for my friends,” Sargent said, “and I wanted to see how deep it was.” His demeanor was extremely polite, Dillon remembers, and they spoke on the phone for several minutes.

“Sargent asked me, unprompted, if I had run his criminal history,” Dillon told me.

“I have so much to tell you,” Sargent said to Dillon. “I’m a convicted felon. I know that I can’t have a gun, that I can’t be around guns. I wasn’t intending to shoot that night and was just going to hold the spotlight while the others shot.” There was a pause—a long-enough silence that Dillon thought the phone might have been disconnected. “But because of the drinking, I shot as well,” Sargent told him.

Sargent had been convicted of grand theft of money and property three years earlier in San Bernardino, California. He had struggled with addiction for most of his teenage and early adult years, but since then, he had cleaned up his life and returned to his hometown, Indian Springs, Nevada. He lived in a trailer and often saw his son, Logan, who was then only one month old and lived with his in-laws in town.

Sargent later admitted to knowing about the pupfish and their endangered status, but insisted he didn’t mean to harm them. His drunken break-in was a slip, he said, a momentary lapse of judgment.

Trent Sargent’s swim was just the most recent threat to the existence of the Devils Hole pupfish. Back in the late 1960s, after the National Park Service began its first studies and population counts, the Cappaerts, a ranching family in Pahrump, decided to dig a number of wells on their 12,000-acre ranch just a few miles from Devils Hole.

When the Cappaerts began pumping, the water level in Devils Hole dropped, exposing large parts of the algae shelf. That exposure, the Park Service argued, decreased algae production and limited the pupfish’s spawning area, which in turn reduced its chance to survive. The aquifer level lowered so drastically that it alarmed not only Park Service staff, but also the U.S. Fish and Wildlife Service and Nevada Department of Wildlife. The park’s staff ordered the Cappaerts to stop pumping.

The Cappaerts said they had spent a lot of money drilling the wells and changing their farming operation, and that they intended to go right on pumping without limitation under “absolute dominion,” also known as the “English Rule,” a 19th-century common-law doctrine adopted by some U.S. states that allowed landowners to use as much groundwater as they pleased. (Nevada had actually abandoned absolute dominion in favor of prior appropriation for both surface and groundwater decades earlier.) The Park Service argued that the special status of the Devils Hole pupfish under the Endangered Species Act and its habitat’s status as a national monument trumped the Cappaerts’ rights to the water.

The Cappaert case went all the way to the U.S. Supreme Court, testing the power of the Antiquities Act and the weight of the new Endangered Species Act. In 1976, the high court affirmed the federal government’s right to maintain water levels sufficient to support the pupfish, even at the expense of water rights held by nearby ranchers.

The decision enraged the residents of Nye County. The attorney representing the Cappaerts argued, “There are two endangered species here: the pupfish and the American rancher,” and said the federal government had chosen a fish over the people. A Pahrump newspaper editor even threatened to throw the pesticide Rotenone into the sunken cave to “make the pupfish a moot point.” The community split into factions, and anger pervaded the air. Warring bumper stickers—KILL THE PUPFISH and SAVE THE PUPFISH—were plastered on cars, street signs, and office buildings across the Southwest.

But the decision has stood the test of time. In the late 1970s, the Cappaert family sold their ranch. The land has since changed hands a number of times, eventually becoming the Ash Meadows National Wildlife Refuge. Had that case gone any differently, had the Park Service not decided that part of its mandate was to protect the species and stop the Cappaerts from pumping—had Truman not designated Devils Hole a national monument in the first place—the Devils Hole pupfish might now be extinct, though Pahrump would probably be a little greener. “If it weren’t for that decision, the Amargosa Valley would have been pumped dry a long time ago,” Wilson, the biologist, told me recently. “There would be no Death Valley, no Devils Hole, no Devils Hole pupfish—but there would be a whole lot more golf courses, I bet.”

The Devils Hole pupfish, a tiny species that has survived such obstacles, represents a paradox for Wilson, who would not live in Pahrump were it not for Devils Hole. He told me that adjusting to a life in the gravel-covered, billboard-lined city was difficult for him and his wife, a Canadian, who, after a few years in Nevada, finally found her niche in, of all things, golf. “I do wish I could just pick up and move Devils Hole and put it somewhere with a higher standard of living,” Wilson told me. “But it’s worth protecting—and worth punishing people who threaten this little species.

“The most important advances in science have come from the edges of what’s possible—from the most extreme environments,” Wilson said. “We have a lot to learn about how the Devils Hole pupfish has even been able to survive.”

Trent Sargent turned himself in just after Memorial Day and pleaded guilty to violating the Endangered Species Act, destruction of federal property, and possessing a firearm while a felon. A few days before his October sentencing, he submitted a letter to U.S. District Judge Andrew Gordon, who would decide his fate.

“I’m not one to make excuses for what I have done wrong and I’m not going to start now,” he wrote, in all capitalized, slanted script. “I made a stupid mistake ... I’m not a bad person, your honor, and I take full responsibility for my actions and the crimes I committed ... I would like to ask you to accept this letter to you as my verbal ‘handshake’ that upon my release I will complete all stipulations given to me by the courts and you will not see me again in your courtroom.”

On the afternoon of October 25, 2018, Sargent stood quietly beside his lawyer in a Las Vegas courtroom as Judge Gordon handed down his sentence: a total of 12 months and one day—nine months specifically for his violation of the Endangered Species Act—in the custody of the Federal Bureau of Prisons. Once he is released from the Los Angeles Metropolitan Detention Center, Sargent must pay nearly $14,000 in restitution to the National Park Service, along with a $1,000 fine. He’s also forbidden to enter federal public lands for the rest of his life.

Four months later, I journeyed to Indian Springs, Nevada, an unincorporated community of fewer than 1,000, where Sargent has lived for most of his life. It’s home to Creech Air Force Base and the Desert Warfare Training Center. I met Sargent’s family at their spacious and warmly lit double-wide manufactured home. There was a chill in the air and a blustery wind, but his mother, Norine, sat outside, watching her grandchildren jump on a trampoline in the yard. Trent’s father, Josh, joined us a few minutes later, home from work at the Nevada National Nuclear Security Site, where he’s been employed as an ironworker for 30 years.

I had assumed that the Sargent family would consider what happened to their son unfair. But I was wrong. In fact, they defended the Endangered Species Act with a conviction that surprised me, and they knew a lot about Devils Hole and the pupfish that swam there. Norine recalled the family taking trips to Devils Hole when Trent was a boy, teaching him about the pupfish. “Trent would just as soon give first aid and mouth-to-mouth resuscitation to that little pupfish than have this thing go on and on,” Josh Sargent said. He acknowledged that his son was paying the necessary price for his actions. “He knows about endangered species, and he takes responsibility for what he did.”

The Sargents’ home was filled with pictures of family, including several of Trent throughout the years. In one, the beaming 12-year-old holds up the first fish he ever caught, a minuscule rainbow trout. But now Trent can’t visit public lands or use a firearm. “Trent grew up hunting and fishing,” Norine said. “And now he’ll never get to go hunting with his dad ever again.”

Had that fateful evening unfolded just slightly differently—had that single pupfish not died—Trent would very likely be sitting in the living room with his family. Sometimes it is a bitter pill for the Sargents to swallow. “I understand the way people feel about the fish,” Josh Sargent said. “But what if someone runs over a cat? Are they going to stop and make sure the cat is alive? No, I don’t think so. They’re just going to keep on truckin’. But Trent kills a fish—and certainly not intentionally—and he’s in prison ... We’re not trying to defend him; the Sargent family is deeply sorry for what happened.”

Because there are so many endangered species, society is forced to make difficult choices about which ones to protect, and to what lengths we should go to save them. Climate change has quickened the pace of extinction, and already the number of critically endangered species exceeds our ability to save them all.

The Devils Hole pupfish, serene, obscure, and tiny, has survived a very long time in an unkind place, just one drunken night or one jug of poison away from oblivion. It is a wonder, to be sure. But how far do you go to save a species like this? For Wilson and the others at Death Valley National Park, it means surrounding this biological wonder with an impenetrable cage. Biologists occasionally feed the fish and clean out Devils Hole as if it were a giant aquarium. They even have a backup population held in a huge climate-controlled tank nearby, insurance against outright extinction. Protecting the species means harsh punishment for anyone who kills even just one fish, according to Patrick Donnelly of the Center for Biological Diversity, which offered a $10,000 reward for help in identifying the drunken skinny-dipper and his friends. “We desperately wanted justice for this. If they didn’t get the book thrown at them, what’s stopping others from doing whatever they want and eliminating an entire species?”

Since the incident, Devils Hole has become an even more formidable fortress. The Park Service capped its towering fences with additional barbed wire. The public can only view the sunken cave from a distance now, more than 20 feet above it. And inside the fenced viewing area are even more cameras, motion sensors, and No Trespassing signs.

“I hate it,” Wilson told me this winter. “I hear from the public all of the time, ‘Why does this place look like a prison?’ People get really upset that they can’t get a closer look. But it’s just what we have to do—to stop people from doing stupid things.”

This post appears courtesy of  High Country News.



It has taken her two decades, but Chi-Hing Christina Cheng has finally solved her ultimate cold case—a fishy mystery that extends from one frigid end of the planet to the other.

Cheng, a Chinese-born biologist, moved to the United States as a teenager and began working in Antarctica in 1984. There, she and her partner, Arthur DeVries, studied the notothens—a group of fishes that swim in the continent’s subzero waters. These animals survive at temperatures that would kill other fish because they produce their own antifreeze—a protein that courses through their blood and prevents ice from forming.

The protein is incredibly simple. It comprises the same three chemical building blocks, repeated over and over—one threonine and two alanines. This repetitive unit, which I’ll call “thralala” for convenience, is perfectly shaped to stick to ice crystals, creating a barrier that stops water molecules from joining and prevents the crystals from growing. Hence: antifreeze.

In 1997, Cheng and DeVries, both at the University of Illinois Urbana-Champaign, found that the gene that makes this antifreeze protein had an unexpected origin—it arose from an ancestral gene that makes a digestive enzyme. Coincidentally, a tiny snippet in the middle of this digestive gene had exactly the right code for making the thralala unit. Over millions of years, that snippet must have duplicated itself, again and again, turning an old digestive gene into a new ice-binding one, and allowing the notothens to survive in Antarctic waters. Very cool.

While discovering all this, Cheng and DeVries learned that at the other end of the world, Arctic cod also make antifreeze proteins, and their versions are built from exactly the same thralala units as the notothens’. The two groups had evolved almost identical antifreezes independently—a stunning example of convergent evolution, where two organisms turn up to life’s party in the same outfit. But there was a big difference between them: The cod antifreeze gene did not arise from a digestive one, and for the longest time Cheng couldn’t find its ancestor. “The gene had to have come from somewhere,” she says.

“These 1997 papers are classics,” says Aoife McLysaght from Trinity College Dublin, who studies the evolution of new genes. “The case for the Antarctic one was very clear, but all they could say was that the Arctic one wasn’t the same. It was also a new gene, doing the same thing. But it had a different origin, and what that origin was wasn’t clear.”

Now, after 22 years, Cheng has finally solved the mystery, and the answer is stranger and more convoluted than she imagined. Her team, which includes her colleagues Xuan Zhuang, Chun Yang, and Katherine Murphy, compared three species of cod that make antifreeze with four that do not. They compared pieces of antifreeze genes from the former against the DNA of the latter, in the hope of finding sequences that shared a vague resemblance. They found a hit—but in a functionless stretch of cod DNA that doesn’t include any genes at all. Somehow, this region of useless junk gave rise to a new and very useful gene. And Cheng’s team has deduced how this happened, step-by-step.

First, through random chance, a short stretch of junk DNA was duplicated twice, creating four identical segments in a row. The stretches between these segments were very close to the code for the thralala unit, and through a single mutation, one of them turned into exactly the right code. This snippet then duplicated, over and over, creating the core of a new antifreeze gene.

But for genes to be useful, they need more than the right sequence. They also need to be next to switches that allow them to be activated in the right time and place. In this case, the newborn antifreeze gene was serendipitously reshuffled to a different spot in the cod genome, where it landed next to one such switch.

At this point, the ancestral cods had a gene for antifreeze and could switch that gene on. But they needed one last tweak: a small signal sequence that acts like a shipping label, allowing the antifreeze proteins to be exported from the cells that make them and into the rest of the animal’s body. Fortunately, that signal was already almost in place: It took just one mutation—the loss of a single DNA letter—to create it.

These changes—duplication, mutation, relocation, and deletion—are the kinds of genomic shenanigans that happen to DNA all the time. The first steps, Cheng thinks, were likely completely random. But once the fish acquired those first thralala units, natural selection had something to work with. Those fish could probably have made small amounts of weak antifreeze, gaining an incremental advantage. Those fish with more thralala units did better; those that brought those units under the auspices of a switch did better still; and those that evolved the shipping label did best of all. All this happened as the Arctic gradually cooled over a substantial amount of time. Slowly, junk became gold. “This goes to show how creative evolution can be,” Cheng says. “It used a sequence we thought was useless and turned it into a vital adaptive protein.”

“This protein is particularly easy to evolve because you just need this [thralala] pattern,” McLysaght says. “But it’s still a very nice example of a new gene arising from scratch, from a noncoding sequence. It’s really neat.” Other proteins are much more complicated, and Cheng suspects that many of them will also have convoluted histories that began in junk. “It’s just a matter of time to figure out how they came about,” she says.

Indeed, this “is a relatively common mechanism for evolutionary innovation,” says Li Zhao from Rockefeller University, who notes that in the past decade, scientists have found many examples of genes that arose in this way. But in most of these cases, it’s not clear what those new genes actually do. The cod antifreeze is special because it’s a new gene whose role is both very obvious and very important. We not only know that it evolved, but also why—to prevent the cod from icing over.



In April 2018, a monkey named Ringo sat in a Harvard lab, sipping juice, while strange images flickered in front of his eyes. The pictures were created by an artificial-intelligence algorithm called XDREAM, which gradually tweaked them to stimulate one particular neuron in Ringo’s brain, in a region that’s supposedly specialized for recognizing faces. As the images evolved, the neuron fired away, and the team behind XDREAM watched from a nearby room.

At first, the pictures were gray and formless. But as time passed, “from this haze, something started staring back at us,” says the neuroscientist Carlos Ponce. Two black dots with a black line beneath them, all against a pale oval. A face, albeit an abstracted one. Soon a red patch appeared next to it, which reminded the watching researchers of the red collar worn by a monkey who lives in the cage opposite Ringo’s. “We all looked at it and said, ‘Oh, that’s Anthony,’” says Margaret Livingstone, a neuroscientist at Harvard Medical School.

“And then, a few days later, we evolved Diane,” she adds. Diane is one of the monkeys’ caretakers, who feeds them while wearing blue scrubs and a white face mask. And when the team hooked XDREAM up to another of the monkey’s visual neurons, it produced a distorted image of a face in a white mask.

XDREAM’s images look like glitchy Kandinsky paintings viewed during a bad trip. You really wouldn’t want to hang them on your wall. But each one is close to the ideal stimulus for a particular neuron. And collectively, they tell us something interesting about how our brain makes sense of the world, and how much we still don’t understand about that process. “If cells are dreaming, [these images] are what the cells are dreaming about,” says Ponce. “It exposes the visual vocabulary of the brain, in a way that’s unbiased by our anthropomorphic perspective.”

New pre-print on #bioRxiv 'Evolving super stimuli for real neurons using deep generative networks'. With @HombreCerebro, @WillXiao1, @Till_S_Hartmann, @gkreiman, and @mlivingstonehms https://t.co/OZMhiPllK1 pic.twitter.com/iTaI4nBEcE

The first hints of that vocabulary emerged in 1962, when Torsten Wiesel and David Hubel showed that specific neurons in the brain’s visual centers are tuned to specific stimuli—lights moving in particular directions, or lines aligned in particular ways. Since then, other neuroscientists have identified neurons that respond to colors, curvatures, faces, hands, and outdoor scenes. But here’s the catch: Those scientists always chose which kinds of shape to test, and their intuition might not reflect the actual stimuli to which the neurons are attuned. “Just because a cell responds to a specific category of image doesn’t mean you really understand what it wants,” says Livingstone.

So why not ask the neurons what they want to see?

That was the idea behind XDREAM, an algorithm dreamed up by a Harvard student named Will Xiao. Sets of those gray, formless images, 40 in all, were shown to watching monkeys, and the algorithm tweaked and shuffled those that provoked the strongest responses in chosen neurons to create a new generation of pics. Xiao had previously trained XDREAM using 1.4 million real-world photos so that it would generate synthetic images with the properties of natural ones. Over 250 such generations, the synthetic images became more and more effective, until they were exciting their target neurons far more intensely than any natural image. “It was exciting to finally let a cell tell us what it’s encoding instead of having to guess,” says Ponce, who is now at Washington University in St. Louis.

There’s a risk that XDREAM could become a glorified Rorschach test, in which researchers see what they want to see. Is that red splotch really Anthony’s collar? Is the white one really Diane’s masked face? To check, the team used another algorithm to confirm that the synthetic images they saw as face-like really do look more like actual faces than other natural photos. They also showed that the neurons that prompt XDREAM to create face-like motifs themselves respond best to photos of true faces.

I mention to Ponce that XDREAM’s images are really unsettling, as if they’ve been plucked from some deep recess of the uncanny valley. “Yes!” he laughs. “They are!” He thinks they’re so good at stimulating monkey visual neurons that they’re also tickling our cells in a way that makes us feel uncomfortable. If one could use XDREAM on human neurons, “would we find similar images or different, and what would we think of them?” he asks. “At the moment, that’s not something anyone can do. But it makes me wonder.”

Livingstone also wonders whether XDREAM’s disquieting output hints at why so many mythical creatures are exaggerated versions of familiar things. Visual neurons, it seems, like exaggeration: In previous studies, her team showed that face-selective cells will respond more strongly to caricatures than to actual faces. “I think that gargoyles and leprechauns, these archetypes that people imagine … there’s a basis in our brains for them,” she says.

Beyond being weird, the most striking thing about XDREAM’s images is that they’re mostly unrecognizable. The team probed 46 neurons across six monkeys, and a few face-like motifs aside, most of the resulting images were messes of color, texture, and shape, which didn’t fit into obvious buckets. “It is striking that cells that were thought to code for simple objects or object parts may in fact code for much more complex visual stimuli,” says Leyla Isik, a neuroscientist at Johns Hopkins University. “Some may find it unsatisfying that the generated images cannot be described easily in terms of semantic categories. This ‘limitation,’ however, may just be a reality of the complex nature of the primate visual cortex.”

Through these experiments, researchers are learning more not just about the brain itself, but also about how to simulate it. Many neuroscientists have developed artificial neural networks that can analyze images and recognize objects, ostensibly by doing something close to what the brain’s actual visual centers do. But how close?

To find out, Pouya Bashivan at MIT used one such neural network to create images that should, theoretically, stimulate an actual brain in particular ways. His colleagues, Kohitij Kar and James DiCarlo, then showed these synthetic images to monkeys to see whether they worked as predicted.

The results were encouraging, if mixed. The neural network succeeded in fashioning images that would stimulate specific neurons more strongly than natural photos. But it wasn’t as good at another task: exciting one neuron while suppressing all its neighbors. This varied scorecard suggests that the network isn’t yet capturing everything there is to capture about the visual system.

Still, it’s capturing something. Bashivan’s team focused on a region that supposedly responds to simple curves, but the images that his network churned out included grids, lattices, and cinnamon-roll swirls. Much like XDREAM’s hallucinogenic not-quite-faces, these complex images suggest that our understanding of how the brain sees the world is too basic. “If we only go by the intuitions of human researchers, we might get it wrong,” says Bashivan. “We’ll do better if we have models that contain all the knowledge in the field.”

“As biologists, many of us are still skeptical that current neural networks are similar enough to the brain to model it reliably,” Ponce says. But like Bashivan, he thinks that such models are the way forward, and studies such as these will help improve them. “Both approaches are about understanding a black box: the brain,” he says. “Both methods are necessary.”



Suddenly, climate change is a high-profile national issue again.

It’s not just the Green New Deal. Around the country, the loose alliance of politicians, activists, and organizations concerned about climate change is mobilizing. They are deploying a new set of strategies aimed at changing the minds—or at least the behaviors—of a large swath of Americans, including utility managers, school principals, political donors, and rank-and-file voters.

They make a ragtag group: United by little more than common concern, they don’t agree on an ideal federal policy or even how to talk about the problem. They do not always coordinate or communicate with one another. And while their efforts are real, it remains far too early to say whether they will result in the kind of national legislative victories that have eluded the movement in the past.

But for the first time since November 8, 2016, if not far earlier, climate advocates are once again playing offense.

This mobilization starts at the top of the U.S. political system. Earlier this month, Washington State Governor Jay Inslee announced that he would run for president to elevate climate change as a pressing national issue. Inslee’s launch did not mention his White House–ready biography—he’s a former star athlete who married his high-school sweetheart—and focused entirely on his decades-long climate focus.

“I’m the only candidate who will make defeating climate change our nation’s number-one priority,” Inslee said in his launch video. His campaign raised $1 million in its first three days, a surprisingly large figure for a single-issue underdog candidate.

Other national political leaders are trying different strategies. Michael Bloomberg, the former New York mayor who has made climate a signature issue, announced that he would not run for president because his considerable fortune would be better spent fighting carbon pollution directly. Instead, he will fund a new campaign called Beyond Carbon for the Sierra Club, an extension of the club’s wildly successful Beyond Coal campaign, also bankrolled by Bloomberg. Beyond Coal says it has helped close 285 of the country’s 530 coal plants, a major reason for the overall decline in U.S. carbon emissions.

This widespread public concern about climate change is already being reflected in policy made at the state level. New Mexico will soon become the third state to set a goal for 100 percent carbon-free electricity. Last week, lawmakers passed a mandate that by 2045, 80 percent of the state’s power must come from renewable sources and 20 percent from carbon-free sources. The governor cheered the measure and is expected to sign it.

California, Hawaii, and the District of Columbia have adopted similar goals, all pegged to 2045. And their ranks could soon expand. Twelve more Democratic governors have promised to mandate the same 100 percent target, according to Rob Sargent, a campaign director at Environment America, a consortium of state-level environmental groups. “Six governors got elected in November running on 100 percent renewables,” he told me. “That wouldn’t have happened four or even two years ago.”

Excitement is also coming from the grassroots. On Friday, thousands of U.S. students refused to go to school, participating in a worldwide student strike for climate action. The Sunrise Movement, a youth-led group that brought national attention to the Green New Deal in November, plans to hold 100 town-hall meetings in support of the plan across the country, organized by local chapters.

Much of this activity is concentrated among Democrats. But public opinion has shifted in their favor on the issue. Nearly two-thirds of Americans say that the Republican Party’s position on climate change is “outside the mainstream,” according to an NBC/Wall Street Journal poll conducted last month. That represents a nine-point bump since October 2015, when the question was last asked.

That poll was conducted in February, when the Democratic-led Green New Deal dominated media coverage. But a majority of Americans said that month that Democratic positions on climate change were “in the mainstream.”

Within the party, rank-and-file Democrats seem to be taking the issue more seriously. Eighty percent of likely Iowa Democratic caucus-goers say that primary candidates should talk “a lot” about climate change—a result that suggests climate change is one of the Democratic Party’s top two issues, according to a CNN/Des Moines Register poll conducted by Selzer and Company this month. Only health care merited such consensus concern among the group.

That points to a potential upheaval in how important voters consider climate policy. In May 2015, when the same polling firm last posed a similar question to likely Democratic caucus-goers, climate change did not rank among the top five most important issues.

And several recent polls have also identified a huge, nearly 10-point surge in worry about climate change among all Americans. “We’ve not seen anything like that in the 10 years we’ve been conducting the study,” Anthony Leiserowitz, a researcher at Yale, told me in January.

Those national surveys found that Americans were motivated by a series of urgent new reports about climate science and an outbreak of extreme weather.

Some Republicans say they’re taking notice. “I think we’re moving from the science of climate to the solutions of addressing climate, and that is a big shift in particular for Republicans,” says Heather Reams, the executive director of Citizens for Responsible Energy Solutions, a nonprofit that encourages GOP politicians to support renewable energy.

This shift, if it is occurring, has yet to result in concrete policy proposals. Nor is it shared across the party. Some Senate Republicans have embraced “innovation” as a possible solution to climate change, but the Trump administration last week proposed zeroing out the budget for two major Department of Energy innovation programs. The programs will survive, however, in part because they have the support of Lamar Alexander, a powerful Republican from Tennessee who chairs the Senate Appropriations Subcommittee on Energy and Water Development.

In the House, Republicans are far more skeptical of climate action. Representative Rob Bishop, a conservative lawmaker from Utah, has said the Green New Deal is nearly “tantamount to genocide.” The House GOP has offered very few climate policies of its own. An exception: Two Republicans—Representative Brian Fitzpatrick of Pennsylvania and Representative Francis Rooney of Florida—last year co-sponsored a bipartisan bill to tax carbon emissions without increasing the federal budget.

It’s still unclear whether the spike in public concern will translate to any lasting GOP shift. The Green New Deal, in all its ambition and haziness, has reframed the climate conversation around solutions, where Democrats have more to say right now; if moderate Democrats fell back to insisting on the acceptance of climate science alone, Republicans might be happy to meet them there.

In any case, the views of the country’s most powerful Republican, President Donald Trump, seem extremely unlikely to change. So it’s left to his would-be 2020 opponents to heighten the contrast. At least eight candidates have made climate change a top issue, according to The New York Times. And announcing his candidacy for president last week, the former Representative Beto O’Rourke of Texas said that “interconnected crises in our economy, our democracy, and our climate have never been greater.” (He has yet to offer a concrete proposal on the issue.)

Whether this focus on climate change produces new policy ideas remains to be seen. Yet even so, environmental groups and their allies are feeling whiplash at how far the conversation has come since 2016. Says Alex Trembath, the deputy director of the Breakthrough Institute, an environmental research center based in Oakland: “If you had asked me a year ago if we would’ve been talking this much about climate change now, I would’ve said, ‘Absolutely not.’”



Thirty-eight years ago, an infant boy—hours old, tears frozen on his face—was found dead in a ditch in Sioux Falls, South Dakota. Last week, police arrested his mother and charged her with murder, after investigators uploaded the baby’s DNA to a genealogy website and matched her relatives.

The same strategy led police to the Golden State Killer suspect in April 2018, and since then law enforcement working with genealogists have made dozens of arrests for rape and murder around the country. Once a headline-grabbing technique, forensic genealogy has become quietly normalized. Now this powerful tool, first used to catch a serial killer, is being applied to abandoned-baby cases that genealogists once hesitated to take on.

More dead and abandoned babies are likely to be identified soon. The Sioux Falls police worked with a forensics company called Parabon NanoLabs, which opened a dedicated genealogy unit after the surge in interest following the Golden State Killer case. Another company called IdentiFinders, run by the forensic genealogist Colleen Fitzpatrick, says it is working on three abandoned-baby cases.

One such case—the death of a baby boy found frozen in Connecticut in 1998—has been in the works since before the Golden State Killer, and its arc demonstrates how much attitudes have changed. This baby was supposed to be the first case of a nonprofit, the DNA Doe Project, that Fitzpatrick founded with Margaret Press in 2017. They planned to use genealogy to identify John and Jane Does, and Fitzpatrick and Press even paid to sequence the Connecticut baby’s DNA out of their own pocket. But over and over again, people advised against taking the case. One medical examiner even told the team she would not work with the DNA Doe Project if it tried to identify dead babies.

At the time, using genealogy databases for cold cases was still controversial. Finding the mother of an abandoned baby did not seem like a good test case. “What if you find a 16-year-old girl who was raped by her father and years later we haul her off to jail?” Press says. They feared a backlash would shut off their access to genealogy websites forever.

Then, police arrested Joseph James DeAngelo as the Golden State Killer, the infamous serial killer and rapist who had terrorized California for decades. “It was a good poster case for the cause,” Press says. In fact, it’s hard to imagine a better one. The case has since spawned a forensic-genealogy industry. Parabon announced its new genealogy unit just weeks after the case. Recently, another forensics lab called Bode Technology launched a similar service. Fitzpatrick’s company, IdentiFinders, uses genealogy to ID perpetrators, including in the Connecticut baby case, and the nonprofit DNA Doe Project works on unidentified bodies, most of them murder victims. So many arrests have been made through genealogy that each one is no longer national news.

The Sioux Falls case has gotten more attention because it involved a dead baby, but it has kicked up very little of the controversy that genealogists once feared. “We’re in a different world now,” Fitzpatrick says. The woman arrested in Sioux Fall, Theresa Rose Bentaas, confessed to abandoning her baby hours after birth in 1981, when she was 19. The public details are scant, but police also interviewed the father—to whom Bentaas is now married—and determined he did not know of the pregnancy. Bentaas alone was charged with murder in the first degree, murder in the second degree, and manslaughter in the second degree.

The killing of a infant within the first 24 hours of life is called neonaticide, and Michelle Oberman, a law professor at Santa Clara University who has studied the issue, says there are probably hundreds of cases every year. The criminal-justice system is not always sure how to deal with them. Charges can range from unlawful disposal of a body to first-degree murder.

In general, Oberman says, “There’s a pretty distinct pattern of overcharging and under-convicting.” Because the cases can be so shocking and incomprehensible, Oberman says prosecutors sometimes ask for murder charges and very long sentences. Many of the women—or girls—desperate enough to abandon their babies are isolated and come from tough family situations. The fathers are usually not in the picture. “When they do go to trial, if it does happen, juries tend to recognize there’s blood on more than one set of hands,” Oberman says. These are complicated cases.

Currently, no laws limit when police can use genealogy databases to catch criminals. (A legislator in Maryland has proposed a law outlawing the practice in that state.) But genealogists have so far limited their criminal investigations to violent crimes, per the terms of service of GEDmatch, the public genealogy site where they upload crime-scene DNA. Steven Armentrout, CEO of Parabon, told me that his company follows those terms of service, and it was police who determined the Sioux Falls case to be a murder case. When I asked Armentrout about regulating how genealogy should be used, he pointed out that police don’t have special access to GEDmatch. “Police can do anything an ordinary citizen can do. We’re using a publicly available database,” he said.

As the use of genealogy to solve crimes becomes routine, some wonder how far it will go. Debbie Kennett, a genealogist in the U.K., says she was “horrified” by the use of genealogy in this case and feared a slippery slope. She points to a case in Georgia in which investigators decided to test DNA from a fetus found in a sewage plant. (It’s unclear whether they were only trying to upload the DNA to law-enforcement databases or also consumer genealogy ones.) The fetus was later found to be the result of a miscarriage, but DNA could theoretically be used to investigate illegal abortions.

In most cold cases, arresting the murderer or identifying the victim is a way to bring resolution to the victim’s family. Identifying the mother of a dead and abandoned baby is different. “Ultimately it’s about punishment, not about closure for a family,” Press says.

At the press conference announcing the arrest in Sioux Falls, police too acknowledged the unusualness of this case. “When we have cases like this, we have family that we can—it’s not share the joy, because there’s nothing joyous about it—but at least let them know we work hard for them,” the detective said. This case was different, he admitted. “We didn’t have that in this case. In this case, the family is the person that did it.” For 38 years, they had kept the case alive. It is solved now, but there is no family to thank them for their work.



Updated at 1:18 p.m. ET on April 12, 2019.

The malfunction happened just a few miles from the surface.

The spacecraft had spent days orbiting the moon and, before that, about a month and a half traveling the 4 million miles from Earth. Back home, its creators sat tense in a control room as they waited for the spacecraft—the product of years of effort and engineering—to land on the terrain.

“We’ve passed the point of no return,” said Opher Doron, who leads the space division at Israel Aerospace Industries, the country’s aerospace manufacturer, as the spacecraft pushed itself out of orbit on Thursday. “We’re in the landing process.”

The descent seemed to be going smoothly. And then: “We seem to have a problem with our main engine,” Doron said.“We are resetting the spacecraft to try to enable the engine.”

The landing sequence was preprogrammed. This was about the most they could try, and it appeared to work. “We have the main engine back on,” Doron said a few seconds later. Then, another voice in the control room: “But it’s not. No, no.”

Engineers lost communication with the spacecraft. Designed to touch down gently on the moon, it crashed instead.

Many spacecraft have gone to the moon in the past 60 years, some carrying people, but this was unlike the rest in one distinct way. If the spacecraft, named Beresheet—Hebrew for “in the beginning,” the opening of the Book of Genesis—had landed, it would have become the first spacecraft built by a private organization, not a national government, to touch the moon. And Israel, the home of the nonprofit group, SpaceIL, would have become the fourth nation—after the former Soviet Union, the United States, and China—to put something on Earth’s cratered companion. (Israel still joins a different space club, as the seventh nation to orbit the moon.)

“Well, we didn’t make it, but we definitely tried,” says Morris Kahn, the billionaire entrepreneur who funded the effort. “And I think the achievement of getting to where we got is really tremendous. I think we can be proud.”

Before anticipation morphed into mourning, Beresheet sent one final photograph back to Earth: a close-up of the surface of the moon, the jagged terrain illuminated in the sunlight, almost the color of sand, specked with craters filled with shadows.

“I was shaken,” Yoav Landsman, the deputy mission director and an engineer at SpaceIL, told me after the crash. “It was very hard for me.”

“Space is hard,” people will say, an axiom that brings little comfort, at least in the moment when a beloved spacecraft smashes down. There are enough triumphs these days that the failures seem especially jarring, almost hard to believe. Hours after Beresheet sent its final transmission, SpaceX’s Falcon Heavy, the most powerful rocket in the world, launched for the second time, hurling a commercial satellite into orbit and pirouetting a trio of boosters back to Earth. (SpaceX even launched Beresheet itself, in February, on its Falcon 9 rocket.) Only a few months ago, China successfully landed a spacecraft on the far side of the moon, a feat no one had ever attempted.

The Beresheet mission arose from a global Google-sponsored competition that challenged privately funded teams to develop, launch, and land a rover on the moon, with a $20 million prize if it worked. More than 30 teams entered the contest in 2007. A decade later, five remained, but everyone was behind schedule. Last year, when it became clear that no one would meet a 2018 deadline, the competition was canceled. As Beresheet wound its way to the moon, the foundation behind the effort announced that SpaceIL would get $1 million if the team could stick the landing. After the crash, the funders said that SpaceIL would still receive the prize.

Space is hard, and more people than ever before have chosen to face down the challenge. For decades, only governments launched stuff into space, from spy satellites to Golden Records to blue-eyed men with buzz cuts. Now the work is done by private entities such as SpaceX, and they get to decide what goes up. Sometimes it’s a red Tesla convertible. Other times it’s a moon lander from a nonprofit. And other spacecraft—landers and rovers—are on their way; commercial companies around the world are working on missions to the moon at a pace not seen since the Apollo era.

Few had imagined this future even a decade ago. Now commercial rockets and payloads seem rather ordinary, and governments are paying private companies to do the job they used to do.

Still, achievements in space by private groups are celebrated as wins for the country that hosts them. That’s especially true in Israel, a country dubbed “start-up paradise” for its population’s entrepreneurialism. Tel Aviv, where SpaceIL is based, has the highest number of start-ups per capita in the world. Years after the space race, landings on other worlds, whether on the moon or on Mars, are still celebrated as national achievements at home and broadcast as displays of prowess to the rest of the world.

On Friday, SpaceIL released a preliminary assessment for the failure. Beresheet had been in good health when it began its descent to the moon. “We performed a lot of health checks,” Landsman said.

The spacecraft experienced a “technical issue” when it was just 8.7 miles above the lunar surface. The glitch caused its main engine to malfunction. “Without the main engine working properly, it was impossible to stop Beresheet’s velocity,” SpaceIL said in a statement. Mission control commanded the spacecraft’s computers to restart, and the engine came back. But it was too late for the thrust to slow down the spacecraft. When mission control lost communication, Beresheet was 492 feet from the ground. It was traveling at about 311 miles an hour. A crash was inevitable.

“We don’t know exactly what happened,” Landsman said. He suspects that the fault was not with the engine, but with some kind of electrical problem.

Beresheet will remain on the moon forever, its pieces scattered across the dust. The impact might have even carved a small crater into the surface. The spacecraft joins countless other artificial bits and pieces on the moon, silent signs of humankind’s desire to explore the closest world to our own. More than half a century ago, the kind of crash Beresheet experienced was actually cause for celebration. In 1959, the Soviet Union launched Luna 2, a round spacecraft with instruments to measure radiation around the moon. As it approached the surface, communication was lost. Mission control erupted in cheers. This was the very beginning of space exploration, and the point was to get to the moon first, even if it meant smashing into the surface. The definition of success is different now.



The troublesome teeth belonged to a woman buried in Sweden. She lived 4,900 years ago, and she died young. Archaeologists found her at the turn of the last millennium, her bones jumbled up with dozens of others in a limestone tomb. Geneticists sequenced her DNA a few years ago, revealing her to be, unsurprisingly, one of the Neolithic farmers who occupied Europe at the time.

Only when scientists reexamined DNA from two of her teeth last year did they notice something shocking: Her DNA was in there all right, but so were genetic sequences from Yersinia pestis, the bacterium that causes plague. The plague is known to have swept through Europe in later times—most infamously as the Black Death during the Middle Ages. But scientists thought the disease had originated thousands of miles away in Asia. What was it doing this far west, in Sweden, this long ago?

“It was really unexpected,” says Nicolás Rascovan, a genetics researcher at Aix Marseille Université. The answer, he and his co-authors suggest in a new study, is that the plague actually originated in Europe. And the bacteria from the woman’s teeth might be the earliest evidence of a continent-wide epidemic, one that explains a sudden and mysterious collapse in the European population.

It’s a lot to conclude from just a few ancient teeth.

The team had set out looking for evidence of plague in publicly available genetic data sets. Getting DNA from ancient bones and teeth is still a fairly new procedure, and it has largely focused on the stuff from humans. But modern sequencing techniques pick out all the genetic material in a sample, which frequently includes a lot of contaminating bacteria. For this reason, “normally 95 percent, 99 percent of the data was just thrown into the Dumpster,” Simon Rasmussen, who studies pathogen evolution at the Technical University of Denmark and co-authored the study, told me. The idea was to look through all this genetic detritus for signs of Yersinia pestis. When people die of the plague, their blood has high levels of bacteria, which leave a distinct genetic signature in the dental pulp inside teeth.

Rascovan ultimately sorted through the genomes of about 100 ancient individuals found throughout Europe. When he found Yersinia pestis in the teeth of the 4,900-year-old woman in Sweden, he looked at other people buried in the same tomb. Up to 78 people were buried around the same time, suggesting a surge in deaths that could have become an epidemic. Indeed, a young man in the tomb also had fragments of plague bacteria in his teeth. The strain of Yersinia pestis in the grave site was distinct from all others ever sequenced. The team thinks that it diverged from other known strains 5,700 years ago.

Rasmussen and others had previously found plague bacteria in ancient human remains all over Eurasia. Prior to this discovery, the oldest and most genetically distinct strain had been found in Central Asia. This fit a neat narrative: Steppe pastoralists from Eurasia began migrating into western Europe around 4,900 years ago, and they could have brought the plague with them. The disease seemed to explain how they were able to supplant the farmers—like the Swedish woman—already living in Europe. In the span of a few centuries, the steppe pastoralists would replace 70 percent of the population in Central Europe and 90 percent in Great Britain. In fact, modern Europeans derive most of their ancestry from steppe pastoralists who came during this period.

But now, the dates don’t match up. If the Swedish plague strain diverged from Central Asian ones 5,700 years ago, but human migration to the region didn’t start until 4,900 years ago, how did plague get to Sweden? Rascovan and Rasmussen turned to their archaeologist colleagues, who saw that this development fit into another pattern: Populations in Europe were falling even before people from the steppes migrated there.

Around 6,000 years ago, mega-settlements as big as 10,000 to 20,000 people sprang up in what is now Moldova, Romania, and Ukraine. The settlements were regularly abandoned and then burned. Perhaps, the new study argues, plague spread through these sites. At the same time, innovations such as wheeled transport and metallurgy allowed distant trade routes to emerge, possibly connecting mega-settlements with far-flung villages like those in Sweden. Thus, some populations were dense enough for a new pathogen to emerge, and trade routes helped spread it across the continent. “This might actually be one of the first plague epidemics,” Rascovan says.

This is all quite speculative. “They’ve obviously got neat DNA results. They’re building a story about it, and it’s an interesting and potentially plausible story,” says Stephen Shennan, an archaeologist at University College London who has studied Europe’s population collapse. But no evidence exists of plague in the mega-settlements themselves. Finding that evidence won’t be easy. “We actually don’t know what they did with their dead,” says David Anthony, an anthropologist at Hartwick College. They didn’t build tombs or establish cemeteries, so ancient-DNA researchers have no bones to analyze for signs of the plague. There is one cave site associated with the mega-settlements, says Anthony, where skeletons might yield some clues.

These are still early days for the study of ancient pathogens. Data points are so few and far between that it’s like making sense of a photograph from just a handful of pixels. With a few teeth, you can lob bombs at previous hypotheses, but you can’t yet make a solid case for an alternative idea.

The next step is to find more ancient plague samples. Many teeth have likely already been sequenced, but not yet analyzed for plague. It’s probably smart to look in samples found across a wide geographic area, too. “In terms of where plague originally emerged, we really don’t know at this point,” says Kirsten Bos, who studies ancient pathogens at the Max Planck Institute. “We’re finding a genome in Sweden. Who would have thought we’d find something that far north?”

Scientists are already hunting for other pathogens such as hepatitis B, Salmonella, and tuberculosis in ancient DNA. In the past decade, ancient human genomes have told us a great deal about how people migrated around the world; now they’re telling us about the pathogens they carried, the lives they lived, and the deaths they died.

The story of how plague got to Sweden 4,900 years ago is likely still incomplete. But the disease seems to have been there. At the end of our conversation, Rasmussen began conjuring up such a past, in which death came without warning. “Imagine you live 5,000 years ago in a small farming village with only 20 to 50 people. Then all of a sudden, one of them brings home food or has been in another village trading. They get ill and die a few days later.”

“And,” Rascovan added, “they had to wait 5,000 years to know exactly what happened.”



With a flash, the sky over New York City turned a mystical blue.

The spectacle, which appeared without warning on Thursday night, stunned observers. They sensed something was wrong—because, obviously, would you look at the freaking sky?—and quickly formulated some possible explanations. The theories leaned heavily on science fiction. Maybe the glow signaled the end of a massive battle between superheroes. Maybe it was an alien invasion. Maybe the apocalypse was nigh, and this, these eerie turquoise clouds over Queens, were the first sign that the end was near.

What people witnessed was much less dire: a quirk of electricity. Just after 9 p.m. local time, some equipment at an electrical power plant in the Astoria neighborhood short-circuited. (There was no explosion or fire, contrary to early reports.) According to the station’s operator, Con Edison, the malfunction produced something called an arc flash. A powerful electric current shot into the air and sent atoms of gas in the air into a state of excitement. When atoms become excited, they emit light, and different gases produce different colors. In this case, the atmospheric recipe resulted in a ghostly blue.

“No injuries, no fire, no evidence of extraterrestrial activity,” the New York Police Department tweeted, extinguishing most of the theories that had flooded social media.

Sorry to disappoint, but the eerie blue glow last night wasn’t an alien invasion. 🤷‍♂️👽 Our live #EarthCam in midtown #NYC captured the electrical arc flash as it turned the night sky blue! pic.twitter.com/3fY56xu1ug

It was a joy to watch the discussion of the blue light unfold online. This strange December night encapsulated so much of what makes the internet great: the dissemination of captivating photos and videos in real time, a shared sense of camaraderie that transcends state lines and borders, and some pretty funny jokes. But the evening also tapped into something much older and more primal. We human beings have long been intrigued by strange lights in the sky. Like the blue glow over New York, these sights have baffled, scared, and mesmerized us, even when we’ve known their source.

Perhaps the oldest example is the aurora borealis, the resplendent performance of dancing lights in the night sky. Today, we know the northern lights are the product of electrons from the sun interacting with different gases in Earth’s atmosphere. But centuries ago, observers, captivated by the wisps of colors, dreamed up their own explanations. In ancient China and Europe, the auroras were dragons and serpents, flitting around in the night. In Scandinavian folklore, they were the burning archway that allowed gods to move between heaven and Earth. During the American Civil War, soldiers thought the lights were a sign of disapproval from God to the Confederacy.

During at least one time in history, the sight of weird lights in the sky became a business opportunity. Starting in the early 1950s, during the height of the Cold War, the United States government detonated thousands of atomic bombs in the Nevada desert, illuminating the sky with bright flashes. The city of Las Vegas, located just 65 miles away, saw lucrative potential in the morbid spectacle, and decided to monetize the mushroom clouds. As Laura Bliss wrote in a 2014 CityLab story:

The Chamber of Commerce printed up calendars advertising detonation times and the best spots for watching. Casinos like Binion’s Horseshoe and the Desert Inn flaunted their north-facing vistas, offering special “atomic cocktails” and “Dawn Bomb Parties,” where crowds danced and quaffed until a flash lit the sky. Women decked out as mushroom clouds vied for the “Miss Atomic Energy” crown at the Sands. “The best thing to happen to Vegas was the Atomic Bomb,” one gambling magnate declared.

Spectators knew what they were looking at, but they were still astonished—excited and frightened at the same time. “People were fascinated by the clouds, by this idea of unlocking secrets of atom,” Allen Palmer, then the executive director of the National Atomic Testing Museum, told CityLab. “But there was absolutely an underlying fear—we were so close by.”

In other cases, a shroud of mystery can heighten those feelings. Around the same time tourists in Las Vegas were watching nuclear explosions bloom, Americans on the other side of the country were enthralled by a different kind of light in the sky. On a summer day in 1952, multiple people in the Washington, D.C., area reported spotting several unearthly points of light traveling over the landscape. One commercial pilot described them as “falling stars without tails.” When they approached the White House, the military summoned a pair of jets to intercept the unknown flyers, but no mystery invaders were found.

The next day, the news of the moving objects was all over the news. Headlines suggested, in capital letters, that the objects were extraterrestrial. Government officials, stumped themselves, didn’t exactly try to quash the rumors. According to The Washington Post, an unnamed Air Force source told reporters: “We have no evidence they are flying saucers. Conversely we have no evidence they are not flying saucers. We don’t know what they are.”

Unidentified flying objects have maintained this allure for decades. As recently as 2012, the Pentagon was operating a program to investigate reports of UFOs. When The New York Times broke the story in late 2017, it proved to be full of the hallmarks of a timeless mystery—surprise, suspense, wonder.

The blue lights over New York were a good mystery, too. The unnatural glow eventually dimmed and the sky returned to its usual evening hue. Con Edison resumed normal operations. People went on with their lives. But for a brief time, they were engaged in a long-standing tradition: trying to make sense, together, of something strange in the sky.



Forty-seven years ago, the Asian elephant now known as Happy was one of seven calves captured—probably in Thailand, but details are hazy—and sent to the United States. She spent five years at a safari park in Florida, time that in the wild would have been spent by her mother’s side. Then she was moved to the Bronx Zoo in New York City. There Happy remains today, and since the death of an elephant companion in 2006, she has lived alone, her days alternating between a 1.15-acre yard and an indoor stall.

For a member of a species renowned for both intelligence and sociality, the setting is far from natural. In the wild, Happy would share a many-square-mile home range with a lifelong extended family, their bonds so close-knit that witnessing death produces symptoms akin to post-traumatic stress disorder in humans. It would seem that Happy, despite the devotions of the people who care for her, is not living her best life.

In considering Happy’s circumstances and what might be done to improve them, should something more than animal-welfare laws and zoo regulations—which the Bronx Zoo has not violated, but arguably are inadequate—be invoked? Should Happy be considered, in legal terms, a person? Which is to say, an entity capable of possessing at least some rights historically reserved for humans alone—beginning with a right to be free?

Making that case is an advocacy group called the Nonhuman Rights Project. Since 2013, the group has filed lawsuits on behalf of four captive chimpanzees in New York and, in neighboring Connecticut, three elephants used in a traveling circus. They’ve lost those cases, but they have persuaded judges to take them seriously, and in October petitioned a New York state court to order Happy’s release. She wouldn’t be returned to the wild, but would be transferred to a sanctuary in California with more space and the company of other elephants. The hearing took place earlier this month, and while no decision was reached—the case will likely be moved to a court within the Bronx Zoo’s jurisdiction—it was still a unique moment to reflect on the status of animals and the law.

Until recently, the idea of elephant personhood would have struck legal observers as a joke. Just a few decades ago, most states still treated animal cruelty as a misdemeanor, like public intoxication or driving without insurance. But an increasing number of Americans take animal well-being seriously: A 2015 Gallup poll found that a majority “are very or somewhat concerned” about animal mistreatment. The legal system has changed in turn. Every state now considers animal cruelty a felony, and laws such as California’s recently passed Proposition 12, which improves living standards for farm animals, are becoming commonplace.

Still, these laws have blind spots and inconsistencies. The federal Animal Welfare Act exempts farm animals and most lab animals; the Humane Slaughter Act omits poultry. State laws are an inconsistently enforced patchwork, and practices that many people consider cruel—such as gestation crates for pigs—remain legal in many places. Even the most beloved animals don’t always receive much consideration. “In the vast majority of jurisdictions, if someone beats your dog to death in front of you, all you can sue them for is the cost of buying another dog,” says Chris Green, the executive director of Harvard Law School’s Animal Law and Policy Program.

Animal-welfare laws also depend on government intervention. Citizens can’t file suit on behalf of animals they don’t own. Animal-welfare laws fall short of actual rights—and centuries of legal custom have reserved rights for humans. “A thick and impenetrable legal wall has separated all human from all nonhuman animals,” writes Steven Wise, the Nonhuman Rights Project’s founder and lead attorney, in his book Rattling the Cage.

To help Happy breach it, Wise invokes both scientific research and legal principle. Elephants, attest scientists who filed affidavits in Happy’s case, are highly self-aware, are emotional, make choices, and have a rich sense of both past and future. (Happy, in fact, was the star of a landmark 2006 Science study describing how elephants can recognize themselves in mirrors, which is considered a measure of especially human-like awareness.) “Elephants share many key traits of autonomy with humans,” write evolutionary biologists Lucy Bates and Richard Byrne in their affidavit. Wise argues that respect for autonomy underlies our own legal right to physical liberty. Extending that to elephants is simply a matter of equality.

In a news release issued after this month’s hearing, the Wildlife Conservation Society—the Bronx Zoo’s owner—describes the lawsuit as “an academic exercise” that, in the words of the zoo’s director, Jim Breheny, is intended to “promote their radical philosophical view of ‘personhood.’” Happy’s present conditions, the society says, are perfectly suitable and meet established welfare standards, and moving her could be traumatic. (That issue won’t be adjudicated in this article; for more information, see court documents filed by Patrick Thomas, the Bronx Zoo’s associate director, and Joyce Poole, one of the biologists supporting the lawsuit.)

More to the philosophical point, the Wildlife Conservation Society cites rulings against similar Nonhuman Rights Project lawsuits filed on behalf of captive chimpanzees. According to those decisions, rights belong only to those who can also accept moral responsibility and social duties—which even the smartest animals can’t.

The rulings have been criticized, though, both by scientists who insisted that chimps do in fact have responsibilities within their own societies and by some legal theorists who don’t necessarily support chimp rights but fear a rationale that could threaten many human beings. The rights of an infant or an elderly grandmother with severe dementia are hardly contingent on the duties they fulfill.

This past May, in rejecting a Nonhuman Rights Project request to appeal these decisions, the New York judge Eugene Fahey wrote that he did so only on procedural grounds. “Does an intelligent nonhuman animal who thinks and plans and appreciates life as human beings do have the right to the protection of the law against arbitrary cruelties and enforced detention?” he wrote. “This is not merely a definitional question, but a deep dilemma of ethics and policy that deserves our attention.”

Fahey’s opinion—intended, as legal opinions are, as a resource for future deliberation—seems to leave New York courthouse doors open for Happy. Whether they’re wide enough remains to be seen. There are certainly other arguments against elephant personhood. Richard Cupp, an animal-law professor at the Pepperdine School of Law, worries that extending rights to animals could ultimately erode our own. “Courts and society might, with this new paradigm, be tempted not only to look at more intelligent animals as being like humans,” he said in a debate with Wise, “but start to think of less intelligent humans a little more like animals.”

Cupp also fears opening a “floodgate of litigation” as animal advocates work their way through the animal kingdom, moving from elephants and chimpanzees to common creatures—a worry echoed by Richard Epstein, a law professor at New York University, who spoke to Harvard Magazine about his concern that people might claim personhood for farm animals. “We kill millions of animals a day for food,” said Epstein. “If they have the right to bodily liberty, it’s basically a holocaust.” Rather than rights, Epstein suggests more animal-welfare protections.

There are rejoinders to both points: Expanding rights to women, racial minorities, and children didn’t erode the rights of property-holding white men, and implications for other species are immaterial to the question of elephant or chimpanzee rights. Lawsuits involving other species and other rights would certainly follow—but those deserve to be addressed case by case rather than forestalled en masse because it’s uncomfortable to consider what they imply for animals we eat.

Regardless of how Happy’s case is decided, though, the legal landscape for animals is changing. Outside the United States, an Argentine court granted freedom to an orangutan at the Buenos Aires Zoo; courts in the Indian state of Uttarakhand ruled that animals both wild and domestic are not property but “legal entities” on whose behalf humans must act as guardians. The European Union, New Zealand, and Quebec explicitly recognize animals as sentient, though the actual impact of sentience laws has been limited. Legal rights for animals are no longer a fringe idea.

Inside the United States, judges in Alaska and Illinois have started to consider the well-being of pets, rather than mere ownership claims, in divorce-custody proceedings. Though an Oregon court rejected a high-profile lawsuit that would have allowed a horse’s advocates to sue for damages caused by criminal neglect, another court in that state ruled that animals could legally be considered victims of crimes—an implicit recognition that they’re more than just property.

The Animal Legal Defense Fund, which filed the aforementioned Oregon horse case, has also pushed for animals to be covered by the Freedom of Information Act, which, by the law’s letter, applies to individuals—not individual humans. Meanwhile, Friends of Animals, another advocacy organization, has collaborated with the legal philosopher Martha Nussbaum to develop what they call a “right to ethical consideration”: In their eyes, the Nonhuman Rights Project’s focus on autonomy sets too high a cognitive bar; rights might instead be based on simpler capacities, such as emotions and imagination.

Ethicists have even suggested property rights for wild animals threatened by development, labor rights for working animals, and the use of citizenship theory as a framework for thinking about animal rights. Domestic animals might be treated as full-blown citizens; wild animals are likened to members of other nations. Even if such ideas seem impractical, they’re valuable prompts to moral imagination. What would fair-labor law look like for a chicken?

“For the most part, there’s been an invisibility to anything but humans throughout the legal system,” says Irus Braverman, a law professor at the State University of New York at Buffalo. “We have to bring the animals back in.”



At the darkest points in the universe, their boundaries perilous and invisible, space warps. In a black hole, the force of gravity is so strong that anything that comes near, whether a puff of cosmic dust or an entire blazing star, is swallowed and devoured. The light sinks past a point of no return and into an unknown realm that can only be imagined.

Black holes sound like an invention of science fiction, but they’re as real as the stars and planets and moons—they’re everywhere, millions and millions of them scattered across the cosmos. Mysterious as they are, they can be found.

Astronomers have detected black holes in the whirling movements of stars and spinning rings of gas and dust that coalesce around a seemingly empty spot in space. They have detected them in bright beacons of ejected particles, the cosmic burps of a hearty meal. They have even detected them in gravitational waves, the faint ripples that distort the very makeup of space and time when two black holes collide.

But no one’s ever really seen a black hole—until now.
Astronomers on Wednesday released the first direct image of a black hole, pieced together from observations by telescopes around the world.

“We have seen what we thought was unseeable,” says Shep Doeleman, an astronomer at the Harvard-Smithsonian Center for Astrophysics and the head of the effort, known as the Event Horizon Telescope.

The black hole resides at the center of a galaxy known as Messier 87, named for the 18th-century French astronomer who discovered it. Messier is one of the biggest nearby galaxies. The black hole at its center has a mass 6.5 billion times that of the sun.

The photographic evidence of a long-unseen cosmic force is an extraordinary achievement in science. Messier 87 is located about 55 million light-years from Earth. The electromagnetic radiation there—the kinds of signals scientists seek to detect—took a very long time to reach the planet, longer than any human beings have been around. By the time it arrived, they had figured out how to peer back into the depths and snap a picture.

Exciting as it is, the photo actually doesn’t capture the black hole itself, nor its interior. Astronomers aimed their telescopes at the event horizon, the invisible boundary thought to surround all black holes. When something crosses this barrier, it doesn’t come back. In the photos, the event horizon has cast a shadow on the bright, hot gas swirling at the galactic center. Just before the cosmic material crosses over, it heats up and glows. The black hole appears in silhouette, a slightly elongated ball, ringed by a halo of fire.

If the photo looks fuzzy around the edges, consider the size of the shadow. Heino Falcke, one of the astronomers involved in the effort, predicted that from here, the shadow of the black hole inside Messier 87 would be 20 to 40 microarcseconds across. All you need to know about microarcseconds is that 10 of them are equivalent to the size of a coin on the moon, viewed from Earth.

These scales made black holes elusive. As massive as they are, as strong as their pull can be, not so long ago, they were enigmatic enough that plenty of scientists didn’t think they even existed.

The modern theory of black holes has its beginnings, as many wonders of gravity do, with Albert Einstein and his general-relativity equations, published in 1915, which described gravity as a distortion of space and time. The physicist Karl Schwarzschild ran with Einstein’s equations and came up with an idea of his own: Based on the principles of general relativity, matter could become squeezed into a tiny point of infinite density, a locus known as a singularity. The singularity would warp the space around it, creating a spherical region with an invisible barrier, from which nothing could escape.

Einstein actually resisted the idea, but the evidence piled up. In the 1930s, the astrophysicist Subrahmanyan Chandrasekhar, just 19 years old at the time, upended theories about star formation with his mathematical calculations showing that some massive stars collapse into dense, light-trapping objects—when they run out of fuel and die. The term black hole entered the literature in the late 1960s, just a few years before astronomers found their first evidence of one, in the early 1970s, in the constellation Cygnus. Before the decade was over, astronomers detected a radio signal coming from the supermassive black hole at the center of our very own galaxy, known as Sagittarius A* (pronounced as “a-star”).

“We’ve been studying black holes so long that sometimes it’s easy to forget that none of us has actually seen one,” says France Córdova, the director of the National Science Foundation, which funded the effort. The Event Horizon Telescope is actually 10 telescopes, sprinkled across four continents in the United States, Mexico, Chile, Spain, and Antarctica, and designed to scan the cosmos in radio waves. For a few days in April 2017, the observatories studied the skies in tandem, creating a gargantuan telescope nearly the size of the planet.

The scale of the observations produced a ridiculous amount of data: more than 1,000 hard drives’ worth. Researchers spent months analyzing the data, searching for a signal in the noise, and then stitched it together to create a single, composite photo.

“This is the strongest evidence we have to date of the existence of black holes,” Doeleman says.

Although Einstein’s theories led to the discovery of black holes, scientists still debate whether the rules of general relativity apply there, under extreme conditions that aren’t found anywhere else in the universe. So far, untested bits of theory are starting to check out: The shadow of the event horizon is, as anticipated, spherical.

“The theory not only predicts the existence of a shadow, indicating a point of no return, but also what size and shape that shadow should have,” says Feryal Özel, an astrophysicist at the University of Arizona and a member of the project. “We’ve been able to carry out the first test of that.”

This is the closest that astronomers have come—and might ever come—to perhaps the most mysterious objects in the universe. Scientists are still grappling with what may be happening inside, in the unknowable depths. Much as they’d like to, they can’t stick their heads in for a peek. At the event horizon, just beneath the fiery edges, the fierce gravitational tug of the black hole stretches matter like taffy. “When you pass through the event horizon, you wouldn’t really feel it,” Sera Markoff, an astrophysicist at the University of Amsterdam and a member of the Event Horizon Telescope team, once told me. “You wouldn’t get shredded until much farther in.”

Safer to watch from a distance, where the abyss—law-defying, mind-bending, relentless—can be captured in a collection of pixels.



In 2016, Nobuaki Mizumoto was visiting the dinosaur museum in his hometown of Katsuyama, Japan, when he came across an unexpected display—not of a dinosaur, but of a school of fish. It was embedded in limestone shale and exhibited in a corner with no particular fanfare. Yet the 50-million-year-old fossil was clearly extraordinary: 259 tiny fish bodies with eyes and spines and even fins. All but a few faced the same direction, as if frozen mid-swim.

Mizumoto does not specialize in fish or fossils, but he does study the collective behavior of termites at Arizona State University. He became intrigued by the idea that this fish fossil showed collective behavior, too. When fish form schools, they have to coordinate their swimming, staying together without crashing into one another.

Of course, behavior doesn’t usually fossilize well. Scientists have discovered other fossils featuring large groups of fish, but the fish tend to be jumbled, facing every which direction—as you would expect if a school of fish had died, sunk to the bottom of a lake, and been slowly buried in sediment.

Mizumoto wondered whether the fossil he saw had actually preserved the fish in position the very instant they died. He teamed up with a fish-fossil specialist in Japan, and they went back to the museum to photograph the fossil.  Then they charted the position and heading direction of every single fish. Mizumoto found that if he looked at where the fish were and where they were going, they seemed to obey two rules that live, modern fish schools follow: repulsion from close neighbors (as if to avoid bumping into one another) and attraction to more distant fish (as if to stay together as a school). Their positions didn’t appear to be random.

“I thought the fossil was fascinating!” James Herbert-Read, an animal-behavior researcher at the University of Bristol, wrote in an email. Scientists look for social rules in live fish by studying their relative positions in photographs; Mizumoto had done the same for long-dead fish but in a fossil. But Herbert-Read still wondered how the fossil could have formed, and whether the fish really had been alive when they were aggregated this way.

The fossilized fish, an extinct species called Erismatopterus levatus, lived approximately 50 million years ago, in a series of giant intermountain lakes that once covered Wyoming, Colorado, and Utah. Today that region is known as the Green River Formation, and it’s the source of extraordinary fossils of insects, birds, bats, snakes, early primates, and, of course, fish. Scientists and commercial fossil hunters alike stake out the region in search of these prehistoric treasures.

Lance Grande, a curator at the Field Museum who has studied fossils from the Green River Formation, even has a few featuring mass mortalities of fish in his collection. But none of them has fish all facing the same direction. “It is really strange,” he says. He’s unconvinced, though, that something could have killed the fish and preserved their positions in the very instant they died. “I think it’s got to be some postmortem stuff going on,” he says. A school of fish probably did die en masse—maybe from a volcanic eruption, maybe a mass of oxygen-less water, maybe just a temperature shift—and after death, it fell to the bottom of the lake and was perhaps aligned by a water current.

Mizumoto and his team did try to mathematically rule out this explanation. (The fish don’t appear to be sorted by size, as one might expect with a current.) They proposed the possibility of a sudden collapse of a sand dune, but Mizumoto admits that they don’t have a great explanation. “I’m the guy in the world who most wants to know how this fossil is created,” he says. He says his main motivation for writing a paper was to make the world aware of this strange, beautiful fossil. And now that it’s out there, perhaps paleontologists and geologists can take a crack at figuring out how this fossil came to be.



The list of animals that can see infrared light, which lies just beyond the red part of the rainbow, is very small. It includes vipers and pythons, whose faces have infrared-detecting pits wired to the visual centers in their brain. It includes a few freshwater fish such as carp and tilapia. It includes salmon, but only when they swim back into rivers from the sea, and only after dramatically retooling the chemistry of their eyes. It includes bullfrogs, but only in the bottom halves of their eyes. It does not include humans, unless we wear special goggles or are exposed to specific kinds of laser pulses. And it doesn’t include mice.

Except, that is, for those in Tian Xue’s lab at the University of Science and Technology of China.

Xue and his colleagues injected the eyes of mice with nanoparticles that were designed to stick to the light-detecting cells in the rodents’ retinas. These particles convert incoming infrared light (that the cells cannot naturally detect) into plain old green light (that they very much can). It’s as if Xue implanted thousands of tiny infrared goggles inside the rodents’ eyes. With their technologically augmented retinas, the mice could respond to infrared light that would otherwise have been invisible to them.

It’s an impressive example of using technology to expand an animal’s “umwelt”—the thin sliver of reality that it’s capable of perceiving. But as far as infrared vision goes, it’s a bit of a cheat. The mice aren’t seeing in infrared; they’re seeing infrared information that’s been changed into a more perceptible form.

But “science has always worked to convert invisible information into the range we can perceive,” says David Eagleman, a neuroscientist from Stanford University. “This is what microscopes and telescopes do: changing the very small or very distant into a form we can digest with our eyes. But instead of building a large piece of equipment to do the conversion, these investigators engineered a microscopic solution, directly mating technology to biology.”

“I love this stuff,” he adds. “It’s wonderfully clever.”

The nanoparticles that Xue used were originally developed for a completely different reason. Fourteen years ago, researchers figured out a way of infusing neurons with light-sensitive molecules, allowing them to control these cells with flashes of light. This technique, known as optogenetics, paved the way for many powerful studies, allowing neuroscientists to precisely manipulate the brains of living animals. It also holds promise for treating several brain diseases.

But there’s a catch: Optogenetics relies on molecules that are triggered by blue or yellow light, both of which are blocked by skin and muscle. To deliver that light into an animal’s brain, researchers must use either invasive optic fibers or implanted LEDs. They could dispense with these cumbersome devices if they simply made optogenetics compatible with infrared light, which more easily penetrates through flesh.

Gang Han from the University of Massachusetts Medical School managed to do that by creating a range of nanoparticles that absorb infrared and emit visible light. And while talking to Xue, his colleague who studies mouse vision, Han wondered, “What would happen if we inject these into a mouse’s eye?”

First, Han bolstered his particles with a protein called ConA, which helps them adhere to the light-detecting cells of the retina. When injected, they formed an even and lasting layer over the cells. And when Xue’s team then shone an infrared beam into the rodent’s eyes, their pupils constricted—a subconscious reaction that clearly showed that they could see the light.

Next, the team put the mice into a pair of linked chambers—one dark and one bathed in infrared. Normal rodents can’t tell the difference between these spaces, and spend equal amounts of time in each. But to the altered individuals, the infrared chamber was bright and off-putting; they spent most of their time in the dark space instead.

Finally, the team plopped the mice into a flooded, Y-shaped arena. The two prongs of the Y displayed different patterns of light—say, a triangle or a circle—and one of these indicated the presence of a hidden platform upon which the mice could rest. If the patterns were in infrared, the altered rodents would choose the right prong, but their normal peers would not.

This isn’t the only way to make mice see infrared: A different team tried in 2013 by implanting detectors in the foreheads of rats and wiring these up to the part of their brain that deals with touch. But this is arguably a simpler approach. Would it work in humans? Before anyone even considers that, the team would have to address several issues, says Lan Yue, an ophthalmologist at the University of Southern California. First, infrared light is low in energy, and the nanoparticles need a lot of it to produce a detectable amount of green light. That’s not a problem for small mouse eyes, but in larger human ones, the particles might only work when infrared levels are unreasonably bright.

Second, although the particles didn’t seem to harm the mice, the team will need to work out how long they stay in the eye, whether they get absorbed by the retina, whether they end up in other organs, and whether they have any long-term side effects. Finally, given how the particles work, it’s unlikely that users will be able to tell the difference between “infrared” and normal green. “It’ll be interesting to see whether it’s possible to produce conscious infrared vision while avoiding confusion with visible vision,” Yue says.

Indeed, why would you want to? The team have filed a patent based on their work, which they say could “pave the way for critical civilian and military applications.” Still, it’s hard to shake the feeling that this is all a cute gimmick. In what situations would altering someone’s retina be better than just … giving that person a set of night-vision goggles?

“Goggles need batteries and they’re very heavy,” Han counters. “They’re also saturated by daylight, whereas our technique is compatible with all-day uses.” Also, he adds, other people can obviously see you wearing them. Someone with temporary infrared vision might be able to spy more covertly. “Maybe you could have a nanoparticle eye drop that allows you to see specific patterns that only you can see,” he says.

You, and any viper, that is. The infrared vision of these snakes “is much more sensitive than what we can achieve,” Han says. Even with fancy nanoparticles, it’s still hard for us to truly bring one animal into the umwelt of another.



It was not so long ago—only 108 years, within a great-grandma’s memory—that a person’s eyes first beheld the South Pole. When Roald Amundsen made it to the bottom of the world in 1911, it marked a new chapter in the human story. Our curious, inventive, and adaptable species, born on the sunny savanna, had reached that last spot of remote desolation on our home planet.

Little did we know that less than a century later, the hustle and bustle of our society would alter that ancient landscape forever.

The pristine environments at both poles of the Earth are changing, perhaps irreversibly, according to a new pair of federal studies. On Monday, a new NASA report warned that ancient glaciers in Antarctica are “waking up” and beginning to dump ice into the sea, which could eventually raise sea levels.

The following day, the National Oceanic and Atmospheric Administration released its new Arctic Report Card, which finds that the top of the world is also thawing, melting, and breaking down. The Arctic is undergoing a period of “record and near-record warmth unlike any period on record,” the report says. 

Emily Osborne, a scientist who leads Arctic research at the National Oceanic and Atmospheric Administration, repeated this warning while speaking at a major geoscience conference on Tuesday. “The Arctic is experiencing the most unprecedented transition in human history,” she said.

The finding at the bottom of the world is in some ways the most shocking. Antarctica is split into two massive ice sheets, the East and the West. Researchers have long considered the East Antarctic Ice Sheet to be less worrisome: Though it contains enough frozen water to raise global sea levels by 173 feet, it sits at a high enough altitude to withstand the first century or so of warming.

The new finding may complicate that conclusion. Using a new database of global ice movements, NASA scientists found that several glaciers in the East Antarctic Ice Sheet are quickening their march toward the sea. Since 2008, a set of glaciers that feed Vincennes Bay—which is due south of Australia—lost about nine feet of overall height. Their speed has also increased, suggesting that these glaciers are dumping more ice into the ocean than researchers previously expected.

The Vincennes Bay glaciers are important because they block the inland Aurora and Wilkes ice basins from tumbling into the sea. If both basins collapsed, they could raise sea levels by 92 feet. “Taken together, they’re about four Greenlands [worth of sea-level rise],” said Catherine Walker, a glaciologist at NASA, speaking at the annual meeting of the American Geophysical Union on Monday.

Alex Gardner, another glaciologist at NASA, said that warming oceans—and not just a warming climate overall—seemed to be causing the decline in glacier levels. Some of the fastest-collapsing glaciers in the world—such as the Jakobshavn Glacier in Greenland—are primarily giving way because of warm ocean waters wearing at their icy fronts.

Both researchers said that existing models of sea-level rise may not account for these changes. “We weren’t expecting it because we never knew it was happening,” Walker said. “This isn’t new; it started happening 10 years ago. We just couldn’t see it.”

Not that the other end of the world is doing much better. NOAA’s new Arctic Report Card—an annual analysis, now in its 13th edition—finds that the world’s Far North is going through a tremendous upheaval. The report says that the catastrophic effects of climate change now wreak mayhem in every season of the year.

In the winter, when the Arctic Ocean has historically frozen into an enormous skating rink, sea ice now struggles to form at all. 2018 was the second-worst year on record for sea ice, the report says. The Arctic is now so warm that it hemorrhages ice even at the coldest, darkest time of the year: “During two weeks in February—normally the most important weeks for sea-ice growth in the year—the Bering Sea actually lost an area of ice the size of Idaho,” said Don Perovich, a geophysicist at Dartmouth, on Tuesday.

In the spring, the sea ice vanishes early, allowing algae blooms to envelop the open ocean. One warm-water species of algae produces toxins that trigger a disease called paralytic shellfish poisoning when absorbed by shellfish and then eaten by humans. Toxins in a single animal can kill a person in as little as two hours, according to the Alaska Division of Public Health. There is no antidote.

Cases of paralytic shellfish poisoning have increased sevenfold in Alaska over the past 40 years, the new report finds. Seals, walruses, and whales have also been killed by the disease.

Finally, in the summer, temperatures soar. In August, huge swaths of the Arctic Ocean surface measured 20 degrees Fahrenheit warmer than normal. Ice now almost never makes it through the summer: Less than 1 percent of sea ice in 2018 formed more than four years ago. When scientists began tracking that figure back in the 1980s, one-sixth of all sea ice was at least four years old.

Animal life is cratering in response to these year-round changes. Caribou and reindeer herds have lost more than half their animals since the 1980s, said Howard Epstein, a professor at the University of Virginia. About 4.7 million caribou and reindeer roamed the tundra a few decades ago. Only 2.1 million do so today.

Meanwhile, micro-plastics—tiny shards of plastic from bottle caps, fishing gear, and the filters of cigarette butts—are pouring into the region. “The Arctic Ocean has a higher concentration of micro-plastics than any other global basin in the world,” said Karen Frey, a professor at Clark University. “All roads in the global ocean-circulation system lead to the Arctic.”

All these dire federal scientific reports might seem like they would prompt a federal governmental response. Tim Gallaudet, the interim administrator of NOAA and a retired rear admiral in the U.S. Navy, was on hand to provide it. He hailed President Donald Trump’s signing of the Save Our Seas Act, a law to combat micro-plastic pollution that Congress passed unanimously in October. He also hailed the White House’s support for NOAA Arctic research.

But he did not endorse any attempt to fight climate change. “The data is the data. Changes are occurring,” he said. “What we need to do is adapt to those changes—and we can adapt as a country effectively by better understanding and improving our predictions.”

Asked whether he or any other senior NOAA official had talked to the president about climate change, he admitted he had not, and did not acknowledge any other efforts. “No,” he said. “I personally have not briefed the president on climate change.”



Northern Ethiopia was once home to a vast, ancient lake. Saber-toothed cats prowled around it; giant crocodiles swam within. The streams and rivers that fed it—more than 3 million years ago, during the Pliocene—left behind trails of sediment that have now hardened into sandstone.

Deposited within these layers are fossils: some of early hominins, along with the bones of hippos, antelope, and elephants. The anthropologist Jessica Thompson encountered two of these specimens, from an area named Dikika, in 2010.

At the time, she was a visiting researcher at the Institute of Human Origins at Arizona State University. Given no explanation as to their history, she analyzed the bones and found signs of butchery. Percussion marks suggested someone may have accessed the marrow; cut marks hinted that flesh was stripped from bone. To her surprise, the specimens were 3.4 million years old, putting the butcher’s behaviors back 800,000 years earlier than conventional estimates would suggest. That fact got Thompson, now an assistant professor in the department of anthropology at Yale University, thinking there might be more traces of tool use from those early times.

In a wide-ranging review published in February’s issue of Current Anthropology, Thompson joined a team of researchers to weave together several strands of recent evidence and propose a new theory about the transition to large-animal consumption by our ancestors. The prevailing view, supported by a confluence of fossil evidence from sites in Ethiopia, is that the emergence of flaked-tool use and meat consumption led to the cerebral expansion that kick-started human evolution more than 2 million years ago. Thompson and her colleagues disagree: Rather than using sharpened stones to hunt and scrape meat from animals, they suggest, earlier hominins may have first bashed bones to harvest fatty nutrients from marrow and brains.

Humans are the only primates to regularly consume animals larger than themselves. This nutritional exploitation, something Thompson and her colleagues call the “human predatory pattern,” has long been synonymous with the flesh-eating, man-the-hunter view of human origins.

Because large animals such as antelope pack serious micro- and macro-nutrient punches, scientists have thought their meat contributed to the development of humanity’s outsize brains. A consensus arose in the 1950s that our ancestors first hunted small animals before moving on to larger beasts about 2.6 million years ago. Flaked-tool use and meat eating became defining characteristics of the Homo genus.

“It’s a very appealing story,” says Thompson. “Right around that time, there appeared to be the first stone tools and butchery marks. You have the origins of our Homo genus. A lot of people like to associate that with what it means to be human.”

Then, starting in the mid-1980s, an opposing theory arose in which Homo’s emergence wasn’t so tightly coupled with the origins of hunting and predatory dominance. Rather, early hominins first accessed brain-feeding nutrients through scavenging large-animal carcasses. The debate has rolled on through the decades, with evidence for the scavenging theory gradually building.

The new paper goes further: Harvesting outer-bone meat would have come at significant costs, the authors argue. The chance of encountering predators is high when scraping raw flesh from a carcass. Chewing raw meat without specialized teeth doesn’t give much energetic benefit, studies have shown. In addition, meat exposed to the elements will quickly rot.

Marrow and brains, meanwhile, are locked inside bones and stay fresh longer. These highly nutritional parts are also a precursor to the fatty acids involved in brain and eye development. And more easily than flesh meat, bones could be carried away from carcass sites, safe from predators.

Conventional thinking has been that the behavioral package of early hominins was to go after meat and marrow together, explains Briana Pobiner, a paleoanthropologist at the Smithsonian Institution, who did not contribute to the new paper. But in the new paper, she says, “this team has shown that marrow may have in fact been more important. It’s a nuance, but an important nuance.”

The Pliocene—between 5.3 million and 2.6 million years ago—was an era of dramatic change. An intensely variable and cooling climate transformed vast swaths of rain forest into mosaics of grassland and savanna. Large clearings spawned ecological niches for opportunistic and versatile hominins like Australopithecus—a likely contender for the Homo ancestor—and Kenyanthropus to fill in. Larger predators may well have left carcasses for them to scavenge.

Evidence suggests hominins shifted their diet about 3.76 million years ago as they took advantage of the open spaces. By about 3.5 million years ago, some species of Australopithecus already showed increased brain sizes, up to 30 percent larger than those of chimpanzees of comparable body size. Canines had shrunk to proportions later seen in the genus Homo, and hand morphology was already more human than ape, with potential for both terrestrial travel and tool use.

Percussive tools, the authors argue, were the key to the transition to large-animal exploitation. Rocks could bash open bones, exposing the marrow inside. The alternative—that humans sharpened stone against stone, creating a flaked tool to carve meat from bone—seems more onerous, they say. They argue that such meat carving and the associated tool creation would likely come later.

As to who wielded these percussive instruments, the timeline presents a puzzle. The earliest Homo specimen is now dated to 2.8 million years. The Dikika fossils suggest butchery behaviors at 3.4 million years ago. Homo may have emerged earlier than scientists suspected—a theory that would need more fossil evidence to support it—or another hominin, such as Australopithecus, may have created tools before Homo.

Some scholars aren’t convinced by the study’s arguments, however. For example, Craig Stanford, an anthropologist at the University of Southern California, questions the emphasis on hominin scavenging behavior appearing before hunting. “We have no examples today of animals that scavenge but don’t hunt,” he adds.

To test the new theory, the review authors suggest seeking out further evidence of percussive tools that predate flaked tools. Researchers could, they note, broaden the search for the signatures of such instruments both within the existing fossil record and at dig sites. Thompson’s graduate students, for example, are using 3-D scanning and artificial-intelligence techniques to improve the identification of marks on fossils—whether they were created by early hominins, saber-toothed cats, hyenas, or other types of creatures.

What they uncover could deal a blow to their theory, but it will also, undoubtedly, enrich our understanding of how our ancestors evolved.

This post appears courtesy of  Sapiens.



In late 2016, American diplomats living in Cuba started hearing a strange noise in their homes. It was high-pitched, deafening, and persistent—and no one could work out where it was coming from.

In the following years, the mystery ballooned into an international incident. Many of the diplomats experienced dizziness, insomnia, hearing loss, and other troubling symptoms. A team from the University of Pennsylvania examined 21 affected people and concluded that they had “sustained injury to widespread brain networks,” based on evidence that other neurologists said was “almost unbelievably flimsy.” Donald Trump, without evidence, accused Cuba of being responsible. Various parties argued that the strange noise was the result of a sonic weapon, a microwave attack, or malfunctioning eavesdropping equipment.

But when the biologist Alexander Stubbs heard a recording, uploaded by the Associated Press, he heard not mechanical bugs, but biological ones. He realized that the noise sounded like the insects he used to hear while doing fieldwork in the Caribbean.

Together with Fernando Montealegre-Z, an expert on entomological acoustics, Stubbs scoured an online database of insect recordings. As first reported by Carl Zimmer in The New York Times, they found that one species—the Indies short-tailed cricket—makes a call that’s indistinguishable from the enigmatic Cuban recording. The duo have written a paper that describes their findings and are set to submit it to a journal for formal peer review.

After analyzing similar recordings, the Cuban government had also pointed its finger at crickets. But they blamed the wrong species—one whose song sounds very different, even to untrained ears. By contrast, the song of the Indies short-tailed cricket matches the Cuban noise in several telltale ways. Both are loudest at a frequency of 7 kilohertz, roughly an octave beyond the highest notes on a piano. Both consist of pulses that repeat 180 times a second. In both, each pulse consists of 30 oscillations, which become slightly lower in pitch as they die away.

Only one thing didn’t match: The pulses in the AP recording were more erratic and variable than those of most insects. But that, Stubbs thinks, is because the cricket’s call was probably echoing off the surfaces of an indoor space, creating several sound streams that interfered with one another. When he played and recorded the cricket’s call indoors, the result matched the Cuban noise even more closely.

Cricket behavior could also help explain another mysterious detail of the Cuban incidents: Several diplomats claimed that the sound abruptly stopped when they entered a room or moved around. That’s “consistent with an insect stopping a call when threatened,” Stubbs and Montealegre-Z write.

Of course, the diplomats could have been attacked in some other way. Or their symptoms might be the result of a mass psychosomatic illness. Diplomats in China also reported mysterious sounds and symptoms, still unexplained. But for now it seems that the noise at the heart of the Cuban incidents probably has a benign origin.

Somewhat ironically, one of the first diplomats to hear the noise was tantalizingly close to the right answer. As reported by ProPublica, he blamed cicadas (which are not crickets, but do also sing). “Cicadas don’t sound like that,” his neighbor reportedly said. “It’s too mechanical-sounding.” But the Indies short-tailed cricket is no ordinary singing insect. It has the fastest pulse-repetition rate of any cricket in the Caribbean or North America. Have a listen. It sounds pretty mechanical!

The cricket story reminds me of a very similar saga: the Sausalito hum. Back in the 1980s, just across the bay from San Francisco, the people of Sausalito were kept awake by a loud, rumbling hum, which reverberated through the walls of their expensive houseboats. Some thought it was effluent being pumped from a sewage pipe. Others blamed a cable recently laid by an electric company. Yet others suspected Russian submarines.

But John McCosker from the California Academy of Sciences eventually showed that the hum was the love song of the male plainfin midshipman—a type of toadfish. These fish attract females by vibrating their swim bladder, the same organ that keeps them afloat, to produce an extremely loud noise that sounds more like a foghorn than a fish. When many males sing en masse, the ruckus can be heard on land, in Sausalito, Seattle, Southampton, and everywhere else that toadfish are found.





Here are puffins, sounding like chainsaws.

Cheetahs chirp, koalas and alligators bellow, barn owls make ungodly screeches, ptarmigans sound like cartoon characters.

Our unfamiliarity with these calls is a boon for moviemakers, who can blend the vocal stylings of actual creatures into the calls of imagined ones. To make the hoots and rasps of the Velociraptors in Jurassic Park, sound technicians mixed together cranes, geese, dolphins (that’s the scream), walruses, and ... er ... tortoises having sex. Here, incidentally, is what mating tortoises sound like:

Underwater, animal noises get even stranger. Although Jacques Cousteau once described the ocean as a “silent world,” it is anything but. That gentle, low hum is the sound of billions of migrating fish and jellyfish, moving up and down the water column to feed. Those crackling pops are made by the oversize claws of snapping shrimp, or perhaps by parrotfish as they crunch through coral. A few years ago, the marine biologist Denise Risch showed that the mysterious “bio-duck,” a quacking noise first heard by submarine sonar operators in the 1960s, is actually produced by the minke whale.

The bio-duck, the Sausalito hum, and the Cuban “sonic attack” all represent collisions between our limited experience of nature’s soundscape and its full, clamorous extent—grunts, wails, thrums, mechanical whirrs. We grow up listening to the barks and meows of pets, the moos and oinks of Old MacDonald’s farm, and the tweets and chirps of dawn choruses. As long as our conception of natural noises is based on only this thin sliver of species, perfectly standard animal noises will continue to sound like news to us—even if they’re not so mysterious after all.



Two years ago, a farmer from Wubaiding Village, in northeastern China, came across a beautiful fossil. The only animal fossils that had ever been found at this site were a pair of salamanders, but when Min Wang from the Chinese Academy of Sciences saw the new specimen, he was sure it was a dinosaur.

Studying the beautifully preserved and nigh-complete skeleton, Wang took note of the creature’s sparrow-size body, the quill-like feathers on its neck, and its stubby tail. But when he looked more closely at the left arm, he saw a thin bone coming down from its wrist—a rod as long as the entire forearm, but not jointed like a finger. “I shouted, and my heartbeat elevated,” he says.

He knew he had found another bat-winged dinosaur.

Hold your arm out to the side, palm facing forward. Imagine a bony rod extending downward from your wrist. Now imagine that rod supports a membrane that stretches from your fingertips to your side. That’s how Wang saw his new dinosaur—a feathered animal with a pair of bat-like wings. He named it Ambopteryx longibranchium, from the Latin for “both wings, long upper arm.”

Ambopteryx is actually the second bat-winged dinosaur to be found. The first was also spotted by a farmer in northeastern China, and eventually described in 2015 by Xing Xu and Xiaoting Zheng. Named Yi qi, after the Mandarin for “strange wing,” it also had a long wrist-rod that likely supported a leathery membrane.

It was a stunning discovery, which broke a neat divide between two styles of prehistoric flight. The dinosaurs took to the skies by transforming insulating fuzz into elegant, flattened feathers, and eventually giving rise to birds. The pterosaurs—often bundled together with dinosaurs, but actually a very different kind of reptile—did so by lengthening their fingers to support membranes, creating a style of wing that bats later reinvented. But Yi straddled both worlds. It was a dinosaur that independently evolved the leathery wings of pterosaurs, and covered their leading edges with fuzzy proto-feathers.

Since its unveiling, “paleontologists have hoped that something similar might show itself to either confirm or refute the interpretation of Yi qi,” says Michael Habib of the University of Southern California, who studies prehistoric fliers. The discovery of Ambopteryx does the former.

Its fossilized arms are folded, so it’s hard to reconstruct their outstretched shape. But the fact that the wrist-rod stows away into a sensible position also backs up the idea that it supported a leathery wing. “After all, an animal wing has to fold up properly when not in use,” Habib says.

“It’s a fascinating find, which confirms that dinosaurs took flight multiple times and very different ways,” says Julia Clarke of the University of Texas at Austin. “It’s not an animal or a set of [traits] I would have predicted.”

Yi and Ambopteryx both belong to the scansoriopterygids—an obscure group of small, two-legged creatures that were closely related to Velociraptor and birds, and that were among the smallest dinosaurs. Only four species have been identified, and all of them have an extremely long third finger. When the group was first discovered, researchers suggested that they used this finger to extract grubs from wood, just like the aye-aye—a bizarre, shaggy-furred lemur—does today. But Wang and his colleagues think that this finger wouldn’t have been mobile enough for that. Instead, they argue, its main role was to support a leathery wing.

That wing almost certainly wasn’t good for flapping flight. Fliers with leathery membranes, like bats and pterosaurs, use muscles in their arms to constantly adjust the tension in their wings, to stop them from being distorted by incoming air currents. The scansoriopterygid wrist-rods had no such muscles, so these dinosaurs probably couldn’t have exerted the fine control necessary for true flight. Instead, Ambopteryx and Yi were likely gliders, much like modern-day flying squirrels, sugar gliders, and colugos. (Flying squirrels also hold their gliding membranes aloft with a long piece of cartilage that comes from their wrists.)

“The Ambopteryx-style wing was probably an evolutionary experiment that didn’t leave any descendants,” Habib says. For whatever reason, pterosaurs fared well with leathery wings (and bats still do), but dinosaurs did not. For them, the crucial innovation was the feathered wing, a feature that today’s dinosaurs—the birds—still rely on.



Imagine you’re a baby mammoth. It’s 1.4 million years before the present day, in the middle of January, and you haven’t seen the sun in weeks. All around you, the Yukon tundra stretches into miles and miles of nothingness. Suddenly, a shape hurtles out of the darkness. And as you turn to meet your killer, you come face to face with … a hyena?

Since the first hyena fossil was identified in the Americas nearly a century ago, scientists have suspected that an extinct species of hyena, Chasmaporthetes ossifragus, must have traveled over the Bering Land Bridge from Siberia. But they never had definitive proof, until Jack Tseng, a paleontologist at the University at Buffalo, examined two mystery fossils that had sat in museum drawers for 40 years. Tseng knows a hyena tooth when he sees one, and he immediately picked up on the triple cusps and pyramidal shape of the third premolar. It took him only half a day to confidently identify the specimens as Chasmaporthetes.

Those two fossilized teeth just so happen to be the first to have been found in the Yukon, and in a new paper, Tseng and his co-authors peg them to be about 1.4 million years old. That means their owner, or owners, likely would have trotted around the same frozen landscapes as giant steppe mammoths and saber-toothed cats.

Hyenas are more familiar today as creatures of the savanna, but on some level, they make sense as Arctic inhabitants, living among large, trunked mammals and big cats, just as modern hyenas live among elephants and lions. “It’s really easy for us to sort of fall into a trap of thinking that these habitats were a lot like the African Serengeti,” says Grant Zazula, the Canadian government’s official Yukon paleontologist and a co-author of the paper. “And in some ways, they were.” After all, the desert and the tundra are both extreme, inhospitable climates, with no forests for big herbivores to hide in. Still, the Yukon during the Pleistocene era was dark four months of the year and very cold. Even though modern-day packs hunt at night, hyenas living in Ice Age Canada would still have depended on some very different adaptations—for a start, some thicker, lighter-colored fur would have been in order.

Based on other specimens collected in the past century, scientists know that Chasmaporthetes had longer, more evenly proportioned legs than modern-day hyenas, along with a shallower skull, which would have made for faster, more sustained running and a wolflike appearance. According to Julie Meachen, a paleontologist at Des Moines University, the hyenas would have hunted and scavenged on animals such as musk oxen and caribou in the Arctic tundra. They might also have chowed down on bison and horses in refugia between the glaciers, where things were relatively temperate and “a little more vegetated.”

Overall, “it would not have been a very comfortable life,” Tseng says.

Paleontologists don’t yet know how long Chasmaporthetes hung around in the Arctic. Meachen says the journey from Siberia to Florida, where other fossils have been found, would have taken at least several generations. But “it’s unknown whether this individual was just passing through, or whether it actually made its home” in the Arctic, she says. Scientists would know for sure only if they found a continuous fossil record in the region.

But such continuity would be hard to establish. Chasmaporthetes fossils in general are not as widespread as, say, Pleistocene-era bison, both because the hyenas themselves were not very densely populated and because glaciers can disrupt these records. The icy behemoths can act like bulldozers, churning up the rock and dirt and bones beneath them as they push along, explains Leigha Lynch, a molecular paleontologist at Washington University in St. Louis who was not involved in the study. When glaciers expand and retreat over centuries, that process can leave the terrain unrecognizable. “That’s the whole Pleistocene,” Lynch says. “It’s just one cycle of that after the other after the other.” (That said, glaciers and permafrost do have the added benefit of preserving flesh and hair, not just bones. As Tseng put it, “I’m hoping maybe one day some of the Siberian permafrost will reveal an Ice Age hyena.”)

Scientists think that plenty of other species made their way from Asia to the Americas, and vice versa, through the Arctic, but they still haven’t found—or, perhaps, identified—fossilized proof. “This is one of the few instances where we have unambiguous evidence,” Tseng says. So given that significance, why did the fossils sit around in a museum for four decades before Tseng came along to identify them?

The two teeth were first uncovered in 1974 and 1977. Soon after, a paleontologist named Brenda Beebe wrote that she thought the specimens belonged to a different species of hyena. Beebe never published her findings, but she did send a manuscript to another paleontologist, Björn Kurtén. (Both Beebe and Kurtén have since died.) A few years ago, one of Kurtén’s former students, Lars Werdelin (who is also an author on the new paper), dug up the manuscript among Kurtén’s notes. He scanned it and sent it to Tseng, who got in touch with Zazula, who figured out that the teeth were being stored at the Canadian Museum of Nature.

After more than 40 years, all it took for Tseng to confirm that the fossils were Chasmaporthetes was a six-hour drive from Buffalo to Ottawa, a few hours of handling and photographing the fossils, and another six-hour drive back. He wrote the paper when he got home.

Meachen, who reviewed the new paper, says it’s “pretty basic” in that it doesn’t do much beyond describe the fossils at hand and offer a probable identification. A common problem with paleontology studies is that authors often draw sweeping conclusions from just a handful of bones or teeth, Lynch points out. “I really appreciated that the authors were very conservative in saying, ‘We tentatively assign it to this species, but we recognize that we have two teeth,’” she says.

The delay between the discovery and description of the Arctic Chasmaporthetes fossils is pretty standard for paleontology, a product of the way paleontological data are collected and how researchers organize their time. Zazula told me that his team can collect almost 10,000 specimens from Yukon sites in any given summer. That’s way too many fossils for them to get through immediately, and not every expedition team includes a hyena specialist, so the team catalogs them on a basic level and stores them until someone comes along to see them. Even the first known fossils of Chasmaporthetes, unearthed between 1901 and 1904, weren’t formally described until nearly 20 years later. “It’s pretty common in paleontology” for specimens to be found and not reported on, Meachen says. “I would love for it to be a systematic experience where people are like, ‘I’m going to go through this whole collection and describe everything that’s not described,’ but that’s never how it works.”

Once the right specialist gets around to looking at the right fossil, identification can often be as immediate as Tseng’s quick assessment of the Chasmaporthetes specimens. Meachen, who is an expert in Plesitocene-era cats and canines, told me, “I can do the same thing, and I can do it with teeth or I can do it with postcranial bones … It just depends on how much experience you have.”

If you’re a paleontologist, waiting a few decades to learn from new discoveries might seem trivial. “To think of hyenas being a major part of that system is so fantastic to most of us. But it’s also not that long ago. It’s geologically yesterday!” Zazula said. “A million years ago is nothing.”



The year 2018 was not an easy one for planet Earth.

Sure, wind and solar energy kept getting cheaper, and an electric car became America’s best-selling luxury vehicle. But the most important metric of climatic health—the amount of heat-trapping gas entering the atmosphere—got suddenly and shockingly worse.

In the United States, carbon emissions leapt back up, making their largest year-over-year increase since the end of the Great Recession. This matched the trend across the globe. According to two major studies, greenhouse-gas emissions worldwide shot up in 2018—accelerating like a “speeding freight train,” as one scientist put it.

U.S. emissions do remain 11 percent below their 2007 peak, but that is one of the few bright spots in the data. Global emissions are now higher than ever. And the 2018 statistics are all the more dismal because greenhouse-gas emissions had previously seemed to be slowing or even declining, both in the United States and around the world.

Many economists expect carbon emissions to drop somewhat throughout the next few decades. But maybe they won’t. If 2018 is any indication, meekly positive energy trends will not handily reduce emissions, even in developed economies like the United States. It raises a bleak question: Are we currently on the worst-case scenario for climate change?

“We’re actually a lot closer than we should be; I can say that with confidence,” says Rob Jackson, an Earth scientist at Stanford and the chair of the Global Carbon Project, which leads the research tracking worldwide emissions levels.

When climate scientists want to tell a story about the future of the planet, they use a set of four standard scenarios called “representative concentration pathways,” or RCPs. RCPs are ubiquitous in climate science, appearing in virtually any study that uses climate models to investigate the 21st century. They’ve popped up in research about subjects as disparate as southwestern mega-droughts, future immigration flows to Europe, and poor nighttime sleep quality.

Each RCP is assigned a number that describes how the climate will fare in the year 2100. Generally, a higher RCP number describes a scarier fate: It means that humanity emitted more carbon dioxide into the atmosphere during the 21st century, further warming the planet and acidifying the ocean.  The best-case scenario is called RCP 2.6. The worst case is RCP 8.5.

“God help us if 8.5 turns out to be the right scenario,” Jackson told me. Under RCP 8.5, the world’s average temperature would rise by 4.9 degrees Celsius, or nearly 9 degrees Fahrenheit. “That’s an inconceivable increase for global temperatures—especially when we think about them being global average temperatures,” he said. “Temperatures will be even higher in the northern latitudes, and higher over land than over the ocean.”

This scenario could still be in the planet’s future, according to Zeke Hausfather, an analyst and climate scientist at Berkeley Earth. Since 2005, total global greenhouse-gas emissions have most closely tracked the RCP 8.5 scenario, he says. “There may be good reasons to be skeptical of RCP 8.5’s late-century values, but observations to-date don’t really give us grounds to exclude it,” he recently wrote.

Even if we avoid RCP 8.5, the less dramatic possibilities still could lead to catastrophic warming. Jackson, the Stanford professor, warned that every emissions scenario that meets the Paris Agreement’s 2-degree Celsius “goal” assumes that humanity will soon develop technology to remove carbon directly from the atmosphere. Such technology has never existed at industrial scales.

“Even some [of the scenarios] for 3 degrees Celsius assume that at some point in the next 50 years, we will have large-scale industrial activities to remove greenhouse gases from the atmosphere,” he said. “It’s a very dangerous game, I think. We’re assuming that this thing we can’t do today will somehow be possible and cheaper in the future. I believe in tech, but I don’t believe in magic.”

Yet not all data suggest that we’re doomed to RCP 8.5 or equivalent amounts of warming, Hausfather cautions. If you look only at pollution from fossil-fuel burning—and not from land-use events like deforestation—then humanity’s recent record trends closer to RCP 4.5.

That’s good news, but only by comparison: RCP 4.5 still forecasts that global temperatures will rise by 2.4 degrees Celsius, enough to kill off nearly every coral reef and soar past the 2-degree target set out in the Paris Agreement on climate change.

There are a few reasons it’s hard to say which RCP comes closest to our reality. First, most of the RCPs tell roughly the same story about global emissions until about 2025 or 2030. Second, the RCPs describe emissions across the entire sweep of the 21st century—and the century mostly hasn’t happened yet. Trying to pick the most likely RCP in 2018 is a bit like trying to predict the precise depth of late-night snowfall at 4:32 a.m.

The RCP 8.5 scenario may also become less likely in years to come, even if major polluters like the United States, China, and India never pass muscular climate policy. RCP 8.5 says that the global coal industry will eventually become seven times bigger than it is today. “It’s tough to claim that … that is a business-as-usual world,” Hausfather says. “It’s certainly a possible world, but we also live in a world today where solar is increasingly cheaper than coal.”

That’s part of the reason the Intergovernmental Panel on Climate Change will soon expand its list of standard scenarios. Its next major synthesis report, due to be published in 2021, will replace RCPs with five “socioeconomic pathways” that allow for a broader range of futures.

Jackson urged caution. “We don’t know yet what scenario we’re on,” he said. “I think most climate scientists will tell you that we’re below the 8.5 scenario. But every year that emissions increase like they have this year, it makes the 8.5 scenario more plausible.”

Jackson published his first academic paper in 1989, just a year after the NASA scientist James Hansen first warned Congress that global warming had begun in earnest. I asked whether he thought actual emissions would ever come close to RCP 8.5. 

“It’s nuts,” he said. “But I used to think a lot of things were nuts that turned out not to be nuts.”



Working the night shift can be pretty boring, even if you’re a telescope. You stare at the same section of sky for hours. Every night, you take in light from the same distant points in the abyss. There’s that asteroid you observed last night, and the night before that, and before that. The job, as important as it is, can be pretty tedious.

But sometimes the universe sends a little excitement—a cosmic phenomenon astronomers have explored only with theoretical models.

One night in June of last year, a telescope in Hawaii captured something noteworthy in its nightly scan. A luminous dot appeared where nothing had been before, as if someone had switched on a light. A message immediately went out on the Astronomer’s Telegram, an alert system for astronomers around the world.

A scramble ensued. There’s no guarantee unexpected objects in the night sky will stick around. Astronomers directed telescopes of all kinds at the point of light, observing the target in every wavelength of the electromagnetic spectrum, from optical light to invisible X-rays. Early data revealed the light originated outside the Milky Way galaxy, from a small, nearby galaxy about 200 million light-years away. (Yes, this is actually considered nearby in cosmic standards.)

At first, the gleaming object looked like it could be a supernova, a cataclysmic explosion that marks the end of a star. Stars, as immutable as they may seem to us, blazing brightly in the night sky, can die. The process is ferocious and quick: The star, after millions and millions of years of existence, runs out of the fuel that produces its brilliant light. Its core shrinks, heats up, and then collapses, sending stellar material hurtling across space. The resulting glow briefly outshines whole galaxies before fading away.

Telescopes have observed supernovae before. But this one?

“It was very clear that it was not a normal supernova,” says Raffaella Margutti, an astrophysicist at Northwestern University, one of the many scientists who followed the mystery object, known as AT2018cow.

The alleged supernova was dozens of times as bright as any supernova on record. It reached its peak luminosity in two days and faded after 16 days. This, on the vast timescales of the universe, is extremely fast—faster than astronomers had ever seen.

According to current understanding in astronomy, this scenario should not be possible. The brightest supernovae usually come from the deaths of the biggest stars. These are slow affairs: The more material a dying star expels, the longer it takes for the afterglow of the explosion to reach its peak radiance. How could the mystery explosion flare so brightly and fade so quickly?

“It’s weird to see something that’s bright and evolving fast,” explains Iair Arcavi, an astronomer at Las Cumbres Observatory, a global network of ground-based telescopes. “It’s kind of a contradiction.”

When astronomers took a closer look at telescope data, they saw an unusual excess of X-rays. “Our first reaction, when we got that data, was maybe we made some mistake, because we’ve never seen that,” Margutti said. It meant that, deep in the core of the explosion, there was a source of X-rays so persistent that it would shine through the material surrounding it.

That gave the astronomers a clue about what they could be looking at. Almost all massive stars are thought to produce new astrophysical objects when they die—either a black hole or a neutron star. Black holes are invisible maws that gobble any material—gas, dust, entire stars—that comes near. Neutron stars are fast-spinning cores of tightly packed neutrons, the stripped-down versions of their progenitors. Both are extremely dense objects capable of violently whisking surrounding material. Margutti and her colleagues suspect that, in this case, those effects were enough to produce an unusually radiant light show.

The telescope, they’ve concluded, had captured the creation of a brand-new astrophysical object, either a black hole or a neutron star, for the first time.

The cosmic explosion has faded from the view of most telescopes, and the telescope in Hawaii now awaits the appearance of the next surprising pinprick of light. That’s what cosmic explosions beyond the galaxy will always look like to us, regardless of their record-breaking radiance. For now, astronomers continue to pore over the data from AT2018cow; Margutti and an international team of scientists published their report about the object this week.

They remain mesmerized by the event’s unusual characteristics—the fierceness of the glow, the speed with which it vanished, the X-rays that illuminated what remained at the core.

“Any one of them on their own would be completely unprecedented, but any two of them together—and certainly all of them together—are unlike anything we’ve ever seen before,” said Daniel Perley, an astrophysicist at Liverpool John Moores University.



The very first giant virus was discovered in a water-cooling tower in 2003. As the name suggests, giant viruses are unusually large and their genomes unusually complex, all of which went against the prevailing idea of viruses as small, simple, and primitive. Then one baffling giant virus became many, as scientists kept discovering different types: in water off the Chilean coast, in Siberian permafrost, in an Austrian sewage plant, and now in mud from a Japanese hot spring.

The newest giant virus is Medusavirus, so named because of the way it infects amoebas, single-celled organisms that commonly live in water. When Masaharu Takemura, a virologist at Tokyo University of Science, first grew microbes from the hot-spring mud in his lab, he noticed that some amoebas would die in the presence of the giant virus. The dead amoeba cells burst open. But others would shrivel and harden, which amoebas sometimes do when guarding against bacteria that also prey on them. (It’s a dangerous life out there for amoebas.)

Takemura told me in an email that he had long been fascinated with the myth of Medusa, who turned men who looked at her to stone. His computer background is Peter Paul Rubens’s famous painting of Medusa. Thus inspired, he named the new giant virus Medusavirus.

Takemura and his colleagues then analyzed the new virus more closely. They put it under an electron microscope and found that it resembles a 20-sided die, covered in 2,660 round-tipped spikes. It’s unclear exactly what the purpose of the spikes are, but they have been found in other giant viruses. The team sequenced the virus’s DNA, which revealed the most interesting information of all.

Medusavirus has a full set of genes for histones, the proteins around which long strands of DNA wind themselves. But viruses aren’t supposed to have histones. “Histones are a way to supercoil the DNA and to organize it,” says Gilbert Greub, a microbiologist at the University of Lausanne. Think of a set of headphone cords, or garden hoses, or long lengths of rope. “If you don’t have the rope arranged, it will be a disaster,” Greub says. Same with DNA. But viruses have too little DNA to need this sort of organization. Even bacteria don’t have histones. Humans and plants, or other complex life forms with long, complicated genomes, have histones.

How could Medusavirus have acquired histones—and not just one, but all five types that are present in complex cells? One theory is the virus acquired the genes from complex cells, such as the amoeba it infects. (Although unicellular, amoebas have complex-enough cells to be categorized as complex life. They have histones.) By comparing the genome of the Medusavirus with the amoeba it infects, the team found 57 examples of gene transfer. “Many people tend to believe viruses steal genes from hosts for their own purposes. This is true,” says Hiroyuki Ogata, a bioinformatician at Kyoto University and another member of the scientific team that discovered Medusavirus. But out of 57 likely gene transfers, only 12 seemed to be cases of the virus taking genes from the amoeba. In 13 cases, the virus seemed to have given the gene to the amoeba. The direction of transfer was unclear in the rest.

What’s more, the Medusavirus had a gene coding for DNA polymerase, an enzyme necessary to synthesize DNA. Its version of DNA polymerase was similar to those in complex life, but it didn’t exactly look like any particular animal or plant’s version—meaning it likely wasn’t stolen directly from a complex cell. Instead, the Medusavirus’s DNA polymerase seemed ancient in origin.

As more and more giant viruses have been discovered, scientists have started to wonder whether some genes in living organisms actually came from ancient viruses. Viruses are not traditionally considered alive, because they lack the cellular machinery to replicate on their own. But scientists have found giant viruses with genes for building proteins, which are necessary for replication. The Lausannevirus that Greub discovered also has genes for histones. Other viruses have yet other genes important to life.

If living organisms got genes from viruses, that would be a radical inversion of previous hypotheses about their origin. Scientists have suggested that viruses might be degenerate versions of living cells that lost most of their cellular machinery, retaining only their protein capsule and genetic material. Or that viruses might be mere fragments of cells that broke off and are unable to replicate on their own.

But if histones and enzymes for synthesizing DNA originated in viruses, then they might have been present when life first began in primordial soup. They might be one reason life on this planet exists at all.



Martin Surbeck remembers the episode vividly. He was in the Democratic Republic of Congo’s LuiKotale rain forest, watching a group of bonobos, African apes that are closely related to chimpanzees. Two of them—Uma, a female, and Apollo, a young, low-ranking male—were trying to have sex. Camillo, the highest-ranked male in the group, caught wind of their liaison and tried to come between them. But Hanna, Apollo’s mother, rushed in and furiously chased Camillo away, allowing her son and his mate to copulate in peace.

This was just one of the many memorable incidents that Surbeck and his colleagues at the Max Planck Institute for Evolutionary Anthropology have observed over 16 years of watching bonobos. At first, before getting to know the individuals involved, Surbeck was surprised. “It’s not typical female behavior,” he says, in that female apes often stop unwanted males from mating with them, but very rarely police the mating attempts of other couples. He only worked out what was happening by collecting the bonobos’ poop, and sending the samples off to colleagues who sequenced the DNA within. Their analysis confirmed how the different bonobos were related, and clearly showed that mothers were repeatedly and actively improving their sons’ sex lives.

Sometimes, they did so without trying. Bonobos live in mostly matriarchal societies, where females both occupy the highest ranks and form the core of social groups. If sons stick close to their mother, they’re more likely to end up at the center of a community, where more females sit. “That creates more mating opportunities,” Surbeck says. “It’s not that the moms physically drag their sons over. It’s more like a social passport.”

But mothers frequently took matters into their own hands, too. As Hanna did, they would stop unrelated males from interfering with their sons’ sexual encounters. They’d interfere themselves, stopping unrelated males from mating with other females. They’d gang up with their sons to evict other males from trees with lots of females.

Surbeck thinks that the mothers use these strategies as a way of furthering their own genetic legacy. They can do this by having more children of their own, or by ensuring that their children give them more grandchildren. They have little influence over their daughters, because bonobo females tend to leave home to find their own communities. Males, however, stay with their birth group, and especially near their mother. Even in the best-case scenario, a male bonobo can easily go through life without reproducing, and without a mother’s presence, the odds of his having a kid are about one in 14. To increase the size of her own dynasty, a mother needs to ensure that her sons have the best sexual opportunities.

And that’s exactly what the team has now found: Males who still live with their mother were three times more likely to sire their own children than those whose mothers had gone.

The same wasn’t true for chimps. Chimps also live in groups where sons stay home and daughters emigrate, and many chimp mothers will support their sons. But that support, on average, doesn’t seem to affect their sons’ reproductive success. Surbeck thinks that’s because chimps live in strict patriarchies where all adult males outrank all females. In such a world, a mother’s ability to help her son might count for less. But in bonobo matriarchies, where females have power and leverage, it counts for a lot. “It’s a great study that highlights the significance of elevated female social power in this close cousin of ours,” says Zanna Clay at Durham University.

Cat Hobaiter at the University of St Andrews adds that chimp mothers might just have fewer chances to help their sons, because they’re less socially cohesive than bonobos. “A bonobo mother will probably see her son most days, while a chimpanzee mother might not see her son for weeks, or even months,” she says. But Hobaiter notes that some chimp subspecies, such as those in West Africa, are more cohesive—and in Surbeck’s study, it’s telling that West African chimps were the only group in which a mother’s support did benefit her sons.

Regardless, the broad difference between bonobos and chimps is both important and expected, says Michelle Rodrigues at the University of Illinois at Urbana–Champaign. Researchers already knew that a male bonobo’s rank depends on his mother’s, but it wasn’t clear if that was due to Mom’s social support, or her genes. After all, the same beneficial genes could account for both her success and his. “But if that was the case, we would see a similar pattern in chimps,” Rodrigues says. That we don’t, even though the two species are so genetically similar, “makes a compelling case” that it’s the differences in their social lives that matter.

Bonobos aren’t the only nonhuman animal group in which mothers clearly assist their adult sons. Orca (killer whale) mothers lead their sons to hot pots of salmon, and sons seemingly depend on that knowledge. If a mother orca dies, her sons’s odds of also dying within the next year can rise by up to 14 times.

This might explain why killer whales are among the few wild animals whose females go through menopause. Along with humans, short-finned pilot whales, narwhals, and belugas, orcas stop reproducing well before the end of their life. Perhaps they have evolved to, at some point, switch from having their own offspring to ensuring that their existing children survive long enough to bear grandchildren.

If that’s the case, one might expect bonobo females to also go through menopause—and there’s no evidence that they do. But Surbeck thinks that might be because no one has looked hard enough. “We’ve seen that certain females like Marta [Camillo’s mother] don’t reproduce for a long time,” he says. “We need to do a broader study to address this question properly.”



The United States is experiencing a new wave of aquarium enthusiasm. Over the past few years, groups in Detroit; St. Louis; Scranton, Pennsylvania; Memphis; Cape Canaveral, Florida; and New York City have proposed or started construction on large aquariums. Springfield, Missouri, and Shreveport, Louisiana, have recently opened aquariums. Boosters for these spaces are selling them as conservation initiatives that will create jobs and bring in revenue—alternatives to sports stadiums and shopping districts meant to revitalize downtrodden downtowns.

But the history of aquariums tells a different story. In the earliest public aquariums, tanks were sparsely populated with somewhat mundane species. These institutions started as traveling fishery exhibits: The 1904 St. Louis World’s Fair contained some of the first tank displays. The state of Pennsylvania fashioned a grotto with glass jewel boxes lining a dark hallway that was illuminated from above. The residents—trout, catfish, and others—had been sent via specialty train.

Enthusiasm for Pennsylvania’s exhibit was high, with many visitors returning several days in a row to walk through the grotto. Even after the fish started dropping dead because of excess lime, aluminum, and heat, the vacant tanks attracted crowds that came to marvel at the new technology.

These early exhibitions were successful enough that seven years later, the city of Philadelphia converted the traveling tanks into a stationary aquarium at Fairmount Park. One of the stars was a giant snapping turtle.

Philadelphia’s aquarium was part of a small but rapidly growing community of large public aquariums in the United States, including the Woods Hole Science Aquarium in Massachusetts (opened in 1885), the New York Aquarium (1896), and Detroit’s Belle Isle Aquarium (1904). Visitors were more concerned with wonder than education, and tanks usually contained local species, the occasional rescued family goldfish or donated lobster, and tropical fish. The aquarium keepers themselves had little interest in conservation. As aquarists developed the craft of holding aquatic organisms captive, many of the fish under their care died. In 1917, the Philadelphia aquarium received 663 fish for exhibition; by the end of the year, 454 had died.

Unlike zoos, which relied on specialty species such as tigers and elephants, early aquariums showed relatively common species—it was the very act of seeing underwater that drew visitors. By 1920, the earliest American aquariums had banded together to collect tropical fish for exhibition. Starting around 1915, a representative from the New York Aquarium traveled twice a year to Key West, Florida, where he collected a wide array of species. That same year, the assistant director and tropical-exhibits collector Louis Mowbray brought 148 animals from Key West to Detroit, including squirrelfish, spiny lobster, stone crab, a hawksbill turtle, two species of moray eel, and three of grouper.

The earliest aquariums had little concern for the impact their collecting might have on the health of a species or ecosystem. Charles Townsend, who became the second director of the New York Aquarium in 1902, knew firsthand through his work with the U.S. Fish Commission that the number of marine mammals was depleted in the wild. This did not stop him from seeking out porpoises, seals, and sea lions along the Atlantic Coast for exhibition. One of the last known Caribbean monk seals, declared extinct in 1952, spent the end of its life on display at the New York Aquarium.

Townsend never thought to use the aquarium as a space for mammal conservation, but he was not entirely inured to the decline in marine populations. In 1929, he imported some of the last Galápagos tortoises to aquariums and botanical parks around the United States and the Caribbean in an effort to save the lumbering giants from extinction. Until his death, Townsend kept close records of the tortoises, moving them to locations that he felt would have luck maintaining and growing captive populations. The year after he died, the first Galápagos tortoises bred in captivity hatched at the Bermuda Aquarium, and in the past decade, the surviving Townsend tortoises were returned to the Galápagos as part of the ongoing conservation initiative.

Through the years, aquariums have done more of this work, becoming integral to conservation initiatives by studying specimens in captivity and funding field research to help maintain endangered species. Established public aquariums are conscious of their past role in marine degradation, and their captive-breeding initiatives, especially for popular species such as seahorses and clownfish, seek to decrease the impact of exhibit collecting on wild populations.

But these initiatives account for only a small number of the exhibits in large aquariums, and have not stopped debate about the impact of collecting on wild populations. Earlier this year, Moody Gardens, a Texas aquarium, collected a variety of fish from a popular snorkeling area in Palm Beach County, Florida, prompting public outcry. A legal battle in Hawaii has resulted in the closure of some reefs for collectors, but has shifted the impact of collecting to foreign reefs, which are not as well managed.

Creating an artificial underwater environment is still a technological and scientific challenge, with limited initial conservation value. Current aquariums took years to develop the resources required to perform effective conservation; new aquariums will not have the ability to develop these initiatives for years, if ever. If they fail, the extraction of marine riches, required for setup, goes to waste. While many of aquariums’ earliest problems have been solved—we no longer see empty tanks—many new builds are doomed to failure, squandering monetary and natural resources in the process.

Architects and construction groups design aquariums, but aquarists must make the spaces functional. Often, aquariums’ most popular exhibits, such as mammals or sharks, prove the trickiest to maintain. Keeping sharks in captivity sounds great, but doing so takes specialized knowledge. The Dubai Aquarium, one of the largest tanks in the world, experienced several shark casualties before opening in 2008. The aquarists eventually worked out the optimum number of species for the tank, but other aquariums struggled longer with these issues. The Jerusalem aquarium, a 30-tank, $28.5 million building originally set to open in May 2017, delayed its opening after the loss of many exotic fish and two sharks. Some aquariums continue to try to keep great whites in captivity, with limited success and an almost 100 percent mortality rate.

The stress of acquisition and maintenance often leads to financial struggle. Originally operated by the City of New York, the New York Aquarium has been managed and funded by the Wildlife Conservation Society (formerly the New York Zoological Society) since 1902 due to financial strain; the City continues to provide electricity and water, while the Wildlife Conservation Society pays for upkeep and exhibition acquisition. Other early aquariums had to develop similar cost-sharing measures between private organizations and taxpayers. In this century, the Denver aquarium, which opened to much fanfare in 1999, declared bankruptcy in 2002 because of defaults on building loans. (It was purchased by Landry’s, a hospitality company, and reopened in 2003.) More recently, the newly opened Shreveport Aquarium has struggled with almost $500,000 in unpaid construction debt. Many of these spaces are subsidized by tax breaks and bonds, to be paid back when an aquarium becomes profitable. But too often, this goal is not realized. As economic-development projects, aquariums are risky.

In the 21st century, entering an aquarium can still conjure a sense of amazement, but for different reasons. I recently walked around the harbor near a public aquarium and saw not fish, but an enormous amount of plastic garbage. Entering the exhibit space, I was struck by the intense beauty of these model environments. There is wonder in seeing so many fish in one place—a protected place—when a reef dive today is more likely to reveal a world in distress. The sense of awe that aquariums can evoke should be mixed with an acknowledgment that the environments we see need saving—sometimes from our desire to see and touch them.

The Fairmount Aquarium in Philadelphia didn’t survive. The cost of maintenance was too much for a financially struggling city; when the call came to update the aquarium to more modern standards, it folded in 1962. The rash of aquariums currently being contemplated or built will eventually face these same concerns, and many will fail. But these spaces will have taken their toll, seizing resources from struggling ecosystems, both human and marine, without the ability to fully give back. And when they close, they will leave even larger holes in those fragile environments.



Nature is “red in tooth and claw,” as Alfred, Lord Tennyson wrote in the poem “In Memoriam A.H.H.” In that now-famous line, Ten­nyson was considering, pre-Darwin, the apparent callousness of nature. Nature is not cruel; it is simply indifferent, and these behaviors show a disregard for other living things, rather than malice.

Humans alone are capable of cruelty, and sexual coercion and rape are immoral and criminal acts. Describing nonhuman behavior in these terms trivializes rape.

We do need to talk about dolphins, though, as their sexual behav­ior is concerning and much discussed. We humans have a strange relation­ship with dolphins. We are often in awe at their intelligence and grace, and the tricks they do for us in captivity and in the wild. And they have nice smiley faces.

Dolphin is a loose and informal name for several different groups of cetaceans, including the Delphinidae (ocean dolphins) and three classes that live in rivers or estuaries (Indian, New World, and brackish). They are smart and have large, complex brains. They also have complex societies, among them notably (but certainly not exclusively) the bottlenose dolphins best studied in Shark Bay in Australia. Two or three male Shark Bay dolphins will form a gang that swim and hunt with each other, called a “first-order” pair or trio. Sometimes two pairs will team up and form a second-order alliance.

These Shark Bay dolphins are also viciously violent. When breeding season comes around, there is fierce competition for access to females, as happens in many sexual species. In most cases in nature, that competition is between individual males. The bottle­nose dolphins have a different tactic: They form gangs.

Alliances are an essential part of the mating strategies of the males. First-order partnerships will single out a female, rush at her, and then herd her away to have sex, which is coercive (this is a general assumption, because it is rarely seen). During this aggressive corralling, the female repeatedly tries to escape, and does so in about one of every four attempts. The males restrict her attempts at freedom by charging in, and bashing her with their tails, head-butting, biting, and body-slamming her into submission.

Second-order alliances do the same, but the team-up makes a ratio of five or six males to one female. The males are often closely related in these alliances, so as a means of transferring their genes into the future, this fits perfectly well within evolutionary theory. On occasion, they form looser “super-alliances,” where multiple second-order gangs will join forces—up to 14 individual males—to corral a single female. These gangs don’t tend to be closely related.

It should be noted that forced copulation has not been directly witnessed, as far as I am aware. The evidence comes from obser­vations of the precopulatory behavior, and physical evidence of violence on the females. Many people say semi-jokingly that in contrast to their cute and smart image, dolphins rape. There is no doubt that sexual coercion is part of their reproductive strategy, as it is in many organisms, and that the behavior is violent. But we must be careful not to anthropomorphize their behavior, whether it be cute, smart, or horrid.

Infanticide is another unpleasant behavior seen in dolphins. It often gets translated into murder in the popular press, but it should be noted that in plenty of other organisms, both males and females kill the young of others within their own species as a reproductive strategy.

A female lion lactates for more than a year when she is nursing cubs, and during this time won’t breed. Males acting alone or sometimes in packs will kill her young in order to bring her back to being fertile so they can then sire a pride. Mother-and-daughter teams of chimps in Tanzania have been seen killing and eating the babies of other parents for reasons that are not clear. Alpha-female meerkats will kill the litters of subordinate females so that they will be free to help nurture the alpha’s litter. Female cheetahs get around all these issues by copulating with multiple males. Their sperm mixes internally in the female, and she will give birth to offspring of several paternities in a single litter.

There are plenty of reports of dolphin calves washed up on beaches with extreme injuries. One study in the 1990s reported nine that had died of blunt-force trauma, including multiple rib fractures, lung lacerations, and deep puncture wounds that were consistent with bites from an adult dolphin.

Are dolphins murderers or rapists? No, because we cannot apply human legal terms to other animals. Is the behavior distasteful to us? Yes, but then again, nature does not care what you think.

This walk through some of the grimmer aspects of the behavior of animals serves as a reminder that nature can be brutal. The struggle for existence means competition, and competition results in conflict and sometimes lethal violence. We recognize these behaviors because humans compete and can be horrifically violent.

But we are not compelled to act violently. The evolution of our minds may have gifted us the ability to craft tools that enable mas­sacres. But it has also furnished us with choices unavailable to our evolutionary cousins. We are different because, with behavioral modernity, we have eased our own struggle for existence away from the brutality of nature, so that we are not obliged to kill others or force sex upon females in order to ensure our survival.

This post is adapted from Rutherford’s new book, Humanimal: How Homo sapiens Became Nature’s Most Paradoxical Creature.



PORTLAND, Maine—A less icy Arctic is coming, and generally speaking, that’s not a good thing. Climate change is warming this region twice as fast as the global average, threatening wildlife and indigenous communities. Melting permafrost in Greenland and the Arctic tundra is releasing vast amounts of methane, a potent climate-altering gas.

But some see an Arctic with navigable seas in the summer and newly accessible fossil fuels as an irresistible opportunity. Cargo shipping, cruising, mining, oil drilling, fishing—all these industrial activities could expand to the Arctic, one of the last remaining wild places, and with potentially devastating consequences.

The people of Maine want in. Public and private interests in the state are working to build trading relationships with other Arctic (and Arctic-ish) nations and communities. Though there is not a tremendous appetite for Arctic mining and fossil-fuel exploration in Maine, these commercial connections could serve to establish the state as an Arctic player for decades to come.

Maine is not, strictly speaking, in the Arctic, but a few things have happened to reorient the state’s compass north. First, in 2013, the state successfully persuaded Eimskip, a major Icelandic shipping company, to move its North American headquarters to Portland from Norfolk, Virginia. Within four years, Eimskip went from biweekly journeys between Portland; Reykjavik, Iceland; and parts of Canada to making them every week, taking Maine cranberries, wood pulp, candles, and more abroad and bringing back goods like frozen fish and sparkling water. From Reykjavik, Maine goods can head to any of the ports that Eimskip services in Norway, Denmark, the Faroe Islands, Greenland, and elsewhere.

Next, Angus King, the junior senator from Maine, made some significant moves. With Senator Lisa Murkowski, Republican of Alaska, he founded and co-chairs the Senate’s Arctic Caucus. And, in 2016, when the United States took its turn as the rotating chair of the Arctic Council, an intergovernmental forum for Arctic governance made up of the United States, Canada, Denmark, Finland, Iceland, Norway, Sweden, and Russia as members and indigenous groups as permanent participants, Senator King successfully lobbied for Portland to host the Senior Arctic Officials meeting, the first time the United States had hosted outside Alaska or Washington, D.C. Senator King seems especially keen on the long-term possibilities of an Arctic connection, which he likened to discovering the Mediterranean. After learning about the rapid decline of Arctic sea ice in the past few decades, “it didn’t take me long to realize that if you’re bringing a shipment of goods from Asia to the U.S., it’s a lot shorter to go [through the Northwest Passage, an Arctic route between the Pacific and Atlantic Oceans passing through the Canadian Arctic archipelago] and end up in Maine,” he said, adding that he is also a passionate advocate for climate-change mitigation. According to Jon Nass, the CEO of the Maine Port Authority, Portland (and Maine’s two other ports, Eastport and Searsport) will likely stay “niche ports,” and not destinations for mega cargo ships, such as the ones China might send to New York or Long Beach, California.

In response to these changes, state colleges and universities have created Arctic or North Atlantic institutes and exchanges. The Maine Maritime Academy has begun a polar-operations course with federal funding; in 2017, the Crystal Serenity, a luxury cruise ship, made a stop in Bar Harbor during a journey that traveled the Northwest Passage.

Almost everyone I spoke with in Maine who’s involved with the Arctic told me that Mainers have more in common with people from Iceland and Norway than they do with people from New York or California—they all live in relatively small communities with fairly extreme weather, and mainly depend on the ocean and other natural resources. People spoke glowingly with me about their trips to Iceland, how popular Maine craft beer is in the North Atlantic, and how this connection gives the state the chance to be at the beginning of something, rather than the last stop on a line that trails off as it stretches from New York to Boston.

But Arctic sea ice, at least in the summer, has to melt before any of the major industrial developments are realized: before the Northwest Passage sees major cargo-ship or cruise traffic; before Greenland is churned up by mining; before Russia, China, the United States, and others attempt to exploit the massive fossil-fuel reserves up there; before Arctic cod or other species are industrially fished. To be fair, those industrial and commercial developments don’t have much to do with Maine, but when dealing with the Arctic, the impacts of industry and commerce don’t stay in the Arctic.

Susan Kaplan, an anthropology professor and the director of the Arctic Studies Center at Bowdoin College, says, “We have a long history of Westerners going up to the Arctic and exploiting resources and leaving, having damaged the environment and having negatively affected the local population.” She adds, “We know better, and it’s time for that to stop. What I keep asking is that people think about that legacy, because we should be doing things differently.”

But others, even those who deal with resilience and adaptation, are more optimistic about the pros, such as Joel Clement, a senior fellow at the Harvard Kennedy School and former top climate-policy expert at the Department of the Interior (reassigned to the accounting office by former Secretary Ryan S. Zinke, he became an early whistleblower in the Donald Trump administration), who also happens to be from Maine. When he first heard about Maine’s Arctic ambitions, Clement says, “I thought it was a little bit surreal.” But in the years since, he’s come around: “They’re not so much taking advantage of climate change as adapting to coming change that they see.”

Maine might also need to explore fishing in the Arctic Ocean, given both the ongoing decline of several species (cod, shrimp, and herring) and the catastrophic warming of the Gulf of Maine, which has warmed faster than 99 percent of the global ocean. The lobster fishery has boomed in the past few years, but it might not last, because warming waters will likely affect the lobsters’ habitat and ability to reproduce. (In the meantime, the lobster and fishing industries contribute $1–2 billion to the state’s economy annually, according to the Maine International Trade Center.)

Warming and overfishing hit Maine’s fish-processing industry hard, so some companies, such as Bristol Seafood, turned north and began importing Norwegian haddock in 1994, when the Georges Bank fishing moratorium took effect. Having Eimskip next door has improved the company’s supply chain and brings in more fish, says Peter Handy, Bristol Seafood’s president and CEO, who also used the North Atlantic connection to learn about and install Icelandic processing machinery. “The North Atlantic, Iceland, [and] Norway’s connection with Maine is the only reason this company still exists,” Handy said, adding that sustainable fishing is very important to the company.

But no one knows exactly what will happen to Arctic fish populations, regardless of management. (Currently, there is an international moratorium on commercial fishing in the central Arctic Ocean.) A study that projected migrations for 686 North American fish species under various emissions scenarios anticipates that most species will move poleward, looking for cooler water, confounding management strategies and making sustainable fishing even more difficult. Essentially, Norwegian haddock could leave Norway, leaving Maine without a reliable fishery to source from. Plus, it could be shortsighted or climate-unaware to connect Maine, whose people and economy have suffered from the effects of overfishing, to a similar dynamic in another part of the world. But is it fair, especially for outside observers, to say they shouldn’t benefit from this opportunity, even if climate change does make it possible?

Handy thinks those mistakes can be avoided. “I don’t view our business in the Arctic as harmful,” he says. “We buy and process more haddock from Norway than we get from the entire state of Maine, and in Norway, no one could eat all of the haddock they catch.”

“Anything left unmanaged goes to hell,” Handy says, “and whether fisheries in the Arctic are growing or shrinking, both those scenarios can result in horrible social and environmental impacts.”

To suggest they are doing something wrong now may be unfair, but it’s worth noting the risks of Arctic development. If the Arctic becomes an essential part of Maine’s economy now, some degree of industrial development (and environmental catastrophe) may be unavoidable later on.

Arctic cruising is one area where that kind of development—with potentially serious environmental consequences—may already be unavoidable. From 2005 to 2015, the number of ships going through the Canadian Arctic alone more than tripled. Over the next two or three years, Arctic cruise companies will build 26 new ships to meet the demand, according to Edda Falk, a spokesperson for the Association of Arctic Expedition Cruise Operators.

The Maine Port Authority and Soli DG, a Portland consulting company, have been trying to encourage Arctic cruise lines —“adventure” cruises with only a few hundred passengers—to call on Maine ports. They have also recruited Hurtigruten, a Norwegian cruise company, to bring some of its North American cruise trips to Maine’s most valuable asset, its coast. Hurtigruten’s cruises through the Northwest Passage can accommodate somewhere between 300 and 500 passengers; typically boast gyms, saunas, and outdoor hot tubs; and range in cost from about $13,000 per passenger to $26,000, depending on the length of the journey.

If cruising in the Arctic is to continue (and it likely will, especially as navigation becomes easier), Greenland and the Canadian Arctic will need more infrastructure—ports, plumbing, buildings—to accommodate the tourists and the ships themselves. Maine businesses are hoping to build some of that infrastructure: Colby Company, a civil-engineering firm, is working with the Maine North Atlantic Development Office to create relationships in Greenland, while Hancock Lumber has expressed interest in providing building materials for the housing stock that may be needed when the ice sheet melts even more.

That infrastructure could be good for local communities, helping meet the needs of tourists who want to see the Arctic before it’s gone. But Kaplan warns that without the adequate involvement of indigenous groups, the arrival of cruise ships in remote communities could destroy their character, reducing them to souvenir-shop versions of themselves: “This is not an exotic playground; this is people’s home,” she says. “What the rest of the world needs to do is respect them and listen to them.” The new infrastructure could also come to support the extractive industries that might arrive and accelerate massive changes in Greenland.

Scientists and environmental advocates also expressed underlying fears for the environment and the survival of Arctic communities. Increased ship activity in the region could disrupt the mating and migration patterns of whales and other marine mammals that still find refuge in the Arctic, and on which indigenous communities depend. Search-and-rescue capabilities are a constant concern: There are no deep-water ports in the Canadian or American Arctic, not to mention that the United States only has one heavy polar-class icebreaker. If there were a disaster in the Northwest Passage or elsewhere in the North American Arctic, such as an oil spill or ship grounding, it could take about four or five days for any kind of cleanup or rescue operation to arrive, some experts say. According to Malte Humpert, the founder of the Arctic Institute, “For a major environmental disaster in the Arctic, it’s a question of when, not if,” a forecast repeated to me several times.

An environmental disaster in the Arctic doesn’t stay in the Arctic: What happens in the Arctic affects everyone, and it affects the Northern Hemisphere directly. The problem for Maine is that establishing trade relationships and developing commercial opportunities in the Arctic and Arctic-adjacent regions aren’t necessarily just about Maine and the Arctic. It smacks of elitism to say that Maine shouldn’t get to explore this new opportunity—especially because it has a higher poverty rate than any other state in the Northeast except New York—if changes to the Arctic will happen anyway. At the same time, protecting and preserving the Arctic is crucial for planetary survival. Figuring out how best to do that will be a global effort. Maybe if Maine has a say now, that could be good for all of us, so long as those with concerns for the environment and indigenous communities lead the way.

Or, as Joel Clement says, putting a twist on an old saying about Maine, “As goes the Arctic, so goes … a lot of other things.”



Imagine that an alien species landed on Earth and, through their mere presence, those aliens caused our art to vanish, our music to homogenize, and our technological know-how to disappear. That is effectively what humans have been doing to our closest relatives—chimpanzees.

Back in 1999, a team of scientists led by Andrew Whiten (and including Jane Goodall) showed that chimpanzees from different parts of Africa behave very differently from one another. Some groups use sticks to extract honey, while others use those same tools to fish for ants. Some would get each other’s attention by rapping branches with their knuckles, while others did it by loudly ripping leaves with their teeth. The team identified 39 of these traditions that are practiced by some communities but not others—a pattern that, at the time, hadn’t been seen in any animal except humans. It was evidence, the team said, that chimps have their own cultures.

It took a long time to convince skeptics that such cultures exist, but now we have plenty of examples of animals learning local traditions from one another. Some orangutans blow raspberries at each other before they go to bed. One dolphin learned to tail-walk from captive individuals and spread that trick to its own wild peers once released. Humpbacks and other whales have distinctive calls and songs in different seas. And chimps still stand out with “one of the most impressive cultural repertoires of nonhuman animals,” says Ammie Kalan, of the Max Planck Institute for Evolutionary Anthropology.

But just when many scientists have come to accept the existence of animal cultures, many of those cultures might vanish. Kalan and her colleagues have shown, through years of intensive fieldwork, that the very presence of humans has eroded the diversity of chimpanzee behavior. Where we flourish, their cultures shrivel. It is a bitterly ironic thing to learn on the 20th anniversary of Whiten’s classic study.

“It’s amazing to think that just 60 years ago, we knew next to nothing of the behavior of our sister species in the wild,” Whiten says. “But now, just as we are truly getting to know our primate cousins, the actions of humans are closing the window on all we have discovered.”

“Sometimes in the rush to conserve the species, I think we forget about the individuals,” says Cat Hobaiter, a primatologist at the University of St. Andrews. “Each population, each community, even each generation of chimpanzees is unique. An event might only have a small impact on the total population of chimpanzees, but it may wipe out an entire community—an entire culture. No matter what we do to restore habitat or support population growth, we may never be able to restore that culture.”

Since 2010, Kalan has been working on the Pan African Programme, an intensive effort to catalog chimp behavior in 46 sites across the species’ entire range, led by Hjalmar Kühl, Christophe Boesch, and Mimi Arandjelovic. At each site, the team checked whether chimps were carrying out any of 31 different behaviors, including many from Whiten’s original list, and some that had only been recently discovered. “We had things like termite fishing, ant fishing, algae fishing, stone throwing, leaf clipping, using sticks as marrow picks, using caves, bathing, and nut cracking,” Kalan says.

After all this work, the team showed that chimps living in areas most affected by humans were 88 percent less likely to show any one of the 31 behaviors than those living in the most unaffected regions. “However we divided up the data, we got the same very obvious pattern,” Kalan says.

It’s hard to prove a negative, though, and it’s always possible that the chimps were up to their old tricks without the team noticing. But the Pan African Programme team filmed the apes using camera traps, to capture behavior without disturbing the animals. It checked for certain traditions by looking for discarded tools, or checking for specific foods among the apes’ poop. And it scored the chimps generously: Even if it only saw a particular behavior once, it recorded the behavior as being present. If anything, the new results underestimate the extent to which humans suppress chimpanzee cultures.

Such suppression isn’t deliberate. Chimpanzees and other apes learn skills and customs from one another, and those chains of tradition depend on having enough individuals to learn from. So when humans kill chimps for bushmeat, they aren’t just killing individuals—they are also destroying opportunities for the survivors to learn new things. When they fragment the forests in which chimps live, they’re stopping the flow of ideas between populations.

The primatologist Carel van Schaik wrote about these problems in 2002 after studying orangutans, and he predicted then that “major traditional erosion is to be expected in all great apes.” “I realized that testing the hypothesis would be extremely difficult,” van Schaik says, but “thanks to the gargantuan efforts by this team, we have the first data, and they appear to totally confirm the model. It’s a very impressive study.” And it’s worrying, he adds, because many of these cultural behaviors aren’t arbitrary. They’re adaptations, and their loss could push an already endangered species even closer to extinction.

No one knows whether the hemorrhage of chimp culture is getting worse. Few places have tracked chimp behavior over long periods, and those that have are also more likely to have protected their animals from human influence.

And “not all human impacts are the same,” cautions Hobaiter, the University of St. Andrews primatologist. Clearing forests for palm oil is very different from sustainably using a forest as a food source. The Pan African Programme team clumped many indicators of human presence into a single metric, but teasing them apart is important. “Long-term conservation approaches are only going to be effective through the support and leadership of the local communities who live there,” Hobaiter says.

In some cases, the presence of people might create new traditions to replace the ones on the team’s list. In Bossou, Guinea, chimps have started drinking the wine that is fermented on palm trees. In other areas, they’ve taken to raiding human crops. “If you’re getting a lot of energy from high-nutrition human foods, you don’t have to spend half your day breaking nuts,” Kalan says. There’s certainly evidence that chimps can adapt to the presence of humans—but can they innovate quickly enough to compensate for the loss of their old ways?

Even if they can, isn’t that still a tragedy? We care about the loss of our own cultures. We work to document languages that are going extinct. We store old art in museums. We establish heritage sites to protect our cultural and historical treasures. It seems shortsighted—unimaginative, even—to be so concerned with our own traditions, but so blasé about those of our closest cousins, especially when we’ve only just started to appreciate how rich their cultural landscape can be.

Parts of that landscape might be lost before anyone realizes why it exists. In 2016, the Pan African Programme team reported that some West African chimpanzees habitually throw stones against the same trees, creating buildups of rocks that are reminiscent of human cairns. No one knows why they do this. “We’re still investigating it,” Kalan says. “And we might be running out of time.”

Other animals are also likely losing their ancestral knowledge at our hands. When poachers kill an elephant matriarch, they also kill her memories of hidden water sources and anti-lion tactics, leaving her family in a more precarious place. When moose and bighorn sheep were exterminated from parts of the U.S., their generations-old awareness of the best migration routes died with them. Relocated individuals, who were meant to replenish the once-lost populations, didn’t know where to go, and so failed to migrate.

These discoveries mean that conservationists need to think about saving species in a completely new way—by preserving animal traditions as well as bodies and genes. “Instead of focusing only on the conservation of genetically based entities like species, we now need to also consider culturally based entities,” says Whiten, who made a similar argument last week in a paper co-written with many scholars of animal cultures.

Kalan and the Pan African Programme team even think that conservationists should recognize places connected with unique traditions as chimpanzee cultural-heritage sites. “When we come across a nut-cracking site that’s been used for many generations, that site is part of the cultural heritage of this one population of chimps,” Kalan says. The same concept might apply to orangutans, whales, and other cultured creatures.

“What we have learned about culture can also be applied to how we conserve animals,” Whiten adds. When people raised endangered whooping cranes in captivity, they had to show the naive birds how to migrate by hopping into ultralight aircraft and showing them the way. “Where animals are to be reintroduced to areas in which they earlier became extinct, we have to make special efforts to reinstate the cultural knowledge they lost,” Whiten says.



For years, the Darién Gap, a narrow strip of pristine rain forest connecting Central and South America, was occupied by the Revolutionary Armed Forces of Colombia–People’s Army, or FARC, making it far too dangerous for any scientist to visit. But in 2016, after FARC negotiated a cease-fire with the Colombian government, the gap became far safer, and Wouter Halfwerk, an ecologist from Vrije University Amsterdam, wasted no time in visiting. He started looking for the túngara frog, a small, warty species that he had been studying in Panama for years. And to his surprise, he couldn’t find any.

Halfwerk had spent years in Gamboa, a town that houses people who work at the nearby Panama Canal. In that urban setting, túngara frogs find you. “They come up to your house, and if you approach them, they just keep on calling. You can just pick them up easily,” says Halfwerk. But in the forests of Darien, “it was like looking at a completely different species.” The forest individuals were shier, more elusive, and more easily disturbed than their urban cousins. And, as Halfwerk and his colleagues showed, they sound different, too.

Túngara frogs have some of the best-studied calls in the animal kingdom. Considering that the frog is just an inch long, its call is roughly as loud as a hair dryer, or a ringing phone. And while most frog calls consist of a single repeated chirp or ribbit, male túngara frogs have two elements: a downward whine, followed by one or more chucks. The more chucks a male adds, the more complex and extravagant his song becomes, and the more attractive he is to females. “We compare the call to a peacock’s tail,” Halfwerk says.

Why don’t males add as many chucks as they possibly can? Because their audience doesn’t consist of just females. Hungry frog-eating bats and blood-sucking midges are listening, too, and they are also more attracted to males with more complex calls. For these frogs, courtship is a risky business, and the balance between lust and danger—between sexual and natural selection—determines how complex they’re willing to make their calls.

Cities change that calculus, because bats and midges both stay away from night-lit homes and streets. These sources of light pollution create a halo of safety, in which túngara frogs can be the best singers they can be, without risking their own lives. “There’s no limit anymore, so the urban males can go wild,” says Halfwerk. Indeed, his team found that in towns, males call more frequently than in forests, and with more chucks. These more complex tunes are more irresistible to females from any location. All else being equal, urban males just sound sexier.

It’s clear that the sights and sounds of cities are problematic for many animals. Bright lights can disrupt the flights of moths and migrating birds, and send turtle hatchlings scurrying away from the sea. Loud noises can drown out mating calls, mask the approach of predators, and drive animals away. One team of scientists demonstrated this in dramatic fashion by playing the sound of traffic through speakers lashed to trees. This “phantom road” drove away a third of the local birds, and suppressed the weight of those that stayed.

But animals can also adapt to urbanity in positive ways. As my colleague Paul Bisceglio reported, there’s increasing evidence that city life can make the animals within them smarter, or at the very least more flexible. When Halfwerk moved urban túngara frogs to forests, the males could dial back the complexity of their calls to avoid bats and bugs. But the reverse wasn’t true: Forest males don’t suddenly croon with more complexity when entering the big city.

Many studies have shown that “wildlife in urban areas are responding to human modifications,” says Danielle Lee, an urban ecologist from Southern Illinois University Edwardsville. “Birds are singing through the night because of light pollution, and raccoons and squirrels are becoming cleverer in overcoming barriers to access food.” But it’s unclear whether reptiles and amphibians would react in the same way, given that they’re more sensitive to environmental conditions than mammals and birds. To see at least one study in which some frogs are adapting to city life “is good news,” Lee says.

In fact, there are now two such studies. A few years ago, Jennifer Tennessen from Pennsylvania State University found, through laboratory experiments, that wood frogs—a common North American species—are disturbed by traffic noise, which chronically raises levels of stress hormones in their bodies. But in the wild, “we were still seeing them in roadside ponds, and they were thriving,” says Tennessen. “It seemed like this mismatch.”

She and her colleagues collected wood-frog eggs from several quiet and noisy ponds, and raised them under the same laboratory conditions. Once the tadpoles had metamorphosed into adults, the team exposed them to recordings of either quiet ambient woodland noise or loud passing traffic, for eight continuous days. They found that frogs from quiet ponds showed higher levels of stress hormones and immune cells—two signs of stress—when exposed to traffic noise. But frogs that came from noisy ponds were unaffected. It seems that they had adapted to their cacophonous environments, perhaps in just a few dozen generations.

Such potentially rapid changes are encouraging, especially given how quickly humans are reshaping the world around us. But Tennessen cautions that there could be undocumented drawbacks to these seemingly positive adaptations. “If a population has evolved to mute its stress response to avoid the chronic costs associated with noise, they may not be able to respond to predators in an appropriate way,” she says.



We found the moose calf half an hour in. He lay atop thin snow on a gentle slope sheltered by the boughs of a big, black spruce, curled up as a dog would on a couch. He had turned his long, gaunt head to rest against his side and closed his eyes. He might have been sleeping. The day before, April 17, 2018, when the GPS tracker on the moose’s collar stopped moving for six hours, this stillness had caused both an email and a text to alert Jake Debow, a Vermont state field biologist who stood next to me now with Josh Blouin, another state biologist, that moose No. 75 had either shucked his collar or died.

“You want pictures before we start?” Debow asked me. He’s the senior of the two young biologists, both still in grad school, both in their late 20s, young and strong and funny, from families long in the north country, both drawn to the job by a love of hunting and being outside. Debow had always wanted to be a game warden; in college, he “fell in love with the science.” His Vermont roots go back 10 generations. “Jake Debow,” Josh told me, “is about as Vermont as you can get.” It was Debow’s second season on the moose project, and Blouin’s first. This was the sixth calf, of 30 collared, that they’d found sucked to death by ticks this season. They were here to necropsy the carcass, send the tissues to a veterinary pathology lab in New Hampshire, and try to figure out as much as possible about how and why these calves were dying.

First, they weighed him. To the trunk of the big spruce they strapped a custom-made scale—a steel ell with three pulleys and a thick rope to which they hooked a spring scale. They wrestled the moose onto a heavy net, collected the net’s four corners, and with the triple-pulley system and considerable effort, hoisted him off the ground. “Any guesses?” Debow asked after they’d secured the rope. The moose swung slowly just above the snow. I asked what this ten-month-old calf would have weighed if healthy: about 400 pounds. Blouin guessed 286. Debow said 312. I said 299. Debow looked at the scale. “Two-seventy. Lightest one yet.” The ticks had taken a third of this animal’s weight.

They gently lowered the calf to the ground and pulled him from the net. Debow took a six-inch steel ruler from his jacket pocket, kneeled behind the moose’s shoulder, and, with his hands, parted the fur and held it down, as one might hold a stiff-spined book to spread its pages, to expose a narrow, tick-width channel of skin some six inches long. Rather, he exposed not the moose’s skin, but some 50 ticks that completely obscured it. A few were male moose ticks, which sport a jagged fan pattern of tan and brown. Most were females, which have tan heads and tan legs that are conspicuous next to their dark, raisin-colored bodies. Beginning early in April, pregnant females living on a moose—and most females are pregnant—take a “blood meal,” sucking themselves full for days in anticipation of dropping to the ground to lay their hundreds of eggs. About half the females on this moose were in that engorged state. Swollen to 10 times their normal size, these ticks were stretched until they turned pale, like raisins morphed into cadaver-toned grapes. When a moose so infested rises from sleep, the imprint left behind in the snow is dotted and smudged with spots of blood.

Debow, wielding his ruler, called out square-centimeter tick counts to Blouin: nine ticks in the first square centimeter, seven engorged; eight in the second, none engorged; 28, four engorged; eight, none. This count would later produce an estimated infestation total of just under 14,000 ticks. This was actually far fewer than they often found, but it was enough to render this calf chronically anemic from January through March and then acutely, fatally anemic in the last couple of weeks of his life. In April, when the gravid females start taking their blood meals, the blood loss over their last two to four weeks aboard the moose “can equate to a calf’s total blood volume,” according to one recent paper—some three and a half gallons. As Inga Sidor, the New Hampshire state veterinary pathologist who processed the tissue samples Debow and Blouin took that day, later told me, the ticks “literally bleed the moose to death.”

Two months before, in mid-March, I had gotten my pre-fieldwork briefing from Vermont’s moose-team leader, Cedric Alexander, at his house in the snowy countryside in Cabot, Vermont. Smack in the middle of the northernmost quarter of the state, Cabot is an apt spot for Alexander. One of 11 children (four of them twins), he was born in the 1950s in the state’s wildest, emptiest, northeasternmost county, Essex, a place of mostly farms and timberland. He grew up fishing for trout and hunting deer, rabbit (with a beagle), and upland birds. When he was in middle school, his family moved across the state to the most citified, populous county, Chittenden, where he eventually earned a degree in wildlife biology at the University of Vermont. He has spent almost all of the 37 years since working as a state wildlife biologist, ranging around the physical and social landscape between Essex County and Burlington. He still believes in hunting—in its power to compel intimacy with a landscape, its honesty about where meat comes from, its world-erasing focus. He looks forward each fall to deer and moose season partly because he gets to staff the department’s weigh stations, most of them at the back of small-town general stores or gun shops—the Rack N’ Reel, Pauline’s Quick Stop, Mr. O’s Sporting Goods—where he queries the hunters who bring their take to be weighed and examined. Good stories, he says, and good intel.

Alexander is a tall man, lean and pleasant, relaxed at home. He was making coffee when I arrived, dressed in jeans and a green-and-black plaid shirt of heavy wool. After stirring us each a cup, he led me to a den beyond the living room. We sat on a big ruby-red modular sofa that framed a tinkling woodstove. Otherwise, it was dead quiet. Out the window, a sun-glinted snowfield sloped away under a brilliant blue sky.

Alexander got into wildlife because he loved birds, he said, and still does. But in a department organized along vernacular lines, he ended up on neither the feather nor fin team, but the fur. That was 1980. At the time, he said, “We didn’t have any moose.” Close; the official estimate that year, I later found, was 200. Moose, along with beavers, bears, fishers, eagles, and many other animals that were once abundant all over northern New England, had been killed off and driven from Vermont, New Hampshire, and most of Maine by the 1800s through uncontrolled hunting, trapping, water pollution, and logging. This environmental destruction, two centuries in the making, was the first of the ecological casualties of North America’s European immigration, and it remains one of the most astounding. When Europeans arrived, 80 percent of northern New England was forested. By 1850, using just handsaws and fire, they had stripped away three- quarters of that—almost 16 million acres—and left only 20 to 25 percent forested.

Another reversal was to come. Starting in the mid-1800s—at first accidentally, as post–Civil War farmers fled west for better soil, and then more and more intentionally—the people of New England righted these ratios; by 1990, the region was 85 percent forested. This recovery, the noted environmentalist Bill McKibben has written, is one of America’s greatest and perhaps least-recognized conservation victories. In the past 50 years, and especially the past 30, many of the species driven out centuries ago have returned. They came down from Canada or over from lands west to which they’d retreated: eagles, peregrine falcons, other birds of prey; pine siskin and black-throated blue warblers; salmon and brook trout; beavers, bears, bobcats, fishers; and moose.

The moose was the last to reappear. Perhaps because of this late return, and definitely because of their strange magnificence, the moose, Alces alces, holds a singular place in the hearts of New Englanders. In a land of straightforward, understated, and sometimes stubborn people, it’s a straightforward, understated, and sometimes stubborn beast.

Adult moose are huge, with females averaging more than 800 pounds and males about 1,100, and some weigh as much as 1,700 pounds. Yet this ponderous, overbuilt beast can run as fast as 35 miles an hour, which would pose some competition to most elite racehorses. See ya, Secretariat. Even belly-deep snow barely slows a full-grown moose. In water, the same moose could swim neck and neck with Michael Phelps at his fastest, about six miles an hour—and after a couple hundred meters, as Phelps fades, keep that pace for another two hours. Their long front legs let them easily clear fences or downed trees. YouTube has a clip of one jumping over the hood of a car as if it’s a puddle.

These and other charms made the returning moose an official mascot in Maine, an unofficial mascot in New Hampshire and Vermont, and a sort of sacred beast throughout New England. Three years ago, in my adopted hometown of Montpelier, Vermont, I emerged from the hardware store early one summer Sunday morning and watched as a moose wandered casually down the empty Main Street sidewalk before me—just me and her at the moment—gazing at store displays and peering into the local dive, Charlie-O’s (“Good Drinks and Bad Company Since the War Between the States”). We parted ways at Main and State. Later I learned that when someone called the police saying that a moose cow was looking confused on State Street, a cop drove over, flipped on the party lights but left the siren silent, and from a respectful distance, slowly escorted her past the golden-domed statehouse to greener spaces beyond.

Moose had been back for about a decade when Alexander and his moose team recognized that they’d soon have to allow hunting to keep the northernmost population in check. In Alexander’s old hunting grounds of Essex County, as in New Hampshire and Maine, the moose, with no predators and abundant browse, were eating so much low-growing greenery that they were reducing the forest’s value to not just landowners but other wildlife, from birds to bears, that counted on low growth for food and cover. Maine started hunting moose in 1980, New Hampshire in 1988, and Vermont in 1993. This provoked passionate objections. Moose had been left to thrive for so long, and could be approached so easily, that many people felt it unsporting to hunt them. A deer would generally bolt at first sight. A moose would stand and stare.

Even with the hunt, though, the moose population grew denser, especially in the north. By the mid-2000s, they were thick enough that Maine, New Hampshire, and Vermont together were having a thousand moose-vehicle collisions a year. Some of these collisions—usually a moose through the windshield, and in some cases a moose and a motorcycle—killed people. The moose had gone from something you had to take pains to find to something you worried about smacking into.

This was the case in Vermont’s northern region in the 2000s, Alexander told me. By then, Vermont had some 5,000 to 6,000 moose, with almost half in the state’s Northeast corner. The department decided to cut the overall population to about 3,000, primarily by increasing hunting permits in Essex and adjacent counties. For most of the decade, they increased the number of permits given each year, with a peak 1,251 distributed in both 2007 and 2008 after hunters bagged a record 648 moose in 2006. It seemed the only way to check the growth.

Even as Vermont ramped up hunting, however, state biologists to the east, in moose-heavy New Hampshire, saw signs that moose numbers there were leveling off. To find out why, a research team led by the wildlife biologist Pete Pekins of the University of New Hampshire put radio collars on 92 moose cows and calves each year from 2002 to 2005 and tracked them to measure survival rates and habitat use. Amid a stack of findings that seemed perfectly normal, two things stood out: In 2002, the study’s first year, fully half of the calves in the study died in the spring from heavy tick infestations, and the preceding winter had been mild and late in coming, leaving the forest floor free of the snow that usually arrived early in fall, when tick nymphs were looking to attach to wandering mammals. Those two factors seemed to explain New Hampshire’s slowdown in moose expansion. As far back as the early 1900s, moose biologists had noted that late-coming warm winters, such as that of 2002, sometimes led to tick irruptions that killed young moose. But such winters were rare. Like droughts, then, these weather-related tick irruptions fit into a pattern of rare stressors that had little long-term impact.

But was it weather related in this case—or climate related?

At the time, in the early 2000s, climate change was being heavily studied as a potential disruptor of New England wildlife, but the focus in current-day wildlife management was still on how to handle the expansion of formerly depleted species, including moose. In a 2002 paper titled “Wildlife Dynamics in the Changing New England Landscape,” for instance, a particularly prominent team of regional ecologists at the Harvard Forest research area concluded that the main challenge for managing the moose and other large mammals in the region was their continued expansion. No one was worried yet about climate dinging moose populations. As Pete Pekins would later note, “Moose managers concluded that the winter tick epizootic in [2002] was an anomaly and that the moose population would make a strong comeback in subsequent years, compensating for the losses.”

It soon became apparent that they had badly underestimated both the possibility of rapid climate change and the explosive effect that change could have on both moose ticks and young moose.



The moose tick, a.k.a. the winter tick—or Dermacentor albipictus, to use its aptly sinister, Potteresque Latin name—feeds on almost every mammal across the reasonably wet parts of North America. But it has an outsize effect on moose. Its life cycle in the northern New England climate is fairly simple. In April, female ticks who have feasted on moose over the winter take their last blood meal and drop off into the leaf litter to deposit several thousand eggs apiece. In May, as the forest starts to leaf out, these eggs release tiny, six-legged larvae called seed ticks. Over the summer, they live on the nutrients from their mothers’ winter feast. Around September, these seed ticks start to form loose groups of up to 1,000, which then climb trees or shrubs up to heights of about four to six feet. There, these groups of poppy-seed-sized ticks, having linked their tiny limbs to form long, almost invisible chains, go out on a branch and, as tick biologists call it, “quest.” They simply wait, and when a big, tall, blood-filled mammal walks by and brushes the branch, one or more of the ticks grasps the animal’s fur and holds tight while the rest of the gang swings as a gossamer-thin thread onto the animal. Then they separate, spread out, follow fur to skin, and dig in.

Two main factors influence how many of these ticks a New England moose will pick up in any given year and area. The biggest factor is the weather from roughly October 1 to January 1, when the seed ticks are questing. A lot of cold and snow during that period, especially early on—normal weather for moose terrain—decimates questing ticks, so that wandering moose are apt to pick up only a few hundred.

The second crucial factor is moose density—that is, how many moose live in a given area and distribute in spring the pregnant tick females whose young will quest in the fall. More wandering moose per square mile increases not just the number of eggs laid, but the number of places they are laid—and thus the number of times that any given wandering moose will encounter questing ticks. When moose are many and winter late, young calves will meet far, far more strands of questers than usual—entire curtains of them—and end up carrying anywhere from 10,000 to 100,000 through the winter.

Tick loads so large are unique to moose, perhaps because moose live almost exclusively in places where warm winters are rare, and have developed no defense against such infestations. Unlike their white-tailed deer cousins and most other furry mammals (including humans) that range more widely, moose don’t groom one another, and they are not habitual or “obligate” groomers; they groom only themselves, and only when heavily infested. By that time, alas, the ticks are on to stay. In a warm fall, then, a dense moose population seems to prime tick populations for an explosion, and calves for a slow, sucking slaughter in the coming winter.

To the dismay of Cedric Alexander, Jake Debow, Pete Pekins, and many others, such winters became far more common just as moose were growing denser than ever through much of their upper New England range. In the mild, late-coming winters of 2008 and 2011, moose biologists in all three northern New England states, now on the alert, saw signs of more ticks and higher calf mortality. By 2013, New Hampshire and Maine had started an updated, five-year version of the earlier winter moose-collaring study, which Vermont joined in 2015. It is for this study that Jake Debow and Josh Blouin are doing field autopsies on dead, collared moose calves.

The study’s results so far are sobering. Before every one of the study’s first three winters (that is, the winters that carried into 2014, 2015, and 2016), the autumn was warm and short on snow; and at the end of every one of those winters, mainly in April, ticks sucked the life out of more than half of all collared calves in all three states. In 2016, when much of the study area had received very little snow before January, 80 percent of the collared calves succumbed.

The ticks didn’t just kill calves. Their depletions made cows smaller and less fertile. In the decade ending in 2005, when ticks started to take their toll, Vermont moose cows averaged about 575 pounds. By 2015, that dropped to 525—a loss of almost 10 percent. Their ovulation rate dropped some 25 percent, to only 0.67 ova per cow in 2015—the lowest rate ever recorded, and the second consecutive year it was below one. The cows also brought fewer pregnancies to term. Cows, in other words, were having fewer calves to start with, and fewer of those calves were surviving their first winter.

Would cold winters make a difference? They did. In the fall of 2016, the first sustained snows began in October, and calf mortality the following winter—2017—dropped to 30 percent.

But the larger pattern remained alarming. While no one systematically counted tick loads from 2008 to 2012, the fall and winter weather in those four years roughly matched the warm, tick-friendly weather seen in the winters of 2014, 2015, and 2016. This means that, as of October 2018, five of the 10 most recent winters had probably produced epizootic events that killed more than half the calves. Moose in the wild generally live a bit longer than a decade. An entire generation of New England moose might have a top-heavy age structure. And it could get worse, both in New England and in moose range elsewhere in North America.

What is to become of these animals?

With the ticks counted, Debow and Blouin pulled the moose onto a flatter spot. “We’ll go tongue to tail,” Debow said, “a full field necropsy.” They would find and observe every organ, note its condition, and take and pack samples to send to the University of New Hampshire veterinary diagnostic lab for microscopic examination. They would try not to slip and fall into the moose.

They laid the moose right side up, because the organs tend to present themselves better that way, and then set about removing the two right legs. Blouin, holding a leg near the hoof, would lever it ever farther away from the torso as Debow used a scalpel-sharp, white-handled, eight-inch fillet knife to carve through the basketball-sized mound of muscle holding the leg to the joint. It took a few minutes to cut through all the muscle, ligaments, and finally the joint itself. Blouin would then lift the released limb, itself almost as long as he was tall, and lay it gently on the ground.

Debow next removed the hide from the animal’s right side. After slicing through the skin along the abdominal midline, he started the knife up at the top of the opening where the front leg had been and shimmied it down along the crease between skin and chest wall, slicing the subcutaneous connective tissue so that he and Blouin, pulling steadily on the animal’s thick, tick-encrusted hide, slowly peeled it away. In less than five minutes, they had exposed the calf’s rib cage and sack of belly. Blouin picked up a heavy pair of Fiskars tree-branch loppers and snapped through the top of each rib near the spine, the loppers making a crunchy cracking sound each time, then again at their junctions with the sternum. Finally they lifted the right half of the rib cage out as one piece and set it on the snow, concave side up. With its smooth, deep-red intercostal muscles and elegant curves, it looked like a huge, glossy serving dish.

The organs of the chest and abdomen now presented like an anatomy diagram. Despite the gore, the smell of digestion, and the animal’s emaciated state, the calf’s innards possessed an acute and unexpected beauty. His depletion—his body’s desperation to extract from itself every joule of energy—had turned the calf’s epithelia, the thin, stretchy linings that surround many organs, and which normally have a milky translucence marbled with pallid blotches of fat, into a gorgeously clear membrane. It was like a shrink-wrapped looking glass. When Debow pulled back the calf’s head and opened the underside of its throat, the animal’s thick windpipe, so cleanly displayed and perfectly formed and isolated, had the quality of a museum piece—with futuristic overtones, in its distinct, hoselike, mathematically regular segmentation, of the bones and strange tubes of the monster in Alien. No atlas or animation ever so beautifully displayed a trachea.

When possible, they dismantled him in systems. The entire trachea and the lungs soon lay in one piece on the snow. Blouin, snipping a sample of lung tissue for the lab, showed me the thin strands of lungworm: less a cause of illness than a sign of the moose’s failing defenses. It went in a sample jar. Debow showed me a fat slice of the kidney, inch-thick like a steak but far smoother, its two lobes a glistening cherry red, brilliant and beautiful in its symmetry. The four chambers of the stomach—the moose is a ruminant—were sliced open and lain flat. The lining of each stomach is smoother and more granular in structure than the one previous. The rumen was like a 1970s shag carpet, color included: a deep pea-soup green from the moose’s chawed, swampy vegetarian fare. The reticulum was more a modernist honeycomb; the omasum, minimalist, with stiff, short spikes like a startled pufferfish. Finally, the abomasum, far fleshier and less green, was folded into long, curved, anchored leaves that splayed, as Debow’s anatomy teacher taught him, “like the pages of a Bible opened on a stand.”

At the end they showed me the brain, first in its cup, with furry ears still behind it, then scooped out and held in Debow’s black-gloved hands. It looked distinctly human. My cortex couldn’t help but wonder what had been in his.

When done, Debow and Blouin realized they had forgotten to bring a garbage bag in which to carry out the hide and some other parts. They decided to leave all that here. The site was a bit of a slaughterhouse: a leg as long as Debow; the huge head, sans cranium, as big as many a human torso. The entrails, the rib-cage serving dish, and the main carcass with its underside and two attached legs still befurred. Most of it would be gone in three days, Debow said, if not before, as soon as the coyotes found it.

In May, when the snow was gone and the dead counted, the Vermont moose team found that of the 29 calves in their study that winter (one having shucked its collar), 15 died of tick infestation. Fifty-two percent. New Hampshire and Maine had similar results. Northern New England’s moose had officially had their fourth tick epizootic event in five years, their sixth in 11.

Over the summer, the Vermont moose team, pondering this mess and reading the literature and talking to colleagues nearby and elsewhere, reached the uncomfortable conclusion that the only way to slow this wintry slaughter was ... to let more people shoot moose in the fall.

They were painfully aware that this would strike many people as nuts. Increase hunting to rescue a failing wildlife population? It appeared to be not just counterintuitive but contrary to the department’s straight decade of shrinking the hunts. From 2008 through 2018, as Vermont’s moose population dropped from almost 5,000 to fewer than 2,000, the department had reduced permits from 1,251 (in 2008) to just 13 for the 2018 season, which itself was down from 80 the year before. (Even for 2018, they had to settle on 13 because they couldn’t get 14 approved.) Seven moose were taken. Walter Medwid, a founding member of the Vermont Wildlife Coalition, told Vermont’s Seven Days in early 2018 that he was baffled that the Fish and Wildlife Department “continues to feel the need to put hunting pressures on a species that is truly imperiled.” The moose population had plummeted straight past the target population in 2015—and they were going to hunt more? How the hell was that supposed to work?

The answer lies in the aforementioned relationship between moose density and tick numbers per moose. The magic density number seems to be about 0.75 to one moose per square mile, according to Pekins; let moose get denser than that, and you exponentially increase the moose’s average tick load and the calves’ mortality rate. Thus, as it were, the more moose, the fewer moose.

Fish and Wildlife can’t do much about snow cover. But through hunting permits, they can do something about moose density when needed. On February 27, the department recommended to its board that no moose-hunting permits be issued this year to allow for uninterrupted research.

They could, of course, just let repeated tick irruptions reduce moose numbers. That would take longer and be less controllable. And it would leave unaddressed the huge hole that tick epizootics are eating in the moose population’s age structure, with ever fewer moose of prime reproduction age—a trend that could make the moose population older, less fertile, and less resilient at a time when it is facing new challenges.

To some people, of course, letting the ticks do the job might seem a more natural solution. It’s not, of course. One of the tragedies of this dilemma—the essence of it—is that whether we shoot the moose or let the ticks suck the young dry, it is we humans, whether through gunshot or climate change, that are killing moose. Jake Debow thinks the hunt would simply be more humane. These tick-ridden calves, he notes, don’t just lie down peacefully one day and die. They suffer for months. He has found sites where coyotes came upon a tick-weakened calf and took it apart. “There’s always blood,” he says, “all over the place.

“And if you’ve seen one of these calves on the verge of death ...” We were back at the truck now. He thought a minute and then pulled out his phone. “Probably shouldn’t do this. But here’s one I came across last spring.” The video shows a pathetically emaciated calf, probably only 20 feet away from Debow as he filmed it with his phone—far closer than a healthy calf would allow—trying to move away among some young trees. Except the calf can barely move. The slope is gentle and the snow only a couple of inches deep. Yet the calf, his legs a-wobble and his head moving uncertainly, looks ready to fall at any second. Repeatedly he tries to lift a foreleg and stride forward, but cannot. He seems to sense that if he falls, he will not rise. After several seconds, he finally succeeds. One step. Debow followed him until dark, he said, before he had to head home. The next morning he found the calf dead, just a few yards from where he had last seen him.

Life Up Close is a project of The Atlantic, supported by the HHMI Department of Science Education.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?



On their last morning on the moon, the astronauts woke up to horns, trumpets, and thumping drums. They recognized the sound immediately—it was the theme from 2001: A Space Odyssey.

“That was a great song,” Gene Cernan told Mission Control. “I think it’s very apropos at the moment.”

It was 1972, and Cernan was on humankind’s sixth odyssey to the surface. After three days of work on the rocky terrain, backed by surreal views, he and the other astronauts came home. No one has been back since.

Not for long, according to the Trump administration. President Donald Trump wants NASA to return astronauts to the surface of the moon in 2024. To get there, the president announced Monday that his administration will ask for another $1.6 billion in NASA’s budget for the coming fiscal year.

“Under my administration, we are restoring NASA to greatness,” Trump said in a tweet on Monday night.

The tweet, resolute and sprinkled with capital letters, exuded confidence and determination. The administration would like this projected mission to be treated, in advance, as a historic event: The mission has been named Artemis—the sister of Apollo—because, officials say, it will put the first woman on the moon. In Trump’s telling, the moon mission sounds inevitable, and success guaranteed.

They’re not.

By space-exploration measures, 2024 is right around the corner. To make that goal, NASA would need to launch astronauts inside a crew capsule (that is still being tested) on a giant rocket (that has never flown before) to a floating station around the moon (that doesn’t yet exist) and drop them to the surface in lunar-specific spacesuits (that don’t exist either). In Greek mythology, Artemis and Apollo are twins, but while the Apollo-era missions were fed with a massive budget, this new Artemis mission is off to a smaller start.

The Trump administration’s budget request, with that $1.6 billion tacked on, will go to Congress, which decides how much to give the agency. The money, officials say, will go toward boosting the work NASA is already doing, such as developing the crew capsule and rocket designed to carry astronauts toward the moon. But is it enough?

Jim Bridenstine, the NASA administrator, calls it a “down payment.” “In the coming years, we will need additional funds,” Bridenstine told reporters. “But this is a good amount that gets us out of the gate in a very strong fashion.”

He didn’t say how much the agency would need in the next fiscal year, or the one after that, but he did acknowledge that the $1.6 billion request is at “the low end” of what the agency needs to hit its 2024 target.

Despite these financial realities, the Trump administration insists that the mission is feasible. We’ve already been to the moon, the message goes, we can do it again. Supporters point out that just eight years elapsed between John F. Kennedy’s declaration to go to the moon and Neil Armstrong’s first steps on the surface—and that was without the technology NASA has now.

To which critics respond, We’ve already gone to the moon. Why do it again?

According to Vice President Mike Pence, the same reason as last time—national pride and duty. “The rules and values of space, like every great frontier, will be written by those who have the courage to get there first and the commitment to stay,” the vice president said when announcing the mission this spring.

President Trump has also shown interest in speeding up certain space efforts in an apparent attempt to bolster his legacy. Not long after his inauguration, he asked the acting NASA administrator whether the agency could land Americans on the surface of Mars before the end of his first term—“if we sent NASA’s budget through the roof,” as he put it, “but focused entirely on that instead of whatever else you’re doing now.” Just a few months ago, the administration was eyeing a 2028 moon landing, before moving the deadline way up.

This new budget request falls short of the “through the roof” threshold: Space-policy experts say the new proposal is modest. “It’s hard to imagine that much money wouldn’t give them the kick start they need,” says Jared Zambrano-Stout, an aerospace consultant and a former chief of staff for the White House National Space Council, which sets the agenda for NASA.

Casey Dreier, an adviser at the Planetary Society, a nonprofit space-advocacy group, predicts that the agency would need $4 billion to $5 billion a year for the next five years, rather than an annual $1 billion infusion. “If they’re proposing a total of $8 billion in five years … this ain’t gonna get us to the lunar surface in 2024,” he says.

Laura Forczyk, a space analyst and the founder of Astralytical, a consulting firm, thinks the proposal was a savvy move. Congress was probably expecting an exorbitant number because, well, it’s coming from Trump. The president has asked for billions to fund his border wall, for example. “Projecting too much money over too long of a project timeline is what doomed Constellation,” Forczyk says, referring to a Bush-era space program the Obama administration deemed too expensive and canceled in 2010. “Taking it year by year with incremental increases is a safer bet.”

In any case, the bottom line is that NASA will need more money than it has had in decades. The latest budget, $21.5 billion, is the agency’s largest in years. But it accounts for less than half a percent of the federal budget. At the peak of the Apollo program, NASA’s budget counted for more than 4 percent of federal spending.

The Trump administration’s moon dreams face a skeptical public. A Pew Research Center poll last year found that while most Americans believed it’s important for the United States to be a world leader in space exploration, only 13 percent said sending humans to the moon should be a top priority. About 63 percent said NASA’s primary focus should be climate research. (Americans weren’t so jazzed about going to the moon in the 1960s either; polls from the time showed that a majority of the population didn’t think the Apollo program was worth the cost.)

Trump’s new effort also faces a skeptical Congress, unconvinced of the nationalist argument for more moon travel. And Democrats, mindful of the 2024 goal, gave Bridenstine an earful at a recent hearing about the moon mission.

So far, it’s not clear where the extra $1.6 billion will come from. Bridenstine said no NASA programs will be cut. The Associated Press reports that the money could be diverted from spending on Pell Grants, federal subsidies that help students pay for college education—a move unlikely to be popular with Democrats.

Space-exploration efforts have always taken longer than officials have expected, usually because of a combination of technical challenges and financial restraints. Presidents who shepherd in new dreams are usually no longer in office when they become reality. Sometimes entire programs get thrown out altogether under a new administration, and NASA is forced to start again on something new. George W. Bush instructed NASA to return Americans to the moon by 2020. Barack Obama canceled that plan, and told NASA to think about Mars instead. Now this administration wants to hit the moon again before going to Mars.

I asked Bridenstine how he would reassure the NASA engineers and scientists he’s asking to carry out this mission, knowing that a new administration could turn it upside down.

“NASA has a history of seeing these starts and stops,” he said. “And it is important for us to understand how important it is to get strong bipartisan support from the beginning.”

Artemis, the moon goddess, was a fierce warrior, one of the most inspiring in the pantheon. Her persona eschews the majority of mythology, which is rife with stories of women being chased, imprisoned, and punished by powerful men. This name pick, while refreshing—exciting, even—also applies some pressure. To put any name on the program makes it more real, more high stakes, and this one now has a powerful name to live up to. In a perfect scenario, with buckets of money and unwavering political will, NASA could make it back to the moon. In a realistic one, the only boot prints on the moon at the end of the Trump presidency might belong to space travelers from 1972.



Updated at 3:15 p.m. ET on February 9, 2019.

Between a sidewalk and a cinder-block wall grew seven mushrooms, each half the size of a doorknob. Their silver-green caps were barely coming up, only a few proud of the ground. Most lay slightly underground, bulging up like land mines. Magnolia bushes provided cover. An abandoned syringe lay on the ground nearby, along with a light assortment of suburban litter.

To hear more feature stories, see our full list or get the Audm iPhone app. 

Paul Kroeger, a wizard of a man with a long, copious, well-combed beard, knelt and dug under one of the sickly colored caps. With a short, curved knife, he pried up the mushroom and pulled it out whole. It was a mushroom known as the death cap, Amanita phalloides. If ingested, severe illness can start as soon as six hours later, but tends to take longer, 36 hours or more. Severe liver damage is usually apparent after 72 hours. Fatality can occur after a week or longer. “Long and slow is a frightening aspect of this type of poisoning,” Kroeger said.

He and I were in a quiet neighborhood of East Vancouver, British Columbia. Across the street, behind St. Patrick Elementary School, kids were playing basketball, and their voices echoed between the occasional passing cars. Kroeger likes kids. As we’d hunted mushrooms from the sidewalk earlier that day, he had cooed at every stroller, then stopped the parents to warn them about the death caps in the neighborhood.

As he shook the mushroom free of its soil and added it to the others he’d lined up on a sheet of wax paper, he surveyed the collection and said, “Enough here to kill an entire Catholic school.”

The death caps were slightly domed, with white gills and faintly greenish stems. At the bottom of each stem was a silky slipper, called the volva, which was a purer white than the rest of the mushroom. The Amanita phalloides species accounts for more than 90 percent of mushroom-related poisonings and fatalities worldwide.

Kroeger, who studied the biochemistry of medicinal mushrooms while working as a lab assistant and technician at the University of British Columbia, is a founding member and the former president of the Vancouver Mycological Society, and the go-to authority on mushroom poisonings in western Canada. When Amanita phalloides first appeared in British Columbia in 1997, he took careful note. It had never before been seen in Canada. The single reported specimen was found among imported European sweet chestnut trees near the town of Mission, an hour east of Vancouver.

The species appeared again a year later, under a large, ornamental European beech tree on the grounds of a government building in the provincial capital, Victoria, on southern Vancouver Island. Ten years later, death caps began to appear in Vancouver, in a neighborhood shaded with mature European hornbeam trees. Kroeger recruited volunteers to search neighborhoods, and put out the word to mushroom hunters. During the first year, they documented about 50 locations in Vancouver. Kroeger wanted to know where the mushrooms were coming from, and where they’d turn up next. Sooner or later, he feared, they would have deadly consequences.

The first serious poisoning in British Columbia was reported in 2003, and another occurred in 2008. Both victims survived. Then, in 2016, a 3-year-old boy from Victoria died after eating mushrooms found outside an apartment complex. Kroeger thought he had anticipated the worst, but he was not prepared, he said, “for a wee child to die.”

Without fail, Kroeger noted, death caps appeared in urban neighborhoods, not in deep woods or city parks. They showed up most often in the strip of grass between sidewalks and streets.

For the past few years, Kroeger and his network of fungiphiles have been putting up posters in infected neighborhoods. The BC Centre for Disease Control sends out his warnings in press releases, and he sets up a booth at street events in order to warn anyone willing to listen that death caps should be left alone. When I joined him in East Vancouver, most of the people he stopped on the sidewalk—parents with strollers and passersby with groceries—had already heard of the invader. A man in a tool belt coming off a house remodel said he’d seen death caps a few blocks away in East Vancouver, and Kroeger scribbled down the address. I asked the man why he was so interested in mushrooms; he said he just liked to know what was growing in the neighborhood.

The first death cap Kroeger found that day had been in front of a house decorated for Halloween, which was two weeks away. He dug into the leafy ground cover, revealing several more greenish domes. Like a leaping gnome, he jumped across the sidewalk, grabbed a plastic human skull off a post, and brought it back to his find. Nestling the skull into a nest of purple periwinkle beside the emergent death caps, he laughed to himself and took a picture. Sometimes, he almost seems to side with the death caps. He appreciates their mysterious tenacity. He greets each one with an excited smile, talking to it: “There you are.”

By the end of the day, Kroeger had collected a couple of dozen death caps, each placed in wrinkled wax paper and then into one of the plastic boxes he carried in a faded, bucket-style day pack. They’d be dried and stored at the university. Most were from new locations. Before rolling a thin cigarette for himself, he fished out a damp cloth to clean his hands. He explained that he couldn’t use a moist towelette with alcohol because it could facilitate the passage of toxins through the skin. While he thought the mushrooms could usually be handled safely, a whole day of repeated touching was risky, since it was always possible to forget and touch one’s face, nose, or lips. “Just to be safe,” he said, wiping his hands and offering the cloth to me.

Dr. Kathy Vo, a medical toxicologist in San Francisco, publishes case studies on rare or unusual poisonings. Amanita phalloides poisonings, she told me, are some of the worst. “When the liver starts to fail, you see bleeding disorders, brain swelling, multi-organ failure. It’s very, very rough,” she said.

The levels of fluid loss, Vo said, are some of the most dramatic she’s seen. The body flushes everything it has. “There’s not an antidote,” she said. “That’s what makes this particularly deadly. We institute a variety of therapies, but there’s not an A, B, C, D. It’s not always the same. The best bet for the patient is fluid, fluid, fluid; keep watching the liver, and if the liver is failing, go for a transplant.”

On average, one person a year has died in North America from ingesting death caps, though that number is rising as the mushroom spreads. More than 30 death-cap poisonings were reported in 2012, including three fatalities, while 2013 saw five cases and no deaths. In 2014, two people died of death-cap poisoning in California; a third died that year in Vancouver after a Canadian man traveled to California, ate the mushrooms as part of a meal, and returned to Vancouver, where he became ill and died.*

Amanita phalloides are said to be quite tasty, and a person who eats one could feel fine for a day or two before illness sets in. The poison is taken up by the liver cells, where it inhibits an enzyme responsible for protein synthesis; without protein, the cells begin to die, and the patient may start to experience nausea and diarrhea—symptoms that can easily be attributed to general food poisoning or other ailments. “If the patient doesn’t realize the connection, doesn’t see the illness as a result of eating a mushroom a day or two earlier, it’s a hard diagnosis,” said Vo.

The first death caps to appear on the West Coast hit Northern California in 1938. Since then, Amanita phalloides has been a constant menace to people in the Bay Area. Vo said that an outbreak of poisonings typically follows a rainy season; in November of 2016, after a long spell of warm weather and copious rain, the Bay Area Mycological Society got in touch with the California Poison Control System hotline, warning that death caps were sprouting up. “Five days after that, we started getting calls,” she said.

As part of a cluster of 14 poisonings in the fall of 2016, a Bay Area family grilled wild mushrooms gathered by a friend, not knowing they were death caps. They were eaten by the young mother and father, their 18-month-old daughter, and two other adults. The parents and a third adult underwent aggressive fluid treatments and were released from the hospital after a couple of days, while the fourth adult and the child required liver transplants. In the process, the little girl, who reportedly ate half a mushroom cap, suffered what Vo described as permanent neurological impairment, and is no longer able to feed herself or follow commands.

“Every year we get lots of calls about mushroom ingestion,” Vo said. “A kid finds one in the backyard and eats it. We ask them to send a picture and usually it’s not a big problem. We call them ‘little brown mushrooms.’ They cause irritation, sometimes nausea and vomiting. But Amanita phalloides is a different case. Flip the mushroom over and tell me if the gills are white. If they are, I’m really concerned.”

The death cap is a global traveler, but only in the past century has it caught its stride. Long after feral cats spread across Australia, long after pigs and mongooses were running loose in Hawaii, Amanita phalloides was still home in Europe, where it grew mostly in deciduous forests and was the leading cause of mushroom poisonings from the Balkans to Russia to Ireland.**

While historical records are inconclusive, the first suspected death caps in North America were reported on the East Coast in the early 1900s. The first in California were spotted on the grounds of the Hotel Del Monte in Monterey in 1938, growing from the roots of a planted, ornamental tree. After that, the species landed hard in the Bay Area, where it is now common, having spread into wild oaks; it is becoming more abundant in California than in its native European habitat. After the Bay Area, it was reported in a string of Pacific Northwest cities, each one farther up the coast.

The species wasn’t just spreading from tree to tree, gradually expanding its range. Instead, it landed like an isolated bomb, colonizing outward from each impact. While this pattern suggests that the mushrooms in British Columbia may have started in California, Kroeger began to suspect that they represented a separate invasion.

When Kroeger put together maps of the first death-cap outbreaks in Vancouver, he had no problem seeing the pattern. They were showing up in neighborhoods built in the 1960s and ’70s, growing under broadleaf trees that had started off in nurseries.

Most mushrooms propagate in the form of spores that fly into the air and land like seeds. Death-cap spores are especially fragile; they degrade in sunlight, and don’t travel far or well. By any measure, the species should have remained a rare European endemic, but somehow, it successfully hitched a ride all the way to North America—not once but many times.

Most of any mushroom is underground, invisible. The majority of its biomass consists of mycelia, a network of living threads that send up occasional fruiting bodies in the form of mushrooms. Death-cap mycelia live only in tree roots. They form a symbiotic bond with certain trees, growing into a web that dramatically extends the reach of their roots.

As the web penetrates the root structure, becoming an inseparable part of the tree, the fungus begins to live off the sugars stored in the roots—while offering the tree greater access to water, nutrients, and chemical messages from surrounding trees. The relationship is called ectomycorrhizal: ecto (outside), myco (mushroom), rhyzal (root). If a sapling with ectomycorrhizal fungi were to be dug up and moved, the fungi would travel with it. In this case, Kroeger surmised, the fungi had been inadvertently carried across the Atlantic to southern British Columbia.

Kroeger can stand on a hill in Vancouver, or look from a freeway, and pick out the neighborhoods where he is most likely to find death caps. He looks for a combination of mature broadleaf trees and European ornamentals, especially hornbeams, mixed with what he calls mid-century modern domestic architecture, where the longest wall of the house is built parallel to the street rather than tucked back into a landscaped lot. This dates a neighborhood, and its trees, to the 1960s and early ’70s.

According to Kroeger, although there is some dispute among experts in the field, death caps appear in these neighborhoods decades after planting, because the mushroom lies dormant for that long.**** Its mycelia live in the roots of a host tree until the tree reaches maturity—when it stops pouring energy into growth and starts storing sugars. For these European imports, that’s about half a century. When surplus sugars enter the fungal web, the first fruiting bodies emerge.

Shadowing Kroeger along streets pillared with old broadleaf trees is like pursuing a fox, not a creature of sidewalks. The matrix he follows is underground. Cutting between parked cars, smoking one of his thin cigarettes as he traveled, he seemed to know every grassy back way, every portage around apartment complexes and medical facilities.

Wearing sneakers and a red flannel jacket, he glided swiftly and paused often. Most of what he found were red and white Amanita muscaria, a showy native species. Like A. phalloides, this Amanita attaches to tree roots, and rings of its fruiting bodies rise like fairy kingdoms around the trunks. Poisonous and hallucinogenic, they had been brought out by the rains, and they were all over the city, some as big as dinner plates, some like cherry-colored doorknobs dotted with white flakes. Kroeger crawled on the ground with his camera, capturing tableaus, tapping on their tops, feeling their firmness in the ground. Passersby stopped to comment, amazed at how beautiful and numerous they were.

The death caps were lurkers. They had to be searched for. Rooting around in a strip of vines and flowers in front of a house where he’d found new specimens, Kroeger looked up as a woman cracked open the front door.

“What are you doing in my garden?”

Kroeger stammered that he was a professional mycologist. He clearly enjoyed talking to mushrooms more than to people. He stood upright and lifted a death cap in his hand like a freshly removed appendix. Did she know that deadly mushrooms were growing in her garden? When she didn’t answer, Kroeger said in his gentle, earthy voice, “I’m just here to collect these.”

“Okay,” she said. “But stay out of my garden.”

He waited a moment after the door slammed, making sure she was gone, then reached into the base of a shrub, using his curved knife to pry up another silver-green mushroom.

As we packed up and moved on, he said, “The development style of the city set the stage for their introduction and proliferation. They will never go away, not, at least, through any known human decision.”

Once an ectomycorrhizal fungus is in the ground, even killing the host tree won’t stop it. A proposal was put before the city to chop down every hornbeam, the major source of death caps. “But then you have to cut the lindens, sweet chestnuts, red oaks, English oaks. That’s a lot of the city, and you still won’t get rid of [the death caps],” Kroeger said.

Across from the Catholic school where Kroeger had collected death caps a few hours earlier, a mature hornbeam tree towered over the neighborhood, its deciduous canopy shading both sides of the street. The house of the woman who had scolded him stood 30 feet from another stately hornbeam. Kroeger has maps of land use over the century, detailing development block by block. To him, they are maps of present and future death-cap distribution. Decade by decade, like an underground echo, more and more appear. Kroeger wonders how long it takes people to learn how to avoid a common and deadly mushroom. It is not common yet, but he knows that it likely will be, and that the first fatality in British Columbia from a local death cap, in 2016, will not be the last.

Britt Bunyard, the founder, publisher, and editor in chief of the mycology journal Fungi, has tasted a death cap. “Very pleasant and mushroomy,” he told me. “A nice flavor, and then you spit it out.”

For the amatoxin poison to begin to work, it needs to enter the intestinal tract. A quick bite without swallowing has little effect.

“Poisonous snakes, reptiles, plants, [and] fish have aposematic coloration that shows off that they are poisonous. Mushrooms don’t,” Bunyard said. “The dangerous ones are all mostly drab or brown, green-brown, bronze. There’s nothing in the taste that tells you what you are eating is about to kill you.”

A large portion of people who are poisoned by death caps in North America are Hmong or Laotian immigrants. They mistake the species for a prized edible from home, what is called the “white Caesar,” Amanita princeps.

Death caps are not only a North American problem. They have spread worldwide where foreign trees have been introduced into landscaping and forestry practices: North and South America, New Zealand, Australia, South and East Africa, and Madagascar. In Canberra, Australia, in 2012, an experienced Chinese-born chef and his assistant prepared a New Year’s Eve dinner that included, unbeknownst to them, locally gathered death caps. Both died within two days, waiting for liver transplants; a guest at the dinner also fell ill, but survived after a successful transplant.

“Because the mushrooms don’t taste bad, they’re probably not meant to be poisonous to ward off being eaten or foraged,” Bunyard said. “Mammals, not even all mammals, are the only ones affected. Some squirrels and rabbits can eat them without being harmed. Why it’s so toxic to humans—who knows? Some poisons are used as communication molecules, and just happen to be poison to us.”

To Bunyard, the death cap’s journey is only a symptom of a larger phenomenon—the global mobilization of the entire Fungi kingdom. With their blowing spores and underground mycelia, mushrooms can travel in as many ways as humans can carry them. Bunyard, who has a Ph.D. in plant pathology, is concerned about how mushrooms might displace and change their new ecosystems. “The way bacteria are the primary pathogen for animals, fungi are the primary pathogens for plants,” he said. “What’s going on is under the soil, what we don’t see. Some of the native mycorrhizal fungi are being displaced, which will in turn displace plants.”

How a newly introduced mushroom and its underground cobweb impacts the life around it is poorly understood. Much about the life cycles and taxonomy of fungi remains elusive. Fungi were not given their own kingdom—now known as the “fifth kingdom”—until 1968. Before that, mushrooms were categorized as plants. Genetically and evolutionarily, they are closer to animal than plant. Mycology is a relatively new science, and researchers are only now beginning to understand how instrumental fungi are in almost every ecosystem, not only in breaking down and recycling organic matter, but also in concentrating nutrients for plant life and acting as chemical communicators.

Kroeger has reported that death caps are now moving from their imported European host trees to an oak species native to British Columbia. The first identified species jump was in 2015. This was seen in California decades ago, when they began moving into coast live oak trees.*** Tree roots mingle underground and mycelia reach across, taking up new residence. Death caps have begun to naturalize, spreading without external aid.

“They could get rid of a lot of humans and dogs,” Kroeger said. The occasional fatality is a risk Kroeger tries to mitigate, but, like Bunyard, he worries more about what he calls the “unexpected consequences” of a biological invasion following paths of modern civilization. What does it mean to move a tree-root mushroom to a distant continent? The steamship gave living plants and mushrooms their first chance to enter global commerce. Now, container ships and airplanes can get them anywhere. “I think anything humans do has a chance of going wrong,” Kroeger said. “The monkeys have a bad history.”

The next day, on a Chinatown-bound city bus, Kroeger moved toward the back like a gentle ghost. His ponytail lay down his back, neatly combed. He sat with his pack on his lap, plastic bins empty for another day of hunting and gathering. As the bus traveled down Main Street near East Vancouver, he rubbed his hands together with some excitement, saying, “We are about to pass the 13th Street location; we must genuflect.”

He was referring to the crop of death caps he’d found the day before, across from the Catholic school. Every year he finds more, new appearances along sidewalk edgings and corner gardens. Soon, he fears, they will move from the city into the surrounding woods. Southern British Columbia could be the next Bay Area in terms of death-cap abundance, with fatalities or life-affecting illnesses after every good rain.

As the bus stopped and started toward the edge of downtown Vancouver, Kroeger ticked off the ways mushrooms get around the world: volcanic pumice rafts, ship ballast, animal stomachs, packing crates, live plants, peat. Human activities that introduce mushrooms to new habitats tend to bring in other non-native species too. “Most of the time you’d never know it’s happening,” he said. “It’s only because this mushroom kills people that we’re paying attention.”

In 1987, Kroeger identified a mushroom previously unknown to science. He found it growing in clumps at the University of British Columbia Botanical Gardens—in mulch beds, on the wet, marshy edges of ponds, and along trails. “Pretty little thing,” he said, as if describing something precious. “Gray gills and an amber-colored cap.” As he does when he talks about any mushroom, he sounded like he was in love.

Kroeger and a colleague named this new species Hypholoma tuberosum, and it was not long before other sightings were reported in New York, Japan, Germany, Belgium, and Australia. The species wasn’t native to British Columbia, but it wasn’t a new arrival, either; it had simply not been noticed by anyone willing to go to the trouble to name it. Since it seemed to favor landscaped grounds, mycologists began looking for its source, thinking that like the death cap, it must have been incidentally carried by humans. The source appeared to be a single nursery in metropolitan Sydney, Australia, where peat carrying H. tuberosum was being used for potting plants, which were then shipped worldwide. That peat had been collected from a bog 130 kilometers away—the likely native source of a mushroom that could have easily remained an obscure local, but has become a global cosmopolitan.

As the bus slowed in downtown Vancouver, Kroeger lifted his pack, saying, “Our stop.”

We got out on Hastings Street and moved along a wide, crowded sidewalk, bedsheets and flattened cardboard stretched out in what looked like a blocks-long flea market. Half the vendors were curled up or sprawled semiconscious next to their wares; it was early in the day in a rough part of town. Kroeger said he’s been hesitant to put up signs in neighborhoods around here: “People with psychiatric issues, suicidal, possibly even with malicious intent. I don’t want them intentionally going after death caps.”

Several blocks away, in a shaded neighborhood, he stopped in front of a house on the corner of East Georgia Street and Princess Avenue. Moving back a fern frond with his hand, he said, “Speak of the devil.”

In the shade of the underbrush was a metallic-colored mushroom, pale green verging on gold. There are 96 hornbeam trees on this chain of blocks, Kroeger said, and he had already found death caps under eight of them. Now the count was up to nine.

Kroeger stopped not just for death caps but for every troop of mushrooms. Anything bright or emergent caught his attention. “Nicely poisonous,” he said about a button-topped Agaricus growing on a corner lawn. “Not near as poisonous as phalloides,” he added.

Later in the day, his plastic containers were full, and he’d gone through five or six thin cigarettes. He found one last death cap, a mature one growing in the grass near the base of a rock wall. He looked around, noting the nearest intersection, committing the location to memory. Then he moved on, leaving the mushroom behind. It had been a long day, and Kroeger is not on a crusade to remove every death cap. He wants to know what they are up to, and he wants to take out enough to matter. He loves kids and dogs, after all.

The death cap he passed up, grown from the roots of a nearby hornbeam, stood clear of the grass on its slender white stalk. Digging it up would not slow what is happening underground; it would not change the worldwide flow of soils and roots, and the fibrous bodies living within them. Digging it up would be almost a symbolic act, less than a drop in the bucket. So Kroeger left the mushroom in place—a nod to the fifth kingdom, the unstoppable.

* This article previously misstated the number of death-cap mushroom fatalities in 2014. 

** This article previously misstated the origin of a species native to Australia.

*** This article previously misstated the name of the death-cap mushroom's California host tree.

**** This article has been updated to clarify the range of views held by mycologists. 

Life Up Close is a project of The Atlantic, supported by the HHMI Department of Science Education.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?



It’s official: When Democrats take control of the House of Representatives next month, they will form a special new committee to examine climate change, Nancy Pelosi said in a statement on Friday.

Pelosi, likely the next speaker of the House, also announced that the new committee will be named the Select Committee on the Climate Crisis. It will be led by Kathy Castor, a seven-term representative from Tampa Bay.

“The American people have demanded action to combat the climate crisis, which threatens our public health, our economy, our national security and the whole of God’s creation,” Pelosi said in the statement. “Congresswoman Castor is a proven champion for public health and green infrastructure, who deeply understands the scope and seriousness of this threat.”

Castor, a longtime member of the Energy and Commerce Committee, has already promised to decline all campaign contributions from coal, oil, or gas companies. Pelosi has not yet described exactly what the committee will do, but House committees of this type can hold hearings, write reports, and bring public attention to political issues.

With its formation, Pelosi makes good on her 2018 campaign promise to revive a special climate-focused committee. (After Republicans took control of the House in 2010, they shuttered the last special climate committee, which Pelosi established in 2007.) But the new committee arrives to a delicate family situation in the Democratic Party. A number of activists on the party’s left have greeted the announcement with frustration. They had hoped (and protested) for a more ambitious Green New Deal committee. Such a panel, they imagined, might finally draft a unified Democratic climate policy, a plan to improve the lot of American workers while massively overhauling the economy to prepare for climate change.

“It’s a big disappointment,” says Stephen O’Hanlon, a spokesman for the Sunrise Movement, a Millennial-led organization that championed the Green New Deal plan. “The select committee on a Green New Deal was put together based on a hard look at what the science demands, and we were hopeful that Nancy Pelosi—who says she wants to take serious action on climate change—would be willing to come to the table for it.”

“We’ll have to see what the actual mandate of the committee is,” he adds.

The Climate Crisis Committee seems likely to get a much narrower mandate than activists envisioned for a Green New Deal committee. It will probably not be allowed to issue subpoenas, as a permanent standing House committee can, nor will it be able to draft legislation. Overall, it will be less powerful than the last House select climate committee, which had subpoena power but not legislative authority.

Castor had been rumored to be Pelosi’s pick to lead the committee since last week. She gets high marks from the League of Conservation Voters, indicating a solid environmental record.

But in the past week, she has sometimes seemed ignorant of major disputes among climate activists. For instance, the Sunrise Movement initially sought to ban Green New Deal committee members from receiving donations of any kind from the fossil-fuel industry. When Castor heard that demand, she balked, claiming that the First Amendment made it impossible. Though she later walked back that comment, calling it “inartful”—and promised to forswear fossil-fuel donations herself—the episode suggested that she is unfamiliar with a constituency she will now have to entertain.

The demand should not have come as a shock: Fossil-fuel money has been a touchy subject for Democrats for years. As recently as August, climate activists warred with party moderates over whether it was appropriate to ban fossil-fuel donations for all Democrats, not just those on a climate-focused panel.

It’s not yet clear whether Castor will impose such a ban on all members of the Climate Crisis Committee. Her office did not respond to a request for comment.

The most interesting aspect of today’s news may be the new committee’s name. Al Gore used the phrase climate crisis often, and even Hillary Clinton sometimes deployed it during the 2016 election. It feels tedious to unfurl its message—Democrats believe climate change is an emergency, obviously—but perhaps the name is a reminder of how much energy politics have changed in the last decade. In 2007, when Democrats last established a select committee on climate change, they chose a name much more fitting for an era of high oil prices: The House Select Committee on Energy Independence and Global Warming. Now, the United States is just a few years off from exporting more energy than it imports. Thanks to fracking and renewable energy, we’ve solved the problem of American “energy independence.” Global warming, meanwhile, continues to get worse.



Dogs, more so than almost any other domesticated species, are desperate for human eye contact. When raised around people, they begin fighting for our attention when they’re as young as four weeks old. It’s hard for most people to resist a petulant flash of puppy-dog eyes—and according to a new study, that pull on the heartstrings might be exactly why dogs can give us those looks at all.

A paper published today in the Proceedings of the National Academy of Sciences found that dogs’ faces are structured for complex expression in a way that wolves’ aren’t, thanks to a special pair of muscles framing their eyes. These muscles are responsible for that “adopt me” look that dogs can pull by raising their inner eyebrows. It’s the first biological evidence scientists have found that domesticated dogs might have evolved a specialized ability used expressly to communicate better with humans.

For the study, a team at the University of Portsmouth’s Dog Cognition Centre looked at two muscles that work together to widen and open a dog’s eyes, causing them to appear bigger, droopier, and objectively cuter. The retractor anguli oculi lateralis muscle and the levator anguli oculi medialis muscle (mercifully known as RAOL and LAOM) form two short, straight lines, which connect the ring of muscle around a dog’s eye to either end of the brow above.

These researchers have long been interested in the ways dogs make eye contact with humans and, in particular, how they move their eyebrows. In 2017, Juliane Kaminski, the lead author of the new paper, found that dogs moved their eyebrows more often while a human paid attention to them, and less often when they were ignored or given food (which, sorry to say, is a more exciting stimulus for them than human love). That suggested the movement is to some degree voluntary. On our side of these longing glances, research has also shown that when dogs work these muscles, humans respond more positively. And both man and mutt benefit from a jolt of oxytocin when locked in on each other.

This isn’t simply a fortuitous love story, in which the eyes of two species just so happen to meet across a crowded planet. Like all the best partnerships, this one is more likely the result of years of evolution and growth. If dogs developed their skill for eyebrow manipulation because of their connection to humans, one way to tell would be to look for the same capacity in wolves. Because dogs split off from their wolf relatives—specifically, gray wolves—as many as 33,000 years ago, studying the two animals is a bit like cracking open a four-legged time capsule. Divergence between the two species marked the start of dogs’ domestication, a long evolutionary process influenced—and often directly driven—by humans. Today, researchers can identify and study differences between the species to gain an understanding of exactly how dogs have changed over time.

In this case, those eyebrow-raising muscles do appear to be an addition to dogs’ anatomy. In the four gray wolves the researchers looked at, neither muscle was present. (They did find bundles of fibers that could be the precursors to the RAOL and LAOM.) In five of the six breeds of dogs the researchers looked at, both muscles were fully formed and strong; in the Siberian husky, the wolflike, oldest breed of the group, the researchers were unable to locate a RAOL.

Sometimes, the origins of changes like these aren’t immediately apparent. Certain physical dog traits—including floppy ears and short snouts—likely originate from the same set of developmental cells that code for tameness, a preferable trait in household pets, for instance. In the case of this new research, though, the connection between the physical trait and the related behavior is a bit more direct. “Previous work—and much of it by these same authors—had shown that these muscles were responsible for enhancing positive responses in humans,” Brian Hare, the director of Duke University’s Canine Cognition Center and the editor of the paper, told The Atlantic via email, “but the current suggests the origin of these facial expressions is after dogs split from wolves.”

By evolutionary standards, the time since this split has been remarkably short for two new facial muscles to have developed. For a species to change that quickly, a pretty powerful force must be acting on it. And that’s where humans come in. We connect profoundly with animals capable of exaggerating the size and width of their eyes, which makes them look like our own human babies and “hijacks” our nurturing instincts. Research has already demonstrated that humans prefer pets with more infantlike facial features, and two years ago, the authors of this latest study showed that dogs who made the facial movement enabled by the RAOL and LAOM muscles—an expression we read as distinctly humanlike—were more likely to be selected for adoption from a shelter than those who didn’t. We might not have bred dogs for this trait knowingly, but they gained so much from having it that it became a widespread facial feature. “These muscles evolved during domestication, but almost certainly due to an advantage they gave dogs during interactions with humans that we humans have been all but unaware of,” Hare explained.

“It’s such a classically human system that we have, the ways we interact with our own infants,” says Angie Johnston, an assistant professor at Boston College who studies canine cognition and was not involved with the study. “A big theme that’s come out again and again in canine cognition and looking at the domestication of dogs is that it seems like they really just kind of dove right into our society in the role of being an infant or a small child in a lot of ways. They’re co-opting existing systems we have.”

The same humanlike facial gestures could also be a dog’s way of simply securing attention in the first place. Eyebrow raising is one of the most well-understood examples of what researchers call ostensive cues, a family of nonverbal signals (often facial movements and expressions) humans send one another to convey their intention to directly communicate. Dogs’ uncanny ability to mimic this human expression likely leads us to project certain human emotions onto them in ways we don’t with other animals, regardless of what they might actually be feeling.

The movement of the RAOL and LAOM muscles is particularly open to interpretation. “In different contexts we’ll call that something different,” says Alexandra Horowitz, a senior research fellow at the Barnard College Dog Cognition Lab. “In one case, I might say it’s sad, but in another case I’ll say, He’s really paying attention. It can look wry, like a questioning or unbelieving look.” According to Horowitz, dogs are the only animals aside from our primate cousins that are expressive in this eerily familiar way. Horses alone share the ability to twist their eyes into the same doleful shape, but their overall expressions don’t strike us as humanlike in the same way that dogs’ do. With dogs, Horowitz points out, we’re so driven to connect that we often search for “smiles” in the shapes of dogs’ mouths. The new research, she says, “makes me think it’s more about being able to move the face in a way that humans move the face. We don’t like unexpressive faces.”

Both Horowitz and Johnston suggested that similar studies looking at populations of dingoes (which Johnston researches) and Siberian foxes could provide yet another time capsule of sorts for understanding eyebrow movements and other evolutionary traits. Both species live near humans and are some of the closest living relatives to the earliest dogs. Why did they stay wild while dogs drifted into domestication? “Anything to do with getting to the bottom of why we as a species picked out this one animal can carry a huge amount of information,” Horowitz says. “In some ways, it’s discovering something about ourselves.”



NASA astronauts haven’t launched to space from the United States in nearly eight years.

They’ve gone to space, of course. An American astronaut is up there right now. But they launch from Kazakhstan, at a hulking facility in the middle of the desert, in a Russian capsule, snuggled close to Russian cosmonauts, on a Russian rocket.

When the U.S. government retired its iconic but expensive space-shuttle program in 2011, officials promised the arrangement would be temporary. One day, human space flight would return to U.S. soil, this time with commercial companies at the helm.

SpaceX and Boeing, with funding from NASA, have spent the past several years designing and building astronaut launch systems. By the end of 2018, the finish line was in sight, after frequent delays and several disapproving reviews for both companies. The first big tests of the program went on the schedule for 2019. The United States was gearing up to restore its capability as a spacefaring nation.

And then the federal government closed.

Hundreds of thousands of federal workers were sent home without pay, including at NASA. For the past three and a half weeks of the shutdown, 95 percent of the space agency’s workforce has been furloughed.

Last week, as the impasse between President Donald Trump and congressional lawmakers calcified, NASA announced that the first significant test of the year, an uncrewed SpaceX launch, would be pushed from late January to no earlier than February. Several news reports suggested the shutdown had contributed to yet another delay.

It hasn’t—at least not yet. NASA and SpaceX tell The Atlantic that, despite speculation, the government shutdown hasn’t affected their work. NASA says the astronaut program, known as Commercial Crew, is part of a small group of NASA activities that are exempt from the government closure, including International Space Station operations, the agency says.

“We believe it’s a national imperative to return the flight of American astronauts on American rockets on American soil,” said Bob Jacobs, a spokesperson for NASA, one of the few still around to respond to questions.

That means NASA employees collaborating with SpaceX on this effort are still on the job, albeit without pay. The latest schedule change, NASA said, was caused by familiar setbacks. Both sides need more time to finish testing hardware and complete various reviews.

SpaceX employees have had to deal with their own workplace woes, as the company announced on Friday it has laid off nearly 10 percent of its workforce of more than 6,000 people. The layoffs, according to the company, were meant to pave the way for big challenges ahead, such as the construction of a spaceship to carry humans as far as Mars. Asked whether staff involved in Commercial Crew were affected, a spokesperson said only that the downsizing was company-wide.

With negotiations in Washington at a standstill, it’s unclear how long the shutdown will drag on. What would happen if NASA and SpaceX were both ready to go—ready to blast off with the first big test of this years-long effort—but the government was still closed? Would they launch anyway?

“We don’t deal a lot in hypotheticals, but yes,” Jacobs said.

James Gleeson, a spokesperson for SpaceX, confirmed that, yes, if NASA made the call, the company would carry out the uncrewed launch.

Imagine that scenario: the nation hitting a major milestone in its venerable space program, the one that put people on the moon, while its government doesn’t have enough money to function normally.

The scene may seem less hypothetical in the future, especially if crewed launches reach a steady cadence. In the 1980s, when the space shuttle was flying, the longest government shutdowns lasted a few days. Today, weeks-long closures are becoming the norm. Bipartisan bickering and rocket launches don’t operate on the same schedule, and there may come a time when one can’t wait for the other.

From a practical standpoint, a Commercial Crew launch during a shutdown seems possible. SpaceX is still working. NASA staff members are still working (and waiting for their paychecks). Even the 45th Space Wing, the Air Force unit that supports launches in Cape Canaveral, Florida, is working; the Defense Department received long-term funding last fall, and no Air Force employees are furloughed, a spokesperson said.

Plus, this demonstration won’t carry astronauts, which makes it significantly less stressful. “We can take more risk on demo-1 because it’s uncrewed,” Jim Bridenstine, the NASA administrator, told reporters in November. “What we want to make sure we do is we have the ability to test and evaluate everything necessary, so when we do demo-2—which will be crewed—we’re ready.”

The crewed SpaceX launch, anticipated sometime this summer, will fly with two NASA astronauts. (Boeing’s launches, both uncrewed and crewed, are slightly behind, scheduled for spring and summer, respectively.)

Of course, it’s possible that even if NASA and SpaceX are ready, space-agency leaders will want to wait until the government reopens. After all, what fun would an important launch be if 95 percent of your staff doesn’t have the option to participate in a professional capacity? Take, for example, Thomas Zurbuchen, a top administrator at NASA. Zurbuchen wasn’t allowed to attend a historic New Year’s Eve spacecraft flyby as registered staff, but he went anyway, as a guest. SpaceX’s first test flight is going to be a major moment many won’t want to miss.

A week before the SpaceX layoffs, as the shutdown entered its second week, a Falcon 9 rocket was lifted onto the launchpad at Cape Canaveral for testing. The crew capsule, Dragon, sat perched on top. If SpaceX’s first demonstration goes well, a pair of astronauts will take an elevator to the top of the rocket and squeeze inside. They will become the first American astronauts to launch to space on commercially built rockets. If it happens this year, that event will align with the anniversary of the best-known milestone in the American space program: the flight of Neil Armstrong and Buzz Aldrin toward the moon, from the very same launchpad.



For the past week, the Democratic Party’s presidential candidates, grassroots organizers, and national committee have fought over whether it would be a good idea to have a “climate-change debate.”

Governor Jay Inslee of Washington, whose presidential campaign is focused on climate change, started the fight a few weeks ago, when he demanded that Democrats devote one of their dozen scheduled primary debates to climate change—both to what it will mean domestically and internationally and to what candidates presume to do about it. Last week, the Democratic National Committee responded by telling Inslee that it wouldn’t hold a climate debate—and that if he appeared in one, it would block him from all future officially sanctioned debates.

Inslee responded with outrage, and since then the DNC has been trying to defend itself. Tom Perez, the DNC chair, has tried to justify the DNC’s decision in a few different ways. He published a Medium post titled “On Debates” earlier this week. “If we change our guidelines at the request of one candidate who has made climate change their campaign’s signature issue, how do we say no to the numerous other requests we’ve had?” he pleaded. The tone demonstrates how poorly the DNC has fared here: Almost nobody has ever published a hyper-earnest Medium post from a position of strength.

The DNC actually has a fine reason for declining Inslee’s request: Adding a single-issue climate debate would be against its rules, which it wrote to account for, and avoid, the bitterness left over from 2016. But the DNC is pretty weak here. Polls suggest that climate change is a top-tier issue for the party’s primary voters. At this point, 14 candidates have expressed some interest in a climate debate—15, if you include Joe Biden’s quick assent to the idea, captured on video by a Greenpeace activist. If five of them, including Elizabeth Warren, go rogue and hold a climate debate of their own, will the DNC really bar them from its official debates?

All of this is political tactics—forgettable and kind of whatever. (Though maybe it should concern the DNC that a candidate polling at 1 percent could play it for a week straight.) What’s more interesting is the loose consensus among climate and energy experts that a climate debate would do more harm than good. When three writers at New York magazine discussed “Should Democrats hold a climate-change debate?” they concluded that Inslee was right on the substance and wrong on the politics. A climate debate would be lousy television, they said. It would be too wonky to interest voters. And it could ultimately endanger the party’s general-election hopes. “The deeper candidates get into the weeds about actual policy, the likelier they are to say something that backfires in the fall,” wrote David Wallace-Wells.

I understand this argument. Climate-change policy, as I have written in the past, can be staggeringly boring. But it’s not all dull, and voters seem to care about it. A climate-change debate is a swell idea. It just requires rethinking much of what’s accepted about climate politics and about debates.

What’s the point of a presidential debate? More than 20 years ago, in a story for this magazine, James Fallows pointed out a fundamental divide between the kind of information that journalists create and the kind of information that most helps voters. Journalists try to generate news: gaffes, scoops, novel data, interesting interpretations of who’s up and who’s down in the political game. But voters ask about the what of politics: “the effects of legislation or government programs on their communities or schools.”

As we hold them today, moderated by television journalists and broadcast live, debates seem designed to generate that first kind of news. Recently, the MSNBC anchor Chris Hayes noted that a straightforward question a voter posed to Warren—“What are you going to do about the opioid crisis? It’s affecting everyone.”—was “the kind of question a journalist … almost certainly wouldn’t ask.”

This is not an atypical critique of political journalism, and Americans have partly absorbed it since the 1990s. Yet it still infects our debates, which are one of the best opportunities to inform voters about the actual policy stakes of an election. A 2016 report from public-policy researchers at the University of Pennsylvania recommended a number of improvements to the televised-debate format. (Vox made a good video about it.) One of their recommendations that has stuck with me the longest: “Enlarge the pool of potential moderators to include print journalists, university presidents, retired judges and other experts.”

In that vein, a climate debate could do plenty of good. Climate is a top-tier issue for voters in the Democratic Party, yet voters remain somewhat underinformed about it. This is … exactly what a debate could address. Moderators could start by asking the following questions, proposed on Twitter by David Hawkins:

1. What concerns you most about climate change?

2. What areas would you prioritize for federal funding?

3. How much federal spending would you propose for next decade?

4. How would you get support for this spending?

5. What steps would you take to reduce the ideological divide?

We already know the candidates disagree about some of these: Biden has proposed $1.5 trillion in climate spending; Inslee has proposed $3 trillion; most candidates have proposed nothing. Why are those numbers the right choice? Where should the money be spent?

After that opening, moderators could pose questions that have legitimately tricky answers. Questions such as:

To all candidates: Dozens of economists say a carbon tax is the best and cheapest way to fight climate change. But they’ve had little success in the United States, both in state legislatures and at the ballot box. Do you support a carbon tax?

Governor Inslee, you say that America has to lead in fighting the climate crisis. But China already emits more carbon pollution than the United States, and India will soon outrank us as well. Why is this America’s battle to fight? What can the United States do about other country’s greenhouse-gas emissions?

Vice President Biden, you have discussed the importance of fighting climate change. President Barack Obama also said fighting climate change was important in 2008, but he failed to pass a climate bill through the Senate, and he didn’t help complete a climate treaty until the end of his second term. Why will you be different?

Senator Warren, you have proposed dozens of plans to bring about “broad structural change” in the United States. Some of these plans mention climate change, but many don’t. In your flurry of reform, where will you rank fighting climate change?

Former Representative Beto O’Rourke, you have released an aggressive plan for fighting climate change. Your home state of Texas is undergoing an economic boom due to increased oil and natural-gas drilling. How will you weigh the benefits of fighting climate change—which will require keeping many of those fossil fuels in the ground—with this burst of short-term economic prosperity?

I am curious about their answers to these questions! I bet many voters are, too.

And anyway, look, the candidates will not be arguing over the nuances of soil-carbon maintenance. Take the two hours of debate a night, subtract at least 20 minutes for intros and interstitials, divide it among the 10 candidates onstage, and you get at most 10 minutes a person. Ten minutes is a lot, but it’s not enough time for Bernie Sanders to explore the pros and cons of negative-emissions technologies. The candidates are going to spend most of the time describing their plans (or lack thereof).

Some experts argue that candidates will overpromise in a climate debate. Candidates might, say, claim that they can decarbonize the United States by 2030, when in fact that is technologically impossible. But—again—why is that a good reason to avoid a debate? Candidates will overpromise anyway, and it’s not like voters will automatically believe the most radical climate plan they hear. (Some polling suggests the opposite may happen.) Right now, across a whole range of issues—health care, student-loan debt, immigration—the main argument in the Democratic Party is between radicals who want broad structural change and moderates who argue that such an overhaul is unrealistic. Why can voters understand a debate about reforming Obamacare versus adopting Medicare for All, but not understand one about climate change? To presume that voters aren’t ready for a climate debate strikes me as low-key antidemocratic. And if climate change is a problem that affects everyone, addressing it is going to take everyone’s involvement, too.



Elon Musk can exhale.

The entrepreneur has been on edge since SpaceX launched a spacecraft to the International Space Station last weekend. The launch went smoothly, the Falcon 9 rocket lighting up the night sky like a flare in the darkness. And SpaceX spacecraft have visited the space station more than a dozen times before, to deliver supplies and science instruments to the astronauts on board. But this mission was unlike the others.

The spacecraft that launched on Saturday was designed to carry humans.

No people were on board, but SpaceX needed to prove the mission would work. NASA gave the company a billion-dollar contract to design, build, and test a new transportation system capable of carrying its astronauts to and from humankind’s sole outpost in space. The United States hasn’t launched astronauts from American soil since the space-shuttle program ended, in 2011. NASA now relies on Russia’s launch capabilities, but wants to use American companies for all its astronaut travel needs instead.

The launch was the beginning of a days-long mission, punctuated by risky and unprecedented maneuvers, that SpaceX needed to execute to show the U.S. government that someday very soon the company can send people to space and bring them home.

“To be frank, I’m a little emotionally exhausted,” Musk told reporters on Saturday, after the Falcon 9 blasted off and deposited the spacecraft into orbit. “Because that was super stressful. But it worked—so far. We have to dock with station; we have to come back. But so far, it’s worked.”

And now it’s over.

The spacecraft, named Dragon, returned to Earth on Friday morning and splashed down in the Atlantic Ocean. A quartet of bulbous, orange-and-white parachutes eased its descent to the water off the coast of Florida, against a sky of fleecy white clouds. The capsule, slightly charred from the fiery plunge through the planet’s atmosphere, bobbed as a pair of speedboats moved toward it.

NASA and SpaceX will now review data from the mission, including from Ripley, the sole passenger, a mannequin outfitted with sensors that will show what the experience might be like for human beings. The first astronauts to fly on the Dragon have been selected, and they’re already in training. SpaceX still has more hurdles to clear, including a test of the Dragon’s launch-abort system, designed to hurl the capsule away from a malfunctioning rocket to safety. If these boxes are checked, NASA astronauts may launch in a Dragon capsule as soon as this summer.

The successful return of the Dragon marks the beginning of a new era in American spaceflight.

For decades, the business of sending people fell solely within the purview of the U.S. government, starting with Project Mercury in the 1960s and ending with the space-shuttle program, which transported astronauts for 30 years before folding under the burden of a high price tag and safety concerns.

The government has paid private aerospace companies to build the hardware for its programs, but it has never handed over the responsibility of reaching space to the extent it could now. NASA awarded a similar billion-dollar contract to Boeing, a longtime aerospace contractor, to develop its own transportation system alongside SpaceX. The hope is that both companies will take over the job of delivering astronauts to the International Space Station, and NASA will pay them to do it.

“This is an amazing achievement in American history,” Jim Bridenstine, the NASA administrator, said after the Dragon dropped into the ocean.

The splashdown is a significant achievement for SpaceX too. The company, founded in 2002, has mastered delivering a variety of payloads to space—commercial satellites, top-secret missions, even a lander bound for the moon. It has cemented its rule in the realm of reusable rockets, perfecting a complicated maneuver that returns rocket boosters to Earth, landing them on the ground or on a ship off the Atlantic coast, to be refurbished and flown again. Last year, it launched more than 20 rockets into space. The roar of rocket engines on the beaches of Florida, the site of historic NASA launches, blends into the usual noise.

It wasn’t so long ago that SpaceX was in a precarious place. In the summer of 2015, a Falcon 9 exploded about two minutes into its flight, destroying 4,000 pounds of food, supplies, and science experiments headed to the International Space Station. In fall 2016, a Falcon 9 exploded on the launchpad while being fueled for a routine engine test. The rocket and its payload, an Israeli communications satellite, went up in flames. SpaceX returned to flight in 2017 and has launched dozens of missions without incident since, including a captivating inaugural flight of its monster rocket, the Falcon Heavy.

The successful mission means SpaceX has edged out Boeing in the effort to send NASA astronauts to space. Both companies have faced schedule delays and technical issues—some of which haven’t yet been resolved—since receiving their NASA contracts in 2014. Officials at both companies have publicly resisted describing the program as a race. That’s a smart public-relations move; even a hint of competition among the contractors risks the perception that SpaceX and Boeing are putting speed over safety. But SpaceX can privately bask in the glow of beating a longtime NASA contractor to a big milestone.

SpaceX stands to receive more than bragging rights and revenue. If the company launches astronauts to space and returns them home safely, it would garner the prestige of restoring human spaceflight to American soil.

The mission began with a nighttime launch from Kennedy Space Center, where SpaceX leases a NASA launchpad that saw the launches of Apollo missions, shuttle flights, and Skylab, the country’s short-lived space station. The Dragon spacecraft reached the space station a day later and docked to a port, using a new approach that relied on the capsule’s autonomous software to guide it to the right place. Engineers on the ground held their breath as the Dragon neared; an accidental collision could put the spacecraft, the station, or both in danger.

The Dragon stuck the docking. After some checks and inspections, the crew on board the station opened the hatches and floated inside. It was a strange scene: There was Ripley the mannequin, clad in SpaceX’s futuristic-looking spacesuit and motorcycle-style helmet, and then there were the astronauts, dressed casually in polo shirts, having recently finished their lunch.

The Dragon arrived with about 400 pounds of cargo on board, which the crew eventually unloaded and returned with items ready to go back to Earth. In the early hours of Friday morning, the spacecraft detached and prepared to leave the station’s orbit, more than 250 miles above Earth.

Musk worried most about this part. Unlike other versions of the Dragon, designed to carry only cargo, the crew-friendly capsule has a more asymmetrical shape, which leaves it more vulnerable to tumbling as it passes through the Earth’s atmosphere. On top of that, the mushroom-cap parachutes had never been used before, and there was a chance that they wouldn’t deploy properly. “Hypersonic reentry is probably my biggest concern,” Musk said last week.

The sight of the splashdown recalled the heyday of American human spaceflight in the 1960s and 1970s, when Apollo capsules parachuted down the same way. The space shuttle, which started flying in the 1980s, returned to Earth like an airplane on a runway. It’s been decades since a capsule designed to carry humans was seen falling from the sky above American shores.

“Early Dragon 1 had a window on the side, and this was clearly a hint to everybody that we wanted to fly humans into space,” Hans Koenigsmann, SpaceX’s vice president for build and flight reliability, said before the launch. “We want to do this. This is our goal; this is why we are actually here. So clearly this is super important for us and incredible.”

Perhaps the next time Dragon flies, there will be someone taking in the view.



CAPE CANAVERAL, Fla.—About a year ago, when SpaceX made history with the successful launch of one of the most powerful rockets ever made, Elon Musk was ebullient. It had seemed possible, even to him, that on its first flight the Falcon Heavy could fail and go up in flames. So when the rocket sailed into the sky and deposited a shiny red Tesla in space, he floated into a room packed with reporters, ready to celebrate, a big grin on his face.

“It seems surreal to me,” Musk, the company’s CEO and lead designer, said then. “I had this image of just a giant explosion on the pad.”

This was not the same Elon Musk who appeared at a press conference early Saturday morning, after another historic launch at Kennedy Space Center. SpaceX had just sent a brand-new spacecraft toward the International Space Station. The spectacle was stunning: A Falcon 9 rocket rose into the dark night sky like a flame ascending a candlewick. If the mission continues to go well, NASA will use SpaceX’s spacecraft to fly astronauts to the ISS, as soon as this year. And yet Musk appeared serious, subdued.

It was 4 o’clock in the morning and, like everyone else in the room, Musk probably hadn’t slept in hours, which might have contributed to his stolid demeanor. But the pressure of the launch seemed to weigh heaviest. Instead of giddy disbelief, Musk exuded plain relief.

“To be frank, I’m a little emotionally exhausted,” Musk told reporters. “Because that was super stressful. But it worked—so far.”

While the launch went splendidly, the mission is far from over. This is the first test of the spacecraft, known as Dragon, which is designed to carry humans. Dragon will spend Saturday catching up to the ISS and dock to the station Sunday morning. The spacecraft will detach, head back to Earth, and parachute down to the Atlantic Ocean on Friday.

The schedule sounds straightforward, but each step is risky, Musk said, and engineers have imagined what could go wrong. Other, cargo-only versions of Dragon are lassoed by the station’s robotic arm, operated by an astronaut; the crew version uses autonomous software to guide itself to a port. During this maneuver, the spacecraft could fail to attach to the ISS. If it goes well, Dragon could still tumble as it reenters Earth’s atmosphere. Or, on the way down, its parachutes could fail to deploy correctly.

The complicated mission is part of a NASA program to use commercially built launch systems to ferry astronauts to and from the ISS. NASA lost that ability in 2011, when the venerable Space Shuttle program folded under the weight of cost, politics, and safety concerns. The same year, the space agency asked the private sector to come up with ideas for the future of space transportation. By 2014, two front-runners had emerged, SpaceX and Boeing, and NASA gave them billion-dollar contracts to help develop their concepts.

Over the next week, SpaceX must prove its launch system can safely carry astronauts to and from the ISS. “Unless something goes wrong, I would think that we’ll be flying hopefully this year, this summer,” Musk said. The NASA administrator, Jim Bridenstine, sitting alongside Musk, concurred.

SpaceX would make history with a crewed flight. But the company is already steeped in the stories of American spaceflight. It leases and launches from Kennedy Space Center’s launchpad 39A, the site of launches for the Apollo and Space Shuttle programs. Musk and his fellow engineers watched Saturday’s launch from inside a firing room at Kennedy Space Center, where mission control once gathered for the launches of space shuttles, glued to their headsets and computer screens. The NASA astronauts assigned to SpaceX’s first crewed flight, Doug Hurley and Bob Behnken, joined them.

A reporter asked Musk at the press conference how he felt about conducting his missions in these storied places.

“It’s hard to believe; I would never have believed that this would ever happen,” Musk said. He paused and shifted his gaze beyond the microphone in front of him, as if to focus on a scene playing out in his mind.

“Yeah, I just think, you know—humanity landing on the moon, man, that was maybe the greatest thing ever,” he continued, choking up. “So I can’t believe we’re launching from that pad.”

The emotion seemed to pass, and then Musk took on an urgent tone. “I hope we go back to the moon soon,” he said. “We should have a base on the moon, like a permanently occupied human base on the moon. And send people to Mars, and build a city on Mars. That’s what we should do.”

The remarks seemed a little off script given the subject at hand—getting humans to low-Earth orbit. But Musk is a well-known multitasker, in cosmic daydreams and real-life situations, and his past few months have been filled with tumult, both professional and personal. The unexpected display of emotion, on what could been a morning of easy triumph, hinted at the intensity of trying to live out the billionaire inventor’s version of having it all.

The Air Force, a SpaceX customer, is currently evaluating the launch-certification process for the company’s Falcon 9 and Falcon Heavy rockets, but hasn’t publicly given a reason why. SpaceX has questioned the U.S. government’s decision to use the United Launch Alliance, a Boeing and Lockheed Martin venture, to launch a NASA mission to Jupiter; SpaceX has argued that it can offer a better, cheaper deal.

NASA is also in the midst of interviewing hundreds of employees at both SpaceX and Boeing as part of a review of workplace culture. Bridenstine said he ordered the assessment because he wants to detect warning signs that could contribute to dangerous or potentially deadly errors. The review was announced not long after Musk smoked marijuana and drank whiskey on a popular podcast, which drew a rebuke from Bridenstine.

This week, the administrator sounded optimistic. “I’m highly confident that our contractors are complying with the terms of their contracts, and I expect that we will find that their culture is very safe,” he said.

And that’s just SpaceX. Musk is still dealing with the fallout from being sued by the Securities and Exchange Commission over a tweet about Tesla that officials said violated federal regulations. The parties reached a settlement in September that forced Musk to step down from his role as chairman of Tesla’s board for three years (but allowed him to still stay on as CEO) and pay $20 million in fines. It also required Tesla to establish stricter control over Musk’s communications, including on Twitter.

But the oversight doesn’t appear to have stuck. Last week, the SEC requested that a federal court hold Musk in contempt for tweeting about Tesla production goals. Less than an hour before the pivotal SpaceX launch, Musk was still conversing with other users on Twitter about the electric-car company.

The launch eventually shifted Musk’s gaze from the screen to the sky. “Need to get back to SpaceX launch control,” he tweeted. In the firing room, as the Dragon spacecraft hurtled into space, Musk said he asked his future passengers, Hurley and Behnken, for their reactions on the launch system. They told him they felt good about flying on it.

If Musk seems stone-faced now, imagine him on the day Hurley and Behnken are inside the Dragon spacecraft, perched atop the Falcon 9.

“I suspect it will be extremely stressful,” he said.



This time last year, Drew Feustel was weightless, floating from room to room on the International Space Station. When he looked out a window, the view was stunning. There was Earth, resplendent and gleaming against the inky darkness of space. There, beneath silky tufts of white clouds, was the rest of humanity.

But even in this rarefied environment, Feustel sometimes turned his attention to a pastime familiar to us earthbound workers—plowing through every single season of a hit television show.

When Feustel and I sat down for a recent interview, the disposable cup of coffee I had set down on the conference-room table in front of us caught his eye. He laughed. The cup, he said, reminded him of something that had happened on Game of Thrones.

Fans know what I’m talking about. During a scene in this week’s episode, the fourth in the highly anticipated final season of the HBO series, viewers noticed something that clearly did not belong in Westeros: a disposable coffee cup, complete with a cardboard sleeve, right there on the banquet table in front of Daenerys Targaryen, the Mother of Dragons, as she shot knowing looks at Jon Snow, the reluctant King in the North.

Feustel, it turns out, had watched seven seasons while he was on the ISS.

“People said it might be interesting, and it seems pretty popular down here,” Feustel said. “So I took the time to try to get caught up on all the episodes and see what all the fuss was about—and enjoyed it.”

This caught me off guard. I’d met with Feustel to talk about his work as an astronaut for NASA, such as whether he felt nervous repairing the Hubble telescope, with nothing but a spacesuit between him and the vacuum of space. What spacewalking feels like, and whether he’s had any close calls. How he adjusted to Earth again after six months, and whether his eyeballs had become a little squished, a weird but common phenomenon in people who spend a long time in space, where fluid in the skull, freed from gravity, floats and pushes against the back of the eye. You know, otherworldly stuff, not meme-worthy continuity errors.

Sure, it felt like everyone on the planet was talking about Game of Thrones this week, but Feustel isn’t exactly everyone else. In the United States, astronauts are treated like celebrities, even national treasures. Feustel looked the part, dressed in a bright-blue jumpsuit with mission patches embroidered across the chest and shoulders, including NASA’s instantly recognizable logo. It was easy to forget that Feustel, like all astronauts, is just a regular guy, and that astronauts do regular-people things, like binge-watch TV shows. They just do it in space.

It’s not only Game of Thrones. Astronauts watch all kinds of entertainment on the ISS, from TV shows and films to sporting events and cable news, usually on their laptops. (Feustel’s favorite was car races, such as Formula One.) On Saturday nights, the crew might watch a movie together on a 65-inch screen that was installed in 2015. Earlier this week, they watched Star Wars in honor of May 4, the unofficial holiday of the franchise. The station is stocked with DVDs, and astronauts can request more in regular cargo deliveries, if there’s room. But most of the media is beamed up as digital files.

“Space-station crew members request whatever programming they would like to see, and Mission Control arranges for those television shows to be uplinked to them on their [laptops],” explains Stephanie Schierholz, a NASA spokesperson. “The connection is quick. Essentially the delay is not any different than the TV broadcast in your house.”

This doesn’t mean astronauts are sitting around the space station watching sitcoms until their fingers are caked in Cheetos dust and the screen goes black and asks, rather judgmentally, “Are you still watching?” Astronaut days are packed. They work regular weekday hours, and spend Saturdays doing housekeeping chores such as vacuuming. They work out for two hours every day so that their muscles and bones, relieved of the responsibility of bearing their weight, don’t atrophy. Exercise is prime time for entertainment consumption; astronauts can watch something on small screens while on the treadmill or stationary bike.

Unlike for many of us, binging TV shows is actually crucial to astronauts’ mental health. Any leisure activity is, really. Board games, music, movies—these provide comfort and distraction in a pretty challenging environment. The ISS is slightly bigger than a six-bedroom house. For six months, astronauts sleep strapped into their bed, bathe with water from plastic pouches, and eat freeze-dried food. There are no sounds of nature, no wind in their hair, no sunlight to warm their skin. And they hang out with the same people, day in and day out.

“We don’t have that many places to go. There’s only so many modules you can float into to get away or experience something different,” Feustel said. “We see the same walls every day unless we go outside for a spacewalk, which is pretty rare. When you’re six people separated from 7 billion people, you like to have things in space that keep you connected to Earth.”

For most of spaceflight history, astronauts have been roughing it in cramped quarters and dangerous conditions. Movies such as Apollo 13 portrayed space exploration as a high-stakes, nail-biting endeavor. At times, that’s still true—an empty SpaceX spacecraft designed to someday carry astronauts blew up just last month—but these days, most space travel is more routine. The ISS is a spaceship, but it’s also a home. Astronauts are spending more time on the station than ever before. The longer they’re cooped up, the more important maintaining their well-being becomes. You can bet a spaceship bound for Mars will come fully stocked with enough hours of entertainment to keep space travelers from strangling one another during the seven-month trip there.

Feustel, who returned to Earth in October, hasn’t watched the latest Thrones season. He doesn’t subscribe to HBO, and Mission Control can’t help with that. Feustel won’t get to see the random cup on the banquet table; HBO producers digitally erased the interloper from the scene a few days after it aired. But at least when Feustel sits down to watch, he won’t have to strap himself down so he doesn’t float away.

“Hopefully, I’ll get caught up,” he said.



In a single drop of water from Lake Ontario, you can find an abundance of algae. In these algae, scientists in 2015 found a new virus belonging to an enigmatic group called giant viruses. And nested inside these giant viruses, scientists have now found yet more novel viruses—three tiny ones that they have named CpV-PLV Larry, Curly, and Moe.

“I originally named them to see if I can get away with it,” says Joshua Stough, now a postdoctoral research fellow at the University of Michigan. He’s a co-author of a new paper describing and naming the Three Stooges, so, in fact, he has gotten away with it.

All three of these viruses are what are known as virophages, viruses that specialize in infecting other viruses. Virophages were first discovered infecting giant viruses from a water-cooling tower in 2008. Since then, scientists have isolated only a handful more—all from giant viruses that infect microscopic organisms such as algae or amoebas. It’s a virus inside a virus inside a cell. “They’re like the Russian doll,” says Curtis Suttle, a virologist at the University of British Columbia who was not involved with the new study.

Giant viruses themselves are strange and poorly understood. Viruses are traditionally considered not to be alive, because they are unable to reproduce on their own like bacteria or multicellular organisms. But giant viruses seem to blur the line between alive and dead—some are almost as big as bacteria, and their genomes sometimes have many of the genes necessary for replication. What’s more, bacteria can be infected by specialized viruses called bacteriophages. Giant viruses can also be infected by specialized viruses, which are of course called virophages. In some ways, giant viruses seem to have more in common with living bacteria than with a simple influenza virus.

[ Read: Beware the Medusavirus ]

Stough’s colleagues managed to sequence DNA from the giant virus found in Lake Ontario, which was given the the far less colorful name CpV-BQ2. As far as Stough knew, they were sequencing pure DNA from CpV-BQ2 viruses. But an oddity in the data made him realize that he was also looking at three completely new virophages. In particular, they had similarities to a virophage that parasitizes another giant virus, called CroV.

Suttle had unknowingly isolated CroV at least as far back as 1995. It would be another decade before other scientists realized that giant viruses even existed, and his lab spent years trying to study CroV. Over the years, he would start a student on the project. They would defrost a sample from storage. The CroV would grow and then mysteriously stop growing. “A couple years later, someone would come along to try again,” Suttle says. It wasn’t until DNA-sequencing technology improved and Matthias Fischer joined the lab that they finally figured out what was going on: Their samples also contained virophages that were “killing” the giant viruses. Freezing destroyed most of the virophages, but each time someone took the giant viruses out of the freezer and grew them in the lab, the virophages would start replicating and attacking the giant viruses. Suttle and Fischer published a paper describing all this in 2011.

The virophages that Suttle found could also explain the origin of another strange genetic phenomenon. Transposons, or “jumping genes,” are DNA sequences that can move around within the genomes of living organisms. The DNA sequences of the virophages that Suttle and Fischer found were similar to those of a certain type of transposon called Polintons. Virophages are now known to infect giant viruses, which in turn infect host cells such as algae or amoebas. Suttle and Fischer hypothesized that this might have gone one step further in the past: Ancient virophages might have become part of the host cell over time as part of a mutually beneficial arrangement—the virophages killed attacking giant viruses for the host and got a safe place to hang out. Eventually, those virophages became transposons.

[ Read: Brain cells share information with virus-like capsules ]

The Three Stooges virophages that Stough described from Lake Ontario are genetically similar to these Polinton transposons, too. He didn’t physically observe any virus particles. But it’s possible, he says, that the three virophages are somehow hiding out inside the giant virus CpV-BQ2.

Stough did also trawl through more sequencing data from Lake Erie and Lake Tai in China. He found evidence of virophages in Lake Tai halfway across the world from North America. What’s more, he looked at not just DNA but also RNA, which is present only if the virophages are replicating, which it appears they are. Bernard La Scola, a virologist at Aix-Marseille Université, says that giant viruses and virophages are not uncommon in sequencing data from different environments. “Probably giant viruses and virophages are very common and present in all environments, everywhere,” he says. Until recently, we just didn’t know to look for them.

Fischer, who is now a virologist at the Max Planck Institute for Medical Research, points out that to find giant viruses and virophages, you first need to look for protists, a catchall group of poorly studied organisms that are not bacteria or archaea or animals or plants or fungi. They include single-celled algae, amoebas, slime molds, plankton, and many even more obscure organisms. Scientists have only just started to explore the world of protists. Inside protists, there is a whole world of giant viruses. And inside giant viruses, apparently, a whole world of virophages.



If you’ve ever complained about DIY home repairs, spare a thought for the colonial aphid, Nipponaphis monzeni, for whom the task of fixing the house can be spectacularly fatal. It fixes holes in its nest by suicidally erupting and, in its death throes, plastering its bodily fluids over the openings.

Each of these aphids is a white bead, just half a millimeter across. In large numbers, they can compel Japanese trees to form large, hollow spheres called galls—roomy mansions in which hundreds or thousands of them can live. Like ants, bees, and termites, aphids divide their labor: Adults reproduce, while immature nymphs act as both workers and soldiers. If moth caterpillars tunnel their way into the galls, the nymphs stab these intruders to death, using the sharp mouthparts that they normally use to suck sap from trees. That deals with the caterpillar, but what about the huge hole that it leaves in the gall?

The aphid’s solution, discovered in 2003, is dramatic. Dozens or hundreds of the young soldiers will gather around a hole and discharge fluid from a pair of tubes on their backsides. This isn’t a gentle leak but a violent eruption, which drains the nymphs so thoroughly that they shrivel down to just a third of their initial volume. As they dry and die, they also use their legs to mix the fluids over the holes. These harden within an hour, sealing the gap and sometimes entombing the suicide plasterers.

These acts of sacrifice save the colonies. In 2009, Mayako Kutsukake from the National Institute of Advanced Industrial Science and Technology showed in a study that when she halted the aphids’ repairs by absorbing the plasterers’ bodily fluids with tissue, the galls almost always die. If she carried out the repairs herself with glue, the galls and the colonies within them survived. An open gall is vulnerable to predators and desiccation. “Letting the plants heal the galls naturally takes a long time and is very risky for the aphid colony,” says Takema Fukatsu, who led the study.

Back then, Kutsukake and Fukatsu compared the aphids’ repairs to the clotting process that we and other animals use to heal open wounds. Now, after a decade of work, they’ve realized that the analogy is more fitting than they could have imagined.

If an insect is wounded, cells called hemocytes rush to the breach and burst, releasing fats that quickly coagulate into a soft plug. Those bursting cells also release an enzyme called phenoloxidase, which cross-links molecules in the insects’ blood into a hard, reinforced mesh—a scab.  

This is almost exactly what happens when the soldier aphids sacrifice themselves at a gall hole. Hemocytes in their bodily fluids rupture, releasing fats that quickly form a plug, which phenoloxidase slowly reinforces. All the components are the same; the soldiers just have a lot more of them. By exaggerating their own immune defenses, they’ve evolved a way of defending their entire colonies. “It’s clotting, just not of the body,” says Nancy Moran from the University of Texas at Austin. “They’re clotting the house that they live in.”

That discovery was hard-won. The aphids can’t be reared in the lab, and in the field, “the gall-repairing soldiers are available only for a few months every year,” Kutsukake says. Her work had to proceed in fits and starts, which is why it took a decade to divine the details of the process.

There are many examples where a colony’s defenses mirror an individual’s: Some ants, for example, will kill infected larvae to stop diseases from spreading, just as their immune systems will destroy infected cells. But Kutsukake’s research “shows that these parallels can even exist at the level of the molecules,” says Sylvia Cremer from the Institute of Science and Technology Austria. In the social aphids, “the same cells and molecules responsible for individual wound healing have been co-opted for colony-level wound healing.”

Many social animals will give up their life to protect their genetically related colony mates—honeybee workers famously die after stinging. But the brand of suicidal altruism where individuals sacrificially rupture themselves has a special name—“autothysis.”

One termite species commits autothysis to release a chemical weapon: When it bursts, blue crystals in its back mingle with chemicals in its salivary glands to create a toxic sludge that kills its opponents. Only older individuals do this; their jaws are too worn to be useful in combat, and, to misquote Neil Young, it’s better to blow up than to fade away.

Meanwhile, several species of exploding ants defend their colonies by flexing so hard that they rip apart their abdomens, unleashing sticky, toxic, corrosive chemicals onto their attackers. To maximize the effect of these chemicals, some workers will stick their abdomens into the mouths of their opponents before letting rip. New species of exploding ants are being discovered all the time; one, which was identified last year, is aptly named Colobopsis explodens.

None of these examples, however, established a clear link between the self-sacrificing behavior and the insect’s own immune system. The social aphids are the first, and they should prompt scientists “to revisit in more detail whether the immune system in those other species is also involved in self-explosion,” says Rebeca Rosengaus from the Northeastern University College of Science.



It has a sleek black pill of a body, with two rigid, white arms sprouting from its sides. It looks, in other words, like an iPad had a baby with a crop duster, or like a Volkswagen Bug from a future designed by Bjork. In the video, it sits on a small, square tarmac, surrounded by grass, then begins to purr and buzz. In a nearby hangar, a group of attractive young Germans stands and watches intently.

And then, slowly, the vibrating thing rises from the ground. Several feet of air open between its body and the tarmac. It is flying. It has neither a small plane’s propeller, nor a helicopter’s immense rotor, nor a drone’s spidery appendages. Yet it is flying all the same.

On Thursday, the German start-up Lilium announced that it had completed its first test of that strange and buzzing vehicle, the five-seater Jet. By the middle of the next decade, Lilium claims, reserving a seat on one will be as easy as hailing an Uber.





The successful flight puts Lilium near the front of a pack of companies that hope to fill the sky with small electric aircraft. These companies see themselves as a key part of humanity’s climate-friendly future: At distances of more than 40 miles, such vehicles may even be better for the environment than electric cars. In the industry, the vehicles are known as electric VTOLs, short for “vertical takeoff and landing” vehicles. 

But everyone calls them by a far more romantic name: flying cars.

The video, which Lilium says was shot on May 4, near its Munich headquarters, shows the Jet’s sole test so far. In the roughly 15 seconds of footage, the five-seater does not rise more than a few feet off the ground. It does not carry any passengers: A licensed pilot stood on the ground during the test and controlled the Jet remotely. And it does not fly either forward or backward—though Remo Gerber, Lilium’s chief commercial officer, says its smaller test models have done so.

But the company says the test nonetheless represents a major milestone because the five-seat model will “serve as a template for mass production,” according to a spokeswoman for Lilium.

Eventually, Lilium hopes to use a fleet of five-seaters to ferry customers around metropolitan areas or between cities. It claims that flights booked through its app will be price-competitive with major airlines, but require far less infrastructure investment than an airport. A Jet requires only “a heliport type of structure, plus parking spaces around it,” Gerber told me. “It’s nowhere near comparable to any rail or road investments.”

“We are very confident that we will have it in a number of different cities by 2025,” Gerber said. He envisions Jets linking New York to Boston, Philadelphia, or the Hamptons. A flight between downtown Manhattan and John F. Kennedy International Airport would cost $70 and take only six minutes, he says. Today that trip by taxi takes at least an hour, but costs about the same.

At least 16 companies are trying to build electric flying cars or taxis, according to Transport Up, a news site that follows the budding industry. And Wired reports that a number of companies have already discreetly met to plan regulatory change. But only a handful have made successful test flights. Vahana, a start-up owned by the European aerospace conglomerate Airbus, says that it has made 50 test flights with its full-scale model, totaling more than five hours of flying time. Both the U.S. giant Boeing and the Silicon Valley–based start-up Kitty Hawk have completed test flights of smaller VTOLs.

Lilium stands out by promising a far longer range than most of its competitors. While many companies say their VTOLs will travel 60 miles on a single charge, Lilium says (but has yet to prove) that it can eke out 185 miles. “We don’t have a magical battery,” Gerber said, adding that the Jet’s solid-body wings and dozens of small electric motors allow it to cruise while using little energy.

Greg Keoleian, an engineering professor at the University of Michigan, could not comment on Lilium’s specific range claim, but he agreed that VTOLs are more efficient when cruising forward than when hovering. In a paper published last month, Keoleian and his colleagues found that a fully loaded flying car could be more efficient than an electric car at a distance of more than 60 miles. Flying cars are more efficient—and emit less carbon pollution—than gasoline-burning cars when going longer than 21 miles. 

While it’s hard to know whether flying cars will ever become a commercial reality, they could help solve a major climate problem. Aviation, which makes up about 2 percent of global carbon emissions, will be one of the hardest parts of the economy to decarbonize. Scientists have yet to invent a cheap renewable fuel as dense with energy as the jet fuel burned by massive airliners. Although even Lilium doubts that its battery-powered taxis will ever be a substitute for long-haul air travel, they could eventually replace the short hops made by commuters and business travelers.

Keoleian told me that the results were surprising, but that they made a certain amount of sense: It is much more energy-efficient to cruise forward through air than it is to drive, but hovering is very energy-inefficient. If you cruise far enough, eventually it becomes worthwhile. Even if Lilium debuts a New York–to–JFK flight, it will still be many times as expensive as just taking the subway.

“You don’t want to displace mass transit or public transit systems, which are very efficient,” he told me. “And you don’t want to encourage sprawl.”

Flying cars would be best for avoiding circuitous driving routes, he said, or to avoid congestion. There is also no traffic in the sky—at least not yet.



On the evening of December 18, 2004, in the hamlet of Madiran, in southwestern France, a man named Jean-Luc Josuat-Vergès wandered into the tunnels of an abandoned mushroom farm and got lost. Josuat-Vergès, who was 48 and employed as a caretaker at a local health center, had been depressed. Leaving his wife and 14-year-old son at home, he’d driven up into the hills with a bottle of whiskey and a pocketful of sleeping pills. After steering his Land Rover into the large entrance tunnel of the mushroom farm, he’d clicked on his flashlight and stumbled into the dark.

The tunnels, which had been originally dug out of the limestone hills as a chalk mine, comprised a five-mile-long labyrinth of blind corridors, twisting passages, and dead ends. Josuat-Vergès walked down one corridor, turned, then turned again. His flashlight battery slowly dimmed, then died; shortly after, as he tromped down one soggy corridor, his shoes were sucked off his feet and swallowed by the mud. Josuat-Vergès stumbled barefoot through the maze, groping in pitch-darkness, searching in vain for the exit.

On the afternoon of January 21, 2005, exactly 34 days after Josuat-Vergès first entered the tunnels, three local teenage boys decided to explore the abandoned mushroom farm. Just a few steps into the dark entrance corridor, they discovered the empty Land Rover, with the driver’s door still open. The boys called the police, who promptly dispatched a search team. After 90 minutes, in a chamber just 600 feet from the entrance, they found Josuat-Vergès. He was ghostly pale, thin as a skeleton, and had grown out a long, scraggly beard—but he was alive.

In the following days, as the story of Josuat-Vergès’s survival reached the media, he became known as le miraculé des ténèbres, “the miracle of darkness.”

He regaled reporters with stories from his weeks in the mushroom farm, which seemed to rival even the grandest tales of stranded mountain climbers or shipwreck victims on desert islands. He ate clay and rotten wood, which he found by crawling on all fours and pawing at the mud; he drank water that dripped from the limestone ceiling, sometimes even sucking water from the walls. When he slept, he wrapped himself in old plastic tarpaulins left behind by the mushroom farmers. The part of Josuat-Vergès’s story that confounded reporters was that he had undergone radical and unexpected oscillations in his mood.

At times, as one might expect, he sank into profound despair; from a piece of rope he found, he even made a noose, “in case things got unbearable.” But during other moments, Josuat-Vergès explained, as he walked in the dark, he would slip into a kind of meditative calm, allowing his thoughts to soften and unspool, as he embraced the feelings of disorientation, letting himself float through the tunnels in a peaceful detachment. For hours at a time, as he wandered the maze, he said, “I sang to myself in the dark.”

Homo sapiens have always been marvelous navigators. We possess a powerful organ in the primitive region of our brain called the hippocampus, where, every time we take a step, a million neurons collect data on our location, compiling what neuroscientists call a “cognitive map,” which keeps us always oriented in space. This robust apparatus, which far outstrips our modern needs, is a hand-me-down from our nomadic hunter-gatherer ancestors, whose very survival depended on powers of navigation. For hundreds of thousands of years, the failure to locate a watering hole or a safe rock shelter, or to follow herds of game and locate edible plants, would lead to certain death. Without the ability to pilot ourselves through unfamiliar landscapes, our species would not have survived—it is intrinsic to our humanity.

It is no surprise, then, that when we do lose our bearings, we are cast into a primal, bitter-in-the-mouth panic. Many of our most elementary fears—being separated from loved ones, uprooted from home, left out in the dark—are permutations of the dread of being lost. In our fairy tales, it is when the fair maiden becomes disoriented in the gloomy forest that she is accosted by the menacing troll or the hooded crone. Even hell is often depicted as a maze, going back to Milton, who made the comparison in Paradise Lost. The archetypal horror story of disorientation is the Greek myth of the Minotaur, who dwells in the winding folds of the Labyrinth of Knossos, a structure, as Ovid wrote,“built to disseminate uncertainty,” to leave the visitor “without a point of reference.”

So deep-seated is our dread of disorientation that becoming lost might trigger a kind of crack-up, where our very sense of self comes apart at the seams. “To a man totally unaccustomed to it,” wrote Theodore Roosevelt in his 1888 book Ranch Life and the Hunting Trail, “the feeling of being lost in the wilderness seems to drive him into a state of panic terror that is frightful to behold, and that in the end renders him bereft of reason … If not found in three or four days, he is very apt to become crazy; he will then flee from the rescuers, and must be pursued and captured as if he were a wild animal.”

From our first step into subterranean darkness, our hippocampus, which so reliably guides us through the surface world, goes on the fritz, like a radio that has lost reception. We are cut off from the guidance of the stars, from the sun and the moon. Even the horizon vanishes—if not for gravity, we’d scarcely know up from down. All of the subtle cues that might orient us on the surface—cloud formations, plant-growth patterns, animal tracks, wind direction—disappear. Underground, we lose even the guide of our own shadow.

Down in a tight cave passage, or in the bounded folds of a catacomb, our field of view is blinkered, never reaching beyond the next twist or kink. As the cave historian William White observed, you never really see a whole cave—only one sliver at a time. When we navigate a landscape, wrote Rebecca Solnit in A Field Guide to Getting Lost, we are reading our surroundings as a text, studying “the language of the earth itself”; the underground is a blank page, or a page scribbled with language we cannot decipher.

Not that it’s illegible to everyone. Certain subterranean-dwelling creatures are marvelously adapted to navigate through the dark. We all know the bat, who swoops through cave darkness using sonar and echolocation, but the champion subterranean navigator might be the blind mole rat: a pink, wrinkly, bucktoothed creature—picture a 90-year-old thumb with fangs—that spends its days in vast, mazelike underground nests. To navigate these dark passages, the blind mole rat periodically drums its head against the ground, then discerns the shape of the space according to the patterns of the returning vibrations. In its brain, the rat even has a tiny iron deposit, a built-in compass, which detects the Earth’s magnetic field. Natural selection has endowed us surface-dwellers with no such adaptive tricks. For us, a step underground is always a step into a navigational vacuum, a step in the wrong direction, or rather, no direction at all.

In any other landscape, when our inborn powers of navigation falter, we turn to a map, which anchors us in space, and keeps us on course. In the underground world, though, mapping has always been a uniquely perplexing endeavor. Long after explorers and cartographers were charting every other terrestrial landscape on the planet, casting clean latitudinal and longitudinal grid lines over remote archipelagos and mountain ranges, the spaces directly beneath our feet remained elusive.

The earliest known map of a cave was drawn in 1665 of Baumann’s Cave, a large cavern in the densely forested Harz region of Germany. To judge from the map’s rudimentary lines, the cartographer, a man identified as Von Alvensleben, does not appear to have been an expert mapmaker, or even a capable one, but the map’s shortcomings are nonetheless remarkable. The explorer has failed to convey any sense of perspective, or depth, or any other dimension—he has failed to communicate even that the space is underground. Von Alvensleben was attempting to map a space he was neurologically ill-equipped to see, a space literally beyond his perception. It came to the point of an epistemological folly, like trying to paint a portrait of a ghost, or catch a cloud in a net.

The map of Baumann’s Cave was the first in a long lineage of curious failures of subterranean cartography. For generations, explorers all over Europe—teams of dauntless, quixotic men—plumbed caves with the intent to measure the underground world, to orient themselves in the dark, only to fail, often in bewildering ways. On fraying ropes, they lowered themselves deep underground, where they wandered for hours, clambering over hulking boulders and swimming down subterranean rivers. They guided their way with wax candles, which gave off feeble coronas of light that extended no more than a few feet in any direction. Surveyors often resorted to absurd measures, such as an Austrian explorer named Joseph Nagel who, in an attempt to illuminate a cave chamber, tied a rig of candles to the feet of two geese, then threw pebbles at the geese, hoping that they would take flight and cast their light through the dark. (It didn’t work: The geese wobbled lamely and tumbled earthward.)

Even when they did manage to make measurements, meanwhile, the explorers’ spatial perception was so warped by the caprices of the environment that their findings would be wildly off the mark. On a 1672 expedition in Slovenia, for example, an explorer plumbed a winding cave passage and recorded its length at six miles, when in reality, he had traveled only a quarter mile. The surveys and maps that emerged from these early expeditions were often so divergent from reality that some caves are now effectively unrecognizable. Today, we can only read the old reports as small, mysterious poems about imaginary places.

The most renowned of the early cave mappers was a late-19th-century Frenchman named Edouard-Alfred Martel, who would become known as the father of speleology. Over the course of a five-decade career, Martel led some 1,500 expeditions in 15 countries around the world, hundreds of them into virgin caves. A lawyer by trade, he spent his early years rappelling underground in shirtsleeves and a bowler cap, before finally designing a kit of specialized caving equipment. In addition to a collapsible canvas boat dubbed Alligator, and a chunky field telephone to communicate with porters on the surface, he devised a battery of subterranean survey instruments. For example, he invented a contraption to measure a cave floor-to-ceiling, in which he attached an alcohol-soaked sponge to a paper balloon on a long string, then set a match to the sponge, causing the balloon to rise to the roof as he unspooled the string. Martel’s maps might have been more precise than those of his predecessors, but compared with the maps drafted by explorers of any other landscape at the time, they were hardly more than sketches. Martel was celebrated for his cartographic innovation of dividing a cave into distinct cross sections (or coupes), which would become the standard in cave mapping.

Martel and his fellow explorers, who spent years trying and failing to orient themselves in the subterranean world, were disciples to lostness. No one knew the sensory experience of disorientation so intimately: For hours on end, they’d float through the dark, caught in a prolonged state of vertigo, as they tried and failed to anchor themselves. According to all evolutionary logic, where our minds are wired to avoid disorientation at all costs, where lostness activates our most primitive fear receptors, they must have experienced a deep anxiety: “the panic terror that is frightful to behold,” as Roosevelt described it. And yet, they went down again and again.

They derived a form of power, it seems, from losing themselves in the dark.

Lostness has always been an enigmatic and many-sided state, always filled with unexpected potencies. Across history, all varieties of artists, philosophers, and scientists have celebrated disorientation as an engine of discovery and creativity, both in the sense of straying from a physical path, and in swerving away from the familiar, turning in to the unknown.

To make great art, John Keats said, one must embrace disorientation and turn away from certainty. He called this “negative capability”: “that is, when a man is capable of being in uncertainties, mysteries, doubts, without any irritable reaching after fact and reason.” Thoreau, too, described lostness as a door into understanding your place in the world: “Not till we are completely lost, or turned round,” he wrote, “do we appreciate the vastness and strangeness of nature … Not till we are lost, in other words, not till we have lost the world, do we begin to find ourselves, and realize where we are and the infinite extent of our relations.” All of which makes sense, neurologically speaking: When we are lost, after all, our brain is at its most open and absorbent.

In a state of disorientation, the neurons in our hippocampus are frantically sponging up every sound, smell, and sight in our environment, scrambling for any strand of data that will help us regain our bearings. Even as we feel anxious, our imagination becomes prodigiously active, conjuring ornate images from our environment. When we take a wrong turn in the woods and lose sight of the trail, our mind perceives every twig snap or leaf rustle as the arrival of an ornery black bear, or a pack of warthogs, or a convict on the lam. Just as our pupils dilate on a dark night to receive more photons of light, when we are lost, our mind opens up to the world more fully.

In the late 1990s, a team of neuroscientists tracked the power of disorientation down into the physical trappings of our brain. In a lab at the University of Pennsylvania, they conducted experiments on Buddhist monks and Franciscan nuns, where they scanned their brains during meditation and prayer. Immediately, they noticed a pattern: In a state of prayer, a small region near the front of the brain, the posterior superior parietal lobe, showed a decline in activity. This particular lobe, as it turns out, works closely with the hippocampus in the processes of cognitive navigation. As far as the researchers could see, the experience of spiritual communion was intrinsically accompanied by the dulling of spatial perception.

It should be no surprise, then, that anthropologists have tracked a kind of cult of lostness running through the world’s religious rituals. The British scholar Victor Turner observed that any sacred rite of initiation proceeds in three stages: separation (the initiate departs from society, leaving behind his or her former social status), transition (the initiate is in the midst of passing from one status to the next), and incorporation (the initiate returns to society with a new status). The pivot occurs in the middle phase, which Turner called the stage of liminality, from the Latin limin, meaning “threshold.” In the liminal state, “the very structure of society is temporarily suspended”: We float in ambiguity and evanescence, where we are neither one identity nor the other, no-longer-but-not-yet. The ultimate catalyst of liminality, Turner writes, is disorientation.

Among many rituals of lostness practiced by cultures all over the world, a particularly poignant one is observed by the Pit River Native Americans in California, where, from time to time, a member of the tribe will “go wandering.” According to the anthropologist Jaime de Angulo, “the Wanderer, man or woman, shuns camps and villages, remains in wild, lonely places, on the tops of mountains, in the bottoms of canyons.” In the act of surrendering to disorientation, the tribe says, the wanderer has “lost his shadow.” It is a mercurial endeavor to go wandering, a practice that might result in irredeemable despair, or even madness, but might also bring great power, as the wanderer emerges from lostness with a holy calling, before returning to the tribe as a shaman.

The most ubiquitous vehicle of ritual lostness—the most basic embodiment of disorientation—is the labyrinth. We find labyrinthine structures in every corner of the world, from the hills of Wales to the islands of eastern Russia to the fields of southern India. A labyrinth operates as a kind of liminality machine, a structure devised to engineer a concentrated experience of disorientation. As we enter the winding stone passages, and turn our focus to the bounded path, we disconnect from external geography, slipping into a kind of spatial hypnosis, where all reference points fall away. In this state, we are primed to undergo a transformation, where we pass between social statuses, phases of life, or psychic states. In Afghanistan, for example, labyrinths were the center of marriage rituals, where a couple would solidify their union in the act of navigating the twisting stone path. Labyrinthine structures in Southeast Asia, meanwhile, were used as meditation tools, where visitors would walk slowly along the trail to deepen their inward focus. Indeed, the archetypal tale of Theseus slaying the Minotaur in Crete is ultimately a story of transformation: Theseus enters the labyrinth as a boy and emerges a man and a hero.

In their modern incarnation, most labyrinths are two-dimensional, their passages bordered by low stacks of stones or mosaic patterns tiled into a floor. But as we trace the lineage of the labyrinth deeper into the past, searching for earlier and earlier incarnations, we find the walls slowly rising, the passageways becoming darker and more immersive—indeed, the very first labyrinths were almost always underground structures. The ancient Egyptians, according to Herodotus, built a vast subterranean labyrinth, as did the Etruscans in northern Italy. The pre-Incan culture of Chavín constructed an enormous underground labyrinth high in the Peruvian Andes, where they conducted sacred rituals in dark, sinuous tunnels; the ancient Maya did the same in a dark labyrinth in the city of Oxkintok in the Yucatán. In the Sonoran Desert of Arizona, meanwhile, the Tohono O’odham tribe have long worshipped a god called I’itoi, also known as the Man in the Maze, who dwells at the heart of a labyrinth. The opening of I’itoi’s labyrinth, a design frequently woven into the tribe’s traditional baskets, is said to be the mouth of a cave.

When Jean-Luc Josuat-Vergès entered the tunnels of the mushroom farm in Madiran with his whiskey and sleeping pills, he’d had notions of suicide. “I was low, having very dark thoughts,” was the way he put it. After he emerged from the maze, he found that he’d regained his purchase on life. He rejoined his family, where he found himself happier and more at ease. He began attending night school, earned a second degree, and found a better job in a town up the road. When asked about his transformation, he told reporters that while he was in the dark, “a survival instinct” had kicked in, renewing his will to live. In his darkest moment, when he desperately needed to transform his life, he traveled into the dark, surrendered to disorientation, preparing himself to emerge anew.

This post is adapted from Hunt’s new book, Underground: A Human History of the Worlds Beneath Our Feet.



The stars orbited each other like a pair of dancers, their sequined costumes glowing against a dark stage. Round and round they went, until the distance between them began to shrink. The closer they got, the faster they spun. And then, smack! The stars collided.

About 500 million years later, Mansi Kasliwal’s phone rang in the middle of the night in April. “Dear human,” a robotic voice said when she picked up. “You have received a new gravitational-wave alert.”

The signal from the cosmic dance had reached her at last.

Kasliwal, an astronomy professor at Caltech, jumped out of bed. Gravitational waves are ripples in the very fabric of the universe. It sounds bizarre, but space is elastic, and can be bent, warped, and squished. These gymnastics require some extremely powerful motions, such as the furious spinning of massive astrophysical objects. Their rotation is so intense that it sends waves coursing through the universe at the speed of light. The ripples move through everything they pass—galaxies, stars, even planets. And when they reach us, ultrasensitive instruments are now waiting to detect them.

Research stations broadcast the detections to astronomers such as Kasliwal and her team at Caltech, a rapid-response group trained to respond to sudden and intriguing observations in the night sky. When she gets the call, Kasliwal commandeers telescopes around the world to drop what they’re doing and search for the origin of the gravitational waves. The ripples are invisible, but sometimes cosmic collisions give off light. Astronomers can learn a lot more if they see that.

A day later, Kasliwal got another call. The universe, the same robotic voice said, was on the line again. This time, the evidence of cosmic dance moves had taken even longer to reach Earth, about 1.2 billion years.

“It’s so remarkable for two of these things to go off in the space of 30 hours,” Kasliwal says.

It’s remarkable how many of these events astronomers have recorded at all. Nearly 100 years passed between Albert Einstein’s prediction of gravitational waves and the first direct proof of their existence, in 2015. The discovery proved the wild-haired scientist right and opened the door to a brand-new field in astronomy. Astronomers detected gravitational waves again, and then again, and again. As of this week, gravitational waves have been detected more than a dozen times.

The discoveries don’t rely on brawny telescopes with broad antennas, but on delicate laser beams inside steel tubes in the ground, located at two sites in the United States and one in Italy. The beams travel up and down the tubes, bouncing off mirrors at each end. When no gravitational waves are present, the distance the light travels remains the same. But when the ripples wash over Earth, they stretch and shrink the steel of the tubes. The distortions are unfathomably imperceptible—the distance shifts by one-thousandth of the width of a proton—but these experiments are sensitive enough to detect them.

From these tiny signals, astronomers can discern some properties of their sources. Einstein’s equations predicted that massive, fast-moving objects could be capable of distorting space, and he was right. Astronomers have traced gravitational waves to black holes, the mysterious, invisible objects that vacuum up anything that comes near, and neutron stars, the bright, leftover cores of big stars that ran out of fuel and imploded, hundreds of millions of light-years away.

The organizations that operate the laser experiments, LIGO and Virgo, now share detections of gravitational waves in real time so that astronomers such as Kasliwal can chase the signals. The first few discoveries came from collisions between two black holes, which, as their name suggests, produce no light. Scientists were obviously thrilled about them, but they couldn’t follow up and pin down the source.

That changed about two years ago. LIGO picked up a wave of cosmic ripples. Two seconds later, a pair of space telescopes observed a sudden burst of gamma rays, the most energetic wave in the electromagnetic spectrum. The timing didn’t seem coincidental. Astronomers scrambled to pivot dozens of telescopes, in space and on the ground, toward the direction from which the gamma rays had come.

Their effort was worth it: They ended up observing a dazzling light show, the product of a collision between two neutron stars, in nearly every wavelength.

“It was absolutely majestic,” Kasliwal says. “It lit up the electromagnetic spectrum.” For the first time, astronomers saw the very source of gravitational waves.

After Kasliwal receives alerts for black-hole mergers at night, she goes back to sleep. She leaps into action for the other collisions, as she did for the two calls she received last month. The first was about a neutron-star merger. The second, if confirmed, is something scientists have never detected before: a mashup of a black hole and a neutron star. Kasliwal summoned an army of telescopes to search for both, but no corresponding light was found.

These days, the merger of a black hole and a neutron star is high on astronomers’ wish list.

They can only guess at the outcome in theoretical models. “Some say that they could be very, very luminous, but maybe in the infrared bands—not so much in the optical,” Kasliwal says. “Some models say maybe the black hole will just swallow the neutron star and you’re left with nothing, so there’s no electromagnetic emission at all.”

And what’s left over? Likely the same object that emerges when the dust settles after the other collisions: a new black hole. In cosmic standoffs, even between two neutron stars, black holes always win.

Aside from the inherent drama of space collisions, astronomers are looking to gravitational waves and the tremendous astrophysical objects that radiate them for answers to some big questions about our universe. They have long suspected that neutron-star collisions produce a stream of heavy elements, such as gold, silver, and platinum, and send them hurtling through the universe. The much-studied merger of 2017 showed some evidence of this.

“Most of the universe is pretty boring; it’s just hydrogen and helium,” Kasliwal says. “It’s [from] these spectacular, rare events that the rest of the periodic table is actually synthesized.” They might be responsible for infusing our world with “the elements that we have taken for granted and put on our wedding rings,” she says.

Scientists also want evidence for more phenomena that exist only in theory, and some of them sound pretty trippy. “There is something called the gravitational-wave memory effect, which is basically a kind of permanent displacement in space-time, which is still there after the gravitational waves have gone by,” says Salvatore Vitale, a physics professor at MIT and a LIGO scientist. “That comes out of Einstein’s theory of relativity, but it would be nice to see that directly.”

The key, as with most scientific work, is more. More cosmic mashups, more ruffles in the fabric of space, more beacons of radiation that broadcast the message Something incredible is happening. Kasliwal is ready.

“My phone’s always on and charged,” Kasliwal says. “Unfortunately, my husband may also wake up, but he enjoys the astrophysics enough that he’s putting up with it.”

After all, when it’s the universe calling, you kind of have to pick up.



The Greenland Ice Sheet is the world’s second-largest reservoir of fresh water sitting on the world’s largest island. It is almost mind-bogglingly huge. 

If Greenland were suddenly transported to the central United States, it would be a very bad day for about 65 million people, who would be crushed instantly. But for the sake of science journalism, imagine that Greenland’s southernmost tip displaced Brownsville, Texas—the state’s southernmost city—so that its icy glaciers kissed mainland Mexico and the Gulf thereof. Even then, Greenland would stretch all the way north, clear across the United States, its northern tenth crossing the Canadian border into Ontario and Manitoba. Kansas City, Oklahoma City, and Iowa City would all be goners. So too would San Antonio, Memphis, and Minneapolis. Its easternmost peaks would slam St. Louis and play in Peoria; its northwestern glaciers would rout Rapid City, South Dakota, and meander into Montana. At its center point, near Des Moines, roughly two miles of ice would rise from the surface. 

Suffice it to say: The Greenland Ice Sheet, which contains enough water to refill the Great Lakes 115 times over, is very large. And it is also falling apart.

A new study finds that the Greenland Ice Sheet added a quarter inch of water to global sea levels in just the past eight years. The research, published Monday in the journal Proceedings of the National Academy of Sciences, covers nearly 20 years previously not included in our detailed understanding of the troubled Greenland Ice Sheet. It finds that climate change has already bled trillions of tons of ice from the island reservoir, with more loss than expected coming from its unstable northern half.

“The glaciers are still being pushed out of balance,” Eric Rignot, a senior scientist at NASA and an author of the paper, told me. “Even though the ice sheet has [sometimes] been extremely cold and had low surface melt in the last year, the glaciers are still speeding up, and the ice sheet is still losing mass.”

The paper casts the transformation of the Greenland Ice Sheet as one of the profound geological shifts of our time. Scientists measure the mass of ice sheets in “gigatons”—each unit equal to 1 billion metric tons, or roughly the same amount of water that New York or Los Angeles uses in a year. Greenland, according to the study, has lost 4,976 gigatons of water since 1972. That’s enough water to fill 16 trillion bathtubs or 1.3 quadrillion gallon jugs. That much water weighs about 11 quadrillion pounds. (A quadrillion is 1 with 15 zeros after it.)

More worryingly, the paper finds that Greenland lost about half of that ice—roughly 2,200 gigatons—in the years between 2010 and 2018. The ice sheet has also failed to gain mass in any year since 1998.

This melting isn’t happening at a steady pace, in other words. Greenland’s demise seems to be accelerating. Think of Greenland as a huge inland ice sea, surrounded by faster-moving ice rivers (which are glaciers) that empty the sea and carry ice to the ocean. The paper finds that those rivers are speeding up, carrying ice out of the island’s core nearly twice as fast now as they did in the 1990s or 2000s.

That’s an alarming result, because it means glaciers might now be shrinking Greenland from the bottom faster than hot weather can melt it from the top. And researchers believe that bottom-melting glaciers are less stable and more prone to rapid collapse. “If there’s a risk of rapid sea-level rise in the future, it will be associated with glaciers speeding up, and not anything happening at the surface,” Rignot said.

The paper’s findings are stirring in part because they go much further back in time. “A lot of the publications [about Greenland’s mass] start in 2000 or 2002, some go back to 1992, but this is the first time we go back another 20 years,” Rignot said. Historically, most studies of Greenland combine data from radar flybys, GPS beacons, and laser or gravity-sensing satellites. But there’s not enough data from before 1992 to be useful, so that’s when estimates usually stop.

Rignot and his colleagues helped hit upon a new resource. The U.S. Geological Survey’s Landsat satellites have circled the planet nonstop since 1972, imaging every speck of land on Earth every 16 days. This archive—which is a kind of Earth-science version of taking a photo of yourself every day for years—includes hundreds of images of Greenland. Rignot and his team taught a computer how to read those pictures of its icy surface, zooming in especially on the dozens of glaciers that connect the interior ice sheet to the sea.

“It’s looking at two different pictures of a glacier, before and after. [In each frame,] the rocks don’t move but the glacier moves, so it can compare and cross-correlate image points,” Rignot said. “Then the algorithm searches around the window for where the pixel might have gone.”

The team ultimately used this technique to calculate the speed of Greenland’s glaciers from 1972 to 1992. Then they combined that data with modern observations of the ice sheet to estimate its historical mass. (They used a similar method to estimate Antarctica’s ice loss in a paper published earlier this year.)

Rignot and his colleagues relied on another new resource too: OMG!

As in, literally, the project is named OMG, short for Oceans Melting Greenland. OMG is a five-year NASA mission, started in 2016, to study how warmer oceans are eroding Greenland’s waterfront glaciers. Rignot helps lead it. “Thanks to OMG, we’ve been able to construct a [bedrock] model of Greenland that is pretty good under the ice, and is very, very good underneath the ocean,” he said.

Brad Lipovsky, a glaciologist at Harvard who was not connected to the research, said in an email that the results “seem plausible at first glance,” but that scientists would need to carefully check some of the team’s methodology. The overall story of Greenland, he said, is that the ice sheet’s flow is slowly accelerating. This “makes sense,” he said, “because it takes the slowly flowing ice sheet a lot longer to respond than the rapidly evolving atmosphere.”

Rignot believes that the new study should make glaciologists look anew at the speed with which Greenland could collapse. The ice sheet’s bleeding-out could eventually raise global sea levels by as much as 25 feet. So the key question, Rignot said, is “How fast can you make these entities fall apart?” The answer will matter to all of us. The surface of Greenland doesn’t have to move through magic to other parts of the world—already, today, its deluge is on its way.



Angela Post wasn’t supposed to study hemp. The North Carolina State University agriculture researcher focuses on small grains such as wheat and barley. But after the 2014 farm bill allowed states to investigate hemp, it became clear the seeds were lucrative. Post had the right equipment to study them, so the job was hers.

At first, Post thought hemp would get as much attention as the other alternative crops she and her colleagues dabble in. “We didn’t know how fast it would grow,” she says. Once the work garnered the attention of hundreds of would-be hemp farmers, “that’s when we got a sense it was something bigger than anticipated.”

Since then, Post’s work has expanded beyond hemp seeds—and her expertise—to fiber and flowers that contain cannabidiol, or CBD, which is extracted for use in seizure medications and over-the-counter tinctures. But there’s no turning down hemp studies if you’re an agricultural researcher in one of the states where residents might want to grow the crop, including North Carolina, Vermont, and Kentucky.

Hemp used to be farmed across the United States, but thanks to its association with the psychoactive form of cannabis, the government banned the crop from commercial and university fields for most of the 20th century. Now hemp could once again become an American staple. For that to happen, researchers like Post—employees of land-grant universities, which are located in every state and are federally mandated to help American farmers succeed—can fill in the knowledge gaps that have appeared and widened over decades. “We get tens and tens of questions each week that we can’t answer,” says Post.

These gaps include how best to plant hemp, what varieties to use, which insects and weeds are most likely to cause problems, and, most important of all, how farmers can turn a profit.

These are big questions. The answers have been stymied by the fact that, until recently, the Drug Enforcement Administration classified hemp as Schedule I, which meant fines and jail time for unauthorized possession and regulations that made experiments extremely challenging. While some research exists—especially from Europe and Canada, where hemp science has been legal since the 1990s—the work doesn’t always translate across environments. And as much as researchers had accomplished since the 2014 farm bill, they weren’t ready for the 2018 farm bill, which was signed into law by President Donald Trump in December.

The bill legalizes the crop, allowing any farmer to grow it—whether or not they know how. That’s why NC State’s research approach is, as Post puts it, “all hands on deck.”

Two hundred years ago, cannabis filled the fields of American farms. It also altered the minds of the American public. Often called “hashish,” the plant went into candies and other foods, and went largely unregulated through the 19th century.

But in the early 1900s, around the same time the temperance movement was crusading against alcohol consumption, many Americans adopted the xenophobic assumption that Mexican immigrants were committing cannabis-fueled crimes. This led western states with a sizable Mexican population to criminalize the plant, and 29 states eventually banned it. The racist fears spread all the way to Capitol Hill. In 1937, Congress passed a bill that taxed cannabis importers the equivalent of about $400 a year in 2018 dollars and slapped rule breakers with up to five years in prison and fines that, today, would equate to $35,000.

In 1971, the federal government classified cannabis as a Schedule I drug, which includes those narcotics deemed to have the highest potential for abuse and no accepted medical use. Five years later, researchers realized cannabis ought to be classified as two subspecies. One, now recognized as hemp, produces CBD in abundance but very little of the psychoactive compound tetrahydrocannabinol, or THC. But since hemp was already stuck on the Schedule I list, it wasn’t going to sprout from American farms again anytime soon.

The United States kept importing hemp, however, a practice that continues today. The plant’s fibers are good for insulation, fabric, and carpet. The seeds can be eaten or pressed for oils used in cosmetics or paint. Or, if growers plant certain varieties, they can collect CBD. In 2017, America imported $67.3 million worth of hemp-seed and fiber products, and the CBD market was worth nearly $200 million.

To see if the United States could reenter this market, Congress allowed states to try growing the crop in the 2014 farm bill. (Farm bills, typically renewed every five years, are the tools through which the country’s agricultural and nutritional policies are set.) Under the legislation, researchers could study hemp if their state legalized and regulated it. For this to work, state governments, departments of agriculture, and the DEA had to collaborate. This process was often bumpy and put the onus of problem solving on the researchers.

That’s what happened to Heather Darby, an agronomy professor at the University of Vermont—a land-grant school in a state that legalized hemp. Darby was eager to start hemp projects, but when she approached the Vermont Agency of Agriculture, Food, and Markets and the local DEA office to file requests, she was stalled by bureaucracy. For example, the DEA paperwork she needed was only formatted for marijuana-research requests, not hemp. Navigating these oversights, Darby says, “was the biggest barrier.”

Even in North Carolina, a state that’s been relatively proactive about allowing hemp, Post chose to keep her research projects small her first year. There was a lag in the state law that would legalize the work, and she risked getting arrested if police found her driving around with hemp buds.

Then there were issues with funding. Researchers typically get money from the federal or state government. But the 2014 farm bill didn’t allocate funds for hemp the way it did for, say, citrus disease. And since land-grant universities are federally backed, administrators have been hesitant to funnel their budget toward a Schedule I drug.

As such, hemp researchers have had to get financially creative. For example, the University of Kentucky—another land-grant school—funds hemp research through private companies, says David Williams, a plant and soil scientist. Though many private investors ask for study results to be proprietary, Williams claims that the vast majority of the research produced by these partnerships has been made public.

At the University of Vermont, however, Darby has mostly seen private offers where the information can’t be shared. To her, that agreement runs counter to her job description. “My goal through the University of Vermont is to make sure whatever we’re doing is for the public good,” she says, which has “made it difficult for us to secure funds.” To help, Darby launched a public, crowdsourced campaign in 2016 with the goal of raising $25,000. As of January, the campaign was only a quarter of the way there.

Post is part of the minority whose work is covered by state and federal funding. The North Carolina Department of Agriculture granted her more than $100,000 in the past two years, and in 2018 she also won a one-time, $16,000 grant from a U.S. Department of Agriculture fund set aside for pesticide research.

While several of her requests were successful, Post understands that entering a competitive grant-application pool with a crop as new as hemp can be intimidating. “I think people, from what I’ve seen, are afraid to put that time and energy and effort into a big proposal knowing the odds,” she says. “It’s already hard with corn and soybean, so it’s daunting for a minor crop.”

Amid all this confusion, hemp scientists are trying to unravel the intricacies of farming the plant. Most are starting with two key strains that are used to make fiber and seed. For these strains, some of the groundwork is set, thanks to relevant research in Europe and Canada. Scientists also know that fiber and seed hemp behave like other major U.S. crops—farmers sow individual seeds and machine-harvest the plants. And since fiber hemp was the only version previously farmed on an industrial scale in the United States, Post also tapped into the limited academic literature for a sense of the plant’s basic qualities.

But those papers didn’t tell Post how to coax the optimal amount of hemp seed or fiber out of a North Carolina acre. So she, like scientists from other states exploring hemp, made the local environment her first research priority. Post looked at fertilizers to assess how much nitrogen, potassium, and phosphorus the crop needed. She tinkered with different seed and fiber varieties to see which produced the highest yield. Similarly, at the University of Kentucky, researchers calculated the row spacing and number of seeds necessary to produce five tons of hemp fiber an acre, the amount a field would have to produce to compete with other commodity crops such as corn, wheat, and soybeans.

Maximizing yields also means controlling weeds and pests. For hemp, this question is particularly important. Farmers can only legally spray a pesticide on a crop if the instructions list it for use on the product’s label, and no chemicals are approved for hemp. To help guide farmers to the right product, Post has permission to test pesticides on hemp. She is also looking at nonchemical solutions, such as seed and fiber varieties that quickly sprout converging foliage. The shade cast from these leaves could discourage weeds from taking root.

Research on CBD-intensive hemp is even spottier, but there’s a higher incentive to study it because of its value. “There is an absolute gold rush in that part of the industry, so any potential production or processing model you can ever dream up is being evaluated at some level across the United States today,” says Williams, who is planting mostly CBD-intensive hemp but also some fiber and seed varieties in order to learn how to optimize production.

One trick will be boosting how much CBD oil the plant’s flower buds produce. So far, it seems that coddling CBD hemp helps, but the best way to nurture the plants is unclear. Researchers are weighing whether to grow the plants from seed in the field or to reproduce them as clones in a greenhouse. Post is betting on the latter. Strangely, some of her plants—ones with identical genes—can end up looking different from one another, which she says makes her “really start to wonder” what is happening with the plant’s genetics.

In Vermont, Darby has assessed how different practices affect CBD concentration with the help of the university’s medical school. She anticipates research will evolve to look at hemp’s terroir, or the way its taste and smell shifts depending on its exact environment. This characteristic also plays out in beer hops—a plant closely related to hemp, hence Darby’s suspicion that the trait will carry. When this research arrives, it will require even more nuanced studies.

Terroir investigations are far away, however, because researchers are focused on “risk management,” Darby says. “If a farmer’s going to take this on, you want to be able to set them up for success. You don’t want them to be struggling for four years to figure out how to do it the right way.”

Despite all that researchers have learned in the past few years, Darby isn’t sure they are ready to fulfill their duty to farmers now that the 2018 farm bill has passed. (With the new legislation, hemp cultivation will still be tightly regulated, but federal oversight will now fall under the USDA.)

“It’s a disservice to farmers to not be ahead of the curve,” she says. “We’re not ready to help farmers do the best job growing these crops.”

The economics of hemp are also unclear. While CBD-intensive hemp could be the most financially rewarding, it also has the shakiest market. As of last fall, about 61 percent of the hemp grown in Kentucky under the 2014 farm bill was for CBD, and Williams is working to figure out how these ambitious investors are going to make money in the long run. Right now, he says, processors pay too much for the crop, and the prices are too volatile to last. He’s seen oil extractors pay anywhere from $2,000 to $10,000 an acre, and prices on the higher end are “just ludicrous” from a production and agriculture perspective.

Those prices incentivize farmers to plant only CBD hemp, which is untenable because a healthy farming economy needs diverse crops. Prices should fall and stabilize, Williams says, but until then, any particular income from CBD can’t be guaranteed.

Many of the questions about the hemp economy will begin to be answered now that the 2018 farm bill has passed.

Even in the states where hemp research has been well funded and pursued by several faculty members, there’s still hesitation about the crop’s future. In North Carolina, Post thinks growers will expand their business now that the government allows it. Investors who were waiting on federal approval will also step in, Post adds, and their production facilities will change the state’s agricultural landscape.

There are consequences for moving too fast. Post and other experts worry that some farmers will repeat earlier failures: In 2015, when North Carolina launched a pilot hemp-research program, the state allowed individuals to apply for growing permits at the same time as university researchers. The gamble on hemp worked out well for some. But according to the Rural Advancement Foundation International-USA, an organization that supports family-owned farms, farmers who are already in financial trouble tend to bet on operations that have both high rewards and high risks. Some of the North Carolina farmers who tried to grow hemp are $15,000 to $20,000 in debt.

“Some put a lot of money on the line and some have been rewarded,” Post says. “And in some cases, they lost their shirt.”



This post appears courtesy of Undark Magazine.



CAPE CANAVERAL, Fla.—Believe it or not, getting to space wasn’t the hard part.

In the past few years, SpaceX has mastered launching Falcon 9 rockets and putting payloads into space. The company has also perfected an intricate maneuver that returns rocket boosters to Earth, landing them gently on the ground or on a ship off the Atlantic coast, to be spruced up and used again. Last year, it launched more than 20 rockets into space without incident.

On Saturday morning, a Falcon 9 again soared above Kennedy Space Center, painting a streak of gold against the night sky, and deposited a spacecraft into orbit. After the launch was over, SpaceX engineers braced for the next hurdle. A mistake could put the spacecraft, the International Space Station, or both at risk.

“The ISS still has three people on board, and so this vehicle coming up to the ISS for the first time has to work,” Kirk Shireman, the manager of the ISS program, said in the days leading up to the launch. “It has to work.”

SpaceX manufactured the spacecraft, named Dragon, as part of a NASA program to return human space flight to American soil for the first time since 2011. There were no people on board this mission, only a space-suit-clad mannequin named Ripley, about 400 pounds of cargo, and a plush toy in the shape of Earth, a cute indicator that started to float when the spacecraft reached microgravity. But there could be humans on board as soon as this summer—if the mission goes well.

SpaceX has visited the ISS before. NASA contracts the company to deliver supplies and science experiments on another version of the Dragon spacecraft, designed only for cargo. When those capsules approach, a powerful robotic arm on the station, controlled by an astronaut inside, reaches out to grab them and pull them toward a port.

But the crew-friendly Dragon was designed for a far more complicated rendezvous. The ISS has been preparing for the arrival of a commercially built spacecraft such as Dragon for years. A new docking port was delivered to the station by SpaceX itself in 2016. Astronauts installed new wiring and even rerouted ventilation in this part of the station so that power and air could flow to the spacecraft once it was docked. “It was a massive modification with an incredible amount of hardware,” Susan Freeman, an ISS engineer at NASA’s Johnson Space Center, tweeted on Sunday morning.

The capsule is equipped with software, sensors, and lasers to autonomously guide it toward and then stick itself to a port. Astronauts on the station can transmit important information to the spacecraft’s computers as it nears, but the final docking is up to the Dragon.

After reaching space, the Dragon spacecraft circled the Earth 18 times, firing engines to put itself on a trajectory toward the ISS. When the capsule neared the station, it moved closer and then backed away, practicing a retreat designed for emergencies.

Then, just before 6 a.m ET on Sunday, about 260 miles above the northern coast of New Zealand, the Dragon spacecraft stuck itself onto the ISS. For the first time in nearly eight years, an American-made spacecraft designed to carry humans had arrived at humankind’s home in space.

Cameras on the ISS captured the steady approach. At first, Dragon appeared as a white blob against the matte black of space. As the distance between the two spacecraft shrank, the Dragon came into full view, its white exterior gleaming in the sunlight. A cover at the nose of the spaceship had been flipped open not long after launch, revealing a ring of springs. As the Dragon made contact with a port on the ISS, the springs absorbed the impact. On the port, a dozen hooks latched the capsule into place.

Back on Earth, SpaceX headquarters erupted in cheers at the sight. Elon Musk, the company’s founder, no doubt exhaled. The mission has scrambled his nerves. “To be frank, I’m a little emotionally exhausted,” a serious-faced Musk told reporters on Saturday, an hour after the launch. “Because that was super stressful. But it worked—so far. We have to dock with station; we have to come back. But so far, it’s worked.”

Here’s the view from the ISS, at left, and from Dragon, at right:

The @SpaceX Crew Dragon is attached to the @Space_Station! It’s a first for a commercially built & operated spacecraft designed for crew! #LaunchAmerica pic.twitter.com/ddck58TVnP

The ISS crew—Anne McClain of NASA, David Saint-Jacques of the Canadian Space Agency, and Oleg Kononenko of Russia’s Roscosmos—monitored the historic approach. After the Dragon docked, the crew members prepared to go inside. They conducted a series of checks, including an inspection of the airtight seal of the spacecraft and the air pressure inside a vestibule between them. Cameras inside the station showed the crew members floating around a square-shaped hatch, sliding their socked feet under wall railings to anchor themselves when they needed to use their arms.

Two hours later, they were ready. “Houston station, Dragon hatch opened,” McClain said. The scene, captured now on a camera inside the Dragon, was surreal. The astronauts, wearing protective masks, floated about the cabin, inspecting the interior and collecting readings of the environment. It was difficult to say who looked more out of place: Ripley the mannequin in a sleek white-and-black spacesuit, or the crew, in pale-blue polo T-shirts and loose pants.

Astronauts on the @Space_Station have opened the hatch on @SpaceX’s Crew Dragon spacecraft! The station crew can now go inside the first American spacecraft to autonomously dock to the orbiting laboratory. 🇺🇸 pic.twitter.com/z2rP5MWCqu

Only later, once their technical work was done, would the astronauts dress up in blue jumpsuits of their own for a more formal welcome ceremony. They floated into the capsule again, where McClain held up the plush Earth to the camera.

Before the launch, Russia seemed hesitant about SpaceX’s unprecedented maneuver. Roscosmos, which controls half of ISS, was concerned about the capsule’s docking software, which diverged from what other spacecraft have used to rendezvous with the station. NASA officials believed the software configuration was safe and wanted to move forward. It was an uncomfortable moment between the two nations, but just days before lift-off, Roscosmos gave its approval for the launch.

After the Dragon spacecraft’s seamless docking, Roscosmos offered a rather passive-aggressive message of congratulations on Twitter. It commended NASA, but left out SpaceX, and added that flight safety must be impeccable.

The snub likely comes from the top. Dmitry Rogozin, the head of Roscosmos, doesn’t seem to be a fan of Musk. Last month, Rogozin told Russian media that he doesn’t believe SpaceX can build better rocket engines than Russia can. “Musk is not a technical expert in this matter,” Rogozin said. “He just doesn’t understand what this is about.” Musk responded on Twitter, pointing out that “I have been chief engineer/designer at SpaceX from day 1.”

For Musk, the docking speaks for itself. But the mission isn’t over yet. The Dragon spacecraft will spend the week at the ISS. The crew will eventually replace the new supplies with cargo destined for home. The hatch will be sealed up, and the spacecraft will prepare for more high-stakes maneuvers, including a fiery plunge through Earth’s atmosphere and a gentle parachute ride to the Atlantic Ocean.

If the Dragon returns home in one piece, SpaceX and NASA will spend weeks reviewing data and completing more tests. Ripley’s ride will be over, but another journey—far more thrilling and nerve-racking—may follow.



There was something odd about the bushbuck, the scientists finally decided.

They’d been watching the small antelope in Mozambique’s Gorongosa National Park in the Great Rift Valley for years, and they’d noticed more and more of the normally cautious, wood-dwelling creatures brazenly grazing on the plains, where they would be easy prey. They were seeking out the lush food that grows in sunny, open places; they were fearless. And they had reason to be, says Justine Atkins, a graduate student at Princeton University who studies antelope at Gorongosa, because almost every predator in the national park had been dead for more than a decade.

In a new paper in Science, Atkins and her collaborators show that there is now a population of bushbuck in Gorongosa that prefer to graze in the open, that their numbers have been increasing, and that they are, by and large, better fed than their woodland brethren. But on some level, they still possess that age-old fear. When scientists released the scent of a lion on the wind or played the growl of a leopard, the bushbuck headed for the trees.

Mozambique’s years of civil war, which ended in 1992, wiped out every predator from the national park except for a small handful of lions. Hungry soldiers and desperate civilians killed most of the herbivores as well, though with more than a decade of restoration work, some have slowly begun to recover. Still, with a radically changed ecosystem may come radically changed behavior.

Ecologists have theorized that when predators are eliminated, prey species will start using resources they would normally have forgone as too risky. This idea had been tested in computer models and in ecosystems such as tide pools, where researchers could remove the predator just by picking it up. The civil war and the decimation of Gorongosa’s wildlife provided a rare, if tragic, opportunity to watch these dynamics on a grand scale, with mammals and large predators.

To confirm their impressions, the researchers put radio collars on bushbuck to track their grazing locations over time. This soon revealed that only some antelope were behaving fearlessly, while others consistently played it safe. To see whether the fearless ones were getting a nutritional boost—an enticement into risky behavior—they sequenced plant DNA from the bushbuck’s feces and developed a detailed picture of their diet. The hunch was correct: Plains-grazing bushbuck were consuming more calories and drastically more protein than woodland-grazers were. They also seemed to be overgrazing plants that would have had refuge from bushbuck in the past, signaling another potential shift in the ecosystem.

As the numbers of large carnivores around the world shrink, the study suggests that the world they leave behind will change, perhaps fairly swiftly, in their absence. There will, sadly, be many more chances to observe such shifts, in ecosystems all over the planet. However, whether those changes persist depends on what happens next.

Curious whether the bushbuck would respond to the signs of a predator, Atkins and her colleagues devised an elaborate spoof: For 48 hours, they deployed speakers playing a leopard’s cries and planted mock lion feces and a repellent developed to mimic the smell of carnivores around the antelopes’ habitat. They found that the animals reverted to grazing in the woods, suggesting that they aren’t immune to the implications of such cues.

That will be an interesting behavior to watch over the coming years, says Atkins. Several follow-up experiments are under way, but “the main thing is seeing what happens to this population as the apex predators are reintroduced to Gorongosa,” she says.

African wild dogs were one of the predator species destroyed during the war, and in the summer of 2018, 14 were released into the park. Interestingly, they appear to be eating mainly bushbuck, which suggests that the species’ days in the sun may be numbered.





Earlier this month, tiny green plants sprouted on the moon.

The plants arrived as cotton seeds, tucked inside of Chang’e 4, a Chinese spacecraft that had landed, in a historic first, on the far side of the moon, the side that never turns toward Earth. The seeds came with the comforts of home: water, air, soil, and a heating system for warmth. Huddled together, the seedlings resembled a miniature, deep-green forest. A hint of life on a barren world.

And then, about a week later, they all died.

Lunar night had set in. Without ample sunlight, surface temperatures near the spacecraft plummeted to –52 degrees Celsius (–62 degrees Fahrenheit). The sprouts’ heating system wasn’t designed to last. The plants froze.

Outer space, as you might expect, is not kind to plants, or people, or most living things, except maybe for tardigrades, those microscopic creatures that look like little bears. If you stuck a daisy out of the International Space Station and exposed it to the vacuum of space, it would perish immediately. The water in its cells would rush out and dissipate as vapor, leaving behind a freeze-dried flower.

China’s experiment marked the first time biological matter has been grown on the moon. (There is biological matter on the moon already, in what NASA politely refers to as “defecation collection devices.”) But plants have blossomed in space for years. They just need a little more care and attention than their terrestrial peers.

The first to flourish in space was Arabidopsis thaliana, a spindly plant with white flowers, in 1982, aboard Salyut, a now defunct Russian space station. The inaugural plant species was chosen for practical reasons; scientists call Arabidopsis thaliana the fruit fly of plant science, thanks to a fairly quick life cycle that allows for many analyses in a short time.

Now, plants grow on the International Space Station, humankind’s sole laboratory above Earth. They are cultivated inside special chambers equipped with artificial lights pretending to be the sun. Seeds are planted in nutrient-rich substance resembling cat litter and strewn with fertilizer pellets. Water, unable to flow on its own, is administered carefully and precisely to roots. In microgravity, gases sometimes coalesce into bubbles, and overhead, fans push the air around to keep the carbon dioxide and oxygen flowing.

The most advanced chamber on the station, about the size of a mini fridge, has precise sensors monitoring the conditions inside, and all astronauts need to do is add water and change filters. Scientists back on the ground can control everything, from the temperature and humidity to levels of oxygen and carbon dioxide.

Plants did not evolve to exist in this unusual setup. But astronauts have grown several varieties of lettuce, radishes, peas, zinnias, and sunflowers, and they do just fine. “Plants are very adaptive, and they have to be—they can’t run away,” says Gioia Massa, a scientist at NASA’s Kennedy Space Center who studies plants in microgravity.

Scientists were surprised to learn that the lack of gravity, the force that has shaped our biological processes, doesn’t derail plants’ development. On Earth, plants produce a filigree-like pattern of roots, as they grow away from their seeds in search of nutrients. Scientists had long assumed the movements were influenced, in part, by the force of gravity. On the International Space Station, roots exhibited the same pattern, without gravity as a guide.

“Plants don’t really care about the gravity so much if you can get the environment right,” Massa says.

For NASA, the growth chambers on the space station are the predecessors of extraterrestrial farms beyond Earth. If human beings ever travel to another planet, they will need enough food for the journey. NASA has spent years perfecting thermo-stabilized or freeze-dried entrées and snacks for astronauts on the International Space Station, from scrambled eggs to chicken teriyaki. The meals are meant to last, but they wouldn’t survive the long journey to Mars, says Julie Robinson, the chief scientist for the International Space Station.

“We don’t have a system today that would preserve all the nutrients in food for all that time, even if it was frozen,” Robinson says.

Future Mars astronauts will likely bring with them an assortment of seeds, a Svalbard-like vault to kick-start the first generations of crops. None will be able to grow in Martian soil, which resembles volcanic ash; it’s devoid of the organic matter—formed on Earth by generations of decomposed plants—that supports life. It also contains chemical compounds that are toxic to humans. Astronauts could flush out the toxins with their own chemical solutions and convert the soil into something workable, but it may be easier to replicate the growth chambers on the International Space Station instead.

On Mars, plants will likely grow in climate-controlled greenhouses, from nutrient-rich gels and under bright lighting, with water delivered through liquid solutions at their roots or by a fine mist released from the ceiling. And anyone living on Mars will need many of these alien gardens; you can’t grow a salad from a petri dish.

Astronauts have already made a space salad. In 2015, astronauts on the space station were allowed to try the leaves of a red romaine lettuce that was cultivated in NASA’s first fresh-food growth chamber. They added a little balsamic dressing and took a bite. “That’s awesome,” the NASA astronaut Kjell Lindgren said then. “Tastes good.”

No one on Earth has sampled a space vegetable yet, according to Massa. Some plants grown on the station are sent down to the ground for study in the lab, but they usually come back frozen or preserved in a chemical solution. “Frozen would be better, but I don’t think lettuce popsicles will be very popular anytime soon,” she says.

NASA scientists are thinking about more than nutrition in these experiments. Growing plants just for the sake of growing plants is quite nice. Research has shown that gardening is soothing and can be beneficial for good mental health. Future deep-space astronauts, cooped up in a small spaceship for years with the same people, will need all the soothing activities they can find. Plants, especially flowers, grown not for consumption but for decoration may help far-flung astronauts feel connected to the comforts of Earth.

“There’s a great deal of joy in growing and watering the plants and producing a flower,” Robinson, the ISS scientist, says. “There can also be some real sadness if plants you’ve been cultivating are not successful and are dying on you.”

Anyone who has enthusiastically purchased a succulent and witnessed it inexplicably wilt days later might relate. Imagine the magnitude of that disappointment on Mars, where the closest store is all the way across the solar system, and the only option is to grow another one.



Imagine you’re on a small boat in the middle of the open ocean, surrounded by what looks like a raft of plastic. Now flip the whole world upside down. You remain comfortably attached to your seat—the abyss towers above you, and all around, stretching up from the water’s surface, is an electric-blue meadow of life. What you thought was plastic is actually a living island. This meadow is made up of a diverse collection of animals. The most abundant are blue buttons and by-the-wind sailors, with bright-blue bodies that dot the sky like suns, and deep-purple snails found in patches so dense one scientist described collecting more than 1,000 in 20 minutes.

This is the neuston, a whole ecosystem living at the ocean’s surface. I once stumbled upon a raft of neuston when a storm blew it ashore in California. Many neustonic animals are vibrant highlighter colors, and the sand was saturated in bright blues and pale pinks. Together, these small creatures may function like upside-down coral reefs: an oasis of shelter and life far out to sea. As far back as the Cold War era, scientists were describing these colorful and important ecosystems, yet they still remain all but unknown. But now, as efforts to clean the ocean of plastic start up, our ignorance is putting this ecosystem at risk.

The neuston is home to more than blue buttons and bright snails. Erupting through the lawn of blue are crackling purple, red, gold, and yellow strands. These are Portuguese man o’ wars, whose tentacles stretch like lightning from the meadows of blue and pink. And among them, dragons roam.

Small nudibranchs, known as blue sea dragons, feast on blue buttons and man o’ wars, using their winglike cerata to grab and hold onto their tentacled prey. There are sea anemones, barnacles, copepods, color-changing crabs, specialized bacteria, even bugs, all living in this inverted reef in the middle of the open ocean. (Organisms that live exclusively by floating at the surface of the water are called pleuston, while neuston is a broader term, referring generally to the sea-surface ecosystem, which is why I chose to use it here.)

Just like reefs on the seafloor, this ecosystem does not stand apart from the open ocean around it. The neuston is a nursery for multiple species of larval fish and a hunting ground for paper nautilus octopuses. It supports sunfish, leatherback turtles, and diverse ocean grazers, which frequent these islands, relying on them as a food source. At night, soft-bodied jellies rise up to join the neuston, sparkling like fireflies. But all of this, from the blue sea dragons to the by-the-wind sailors, is in peril.

When I learned about the Ocean Cleanup project’s 600-meter-long barrier with a three-meter-deep net, a wall being placed in the open ocean, ostensibly to collect plastic passively as the currents push water through the net, I thought immediately of the neuston. How will it be impacted? But in the 146 pages of the Ocean Cleanup’s environmental-impact assessment, this ecosystem isn’t mentioned once.

I was disturbed by this omission. Though the neuston isn’t known to many people, it is certainly known to marine biologists. Evidence that the Ocean Cleanup knows about the neuston is clear from a table reporting animals in the vicinity of the Ocean Cleanup deployment area, where both blue buttons and by-the-wind sailors are listed. But the ecosystem itself is never discussed. By omitting the neuston from its assessment, the project is overlooking the habitat it could be impacting most, and there is no sense of what the damage might be. Because the impact report didn’t provide any answers, I went looking for my own.

There are few contemporary reviews of whole-ocean neuston ecosystems. I started with smaller studies on specific animals and worked my way through their references. One reference, in Russian Cyrillic, came up again and again. This made sense. I knew the United States and the U.S.S.R. had both developed extensive oceanographic-research programs after World War II, but each region published in its own language, making overlap difficult. I sat with a librarian for nearly an hour, hunting this study down. Finally, we found it: a 1956 study published in the U.S.S.R., in Russian, by an oceanographer named A. I. Savilov. This led us to another study of his from 1968, mercifully translated into English. Savilov spent his career studying the neuston by conducting extensive surveys all across the Pacific and synthesizing this work into a map of the open-ocean surface ecosystems.

Savilov described seven unique neuston meadows in the open ocean, each with its own unique composition of animals. Just as rainforests differ from temperate forests, these neustonic ecosystems are unique. And one of them, Neuston Ecosystem 2, is in exactly the same spots as the “garbage patches” where the Ocean Cleanup plans to operate. This makes sense: The neuston ecosystem is entirely passive—floating just like plastic—and evolved over millions of years to thrive within these regions, where surface-bound objects collect. But these ocean gyres are precisely where the Ocean Cleanup project intends to operate, and where it is currently testing its first system.

The Ocean Cleanup was founded with the vision of clearing the world’s ocean of plastic. The project’s goals are ambitious, and it plans to launch approximately 60 systems to reduce “the amount of plastic in the world’s oceans by at least 90% by 2040.” It is starting with what’s known as the Great Pacific Garbage Patch, but is already scoping out other targets, too.

Even without an environmental-impact assessment, it’s easy to imagine what will happen if the Ocean Cleanup succeeds. Neuston and plastic co-occur: They’re in the exact same spots. Cleaning up 90 percent of the plastic using the current method means potentially destroying 90 percent of the neuston.

This reality is built into the project’s design. Plastics mimic the neuston world—it’s buoyant, surface bound, and rubbery. When wind and ocean currents sweep neuston through the project’s barrier, animals such as blue sea dragons will be corralled and confined in a huge trap, their fragile bodies colliding with hard and jagged surfaces. They cannot sink below or swim around. They will be suffocated, crushed, and hauled to landfills.

The fact that we don’t have a solid understanding of the neuston ecosystem is even more worrying: We will have very little “before” data to compare the Ocean Cleanup’s impact against. By deploying its system right now, the project could rob the world of an entire ecosystem that we don’t understand and may never get back.

The Ocean Cleanup says it wants to protect animals at the ocean’s surface from plastic, but neuston is the ecosystem of the ocean’s surface. There is a reason turtles and sunfish eat floating surface plastic: It looks like neuston. Using these wall-like barriers to collect plastic in spite of the neuston is like clear-cutting a canopy in the name of helping a forest. There is no point in collecting plastic if by the end there is nothing left to conserve.

I believe that the founders of the Ocean Cleanup mean well and that the engineers involved are passionate about protecting the ocean. When I shared my concerns about the neuston, the organization was responsive, but said that its assessment had already estimated impacts to relevant groups of animals based on the best data it could find. That’s far from reassuring. We cannot monitor this ecosystem with our current technology, and millions of animals may die and dissolve before the scale of destruction is fully understood.

Here is one alternative solution: Place a modified design closer to plastic sources—river mouths and bays—to catch plastic before it enters the open ocean. Choose a place where it can be monitored and corrected for environmental impact. It seems too great a risk to disrupt the whole surface ocean ecosystem so severely, when it is also one we barely know. The neuston is an alien world, as bizarre as it is beautiful. It’s still possible to avoid destroying this strange ecosystem, wedged between sea and sky.



In 2001, Alice Gorman returned home after a long day of work, grabbed a cold beer, and settled into a chair on the veranda of her house in Australia. She lifted her head and stared at the night sky. Countless milky-white stars glittered in the velvety darkness. Her mind began to churn.

“I just started to think about the fact that there’s a lot of space junk up there, and wondered what its heritage value was,” Gorman recalls.

It sounds like an unusual thought, but not for Gorman. Gorman is an archaeologist. Her job is to examine artifacts and determine their place in human history. Earlier that day, Gorman had been at a field site in Queensland, inspecting millennia-old relics used by Aboriginal peoples.

After that evening on the veranda, Gorman began researching the heap of objects people have lofted above Earth—satellites, telescopes, space stations. She read about gravity and the natural forces that engineers use to deliver objects to space and keep them there. Perhaps, she wondered, the products of the space age deserve the same kind of care and commemoration as relics of the ancient past. Perhaps they, too, could be preserved in thoughtfully curated museum exhibits—not on Earth, but right there in space.

Imagine that experience: Future generations, equipped with advanced spacefaring technology, blast off from the planet and head toward an abandoned space station. Their spaceships, propelled by fuel we can only imagine and coated in radiation-blocking material we can’t yet design, match the speed of the spacecraft and sidle up to it. The smooth voice of a museum curator fills the capsule. The passengers listen as she speaks, retelling the story of the space station, the nations that built it, and what happened to them all those years ago.

When the tour is over, the sightseers zip over to a museum building floating nearby, dock their spacecraft, and clamber inside. They grab a cup of hot chocolate from the café and browse the gift shop, wondering which trinket—space junk fragment?—will best commemorate their experience.

As it happens, commercial companies around the world are actively thinking about how to manage the thousands of objects in low-Earth orbit. In September, a British satellite unleashed a net and snared a piece of space debris 180 miles above Earth, the first demonstration of its kind. The goal of such technology is to remove defunct hardware and reduce the risk of collisions between objects, which produce even more debris. But the technique could be reconfigured to protect objects instead. Future satellites could capture aging spacecraft and then drag them up into higher orbits, where the pull of Earth’s gravity is weaker. There they will stay, safe from a fiery plunge into the planet’s atmosphere, until we develop the technology to visit them.

Unlike Earth, outer space is quite good at preserving human-made objects. It has no humid air to warp materials or encourage mold, no threats of natural disasters or accidental fires, no pesky teenagers to scribble graffiti.

Sure, cosmic radiation—the unseen, constant barrage of energetic particles from the sun and beyond—can degrade even the hardiest metals after long-term exposure. Strikes from micrometeoroids, tiny space rocks that travel at high speeds, can also pack a punch. But the cosmic damage to spacecraft is minimal. After all, they were built to withstand the extreme conditions of space.

But before we can think about building space museums, we should determine which of these objects we actually want to preserve.

There are a few obvious candidates: the Hubble Space Telescope, which has spent nearly three decades peering into the far reaches of the universe and returning exquisite photographs of the first stars and galaxies. The Kepler telescope, which found thousands of planets, including some that could support life, beyond our solar system, before it ran out of fuel last month. The International Space Station, humankind’s home away from home, which may someday be abandoned and crashed into the ocean, like other space stations that ran their course.

The ISS is a particularly interesting artifact; it will be remembered not only as a masterpiece of engineering, but as a rare symbol of cooperation among rival spacefaring nations.

“I think historians might look back at the post–Cold War era and look at the ISS and say, you know what, actually that was a pretty amazing thing they managed to make happen,” says Stuart Eves, an engineer and an advocate for the creation of space museums. Eves previously worked at Surrey Satellite Technology, the company that manufactured the satellite that lassoed space debris earlier this fall.

The list should also include the earliest versions of the satellite technology that the world relies on today. There’s Vanguard 1, the first solar-powered satellite, launched in 1958. Telstar 1, the first active telecommunications satellite, in 1962. Syncom 3, the first of hundreds of communications satellites, which thrilled Americans when it brought the Tokyo Summer Olympics to their televisions, in 1964.

Eves likened the narrative of these advancements to museum exhibits of early transportation. “You can visit terrestrial, conventional museums and you can see old cars, planes, trains, boats,” he says. “It would be a real shame if some of the really iconic spacecraft that have contributed enormously didn’t have some sort of permanent record.”

It’s too late for some objects, such as Sputnik, the first-ever satellite in space, which plummeted back to Earth several months after the Soviets launched it in 1957. But many historic firsts are still ahead; Bangladesh launched its first satellite just this year.

The moon offers a cornucopia of artifacts for space archaeologists to consider. Tranquility Base, the site of the Apollo landing, is akin to the slab of 3.7-million-year-old volcanic ash in Laetoli, Tanzania, that preserved the footprints of early humans who stood upright and walked on both legs, says Michelle Hanlon, the co-founder of For All Moonkind, a volunteer organization of lawyers who specialize in space law. Tranquility Base is the “cradle of our spacefaring civilization,” Hanlon says.

According to a NASA catalog, dozens of human-made objects from the Apollo era remain, from scientific equipment and batteries to nail clippers and “defecation collection devices.” In the last decade, China, India, Japan, and a consortium of European nations have sent spacecraft to the moon and deliberately crashed them into the surface when their missions ended, scattering pieces of hardware across the regolith.

Under current regulations, a space museum brimming with relics from different cultures would be nearly impossible.

According to the United Nations Outer Space Treaty, the international principles that have governed the use of space since the late 1960s, space is for everyone. “Outer space, including the moon and other celestial bodies, is not subject to national appropriation by claim of sovereignty, by means of use or occupation, or by any other means,” the accord states. On top of that, all objects sent into space remain the property of the nations that launched them. On top of that, as the number of objects in low-Earth orbit swelled in the last decade, UN officials began advising satellite operators to dispose of their satellites after 25 years.

Some groups, like For All Moonkind, are trying to foster some agreement in the space community. Hanlon and her team of space lawyers have spent the past year lobbying lawmakers and CEOs alike about the need for a global treaty on space heritage. So far, she has received formal or verbal reassurances from several commercial companies seeking to send robotic missions to the moon in the next few years because, well, could you imagine if one of them crash-landed on Neil Armstrong’s footprints? The effort has been less successful with national governments, Hanlon says.

“We haven’t agreed to a space treaty since the ’60s, so it’s not going to be easy,” she says. “Ultimately, we would see a convention on universal heritage and outer space, something that can travel with us as we become a truly spacefaring species.”

Let’s say Hanlon gets her wish, and the technology required to assemble the first space museum, at long last, exists. How would we build one?

The easiest location may be the moon, where artifacts are not hurtling through space at 17,500 miles per hour. Hanlon envisions an extensive cable-car system that transports tourists across historic sites, from the site of Luna 2, the Soviet spacecraft that landed in 1959, to assorted Apollo bases established in the 1960s and 1970s. “There’s no danger of contaminating or disrupting the site at all, because you’re floating over it,” Hanlon says.

An off-world museum presents bigger challenges. In the space above Earth, curators must contend with some significant natural forces. Home to a range of objects from communications and military satellites to the ISS and Hubble, this region is not a perfect vacuum. Low-Earth orbit contains enough air particles to produce some drag and slow down objects. Over time, the atmospheric drag can reduce the speed so much that the objects begin to feel the tug of Earth’s gravity.

Left untouched, these objects will drift closer and closer to the planet until they hit the atmosphere and burn up. Some spacecraft, such as the ISS, can periodically lift themselves to higher altitudes, but many satellites lack the propulsion systems to do the same. Eventually, most of what goes up must come down.

To avoid this fiery fate, satellites could latch onto aging spacecraft and drag them into higher orbits, extending their lifetimes by hundreds of years. Future generations, equipped with more advanced spaceships, could hop from one object to another, like a space safari. Perhaps, when they reach a long-empty ISS, they could step inside. Eves, the satellite engineer, imagines curators installing long plastic tubes that unfurl throughout the station like tentacles. Tourists would glide through and inspect the provincial habitat that kept their ancestors alive in space. And keeping visitors confined to tubes would eliminate the need for a Please don’t touch sign.

For a more conventional museum arrangement, satellites could herd spacecraft into specific locations in space known as Lagrange points, where natural forces cooperate to keep objects in stable orbits. Engineers have already used one of these points, known as L2, located about a million miles from Earth. In 2001, NASA launched a probe designed to study the leftover radiation from the Big Bang to this spot. The spacecraft kept its back to the sun and its front to deep space, a configuration that provided an unobscured view of the cosmos. The James Webb Space Telescope, the scientific successor to Hubble, will reside in L2 when it launches in 2021.

Objects in L2 would be safe from Earth’s gravitational tugs. Curators could group artifacts here based on certain themes and eras, or lump everything all together.

Gorman, the space archaeologist, says she has mixed feelings about this kind of organization. It forces curators to decide whether they want to protect artifacts where they are, as they would with an ancient monument on Earth, or install them in a museum exhibit far from their original homes. “If you take Vanguard 1 out of its orbit, then you’ve taken away something from its cultural value,” she says.

The clustering of spacecraft at distant points could have a rather unusual effect on the space environment. The fewer objects in orbit around Earth, the smaller the risk of collisions. Space museums may find support among researchers who believe this region is growing dangerously crowded.

“One big collision at geostationary orbit could actually inconvenience us enormously,” says Brian Weeden, a space-policy expert at the Secure World Foundation, a nonprofit group that promotes peaceful uses of space. “The case for curating some of the old satellites would actually perhaps alleviate that problem a little.”

Regardless of location, Gorman thinks space museums shouldn’t charge admission. “By the time you’ve been able to afford to go up into space and visit the museum orbit or the actual spacecraft, you’ve probably already spent a reasonable amount of money,” she says. “It’s a bit more like a national park—once you get to the park, you don’t have to pay more money to experience the landscape.” As for how the museums will make a profit with this business model—well, that’s less fun to daydream about.

If the idea of a space museum still seems too unrealistic, consider that humankind went from launching its first satellite into the space above Earth to landing a rover on Mars in just 40 years. Perhaps in the next 40 years, humans will find themselves surrounded by favorable conditions for space travel—money, political will, and technology—and, at last, leave the comfort of the planet’s orbit to travel across the solar system. Maybe on their way out, astronauts will swing by the local museum, located a million miles from Earth. They’ll take a quick spin through an exhibit or two, buy some chalky astronaut ice cream, and blast off into the unknown, taking with them the memory of the ancient spacecraft that paved the way for their own.



Thousands of years ago, small groups of humans across the globe began to transition from hunting and gathering their food to raising and planting it instead. They milked cattle, milled grains to make soft bread, and used new inventions like pottery to preserve meat and vegetables. And once they did that, they could start spicing up their speech by throwing some f and v sounds into the mix.

At least, that’s according to a new study published Thursday in the journal Science. The authors argue that sounds like f and v weren’t part of human language until farming appeared during the Neolithic age. Agriculture, they say, allowed humans to eat soft foods, which changed the way their jaws developed throughout life, which shaped the kinds of sounds their mouths were capable of making.

This shift would be an exception to a core rule of linguistics, called the uniformitarian principle, which posits that humans’ ability to use language has not significantly changed since language itself first appeared. “Basically, the uniformitarian principle is necessary to do historical linguistics,” Anthony Yates, a linguist at UCLA, told me. It’s hard to say when exactly humans started speaking, but most estimates place the date at least 50,000 years ago. Agriculture, meanwhile, sprung up during the Neolithic, some 12,000 years ago. The idea that humans weren’t using f’s and v’s for the first 38,000 years of our linguistic history is a striking rebuke to uniformitarianism.

Linguists spend a lot of time thinking about all the strange ways humans can shape their mouths, and how that affects the sounds they can make. Anthropologists believe that since at least the Neolithic, humans have been born with overbites (in which the top teeth come down over the bottom teeth) and overjets (in which the top teeth are positioned more forward than the bottom teeth). If a person’s teeth are exposed to a lot of wear and tear over her lifetime, her jaws will shift to put her teeth in an edge-to-edge alignment instead. Extreme wear was common early in human history, when most of our ancestors were hunters and gatherers. In farming societies, on the other hand, people tend to put less strain on their teeth, and retain overbite and overjet for their whole life.

John Lukacs, an anthropologist at the University of Oregon who was not involved in the new study, told me that agricultural diets are easier on the teeth in two main ways. First, they’re less diverse, made up mostly of staple grains such as corn, wheat, and rice. They’re also moderated by food-processing technologies such as grain mills and pickling jars. “It’s not just what you eat,” Lukacs said. “It’s how you prepare what you eat.”

Mouths with overbites and mouths with teeth lined up edge-to-edge are good at different things. F’s and v’s belong to a group of sounds called labiodentals because they’re made by touching the upper teeth to the lower lip, and the shape of a person’s mouth determines how easy they are to produce. If you’re reading this article, odds are you live in an agricultural, overbite-bearing society. When you say the word foot, you don’t have to move your mouth too much from its resting position, because your top teeth are already lined up with your bottom lip to make the labiodental f sound. If you move your teeth into an edge-to-edge position, roughly the way an adult hunter-gatherer’s jaws would be arranged, making an f sound involves a lot more movement. (Try it.) In fact, the authors of the Science study estimated that it’s nearly 30 percent easier for people with an overbite to make labiodental sounds than it is for people with edge-to-edge bites.

Because it’s so difficult for people with edge-to-edge bites to produce sounds like f and v, the study’s authors figured they would be unlikely to say them by accident, or to incorporate them into their languages. They checked to see whether they could find this pattern playing out in the real world by comparing the sound systems of languages across the world with the subsistence style of the people who speak those languages. About half of the world’s languages use labiodental sounds, but on average, languages spoken by hunter-gatherer societies turned out to use fewer than one-third the number of labiodental sounds as their agricultural counterparts.

Noreen von Cramon-Taubadel, an anthropologist at the University at Buffalo, called the study “really exciting” because it crossed disciplinary boundaries. “We often tend to separate out biological factors from cultural factors,” she told me, but “in humans, it’s really hard to do that.”

The authors of the study are well aware of that tension. In a call with reporters, one of the authors, Balthasar Bickel, lamented that linguistics is often grouped with subjects such as literature and art, but scarcely (if ever) mentioned in biology classrooms. This has enabled what Bickel, a linguist at the University of Zurich, called an “introvert perspective” in the field. “Traditionally,” he said, “change and diversification in language has been chiefly seen as driven by internal processes”—that is, psychology, not biology. Bickel thinks that focus is holding linguists back. “I believe there is a huge potential out there for studying language as part of the biological system it really is embedded in,” he said.

Mixing biology and psychology doesn’t always lead to scientific enlightenment. In the late 19th century, eugenicists were eager to insist that biological factors are the primary driver of humans’ mental abilities, which, they thought, justified keeping those deemed undesirable from reproducing. That concept is known as biological determinism, and on first glance, it’s possible to catch a whiff of it in this study. After all, the authors are arguing that a biological fact (jaw shape) affects the kind of language a person can use (a psychological process). But none of the researchers I spoke with seemed particularly concerned that biological determinism is at play in this study.

Lukacs, the anthropologist, said that the paper provides evidence of a “biological linkage” or “covarying function” between diet and speech, but it does not argue that diet directly causes or determines how a person speaks. Yates, the linguist, said he isn’t worried about the study sparking a deterministic renaissance in linguistics, because it showcases a “very minor, principled exception” to the uniformitarian principle. “I don’t think they’re going to find more,” he told me. “This is not something that we should have to spend a huge amount of time worrying about.”

That’s a sharp contrast to the authors of the study, who said on the call with reporters that they hope more researchers will follow their lead and investigate whether other classes of sounds, besides labiodentals, might have appeared relatively late in humans’ linguistic history. On a later call, Bickel told me he’s especially interested in the farming cultures of Mesoamerica, a region that received somewhat less attention in the new study. But that doesn’t mean he’s plotting some kind of biodeterministic takeover.

“It’s very clear and also very important for us to note that the mechanisms that we found are not deterministic; they are probabilistic,” Bickel said. In other words, just because agricultural societies are more likely to use f’s and v’s, they aren’t necessarily resigned to that fate. Japan, for example, has a strong and long-standing agricultural tradition, but the Japanese language doesn’t use any labiodentals.

The study pokes at some of the most fundamental seams of linguistics: its somewhat ill-fitting niche between literature and cognitive science, its attempts to reconcile the universality of language abilities between humans with the enormous diversity of individual sound and syntax systems worldwide.

Bickel told me he thinks the new findings pull at the very fabric of Western philosophy, too. His colleagues in the humanities, he said, often talk about human behavior as if it’s completely “isolated from nature” because they’re “uncomfortable even comparing” it with the actions of animals. If we want to make “any progress” toward understanding the very thing that makes us human, he said, we need “to understand language as part of the evolutionary history that our species went through.”



I first heard of Thad Roberts during a lecture on black holes. November 18, 2000, was the University of Utah’s Science Day, a grand affair for visiting high-school students like me; the lecture hall was packed. The professor began by invoking the name of the 18th-century natural philosopher John Michell, whose theory of a “dark star” was the forerunner of today’s black hole—a fuel-spent star so compressed by gravity that even light bends to its will.

The lecture then took a detour. The professor boasted that the university’s own rising star, Thad Roberts, had just been accepted to NASA’s internship program. At 23, Roberts was a triple major in physics, geology, and geophysics, as well as the founder of the Utah Astronomical Society. He was determined to be the first person on Mars. He was also about to change the trajectory of my life.

After the lecture, I asked my undergraduate guide, who was friends with Roberts, to pass him my email address. I wanted to be an astrophysicist, but my ambitions conflicted with my upbringing; as a 16-year-old Mormon girl, I felt pressure to focus almost exclusively on home, family, and church. I didn’t feel confident that I belonged in science. Maybe this rising star could light the way.

Roberts soon wrote back, offering to help, and he became my unofficial career counselor. But then the Mars-bound intern captured headlines for a different reason: In the summer of 2002, he stole more than $20 million worth of moon rock and Martian meteorite samples from under NASA’s nose. He was caught in an FBI sting in Florida and spent six years in prison.

The heist sabotaged not only Roberts’s own goals of space travel but also those of his accomplices: fellow NASA interns Tiffany Fowler, then 22, and Shae Saur, then 19. “Being an astronaut is something I had planned to do and aspired to do my entire life,” Saur told the Houston Chronicle before she was sentenced. “My own actions have shattered that dream.” The two Texan women were given three years’ probation and required to repay NASA $9,000 in damages.

In the years since, Roberts has received a great deal of media attention, including a TEDx talk based on a book he wrote in prison and the writer Ben Mezrich’s version of the tale, Sex on the Moon: The Amazing Story Behind the Most Audacious Heist in History. Million Dollar Moon Rock Heist, a documentary by Icon Films, aired on the National Geographic channel in 2012. In contrast, Fowler and Saur have faded from public sight.

Why the two women joined him remains unclear; neither could be reached for comment. But accounts over the years suggest that Roberts was talented in recruiting others to accompany him in sometimes risky exploits. One of the FBI officers interviewed in the Icon Films documentary said of the court ruling, “I think the judge was very sympathetic. She realized that Thad manipulated them and that this was out of character for them.”

Recently, I interviewed Roberts to ask him myself why he stole moon rocks from NASA. His story still haunts me because I was part of its prequel: Before he apparently charmed Fowler and Saur, he charmed me.

Thad’s first email came a few days after my Science Day visit to the University of Utah, in 2000. “I heard from Oliver that you have some questions about becoming an astronaut. Feel free to ask me anything you like,” he wrote. Even digitally, Thad exuded confidence, from his “astronaut_thad” Yahoo handle to the three inspirational quotes on his automatic signature. One was unabashedly his own: “Passion is the essence of the human soul, to be truly alive is to kindle that fire within and explore your passions. —Thad Roberts.”

In the flurry of emails that followed that winter, Thad asked whether I wanted to visit the moon or Mars as casually as asking whether I wanted a hamburger or a hot dog. Because he was still an intern, alternating semesters between NASA and the University of Utah, he encouraged me to join him in learning skills he felt would give us an edge in applying for full-time positions at NASA. Learn Russian and Japanese, he said. Start attending astronomy nights. Get your pilot’s license.

A month later, after my 17th birthday, Thad offered to take me flying. He asked which high school I attended.

“You won’t come stalk me or anything?” I wrote.

“Just give me any info that you are comfortable with me knowing,” he responded. To assure me he was no Ted Bundy, he sent a picture of his wife, Kaydee, visiting him in NASA’s lunar lab. Both of them were wearing protective gear as they handled moon rocks. “Cute, isn’t she?” he wrote. Kaydee was pursuing modeling back in Utah, and she often accompanied Thad on his many outdoor adventures. I assumed the couple were Mormon—a common mistake in Utah—but they’d left the faith several years earlier. (Kaydee has since returned to Mormonism.)

My constant begging and a reassuring phone call from Thad had persuaded my protective parents to let me board a single-propeller Cessna with a stranger who’d barely earned his pilot’s certificate. How could he be dangerous if he was a happily married man who worked for NASA?, I’d argued. In the frigid waiting room of the Ogden-Hinckley Airport, my father and I met Thad and a friend of his who joined us for the flight. Thad had a warm smile, a firm handshake, and disarming green eyes. His stocky outdoorsman build gave the impression that he was a man who did things and did them well.

“We’ll be back in an hour,” Thad told my father, and I buckled up in the back seat of the plane. The jolt of vertigo I felt was forgotten as we ascended: The fresh snow on the Rocky Mountains blinded me as early-morning light shone through silver-white clouds. “Eeeeexcellent,” Thad said, quoting Mr. Burns from The Simpsons. “Time for the first zero g.” My stomach screamed as Thad tipped the nose of the plane into a steep dive. I saw fast-approaching white fields out the front window. My body was weightless; I’d been momentarily set free from the gravitational power of my planet, a wonderful and terrible sensation. Thad yee-hawed.

As he started climbing again, I felt triumphant. This is what space is like, I told myself. I could do this. Who needed a multimillion-dollar Vomit Comet when you had Thad Roberts for a friend?

The rest of the flight didn’t go as planned. Before we returned to my frantic father much later than promised, we got lost and landed in a deserted airport in Preston, Idaho. Thad’s friend was feeling sick, so Thad offered me the co-pilot’s seat, and he guided me in managing the rudders and lifting the plane off the ground. My first time in a plane, and I’d flown it. When we were again soaring through the wintry air, I peppered Thad with questions about black holes. I didn’t fully understand his answers, but the fact that he knew them still made me feel important.

“Hey, want to see a cool trick?” Thad asked at one point. He cut the engine.

While unnerved by Thad’s antics, I was still thrilled to be making steps toward a career in astrophysics. Soon after our flight, I asked him for help making a portfolio for a statewide scholarship competition for graduating high-school students. We met during spring break in the University of Utah’s computer lab, where he helped me build my first HTML webpage. I posted an image of the Eagle Nebula, new stars forming in its clutching fingers. To me, it was an image of hope, of the chance to escape the prescribed orbit set for me by my religious culture.

Thad offered to give me a quick tour of campus. I mentioned that my father had once worked for the university’s cosmic- ray research group, and he showed me their building. He encouraged me to ask them for a job interview, something that hadn’t even occurred to me to try. When you put yourself out there, Thad said, opportunities come to you. Cliché, but correct: For the next three summers, I would intern for the group, learning how to program, to solder, to track down cosmic rays with air-fluorescence detectors in the Utah desert.

It didn’t take long, though, for Thad’s mischievous side to reappear. At the end of that campus tour, Thad led me to some large orange tanks in the basement of the South Physics Building. After pouring liquid nitrogen into a two-liter bottle, he brought me up to the roof, then sniggered as he dropped the bomb off the side of the building, rattling windows across campus. The rattling shook me, as well. Maybe I’d put too much trust in this man.

I consciously distanced myself from Thad after that, focusing on my summer internship and the demands of senior year. Thad emailed me once more the following spring about an upcoming University of Utah astronomy night. He was setting up the telescope’s solar filter for sunspot viewing—on the same roof where he’d thrown liquid-nitrogen bombs. Would I like to join him and the others? In the waning light, after seeing sunspots for the first time, I showed Thad the portfolio he’d helped me create, complete with pictures from our flight and from my internship with Cosmic Ray Research. He was delighted to hear I’d won runner-up in the scholarship competition.

Three months later, on July 13, 2002, Thad stole a national treasure. The plot had been forming throughout the time I knew him. Early in 2001, during Thad’s visit to NASA’s lunar lab in Houston, Texas—the trip when he posed with his wife for the photo he later sent me—he spotted a 600-pound safe containing lunar samples from almost every Apollo mission. These were “contaminated” rocks, still useful for certain research but no longer sealed in nitrogen for safekeeping. Thad noticed that the NASA senior scientist Everett Gibson opened the safe by first looking at something written on the back of its label. Hearing other scientists bemoaning their tight budgets and wishing they could sell some of these rocks, Thad began concocting a fantasy of how someone might steal them.

That same year, Thad met a student named Gordon McWhorter during another rooftop astronomy night, and McWhorter agreed to research how to sell moon rocks. Using the alias “Orb Robinson,” he emailed a Belgian amateur mineralogist in May 2002. The mineralogist, Axel Emmermann, suspected a hoax and alerted the FBI, who took over the online correspondence by pretending to be Emmermann’s sister-in-law. To Thad, it looked as if they’d found someone to buy the moon rocks he’d not yet stolen.

A month later, during the last round of his NASA internship, Thad met Tiffany Fowler and says that he immediately fell in love with her. Thad claims that he and Kaydee had grown apart as they followed their separate dreams, and they’d decided to have an amicable open marriage. Kaydee, however, says she had not agreed to this. “Thad has put so much incorrect info out there,” she wrote in a Facebook message to me, “so he seems like a hero to others instead of the lying, manipulative person he really is.” In an episode of the television series Who the (Bleep) Did I Marry?, Kaydee claims that when she confronted Thad about Fowler, he told her that she “didn’t understand his relationship with Tiffany. He was using her for something.”

Some facts of the heist remain murky, with certain details varying across reports—including the Icon Films documentary, the FBI’s account, and stories by the Los Angeles Times, the Orlando Sentinel, Science, CBS News, and other publications. Thad now admits he initially “just let people go with” some of the more exaggerated claims. What seems clear is that a week before the heist, Thad told Fowler of his plan to steal the moon rocks. Thad’s friend Shae Saur joined them just a few days after Fowler. While Saur waited in a borrowed Jeep outside NASA’s Building 31N, Thad and Fowler cracked the four-digit combination on NASA’s lab door. They arrived at the safe, and Thad pulled its label off, sure he’d find Gibson’s code on the back. The label proved worthless; it was only an algorithm that Gibson had created to remember the combination. So Thad and Fowler used a heavy-duty dolly they’d brought to wheel the entire safe out to the Jeep.

Back in a motel room, the three interns broke open the safe with a power saw and cataloged the lunar samples in vials. Then they discarded the safe, along with a set of green notebooks that represented 30 years of Gibson’s research. (In court, Thad denied that the notebooks were in the safe, but Fowler and Saur told the FBI he had insisted on throwing the notebooks out.)

Hiding the samples and the meteorite in Fowler’s apartment, the trio returned to NASA as if nothing had happened. A week later, Thad and Fowler drove to a hotel in Orlando, Florida, to complete the sale. In a romantic gesture before the meeting, Thad told me he put a few vials of moon rocks under Fowler’s hotel pillow—unbeknownst to her—wanting to say he’d had sex on the moon. Thad embellished this detail in previous interviews, telling CBS News that having sex on top of moon rocks was “uncomfortable.”

McWhorter joined Thad and Fowler, and the three met Emmermann’s “sister-in-law,” the undercover FBI agent, at an Italian restaurant. Thad proudly told her the whole story. Thad, Fowler, McWhorter, and Saur were all arrested and eventually sentenced. (Thad, Fowler, and Saur pleaded guilty; McWhorter denied the charges but was convicted at trial.) Kaydee sent Thad divorce papers.

Meanwhile, in a cubicle at Cosmic Ray Research, I stared, horrified, at Thad’s mug shot in the newspaper after his arrest. It wasn’t even his first theft, I learned: An FBI search of Thad’s home had revealed fossils stolen from the basement of the University of Utah’s Natural History Museum. The mentor who believed in me turned out to be a con man.

While I’ll never get on another plane with Thad, he has served his years in prison, and he is trying to move on. Instead of fleeing from science, he now puts forth theories on quantum gravity as a “philosopher of physics,” according to his website. As a public speaker, he urges people to commit to their dreams and rebound from their mistakes.

Over the past year, I’ve reestablished contact with Thad to better understand why he gave up the very dream he’d encouraged me to seek. He immediately responded to my email, agreeing to an interview on Skype. He was as charming as I remembered him, although he appeared more careworn and subdued. I finally asked him the question that had plagued me for almost 20 years: Why steal the moon rocks in the first place? Was it for money? I didn’t believe it was for love, since he’d been planning the theft well before he met Fowler.

“To feel good enough,” he said. This surprised me—he had always seemed sure of himself. Kaydee, too, says she saw him as a confident person. But Thad claimed he’d felt insecure from the beginning, terrified from day one of his internship with NASA. He was afraid of being abandoned by Fowler, his new lover; worried about losing his wife; and unsure he’d be able to provide for both of them. It didn’t help that at 19, at least according to Thad, he’d been sent home in disgrace from his Mormon mission for confessing to premarital sex—and, subsequently, thrown out of his home in Syracuse, Utah, by his family.

Kaydee was the one, Thad insisted, who believed he could make it to NASA, a fact she also confirmed to me. She was even willing to get another part-time job to support him. Although he was newly involved with Fowler, Thad said he wanted to support her dreams in return. Stealing the moon rocks would solve the problem. Anytime he started doubting his plans, he’d tell himself he’d already decided to do it and dismiss the fear.

The more I reviewed Thad’s history, the less the label con man—or its back-formation, confidence man—seemed to fit him. Con artists use a show of confidence to trick their “marks” out of money or other valuables. They’re people who overpromise and under-deliver on purpose. Thad, in contrast, was a simple thief. Led by his own irrational justifications and the conviction that he could evade capture, he was willing to persuade accomplices to join him, abuse the trust his employers placed in him, and deliver stolen goods to a buyer as promised.

Months after our initial interview, Thad emailed to say he was in Utah and wanted to meet for lunch. We met at The Pie Pizzeria, a dimly lit, underground restaurant adorned with graffiti. Thad had asked whether he could invite additional friends, and he brought a full contingent with him: one of the women he is currently dating, on her way to live with her other boyfriend in Canada; a camping friend; a prison friend; and a friend from one of his old philosophy classes. Thad still drew people together.

The conversation was amiable and casual. At some point, Thad revealed that he had dumped his entire life savings into a new online business venture. “I haven’t regretted it yet,” he said. “I thought, I’m a divorced, two-time-loser felon. This is my last chance for security. Let’s go.” Despite this bleak assessment, Thad held on to the idea that if you put yourself out there, opportunities come to you.

I stood to go, and Thad rose to give me a hug. I told him, genuinely, that I wished him all the best. For years, I’d thought of Thad as my own dark star. He’d drawn me into orbit around him, and I’d let him overrule my sense of what was smart and safe. But people are more complex than black holes. We can change course if we choose.

For so long, I’d wasted time and energy seeking assurance that I belonged in science. Last summer, almost 20 years after my first lesson on dark stars, I started working for Cosmic Ray Research again. This time, I’m confident that I can do it.



The moment has arrived at last. A woman in a hospital gown steels herself, ready to push. A nearby monitor displays her baby’s heart rate in big, neon numbers. A nurse in crisp scrubs coos in her ear, offering words of encouragement, advice. The scene would resemble any other delivery room if it weren’t for the view outside the window: the soft curvature of the blue Earth against the blackness of space, 250 miles below.

Delivering a child in microgravity may sound like science fiction. But for one start-up, it’s the future.

SpaceLife Origin, based in the Netherlands, wants to send a pregnant woman, accompanied by a “trained, world-class medical team,” in a capsule to the space above Earth. The mission would last 24 to 36 hours. Once the woman delivered the child, the capsule would return to the ground. “A carefully prepared and monitored process will reduce all possible risks, similar to Western standards as they exist on Earth for both mother and child,” SpaceLife Origin’s website states. The company has set the year 2024 as the target date for the trip.

The concept raises a host of questions—we’ll get to those later—but perhaps the most immediate may be this: Why?

Egbert Edelbroek, one of the company’s executives, says spacefaring childbirth is part of creating an insurance policy for the human species. Should a catastrophe someday render Earth unlivable—climate change, Edelbroek suspects—he hopes the human species will move off-world and settle elsewhere. Wherever they land, they will plant roots, build homes, and start families.

“Human settlements outside of Earth would be pretty pointless without learning how to reproduce in space,” Edelbroek says.

Fair enough. If human beings someday venture far beyond this planet and land on another—not to visit but to stay—it’s not impossible to imagine that a pregnancy could occur during the journey or on the ground. One can picture toddlers in puffy spacesuits running around on Mars, the oxygen packs on their backs rattling with each leap.

Of course, this future assumes that human beings have resolved many other challenges that come with traveling to other worlds. Scientists are still trying to figure out how to keep adult humans healthy during long stays on the International Space Station, which is indeed in space, but still within Earth’s magnetic field, an invisible bubble that protects the station and its inhabitants from the worst of space radiation. On top of that, the technology for deep-space travel doesn’t exist. Human beings are a long way from becoming an interplanetary species, and reproduction is just one rung on a very tall ladder.

Edelbroek says he has met with private spaceflight companies that may be willing to launch the delivery mission, and with people who will pay for it. He’s visited survivalist communities in the United States; he believes “preppers” are more likely to appreciate the company’s ethos, and some are quite wealthy, spending thousands of dollars on high-end shelters. He’s even chatted with some women who are interested in claiming the historic title, for themselves and their offspring.

Let’s say Edelbroek gets all three: money, a rocket, and a volunteer. What happens then?

Long before anyone gets off the ground, SpaceLife Origin will face a barrage of questions from regulatory authorities, perhaps even from more than one nation. Commercial space travel is not confined by national borders, and it’s not uncommon for customers in one country to pay the government of another to launch their payloads. SpaceLife Origin’s ambitious mission could include an American woman, in a Japanese capsule, on an Indian rocket, accompanied by a team of doctors from multiple nations.

In this scenario, it’s difficult to say who will regulate what. The pregnant woman’s actions may be subject to regulation, too. In the United States, women are harassed and even arrested for leaving their kids unattended, shamed for apparently putting young children in danger. Space is far more dangerous than the sidewalk outside a store. Would the law consider a woman’s decision to give birth there a criminal act?

Even if SpaceLife Origin finds a willing participant—and Edelbroek stresses that she will be calling the shots—would it be ethical for the company to send her? The doctors who would supposedly accompany her, too, might risk violating the physician’s oath: “First, do no harm.” It seems difficult to make the case that helping launch a pregnant woman into space follows this promise.

“Most of the pregnant women I know feel great comfort in knowing that they have access to medical help if there’s an issue during a delivery—or prior to a delivery, or after a delivery,” says Virginia Wotring, a professor of space medicine at Baylor College of Medicine. “Putting people in a situation where they are many, many, many miles away from medical help does not seem to be advisable.”

Let’s set aside, for a moment, the question of how SpaceLife will time labor contractions with a rocket launch to get their participant into space just in time for delivery. Astronauts usually experience three times the force of gravity during the ascent to orbit. In the case of a botched launch and emergency landing, that force triples. It’s unclear what effect such extreme pressure could have on a pregnant person.

There’s little in the literature to guide us on what may transpire in orbit. Experiments on reproduction have been conducted in space, but they have been limited to mice, fish, lizards, and invertebrates. In the 1990s, pregnant rats gave birth after a week on a U.S. space-shuttle mission. Each rat pup was born with an underdeveloped vestibular system, the inner-ear structure that allows mammals to balance and orient themselves. As scientists suspected, the absence of gravity had thrown the pups off-kilter. The animals’ sense of balance recovered not long after birth, but the lesson was clear: Animal infants need gravity.

Imagine childbirth without it. The expectant woman would be unable to take walks to ease the pain of labor, to take advantage of gravity’s downward tug as she pushed. The thought of administering an epidural seems terrifying; the anesthesiologist would have to make sure her patient didn’t float away as she carefully weaved a needle toward the spinal cord. Bodily fluids would clump into blobs and glide through the capsule.

When the time came, the baby’s first breaths would suck in the air of a sealed metal box, composed of oxygen made by complex artificial systems, not plant life.  “A baby might be breathing a gas mixture that is different from Earth air,” Wotring said. “Adult humans seem to handle it just fine, but if you’re using your lungs for the very first time, would it make a difference? I don’t know.”

After the delivery is over, mom and baby would have to survive the descent back to Earth. For current astronauts, that involves a bone-rattling free fall through the atmosphere, followed by a parachute landing in the Kazakh desert. On the ground, the team would be faced with yet another unusual question: Where do you get a birth certificate for someone born in space?

The list of unknowns goes on and on. SpaceLife Origin seems like an unusual player in such a perilous endeavor. The top three employees named on the company’s website are business executives with no experience in medicine or spaceflight, including Edelbroek, whose biography describes him as a “serial entrepreneur.” Five advisers are listed, two of them women. (Edelbroek says the company is working with dozens more, but declined to name them.) Edelbroek says his interest stems in part from his experience as a sperm donor, which led him to father several children and learn about in vitro fertilization techniques. Another of SpaceLife Origin’s missions involves launching sperm and egg cells into space to form an embryo and returning it to Earth for implantation.

Gerrit-Jan Zwenne, one of SpaceLife Origin’s advisers and Edelbroek’s cousin, is convinced that if this company doesn’t do it, another will. Zwenne, a law professor at Leiden University, cited the case of He Jiankui, the Chinese scientist who announced in late November, to the world’s surprise, the alleged birth of healthy twins whose embryos he had altered with a gene-editing technique known as CRISPR. The news prompted international outcry. His work, conducted in near-secrecy, flouted conventional norms in gene-editing technology, a fast-moving field that has avoided attempts at modifying human embryonic cells.

“I think at some point this will happen anyway, so we better do it in a very open and transparent manner,” Zwenne says. “If it’s somebody working on his own, in isolation, not in contact with the rest of the world, you may discover that something happens and you can’t reverse it.”



Last fall, Gilad Japhet, the founder of a DNA-testing company, got up at an industry conference to talk about his grandmother Rosa’s love letters.

Japhet’s company, MyHeritage, sells cheek swabs to people interested in their family history. It now has 2.5 million people in its DNA database, making it the third largest behind 23andMe and AncestryDNA. But Japhet wasn’t satisfied with only testing the living; he wanted to test the dead. Which brings us to the love letters—or really, the envelopes they came in.

The envelopes were sealed by his grandmother, and the stamps on them presumably licked by her. “Maybe our ancestors did not realize it,” Japhet said, a smile growing on his face, “when they were licking those stamps and the envelope flaps, they were sealing their precious DNA for you forever.” Then he made the big announcement: MyHeritage would soon begin offering DNA testing on old stamps and envelopes.

He didn’t stop there. If you can test the letters of your grandmother, why not those of historical figures? Japhet is a prodigious collector of autographs, and he revealed that he possessed handwritten letters from Albert Einstein and Winston Churchill. In an intriguing if provocative PR move, he promised that “their DNA is coming to MyHeritage very, very soon.”

In the past year, genealogists have been abuzz about the possibility of getting DNA out of old stamps and envelopes. In addition to MyHeritage, a British company called Living DNA began informally offering the service for $400 to $600 last year, and a small Australian start-up called Totheletter DNA, which specializes in DNA from envelopes and stamps, launched a similarly priced service in July. MyHeritage says its own service should debut later this year. (A spokesperson declined to comment on when Einstein and Churchill’s DNA profiles will be uploaded to the company’s site.)

Among genealogists, demand for this service has been pent up for years. “At every conference I do, every seminar I do, I always get questions about artifact DNA. I think there is enormous potential,” says Blaine Bettinger, a professional genealogist. Getting the DNA of an ancestor can be tremendously helpful for finding new relatives. For example, your great-great-grandmother passes about 6.25 percent of her DNA to you. But she may have plenty of other relatives who only share DNA from the 93.75 percent that you did not inherit. One way to genetically match those relatives is to test her directly.

Ask genealogists, and you will hear a story about a grandmother’s letter or a father’s tissue biopsy or a great-aunt’s hairbrush, full of DNA that could unlock a family mystery. While 23andMe and Ancestry require large vials of saliva for DNA analysis, which are hard to obtain without a person’s cooperation, artifacts are much easier to come by. But extracting DNA from these sources opens up so many new possibilities—some unsavory, some simply uncomfortable. Should you be able to test a parent who refused to play along by digging up an old letter? Or do a secret paternity test on your child, using a cup discarded by the man suspected of having an affair with your wife? Or trace anonymous letters? Or obtain the DNA of celebrities?

In Vallejo, California, police have also sent envelopes from the Zodiac Killer for DNA extraction, in hopes of applying the same genetic genealogy tools that caught the Golden State Killer suspect. (Investigators in the Golden State Killer case had the advantage of well-preserved DNA from a rape kit, though.) Criminal-forensics labs have long analyzed DNA from objects, but they rely on a technique that looks at only 20 sites, called short tandem repeats (STR). To find their suspect in the Golden State Killer case, investigators used a technique from commercial at-home DNA tests, called genotyping, which looks at hundreds of thousands of sites in the human genome. Genotyping yields far more details than STR, revealing distant family relationships as well as genetic variants that can affect a person’s health and appearance. That’s a lot of information, potentially hidden in an envelope.

For these reasons, the companies offering DNA services for envelopes are drawing a line: These tests are not for living people. The only reason, after all, to resort to getting a living person’s DNA from a letter is if the person is not cooperating with a cheek swab or vial of spit—in which case they probably are not consenting.

This means saying no to potential customers. Joscelyn McBain, the founder of Totheletter DNA, told me that several people have contacted her about testing anonymous poison-pen letters. She’s sympathetic, but she says, “It just opens up a big can of worms.” To avoid testing living people, Totheletter asks customers to explicitly state that the envelope comes from a dead relative. McBain is not against using DNA and genealogy to find violent criminals like the alleged Golden State Killer—she’s actually interested in working with police in Australia—but she’s uncomfortable with using it to track down just anyone.

To limit the possibility for abuse in this, MyHeritage does not plan to test items such as toothbrushes, dentures, and old clothing. Since envelopes are usually postmarked and have a sender’s name written on them, it’s easier to validate that the item is what the customer says it is and not some secretly obtained sample. MyHeritage told me it plans to update its terms and services to prohibit uploading DNA profiles of living people that have been obtained through stamps or envelopes. But DNA from dead people, including dead celebrities like Einstein and Churchill, will be allowed.

The ethics of testing a deceased person’s DNA are more ambiguous, says Bettinger. Dead people usually don’t have privacy rights. Dead celebrities, having been public figures, have even less of an expectation of privacy. But dead people still often have living descendants, who share some portion of their ancestors’ DNA and who do have privacy rights. What if Einstein’s living descendants aren’t thrilled about a company uploading his DNA, just so random people online can find out if they’re distantly related to a genius?

On the other hand, says Bettinger, we don’t ask all our living relatives and future unborn descendants for consent when we ourselves mail in a DNA test—even though it affects them all. The alleged Golden State Killer, for example, was identified through third and fourth cousins who took DNA tests. Right now, any one individual has relatively little control over his or her  own genetic privacy.

Living DNA’s terms of service would allow testing envelopes for the DNA only when the target person is deceased and the customer has obtained the envelope legally. Of course, these terms of service rely on the honesty of the customer. A lab technician reviews materials to make sure they are what customers claim they are, but cost might be the most practical deterrence. Living DNA’s co-founder, David Nicholson, brought up the example of paternity tests. They’re available in drugstores for around a hundred dollars, while Living DNA’s service costs $400 to $600. “It’s a very expensive way to do that,” says Nicholson.

The cost of testing envelopes for DNA is unlikely to come down soon. 23andMe, AncestryDNA, and MyHeritage are able to offer ordinary ancestry tests for less than $100 because they use standardized vials and swabs. That process is easy to automate with robots. In contrast, every envelope is different. A human hand needs to carefully cut out the envelope flap or stamp, dissolve the glue, and extract the DNA. Nicholson says different types of glue might require different extraction techniques. DNA also degrades over time, so the success rate of testing old letters hovers around 50-50.

So for now, the commercial viability of envelope DNA testing is still uncertain. “At the moment, we’re doing it as a token to help people,” Nicholson says. It’s not really making the company any money. He’s considered offering a two-tiered service, where customers pay a smaller free upfront and only pay for the full genetic analysis after it looks like it will work. McBain has been open about similar challenges for Totheletter. She’s currently refunding customers whose samples are not successful. “We have to improve our results if it’s something we can commercially sustain,” she says. The entrance of MyHeritage, a big player in the consumer DNA industry, will be an important test case.

Genealogists are, by disposition, people who enjoy thinking about ways of the past. It is not lost on them that we have stopped writing letters and licking stamps. “There’s kind of this golden period from the late 1800s to maybe the past decade or so,” Bettinger says. Then he adds, “Maybe DNA testing is picking up that slack.” In other words, now we have a generation of people who are voluntarily testing themselves and sharing their DNA—what more could you ask for?



In 1828, a teenager named Charles Darwin opened a letter to his cousin with “I am dying by inches, from not having anybody to talk to about insects.” Almost two centuries on, Darwin would probably be thrilled and horrified: People are abuzz about insects, but their discussions are flecked with words such as apocalypse and Armageddon.

The drumbeats of doom began in late 2017, after a German study showed that the total mass of local flying insects had fallen by 80 percent in three decades. The alarms intensified after The New York Times Magazine published a masterful feature on the decline of insect life late last year. And panic truly set in this month when the researchers Francisco Sánchez-Bayo and Kris Wyckhuys, having reviewed dozens of studies, claimed that “insects as a whole will go down the path of extinction in a few decades.” The Guardian, in covering the duo’s review, wrote that “insects could vanish within a century”—a crisis that Sánchez-Bayo and Wyckhuys believe could lead to a “catastrophic collapse of nature’s ecosystems.”

I spoke with several entomologists about whether these claims are valid, and what I found was complicated. The data on insect declines are too patchy, unrepresentative, and piecemeal to justify some of the more hyperbolic alarms. At the same time, what little information we have tends to point in the same worrying direction. How, then, should we act on that imperfect knowledge? It’s a question that goes beyond the fate of insects: How do we preserve our rapidly changing world when the unknowns are vast and the cost of inaction is potentially high?

First, some good news: The claim that insects will all be annihilated within the century is absurd. Almost everyone I spoke with says that it’s not even plausible, let alone probable. “Not going to happen,” says Elsa Youngsteadt from North Carolina State University. “They’re the most diverse group of organisms on the planet. Some of them will make it.” Indeed, insects of some sort are likely to be the last ones standing. Any event sufficiently catastrophic to scour the world of insects would also render it inhospitable to other animal life. “If it happened, humans would no longer be on the planet,” says Corrie Moreau from Cornell University.

The sheer diversity of insects makes them, as a group, resilient—but also impossible to fully comprehend. There are more species of ladybugs than mammals, of ants than birds, of weevils than fish. There are probably more species of parasitic wasps than of any other group of animal. In total, about 1 million insect species have been described, and untold millions await discovery. And having learned of a creature’s existence is very different from actually knowing it: Most of the identified species are still mysterious in their habits, their proclivities, and—crucially for this discussion—their numbers.

Few researchers have kept running tallies on insect populations, aside from a smattering of species that are charismatic (monarch butterflies), commercially important (domesticated honeybees), or medically relevant (some mosquitoes). Society still has a lingering aversion toward creepy crawlies, and entomological research has long been underfunded. Where funds exist, they’ve been disproportionately channeled toward ways of controlling agricultural pests. The basic business of documenting insect diversity has been comparatively neglected, a situation made worse by the decline of taxonomists—species-spotting scientists who, ironically, have undergone their own mass extinction.

When scientists have collected long-term data on insects, they’ve usually done so in a piecemeal way. The 2017 German study, for example, collated data from traps that had been laid in different parts of the country over time, rather than from concerted attempts to systematically sample the same sites. Haphazard though such studies might be, many of them point in the same dispiriting direction. In their review, Sánchez-Bayo and Wyckhuys found 73 studies showing insect declines.

But that’s what they went looking for! They searched a database using the keywords insect and decline, and so wouldn’t have considered research showing stability or increases. The studies they found aren’t representative either: Most were done in Europe and North America, and the majority of insects live in the tropics. This spotty geographical spread makes it hard to know if insects are disappearing from some areas but recovering or surging in others. And without “good baselines for population sizes,” says Jessica Ware from Rutgers University, “when we see declines, it’s hard to know if this is something that happens all the time.”

It’s as if “our global climate dataset only involved 73 weather stations, mostly in Europe and the United States, active over different historical time windows,” explained Alex Wild from the University of Texas at Austin on Twitter. “Imagine that only some of those stations measured temperature. Others, only humidity. Others, only wind direction. Trying to cobble those sparse, disparate points into something resembling a picture of global trends is ambitious, to say the least.”

For those reasons, it’s hard to take the widely quoted numbers from Sánchez-Bayo and Wyckhuys’s review as gospel. They say that 41 percent of insect species are declining and that global numbers are falling by 2.5 percent a year, but “they’re trying to quantify things that we really can’t quantify at this point,” says Michelle Trautwein from the California Academy of Sciences. “I understand the desire to put numbers to these things to facilitate the conversation, but I would say all of those are built on mountains of unknown facts.”

Still, “our approach shouldn’t be to downplay these findings to console ourselves,” Trautwein adds. “I don’t see real danger in overstating the possible severity of insect decline, but there is real danger in underestimating how bad things really are. These studies aren’t perfect, but we’d be wise to heed this warning now instead of waiting for cleaner studies.”

After all, the factors that are probably killing off insects in Europe and North America, such as the transformation of wild spaces into agricultural land, are global problems. “I don’t see how those drivers would have a different outcome in a different area, whether we know the fauna there well or not,” says Jennifer Zaspel from the Milwaukee Public Museum.

Insects, though diverse, are also particularly vulnerable to such changes because many of them are so specialized, says May Berenbaum from the University of Illinois at Urbana-Champaign. “There’s a fly that lives in the gills of a crab on one Caribbean island,” she says. “So what happens if the island goes, or the crab goes? That’s the kind of danger that insects face. Very few of them can opportunistically exploit a broad diversity of habitats and supplies.” (That said, Sánchez-Bayo and Wyckhuys concluded that several once-common generalist species are declining, too.)

The loss of even a small percent of insects might also be disproportionately consequential. They sit at the base of the food web; if they go down, so will many birds, bats, spiders, and other predators. They aerate soils, pollinate plants, and remove dung and cadavers; if they disappear, entire landscapes will change. Given these risks, “do we wait to have definitive evidence that species are disappearing before we do something?” Berenbaum asks.

Doing something is hard, though, because insect declines have so many factors, and most studies struggle to tease them apart. In their review, Sánchez-Bayo and Wyckhuys point the finger at habitat loss above all else, followed by pesticides and other pollutants, introduced species, and climate change, in that order. “If it was one thing, we’d know what to do,” says Moreau from Cornell. Instead, we are stuck trying to tend to 1 million smaller cuts.

At least people are talking about the problem—a recent trend that surprised many of the entomologists I spoke with, who are more used to defending their interests to a creeped-out public. “Since when do people care about insects?” Berenbaum says. “I’m staggered by this!” She hopes that the apocalypse headlines will motivate people to take part in citizen-science projects, such as the BeeSpotter initiative she runs in Illinois. “There’s a huge amount of diversity, but we can divide up the work,” she says.

Youngsteadt of North Carolina State is also confused by the sudden flux of interest, but it has meant a lot of invitations from community groups that want her to talk about the declines. She advises them to plant their gardens with native flowers, which promote a wider diversity of insects than neatly manicured lawns. Many people heed that advice to save beautiful species such as monarchs, “but are shocked by all the bugs that come over,” Moreau says. “They’ll see flies, bees, other caterpillars. They start appreciating the whole realm of insects out there. Going from ‘Ew!’ to ‘I’ve heard they’re in trouble; what can I do?’ is a good thing.”

She and others hope that this newfound attention will finally persuade funding agencies to support the kind of research that has been sorely lacking—systematic, long-term, widespread censuses of all the major insect groups. “Now more than ever, we should be trying to collect baseline data,” Ware says. “That would allow us to see patterns if there really are any, and make better predictions.” Zaspel would also love to see more support for natural-history museums: The specimens pinned within their drawers can provide irreplaceable information about historical populations, but digitizing that information is expensive and laborious.

“We should get serious about figuring out how bad the situation really is,” Trautwein says. “This should be a huge wake-up call, and we should get on the ball instead of quibbling.”



Imagine trying to test the memory of the blue whale—the biggest animal that exists or has ever existed, a 190-ton behemoth that dwarfs even the largest dinosaur, a leviathan that is rarely seen except when it comes up for air and a minute part of its 110-foot-long body breaks the surface and slowly crests for what seems like an eternity. How would you subject such a creature to a psychological test?

You can’t, exactly. But there is another way to get a sense of how their minds work. For years, scientists have been fitting radio tags to these giants to track their whereabouts. By analyzing a decade’s worth of that data, Briana Abrahms from the National Oceanic and Atmospheric Administration has shown that these animals fine-tune the paths of their epic migrations to track the historical abundances of krill—the tiny crustaceans that they eat. Rather than finding where their prey currently is, they go after the places where their prey was in years past. Their migrations, in other words, are guided by memory. So what happens in a world where memory might lead them astray?

Countless species of animals migrate over long distances to exploit far-flung sources of sustenance, but these voyages aren’t just about getting to the final destination. The journey itself can be a sort of food tour, too. Migrating animals often adjust the pace and timing of their movements to hit pulses of seasonal food that spring up along their path. The ecologist Sandra van der Graaf described this as “surfing the green wave” after first observing it among barnacle geese. Others have found the same pattern among wasps, elk, mule deer, and brown bears, although since the latter are tracking salmon, they’re more accurately “riding the crimson tide.”

Whether these patterns map onto a supply of fish flesh or fresh foliage, the principle is the same: As waves of food sweep the world, waves of animals track them. At least, that’s what happens on land. No one had examined this phenomenon in the oceans before, until Abrahms and her colleague Ellen Aikens came up with a plan to study blue whales.

The blue whales of the North Pacific spend their winters in their breeding grounds off California and Costa Rica. Come spring, they swim up the coast of North America toward the food-rich summer waters of the Pacific Northwest. They could make the journey in two months (and they do, on the reverse trip back south). Instead, they take twice that time, pausing to gorge themselves on blooms of krill that appear along the way. It’s a leisurely season-long tour of a continent-wide buffet line.

Scientists can get a good sense of this changing buffet by measuring the concentrations of chlorophyll in different patches of ocean. This green pigment reflects the amount of plankton, which in turn is eaten by krill. The more chlorophyll there is, the more food a blue whale might find.

By comparing chlorophyll counts to whale movements, Abrahms and her team expected to see that “they follow the timing of their prey, as it becomes available,” she says. But they were surprised to learn that the animals very rarely tracked contemporary waves of krill. Instead, their movements were strongly correlated with 10-year historical averages of chlorophyll. Put it this way: You could predict a blue whale’s movements with far more accuracy by looking at where their food has been than where their food currently is.

In retrospect, the idea that whales would surf historical green waves “makes a lot of sense, given how dynamic the ocean is,” says Abrahms. “There’s so much variability year-to-year that the whales can hedge their bets by going with the average timing that they’ve experienced in the past.” Indeed, the team also found that the whales favor areas with unusually low year-to-year variation in chlorophyll counts.

“It’s striking that they return to the best and most consistent areas on average, rather than tracking current conditions,” says Chloe Bracis from IFREMER. “This implies that they could be using memory to return to these locations.” It’s “a big step forward” to have that kind of data for a wild marine species, adds Sabrina Fossette from Swansea University, who would love to see similar studies in other marine mammals and sea turtles.

Understanding whales’ migration decisions is especially important given how quickly the world is changing. Nature’s schedule is becoming more erratic, and once-reliable timings are fluctuating beyond their normal variations. “The characteristics of the Anthropocene are very different from the past,” says Abrahms. Once, a blue whale’s memory might have sent it off course in a weird year, but what if every year is weird? “The concern is that if the whales get the timing too wrong, they’d miss their food,” Abrahms says. “We’re starting to see a lot of that in other species, with migratory birds arriving in their breeding grounds after the best food has come and gone.”

“Marine mammals are highly adaptable,” says Helen Bailey from the University of Maryland Center for Environmental Science. But earlier work that she was involved in showed “that blue whales moved further up the U.S. coast during years when prey was less abundant, and had to search further for food. This new study confirms that they go to predictably good food locations first, and then make decisions about where to go next based on the current conditions.”

Some whales, like humpbacks, are flexible enough to switch from krill to fish if they can’t find enough prey. But blue whales are specialist hunters. Their existence depends on finding dense enough swarms of krill to swallow half a million calories in every mouthful. And that existence is already under threat. Blue whales are endangered, confined to a shrinking habitat rife with collision hazards, cacophonous underwater noises, and human-made pollutants that accumulate in their flesh. If, on top of all that, they can’t reliably find enough food, these memory-reliant creatures might become memories themselves.



The climate candidate now has a climate plan—or at least the beginnings of one.

On Friday, Governor Jay Inslee of Washington announced a major plank of his climate-focused platform for president: a three-part plan to reshape the U.S. auto market, building code, and power grid over the next decade and a half.

You could call it the 100-100-100 plan. Inslee would require that, by 2030, 100 percent of new cars sold in the United States must be fully electric, 100 percent of U.S. electricity must come from carbon-neutral sources, and 100 percent of newly constructed buildings must emit no greenhouse gases from their kitchens, chimneys, or heating systems.

He would also mandate that, by 2035, 100 percent of U.S. electricity be generated by zero-emissions sources. A carbon-neutral grid requires utilities to remove as much carbon pollution from the atmosphere as power plants emit. (This might mean, for example, planting more trees.) A zero-emissions grid requires utilities to use only power sources that release no greenhouse gases at all, such as wind turbines, solar panels, hydroelectric dams, and nuclear plants.

The agenda mirrors many of the policies that Inslee has piloted in Washington. Next week, the governor will sign a bill committing the Evergreen State to a carbon-neutral grid by 2030, and a zero-emissions grid by 2045. It will represent a long-awaited victory for Inslee: After years of trying, and several failed attempts to put a statewide price on carbon pollution, Inslee will succeed in passing an ambitious climate policy in Washington. And he has found this success not by trying to tax carbon pollution, but by going sector by sector, coaxing and prodding individual parts of the economy to change their ways. It is a strategy he now hopes to bring to the White House.

The Inslee campaign considers the bill “the most comprehensive path to 100 percent clean energy,” Jared Leopold, a spokesman, told me. “It sets down real teeth and standards. It’s reflective of what the modern discussion is at the state level.” Inslee has also launched a green-buildings code as governor.

The new plan earned mostly good reviews from a slate of climate-policy experts, who said it built on preexisting state-level policies while pushing a faster timeline. “It is already aligning with a lot of the ambition of the Green New Deal,” says Greg Carlock, a policy researcher at the leftist advocacy group Data for Progress. “They’re picking something ambitious.”

But climate ambition has often flubbed on a federal level. Leah Stokes, a political scientist at UC Santa Barbara, noted that even though Inslee’s policies have found success in Washington State, the same policies have not had the same record in D.C. “There have been many efforts to pass a federal [renewable electricity standard], in the ’90s, and under [the 2009 climate bill] Waxman-Markey, and it’s always resisted by utilities and ultimately defeated.”

She also advised considering the practical challenges of the plan. Carbon-free sources—such as wind, solar, and nuclear—now generate 37 percent of U.S. grid electricity. Under the Inslee plan, they must take over the last 63 percent of the grid over the next 16 years, Stokes said.

To meet that target, clean energy must add about four percentage points every year between now and 2035. This would be unprecedented: Even over the past few years of record-setting expansion for renewables, clean energy has grown by only 0.6 percentage points a year.

And that may actually understate the challenge. “It’s not just an eightfold increase—it’s probably closer to a tenfold increase, because if you’re going to electrify everything, you have to grow the grid,” Stokes said. The Inslee plan would add tens of millions of new electric cars to the road, all of which would need to draw their energy from the power grid. A literature review last year found that U.S. electricity use could more than double by 2050.

The plan sets a similarly ambitious target for zero-emissions vehicles, mandating that all newly sold light- and medium-duty cars and trucks have fully electric drivetrains by 2030. Of the 17 million new cars and light trucks sold in the United States in 2018, about 300,000—or 2 percent—were plug-in electric vehicles. (Meanwhile, more than 1 million electric cars were sold in China last year.)

Inslee also wants the government to undertake a “Clean Cars for Clunkers” program, allowing Americans to trade in their old gas-burning vehicles for a discount. And he would provide incentives for cities, states, and utilities to build new electric-charging stations.

Programs such as these are crucial to making sure Americans, especially in rural areas, will not be disadvantaged by a climate transition, Carlock said. It’s unlikely that the kind of transit-oriented approaches that work best in cities—such as fully electric buses or expanded subway systems—would work at scale in the country’s most spread-out areas. “Kind of like with rural electrification or rural broadband, you need to do rural charging. You’re never going to bring a lot of public transport out there,” he said.

Finally, the Inslee plan requires all new buildings constructed after 2030 to emit no greenhouse gases. This would effectively phase out gas stoves, gas ovens, and heating systems that burn oil or gas. Buildings pose an often-forgotten climate problem for the United States: In 2018, emissions from buildings leaped by 10 percent, driving a national surge in carbon pollution.

The Inslee campaign demonstrates the challenge of fighting climate change—economists and policy designers have devised climate policy for 30 years, but it has never been massively implemented in the United States. “Maybe this Inslee plan is doable with a huge government investment, like a war effort,” Stokes later told me by email. “I suppose if the U.S. government sticks its mind to the task, it could get a long way to meeting these ambitious timelines.”



Between the shipping and handling, the web servers, the groceries, and the newspapers, Jeff Bezos never stopped thinking about the moon. He was five years old when Americans first walked on the lunar surface, and he remembers the grainy black-and-white footage from that historic moment.

“It had a huge impact on me,” Bezos said. “And it hasn’t changed.”

Bezos, in addition to leading Amazon and owning The Washington Post, runs a spaceflight company called Blue Origin. Blue Origin has been working on something for the past three years, and on Thursday, Bezos unveiled it: a giant spacecraft designed to touch down gently on the lunar surface, plus a small rover with droopy camera eyes, like WALL-E.

“This is an incredible vehicle,” Bezos said, beaming. “And it’s going to the moon.”

If this news seems like it’s coming out of, well, the blue, that’s because Blue Origin is not the flashiest company. It has conducted much of its work in secret and rarely holds press events. But the company, Bezos has said, is “the most important work that I’m doing.” He spends about $1 billion on it each year, collected from selling off his Amazon stock.

So far, the work has stayed close to the ground. Blue Origin has carried out nearly a dozen successful flights of its New Shepard rocket, named for Alan Shepard, the first American to go to space. The rocket hurtles upward until it reaches the edge of space, then descends and lands vertically on the ground. Bezos wants to use New Shepard to fly space tourists, perhaps as early as this year.

That’s one dream. The moon is another kind, and requires different technology.

The lander revealed on Thursday, a mock-up, is called Blue Moon. It’s sleek, hulking, and insect-like, with spindly legs to cushion the landing. Here’s the plan, or at least part of it: Before touching down on the lunar surface, Blue Moon will dispatch a bunch of tiny satellites, depositing them into an orbit around the moon, where they can collect scientific data. Then it will fire its engines and begin its approach. Less than a mile from the surface, it will rotate itself to land upright. The underbelly is equipped with lasers to guide the spacecraft to its target landing zone. Once it’s on the ground, robotic arms will lower a rover, perhaps as many as four, onto the dusty, slate-colored ground.

Bezos said engineers are ready to begin engine tests as early as this summer. But there are some notable gaps in this plan. The lander must be launched into space on a rocket, and Bezos didn’t say which one. He didn’t say when it might fly either. But he said enough—especially to the people he made sure were listening.

The big reveal was held at a conference center about a five-minute drive from the White House. In March, Vice President Mike Pence announced that NASA would undertake a mission to the moon and return American astronauts to the surface in 2024. It’s an ambitious plan, and currently unfunded; NASA has yet to tell Congress, which determines the funding for the agency, how much this effort will cost. NASA has solicited proposals from U.S. commercial spaceflight companies to help, and many, mostly small start-ups, have jumped at the chance.

That now includes Blue Origin, which leads the pack in spaceflight experience. Bezos spoke effusively about the new policy and Pence’s vision. He invited Mark Sirangelo, a space professional whom NASA hired to guide the new effort—to be, essentially, Trump’s moon czar—to the event. Bezos declared, “It’s time to go back to the moon, this time to stay.” Here I am, Bezos seemed to plead; use me.

In the vision he laid out, Bezos went beyond the moon. Earth’s resources, he warned, are finite. Someday they will be depleted, and humankind will be forced to look for other homes. “Space is the only way to go,” he said. But he eschewed popular destinations such as Mars, which his colleague in the space biz, Elon Musk, dreams of tearing up like an old carpet to construct a new, Earth-like environment.

Bezos offered an argument made famous by Goldilocks. Other planets, he said, are too small. They’re too far. They don’t have enough gravity. Instead, human beings should build habitats in orbit around Earth, perpetually rotating to produce artificial gravity, a concept popularized in the 1970s by the American physicist Gerard O’Neill. These manufactured worlds, Bezos said, could each house 1 million people or more. Some habitats would be cities, others national parks. Some might even re-create famous places on Earth. All, according to the animations Bezos shared, would be idyllic, with perfect weather all year round.

“People are going to want to live here,” he said.

And what happens to Earth in this Interstellar-esque future? The planet would be zoned for residential and light industrial use. The heavy, pollution-causing stuff would exist in one of those off-world habitats.

Bezos doesn’t plan to take care of this himself, though.

“Who is going to do this work? Not me,” Bezos said. He pointed to a group of middle-school-aged children near the front of the stage, all dressed in Blue Origin T-shirts. “You guys are going to do this, and your children are going to do this. This is going to take a long time.”

No pressure. In the meantime, Bezos said he would do what seems feasible in the present, such as reducing the cost of space launches by reusing parts of a rocket, something Blue Origin and Musk’s SpaceX already do. And starting with the Blue Moon lander, he would mine the natural resources on the moon.

Robotic missions to the moon have found evidence in the past decade that water exists on the moon, in the form of ice. Pence, along with the NASA administrator Jim Bridenstine, have insisted that exploiting that precious resource would make long-term outposts on the moon possible. It’s far easier than bringing along giant watercoolers from Earth. Future lunar explorers, they say, could feed the water ice into life-support systems, or split it into hydrogen and oxygen and turn it into rocket fuel. “Ultimately, we’re going to be able to get hydrogen from that water on the moon, and be able to refuel these vehicles on the surface of the moon,” Bezos said.

The moon might seem like an easy destination—it’s right there, and astronauts have gone before—but success is far from guaranteed. Just last month, an Israeli lander tried and failed to land on the surface, splintering into pieces as it crashed.

Bezos is a natural fit for this kind of endeavor. Today, rich guys are doing the work historically done by governments and their vaunted space agencies. They’re launching satellites, space-station supplies, even a Tesla. Soon, if everything goes well, they’ll even be launching NASA astronauts. And Bezos is the richest of them all. With a net worth of $156 billion, he’s the wealthiest person on the planet, and—considering we haven’t found anyone else out there—possibly the universe.

His immense wealth often prompts questions about how he chooses to spend it, and Bezos hinted at the criticism on Thursday. “There are immediate problems, things that we have to work on … I’m talking about poverty, hunger, homelessness, pollution, overfishing in the oceans,” he said. “But there are also long-range problems, and we need to work on those too.”

Blue Origin was founded before SpaceX, and before Virgin Galactic, another company run by a rich guy, Richard Branson, who wants to send paying customers to the space right above Earth. And yet Thursday’s event felt like something of a debut. The company went all out. The entire ballroom was awash in blue light. The walls were draped in black fabric dotted with LED lights that mimicked the cosmos as they twinkled. Tall blue fixtures that could best be described as oversize glow sticks surrounded the seating area. The playlist featured only space-themed songs, such as Electric Light Orchestra’s “Mr. Blue Sky” and Styx’s “The Outpost.”

The event felt like an introduction for Bezos too. Unlike Musk, Bezos lacks a dedicated following of fanboys drooling over his every move; the public is just beginning to learn just how much of a character Bezos might be. As he pushes ahead with his moon vision, he’ll be up against Musk’s particular brand of swagger. So far, Bezos’s wealthy space persona comes across as an Apple showman running through the specs of a new phone. But in the long run, it’s the moonshot that matters—and whether Blue Origin sticks the landing.



Pilots are about to receive a new memo from management: If you encounter an unidentified flying object while on the job, please tell us.

The U.S. Navy is drafting new rules for reporting such sightings, according to a recent story from Politico. Apparently, enough incidents have occurred in “various military-controlled ranges and designated airspace” in recent years to prompt military officials to establish a formal system to collect and analyze the unexplained phenomena. Members of Congress and their staffs have even started asking about the claims, and Navy officials and pilots have responded with formal briefings.

The Washington Post provided more details in its own story:

In some cases, pilots—many of whom are engineers and academy graduates—claimed to observe small spherical objects flying in formation. Others say they’ve seen white, Tic Tac–shaped vehicles. Aside from drones, all engines rely on burning fuel to generate power, but these vehicles all had no air intake, no wind and no exhaust.

The Navy knows how this sounds. It knows what you must be thinking. But the fact stands that some pilots are saying they’ve seen strange things in the sky, and that’s concerning. So the Navy is trying to assure pilots that they won’t be laughed out of the cockpit or deemed unhinged if they bring it up. “For safety and security concerns, the Navy and the [U.S. Air Force] takes these reports very seriously and investigates each and every report,” the Navy said in a statement to Politico.

Yet even as the Navy indicates it’s willing to discuss the taboo topic, it’s also shying away from three notorious little letters. UFO carries an airport’s worth of baggage, bursting with urban legends, government secrecy, and over-the-top Hollywood movies. The statements and quotes that the Navy provided to news outlets are devoid of any reference to UFOs. Instead, they’re called “unexplained aerial phenomena,” “unidentified aircraft,” “unauthorized aircraft,” and, perhaps most intriguing, “suspected incursions.”

The message is, if you see something, say something, but for God’s sake, lower your voice. Don’t call it a UFO. Which is funny, since the military came up with the name in the first place.

The earliest government programs dedicated to investigating UFO sightings in the late 1940s treated the claims, unsurprisingly, as a big joke. As a rule, officials dismissed and debunked any reports as hoaxes and hallucinations, according to UFOs and Government: A Historical Inquiry, a textbook-style deep dive published in 2012. This apparently didn’t sit well with some of the higher-ups.

In some ways, the Navy’s modern-day attempt to take seriously reports of UFO sightings is a rerun of what happened next. “I want an open mind,” Major General Charles Cabell, then the head of Air Force intelligence at the Pentagon, reportedly demanded at a meeting with subordinates in 1951. “Anyone who doesn’t keep an open mind can get out now.”

A new, secretive program, dubbed Project Blue Book, was quickly organized to investigate claims of strange visions in the sky without ridiculing them. Its director, Edward Ruppelt, introduced the term unidentified flying object sometime around 1953. The definition carried no hint of extraterrestrial life; in a national-security official’s scariest daydreams, the objects were probably Russian spycraft. For the military, a UFO was simply “any airborne object which by performance, aerodynamic characteristics, or unusual features, does not conform to any presently known aircraft or missile type, or which cannot be positively identified as a familiar object.”

By then, there had already been several high-profile reports of objects flying through or falling from the sky. For the public, these sightings didn’t just seem unfamiliar—they seemed not of this world. A civilian pilot had seen nine somethings flying in formation near Mount Rainier in Washington State. A rancher found mysterious wreckage on his property outside Roswell, New Mexico. Multiple people spotted a series of lights hovering over Washington, D.C., and moving toward the White House. The military even mobilized jets to intercept them, but found nothing.

In the meantime, UFOs further infiltrated the public consciousness. They sailed into Hollywood, which to this day remains obsessed with stories about aliens, from friendly creatures to nightmarish monsters. The fourth Men in Black movie is coming out this summer, and it’s probably not the last.

Elsewhere, the lines between fiction and reality blurred. People told harrowing stories of nighttime abductions. UFOs became the focus of conspiracy theories about government secrecy. A disheveled, wild-haired man on the History Channel suggested that extraterrestrial beings helped build Stonehenge. Over time, a collective opinion emerged about those who truly believed UFOs proved the existence of aliens, and it wasn’t a flattering one. “Let’s face it—believing in the paranormal has become shorthand for crazy,” wrote Alexandra Ossola in Futurism in 2017, on the lasting stigma surrounding UFO truthers.

Military pilots are well aware of the taboo. Christopher Mellon, a former deputy assistant secretary of defense for intelligence in the Clinton and Bush administrations and an advocate for UFO study, has said service members worry that reporting UFOs puts their careers at risk. They also worry that staying silent could threaten national security, in case one of those mysterious objects turns out to be a new form of aircraft from a rival country.

“Nobody wants to be ‘the alien guy’ in the national-security bureaucracy,” Mellon wrote in a Post op-ed last year. “Nobody wants to be ridiculed or sidelined for drawing attention to the issue.”

After two decades in operation, Project Blue Book eventually concluded there was “no evidence that [UFOs] are intelligently guided spacecraft from beyond the Earth.” They attributed most sightings to, among other things, clouds, weather balloons, and even birds. “The report brushes aside the demands of some scientists and laymen for a large-scale effort to determine the nature of such ‘flying saucers,’’ The New York Times wrote in 1969. “Such a project, the report says in effect, would be a waste of time and money.”

Future generations at the Pentagon thought differently. From 2007 to 2012, the Department of Defense operated a top-secret, $22 million program dedicated to investigating UFO reports, known as the Advanced Aerospace Threat Identification Program. The New York Times revealed its existence in a jaw-dropping story in 2017. “The program produced documents that describe sightings of aircraft that seemed to move at very high velocities with no visible signs of propulsion, or that hovered with no apparent means of lift,” the Times reported.

Although the funding eventually ran out, officials say Defense officers continue to investigate claims reported by service members.

Edward Ruppelt probably didn’t imagine the journey his three-letter abbreviation would take over the years. In 1955, five years before he died, he dumped everything he had learned about UFOs into a nearly 300-page report. “People want to know the facts,” he wrote. “But more often than not, these facts have been obscured by secrecy and confusion, a situation that has led to wild speculation on one end of the scale and an almost dangerously blasé attitude on the other.”

As his successors in the U.S. military draft their reports and memos and guidelines, carefully avoiding any mention of that word, they will no doubt run into the same trouble he did. “The report has been difficult to write,” Ruppelt wrote in 1955, his frustration hovering above the page like the air over pavement on a hot day, “because it involves something that doesn’t officially exist.”



Updated on December 28, 2018.

What are the aliens thinking? That’s always been a problem for the search for extraterrestrial intelligence (SETI). Until recently, SETI’s focus has been on alien “beacons,” signals that somebody somewhere intentionally beamed into space. But this traditional method involves making informed guesses about what the aliens were thinking when they built their beacons, and those guesses may turn out to be laughably wrong.

There’s an entirely new way to do SETI now, and understanding its promise begins with considering the properties of solar panels. Rather than just looking for beacons, SETI researchers now want to also search for unintentional “technosignatures” from alien industrial civilizations. An example of an unintentional technosignature could be pollutants in a distant planet’s atmosphere, or the shadow of a large artificial structure orbiting a planet.

The best way to find a technosignature is to search for the observable byproducts of activities that are necessary for all civilizations. For instance, industrial civilizations, by their very nature, must extract energy from their surroundings to do work and keep themselves running. In a creative paper published last year, the astronomers Manasvi Lingam and Avi Loeb wondered what technosignatures would radiate out from a civilization that powered its world by harvesting solar energy on a planetary scale.

It’s easy to imagine a civilization covering a fraction of its world with solar panels. This is something we might try in, say, the Sahara desert. What Lingam and Loeb did was calculate how the large-scale deployment of solar technology would leave a mark in light that bounces off a planet’s surface.

Technosignatures are similar to biosignatures, which are the means for finding life of any kind on a planet. The chemical makeup of an exoplanet’s atmosphere can, for example, be extracted by catching light passing through the planet’s veil of gas. On Earth, atmospheric oxygen or methane would quickly react away without our planet’s abundant life. That means seeing oxygen and methane in an exoplanet atmosphere might serve as a good signature for a biosphere thriving on that distant world.

But the vegetation covering our planet creates many kinds of signatures that could be seen from a distance. In particular, Earth’s vast array of leaves alters the spectrum of sunlight that we reflect back into space. Chlorophyll, the chemical responsible for photosynthesis, reflects light in the green part of the sun’s spectrum. Its “reflectance” also rises steeply at the boundary between red and infrared light, much of which escapes humans’ visual perception.* That means that sunlight bouncing off Earth has a noticeable “red edge” from all the biosphere’s leaves, grass, etc. If you plotted how much sunlight gets reflected from Earth versus that light’s wavelength, you’d see the planet’s “reflectance” rise sharply as you cross from the green parts to the red parts of the spectrum. The rise is so sharp that astrobiologists have long floated proposals aimed at searching for a photosynthetic red edge from exoplanets. They’ve even calculated the reflecting properties of novel forms of photosynthesis that might evolve on worlds with stars very different from our sun.

Lingam and Loeb saw that large-scale deployments of solar-energy collectors would also change the way sunlight reflects from an exoplanet. Focusing on the properties of silicon, they calculated the wavelengths of light that solar panels would absorb and the wavelengths that they’d bounce back into space. Instead of a red edge, their calculations showed that silicon-based solar panels would produce a sharp change in reflectance at the ultraviolet part of the electromagnetic spectrum. They called this the silicon edge.

A skeptic might argue that silicon is too human-centric a solar-panel construction material to produce a universal technosignature. Lingam and Loeb, however, gave convincing arguments that it’s the element of choice for solar-powered exocivilizations. There are only a few kinds of light-energy harvesting materials you’d find on any planet. Using the cosmic abundances of the elements, Lingam and Loeb showed that most planets are likely to have a lot of silicon lying around, making it an obvious component for building solar collectors.

For good measure, the two scientists also calculated the reflectance properties of gallium arsenide and the mineral perovskite, both of which might be used in solar panels. Each produced its own distinctive edge in the planet’s spectrum. Now, all astronomers have to do is go looking for these signatures. Fortunately, the telescopes they need to do so are starting to come online.

* This article previously misstated the reflective spectrum of chlorophyll.





What does it mean when your stomach rumbles? How do our bodies extract nutrients and vitamins from food? Does what you eat affect your mood? Digestion is an invisible, effortless, unconscious process—and one that, until recently, we knew almost nothing about. On this episode of Gastropod, we follow our food on its journey to becoming fuel, from the filtered blood that helps slide food into the stomach to the velvet walls and rippling choreography of the small intestine to the microbial magic of the colon and out the other end. And we do it by visiting the world’s most sophisticated artificial gut at dinnertime—a plumbing marvel named TIM that chews, swallows, squeezes, farts, and poops just like the real thing.

Before the invention of refrigeration, cadavers that early scientists dissected to learn about human physiology usually had their gut removed, to help reduce the stink. As a result, the digestive system largely remained a black box—food went in; the processed remains came out—until a window opened into that black box in 1822, in the form of a bullet hole in Alexis St. Martin’s stomach. An impoverished French Canadian trapper, St. Martin worked for the American Fur Company until he was accidentally shot. As Mary Roach, the author of Gulp: Adventures on the Alimentary Canal, told Gastropod, a surgeon named William Beaumont discovered that the bullet hole offered a literal opening into the mysterious workings of the stomach, because St. Martin’s “breakfast kind of spilled out.” Roach said it’s unclear whether Beaumont did his best to heal St. Martin: “He says that he did. But, I’m just guessing, maybe he kind of saw an opportunity here.”

For more than a decade, the two enjoyed a strange relationship, each dependent on the other. St. Martin lived at Beaumont’s house, and Beaumont took advantage of the unhealed stomach opening to dangle food in on a string, to learn that stomach acid can digest food even without the stomach’s viselike squeeze. Today Beaumont is recognized as one of the fathers of modern physiology.

Though scientists have long moved past the food-on-a-string method of research, the current techniques for investigating how we process our food, as digestion is occurring in our bodies, remain invasive and expensive. And so researchers also rely on sophisticated models of the gut that attempt to mimic every crucial stop along the 30-odd feet of our digestive system. To learn what these models can teach us, we traveled to the Netherlands to visit TIM, the world’s most sophisticated model gut, at the Dutch public-private research organization TNO. TIM’s entire system fills two huge, beige cabinets of silicone tubes and metal valves, from its mouth-input funnel to the fart tube that removes the smelly gas produced at the other end.

TIM’s system is larger than life—but the biologist Don Ingber and his colleagues at the Wyss Institute for Biologically Inspired Engineering at Harvard have shrunk the large and small intestines down to two small, flexible squares of clear rubber. On each “organ on a chip,” nearly invisible tubes are lined with cells from our intestinal walls—cells whose function mimics the activity in our own, real intestinal walls.

To compare these models with the real thing, we spoke with Giulia Enders, a doctor and the author of Gut: The Inside Story of Our Bodies’ Most Underrated Organ, and perhaps the biggest gut fan of all. Enders explained how the gut acts as a second brain in the body, with its own form of consciousness. By the time we’re through, you’ll have a new appreciation for the gut as a thing of beauty—and you may never be embarrassed by a rumbling stomach again. Listen in now!

This post appears courtesy of  Gastropod.



The NASA astronauts aren’t nervous for their next trip to space. They’ve been in the job for almost two decades, and they served as military pilots before that. Together, they’ve spent nearly 1,400 hours in orbit above Earth.

But they’ve never had a ride quite like this.

Doug Hurley and Bob Behnken are training for their first flight on a new astronaut-transportation system built by SpaceX, and as early as this summer could launch into the sky in a capsule named Dragon. The interior of the capsule is black and white, with clean lines and cushy seats. A triptych of touch screens, compatible with space-suit gloves, displays important information. The cabin is spacious enough to seat seven.

Decades after the first people reached Earth’s orbit, the physics of getting to space hasn’t changed. Neither have the dangers. But the aesthetics have.

The astronauts stress that the safety of the launch vehicle matters most, but that doesn’t mean they aren’t impressed. “It’s an incredibly sleek-looking vehicle from the inside,” Hurley told me.

When the United States and the Soviet Union began sending astronauts and cosmonauts to space, capsules were small and cramped. Control panels brimming with switches, buttons, and levers covered nearly every inch of the interior. Life-support systems and other equipment crowded the single seat. If there were any nooks and crannies, they were crammed with wires. NASA astronauts, who couldn’t be more than 6 feet tall to fit inside, joked that “you don’t get in it, you put it on.”

Such utilitarian capsules were made to serve a single purpose: Put a man in orbit and then bring him home alive. There was no room for error, so there was no room for much else, either.

Though the computers have been updated, the Soviet design for the Soyuz spacecraft, developed in the 1960s, remains in use. Hardware juts out from the walls, and passengers are squished together, with life-support supplies wedged between them and their legs pulled close to their chest. The system has been considered so reliable that China bought Soyuz technology from Russia in the 1990s to build the country’s own crew-friendly spacecraft, Shenzhou. Unlike the earliest crew capsule, the Soyuz can fit three passengers and regularly swaps crew members on the International Space Station. But it’s a tight fit.

“In Soyuz, there was so much equipment between the seats that I couldn’t even see [the cosmonaut’s] head right next to me,” says Suni Williams, a NASA astronaut and Soyuz veteran.

It’s also the only way up. China hasn’t launched a Shenzhou crew since 2016, and the United States folded its Space Shuttle program in 2011.

The United States has relied on Russia since then, paying tens of millions of dollars per seat to fly NASA astronauts to the International Space Station, where they stay for up to six months at a time.

After NASA retired the shuttles, the agency awarded billion-dollar contracts to SpaceX and Boeing to do the job instead. SpaceX built the Dragon, which recently survived its first flight without a crew, and Boeing developed the Starliner, scheduled to fly this spring.

Kjell Lindgren, a NASA astronaut and a backup crew member for the SpaceX flight, says the difference between the Dragon and the Soyuz is striking. “It’s a beautiful interior,” Lindgren says.“If you had to think about what spacecraft looked like for a movie set, or from the future, it’s a little bit of that.”

Compared with Soyuz, these quarters are lavish. “You can turn your head and you can look at the person next to you, which is nice—you can give him a thumbs up or give him an okay without having to talk,” says Williams, who’s assigned to the first crewed flight of the Starliner.

The interior of the Dragon feels downright bare next to the Soyuz and the space shuttles. While the shuttle, the size of a single-aisle airplane, was considerably roomier, its control panels were overstuffed. Hurley estimates that the SpaceX capsule has about 30 manual switches and circuit breakers, compared with the shuttle’s 2,000.

“You had switches literally right next to each other, and if you threw the wrong one, you could make your day a lot worse rather than a lot better,” he says.

That risk is minimal inside the Dragon, where passengers interact with touch screens. But the modern edition, while visually pleasing, has inadvertently changed the flight experience that astronauts are used to.

On the Soyuz and the shuttles, crew members flipped switches and pressed buttons, sometimes with the help of a stick. That sense of texture is lost with touch screens. Astronauts don’t receive the physical feedback that signals they’ve completed an important step or procedure. Behnken says he’s had to retrain his mind to process his actions on the screen.

“There’s a mode you can turn on where you can see the touch, so that when you put your finger on the screen, it blooms or it flares—which is extremely helpful when you’re wearing gloves and you might not know if you’ve actually touched it,” he says. “It’s just training yourself to maybe use a different cue, like a visual cue instead of a physical cue, that you’ve actually accomplished the thing that you were trying to do.”

The sleek display has provided some operational bonuses. On the Soyuz, astronauts don’t receive many alerts about their progress as the capsule hurtles toward orbit and the rocket falls away. Confirmation comes from a jolt of the capsule as the rocket hardware detaches. “You don’t have anything on the display that shows that,” Williams says. But “on these other spacecraft, we have a visual display of how that’s happening or words that tell us, this just happened.”

The astronauts assigned to Dragon and Starliner warn that the spacecraft might not always look as good as they do now. The shuttles, for example, became packed with extra equipment in lieu of expensive renovations over the years. “The shuttle was cluttered with 135 flights’ worth of people living with it and trying to make it better,” Behnken says. “As we go forward here, they’ll get cluttered a little bit by the people adding things to them.”

For now, the squeaky-clean spacecraft represent a new era in spaceflight. While the U.S. government has paid private companies to build hardware for NASA, it has never handed over the responsibility of reaching space to one of them. NASA engineers have provided oversight and guidance during development, but SpaceX and Boeing are in charge of the training, engineering, and of course, interior design.

These are private companies worried about revenue streams, not taxpayer concerns. The spacecraft they develop to deliver NASA astronauts to their space office could also lug wealthy tourists on a loop around Earth. They want the environment to be appealing, luxurious. That’s especially true for Elon Musk, SpaceX’s founder, who has a taste for polished transportation design, whether it’s rockets or electric cars. But both companies have every incentive to think about avionics and aesthetics.

“We’ve passed where we just jammed a man in a can,” Williams says.



As the sun rose on Wednesday, 26 million Americans peered out their windows onto a land chilled to 20 degrees Fahrenheit below zero. And that’s when the air was still: When the wind picked up, as it did from Chicago to the Dakotas, it could feel like it was 50 below. Boiling water tossed from a pot turned into a cloud of snow before it could hit the ground.

The experience was half Uz, half Oz. But had Dorothy’s house been relocated to Mount Everest, not Munchkinland, her journey still would have been more pleasant than many midwesterners’ Wednesdays. They spent the day essentially shut down, as hundreds of schools, offices, universities, and even an ice castle closed. The National Weather Service advised against “talking” or “taking deep breaths” outside so as to keep delicate lung tissue from freezing on contact.

The vortex was felt nearly across the entire continent. As many as 225 million Americans—from Alabama to Nevada—could have started their 8 a.m. commute in below-freezing temperatures. 

It is dangerous, record-breaking, can’t-look-away weather. Yet this cold snap’s arrival was preceded by a marvel so spectacular that we hardly noticed it: It was correctly predicted. As early as a month ago, forecasters knew that colder-than-average weather would likely strike North America this month; a week ago, computer models spit out some of the same figures that appeared on thermometers today.

Meteorologists have never gotten a shiny magazine cover or a brooding Aaron Sorkin film, and the weather-research hub of Norman, Oklahoma, is rarely mentioned in the same breath as Palo Alto. But over the past few decades, scientists have gotten significantly—even staggeringly—better at predicting the weather.

How much better? “A modern five-day forecast is as accurate as a one-day forecast was in 1980,” says a new paper, published last week in the journal Science. “Useful forecasts now reach nine to 10 days into the future.”

The paper is a birthday present from meteorology to itself: The American Meteorological Society turns 100 this year. But it also acts as a good report card on how far weather prediction has come.

“Modern 72-hour predictions of hurricane tracks are more accurate than 24-hour forecasts were 40 years ago,” the authors write. The federal government now predicts storm surge, stream level, and the likelihood of drought. It has also gotten better at talking about its forecasts: As I wrote in 2017, the National Weather Service has dropped professional jargon in favor of clear, direct, and everyday language.

“Everybody’s improving, and they’re improving a lot,” says Richard Alley, an author of the paper and a geoscientist at Penn State.

With the current polar vortex, the first signs came almost a month in advance. On the final day of 2018, scientists detected what they call a “sudden stratospheric warming event,” high above the North Pole. The stratosphere, a layer of air about 20 miles above the surface, was being rocked by waves of warm air from below.

“What happens in the Arctic does not stay in the Arctic,” warned the meteorologist Andrew Freedman at the time. “Sudden stratospheric warming events are known to affect the weather in the U.S. and Europe on a time delay.” The next 60 days would probably be colder than average, he said.

By January 20, much of North America hit its first cold snap of the season. Then, a week ago, the European weather model began to project that a dangerous air mass would descend over the central United States. “It’s safe to say that the [European] weather model cannot get any colder for the Midwest,” said the meteorologist Ryan Maue on Twitter. “Wind chills would be in the -40 degree to -50 degree Fahrenheit range as well. This would be bad … but hopefully the model moderates.”

The model barely budged. On Wednesday morning, Minneapolis recorded a wind chill of 52 degrees below zero.

This kind of pattern—where a seasonal climatic projection (“It will be colder than average at the end of the month”) precedes a definite week-ahead forecast (“It will be 40 degrees below zero on Tuesday”)—will become more common in the years to come. Meteorologists are increasingly uniting weather models and climate models, allowing them to project the general contours of a season as it begins.

“The conventional wisdom was that weather prediction would saturate after a week or so” because the atmosphere is chaotic, Antonio Busalacchi, the president of the University Corporation for Atmospheric Research, told me. But “new areas of forecasting … really take an Earth-systems-science approach. It’s no longer just [modeling] the atmosphere by itself.”

Understanding months-long events like El Niño, for instance, has allowed meteorologists to go beyond the seven-day forecast. Alley, the Penn State professor, says that he is awed by the new models. Well-studied features of Earth’s climate—like the temperate Gulf Stream in the Atlantic Ocean—emerge in computer models, even though developers have written code that only mimics basic physics. “You translate Newtonian physics into a sphere and get Coriolis [force],” he says. “There’s no line in the code that says, Please make a Gulf Stream. But it is the physics of the Earth, so when you spin it up, the Gulf Stream appears because it has to.”

We are now surrounded by the products of these miraculous models. In 2009, a back-of-the-envelope study estimated that U.S. adults check the weather forecast about 300 billion times per year. Perhaps in all that checking we have forgotten how strange the forecast is, how almost supernatural it is that people can describe the weather before it happens. More than 1,000 years ago, the Spanish archbishop Agobard of Lyon argued that no witch could control the weather because only God could understand it. “Man does not know the paths of the clouds, nor their perfect knowledges,” he wrote. He cited the Book of Job for authority, which asks: “Dost thou know when God … caused the light of his cloud to shine? Dost thou know the balancings of the clouds … ?”

It’s no slight to any whirlwind—arctic, divine, or otherwise—to point out that Americans now certainly do know the balancings of the clouds. There is a basic-cable channel devoted to the topic.



As far as anyone knows, we have always been alone. It’s just us on this pale-blue dot, “home to everyone you love, everyone you know, everyone you ever heard of,” as Carl Sagan so memorably put it. No one has called or dropped by. And yet the universe is filled with stars, nearly all those stars have planets, and some of those planets are surely livable. So where is everybody?

The Italian physicist Enrico Fermi was purportedly the first to pose this question, in 1950, and scientists have offered a bounty of solutions for his eponymous paradox since. One of the most famous came from Sagan himself, with William Newman, who postulated in a 1981 paper that we just need patience. Nobody has visited because everyone is too far away; it takes time to evolve a species intelligent enough to invent interstellar travel, and time for that species to spread across so many worlds. Nobody is here yet.

Other researchers have argued that extraterrestrial life might rarely become spacefaring (just as only one species on Earth ever has). Some argue that tech-savvy species, when they arise, quickly self-destruct. Still others suggest that aliens might have visited in the past, or that they’re avoiding us on purpose, having grown intelligent enough to be suspicious of everyone else. Perhaps the most pessimistic answer is a foundational paper from 1975, in which the astrophysicist Michael Hart declared that the only plausible reason nobody has visited is that there really is nobody out there.

Now comes a paper that rebuts Sagan and Newman, as well as Hart, and offers a new solution to the Fermi paradox that avoids speculation about alien psychology or anthropology.

The research, which is under review by The Astrophysical Journal, suggests that it wouldn’t take as long as Sagan and Newman thought for a spacefaring civilization to planet-hop across the galaxy, because the movements of stars can help distribute life. “The sun has been around the center of the Milky Way 50 times,” says Jonathan Carroll-Nellenback, an astronomer at the University of Rochester, who led the study. “Stellar motions alone would get you the spread of life on time scales much shorter than the age of the galaxy.” Still, although galaxies can become fully settled fairly quickly, the fact of our loneliness is not necessarily paradoxical. According to simulations by Carroll-Nellenback and his colleagues, natural variability will mean that sometimes galaxies will be settled, but often not—solving Fermi’s quandary.

The question of how easy it would be to settle the galaxy has played a central role in attempts to resolve the Fermi paradox. Hart and others calculated that a single spacefaring species could populate the galaxy within a few million years, and maybe even as quickly as 650,000 years. Their absence, given the relative ease with which they should spread, means they must not exist, according to Hart.

Sagan and Newman argued it would take longer, in part because long-lived civilizations are likelier to grow more slowly. Faster-growing, rapacious societies might peter out before they could touch all the stars. So maybe there have been a lot of short-lived, fast-growing societies that wink out, or a few long-lived, slowly expanding societies that just haven’t arrived yet, as Jason Wright of Pennsylvania State University, a co-author of the new study, summarized Sagan and Newman’s argument. But Wright doesn’t agree with either solution.

“That conflates the expansion of the species as a whole with the sustainability of individual settlements,” he says. “Even if it is true for one species, it is not going to be this iron-clad law of xenosociology where if they are expanding, they are necessarily short lived.” After all, he notes, life on Earth is robust, “and it expands really fast.”

In their new paper, Carroll-Nellenback, Wright, and their collaborators, Adam Frank of Rochester and Caleb Scharf of Columbia University, sought to examine the paradox without making untestable assumptions. They modeled the spread of a “settlement front” across the galaxy, and found that its speed would be strongly affected by the motions of stars, which previous work—including Sagan and Newman’s—treated as static objects. The settlement front could cross the entire galaxy based just on the motions of stars, regardless of the power of propulsion systems. “There is lots of time for exponential growth, basically leading to every system being settled,” Carroll-Nellenback says.

But the fact that no interstellar visitors are here now—what Hart called “Fact A”—does not mean they do not exist, the authors say. While some civilizations might expand and become interstellar, not all of them last forever. On top of that, not every star is a choice destination, and not every planet is habitable. There’s also what Frank calls “the Aurora effect,” after Kim Stanley Robinson’s novel Aurora, in which settlers arrive at a habitable planet where they nonetheless cannot survive.

When Carroll-Nellenback and his co-authors included these impediments to settlement in their model and ran many simulations with different star densities, seed civilizations, spacecraft velocities, and other variations, they found a vast middle ground between a silent, empty galaxy and one teeming with life. It’s possible that the Milky Way is partially settled, or intermittently so; maybe explorers visited us in the past, but we don’t remember, and they died out. The solar system might well be amid other settled systems; it’s just been unvisited for millions of years.

Anders Sandberg, a futurist at the University of Oxford’s Future of Humanity Institute who has studied the Fermi paradox, thinks spacecraft would spread civilizations more effectively than stellar motions. “But the mixing of stars could be important,” he wrote in an email, “since it is likely to spread both life, through local panspermia”—the spread of life’s chemical precursors—“and intelligence, if it really is hard to travel long distances.”

Frank views his and his colleagues’ new paper as SETI-optimistic. He and Wright say that now we need to look harder for alien signals, which will be possible in the coming decades as more sophisticated telescopes open their eyes to the panoply of exoplanets and begin glimpsing their atmospheres.

“We are entering an era when we are going to have actual data relevant to life on other planets,” Frank says. “This couldn’t be more relevant than in the moment we live.”

Seth Shostak, an astronomer at the SETI Institute who has studied the Fermi paradox for decades, thinks it is likely to be explained by something more complex than distance and time—like perception.

Maybe we are not alone, and have not been. “The click beetles in my backyard don’t notice that they’re surrounded by intelligent beings—namely my neighbors and me,” Shostak says, “but we’re here, nonetheless.”

This post appears courtesy of Quanta Magazine.



The last decade of Elizabeth Madin’s work began with one day of terrible weather.

In 2010 she and her husband, Joshua, both ecologists, flew to Heron Island in Australia to study how fishing influences the creatures of the Great Barrier Reef. But they arrived to find strong winds and rough seas that constrained them to the beach. While trying to work out how to spend her time while the elements calmed down, Madin happened across a large satellite image of the island and its surrounding lagoon. That’s when she noticed the rings.  

The lagoon is full of “patch reefs”—isolated chunks of coral that can be as small as a melon or can span acres. Regardless of size, these chunks are often encircled by barren rings of sand, which separate them from the algae and seagrass that lie further afield. “It’s a teeming city on the reef and then when you move away, it’s like a desert,” says Madin. These bare circles are obvious to swimmers, but they’re also visible on satellite images like the one Madin found.

First described in the 1960s, the circles have since become known as grazing halos. The idea is that fish and sea urchins that live within the reefs gobble up anything that grows nearby, leaving bare sand behind. But these grazers are loathe to venture into the open, where they could be easily picked off by sharks, barracuda, snappers, and jacks. Their fear keeps them close to the reef, and their hunger keeps that zone free of greenery. Hence: grazing halos.

At least, that was the theory. No one had ever truly tested it, so the Madins decided to do so. As they waited for the weather to calm down, they waded through the waist-deep lagoon and sowed clumps of seaweed in various locations. Anything they placed within nine meters of a patch reef was quickly eaten; everything else was largely untouched. The grazer hypothesis was right. “We thought it would be a quick open-and-closed study,” says Madin, who is now at the Hawaii Institute of Marine Biology. “But I fell down a rabbit hole. These halos are far more complex than we originally thought.”

In subsequent trips to Heron Island, Madin and her colleagues carpeted the lagoon with GoPro cameras to work out exactly which fish are creating the halos. To their surprise, they learned that grazers such as surgeonfishes never ventured out to the very edges of the halos. These fish were clearing some of the greenery away, but not all of it.

Their accomplices weren’t active during the day, so to find them, the team had to jury-rig a network of night-vision cameras and infrared lights. That’s how they learned that the outer rims of the halos are the work of emperors and sweetlips—fish that forage for buried shellfish by rootling through the sand “much like pigs,” Madin says. Bigger, less vulnerable, and less fearful than the grazing species, they’re more likely to stray from the reefs. They widen the halos that the grazers create.

But even that can’t be the whole story. If the halos are entirely driven by the presence of fish, they should be more common in waters where fishing is forbidden. They should also be smaller, since fishing bans preserve big predators, which force fearful grazers to stick closer to the reefs. But only the former is true. By comparing 214 patch reefs through the Great Barrier Reef, the team showed that halos are more common within marine reserves—and especially within mature ones that are at least 8 years old. But they were neither bigger nor smaller. “That was a big surprise,” Madin says. “We’re surely missing something.”

The team also can’t explain why the halos sometimes grow and shrink, disappear and reappear. These changes don’t correlate with obvious environmental conditions such as temperature or wind speed. Are they related to other reef dwellers, such as invertebrates living in the sand? Could they be influenced by forces beyond grazing and digging, such as the poop from local fish? Are the microbes that live in the reefs involved? Halos seemed like a simple matter of hungry predators and fearful grazers. But “to truly understand the mechanisms that drive them, we’ll likely need to integrate most of what we know about reef ecology,” says Randi Rotjan from Boston University.

Other mysterious patterns are similarly testing our understanding of nature. Take the “fairy circles” of Namibia and Australia—bizarre spots of barren soil that pockmark grassy landscapes. Some scientists think they’re the work of termites. Others say that they’re caused by plants, whose battles for water self-organize the land into patches of drought and moisture. Whatever the answer, the surprisingly vigorous debate between these two camps highlights how little we know about the forces that shape landscapes—or seascapes.

By understanding those forces, Madin hopes that scientists could eventually use the halos to quickly assess the health of coral reefs, and the fish populations within them. Rather than visiting these sites directly, they could simply measure the presence and extent of the halos on satellite images.

“We would never completely replace the traditional methods of sending divers down to count fish and corals,” she cautions. But in remote areas, “it’s expensive, difficult, and time-consuming to send diver teams, and in some places, you can’t even get a boat in. With satellite images, we can see those places and get a first-cut idea about what might be changing in their food webs. We can also go back in time, which you can’t do on a swim.”



In the late 1980s, an Inuit subsistence hunter named Jens Larsen killed a trio of very strange whales off the western coast of Greenland.

He and his fellow subsistence hunters would regularly catch two species: narwhals, whose males famously have long, helical tusks protruding from their snouts; and belugas, with their distinctive white skin. But Larsen’s new kills were neither. Their skin wasn’t white, nor mottled like a narwhal’s, but uniformly grey. The flippers were beluga-like, but the tails were narwhal-esque. In all his years of hunting, Larsen had never seen anything like them. He was so struck that he kept one of their skulls on the roof of his toolshed.

In 1990, it caught the attention of Mads Peter Heide-Jørgensen, a scientist who studies marine mammals. With Larsen’s permission, he took it to the Greenland Fisheries Research Institute in Copenhagen for study. And after comparing it to the skulls of known belugas and narwhals, he suggested that it might have been a hybrid between the two species—a narluga.

It was a reasonable idea. Belugas and narwhals are the same size, share the same Arctic waters, and are more closely related to each other than to any other species. Individuals from both species have been found swimming among each other’s pods. But no one had ever found a narluga before, and at the time, Heide-Jørgensen had no way of confirming his hypothesis.

That changed in the intervening decades, as researchers developed more and more powerful ways of yanking minuscule amounts of DNA from bones. These techniques have typically been used to study ancient creatures such as Neanderthals and mammoths. And now they have helped to prove that the narluga is indeed a narluga, supplying the first genetic evidence that such creatures even exist.

By analyzing DNA extracted from one of the creature’s teeth, a team led by Eline Lorenzen from the Natural History Museum of Denmark showed that it was a male, born to a beluga father and a narwhal mother. Most of its DNA was a half-and-half mix between the two species, but its mitochondrial DNA—a secondary set that animals inherit only from their mothers—was entirely narwhal. “A while back, we presented our findings at a conference of 150 people who are very into belugas, and you could hear a pin drop,” Lorenzen says. “None of them were familiar with hybrids between those two species.”

A brief digression: When naming hybrid animals, patriarchal conventions dictate that the father’s species comes first in the portmanteau. A cub born to a male polar bear and a female grizzly is a pizzly, but one with a grizzly dad and a polar mom is a grolar. So, technically, the skull from Larsen’s toolshed is a belwhal, not a narluga. But the latter name might well stick because it’s been called that for decades and, as Lorenzen says, narluga just sounds better.

Narwhals and belugas have been evolving independently for at least 1 million years. They clearly can still breed with each other, but no one knows why or how often that happens. Both species breed at a time of year when thick sea ice keeps inquisitive scientists out, so we know next to nothing about how they reproduce. The male narwhal’s tusk, for example, was thought to be so sexually attractive that a female narwhal would be unlikely to mate with a tuskless male from another species. And yet, the narluga’s narwhal mother clearly did have sex with a beluga. “What are the odds that someone would find the only hybrid ever and keep it on his shed, and that someone else would find that and send it to a museum?” Lorenzen says. “There must be more. But maybe not! We have no idea.”

The strangest part of the narluga’s skull is its teeth. Belugas have up to 40 teeth in their upper and lower jaws, all of which are identical. Narwhals have no teeth at all, besides the spiraling tusk and a pair of vestigial teeth behind it. The narluga seemingly split the difference between its parents with 18 teeth, all different and strangely shaped. Many of these stuck out horizontally, and some even had spirals that turned in the same direction as a narwhal’s tusk. It’s as if someone took the program for creating a narwhal tusk and ran it in a beluga’s mouth.

By analyzing the chemical composition of those weird teeth, Lorenzen’s team could work out what kind of food the narluga ate. And they showed that its diet must have been radically different from either of its parents, both of which dive in search of fish and squid. The narluga’s teeth, by contrast, were chemically closer to bottom-feeders like walruses, which dig up buried prey from the ocean floor. Perhaps the narluga did the same thing, using its outwardly protruding teeth as shovels for rootling through sand.

There’s something faintly magical about that. This fluky merger between two species ended up with a mouth that doesn’t normally exist in nature but still found a way of using it. It lived neither like a beluga nor a narwhal, but it lived nonetheless.

But there’s a dark side to hybridization, especially for the Arctic’s endangered residents. If hybrids are infertile, as they often are, they would act as genetic dead ends for already small populations. If they are fertile, the mixed genomes of their offspring could displace those of their respective parents. As the Arctic warms and its ice disappears, some scientists are concerned that once-isolated species could be meeting and mating more frequently, and damaging their own prospects in the process.

Does the narluga “represent an isolated event, or does it signal an increase in hybridization as a consequence of changing climates?” asks Sandra Talbot from the United States Geological Survey. And if it’s the latter, does cross-breeding offer a way for narwhals to bolster their relatively low levels of genetic diversity by bringing in genes from their closest relatives, or might it inadvertently doom them?

Modern humans still carry the genes of Neanderthals, Denisovans, and our other ancient relatives, but those groups are all extinct now. If polar bears and narwhals get edged out in a world of pizzlies and narlugas, they could suffer the same fate.



NASA has spent the past decade working on the world’s most powerful rocket. The Space Launch System will stand taller than the Statue of Liberty. It will be capable of lifting more than 200,000 pounds into space. It’s designed to launch American astronauts toward the moon once again.

The SLS is supposed to fly for the first time in June 2020. NASA plans to launch an empty crew capsule on a trip around the moon and back, an important test before putting people on board. But the rocket isn’t ready.

“We’re now understanding better how difficult this project is,” Jim Bridenstine, the NASA administrator, told Congress, which controls the agency’s budget, this week. “And it is going to take some additional time.”

Bridenstine seemed to be setting up another disappointing delay, ready to reassure lawmakers with a new date for the inaugural flight of the record-breaking rocket. Instead, he said NASA might scrap its current plan and use a different rocket altogether.

Officials will now consider using a rocket from a commercial U.S. company, not a federal agency, to launch the Orion capsule on a three-week journey around the moon.

The announcement marks a stunning reversal in long-term strategy for the space agency. NASA has already spent billions of dollars to develop the SLS and prepare the rocket to carry the capsule to space. Under this plan, the agency would presumably pay a company to do the job. Donald Trump’s administration wants to get NASA to the moon next summer, and that appears to take precedent over how it gets there.

“We have amazing capability that exists right now that we can use off the shelf in order to accomplish this objective,” Bridenstine said.

A return to the moon has been a top priority for NASA since President Trump was elected, and the Space Launch System is key to the effort. The Trump administration wants to use the rocket to help build a floating lunar outpost, the equivalent of a little International Space Station around the moon, and it wants construction completed by 2024.

But the SLS program, established during Barack Obama’s administration, is running behind schedule and over budget. The office of NASA’s inspector general has criticized NASA and Boeing, the rocket’s main contractor, over their management and performance, predicted more delays, and even questioned whether the entire effort is sustainable.

NASA has a long history of being late, including on some of its most high-profile missions, such as the Hubble Space Telescope and the Mars Curiosity rover. According to government auditors, the agency’s major projects experienced average launch delays of 12 months in 2018, the worst in a decade. Some degree of delay is certainly expected, considering the nature of the work; when your job is to try something no one else has ever done before, in outer space, it’s difficult to estimate how long it will take.

But engineering challenges are only part of the equation. NASA tends to set overly ambitious deadlines, a habit forged in the days of the Apollo era, when budgets and schedules were secondary concerns to success. When the payoff was beating the Soviets to the moon, lawmakers ultimately accepted these pitfalls.

This kind of culture might have been sustainable if NASA’s budget continued to grow, or even remained steady, in the years since the Apollo program, but it has shrunk instead. (The president’s budget proposal for NASA, released days ago, included a 17 percent cut in funding for SLS.) Add the effects of rotating casts in Washington throughout the years, featuring players with their own ideas about what NASA should do, and you’ve got a recipe for not getting much done on time.

Bridenstine said the moon mission would require a heavy-lift vehicle, a type of powerful rocket capable of lifting something into orbit above Earth. The administrator didn’t say which rockets the agency would consider, but he has options. There’s the Delta IV Heavy, built by the United Launch Alliance, a joint venture of Boeing and Lockheed Martin, the contractor for the capsule. This mammoth rocket launched the Orion capsule into orbit for a quick, four-hour test in 2014. And then there’s the Falcon Heavy, even more powerful, from Elon Musk’s SpaceX, which flew for the first time last year.

SpaceX seems like a natural fit for this endeavor. The company is currently building a rocket-and-capsule combo designed to reach the moon in 2023, and a Japanese billionaire has already bought a ticket for as many as eight passengers. Musk has spent years saying that someone should have built a base on the moon by now. He said it again less than two weeks ago, and Bridenstine was literally sitting next to him. “I hope we go back to the moon soon,” Musk said. “We should have a base on the moon, like a permanently occupied human base on the moon.”

And yet SpaceX has been conspicuously absent from the Trump administration’s plans for lunar exploration. NASA and SpaceX already have a solid working relationship—Bridenstine and Musk even posed for a selfie recently, wearing matching hard hats before an important SpaceX launch. But though NASA has solicited proposals from U.S. space companies for rover and lander concepts, as well as hardware for the proposed lunar outposts, SpaceX’s name hasn’t come up, at least not publicly. (SpaceX did not respond to a request for comment about the announcement.) Bridenstine did celebrate the company’s successful launch to the International Space Station during his Congress appearance this week, and for him, a private company’s triumphs in space could still count as a victory for American innovation and industriousness. These achievements also make it difficult, or at least uncomfortable, for NASA to tout costly programs when commercial companies are doing similar work for less.

Trump himself has picked up on that. “We’re letting them use the Kennedy Space Center for a fee and, you know, rich guys, they love rocket ships,” Trump said last year, after the Falcon Heavy blasted off from a launchpad in Cape Canaveral that NASA leases to SpaceX. “That’s better than us paying for them.” He went on to say that NASA would probably have run through “40, 50 times” the money to achieve the same goal.

The president’s remarks seem eerily portentous now.

The news came as a surprise, including to the very engineers developing the Orion capsule. A spokesperson for Lockheed Martin says NASA told them about the potential change a few days ago, and added that the company is “committed to this goal.” But it appears that some employees weren’t in the loop.

“Completely changing the mission would invalidate tons of work already done,” says an engineer who works for Lockheed Martin, who requested anonymity because he was not authorized to speak with the press. “Pretty irritating that I have been busting my ass for a couple of weeks on some close-out analysis for [the first SLS flight] that directly pertains to SLS, only for the administrator to drop this bomb.”

The administrator’s proposed plan would require more work for Orion engineers, he said, which could lead to even more delays.

The SLS could have taken the Orion crew capsule directly to the moon. No commercial rocket is powerful enough to get that far, so Bridenstine has proposed breaking the mission into two launches. The first would deliver the capsule and its service module, supplied by the European Space Agency, which provides the electricity, propulsion, temperature regulation, and other important features. The second would deliver a smaller rocket equipped with an engine that can be used in space. The spacecraft and the rocket would join together, and the engine would fire to boost them all toward the moon.

NASA has completed such complicated unions in the past, but the current design for Orion doesn’t accommodate it. “Between now and June of 2020, we would have to make that a reality,” Bridenstine said.

“The integration challenges are significant,” the Coalition for Deep Space Exploration, an industry group that represents Boeing and other aerospace companies, said in a statement. “It is also clear that this approach would require additional funding, since the idea is to undertake both this mission and to continue development of the SLS apace.”

Bridenstine said that he remains committed to supporting the development of the SLS for future missions, including a crewed visit to the moon. No commercial rocket is certified to transport humans, and companies would need to undergo rigorous reviews and testing from NASA if they wanted to do it. But all missions to space, whether they carry a Tesla or an astronaut, start with a rocket—and it really helps to have one if you’re raring to fly.



Updated at 2:40 p.m. ET on February 13, 2019.

The Mars probe came barreling in. It streaked through the planet’s atmosphere at about 12,000 miles per hour. With the surface in sight, its parachute unfurled. The probe fired its rockets to slow itself down, and inflated its airbags to cushion the landing. Touching down gently, it bounced across the clay-colored terrain.

When the dust settled, the probe unwound itself, like a flower opening toward the sun, and revealed its cargo: a rover, no bigger than a golf cart.

The rover, named Opportunity, was sent to study what the Martian surface was made of and search for signs of a watery past. If life had ever existed on this other planet, the composition of the alien dust, soil, and rock might hint at its nature. The rover’s work was slow and precise. For years, it rolled over plains and craters, digging into the ground and relaying its findings to Earth.

Then, last summer, it stopped. On Tuesday, following months of attempts to regain contact, the Opportunity team sent a final set of commands to the rover. After receiving no response, NASA announced that the Opportunity mission, after nearly 15 years, was officially over.

“I was there with the team, as the commands went out into the deep sky. And I learned this morning that we had not heard back,” Thomas Zurbuchen, associate administrator of NASA’s science division, said in a press conference. “It is therefore that I’m standing here with a sense of deep appreciation and gratitude that I declare the Opportunity mission as complete.”

In June 2018, an enormous dust storm clogged the Martian atmosphere, blocking sunlight from reaching the surface. Opportunity, a solar-powered rover, couldn’t charge its batteries in the darkness and entered a deep sleep.

Engineers at NASA’s Jet Propulsion Laboratory made more than 1,000 attempts to rouse Opportunity. The rover did not respond, even as the storm passed in September. The team held out for a windy season in January, which could wipe off any dust coating the rover’s solar panels. They ran out of options. Engineers transmitted a final set of commands to Opportunity on Tuesday night—one last chance—and received nothing but silence in return.

During its years on Mars, Opportunity crept along at a tiny fraction of a mile per hour. A robotic arm burrowed into the surface, exposing fresh rock, and scooped soil samples for analysis. Scientists back on Earth delighted as Opportunity returned detailed images of the landscape, and when the rover found evidence that Mars once had water, enough to support microbial life.

The engineers sent the commands, directing the rover where to drive and what to inspect, but it seemed, at times, as if Opportunity was doing the work on its own. The rover’s communication with mission control felt less like data transmissions from a mindless robot, and more like dispatches from a curious explorer.

The end of Opportunity leaves only one functioning rover on Mars: Curiosity. Curiosity arrived on the planet in 2012 and, despite some technical problems of its own last year, is in good health. The rover is on the opposite side of the planet, and with Opportunity shut down, “we basically lost our surface presence on one half of Mars,” says Mike Seibert, a former Opportunity flight director. (Seibert was around for the last massive dust storm on Mars, in 2007, which the rover survived just fine.)

Curiosity doesn’t have the time or speed to trundle over and check on its friend. The only views NASA has of Opportunity come from robotic spacecraft that orbit Mars, like satellites circle the Earth. From here, Opportunity is a fuzzy smudge against a vast, rugged landscape.

For engineers and scientists, the pain of the mission’s demise is softened by this fact: Opportunity was supposed to die years ago. It was one of two rovers NASA landed on Mars in 2004. The other, named Spirit, touched down on the other side of the planet. The missions were expected to last three months, but they kept going for years.

Spirit met its end in 2009. While exploring, the rover broke through some crust and slipped into a sand pit. Engineers commanded the rover to wiggle its wheels, but it was stuck. For the first time in its mission, Spirit wouldn’t be able to drive to a north-facing slope. The rovers looked for these slopes each winter, where their solar arrays could absorb as much sunlight as possible each day. “We saw it coming,” Steve Squyres, the principal investigator for both rovers, told me. “I knew from day one, if Spirit has to spend a winter on flat ground, that was going to be Spirit’s last winter.”

Opportunity was in good shape when the skies darkened last year. It was exploring a valley that might have been carved by powerful winds or flowing water. Over the years of the rover’s journey on Mars, mission planners had stared for hours at high-resolution images of the terrain to find intriguing spots for it to investigate. In total, the rover drove 28 miles, more than a marathon.

As engineers prepared to transmit their final commands, through massive radio antennae positioned around the world, the mood at JPL was somber, according to Tanya Harrison, a scientist on the mission.

“The rover surpassed every single expectation we could’ve possibly had,” Harrison says. “But I’m not sure anything can fully prepare you for the wave of emotion of hearing a mission you work on is coming to an end.”

Harrison and her colleagues now find themselves members of a rather depressing club in space exploration: scientists, engineers, and other NASA staff who have devoted years, sometimes decades, of their lives to spacecraft that eventually broke, exploded, or even disintegrated in the atmosphere of a planet. Some have compared the pain of ending a mission to losing a family member. “It’s like you have a loved one in a coma in the hospital,” John Callas, the Opportunity project manager, told reporters last year. “The doctors are telling you that you just got to give it time and she’ll wake up, all the vital signs are good, it’s just waiting it out.”

Curiosity won’t be alone for long. NASA’s next rover is expected to land on the planet in February 2021. Another rover, built by the European Space Agency, will arrive in the same year.

They will follow in Opportunity’s tracks, casing the Martian rock for signs of life, present and ancient. Perhaps someday, more complex spacecraft will join them, not to stay, but to collect samples and fly back to Earth, delivering chunks of another planet for scientists to study for themselves.

Until then, Curiosity bears the burden of maintaining the rover streak on Mars, set in 2004 with Opportunity and Spirit.

“There are high-school freshmen this year that have lived their entire lives with functioning Mars rovers,” Seibert says. “I think everyone is going to be like, Don’t break the car. It’s the only one we’ve got.”



Updated at 9:58 a.m. ET on January 2, 2019

After Pluto was discovered, in 1930, astronomers wondered whether the solar system stopped there. For decades, they peered through their best telescopes, searching for hints of more objects in the darkness. In the early 1990s, when telescope technology became powerful enough, they found one. The object was thousands of times fainter than Pluto, but it was there. A few months later, they found another. And then another. And another. With each new discovery, the edges of the solar system expanded.

More than 3,100 similar objects have been found in this cold, dark region, known as the Kuiper Belt, named for an astronomer who predicted their existence. On New Year’s Eve, for the first time, one of these objects received a visitor.

At exactly 12:33 a.m. Eastern time, as people on the East Coast drained their champagne glasses, a NASA spacecraft about the size of a grand piano approached a Kuiper Belt object about the size of a city. The object was 2014 MU69, which NASA has nicknamed Ultima Thule, an ancient phrase meaning “beyond the known world.” Ultima Thule orbits about 4 billion miles from Earth, making this the most distant encounter with another celestial object in the history of space exploration.

Like New Year’s revelers back on Earth, the spacecraft, known as New Horizons, snapped many photographs to capture the experience. And it had to do it fast. This mission was a flyby, not a visit, and Ultima Thule, measuring just 20 miles long and 10 miles wide, was a difficult mark to hit. New Horizons came within 2,200 miles of Ultima Thule’s surface. Then, traveling at a brisk pace of 32,000 miles an hour, the spacecraft left as quickly as it arrived, continuing on to the very ends of the solar system.

At a distance of 4 billion miles, it takes some time for data from New Horizons to reach Earth. The spacecraft called home for the first time since the flyby on Tuesday morning. Engineers reported that systems were working properly and packed with tantalizing new data. Scientists plan to unveil the first close-up images of Ultima Thule on Wednesday.

On Tuesday night, a Newsweek story from March kicked off a discussion on social media about NASA’s decision to use the name Ultima Thule, one of thousands of entries to a public naming contest. The term first originated more than 2,000 years ago with the Roman poet Virgil and has appeared in literature as a descriptor for distant places. Newsweek reported that the term was also popularized by the Nazi party and remains in use by modern-day white nationalist groups.

For now, the best view they have of Ultima Thule is this fuzzy, elongated blob, which resembles a snowman (or a peanut, or a bowling pin), taken on New Year’s Eve:

Ten hours earlier, on Monday night, hundreds gathered at the Johns Hopkins University Applied Physics Laboratory, in Maryland, where New Horizons was built, to celebrate the flyby. The mood was festive. There was cheese and crackers, glittery party hats and kazoos. String lights draped across the walls gave the room a soft glow.

It felt like any other New Year’s Eve soiree, except it was clearly obvious that no one actually cared about New Year’s Eve. Brian May—the curly-haired lead guitarist for Queen who became a professional astrophysicist about a decade ago—debuted a recording of a song he wrote specifically for New Horizons. Guests cheered with more enthusiasm for the flyby than they did for the arrival of 2019.

All night, scientists buzzed about what sights New Horizons may reveal. From Earth, these objects look like tiny pinpricks of light. The faint glint can be used to calculate the objects’ orbits, but little else. Scientists think that Ultima Thule, like most Kuiper Belt objects, is icy. They suspect it will likely be reddish in color, thanks to billions of years of exposure to the radiation that permeates space. They don’t even know whether it’s one object or two; Ultima Thule could be two objects orbiting in close contact as one, or two objects orbiting each other.

The flyby data will provide answers to this and other questions. New Horizons’s science instruments were instructed to collect data about Ultima Thule’s composition, determine whether it has an atmosphere, and search for moons or rings. (Yes, even very tiny, icy worlds in the farthest reaches of the solar system, well beyond the glare of the sun, can have the kinds of features we associate with giant planets.)

“I’m hoping to see something I’ve never seen before,” said Kelsi Singer, a planetary scientist on the New Horizons team who planned some of the spacecraft’s observations. “I’m hoping that there’ll be features that we’ve never seen anywhere else in the solar system.”

It’s happened before. New Horizons left Earth in 2006, eight years before Ultima Thule was even discovered. In 2015, the spacecraft swept past Pluto. The encounter produced unprecedented observations of the dwarf planet, which lost its status as a full-fledged planet in 2006, a demotion its fans fulminate against to this day. The images revealed, in tremendous detail, 11,000-foot mountain ranges made of ice and smooth plains of frozen nitrogen. Some land features suggested that Pluto may even be geologically active.

“There were things on Pluto that we never would have guessed were there, because they’re literally only on Pluto,” Singer said.

Scientists hope their observations of Ultima Thule will provide new information about the formation of the solar system 4.5 billion years ago. Objects in the Kuiper Belt are cosmic leftovers, remnants of a tumultuous process that swept some debris into planets and scattered the rest. Thanks to their distance from the sun, the objects orbit in an extremely cold environment that has left them virtually unchanged for billions of years. This means they contain the same materials that formed the planets. For planetary scientists, Ultima Thule is a cosmic time capsule in pristine shape.

For now, the arrival is thrilling enough. The New Horizons team has waited three and a half years for the spacecraft to approach Ultima Thule. Scientists have had plenty of time to daydream about the object’s landforms and make their predictions. And they’re well aware that they may be wrong.

“I always feel like we ought to call it exploration and discovery, because the whole point of exploring is to go places no one’s ever been before, to see things no one’s ever seen, and to find out what’s there,” said Andrew Chaikin, a space historian. “Every time we’ve gone someplace that we’ve never been before, we’ve been surprised.”



Since 1969, 12 men have walked on the moon’s surface, leaving boot prints in the fine slate dust. In 1972, as the crew of the last lunar mission flew home, President Richard Nixon predicted, “This may be the last time in this century that men will walk on the moon.” Several presidents since have promised to put American astronauts on the moon again, someday, and the desire to return has not faded.

Weeks after President Donald Trump was inaugurated, leaked memos revealed that the president’s advisers had contemplated a moon return as early as 2020. By late 2017, federal officials directed NASA to focus on a voyage to the moon—not to plant another flag, but to build a lasting presence, aimed at launching missions deeper into space. And in the past year, the administration’s aspirations have crystallized into a specific plan.

There are no Cold War tensions to push Americans to the moon in this century. But there is a rush. The Trump administration has moon fever, and with the 50th anniversary of the first moon landing just around the corner, NASA is in a hurry.

The Trump administration wants to put humans on the moon by 2028. Unlike the Apollo program, this won’t be an in-house effort. NASA has asked American aerospace companies to submit designs for transportation systems that could be launched and tested, without a crew, as early as 2024. Applications are due in late March, and the winners stand to receive contracts worth from $300,000 to $9 million. Potential participants include longtime NASA contractors such as Boeing, Lockheed Martin, and Northrop Grumman; the quirky-billionaire-owned SpaceX and Blue Origin; and smaller, more obscure companies.

“We care about speed,” Thomas Zurbuchen, the associate administrator of NASA’s science division, said recently. “We want to start taking shots on goal. We do not expect that every one of those launches, every one of those landings, will be successful.”

Why the urgency? One interpretation: Trump is more than halfway into his first term, and his administration is ready to put months of planning into motion. Another: Trump is more than halfway into his first term, and the administration still has little to show for itself, especially as the Apollo anniversary approaches. Officials say they could sign the first contracts as soon as July, just in time for the occasion.

The administration’s vision calls for the construction of a lunar outpost—the equivalent of a little International Space Station, orbiting the moon. Like the ISS, the outpost would be assembled in orbit, piece by piece, module by module. From there, astronauts would travel to and from the lunar surface. NASA’s latest call for designs includes vehicles to move astronauts from the station, down to the lunar surface, and back up. Some of the transportation elements could be refueled and reused.

The companies competing for these contracts will have to build this complex infrastructure in eight years with a fraction of the budget available during the Apollo era. At the Apollo program’s peak, NASA’s budget accounted for more than 4 percent of federal spending. Now it’s less than half a percent. Even with a ballooning federal budget, that still works out to less than half the spending power that NASA had in the 1960s.

There is also another challenge to the administration’s ambitious goals: The rocket that would facilitate access to this floating station is still under construction. So is the capsule that would hold the crew on its journey there. Both programs are running behind schedule and growing more expensive. Last fall, a report by NASA’s Office of Inspector General predicted that the rocket-and-capsule combo won’t be ready for its first test flight, in mid-2020, unless it receives an additional $1.2 billion.

In the midst of all that, NASA also hopes to land robotic missions on the moon. “For us, if we had any wish, I would like to fly this calendar year,” Zurbuchen said, in another show of urgency. The agency picked nine American companies to compete over contracts for the missions last year, and unveiled the payloads—a dozen scientific instruments—this week. It hasn’t mentioned who would fly these missions to the moon. The only systems that would be available by Zurbuchen’s dream deadline are in the private sector, not at NASA.

All together, this is a very tall order. As with most space-exploration ambitions, the timelines for the Trump administration’s lunar plans should be taken with a big grain of moon dust. The U.S. is unmatched when it comes to deep-space exploration—the country has left the solar system twice with the Voyager spacecraft, and has landed on Mars eight times—but its lunar glory days are far behind it. Since the last moonwalkers returned to Earth, NASA hasn’t landed anything on the surface. On top of that, the agency can’t launch its astronauts to the ISS from U.S. soil, and will continue to buy seats for them on Russia’s launch system until SpaceX and Boeing, American companies, can take over the job, a scenario that’s still at least a year away.

Realistic or not, the Trump administration’s plans also elide another major threat to any space policy: electoral politics. If the president has to leave office after 2020, his administration’s moon shot might go with him. New presidents come in with their own policies, and entire programs end up on the chopping block the morning after Election Day. Barack Obama erased George W. Bush’s hopes for a mission to the moon, and Donald Trump upended Obama’s directive for a trip to Mars. If the 2020 election produces a president with a different vision, NASA would, once again, readjust, and the effort to etch fresh boot prints on the moon would remain in the blueprints.

During the Cold War, the race to space was restricted to just two major players—the United States and the USSR. But the new race to the moon coincides with the ambitions of a growing group of spacefaring nations, as well as private companies. Last month, China landed a spacecraft on the far side of the moon, a world first. The space agencies of China, Russia, and India seek to land their astronauts on the moon in the next decade or two. In the private sector, business is booming. Last week, SpaceX launched an Israeli lander bound for the moon. If successful, the lander will become the first privately funded spacecraft to touch down on the surface of another world.

Many commercial companies are working on lunar missions of their own, from robotic rovers to tourist spaceships. SpaceX is developing a launch system designed “to reach the moon as fast as possible,” according to the company’s founder, Elon Musk. The same company hired to launch NASA astronauts to the ISS could leapfrog the agency on its way to the moon. With all the competition, it’s no wonder NASA wants to—as Zurbuchen put it—“fly faster.”



In 2009, hundreds of astronomers gathered in Long Beach, California, for the annual conference of the American Astronomical Society. Attendees participated in workshops during the day and mingled at after-parties at night. At one party, Katelyn Allers, now an astronomy and physics professor at Bucknell University, spotted Neil deGrasse Tyson, the well-known astrophysicist.

Allers approached Tyson and asked him to pose for a photograph. In one, the two are next to each other and smiling, Tyson in a black bolero and jacket, Allers in a plaid dress. In another, Tyson is holding Allers’s arm in both hands and examining the tattoo on her shoulder, a depiction of the solar system.

What happened next depends on whom you ask.

Right after the second photo was taken, Allers says Tyson probed her dress in an “uncomfortable and creepy” manner; in an interview with the website Patheos, which published the photos last week, Allers alleges that Tyson’s hands followed her tattoo, which extends from her arm to her back, under her dress. “After we had taken the picture, he noticed my tattoo and kind of grabbed me to look at it, and was really obsessed about whether I had Pluto on this tattoo or not … and then he looked for Pluto, and followed the tattoo into my dress,” Allers said.

Tyson said he was indeed interested in Allers’s tattoo, but he denied touching her inappropriately. “I was reported to have ‘groped’ her by searching ‘up her dress,’ when this was simply a search under the covered part of her shoulder of the sleeveless dress,” Tyson wrote in a Facebook post on Saturday.

Tyson provided that explanation as part of a larger response to several allegations against him, which have made national headlines in recent days: that of Allers, but also that of a former assistant who claims Tyson made inappropriate sexual advances, and that of a woman who alleges that Tyson raped her while they were graduate students in the 1980s. Fox Broadcasting Company and National Geographic, the producers of Tyson’s popular-science show Cosmos, have said they will investigate the allegations.

In his post, Tyson apologized to Allers, saying he didn’t know she found their encounter to be “creepy.” “I am asked by thousands of people per year to take pictures with them,” he wrote. “A flattering, time-consuming, but delightful chore.”

Few Tyson admirers would pass up an opportunity to pose for pictures with the astrophysicist, who is one of the best-known popularizers of science since Carl Sagan. Photo ops with famous folks are, generally, quite exciting. You get to chat with someone you admire, tell the celebrity why his or her work matters to you, and then leave with photographic evidence of the whole thing to show your friends.

But in the year since the #MeToo movement took hold, the photo op has become something else. The same circumstances that can produce a cherished keepsake can also facilitate something sinister. The nature of the photo op can, at best, cause uncomfortable misunderstandings and, at worst, encourage predatory behavior.

Take the example of another well-known individual in the scientific field, the theoretical physicist Lawrence Krauss. In November 2016, Krauss was in Melbourne for the Australian Skeptics National Convention, a gathering of scientists who advocate for empirical research of dubious claims. At a dinner, a woman approached Krauss and asked him to take a selfie with her. Melanie Thomson, a friend of the woman, claimed in an interview with BuzzFeed News earlier this year that as her friend held out her phone, Krauss grabbed the woman’s right breast.

“As soon as she reacted, which was instantaneously, she body checked him and then she spun around,” Thomson said. Two other attendees told BuzzFeed News they also witnessed the incident.

Krauss has denied he grabbed the woman’s breast. “That would require an outburst of brash and irrational behavior that isn’t consistent with anything else about my behavior … during the tens of thousands of other selfies I have taken with people over the years,” he wrote in a lengthy document shared last month, after he announced that he would retire from his position at Arizona State University, which had investigated him.

Krauss included the photo in his explanatory document. The woman leans against Krauss, whose hand, blurred by movement, hovers over her chest. The astrophysicist added a gray circle to block the woman’s face; only Krauss’s face is visible. “I may have inadvertently touched her breast, but it would have been a complete accident,” Krauss said.

In this case, the camera captured a distinct moment—the moving hand—which both sides could use to bolster their very different arguments. The witnesses claimed Krauss was moving it toward the woman; Krauss insists he was moving it away. In other cases, there is little to dispute. The misconduct occurs behind the subjects, where the camera lens can’t reach.

In October 2017, just a few weeks after the Harvey Weinstein investigations were published, an actress alleged that in 2014, the late George H. W. Bush, by then in a wheelchair, had groped her while they posed for a photo. Within a month, at least seven more women came forward with similar stories of their own photo ops with the 41st president. Their experiences spanned more than 20 years. Two women said that Bush said “David Cop-a-feel!” as he groped or squeezed their buttocks. One of the accusers said Bush groped her when she was 16 years old. In a flash, Bush’s admirers were made to feel like victims.

Bush apologized in response to the allegations, through a spokesperson: “To anyone he has offended, President Bush apologizes most sincerely.”

The statement gave this explanation for the disturbing pattern: “To try to put people at ease, the president routinely tells the same joke—and on occasion, he has patted women’s rears in what he intended to be a good-natured manner. Some have seen it as innocent; others clearly view it as inappropriate.”

If they had not said otherwise, it would be easy to believe that these women weren’t bothered by Bush’s actions, that they found the gesture, as his spokesperson suggested, innocent. In the photos, the women stand close to the president, almost pressing into him. Everyone is smiling. Looking at the pictures, no one would think there was something wrong.

The roles in a photo op gone wrong—the admirer as alleged victim, the celebrity as alleged predator—can be reversed. Consider the legal battle between the singer Taylor Swift and a former DJ named David Mueller. In 2013, Swift, Mueller, and Mueller’s then girlfriend posed for a photograph at a backstage meet and greet after Swift’s concert in Denver. Swift said that Mueller groped her buttocks as the photo was taken. Mueller denied the claim.

The legal standoff would likely have followed the standard “he said, she said” narrative that has guided and decided stories of sexual misconduct since time immemorial. But there it was, publicly available and widely shared, the photo of the exact moment in question: Swift stands between the couple, with Mueller’s arm behind the singer, positioned well below her waist. At the trial, which took place in the summer, Swift and Mueller offered two very different characterizations of the same image to the jury.

Mueller said he touched Swift’s arm and ribs while “jostling” for the photo. Swift said that actually, no, there was no jostling, no contact with her arm or ribs: “He grabbed my bare ass.”

Mueller’s attorney asked the singer why, if Mueller had inappropriately touched Swift beneath, the front of her skirt doesn’t appear ruffled.

“Because my ass is located in the back of my body,” Swift responded.

After four hours of deliberation, the jury ruled in Swift’s favor. The photograph was no smoking gun—the lengths to which Mueller’s attorney went to describe what might have occurred behind Swift and his client make that clear—but it no doubt helped decide the verdict. “Believe women,” the axiomatic slogan of the #MeToo movement demands, but the bar remains, as it has for centuries, high, whether in front of a jury or in front of Congress. Photos, when they exist, lower that bar.

In some cases, the contents of a photo op are difficult to dispute, especially when one party couldn’t even agree to the photograph in the first place. In 2006, Leeann Tweeden, a radio-show anchor, was headed back to the United States after a USO tour to entertain American troops stationed in Iraq. Al Franken, then a comedian, was part of the group. Tweeden fell asleep on the flight, and Franken took the opportunity to pose with her with his hands outstretched as if grabbing her breasts. Tweeden publicly shared the photo in November 2017, and Franken, by then a U.S. senator, resigned a month later.

The secret photo op was allegedly just one example of Franken’s penchant for inappropriate behavior with women in front of camera lenses. Days after Tweeden shared the photo, at least four other women claimed that Franken had grabbed their buttocks or squeezed their waist while taking a photo at political events in the past decade.

In the case of Franken—and, to some extent, Swift—the photograph added another layer to the discussion and to the competing stories that in the end tipped the scales toward the woman. It provided an unsettling twist. For the alleged victims, the portrait of their violation became the proof they needed to convince others that it happened.

While it is difficult to deny allegations of bad behavior when some visual proof exists, it’s not impossible. Even with photographic evidence, the public discussions surrounding alleged instances of sexual misconduct have often defaulted to the standard narrative. People view the photos of the #MeToo movement as they do the stories: through the lens of their own preconceived notions. Faced with the exact same image, they may perceive entirely different realities. They will choose to believe what he said over what she said, or vice versa. A picture may be worth a thousand words, but it doesn’t tell the same story to everyone.



Onscreen eagles lock talons in aerial combat, and humpback whales engulf herring by the shoal. Birds of paradise, hunting dogs, leafcutter ants—they’re all there. This is Our Planet—Netflix’s new, big-budget nature documentary—and, without the sound on, viewers could easily think that they’re watching Planet Earth III.

The resemblance to the oeuvre of the BBC’s renowned Natural History Unit is striking. The series is produced by Alastair Fothergill, who was also responsible for the original Planet Earth. Everything is narrated by David Attenborough, whose unctuous tones, somehow both silky and gravelly, have become synonymous with wildlife films.

But this time, the messages delivered by that familiar voice are different. Here, much of the awe is tinged with guilt, the wonder with concern, the entertainment with discomfort.

Repeatedly, unambiguously, and urgently, Our Planet reminds its viewers that the wonders they are witnessing are imperiled by human action. After seeing a pair of mating fossas—a giant, lemur-hunting, Madagascan mongoose—we’re told that the very forests we just saw have since been destroyed. After meeting the endearing orangutans Louie, Eden, and Pluto, we are told that 100 of these apes die every week through human activity. We see Borneo’s jungle transforming into oil-palm monocultures in a time-lapse shot that is almost painful to watch. We’re told that Louie and Eden’s generation could be the last for wild orangutans.

If you muted the series, it would look almost identical to any other wildlife documentary. You could sit back, content and relaxed, gawping at nature’s splendor. But Our Planet seems to have no interest in letting you be contented. Though the film is still entertaining and beautiful, its narration imparts its shots with a more complex emotional flavor. It’s like watching an American drug ad during which a voice-over reads out lists of horrific side effects over footage of frolicking, picnicking families.

Frankly, it’s about time.

The BBC’s natural-history series have been a gift, enchanting tens of millions of viewers with nature’s wonders. But the shows have also been criticized for whitewashing the decline of the creatures they feature. Disappearing species, shrinking habitats, spreading diseases, accumulating pollutants, changing climates—Planet Earth obliquely hinted at these problems in its final line. “We can now destroy or we can cherish: The choice is ours.”

Frozen Planet, a tour of polar fauna, saved its talk of climate change for its final, seventh episode—and Fothergill told me he had to fight for even that. “There has been a habit of having a 45-minute show where we say that everything’s fine, and in the last five minutes, we say there’s a problem,” he said. “I think that’s a little bit trite. It doesn’t deal with the issue.”

After Planet Earth II repeated some of these problems, the natural-history-film producer Martin Hughes-Games wrote that by showing a pristine world without context, these series are “lulling the huge worldwide audience into a false sense of security.” The rejoinder has always been that warnings would dissuade viewers. “Every time that image [of a threatened animal] comes up, do you say ‘remember, they are in danger’?” Attenborough asked in an interview with The Observer. “How often do you say this without becoming a real turn-off?”

The answer from last year’s Blue Planet II—still the greatest nature series of all time—was at least once an episode. The answer from Our Planet is repeatedly, in shot after shot. It does what no other natural-history documentary has done. It forces viewers to acknowledge their own complicity in the destruction of nature, in the moment. It feels sad, but also right.

That’s not to say that Our Planet is a dour, finger-wagging downer—far from it. It is hard not to cheer as an initially incompetent Philippines eagle takes her first flight, or laugh as a tree shrew uses a pitcher plant as a toilet, or marvel at two Arabian leopards meeting and mating—1 percent of the species’ surviving individuals, perhaps creating a few more. We’re treated to a rare glimpse of the oarfish, a luminescent, serpentine creature that looks as if it has swum out of mythology. We witness the improbably complex dance of the western parotia, a bird of paradise that almost single-handedly justifies the entire group’s name. Most of the series is still joyful, but it is never allowed to be naively so.

“The only reason I worked on this project was that, from day one, conservation was part of it,” says Sophie Lanfear of Silverback Films, who produced the second episode, about polar life. “It had to be the heart of every episode.” This commitment is framed from the opening seconds of the first episode, as the camera pans over the pockmarked surface of the moon to reveal the Earth, and Attenborough intones:

Just 50 years ago, we finally ventured to the moon. For the very first time, we looked back at our own planet. Since then, the human population has more than doubled. This series will celebrate the natural wonders that remain and reveal what we must preserve to ensure that people and nature thrive.

That remain! What you’re seeing is what is left to see.

The message is clear. It’s bad. It’s urgent. It’s our fault. We can still fix it. Our Planet is a eulogy, a confession, a slap on the wrist, a call to arms. (The task of offering actionable advice is outsourced to the series’ website.)

There is optimism, too. Amid doom-laden warnings, the documentary highlights success stories in which conservation measures have allowed species to start bouncing back. When we watch five cheetah siblings do their best lion impressions and cooperatively bring down a wildebeest, Attenborough tells us that we get to enjoy such dramas only because the Serengeti has been protected for decades. And in a sequence of unexpected poignancy, wild horses, foxes, and wolves are seen thriving among the ruins of Chernobyl, the radiation a minor inconvenience compared with the boon of human absence. “In driving us out, the radiation has created space for wildlife to return,” Attenborough says.

The series isn’t faultless. Some episodes still feel as disjointed as those of Planet Earth II did, with few narrative threads connecting the individual sequences. There are a few minor but weird mistakes: Orangutans are described as our ancestors when they’re our distant cousins, and phytoplankton are called plants when most are nothing of the kind. And the score never goes for a subtle musical cue when a saccharine one will do.

But these are small gripes for a series that audaciously treads where its predecessors have feared, and sets the bar for its successors. “Five years ago, when we started on this journey, it was always hard to get environmental programming onto prime time,” Fothergill said. “That’s definitely changed. Even the BBC are now saying that they want environmental messaging in their programs.” While seeing elephants, we will finally hear about the elephant in the room. And not a moment too soon.



At first glance, the hagfish—a sinuous, tubular animal with pink-grey skin and a paddle-shaped tail—looks very much like an eel. Naturalists can tell the two apart because hagfish, unlike other fish, lack backbones (and, also, jaws). For everyone else, there’s an even easier method. “Look at the hand holding the fish,” the marine biologist Andrew Thaler once noted. “Is it completely covered in slime? Then, it’s a hagfish.”

Hagfish produce slime the way humans produce opinions—readily, swiftly, defensively, and prodigiously. They slime when attacked or simply when stressed. On July 14, 2017, a truck full of hagfish overturned on an Oregon highway. The animals were destined for South Korea, where they are eaten as a delicacy, but instead, they were strewn across a stretch of Highway 101, covering the road (and at least one unfortunate car) in slime.

Typically, a hagfish will release less than a teaspoon of gunk from the 100 or so slime glands that line its flanks. And in less than half a second, that little amount will expand by 10,000 times—enough to fill a sizable bucket. Reach in, and every move of your hand will drag the water with it. “It doesn’t feel like much at first, as if a spider has built a web underwater,” says Douglas Fudge of Chapman University. But try to lift your hand out, and it’s as if the bucket’s contents are now attached to you.

The slime looks revolting, but it’s also one of nature’s more wondrous substances, unlike anything else that’s been concocted by either evolution or engineers. Fudge, who has been studying its properties for two decades, says that when people first touch it, they are invariably surprised. “It looks like a bunch of mucus that someone just sneezed out of their nose,” he says. “That’s not at all what it’s like.”

For a start, it’s not sticky. If there wasn’t so damn much of it, you’d be able to wipe it off your skin with ease. The hagfish themselves scrape the slime off their skin by tying a knot in their bodies and sliding it from head to tail.

The slime also “has a very strange sensation of not quite being there,” says Fudge. It consists of two main components—mucus and protein threads. The threads spread out and entangle one another, creating a fast-expanding net that traps both mucus and water. Astonishingly, to create a liter of slime, a hagfish has to release only 40 milligrams of mucus and protein—1,000 times less dry material than human saliva contains. That’s why the slime, though strong and elastic enough to coat a hand, feels so incorporeal.

Indeed, it’s one of the softest materials ever measured. “Jell-O is between 10,000 and 100,000 times stiffer than hagfish slime,” says Randy Ewoldt from the University of Illinois at Urbana-Champaign, who had to invent new methods for assessing the substance’s properties after conventional instruments failed to cope with its nature. “When you see it in a bucket, it almost still looks like water. Only when you stick your hand in and pick it up do you find that it’s a coherent thing.”

The proteins threads that give the slime cohesion are incredible in their own right. Each is one-100th the width of a human hair, but can stretch for four to six inches. And within the slime glands, each thread is coiled like a ball of yarn within its own tiny cell—a feat akin to stuffing a kilometer of Christmas lights into a shoebox without a single knot or tangle. No one knows how the hagfish achieves this miracle of packaging, but Fudge just got a grant to test one idea. He thinks that the thread cells use their nuclei—the DNA-containing structures at their core—like a spindle, turning them to wind the growing protein threads into a single continuous loop.

Once these cells are expelled from the slime glands, they rupture, releasing the threads within them. Ewoldt’s colleague Gaurav Chaudhury found that despite their length, the threads can fully unspool in a fraction of a second. The pull of flowing water is enough to unwind them. But the process is even quicker if the loose end snags on a surface, like another thread, or a predator’s mouth.  

Being extremely soft, the slime is very good at filling crevices, and scientists had long assumed that hagfish use it to clog the gills of would-be predators. That hypothesis was only confirmed in 2011, when Vincent Zintzen from the Museum of New Zealand Te Papa Tongarewa finally captured footage of hagfish sliming conger eels, wreckfish, and more. Even a shark was forced to retreat, visibly gagging on the cloud of slime in its jaws.

“We were blown away by those videos,” Fudge says, “but when we really looked carefully, we noticed that the slime is released after the hagfish is bitten.” So how does the animal survive that initial attack? His colleague Sarah Boggett showed that the answer lies in their skin. It’s exceptionally loose, and attaches to the rest of the body at only a few places. It’s also very flaccid: You could inject a hagfish with an extra 40 percent of its body volume without stretching the skin. The animal is effectively wearing a set of extremely loose pajamas, Fudge says. If a shark bites down, “the body sort of squishes out of the way.”

That ability makes hagfish not only hard to bite, but also hard to defend against. Calli Freedman, another member of Fudge’s team, showed that these animals can wriggle through slits less than half the width of their bodies. In the wild, they use that ability to great effect. They can hunt live fish by pulling them out of sandy burrows. And if disturbed by predators, they can dive into the nearest nook they find. Perhaps that’s why, in 2013, the Italian researcher Daniela Silvia Pace spotted a bottlenose dolphin with a hagfish stuck in its blowhole.

More commonly, these creatures burrow into dead or dying animals, in search of flesh to scavenge. They can’t bite; instead, they rasp away at carcasses with a plate of toothy cartilage in their mouths. The same traveling knots they use to de-slime themselves also help them eat. They grab into a cadaver, then move a knot from tail to head, using the leverage to yank out mouthfuls of meat. They can also eat by simply sitting inside a corpse, and absorbing nutrients directly through their skin and gills. The entire hagfish is effectively a large gut, and even that is understating matters: Their skin is actually more efficient at absorbing nutrients than their own intestines.

Hagfish are so thoroughly odd that biologists have struggled to clearly work out how they’re related to other fish, and to the other backboned vertebrates. Based on their simple anatomy, many researchers billed the creatures as primitive precursors to vertebrates—an intermediate form that existed before the evolution of jaws and spinal columns.

But a new fossil called Tethymyxine complicates that story. Hailing from a Lebanese quarry, and purchased by researchers at a fossil show in Tucson, Arizona, the Cretaceous-age creature is clearly a hagfish. It has a raspy cartilage plate in its mouth, slime glands dotting its flanks, and even chemicals within those glands that match the composition of modern slime. By comparing Tethymyxine to other hagfish, Tetsuto Miyashita from the University of Chicago concluded that these creatures (along with another group of jawless fish, the lampreys) are not precursors to vertebrates, but actual vertebrates themselves.

Such work is always contentious, but it fits with the results of genetic studies. If it’s right, then hagfish aren’t primitive evolutionary throwbacks at all. Instead, they represent a lineage of vertebrates that diverged from all the others about 550 million years ago, and lost several traits such as complex eyes, taste buds, scales, and perhaps even bones. Maybe those losses were adaptations to a life spent infiltrating carcasses in the dark, deep ocean, much like their flaccid, nutrient-absorbing skins are. “Hagfishes might look primitive; they’re actually very specialized,” Miyashita adds.

Their signature slime might have also evolved as a result of that lifestyle, as a way of fending off predators that were competing for cadavers. “Everything about hagfish is weird,” says Fudge, “but it all kind of fits.”  



Democrats don’t yet have a consensus plan to address climate change, but they’re trying. On Wednesday, the party’s leadership in Congress issued a demand to President Donald Trump and began searching for long-term footing on the issue.

In the House, Speaker Nancy Pelosi unveiled the Climate Action Now Act, a bill that would essentially forbid the United States to withdraw from the Paris Agreement. The bill would also require that the White House develop a plan to meet the U.S. commitment under that treaty.

“Despite what the president has said, America will not retreat, and America will not cut and run,” said Representative Kathy Castor, a Florida Democrat, in a press conference at the Capitol.

In the Senate, without a majority, Democrats can’t do as much. On Wednesday, Minority Leader Chuck Schumer announced a new Democratic committee on climate change that will give his party a larger forum for talking to experts and planning next steps. But the new group will lack the powers of an official Senate committee: Democrats say they tried, and failed, to interest the GOP in forming a bipartisan climate panel.

Senator Brian Schatz of Hawaii will chair the new group. He told reporters that he didn’t think Democrats would be able to do much without a Senate majority. “The truth is, we’re preparing to lay the predicate for action when and if Chuck Schumer becomes the majority leader,” he said.

The double billing provided a good view into the party’s unsettled climate agenda. The problem for Democrats is not that they have too few options; it’s that they have too many. Since 2010, when the Obama administration’s climate bill failed, dozens of senators and representatives have proposed various climate policies big and small, including several variations on a carbon tax. But these proposals have been advanced haphazardly, to send a message, with little hope of passage.

This is a very different problem from the one faced by the GOP. While many Republicans in Congress will now affirm the reality of climate change, the party has not advanced a serious policy proposal in years. And the Republican president is furiously undoing climate-focused regulations—and questioning the underlying scientific basis—as fast and energetically as he can.

Now, with a House majority and a newly climate-concerned public, the Democratic Party is searching for a serious legislative way forward—and so far, its moderates have found the Green New Deal lacking.

The party is almost totally united around one climate policy: being in the Paris Agreement, which the Trump administration has promised to leave. (For legal reasons, the United States cannot fully exit the pact until late 2020.) Pelosi would not have introduced the Climate Action Now Act if it couldn’t pass her caucus overwhelmingly. She even gave it a single-digit number—in the House filing system, it’s known as H.R. 9—to underscore its importance; it sits on a par with Democrats’ bills on campaign finance (H.R. 1), LGBTQ equality (H.R. 5), and gun control (H.R. 8).

Rejoining the Paris Agreement won’t do anything by itself, though. The agreement is mostly nonbinding, and it imposes few requirements on its member states. During the Obama administration, the laws that actually cut carbon emissions weren’t Paris-related; they were rules issued by the Environmental Protection Agency under the Clean Air Act.

So the Climate Action Now Act aims to put some legal muscle behind Paris. It uses Congress’s power over the federal purse to shore up the accord, prohibiting the executive branch from spending any money to advance the withdrawal from the climate treaty. Similar language appeared in the bipartisan NATO Support Act, which passed the House earlier this year and forbade U.S. withdrawal from the North Atlantic Treaty Organization.

When it first joined the Paris Agreement, the United States promised to cut, by 2025, its carbon emissions to at least 26 percent below their historic peak. The country is currently not on track to meet that goal.

The Climate Action Now Act requires the White House to submit a plan saying how it will make that 26 percent target. It also mandates that a new, more ambitious plan be submitted every year. But it provides no legal mechanism to punish the president if he fails to follow through on a plan he submitted.

The new House Select Committee on the Climate Crisis, which Castor leads, will also devise its own plan to meet the Paris goal.

Democrats know this isn’t enough—and they are willing to say so. “This is a step in the right direction,” said Representative Mike Levin of California, another member of the climate-crisis committee. “There’s so much more we must do. H.R. 9 is a down payment.”

But what should Democrats do? Here it gets dicey. At the press conference on Wednesday, senators expressed a strikingly divergent set of goals for their new climate committee. Senator Sheldon Whitehouse of Rhode Island said he hoped it would attack Republicans, oil companies, and “phony baloney” climate deniers. “We are going to have fun,” he said. Senator Michael Bennet of Colorado, meanwhile, lauded the Republicans’ “honorable legacy” of environmental legislation. He hoped the group could set up an eventual bipartisan climate bill.

Schatz, the chair of the panel, would have to serve as “chief cat herder” on the issue, one of the members joked. And Schatz, perhaps aware of his tough mandate, refused to say whether any eventual climate bill would aim to keep global warming below a certain number of degrees, or emissions below a certain level. He promised only that Democrats would take action commensurate with the problem.

Looming over the proceedings of both houses of Congress this week was the Green New Deal, which—for all its vagueness—has generated more debate over climate policy than anything else has in years. On Tuesday, Republicans in the Senate roundly defeated the progressive resolution, 57–0. All but three Senate Democrats essentially abstained from the tally, voting only “present.” On Wednesday, Schumer thanked Majority Leader Mitch McConnell for holding that vote, saying that it underlined that Democrats want to do something about climate change and Republicans don’t. (Which is true, as it goes.) But when a reporter asked Schumer whether the new committee had been founded in response to the Green New Deal, he avoided the question. Schatz then intervened, and recognized the activists indirectly: “Whenever the cause, we certainly feel like we have momentum. We have the moral high ground,” he said.

But legislators may have a harder time talking in those moral terms. Earlier in the week, dozens of activists associated with the Sunrise Movement—the youth-led group that first brought national attention to the Green New Deal—lined up outside the Capitol dome. They wore shirts with a clear, if philosophically interesting, demand: “We have a right to a GOOD JOB and a LIVABLE FUTURE.”

“The Green New Deal is more than a resolution; it is a revolution,” declared Senator Edward Markey of Massachusetts, who sponsored the original resolution with Representative Alexandria Ocasio-Cortez. (Markey is also on the new Democratic climate committee.) He was one of several senators to criticize McConnell. Senator Kirsten Gillibrand of New York compared the Green New Deal to President John F. Kennedy’s moonshot. Senator Jeff Merkley of Oregon led the assembled activists in cheers.

Then Senator Ron Wyden, also of Oregon, took the lectern. Bedecked in an emerald scarf, tie, and baseball cap, he told the crowd that, as the ranking member of the Senate Finance Committee, he knew there were 40 tax breaks for oil companies.

“Folks, let me promise you today—as part of our effort, I’m going to throw those dirty-energy tax breaks in the garbage can!” he said. When Democrats take back the Senate, he promised, they would replace those 40 tax breaks with only three: “One for clean energy, one for clean transportation, and one for energy efficiency.”

It was an applause line, and the young people arrayed behind the senator eventually figured that out and clapped. The moment seemed to gesture to the difficulty of making climate policy popular—to how, in the day-to-day reality of government, a moral demand for a livable future can transform into a reform for internal-revenue collection. In the months to come, Senator Schatz and Representative Castor are going to propose plenty of tax-reform-style ideas. It will be interesting to see whether they sate activists.



Ah, spring.

The season of vibrant flowers lining the sidewalk on the commute home, their gentle fragrance wafting into the air. Of sunshine that calls for a light jacket instead of a bulky coat. Of the passionate urge to clean everything in sight.

Outside The Atlantic’s Washington, D.C., headquarters, it’s about 43 degrees Fahrenheit (6 degrees Celsius)—not warm enough for open-toed shoes, but still more pleasant than, say, a polar vortex. I’ve been longing for this day, and it got me thinking about spring on other planets, and whether it even exists.

We owe the seasons to Earth’s axis, which stays tilted at about 23 degrees as the Earth loops around the sun. But the orientation of the planet’s hemispheres in relation to the sun changes; different parts of the Earth lean toward or away from the sun at different times of the year, and receive varying amounts of sunlight.

But how do other planets work? To find out, and also to procrastinate my spring cleaning, I reached out to some scientists who spend their days thinking about other worlds.

Mercury

“Mercury doesn’t really have anything approaching spring, or any season for that matter,” says Paul Byrne, a planetary geologist at North Carolina State University. The planet’s axial tilt, a fraction of a degree, is negligible. “The amount of daylight at a given latitude on Mercury is essentially fixed during the entire year.”

The daylight is relentless and scorching. But the orientation produces a rather cool phenomenon. “It lets Mercury have regions of permanent shadow near its poles that are never sunlit, and lets ice be present in those regions—even on the planet closest to the sun,” says Nancy Chabot, a planetary scientist at the Johns Hopkins University Applied Physics Laboratory.

“It’s one weird little planet,” Byrne adds.

Venus

“There is no springtime on Venus, nor any other season—no seasons in hell!” says Allan Treiman, a scientist at the Lunar and Planetary Institute.

It’s difficult to sugarcoat the environment on Venus. Surface temperatures are a sizzling 870 degrees Fahrenheit (470 degrees Celsius), hot enough to melt lead, all year round. Like Mercury’s, Venus’s axis isn’t tilted enough to produce a noticeable difference.

But the real reason the planet doesn’t have any seasons is its atmosphere, which is choked with clouds. “The clouds are so thick that its surface gets nearly no light or heat from the sun. Nearly all the sunlight and heat are absorbed by clouds, which then radiate heat down to the surface—the famous greenhouse effect,” Tremain says. “Venus clouds circulate faster than the surface does, so all the greenhouse heat is spread around the planet, whether it’s day or night.”

That’s not all. “To top everything else off, Venus’ day is longer than her year,” says Vicki Hansen, a scientist at the Planetary Science Institute. (It takes 243 Earth days for Venus to rotate once on its axis, but 225 Earth days for the planet to loop around the sun.) “So if she had spring, it would be hard to say what day it happened.”

Mars

Mars’s axis is tilted slightly more than Earth’s—about 25 degrees—which means the planet experiences distinct seasons, too. In fact, like the Northern hemisphere here, the Northern hemisphere on Mars is entering spring now.

“The Northern hemisphere is starting to heat up; the Southern hemisphere cooling off—just like on Earth,” says Don Banfield, a scientist at the Cornell Center for Astrophysics and Planetary Science.

Well, not just like on Earth. Orbits affect seasons, too; the Martian year is twice as long as a terrestrial year, so the seasons stretch out longer. There are seasonal trends, such as summer dust storms, “but without rain and plants, they aren’t quite as obvious,” says Banfield.

Jupiter

“Jupiter does not have a springtime,” says Cheng Li, a scientist at NASA’s Jet Propulsion Laboratory. Like Mercury, Jupiter’s axial tilt is too small to matter.Saturn

Saturn does have spring: Its axial tilt is similar to that of Earth and Mars.

“Saturn is warm in the summer and cold in the winter,” says Leigh Fletcher, a planetary scientist at the University of Leicester. “The clouds and chemicals respond to these changes in sunlight. Perhaps the best example is the color of Saturn’s atmosphere, which shifts from blue hues in the winter—relatively clear skies with very few hazes—to golden hues in summer—a more smoggy atmosphere with lots of hazes.”

Saturnian spring also provides the most visibility for a massive, hexagon-shaped storm at the planet’s north pole that has mesmerized scientists for years. Some parts of Saturn can even experience miniature versions of seasons, thanks to its shimmering rings.

“A fixed point in Saturn’s atmosphere would experience additional periods when the rings shade the sun,” says Mike Wong, a planetary scientist at the University of California, Berkeley. “We actually have something like this at my house, because the neighboring building has a billboard on top. From a certain date in November to a certain date in February, our roof is in constant shade because the billboard blocks the sun, so our house gets colder.”

Uranus

With a 98-degree tilt of its axis, Uranus basically spins on its side. This alignment means the planet experiences the most extreme seasonal contrasts in the solar system.

“The poles get a great deal of illumination from an overhead sun that barely seems to move in the sky during local summer and a great deal of darkness in winter,” says Glenn Orton, a scientist at NASA’s JPL. “As spring begins, the sun is virtually always at the horizon for anyone living at the poles and virtually straight overhead for a Uranian in the low-latitude tropics.” (We should clarify: These are fictional Uranian residents. Alien life hasn’t been discovered there.)

During spring, a giant white cap emerges over the north pole, standing out against the planet’s usual blue hues. Scientists suspect the warming temperatures produce atmospheric changes.

This far out in the solar system—where orbits are vastly longer—seasons stretch out for years. A Uranus spring lasts 21.

Neptune

Spring on Neptune is twice as long. The planet experiences distinct seasons, but “I don’t think we’ve been able to observe Neptune long enough with enough detail to say for sure how spring in one hemisphere differs from any other season in terms of atmospheric activity,” says Anne Verbiscer, a planetary scientist at the University of Virginia.

Pluto

“Why yes, it’s springtime on Pluto right now, at least in the northern hemisphere!” says David Grinspoon, a scientist at the Planetary Science Institute. “And it has been since 1990.”

(Please don’t overthink the inclusion of Pluto on this list. Scientists have spent years arguing over the correct categorization of this celestial body. For some of them, the 2006 decision to reclassify Pluto as a dwarf planet is not the final word. We’ll leave the debating to them.)

Pluto’s orbit around the sun is highly elliptical. “The distance to the sun is quite different for the same season in the south versus the north,” Grinspoon says. “This creates asymmetrical and extreme climate behavior where, over the timescale of the seasons—which are many decades long—the atmosphere goes through the magnitude of changes that on other planets we would call climate changes.”

Spring sounds mild compared with colder seasons. Without enough exposure to sunlight, Pluto can get so cold that its atmosphere freezes and falls on the surface. “You can imagine what life would be like if we had that experience on Earth,” says Bob West, a scientist at JPL. “The air we breathe and which sustains all life on the dry land would form crystals of water, oxygen, nitrogen, and carbon dioxide and fall to the ground as snow, leaving a near vacuum where once there was air.”

Wow. A little spring cleaning doesn’t sound so bad now.



In the middle of the Southern Ocean, time is measured in latitude and longitude, wave height and wind speed and the proximity of an iceberg. Ice is the language of ocean and land in the waters around Antarctica, and it is on the floating platforms of ice, those liminal places between land and ocean, that emperor penguins gather every year to mate and, if conditions are right, to lovingly raise their chicks.

The largest and heaviest species in the penguin family, the emperor was given its scientific name, Aptenodytes forsteri, in honor of Johann Reinhold Forster, the naturalist on board James Cook’s second voyage to the Southern Ocean. (Aptenodytes means “featherless diver.”) Forster was likely the first person to see the bird, although he mistakenly identified it as a king penguin, the emperor’s closest relative.

Like the ice shelves that support their breeding colonies, emperor penguins are creatures of both land and sea. They are well adapted to the extreme cold of an Antarctic winter, with four layers of scale-like feathers. Mature birds, both male and female, stand about 70 centimeters (27.5 inches) tall, and both are remarkable divers. They gorge on an assortment of fish, krill, and squid. By the time they join their colonies to breed, in late autumn, they can weigh up to 40 kilograms (88 pounds). Pairs mate and lay a single egg. As winter descends, the male draws on his body reserves to incubate the egg and raise the chick, while the female leaves the colony to feed.

The emperor penguin is the only animal to breed in the extreme cold of the Antarctic winter, and the males must rely on one another to survive. They do so, in a rare and remarkable demonstration, by huddling together in tight groups to share warmth and resist the freezing katabatic winds that blow down from the polar plateau. The birds take turns standing on the outer edge of the group. One by one, they peel off the windward side and shuffle along to the leeward side before rejoining the huddle, all the while balancing their precious single eggs on top of their feet. By the time the females return, in July, the males have lost almost half their body mass. The chick-rearing season then runs from August to December.

Edward Wilson, an assistant surgeon on the Discovery expedition that set sail for Antarctica in 1901, developed a particular interest in emperor penguins when he discovered the first-known breeding colony, on sea ice under the cliffs of Cape Crozier, on Ross Island. Finding that the chicks were fledging in December and January, he speculated that they must have hatched from eggs laid during the coldest months of the year, a breeding cycle that was “eccentric to a degree rarely met with, even in Ornithology.” He made several visits during the expedition, observing that the chicks seemed to have an extraordinarily high mortality rate of about 70 percent.

Few Antarctic explorers had even seen emperor penguins, much less witnessed their breeding practices, and to naturalists of the day, they represented an intriguing evolutionary mystery. The scientific consensus was that they were a primitive form of bird. Wilson was aware of an archaeological discovery made in 1861 of the fossilized remains of a small dinosaur, Archaeopteryx, in Jurassic-era limestone in Bavaria, Germany. Its features placed it somewhere between a reptile and a bird, and Wilson was keen to examine emperor penguins at different stages of development in the hope that they might reveal their evolutionary secrets.

When Wilson returned to Antarctica with Robert Falcon Scott’s Terra Nova expedition, in 1910, he was keen to test a theory proposed by the German zoologist Ernst Haeckel that the evolution of species was mirrored in their embryonic development. According to the theory, embryos of more advanced species, such as humans, passed through stages in which they displayed the adult characteristics of their more primitive ancestors. Wilson thought that studying emperor-penguin embryos might reveal an evolutionary link between birds and reptiles.

In the depths of the 1911 winter, Wilson left Scott’s base camp with the expedition’s assistant zoologist, Apsley Cherry-Garrard, and Henry “Birdie” Bowers. They trekked 100 kilometers (62 miles) in complete darkness and temperatures as low as –60 degrees Celsius (–76 Fahrenheit) to reach the emperor-penguin breeding colony at Cape Crozier that Wilson had sighted 10 years earlier. Fewer than 100 penguins were there, all huddled together under the barrier cliff and trumpeting loudly as the men approached.

The men managed to retrieve five live eggs, keeping them inside their mittens for warmth. Two broke on the journey back to the base camp, but Wilson managed to cut open and remove the embryos from two of the remaining three eggs, which he pickled and eventually delivered to the Natural History Museum in London. Sliced and mounted onto slides, the embryos remained unexamined until 1934. By then, the evolutionary theory that inspired the expedition had been rejected.

Three years after Wilson’s harrowing winter trek, in August 1914, Ernest Shackleton led his second expedition to the Antarctic ice. The Endurance left the Grytviken whaling station on South Georgia Island on December 5, 1914, and within two days, Frank Worsley, the ship’s master from New Zealand, was steering through sea ice. Worsley had enthusiastically signed up for his first voyage into the Southern Ocean. He was an experienced navigator and a meticulous man by nature, and his charts, logs, and diaries ultimately survived as the only written records of the expedition, providing the raw material for both his and Shackleton’s later accounts.

On January 10, 1915, Worsley sighted part of the Antarctic continent called Coats Land. The water was “turgid with diatoms,” and the nearby sea ice was crowded with an assortment of crabeater seals, seabirds, and Adélie and emperor penguins. This was a polynya, an area of open water, that formed and re-formed annually along the Weddell Sea coast as a result of strong katabatic winds.

As the ship steamed along the ice cliffs of the sea, the men on board spotted a group of 40 emperor-penguin fledglings and captured 11 as food or biological specimens. When they set three or four free, Worsley wrote, “the departing birds turned round, gave us a little bow, and then hopped over the rail onto the ice, where they again bowed and walked off. It was so extraordinarily human as to be almost uncanny.”

By the week’s end, the vessel was caught fast in sea ice and drifting away from the coast. These were midsummer months, but the temperature fell to –50 degrees Celsius (–58 Fahrenheit), and the sea ice eventually froze into a solid mass around the ship. The Endurance drifted in the pack for more than nine months. On November 21, 1915, it was finally crushed. An attempt to sledge to land failed, and Shackleton decided that the drifting ice floe christened Patience Camp would be their best chance of reaching safety.

For the next five months, the men experienced all that a drifting ice floe can offer: cracks suddenly opening up beneath their tents, leopard seals lying in wait for a meal of penguin at the edge of the floe, a shortage of fresh water while all around lay a vast desert of sea ice too salty to drink. But in spite of all the dangers in those liminal spaces between ice and water, penguins proved to be their most cherished companions. Then, as winter closed in and the last remaining penguins and seals disappeared, the men were left with the loneliness of the sea ice. “Our craving,” wrote Worsley, “to see some living, breathing creature, any creature at all, may be imagined when I say that we missed them as though they had been our personal friends.”

When early polar explorers began to traverse the icy expanses of the Antarctic continent, they were surprised to see the abundance of life around its edges. Aboard the Terra Nova in 1910, Scott observed the myriad creatures that could be found living amidst the sea ice. At the edge of every ice floe was an assortment of crabeater seals, snow petrels, and Adélie penguins feasting on a banquet of krill.

Sea ice is notoriously fickle. The ship might enter an area of thin ice that gave way easily, only to be brought to a halt by a small floe that seemed to Scott to be “possessed of an evil spirit.” On occasions, caught between two floes, the Terra Nova would swing around and fall away, then drift to leeward before the next assault on the ice. Each maneuver could take up to half an hour, and Scott found himself being entertained by groups of Adélie penguins diving for food under the ship. He thought them “wholly ludicrous” on the ice, but underwater their agility and speed were astonishing.

Discovered in 1840 during the French Antarctic expedition led by Jules Dumont d’Urville, Adélie penguins are excellent swimmers as well as being adept on land. They breed on land in the warmer months and spend winter in the sea ice. They are also capable of walking long distances across ice to reach their colonies, occasionally sliding on their belly where there is sufficient snow covering.

During Shackleton’s Nimrod expedition a year or so earlier, the Adélies had won over everyone with their humanlike antics. T. W. Edgeworth David, the expedition’s chief scientist, wrote, “They are the dearest, quaintest, and most winsome birds imaginable.” They would come running up to the men, waving their flippers as if to signal for them to wait, and occasionally tripping over in their haste. Shackleton’s expedition artist, George Marston, would mimic their movements, then lead them in a procession over the ice, issuing orders as they copied him with a series of military-like maneuvers that brought roars of laughter and applause from the men and, no doubt, confusion to the penguins.

Such interactions between humans and penguins may have been heartwarming in any other context, but in reality most ended with the animals being slaughtered either to supplement the men’s diet with fresh meat or to be preserved as specimens. Some of the expeditioners felt the incongruity of the situation. Scott reflected, “It seems a terrible desecration to come to this quiet spot only to murder its innocent inhabitants and stain the white snow with blood; but necessities are often hideous.”

This post is adapted from McCann’s upcoming book, Wild Sea: A History of the Southern Ocean.



One day last June, Doug Boss pulled into a police-station parking lot to meet a stranger from Craigslist. His purpose: to buy used insulin pumps. Boss has type 1 diabetes, and he relies on a small pump attached to his body to deliver continuous doses of insulin that keep him alive.

To be clear, he didn’t need to buy used medical equipment on Craigslist. Boss, who is 55 and works in IT in Texas, has health insurance. He even has a new, in-warranty pump sitting at home. But he was thrilled to find on Craigslist a coveted old model that was made by the medical-device company Medtronic and discontinued years ago. What makes these outdated Medtronic pumps so desirable is, ironically, a security flaw. Boss was looking for a pump or two he could hack.

He’s not the only one. In 2014, a few hackers realized that the security flaw in certain Medtronic pumps could be exploited for a DIY revolution. Type 1 diabetes is a disease where the pancreas is unable to produce insulin to control blood sugar. For years, Boss had counted, down to the gram, the carbohydrates in every meal and told his pump how much insulin to dispense. Every cup of coffee (more insulin), every brisk walk (less insulin) turned into a math problem with serious consequences: Extremely high or low blood sugar can be fatal. The healthy pancreas does these “calculations” to adjust insulin automatically, and for decades researchers have worked toward creating an artificial pancreas that can do the same.

By 2014, the hardware components of a DIY artificial pancreas—a small insulin pump that attaches via thin disposable tubing to the body and a continuous sensor for glucose, or sugar, that slips just under the skin—were available, but it was impossible to connect the two. That’s where the security flaw came in. The hackers realized they could use it to override old Medtronic pumps with their own algorithm that automatically calculates insulin doses based on real-time glucose data. It closed the feedback loop.

They shared this code online as OpenAPS, and “looping,” as it’s called, began to catch on. Instead of micromanaging their blood sugar, people with diabetes could offload that work to an algorithm. In addition to OpenAPS, another system called Loop is now available. Dozens, then hundreds, and now thousands of people are experimenting with DIY artificial-pancreas systems—none of which the Food and Drug Administration has officially approved. And they’ve had to track down discontinued Medtronic pumps. It can sometimes take months to find one.

Obviously, you can’t just call up Medtronic to order a discontinued pump with a security flaw. “It’s eBay, Craigslist, Facebook. It’s like this underground market for these pumps,” says Aaron Kowalski, a DIY looper and also CEO of JDRF, a nonprofit that funds type 1 diabetes research. This is not exactly how a market for lifesaving medical devices is supposed to work. And yet, this is the only way it can work—for now.

By the time Boss decided to try looping, he had not gotten a good night’s sleep in a decade. Every night, the alarm on his glucose monitor would go off when his blood sugar dipped too low or climbed too high. He’d wake up, do math with a sleep-fogged brain, and either eat a snack or give himself extra insulin. Like many patients with type 1 diabetes, he was sacrificing sleep to stay alive.

OpenAPS changed that. To start looping with OpenAPS, Boss did also need to buy a mini computer called an Edison. The Edison receives data wirelessly from his continuous glucose monitor, runs an algorithm to predict future blood sugar, and tells the insulin pump how much to dispense every five minutes to prevent highs and lows. Boss could choose to monitor everything through his phone. But at night, he simply slept. “The sheer idea that I have a chance to sleep through the night ... ” he marveled to me. So many other loopers I spoke with echoed the sentiment. Jeremy Pettus, another looper, used to keep apple juice by his bed to guard against perilously low blood sugar. “One day my wife was like, ‘We haven’t bought you apple juice in a long time,’” he says. “That burden of having a dangerous low in the middle of my night completely disappeared.”

The looping algorithm makes these corrections throughout the day too. Laura Nally, another looper, described to me how she had always planned out her life hours in advance: Would she be walking a lot at work that day? Eating a meal in a couple hours? Taking a hot shower that could affect insulin absorption? “You’re always thinking, ‘What is the next thing I’m going to be doing?’” she says. With Loop, she still uses an app on her phone to tell the algorithm when she’s eating. (Same with OpenAPS, which is why both systems are technically “hybrid” closed systems rather than fully closed.) But if she is off by a few grams of carbohydrates or walks a little bit more than she expects, Loop can easily make real-time corrections. “Every decision we make, we’re trying to hit a bull’s-eye. With Loop, all I’m trying to do is get the dart on the board,” explains Erik Douds, who also uses Loop to manage his type 1 diabetes.

Loop and OpenAPS users tend to be a pretty self-selecting bunch, as the systems require buying your own equipment out of pocket and following detailed setup instructions. They also come with a bit of a learning curve. But according to one small study and many, many anecdotes, looping is, when done properly, both safe and better than a human brain at managing blood sugar. As the good word about looping has spread, demand for the few compatible models of Medtronic pumps has swelled.

Early on, loopers were often able to find old, compatible Medtronic pumps sitting unused in their own closets or a friend’s. Boss had actually gotten his first Medtronic pump from a cousin’s daughter before upgrading to a bigger version he found on Craigslist. Pettus, himself an endocrinologist, got his from a young woman who was his patient. “I have a cute little purple pump,” he says. Douds got his from a friend and looping evangelist whom he stayed with while traveling across the country. But when Nally wanted to start looping last year, she was living in the Bay Area, full of tech-savvy early adopters, and everyone she knew with a compatible Medtronic pump was already a looper. She was wary of buying one from a stranger online. Luckily, she ended up winning one of the periodic raffles for a loopable Medtronic pump in an online diabetes group. That’s how coveted the pumps have become.

An underlying security flaw is still the reason looping is possible with Medtronic pumps. (Would-be loopers are even told to watch out for old pumps whose software has been upgraded to fix the flaw.) The security issue doesn’t bother Boss, whose day job is in IT. There’s a tiny, theoretical risk that someone who knows his pump’s serial number and gets physically close can take over. But, he says, “if I drink coffee in the morning and forget to enter it into my phone, my blood sugar is going to be higher than normal.” The everyday risk of making such a mistake outweighs the remote risk of someone else hacking his pump.

A spokesperson for Medtronic wrote in a statement, “Patient safety is our first priority, and intentional device modifications can adversely impact device performance and put patient safety at risk. Medtronic strongly discourages intentional device modification of our insulin-pump systems.”

In the absence of official customer support, loopers have come to rely on one another. Rebecca Vitale told me the only reason she hasn’t quit Facebook is because she uses a group for Loop tech help. (Vitale is also friends with my partner.) From the group, she learned to cover her Medtronic pump in packing tape. The compatible Medtronic pumps, unlike newer models, are not waterproof, and their buttons are especially finicky around moisture. The packing tape keeps the pump just a bit more sweat-proof and waterproof. It’s a hack around a hack.

The looping community is so tight-knit that the person who wrote the code is sometimes the person answering questions. Hilary Koch, whose son loops, remembers spending two hours on the phone with one of the creators of OpenAPS. She tries to do her part too. “How you give back is, if you see somebody ask a question you know you can answer, you answer it,” she says. Boss also scours eBay for Edisons, which have been discontinued, and has given a few to people who want to loop, in return for a small donation to Nightscout, another open-source project used with OpenAPS to remotely access glucose data.

When the creators of OpenAPS, Dana Lewis and Scott Leibrand, shared their code back in 2015, they did so for free. They weren’t in it for money, and that ethos is still very much alive in the looping community today. And so, despite all the people clamoring for loopable Medtronic pumps, attempts to sell one to the highest bidder are met with swift backlash in the online community. The going price is usually about $500. “You’ll see posts for $1,000 to $3,000—and community members are like, ‘Haha, no,’” says Lewis. (The sticker price of new Medtronic pumps runs over $7,000.)

Since OpenAPS first became available, looping options have slowly expanded. Another group developed Loop for iPhone, which is more user-friendly in some ways but still requires an extra piece of hardware called a RileyLink.

A couple of other new options don’t even require Medtronic pumps—but they are currently limited in other ways. AndroidAPS, for example, runs on Accu-Chek or Dana pumps, which are approved in Europe and elsewhere, but not yet in the United States. The system also goes straight to an Android phone, eliminating the need for an extra device such as a RileyLink or an Edison. The manufacturer of Dana pumps consulted with the DIY looping community in developing its latest version.

Erica Potter liked the fact that her eight-year-old daughter would not need to carry around another part with AndroidAPS. But her family lives in the U.S., where no compatible pumps are sold. Through a contact in the diabetes community, Potter managed to find a medical-supply company in North Africa that would ship a Dana pump overseas. It came out to $2,000 with supplies and shipping. The setup has worked so well that Potter has ordered a second pump for her 6-year-old, who was recently diagnosed with type 1 diabetes. “I’m aiming for perfection because these are my kid’s organs,” she says. She is waiting for that second pump to ship right now.

More recently, loopers have started testing a hacked version of another pump called Omnipod, which is available in-warranty and tubeless. (Think about the convenience of AirPods versus regular earbuds, except for something that goes under your skin.) Public testing of the Loop-Omnipod system began just last week. Kate Farnsworth, who runs a Facebook group about looping and whose own daughter loops, saw her group gain 1,000 new members in just a few days, buoyed by interest in Omnipod. “I think we’ll have a lot of new loopers,” she says.

Even with these new options, DIY looping is still on the margins of the official health-care system: It means going overseas to buy pumps not yet approved in the United States. It means testing an experimental version with Omnipod. And in most cases in the United States, it’s meant finding old, out-of-warranty Medtronic pumps. Loopers with Medtronic pumps told me they worried their decade-old devices might break, and they’d have no way to fix them. Boss has a couple of backup pumps stockpiled. Kowalski, of the nonprofit JDRF, told me he once saw his brother, who also loops, watching soldering videos on YouTube when something broke. “People are doing wacky stuff,” he says. “We don’t want wacky. We want them to use things like they normally would.” JDRF, which is a major funder of artificial-pancreas research, has been working to make the technology mainstream.  

In fact, the FDA approved a looping system from Medtronic called the Minimed 670G in 2016, after the first people started using OpenAPS. The DIY loopers I spoke with had various reasons for sticking with their DIY setup, though: It gave them more flexibility in setting their target blood sugar. It allowed them to use their preferred glucose monitor rather than Medtronic’s.

A nonprofit called Tidepool is now collaborating on a clinical trial to get Loop approved by the FDA.  It’s also partnered with the company behind Omnipod to make the next version of its pods officially Loop-compatible—a more formalized version of the DIY Loop-Omnipod system that hackers just made available for public testing.

JDRF, which is a funder of Tidepool, has put forth a vision of a “plug and play” artificial pancreas. Currently, Medtronic’s MiniMed 670G locks the patient into a Medtronic pump, a Medtronic glucose sensor, and Medtronic software. The idea, says Kowalski, is to have multiple compatible pumps, glucose sensors, and algorithms, so that patients can mix and match what they prefer. Looping, in whatever form, is almost certainly the future for type 1 diabetes. It might be all that kids today ever know.

Koch’s son is almost 13 now, old enough to start learning how to manage diabetes on his own. She reflected on the years of interrupted sleep, of weighing the carbs in every meal he brought to school, of ticking off minutes for his blood sugar to drop before he could eat a snack. He’s been looping for more than two years now, and some of those memories are starting to fade. “He will never know it like we did,” she says. “And I think that’s a wonderful thing.”



When people pose the old question about whether a tree falling in an empty forest makes a sound, they presuppose that none of the other plants in the forest are listening in. Plants, supposedly, are silent and unhearing. They don’t make noises, unless rustled or bitten. When Rachel Carson described a spring bereft of birds, she called it silent.

But these stereotypes may not be true. According to a blossoming batch of studies, it’s not that plants have no acoustic lives. It’s more that, until now, we’ve been blissfully unaware of them.

The latest experiments in this niche but increasingly vocal field come from Lilach Hadany and Yossi Yovel at Tel Aviv University. In one set, they showed that some plants can hear the sounds of animal pollinators and react by rapidly sweetening their nectar. In a second set, they found that other plants make high-pitched noises that lie beyond the scope of human hearing but can nonetheless be detected some distance away.

After the team released early copies of two papers describing their work, not yet published in a scientific journal, I ran them past several independent researchers. Some of these researchers have argued that plants are surprisingly communicative; others have doubted the idea. Their views on the new studies, however, didn’t fall along obvious partisan lines. Almost unanimously, they loved the paper asserting that plants can hear and were skeptical about the one reporting that plants make noise. Those opposite responses to work done by the same team underscore how controversial this line of research still is, and how hard it is to study the sensory worlds of organisms that are so different from us.

The concept of floral communication has long been controversial, especially after decades of pseudoscientific (but very popular) claims about plants growing well to classical music or being attuned to human emotions. Those hokey claims “have never been substantiated by rigorous experiments,” says Richard Karban from the University of California at Davis, and they tainted the entire field of study, making scientists skeptical about the very notion of plants exchanging signals.

But after many careful studies, it’s clear that plants can send airborne, chemical messages, warning faraway relatives about marauding plant-eaters, and that animals can eavesdrop on these communiqués. Plants can also influence one another through the network of fungi that connects their roots—a so-called wood-wide web. And they can respond to vibrations moving through their tissues: Many release pollen only when insects land on them and buzz at the right frequency, while others create defensive chemicals when they sense the rumbles of chewing insects.

To Hadany, one of the Tel Aviv University researchers, it seemed weird to think that plants wouldn’t also make use of sounds—airborne vibrations. “Plants have plenty of interactions with animals, and animals both make and hear noises,” she says. “It would be maladaptive for plants to not use sound for communication. We tried to make clear predictions to test that and were quite surprised when it worked out.”

First, two team members, Marine Veits and Itzhak Khait, checked whether beach evening primroses could hear. In both lab experiments and outdoor trials, they found that the plants would react to recordings of a bee’s wingbeats by increasing the concentration of sugar in their nectar by about 20 percent. They did so in response only to the wingbeats and low frequency, pollinator-like sounds, not to those of higher pitch. And they reacted very quickly, sweetening their nectar in less than three minutes. That’s probably fast enough to affect a visiting bee, but even if that insect flies away too quickly, the plant is ready to better entice the next visitor. After all, the presence of one pollinator almost always means that there are more around.

“This shows yet again that plants can behave in remarkably animal-like ways,” says Heidi Appel from the University of Toledo, who has studied plants’ responses to animal vibrations. Crucially, she says, the study is “ecologically relevant”—that is, it involves a sound (bee buzzes) and a response (nectar sweetening) that actually matter to the plant. It’s a far cry from past studies that showed plants reacting to sounds they would never normally encounter, such as classical music, in ways that are hard to interpret (certain genes might switch on or off, but to what end?).

Here, the plants’ responses make clear evolutionary sense. Sweeter nectar is more enticing to pollinators, and by attracting more pollinators, the plant increases its odds of making more plants. But it takes a lot of energy to make supersweet nectar, and the resulting brew could be degraded by microbes or stolen by non-pollinating thieves. Far better to sweeten the fluid when it most needs to be sweet—and the buzz of a bee is the perfect cue that the time is right.

But if plants can hear, what are their ears? The team’s answer is surprising, yet tidy: It’s the flowers themselves. They used lasers to show that the primrose’s petals vibrate when hit by the sounds of a bee’s wingbeats. If they covered the blooms with glass jars, those vibrations never happened, and the nectar never sweetened. The flower, then, could act like the fleshy folds of our outer ears, channeling sound further into the plant. (Where? No one knows yet!) “The results are amazing,” says Karban. “They’re the most convincing data on this subject to date. They’re important in forcing the scientific community to confront its skepticism.”

“It’s such a wonderful and exciting finding,” adds Monica Gagliano from the University of Sydney, a pioneer in the study of plant acoustics. She notes that one of the team members, Daniel Chamovitz, “was quite skeptical, or even dismissive, of the whole idea of plant bioacoustics only a few years ago. Now, in the spirit of good science, he is experimentally testing these ideas. That approach deserves to be applauded and encouraged.”

But she and the others are less impressed by the Israeli team’s second study, which looked at whether plants make sounds. For decades, scientists have known that plants give off popping noises, as air bubbles form and collapse in their stems—a botanical version of the bends, which is exacerbated by drought. But these pops have mostly been recorded by microphones placed directly onto stems. Hadany and Yovel wanted to know whether they could be heard from afar, through the air. If so, perhaps they could act as signals for animals—or, more enticingly, for other plants.

The team put individual tobacco or tomato plants inside soundproof boxes, in front of two sensitive microphones each. They then searched for noises they could attribute to a specific plant—sounds picked up by a plant’s two dedicated mics but not by those trained onto its neighbors. It worked: Every few minutes, the plants emitted short ultrasonic sounds, too high for humans to hear normally. But they were still relatively soft noises. At a distance of four inches, they had a volume of 60 decibels, roughly equivalent to normal conversation and perhaps insignificant to any other creatures. “Ultrasonic-sensitive creatures like moths and bats, going around a field, might be hearing lots and lots of sound,” Hadany says.

The team also found that dry or damaged plants produce noises more frequently. A computer could even learn to distinguish the sounds of ailing plants from those of healthy ones, with about 70 percent accuracy. And if software can do it, could an insect? Might a moth use sound to avoid laying eggs on a stressed plant? Could hungry bats head toward the noise of plants being besieged by insects? And could farmers use these pops to tell whether their crops need more water?

Without knowing exactly how the pops of harmed and healthy plants differ, it’s hard to know how informative they’d be, says Rafael Rodríguez Sevilla from the University of Wisconsin at Milwaukee, who has called for more careful interpretations of studies on plant acoustics. Would an eavesdropper be looking for some change in how frequent they are? They’re not that common. They’re also very brief, and liable to fade with distance. “Yes, in theory, animals might use the sounds to gain information about a plant’s condition,” says Carel ten Cate from Leiden University, “but how meaningful is it if a plant produces something like 20 soft 0.1-millisecond pulses per hour?” And since the sounds would likely vary with different types of damage, or degrees of dryness, how much specific information could an animal possibly glean from them?

Also, “there is no indication that the pops are specialized signals of stress rather than cues produced incidentally due to the damage,” Rodriguez Sevilla adds. Hadany acknowledges that but says, “If the sounds are out there, they’re informative, even if they’re not ‘intentional’ by the plant.”

To convince their critics, Hadany and Yovel clearly need to do more experiments. They’re already planning to repeat their study in a more natural outdoor setting to see whether those sounds carry amid ambient noise. “We also need to test specific relevant organisms to see if they respond,” says Hadany. “And, of course, the most exciting prospect for us is: Are plants capable of hearing the sounds of plants?”





Today, a half century after Neil Armstrong took one small step onto the surface of the moon, there are just three humans living in space: the crew of the International Space Station. But after decades of talk, government agencies and entrepreneurs are now drawing up more concrete plans to return to the moon, and even travel onward to Mars. Getting there is one thing, but if we plan to set up colonies, we’ll have to figure out how to feed ourselves. Will Earth crops grow in space—and, if so, will they taste different? Will we be sipping spirulina smoothies and crunching on chlorella cookies, as scientists imagined in the 1960s, or preparing potatoes 6,000 different ways, like Matt Damon in The Martian? Listen in this episode for the stories about how and what we might be farming once we get to Mars.

Space is harsh. We aren’t suited to the thinner atmospheres and lower gravitational pull of Mars or the moon, and without Earth’s atmosphere to protect us, cosmic rays could damage the structure of our cells, including our DNA. Plants, it seems, are a little tougher than humans when it comes to adapting to the rigors of alien worlds: According to the NASA scientist Ray Wheeler, scientists began sending algae into space in the 1950s, and since 2015, U.S. astronauts on the ISS have been able to enjoy the odd leaf of homegrown lettuce, thanks to the work of Wheeler’s Kennedy Space Center colleague Gioia Massa.

One of the big leaps forward in space agriculture came little more than a decade ago with the introduction of broad-spectrum, affordable LED lights—these are now powerful, efficient, and cool enough to allow plants to be grown entirely indoors. In this episode, Gastropod visits Wageningen University in the Netherlands, the world leader in indoor farming, where the scientist Esther Meinen drew on her greenhouse expertise to select the crops and design the best “light recipe” for EDEN ISS, a European space-farming prototype that provided fresh herbs and vegetables to the crew of the Neumayer Antarctic station throughout the last polar winter.

Those radishes, celery, and tomatoes were all grown hydroponically, without soil. But plants love soil—and on Mars, the subsurface soil may even offer some water. So can we grow crops directly in Martian or moon dirt? As it turns out, although Apollo astronauts brought nearly a thousand pounds of rocky dust back from the surface of the moon, no one at NASA had ever used it to grow plants. The remaining lunar material is too precious for NASA to hand out, and we don’t even have soil from Mars. But a few years ago, Meinen’s colleague Wieger Wamelink decided to try growing plants using Martian- and lunar-soil simulants. In this episode, we visit his Martian test plot to learn about the challenges of exoplanetary terroir—and taste the results. And whether we get there or not, it turns out that figuring out how to grow plants in space has plenty to teach us about farming here on Earth. Listen in this episode for the how, what, and why of space agriculture.

This post appears courtesy of Gastropod. 



Over the next decade, more than 400 large dams will be built on the Himalayan rivers—by India, China, Nepal, Bhutan, and Pakistan—to feed the region’s hunger for electricity and its need for irrigation. New ports and thermal power plants line the coastal arc that runs from India, through Southeast Asia, to China. India and China have embarked on schemes to divert rivers to bring water to their driest lands: Costing tens or hundreds of billions of dollars, they are the largest and most expensive construction projects the world has ever seen. At stake in how these plans unfold is the welfare of a significant portion of humanity. At stake is the future shape of Asia, the relations among its nations.

The Indian subcontinent is the crucible of the monsoon. In its simplest definition, the monsoon is “a seasonal prevailing wind.” There are other monsoons, in northern Australia and in North America; none is as pronounced, as marked in its reversal between wet and dry seasons, as the South Asian monsoon. More than 70 percent of total rainfall in South Asia occurs during just three months each year, between June and September. Even within that period, rainfall is not consistent: It is compressed into just 100 hours of torrential rain across the summer months.

Despite a vast expansion in irrigation since 1947, 60 percent of Indian agriculture remains rain-fed, and agriculture employs about half of India’s population. Unlike China, unlike most large countries in the world, India’s population will continue to be predominantly rural until the mid-21st century. No comparably large number of human beings anywhere in the world is so dependent on such intensely seasonal rainfall. In the first decade of the 20th century, the finance minister in the imperial government declared that “every budget is a gamble on the rains”; more than a century later, the leading environmental activist Sunita Narain reversed the terms but retained the substance of the observation: “India’s finance minister is the monsoon,” she declared.

Climate is woven into the fabric of Indian social, economic, and political thought in a way that it is not (or is no longer) elsewhere. In the late 20th century, that claim would have raised hackles among scholars of South Asia; it might still do so today. A fundamental assumption of modernity was that we had mastered nature. The notion of India in thrall to the monsoon would seem to perpetuate a colonial idea of India’s irredeemable backwardness. To emphasize the power of the monsoon would be to portray Indian lives as so many marionettes moved by a climatic puppet master. That is how this story would have been understood a generation ago.

But now, alarmed by the planetary crisis of climate change, a reminder of nature’s power has different implications. This is not a story of geography as destiny. It is a story of how the idea of geography as destiny provoked, from the mid-19th century on, a whole series of social, political, and technological responses within and beyond India.

The South Asian monsoon has effects far beyond South Asia. We know this, at least in part, because of climate research undertaken in India in the 20th century. Sir Gilbert Walker, a pioneer of global climate science, wrote in 1927 that “the climate of India is of special interest, not merely as that of the greatest tropical region in the British Empire, but also because it seems to have been designed by nature with the object of demonstrating physical processes on a huge scale.” That sense of scientific opportunity, combined with the pressing material need to understand the monsoon, inspired a century of study in India. Charles Normand, Walker’s successor as head of the Indian weather service, insisted that the monsoon is “an active, not a passive, feature in world weather.”

Subsequent research has confirmed his view—the Asian monsoon is entwined with many aspects of the global climate. It has an important influence on global atmospheric circulation. The future behavior of the South Asian monsoon has implications for the whole world. Arguably no other part of the global climate system affects more people, more directly.

The breakthroughs in tropical meteorology of the late 20th century shed new light on the scale and complexity of internal variability in the monsoon on multiple timescales—from the quasiperiodic impact of the El Niño–Southern Oscillation system to the tropical-weather fluctuation pattern known as the Madden-Julian Oscillation. In recent years, the focus of scientific research has been on how the effects of anthropogenic climate change interact with the monsoon’s natural variability in dangerous and unpredictable ways.

The most fundamental forces driving the monsoon are the thermal contrast between the land and the ocean and the availability of moisture. Climate change affects both of these drivers of wind and rain. The warming of the ocean’s surface is likely to augment the amount of moisture the monsoon winds pick up on their journey toward the Indian subcontinent. But if the ocean surface warms more rapidly than the land, which appears to be happening in equatorial waters, this would narrow the temperature gradient that drives the winds, and so weaken circulation. Put simply, many climate models predict that the first of these processes will predominate: “Wet gets wetter” as a result of greenhouse-gas emissions. They predict, that is to say, that the moist monsoon lands will see an increase in rainfall.

But the monsoon is an intricate phenomenon, as meteorologists have long known. It is increasingly clear that monsoon rainfall is affected not only by planetary warming but also by transformations on a regional scale, including the emission of aerosols—from vehicles, crop burning, and domestic fires—and changes in land use. The urgent challenge for climate science is to disentangle and to understand these global and regional influences on the behavior of the monsoon. And so far, the monsoon has proved much harder to capture in models than, say, global temperatures.

The availability of detailed records of climate and rainfall in India—which themselves are a product of the history of Indian meteorology going back to the efforts of Henry Blanford and his colleagues in the late 19th century—have allowed scientists to reconstruct in detail the monsoon’s behavior over the past 60 years. The picture these data present is complex, and in some ways surprising. Average summer rainfall over India has declined by around 7 percent since 1950. The cause of this downward trend in rainfall lies in the pattern of India’s development since independence. Its explanation, that is to say, lies in the province of economic history.

In the late 1990s, research vessels observed exceptionally high concentrations of aerosols in the northern Indian Ocean. Satellite images showed a stain that spread across the Indo-Gangetic Plain and over the Indian Ocean—researchers called it the “brown cloud,” an accurate, if not a poetic, description of the haze. Between January and March 1999, a large team of investigators set out to understand this brown cloud, taking readings from their base at the Kaashidhoo Observatory on one of the most remote islands of the Maldives. The project was led by Veerabhadran Ramanathan, an Indian oceanographer based at the Scripps Institute in La Jolla, California. One of the scientists involved was the Dutch atmospheric chemist Paul Crutzen, who around the same time also coined the term Anthropocene, referring to a new geological epoch in which human activity is the most important influence on Earth’s physical processes.

The project found that the haze was a noxious composite of sulfate, nitrate, black carbon, dust, and fly ash, as well as naturally occurring aerosols including sea salt and mineral dust. Three-quarters of the composition of the brown cloud could be attributed directly to human activity, especially concentrated along the densely populated Indo-Gangetic Plain and northwestern India. In this region, where up to 80 percent of the population remains rural, and where many rural families continue to be deprived of electricity, much of the black carbon is produced by domestic burning of biomass—wood, crop residue, dung, and coal— used primarily for cooking. Open crop burning accounts for the rest. The stoves used in households are inefficient and combustion is incomplete, producing large amounts of soot.

Apart from their likely effects on regional climate, these emissions also poison human bodies. By one estimate, more than 400,000 premature deaths each year in India can be attributed to indoor pollution. Black carbon combines, in the brown cloud, with sulfates and other aerosols—and the Indo-Gangetic Plain bears an additional burden in this respect, as a result of pockets of intensive industrial and extractive activity. Since the late 19th century, the Indo-Gangetic Plain has been the core region of India’s extractive industries, built around the rich coal and mineral deposits in the Chota Nagpur region. Further along the Yamuna River, the Delhi region is one of India’s fastest-growing metropolitan areas, and its largest in absolute terms. Emissions have increased exponentially since the 1970s as India’s population has grown, as its economy has expanded, as inequalities within and among regions have widened. The Indo-Gangetic Plain suffers from a double pathology: The sulfur, carbon, and nitrogen-dioxide emissions that accompany energy-intensive growth are combined with the black carbon that comes from the use of cheaper, dirtier fuels by millions without access to electricity.

All this is shifting the monsoon’s patterns. Aerosols absorb solar radiation, allowing less of it to reach Earth’s surface. This cools the land, diminishes the temperature contrast between the land and sea, and weakens the atmospheric circulation that sustains the summer monsoon. Changes in circulation over the Indian subcontinent in turn affect the tightly integrated air-sea interaction that binds the Asian continent with the Indian Ocean, a system that already contains plenty of internal variability. Because of the way the Asian monsoon is linked to other parts of the planet’s climate, it is possible that aerosols over South Asia have global consequences. When all these effects are coupled with the impact of global warming on the ocean and the atmosphere, the instabilities multiply. Far from counteracting the effect of greenhouse gases in any simple sense, the impact of aerosols complicates them.

A further driver of regional climate change is rapid changes in land use. Over the past 150 years, forest cover over most parts of Asia has declined dramatically. The intensification of agricultural production in India, and the use of more water for irrigation, has affected the moisture of the soil, its capacity to absorb or reflect heat. Crops reflect more solar radiation than forests, which tend to absorb it; the greater reflexivity of land planted with crops makes it cooler, once again weakening the temperature differentials that drive circulation and rainfall. The tropical meteorologist Deepti Singh points out that climate models have often failed to predict the monsoon’s behavior in part because they are too abstract to take into account the “complex topography, temperature, and moisture gradients in the region that can influence the monsoon circulation.” The models omit, that is, precisely the details of landscape and microclimate that the meteorologists of a century earlier were so deeply interested in, which they depicted in their detailed local and regional maps of India’s climate.

We are left with the most bitter of ironies. Many of the measures taken to secure India against the vagaries of the monsoon in the second half of the 20th century—intensive irrigation, the planting of new crops—have, through a cascade of unintended consequences, destabilized the monsoon itself. When the geographers of the early 20th century wrote of “monsoon Asia,” they saw the monsoon as sovereign—it shaped the lives of hundreds of millions of people, who waited on its every move. Monsoon Asia means something quite different now, when the monsoon’s behavior, increasingly erratic, responds to human intervention.

This post is adapted from Amrith’s new book, Unruly Waters: How Rains, Rivers, Coasts, and Seas Have Shaped Asia’s History.



When plants are bitten by insects, they release a chemical scream—a cocktail of compounds that travel through the air. Some deter pests directly by confusing or repelling them; others indirectly protect plants by summoning predatory ants or parasitic wasps. Still others raise the alarm in parts of the plant that aren’t yet under attack, telling them to ramp up their defenses in preparation. These same alarms can spread over entire fields, warning other plants to prep their defenses. We can’t perceive these signals, but to plants, they’re as foreboding as wailing sirens.

But Peng-Jun Zhang and Xiao-Ping Yu from China Jiliang University have shown that one of the world’s worst agricultural pests—the silverleaf whitefly—can hack this communication system. When the whiteflies bite, they somehow change a plant’s airborne warnings so that they convey information about the wrong threat. Deceived, the neighboring plants invest in the wrong defenses and become more susceptible to the whiteflies. These pests, by seeding entire fields with faulty intelligence, can prime the plants ahead of them for their arrival.

This might help explain why the silverleaf whitefly is so devastatingly invasive. It causes billions of dollars’ worth of damage every year and feeds from some 500 types of plants—squash, cucumber, cotton, melons, eggplant, cabbage, and more. Wherever it goes, it drains nutrients from its hosts, covers their leaves in sticky liquids that promote the growth of molds, and infects them with devastating viruses. Originating somewhere in Africa, it has spread across the entire world over the past two centuries.

In very rough terms, plants have two main defense systems: one for insects and other plant-eating animals, and another for infectious microbes. The former centers on jasmonic acid, a hormone that triggers the production of insecticidal toxins. The latter centers on salicylic acid, a different hormone that triggers the production of antimicrobials, or tough molecules that barricade a plant’s cells against besieging microbes. In 2007, Sonia Zárate and Louisa Kempema from the University of California at Riverside showed that whiteflies induce the wrong defense—the antimicrobial salicylic-acid one, instead of the anti-insect jasmonic-acid one.

Now Zhang and Yu have expanded on that finding by showing that these inappropriate defenses can cascade through an entire field. The team placed pairs of tomato plants in separate glass chambers, connected by tubes that allowed air to pass between them. If the first plant was infested with caterpillars, the second ramped up its anti-insect defenses. When caterpillars attacked that second plant, they had a tougher time and grew more slowly.

But if the first tomato was infested with whiteflies, everything went topsy-turvy. The plant released a very different airborne cocktail, which compelled its neighbor to turn down its anti-insect defenses and turn up the antimicrobial pathway. If whitefly larvae ended up on that misinformed tomato, they actually grew faster than they would have on plants that had received no warnings at all.

It’s not clear how the whiteflies hack the plants’ messages, but the consequences are evident. By simply biting a plant, whiteflies can make surrounding plants into more suitable hosts for the next generation of whiteflies. “It’s a really interesting finding,” says Petra Bleeker from the University of Amsterdam. Although the whitefly larvae gain only a small edge on the neighboring plants, Bleeker says, that small effect could add up across time and space. It would be interesting to do a larger-scale experiment to see how these corrupted messages play out over an entire field or greenhouse.

“It is super interesting to step into this invisible world,” says UC Riverside’s Zárate. “It appears that the whitefly is ahead in the arms race … but the plant may be preparing itself and neighboring plants to do battle with the viruses that the whitefly is known to harbor.” If these are the true threat, it might make sense for infested plants—and their neighbors—to steel themselves against imminent infections instead of approaching insects. “The problem for the plants is that this also benefits the whiteflies,” says Ted Turlings from the University of Neuchâtel, who was involved in the new study.

Turlings suggests that it might be possible to change these responses to our advantage, perhaps by breeding or modifying plants to launch the anti-insect defenses in response to whitefly attacks.

He is also leading a five-year project called Agriscents to create machines that can eavesdrop on the chemical alarms of plants, warning farmers of infestations in real time, before they’re evident to the naked eye. “The ultimate goal is to have robots sniff plants and inform farmers about the presence of pests,” says Turlings. “The farmer—or the robot—can then apply a pesticide at the right time and in the right place, long before the insects do too much damage.”

Such a system might be years in the making, but for now, there already is an animal that does something similar. Encarsia formosa is a parasitic wasp that exclusively targets whiteflies, and as Zhang and Turlings discovered six years ago, it homes in on one of the airborne chemicals released by infested plants. The whiteflies can fool their hosts, and the neighbors of their hosts, but they can’t fool the wasp.



In 1957, a beach-ball-shaped satellite hurtled into the sky and pierced the invisible line between Earth and space. As it rounded the planet, Sputnik drew an unseen line of its own, splitting history into distinct parts—before humankind became a spacefaring species, and after. “Listen now for the sound that will forevermore separate the old from the new,” one NBC broadcaster said in awe, and insistent that others join him. He played the staccato call from the satellite, a gentle beep beep beep.

Decades later, we are not as impressed with satellites. There have been thousands of other Sputniks. Instead of earning front-page stories, satellites stitch together the hidden linings of our daily lives, providing and powering too many basic functions to list. They form a kind of exoskeleton around Earth, which is growing thicker every year with each new launch.

The newest additions come from SpaceX. The company launched 60 satellites into orbit Thursday night, the first batch of thousands of satellites that will someday beam internet down to Earth. The satellites traveled to space in a big, cozy stack. Once in orbit, they will fan out—“like spreading a deck of cards on a table,” according to Elon Musk—and unfurl solar arrays to soak up the sunlight they’ll use to power themselves. As of early Friday morning, all 60 satellites had come online.

Musk, SpaceX’s CEO, says the effort, named Starlink, will provide convenient and reliable internet service “ideally throughout the world.”

Sixty is just the beginning. Musk hopes to deploy as many as 12,000 satellites to furnish the constellation. “I wouldn’t be surprised if we’re launching at least on the order of 1,000 to 2,000 satellites a year,” he told reporters recently.

Here’s what that would look like:

Starlink will connect the globe with reliable and affordable high-speed broadband services pic.twitter.com/dWVvPwVWU4

That’s a lot of satellites. Right now, about 5,000 are in orbit around Earth—in total. Only about 2,000 are still functioning. Nearly half belong to the United States, with China and Russia leading the pack with the rest. “I think within a year and a half, maybe two years, if things go well, SpaceX will probably have more satellites in orbit than all other satellites combined,” Musk said. “If things go according to plan—a big if, of course, but it is quite remarkable to think of that being the case.”

The launch puts Musk ahead of other entrepreneurs with their own internet-satellite ambitions. Jeff Bezos wants to launch thousands through a program under Amazon, and Greg Wyler, the head of OneWeb, which was established for this express purpose, deployed the company’s first six satellites in February.

SpaceX’s initial delivery of satellites is also a bit of a headache for a niche group of conservationists, the people who worry about the growing number of satellites and pieces of debris accumulating over Earth. They warn that a crowded orbit increases the risk of collisions, fast-moving impacts that would generate even more floating junk. A historian once told me that if an avalanche of crashes were to knock out the entire satellite infrastructure, “tentacles of disruption” would unfurl across the globe. Some experts even say that a packed orbit would make it more difficult for space missions to squeeze through and leave Earth altogether.

“The space environment isn’t easy to clean,” says Lisa Ruth Rand, a historian who studies orbital debris. “As difficult as it is to remediate damage on Earth from, say, an oil spill, imagine how difficult it would be to clean up a disaster in microgravity.”

Musk said SpaceX is “taking great pains to make sure there’s not an orbital-debris issue.” The newest satellites, he pointed out, orbit at an altitude low enough that allows them to become sucked back into Earth’s atmosphere within a year if they stop working. The satellites also receive radar information that tracks objects in orbit, allowing them to “automatically maneuver around any orbital debris.”

The fact that SpaceX is doing the kind of work historically done by national governments doesn’t seem as novel as it did even a few years ago. But the thought of a commercial company’s satellites outnumbering all the rest, and in such a short period of time, is rather astonishing. If extraterrestrial beings were to swing past Earth and check the tags on the artificial objects shrouding the planet, they might think the place belonged to SpaceX.



The phrase Cold War didn’t always refer to a time period. In the late 1940s and early 1950s, the very years that the battle lines between the United States and the Soviet Union were being drawn, U.S. foreign-policy strategists used the phrase to invoke a specific kind of conflict, one carried out by “means short of war.” If, as NSC-68, a key document of U.S. strategy, asserted in 1950, the United States and the Soviet Union were locked in an ideological clash of civilizations, a battle between “slavery” and “freedom,” a victory by force would be hollow. If the United States wanted to defeat communism, it needed to do so “by the strategy of cold war,” combining political, economic, and psychological techniques. “The cold war,” NSC-68 warned, “is in fact a real war in which the survival of the free world is at stake.”

This was a new kind of conflict requiring new kinds of weapons: psychological weapons. The question of psychological warfare preoccupied a small but influential group of foreign-policy officials during President Harry S. Truman’s second term. By the time that Truman left office in January 1953, the United States had laid the legal and institutional foundations for overt propaganda campaigns as well as covert action. During that period of experimentation leading up to the Eisenhower presidency, almost anything U.S. strategists could dream up, short of overthrowing foreign governments (that would come later), was up for discussion. Among other things, the Marshall Plan allotted $13 billion to rebuild Western Europe, Voice of America transmitted jazz and news to listeners in 46 languages in more than a hundred countries, and the CIA sent tens of thousands of balloons filled with anti-Communist pamphlets into China.

Even as State Department, CIA, and Army officials spent countless hours working through the administrative challenges of launching a psychological-warfare program more or less from scratch, they spent remarkably little time discussing what kinds of messages might best promote the cause of “freedom.” Ideas about science rarely, if ever, explicitly appeared on lists of psychological-warfare objectives. Science entered U.S. psychological-warfare programs as a stowaway, tucked into the pockets of some of the private individuals to whom the State Department and the CIA turned to wage the United States’ battle against communism. More subtext than text, ideas about science subtly undergirded policy makers’ emerging plans for waging and winning this new kind of war.

Prior to the Cold War, the United States had never formally mounted psychological-warfare campaigns during peacetime. The country had, of course, engaged in practices that we might consider psychological warfare, using world’s fairs, missionaries, economic policies, and educational exchanges to promote U.S. values. But what changed in the years immediately following World War II was a sense that the United States was engaged in a prolonged battle of civilizations that could not be won through force alone. And, as was so typical throughout the Cold War, U.S. policy makers blamed the Soviet Union for forcing their hand.

On March 12, 1947, President Truman appeared before a joint session of Congress to request $400 million in economic and military aid to Turkey and Greece. In what came to be known as the Truman Doctrine, the president pledged to give such assistance as needed to help “free and independent nations to maintain their freedom” in the face of Communist threats. Three months later, the Marshall Plan was announced. Leaders in the United States didn’t consider the Marshall Plan an act of psychological warfare per se, but the Soviet Union’s leaders did and barred its satellite countries from participating.

This turned out to be the opening salvo in a high-stakes game of propaganda. In fall 1947, Communist Party officials revived the party’s prewar international propaganda network under a new name, the Communist Information Bureau, or Cominform. In mid-1948, the Soviet Union launched a campaign against the United States, targeted at audiences both within its own territories and in the world at large. In Moscow, the authorities celebrated writers, musicians, and scientists who promoted seemingly “Russian” values; abroad, the Cominform’s agents attacked U.S. aggression and promoted the Communist commitment to peace. Soviet authorities meanwhile cracked down on Soviet citizens’ ability to communicate with foreigners and foreign institutions. A dispatch from the U.S. ambassador to Moscow in January 1949 warned of the “near-impregnable barrier between Soviet citizens and foreigners in the U.S.S.R.” and specifically noted that the new restrictions eliminated exceptions for “scientific and educational institutions.”

Over the next year, the United States intensified its commitment to psychological warfare and, increasingly, did so publicly. On April 20, 1950, President Truman kicked off a national “Campaign of Truth” with an address before the American Society of Newspaper Editors. In a lunchtime address at the Statler Hotel in Washington, D.C., Truman implored the country’s leading editors to join the government in meeting “false propaganda with truth all around the globe.” “Everywhere that the propaganda of Communist totalitarianism is spread,” the president warned, “we must meet it and overcome it with honest information about freedom and democracy.”

Truman’s public speech coincided with a new statement of U.S. strategy issued behind closed doors. NSC-68, a top-secret document drafted by a committee chaired by Paul Nitze, the new head of the State Department’s Policy Planning Staff, confirmed the U.S. view of the conflict with the Soviet Union as total and ideological. It is not hyperbole to refer to the 66-page document as “apocalyptic,” as historians so frequently do, because the document responded directly to a potentially world-ending threat: the Soviet Union’s explosion of an atomic weapon in August 1949. The end of the U.S. atomic monopoly, along with Truman’s subsequent decision to endorse a hydrogen-bomb program in January 1950, dramatically raised the stakes of a potential hot war. Over and over again, NSC-68 called for overt and covert psychological strategies to both strengthen the resolve of allies and foment unrest in the Soviet Union’s vulnerable satellites.

This new, explicit focus on psychological warfare, combined with the outbreak of the Korean War in June, had an immediate effect on both overt and covert propaganda programs. Truman requested nearly $90 million from Congress to step up the State Department’s information campaigns; Congress agreed to two-thirds of this, $63.9 million, in September 1950. On the covert side, the CIA’s Office of Policy Coordination (OPC), the agency’s covert-operations wing, immediately submitted budget estimates to dramatically expand the OPC’s operations through 1957. The request included funds for staff, Washington facilities and overseas supply bases, organizational resources, paramilitary training, and a worldwide communications network.

The CIA also asked for something more difficult to supply than money: expertise. As matters currently stood, the OPC lacked “a significant body of knowledge, personnel reserves, techniques, and philosophy of operations” regarding psychological warfare. For this, the architects of U.S. psychological-warfare strategy turned to the scientific community. Undersecretary of State James Webb asked the noted physicist and veteran adviser Lloyd Berkner’s help in assembling a crack team of scientists to tackle the problem of psychological warfare. The resulting Project Troy brought together a group of social scientists and physical scientists from MIT and Harvard that either already had or would soon play leading roles in the Cold War. In addition to Berkner himself, the group included the electrical engineer (and future adviser to President Kennedy) Jerome Wiesner, the physicist and future Nobel laureate Edward Purcell, and the economist Max Millikan, all at MIT; the anthropologist Clyde Kluckhohn and the psychologist Jerome Bruner, both Office of War Information veterans now at Harvard; and a select few others from outside the universities, including RAND’s Hans Speier and Bell Labs’ John Pierce.

Webb had specifically asked Project Troy’s members to investigate technical obstacles to U.S. information campaigns, especially ways to circumvent the Soviet Union’s jamming of Voice of America broadcasts. This ambitious group, however, interpreted its mandate much more broadly, producing an 81-page report (plus appendixes) on all imaginable aspects of political warfare. In addition to the expected chapters on radio transmissions and the use of long-distance balloons, the study group’s February 1951 report covered such wide-ranging topics as preparing for Stalin’s death and strategies for debriefing Soviet defectors. The State Department was unimpressed, and Nitze pointed out that the group “went vastly beyond its original terms of reference and explored a field for which it had no special competence and about which it had little information.”

Project Troy’s biggest impact ultimately turned out to be long-lasting relationships between government officials at the State Department and the CIA and social scientists at MIT and Harvard. In the more immediate future, however, Project Troy’s endorsement of some sort of central agency to coordinate the various overt and covert psychological-warfare programs already in place sent ripples through the foreign-policy establishment.

Despite their top-secret clearances, the Project Troy members lacked access to information on, or even confirmation of the existence of, some of the OPC’s clandestine programs. But even lacking those details, they gleaned the obvious point that having so many government agencies involved in propaganda raised the risk of duplication, crossed purposes, and blown covers. The State Department had its overt information programs, of course, but so did the Economic Cooperation Administration (the agency in charge of implementing the Marshall Plan), the Army, and NATO. The CIA, the Economic Cooperation Administration, and the Army also maintained covert information programs. In Korea, the theater commander controlled psychological-warfare operations. None of these programs were being coordinated with the others.

Project Troy recommended a sort of “superboard” that would “plan general strategy for virtually all unconventional warfare measures,” including overt propaganda campaigns, covert actions, and economic warfare. In response, on April 4, 1951, Truman created a Psychological Strategy Board (PSB) responsible for “the coordination and evaluation of the national psychological effort.” Like Truman’s speech announcing a “Campaign of Truth,” the creation of the PSB was a public act: In late June, the White House and the State Department issued simultaneous press releases describing the PSB’s purpose, membership, and powers. The press releases of course omitted any reference to covert activities, but the U.S. government’s broader embrace of psychological strategies was not remotely secret at this point in the Cold War.

As a coordinating body, the PSB proved a disappointment. The wording of the board’s mandate suggested that it would oversee psychological programs but not actively participate in them, leaving operational control in the hands of the originating agency. Once again, the State Department, the CIA, and the Joint Chiefs of Staff began sniping over turf. Mired in scheduling conflicts, the board rarely met during its first six months and spent most of the time that it did meet on procedural details. The first meeting confirmed its astonishingly broad mission, covering “every kind of activity in support of U.S. policies except overt shooting and overt economic warfare.” In an impressive bit of understatement, Gordon Gray, the PSB’s first director, later recalled, “I don’t consider this one of the conspicuous successes of my life.”

The PSB’s eventual compromise on how it would evaluate projects—a negotiation that lasted until February 1952, nearly a year after the board’s creation—created a screening board that kept all but the most controversial projects off the PSB’s agenda. The State Department, for its part, was by now ready to relinquish control over covert operations. A State Department circular issued in December 1951 carefully distinguished among white, gray, and black propaganda, reminding foreign-service officers that neither the State Department nor the Economic Cooperation Administration was authorized to participate in black propaganda. As examples of permitted activities, the circular suggested contracts with publishers and other media producers, with or without attribution to the U.S. government, provided that attribution of material to the United States could be done “without serious embarrassment.” Inappropriate activities included direct assistance to foreign newspapers, financial assistance to labor or youth groups, and propaganda campaigns designed to influence foreign elections—all activities notable for being pursued at that very moment by the CIA’s Office of Policy Coordination.

The word science is strikingly absent from the key documents that established the parameters for early U.S. psychological operations. Even NSC-68, a notably thorough document, primarily discusses science in terms of weapons technology. Despite the dearth of explicit references to science in declassified reports on psychological operations during the Truman era, substantial evidence suggests that U.S. policy makers wanted science to play a larger role, even at this early date. We know that Marshall Plan administrators directed funds toward rebuilding European scientific research activities, most notably in the form of CERN, the European Organization for Nuclear Research. Approximately 15 percent of the articles published in the State Department’s glossy Russian-language publication Amerika from 1945 to 1952 covered advances in science, medicine, or technology. In 1950, 20 percent of Fulbright grants to university faculty and teachers went to natural scientists, with an additional 25 percent going to social scientists.

All this suggests that scientific programming had a place, if not necessarily a prominent one, in both overt and covert psychological-warfare programs in the early 1950s. Over time, the CIA and the State Department would find ways to incorporate messages about scientific progress more directly into their work. They did so particularly with programming aimed at a particular class of elite technocrats in developing nations—the very people that NS-68 proposed to win over in the first place.

This post is adapted from Wolfe’s new book, Freedom’s Laboratory: The Cold War Struggle for the Soul of Science.



On a family vacation last summer, driving along the empty highways of northern Idaho near the Canadian border, I saw an unlikely road sign—a relic. Diamond-shaped with a yellow background, the sign featured the familiar black silhouette of a deerlike animal. But unlike those on deer-crossing signs, the animal pictured had large antlers and appeared to be ambling toward the road, not leaping. It took me a moment to realize that it was a caribou.

Seeing a caribou wander onto an Idaho highway is about as likely as watching a UFO land there. The South Selkirk herd—the only remaining caribou herd that roamed the continental United States—has dwindled to just two animals, both female. “Not even Noah could save them,” a Canadian biologist told me. Last spring, scientists declared the herd functionally extinct.

Though that news barely registered with the American public, it was powerful: the imminent disappearance of a large mammal species from the Lower 48. And the Selkirk caribou are only the tip of the melting iceberg. Across a broad swath of Canada and Alaska, caribou populations have been plummeting for decades. The main cause: industrial development in their habitat. Today seeing caribou in their original Canadian range requires luck, patience, and often a helicopter.

One July afternoon in northeastern British Columbia, near where the Peace River flows out of the Canadian Rockies and toward the plains, I climbed into the back of a pickup truck. At the wheel was Line (pronounced Lynn) Giguere, a Francophone wildlife biologist. In the passenger seat was her husband, Scott McNay, an ecologist who has spent more than two decades trying to save caribou.

Here, in what’s called the South Peace region, on behalf of two local First Nations communities, Giguere and McNay have piloted a last-ditch effort to revive a different struggling caribou herd. It’s a remnant population of a much larger herd that once roamed the region’s forests. Trying to save this one small herd has been grueling at times—physically, emotionally, politically. Stemming the caribou declines on a larger scale, the couple say, could also take a personal toll.

Giguere and McNay live three hours away in Mackenzie, a town of about 3,500 people dominated by sawmills and pulp mills. McNay, who is tall with thinning hair and a bushy blond mustache, used to work as a biologist for the timber industry there. “Mackenzie is a small town,” he said. Saving the other herds in the South Peace region—six more, all in trouble—would require habitat protections that could shrink the area’s logging economy. Which would make the couple highly unpopular. “We might have to sell our house,” McNay said, half-joking.

Giguere, who exudes a cheerful, midwestern-style competence, agreed. “They’re gonna hate us,” she said in French-accented English.

We headed out of the tiny town of Hudson’s Hope into the mountains, and soon arrived at an active logging road. For about 60 miles, a two-hour ride, we bounced along dirt paths that grew steeper and rockier as we climbed. In the passenger seat, McNay, who hails from Prince Edward Island, dutifully called out our location over the truck’s radio every even-numbered kilometer, a protocol designed to avoid collisions. Trucks coming downhill called at the odd numbers, and soon one announced its location just uphill. “You should pull over soon,” McNay said. “Where? Shit,” Giguere replied. She found a narrow pullout and edged the Ford Super Duty out of harm’s way. A couple of minutes later, a truck loaded with logs came barreling past.

Up to 100 trucks a day carry timber down this road. About 20 years ago, timber companies carried out a series of big clear-cuts in this area, which impacted the caribou herds. “They’re just kind of getting back to it now,” McNay says of the logging, which has resumed on a large scale, in part to take away trees killed by the mountain pine beetle. “That’s what we’re up against in trying to protect habitat.”

A half hour or so later, as McNay called out our location—“36 up the Johnson, pickup”—a young deer pranced out of the woods. Giguere tapped the horn to coax it back into the forest. At the 42-kilometer mark, a lynx darted across the road. Further up, the road skirted a logging camp, with tents and RVs and piles of stacked timber. At 68 kilometers, a mother grouse and her chick appeared at the forest’s edge. We turned onto a bumpier dirt track, and then another, until we finally arrived at a flat clearing. A long, high fence covered in black fabric marked the edge of a caribou maternity pen—the centerpiece of an expensive, labor-intensive effort to revive the dwindling Klinse-Za herd.

Inside the fence was a 37-acre patch of woods and meadows, dense stands of pine and spruce opening onto sunny clearings, where a dozen female caribou and their nine babies were spending their summer. After being located by helicopter (many of the animals are radio-collared), the cows had been netted from the air, sedated, zipped into body bags, and flown to the enclosure, one at a time, back in snowy March. The pregnant cows had given birth inside the pen, where they and their babies were safe from wolves, bears, and other predators. In a couple of weeks, when the calves were two and a half months old—big enough to outrun a grizzly, if not a wolf—all the caribou would be released from the pen.

As a conservation measure, the maternity pen is a highly meddlesome intervention. But it’s one that McNay, Giguere, and members of local indigenous communities—who for millennia harvested caribou across their ancestral lands—feel is essential. “Because of where we are, we have to be a little heavy-handed until we can get things back into balance,” Roland Willson, the chief of the West Moberly First Nations, told me in his office on the shore of Moberly Lake. “The maternity pen is very obtrusive. Chasing caribou with helicopters, netting them—that’s not something you want to be doing. But because it’s an extreme situation, we have to take extreme measures.”

It’s becoming a familiar scenario, in North America and around the globe. As human activity pushes other species to the brink, the most feasible solutions seem more and more ludicrous. Yet meddling with nature in preposterous ways is often vastly easier than the alternative: fundamentally altering human behavior.

Caribou, a type of deer, live across a massive slice of the planet’s north, from the Arctic tundra south through the boreal, or northern, forest. They reproduce slowly: Females are pregnant for nearly eight months and give birth to just one baby at a time. They’re the only species on Earth in which both sexes grow antlers.

They are also what scientists call an “indicator species,” one whose own health shows the status of a whole ecosystem. And they’ve become unwitting sentinels, on some level, of life as we know it. The boreal forest, a vast band of spruce, fir, pine, and birch that covers one and a half billion acres of North America, stores roughly a third of the planet’s land-based carbon. It is a crucial source of Earth’s fresh water, and billions of birds from more than 300 species breed within it. The boreal is still the largest unbroken forest on Earth, representing a quarter of all remaining intact forest. But nearly a third of Canada’s boreal has already been carved up or earmarked for industrial use.

The starkest casualty so far has been the caribou. Though they belong to the same species as reindeer, rangifer tarandus, unlike reindeer they have never been domesticated. Perhaps that’s why they’re often used as symbols of wildness and freedom, and subtly tied to Canada’s national identity. Or not so subtly: They’re featured on Canadian quarters. In that sense, their story parallels that of bison in the United States—an animal that was immensely important to indigenous people, and which white Americans clung to as an icon even as they nearly let it vanish.

Canada’s woodland caribou, a subspecies, are most at risk. They live in old-growth forests, where they feed largely on lichens that grow on the ground and on trees. The reasons for their decline are not especially complex or mysterious. Cutting down forests wipes out their habitat. Building roads across forests provides easy access for animals that eat them. And because caribou reproduce so slowly, the problem boils down to simple math: Too many are dying, and not enough are surviving to reproduce.

In the South Peace region, where West Moberly lies, the Klinse-Za herd had dwindled to just 16 animals by 2013, down from around 180 in the 1990s. In the past, the herd would migrate in the wintertime to high in the mountains, where snow would act as a buffer from wolves. But the roads that now crisscross the region’s forests—and that continue to sprout like weeds—dealt a dual blow. They fragmented caribou habitat, slicing up interconnected herds into isolated groups. And they provided the wolves year-round access to tasty caribou flesh. Research suggests that wolves can travel up to three times faster along roads and trails than they can in unbroken forest.

Opening up the forest also brings in more of the animals wolves crave—deer, elk, moose. With more to eat, the wolves can proliferate, increasing the pressure on caribou. And because the wolves have so many species to feast on, their populations remain large even as caribou numbers shrink.

As of last year, 28 of the 57 distinct populations of woodland caribou across Canada were shrinking. In Alberta, all of the woodland caribou populations whose ranges overlap with oil-and-gas development “are in rapid decline,” according to a recent study, and they are shrinking by half every eight years. Scientists now predict that nearly a third of Canada’s boreal caribou could disappear within the next 15 years.

“It’s North America’s greatest terrestrial conservation problem,” says Robert Serrouya, the director of the Caribou Monitoring Unit at the Alberta Biodiversity Monitoring Institute. Unlike some endangered species that live in a discrete, fairly small area—a snail, say, that lives only in one hot spring—caribou naturally occur in relatively small populations but are broadly distributed across a massive landscape. And that landscape is irresistible to industry.

Although caribou were listed as threatened in 2003, under Canada’s nascent Species at Risk Act (SARA), it took almost a decade for the government to create a plan to save them. And though long awaited, that plan has so far had little impact. Not a single province met its federally mandated 2017 deadline to produce a recovery strategy.

For Willson and his community, that lack of action has been agonizing. The members of West Moberly, a small band of Dunne-Za people, historically ate caribou meat, made clothing from their skin, used their antlers for medicine, and even made tools from their bones; since childhood, Willson has listened to tribal elders reminisce about hunting caribou on their traditional lands. “Caribou were considered a convenient food because there were so many of them,” he said. “If you couldn’t get a moose or an elk, you could always go to the mountains and get a caribou.” Willson has hunted caribou, but to do so, he’s had to travel far to the north, where development is sparser and herds are faring much better. “But north of us is somebody else’s area. We’re going into their area and harvesting their caribou. And it’s not just us; it’s everybody that hunts. Everybody’s going to that area.” (West Moberly is one of 39 nations across four provinces that are signatories to Treaty 8, which governs tribal rights to hunting and fishing, among other things. Treaty 8 member nations can hunt and fish across the whole 325,000-square-mile territory covered by the treaty.)

The caribou crisis in the South Peace region began in the late 1960s, when construction of the W. A. C Bennett Dam flooded several nearby canyons and turned a long stretch of the river into the 680-square-mile Williston Lake. The new lake, the world’s seventh-largest reservoir, submerged the territorial home of two other First Nations, Kwadacha and Tsay Keh Dene. It sunk First Nations cemeteries, hunting grounds, fishing spots, and trapper cabins. It also slashed a large caribou herd’s migration route, stranding groups of animals on opposite sides of the lake. After the dam went in, the water rose far faster than engineers had predicted, sweeping timber down hillsides and drowning an unknown number of caribou and other animals.

With hydropower on hand, industrial development quickly followed: large-scale forestry, mining, oil, and gas. And not long afterward, local indigenous people “noticed this drastic decline” in caribou, Willson says. Local First Nations voluntarily imposed a moratorium on caribou hunting. Decades later, after SARA passed and caribou were listed as threatened, Willson waited for British Columbia to set some key areas off-limits to industry.

Instead, in 2008 West Moberly learned that a coal-mining company had applied for a permit in the core habitat of the Burnt Pine caribou herd, one of eight herds then remaining in the region, whose numbers had already dwindled down to nine. The nation filed an injunction to stop the mine, and in an important court ruling, West Moberly prevailed. But the decision came too late. Without permits, the mining company had been illegally clearing the forest. By the time West Moberly won its case, only two caribou—a male and a female—remained.

A few days after the verdict, tragedy struck. The bull fell to his death in a pit the company had unlawfully dug. The cow wandered off in search of companionship. Scientists later found her radio collar, but her fate remains a mystery. Less mysterious is the fate of the Burnt Pine herd: It’s extinct.

Today British Columbia continues to allow open-pit coal mines and fracking wells in caribou habitat, and it is building yet another hydroelectric dam on the Peace River, just south of the oil-and-gas boomtown of Fort St. John. Most of the electricity the dam produces will be exported to the United States, and it has been sharply criticized by local and national activists.

At the visitor center next to the W. A. C. Bennett Dam, there is a monument to the reservoir’s impacts on First Nations. Walls are lined with personal accounts of loss, including Willson’s own. He tells of his grandmother catching fish, collecting wild plants, and passing the knowledge along to his mother. “Nowadays,” reads his statement on the wall, “what I get to do is teach my son how to throw contaminated fish back into the river.” (Fish in Williston Lake are contaminated with methylmercury from the decomposing forests beneath the surface.)

When the First Nations Impact Gallery opened two years ago, an official from BC Hydro, the dam’s operator, publicly acknowledged the harm done to both indigenous people and the environment. He pledged that the company would “not repeat the mistakes of the past.” Yet the new dam, known as Site C, would submerge both historic and contemporary tribal sites, and BC Hydro is already clearing forest and moving earth in preparation for construction. The week after I met Willson, he headed to court to testify in one final attempt to stop the project.

After the debacle with the Burnt Pine herd in 2008, Willson called McNay. “We were not going to run around the rose bush with the province,” Willson says. Across the country, many First Nations communities have reached a similar inflection point; unwilling to sit by as provincial governments allow territorial lands to fall to development and climate change, they are launching their own land-management plans—and beginning to set the agenda for conservation in Canada.

McNay, who has worked on caribou issues for both government and industry, was by then as fed up as Willson. “I’ve been involved in three different major pushes the province has initiated for caribou recovery,” McNay says. “They’ve all been about planning and research and collecting more data, instead of getting on the ground and doing stuff.” He told Willson: “I’m not going to work with you unless we do something action-oriented.”

Willson was thrilled. West Moberly joined forces with the neighboring Saulteau First Nations and formed a nonprofit caribou-conservation society. With McNay’s guidance, it hammered out a plan for the seven remaining nearby herds. But when McNay delved into the population data, he discovered that the Klinse-Za herd had already crashed. “We thought we were around 90 caribou there, but we were down below 20,” Willson recalls. “Something had to be done almost immediately in order to save that herd.”

Maternity pens had been tried in a handful of other areas, to varying degrees of success. But McNay believed a pen was the only way to give the herd a chance at survival. He says the First Nations communities mostly embraced the plan, viewing it as an unfortunate short-term necessity. (Other communities have been less receptive, put off by the severity of the meddling. McNay gave a presentation to one Alberta First Nations that was, he says, “appalled at what we were doing.”)

“Caribou were always an animal that if we ever needed something, we could go to them and they would help,” Willson says of West Moberly. “Now the caribou are in a struggle, and they need us. We have to at least try.”

British Columbia declined to fund the maternal pen, so the group sought money from industry and launched a crowdfunding campaign. It raised around $300,000 (almost entirely from industry; crowdfunding only scared up around $1,000), and during the first year in 2014 the group captured 10 females, each of which gave birth in an enclosure 30 miles from the town of Chetwynd. Nine calves survived and were released, yet only four were alive a year later. Two calves born outside the enclosure also survived that year.

In addition to the maternity pen, the program includes a substantial wolf cull and habitat restoration. The first restoration project decommissioned and reseeded a four-and-a-half-mile stretch of road through the forest. “Not even a month later, somebody went in behind us and reopened the road,” Willson told me. “They ruined everything we were doing there.”

In the six years since they began McNay’s program, indigenous trappers have killed 139 wolves on the ground. Over the past four years, the province has killed another 173 wolves by shooting them from helicopters. That’s an awfully bloody short-term fix—and the cull is growing contentious. Two conservation groups have petitioned the government to stop using tax dollars to slaughter wolves, which they call “inhumane” and “a morally bankrupt display.”

As of last year, the Klinse-Za caribou herd had grown to 66 animals.

Inside the maternity pen’s perimeter, behind the tall walls and an elaborate electric fence, McNay, Giguere, and I hiked to a rustic wooden observation platform built into a tree. Below us stretched a meadow, where several red metal troughs were filled with pellets made from vitamin-and-mineral-enriched barley, wheat, and corn, a supplemental diet for the caribou. (The fenced-in forest is too small to provide enough food for the animals.)

First Nations members patrol the pen in week-long shifts, bunking in a plywood shack they built outside the fence. These “guardians” walk the perimeter a few times a day, look for compromises in the fence line, keep watch for predators, and feed the caribou. In addition to the pellets, they feed the animals lichens, which are harvested by locals—including schoolkids and tribal elders—and hauled up the road in big mesh sacks.

As we stood on the platform and watched the far end of the meadow, where Battleship Mountain towered above the pine and spruce, two caribou slowly appeared like apparitions at the forest edge. Their fur was mottled in shades of gray and brown, and they sauntered through the field under bands of shadows cast by fast-moving clouds. Soon, more caribou joined them, including a few fuzzy calves, some of which lay down in the grass while their mothers browsed. The calves looked surprisingly small and fragile, considering they were just a couple of weeks from release. The scene—moms, babies, sun-dappled meadow—looked so peaceful, so primal, that I half-wished the animals could remain here in safety forever, though of course that was absurd.

The guardians had been tracking the whereabouts of four grizzlies they’d seen hanging around not far from the enclosure and which seemed “to have a little more interest in the pen than we’d like them to have,” as McNay put it. If the bears remained nearby, the caribou release might have to be postponed.

For the better part of an hour, we watched the caribou as they lolled about the field. And then, as the wind picked up, they vanished back into the trees.

Outside the enclosure, at the guardians’ hut, Steven Desjarlais had just arrived to join his cousin for a week-long shift. Both men are members of West Moberly, and they had spent months up here—building the pen, maintaining it, watching over the caribou, living in the forest. They lamented the looming end of the job, and said they would soon have to find new work, possibly on logging crews. Desjarlais said he saw the caribou as key to protecting the whole landscape; if the caribou die out, there’s no hope for saving the boreal forest. “Without them here, industry would run wild, and you’d never get them back,” he said. “The province would never put them back. They’d just build roads all over, go nuts.”

Under SARA, if provinces aren’t acting, the federal government can step in. That’s beginning to happen. Last May, Prime Minister Justin Trudeau’s government declared an “imminent threat” to British Columbia’s caribou. Now, if the province doesn’t act, Ottawa can take control of its natural resources—making decisions about things such as logging and mining permits.

News of the possible federal intervention set off a panic, as British Columbians worried about economic calamity. Even in the outdoor-recreation mecca of Revelstoke, where you might expect sympathies to lie with the caribou, city leaders warned of financial doom. Protecting caribou habitat, they said, would spell ruin for the town’s heli-skiing businesses and destroy its backcountry-tourism economy, in addition to killing the local forestry industry. Instead of limiting human activity in caribou habitat, they suggested more research.

This kind of response drives McNay bonkers. There’s nothing more to research, he says. It’s time—past time—to act. He shook his head as he described the province’s decision last spring to spend the equivalent of 20 million U.S. dollars over five years to jump-start a new caribou-conservation effort. If you divide the money by the number of herds in trouble, and divide that by five years, you end up with less than $150,000 for each herd a year—a number, he said, that is essentially useless.

“If we want to do a serious job here,” McNay said, “it’s going to [have an] impact—socially, economically. The local-level municipal governments are pretty scared.”

As with so many at-risk species, the real obstacle for caribou-conservation efforts is socioeconomic. Recovering caribou broadly, across Canada, would require severely curtailing industrial activity across their habitat. Research has shown that woodland caribou avoid areas within 500 meters of human development—which means that the impact of, say, an oil well is far greater than just its footprint on the soil.

The energy sector accounts for a quarter of Alberta’s economy and about 13 percent of Canada’s total GDP. (Three-quarters of Alberta’s oil goes to the United States.) And Canada contains a tenth of the world’s proven oil reserves.

Which is the main reason no one has been willing to do the one thing that matters: protect the boreal forest from development.

“You could go across the boreal and see the exact same story playing out,” says Tim Burkhart, the Peace River coordinator for the Yellowstone to Yukon Conservation Initiative. “The response of government has been to try to save as many caribou as they can without impacting industry in any way.”

Over a seven-year period, in the nearly ruined range of a single caribou herd, Alberta killed 841 wolves. Yet during that same time, the province issued hundreds of permits for new oil-and-gas wells in the same area. Restoring caribou habitat in that area would require buying the energy leases from the companies that hold them. But purchasing those leases on the range of just one herd in Alberta’s oil-sands region would cost 33 billion U.S. dollars, according to a 2010 estimate. Mark Hebblewhite, an ungulate ecologist at the University of Montana, has calculated that “effective habitat protection” in Alberta alone would cost more than $112 billion.

Against this economic reality, trying to save Canada’s woodland caribou can seem like a lost cause. “Piecemeal solutions aren’t going to get to that broader threat of their habitat disappearing,” says Courtenay Lewis, the manager of ecosystems policy for the Natural Resources Defense Council’s Canada Project.

It’s why Hebblewhite, who is Canadian, suggested last year that triage may be the only option—choosing some herds to protect, and letting others simply die off. “Pretending we can continue to conserve everything, and asking wolves to pay the price while energy development continues, is not only ethically and morally wrong, it is extremely poor conservation policy,” Hebblewhite wrote in a paper published last year.

It’s something British Columbia is discussing, especially as climate change presents yet another threat to the southerly herds. “We know we are going to have to make some of these tough calls,” says Chris Ritchie, the acting executive director of the Species at Risk recovery branch of the provincial agency in charge of forests and natural resources.

Meanwhile, though, the federal government’s imminent-threat order has required the province to negotiate a caribou-conservation plan in partnership with both Canada and the West Moberly and Salteau First Nations. The draft agreement, whose finalized details have not yet been released, proposes to set aside nearly 1 million acres in the South Peace region—more than 1,540 square miles—for caribou, closing much of it to logging, hunting, and snowmobiling. Some land might be set aside as provincial parks with no industrial activity permitted; other areas might allow some logging or mining but under “a more caribou-centric management regime,” Ritchie says.

As the outline of the agreement leaked, anger in the region grew. A petition on Change.org by a snowmobiler-backed group called Concerned Citizens for Caribou Recovery bears the headline “Your back country access is being seriously threatened right now” and warned that “our way of life in Northern BC is at risk.” It demands that “all negotiations halt immediately.” In less than a week, more than 13,500 people signed the petition—though it’s unclear how many of them are locals. The group appears, from its Facebook page, to be connected to the outdoor-recreation industry.

McNay says he’s beginning to see pushback from all sides. Snowmobilers are livid about potential trail closures. He’s gotten hate mail from environmentalists furious about the wolf killings. And he fears the opposition will only increase, given the economic turmoil that could follow large-scale conservation measures. How many sawmills will have to shut down? How many jobs will be lost? “It will come. I see the edge of it already,” Mcnay says. “Because we are talking massive, massive impacts. I really don’t know where it’s all going.”

Back in the Ford Super Duty headed down the logging road toward Hudson’s Hope, I asked what would qualify as successful recovery for the Klinse-Za herd. The federal recovery plan sets a threshold of 120 animals in a herd, but McNay says that number doesn’t mean much. For First Nations, recovery means a self-sustaining population that members can hunt on a limited basis. Right now, the Klinse-Za herd is growing by about 15 percent a year. At that rate, in another decade there would be maybe 350 animals, and the local First Nations communities could potentially harvest a few caribou a year. “Back of the envelope, I’m saying in 10 years we might be looking at something that you could kinda say is on its way,” McNay says. But that, he stressed, is just the beginning of real recovery. “I don’t want people to get the impression that in 10 years we’ll be able to take a few animals and then we’re done.”

A couple of weeks after my visit—right on schedule, with no other humans around—the caribou guardians opened a portion of the fence. Over the next few hours, the caribou ventured out, wandering uphill, into the alpine. In the four months since, one cow has been killed by a grizzly, probably while defending her calf, which survived. The rest of the caribou are still alive.

Life Up Close is a project of The Atlantic, supported by the HHMI Department of Science Education.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?



During the last centuries of China’s Shang dynasty, which lasted from 1600 B.C. to 1050 B.C., ritual sacrifice was a well-oiled cultural phenomenon, rich and varied in its manifestations. Rulers and elites sacrificed animals and humans to appease spirits or the ancestors. Just as humans met their ends, dogs were often right beside them.

Now a study in Archaeological Research in Asia, published in March, shows that people from the Shang dynasty relied heavily on sacrificial puppies to accompany them in death. “Although superficially it seems like a horrific thing to kill a puppy and put it into a tomb, it’s actually a window into the complex world of Shang human-animal relations,” says Roderick Campbell, an archaeologist at New York University and one of the co-authors of the study.

Researchers have long known that people in the Shang dynasty sacrificed and buried canines alongside the elite. The assumption has been that these dogs were pets, ritually sacrificed after their owners’ death so that the canines would spiritually accompany them into the afterlife. But Campbell and his co-author Zhipeng Li, an associate professor at the Institute of Archaeology at the Chinese Academy of Social Sciences in Beijing, say that this explanation doesn’t fit their findings.

The team examined Chinese archaeological site reports and about 2,000 Shang-era graves at a site called Xiaomintun under the modern city of Anyang, China. The researchers discovered that the buried canines were predominantly juveniles. About a third of the graves contained a dead dog in a small pit dug under the coffin.

The puppies’ remains didn’t show any clear sign of how they died; someone likely drowned or suffocated the animal, or slit its throat (soft-tissue damage doesn’t leave many long-term traces). Furthermore, many of the people buried appeared to be middle-class rather than elite based on the quality and quantity of goods they were buried with. Campbell says that the sacrificial puppies could have come from the Shang-era equivalent of puppy mills or from litters around the city, as strays or pets.

The reasons for the use of puppies as opposed to adult dogs aren’t yet clear, but Campbell places it within a larger tradition of miniaturization in grave offerings. Items such as ceramics left with the dead became progressively smaller on average throughout the Shang dynasty, until they were little more than doll-sized cups. The change made offerings more affordable. Seen in this light, puppies might have been the cheaper alternative to dogs.

“If you let dogs grow up, you have to take care of them,” says Angela Perri, a postdoctoral researcher in archaeology at Durham University in the U.K. who studies dog burials but was not involved in the Shang-dynasty study. People therefore might have been less attached to puppies, an idea that counters the notion that they were burying pets with their masters. And Perri notes that puppies might have had a symbolic significance, representing youthful innocence.

In addition to studying the graves and site reports, Campbell analyzed the inscriptions on engraved ox-shoulder bones and turtle-shell pieces, called “oracle bones,” used in divination during the Shang dynasty. The bones reveal that elite members of society likely sacrificed dogs in fire rituals—sometimes in the hundreds—to ancestors or to spirits representing weather or the cardinal directions. Due to the nature of their fiery demise, archaeologists haven’t discovered any of these canine remains yet.

Zhichun Jing, an archaeology professor at the University of British Columbia who studies the Shang dynasty but was not involved in this research, says that the zooarchaeological work on the dog remains from Xiaomintun “is indeed very exciting and revealing.” He believes the work could encourage a better understanding of the reasons behind ritual sacrifice.

Many other societies sacrificed dogs at various periods of their history. For example, the Hittites ritually sacrificed puppies and not adult dogs; in one case discovered by archaeologists, they decapitated the puppy and placed its head between its hind legs.

But the new findings also enrich our understanding of sacrifice in the Shang dynasty. “This is a society that has human sacrifice as well as various kinds of animal sacrifice, so the idea of giving a life in ritual is a very familiar one for them,” Campbell says. One king, he notes, Wu Ding, who ruled from 1324 B.C. to 1266 B.C., may have sacrificed as many as 15,000 humans, as well as a number of livestock and dogs—an act that Campbell believes was intended to augment the ruler’s stature as an intermediary between the living and the dead.

This post appears courtesy of  Sapiens.





Subscribe to Radio Atlantic: Apple Podcasts | Spotify | Stitcher | Google Play

A Chinese researcher recently announced the birth of the first genetically edited babies. The claims remain unverified, but the news shocked and dismayed scientists around the world, touching off a scandal that has only grown.

Atlantic staff writers Ed Yong and Sarah Zhang often write about the revolutionary technology the researcher used: CRISPR. Speaking with Matt Thompson on this week’s Radio Atlantic, Ed and Sarah describe some of its incredible applications. From curing diseases to creating new crops of food, the possibilities seem limitless.

CRISPR is also deceptively easy to use though, which is why a researcher working in secret was allegedly able to use it to create human embryos without anyone knowing.

Listen in to learn why scientists were so aghast to hear the news, why another genetics scandal from the 1990s helps explain this moment, and why the designer babies and Dr. Moreau hybrids people often fret over with gene-editing might not be what we should be worrying about.





Ed wrote about the CRISPR baby scandal breaking and getting worse by the day.

Sarah interviewed a CRISPR pioneer and spoke with Chinese scientists outraged by reports of gene-edited babies.



The cover illustration of The New Yorker’s March 29, 1976, issue depicted a “view of the world from 9th Avenue,” starring a massive Manhattan that dwarfed not only other U.S. cities but entire countries, reducing the Pacific Ocean to a band of water not much wider across than the Hudson River.

But New Yorkers aren’t the only ones with a skewed perception of scale or an idiosyncratic sense of geography and place. Humans and other animals behave in ways that suggest they’re mapping out their view of the world by emphasizing the information they find valuable.

Two studies appearing in Science last week show how deep that bias runs. Both research teams observed how the neurons that compile mental maps of physical space reprogram themselves to better reflect our experiences, activities, and priorities. The findings also offer evidence for a link that other scientists have started to uncover: The brain’s way of encoding positional information might extend to the way it organizes volumes of other information to be navigated, including varieties of sounds and abstract concepts such as social hierarchy.

To help mammals keep track of where they are within their physical surroundings, their brains have developed two types of specialized cells. Place cells in the hippocampus fire when an animal is in a particular location—for example, near a recognizable landmark. Grid cells in the entorhinal cortex, a region that abuts the hippocampus, fire when the animal passes through some set of positions arranged like the vertices of a hexagon; collectively, these hexagons overlap to tile over a terrain, like a grid (hence the neurons’ name).

Both kinds of cells “remap” when an animal enters a new environment, and the place cells were known to remap when key features in an environment changed. But grid cells were supposed to be more consistent: Their striking mathematical organization was widely believed to generate a precise coordinate system that didn’t vary over time or with new circumstances. It seemed to provide a static metric of Euclidean space that could be useful for navigation even in the absence of external cues. When the scientists who discovered the neurons were awarded the Nobel Prize in 2014, the grid cells were popularly described as “the brain’s inner GPS.”

Typically, experiments designed to study grid-cell activity involve an animal foraging randomly in a box or a similar artificial environment. But Lisa Giocomo, a neurobiologist at Stanford University, was curious about whether something different might happen in the wild, where animals search for food more strategically, with specific goals and motivations in mind. There, for instance, they might use information from previous experiences to guide their search. Could these factors influence that “GPS” signal in the entorhinal cortex and connect it to something more than position alone?

The findings that Giocomo and her colleagues have now reported in Science point to exactly that conclusion: Having a goal seems to affect how the brain encodes its spatial environment, and possibly much more.

Giocomo’s team recorded the neuronal activity in the entorhinal cortex of rats as they ran through a testing environment, searching for randomly placed food. Then the team ran the experiment again—but only after training the rats to sometimes associate a particular spot in the environment with a large food reward.

That training seemingly altered the firing pattern of the rats’ grid cells: The neurons fired closer to the reward location, shrinking the spacing of the navigational grid around that position like water swirling down a drain. The overall orientation, or tilt, of the grid also rotated, as if responding to an entirely different spatial context. (Other types of cells in the same brain region, such as “head direction” cells that fire in response to where the rat is facing, also rotated.)

“All those changes combined really indicate that the entorhinal cortex is generating a completely different map of this space,” Giocomo says. “The goal of the behavioral task, or potentially the behavioral state of the animal, really is enough to drive a completely new map of the same spatial location.”

Moreover, the team found that the grid cells fired more often when the animal was near the reward location. It seemed that the entorhinal cortex was representing that one small sliver of space more faithfully, more precisely, than the rest of the area—presumably to make finding future rewards more efficient. “The rat could then possibly navigate to that location a little bit more easily by changing its representation,” says Manu Madhav, a postdoctoral fellow at Johns Hopkins University who was not involved with the study.

Meanwhile, across the ocean at the Institute of Science and Technology Austria, the lab group of the neuroscientist Jozsef Csicsvari took a deeper look at this change in representation as it happened. The scientists trained rats on a platform with holes into which rewards could be placed. First the rats foraged on a board without any rewards; then they were trained to find three rewards in specific locations; finally, they were sent off again on a board with no rewards.

Like Giocomo’s group, Csicsvari’s found that the reward-training experience deformed the rats’ grid maps. The grid cells had shifted their firing targets to positions closer to where the rewards had been—and the closer their targets had initially been to the rewarded spots, the more they had moved. The perfect hexagonal tiling array described by the discoverers of grid cells didn’t look so perfect anymore.

Furthermore, when the rats were first learning about the presence of new rewards in their environment, Csicsvari’s team observed a “flickering” transition between the two map representations—as if the rats’ brains were bouncing back and forth between the maps until they became accustomed to the presence of the rewards, rather than simply transforming steadily from one grid to the other.

It all suggests “that actual grid cells are supporting much more than only Euclidean space. They’re supporting information about goals, for one,” says Charlotte Boccara of the University of Oslo, who was a postdoctoral fellow in Csicsvari’s lab during the study. “And that brings us to: What are grid cells?”

Rather than organizing space, “they really seem to be about the organization of memory.”

Imagine, Giocomo says, that during the winter, a mouse has to forage for whatever nuts and berries it can find. It has a cognitive map of the parts of the forest where it might find some. Then, one summer, the mouse stumbles across a huge patch of strawberries. “It could be advantageous for it to have a completely different map ... that highlights or overrepresents that patch of strawberries,” Giocomo says.

Or just think about how we remember places in our own lives: We know, for instance, exactly where to find our home and workplace, but not the precise locations of every store, park, and road we pass daily between the two. “An organism has a sense of what things matter or don’t, and that overlays its sense of where things are in the world,” says Loren Frank, a neuroscientist at the University of California at San Francisco, who did not participate in either study. It’s been a misunderstanding to think that the brain has a representation of space that is “pure” and uncontaminated by considerations of relevance or reward, he added. “These things are really intimately tied together” and can’t be so neatly divorced.

This also implies that how we form memories—and which memories we form—depends on what we’re trying to do. Not all memories, locations, and experiences are created equal (or at least they’re not encoded that way).

Therein lies the flaw in comparing the entorhinal map to a GPS or other navigational tool. “Google doesn’t pull up a different map for me if I’m headed to Starbucks, versus if I’m going out for a walk,” Giocomo says.

She wants to investigate what happens in the presence of punishments instead of rewards, and what happens when the rat’s motivations change—if it’s not hungry during the task, for instance. “This work opens up a whole new territory, in terms of considering what cues are capable of driving new maps of a space,” she says.

A greater appreciation of the plasticity of the entorhinal cortex could help researchers understand the remapping that happens (or fails to happen) as a result of aging, neurological disease, and drug addiction. It could also reveal a much vaster repertoire of behaviors, beyond simple navigation, that this brain system might be encoding. “The entorhinal cortex is playing a much larger role in the intersection of space and memory than we previously thought,” Giocomo says.

Because spaces are easy to measure, Boccara suggests, identifying the function of grid-cell activity in codifying spatial relationships was relatively straightforward. “But actually, it could be doing much, much more,” she says. The coding properties in the entorhinal cortex change based on what the animal is doing rather than just where it is. Regardless of whether the challenge is to navigate a physical space or a mental “landscape” of abstract thoughts or sensory experiences, “the code seems to alter to fit that space, to make the task in that space easier,” Madhav says.

When it comes to grid cells, then, “our first definition was quite rigid, as first definitions tend to be,” Boccara says. But that viewpoint might have outlived its usefulness. Perhaps it’s finally time to move on.

This post appears courtesy of Quanta Magazine.



When you read through the list of missions humankind has launched into space over the past 60 years, a pattern emerges.

There’s Hubble, the telescope that sighted countless glittering galaxies. Cassini and Galileo, which orbited Saturn and Jupiter, respectively, for years. Kepler, the discoverer of thousands of exoplanets; Herschel, the chronicler of the Milky Way’s star-forming regions; Huygens, the lander that plopped down on a Saturnian moon.

Magellan, Einstein, Newton, Planck, Euclid, Chandrasekhar, Fermi, Van Allen—these missions have provided scientists with heaps of information about the universe. And they are all named for men.

So it was a nice surprise when the European Space Agency recently announced that its next rover mission to Mars, launching in 2020, would bear the name of a woman: Rosalind Franklin, the English chemist whose work led to the discovery of the double-helical structure of DNA in the 1950s.

The news was warmly received. It seemed fitting to name a rover designed to search for evidence of life on one planet after a scientist who studied the molecular basis of life on another. And the choice seemed just—recognition for a brilliant scientist whose contributions were overlooked and uncredited for years. 

Many space missions aren’t named for anyone, actually. Some receive abstract labels intended to capture the grandeur of exploration: Endeavor, New Horizons, Curiosity. Some get inventive descriptions that are easily squished into charming acronyms: Consider JUICE (JUpiter ICy Moons Explorer) and MAVEN (Mars Atmosphere and Volatile EvolutioN. There's even a ground-based mission called—and this is quite the reach—SPECULOOS (Search for habitable Planets EClipsing ULtra-cOOl Stars). Still others bear the names of figures in mythology: Juno, the Roman queen of the gods; Ulysses, the hero of Greek mythology; Chang’e, the Chinese goddess of the moon.

But the missions named for human beings are disproportionately named for men. This isn’t surprising. The namesakes were meant to honor the scientists and researchers who presented new theories and published groundbreaking papers—and for most of human history, these were men. There were certainly women in these fields, but their contributions were likely to be downplayed or forgotten. When the people in charge of naming spacecraft reach into the past for inspiration, the names of men, buoyed for centuries, float to the top.

Most of the missions named for women are close to Earth, in both purpose and physical proximity. Satellogic, an Argentinian company, has launched Earth-observing satellites named after Ada Lovelace, the English mathematician who wrote about computer programming a century before the machines appeared, and Maryam Mirzakhani, an Iranian mathematician who was the only woman ever to win the Fields Medal, the “Nobel Prize of math.” Spire Global, an American company that makes satellites to track weather and ship traffic, names satellites after its employees, some of whom are women. India’s first meteorological satellite, now defunct, was named for Kalpana Chawla, the Indian American astronaut who was killed in the space shuttle Columbia disaster in 2003.

Push deeper into space, beyond the influence of Earth’s gravity, and there’s only one. Sojourner, an old NASA rover, explored the Martian surface for three months in 1997, taking photographs and probing the soil before it stopped communicating with Earth. It was named for Sojourner Truth, the escaped slave who became one of the most prominent civil-rights activists in the United States.

NASA is currently working on a new mission to Jupiter called Lucy, but it’s not named after a human woman. The namesake is an incomplete skeleton of a female Australopithecus afarensis, an extinct hominin.

Franklin and Sojourner both received their names from public campaigns. For Franklin, the European Space Agency solicited and reviewed 36,000 nominations for “creative and bold” names. For Sojourner, scientists and engineers at NASA’s Jet Propulsion Laboratory reviewed 3,500 essays from students who had been asked to select a “heroine” in history and describe her accomplishments.

The finalists were Truth, the chemist Marie Curie, and Judith Resnik, a NASA astronaut who died in the Challenger explosion in 1986. Submissions were scored not only on the quality of the essay, but also on “the appropriateness of the name for a Mars rover.” The Jet Propulsion Laboratory said it chose Sojourner in part because the name means “traveler.” It sounded better than the others.

Such caveats don’t seem to apply to missions named for men. The decisions don’t tend to be crowdsourced either. Take, for example, one of NASA’s most ambitious missions of the 21st century so far, the James Webb Space Telescope. The telescope will become the most powerful in history when it launches in 2021, carrying the name of a former NASA administrator who served during the Mercury and Gemini programs that put men into orbit in the 1960s.

Sean O’Keefe, another former NASA administrator, picked the name in 2002, when the telescope project was in its early stages. O’Keefe says the effort was shaping up to become a massive undertaking that would require a successful leader of the space agency. His predecessor sprang to mind. “He was, in my estimation, the most extraordinary guy to ever serve in that job,” O’Keefe says, adding that he didn’t consider opening up the decision to the public. “There was no established standard at the time [for naming missions], and I don’t know if there is much of one now either.”

Male figures dominated the cosmos long before any spacecraft left Earth, in the names of planets, moons, and constellations of stars. They came from classical myths, which rarely ended well for the women involved. These stories were rippled with misogyny, and so is the night sky, wrote Leila A. McNeill in an Aeon essay in 2016. The constellation Andromeda is in the shape of a woman chained to a rock as punishment from Poseidon. The Pleiades, a cluster of stars in the Taurus constellation, are named for seven sisters who were pursued by Orion the hunter, and the way Orion is mapped onto his constellation, he’s still in pursuit.

The appeal of traditional naming practices persists. NASA is currently developing the Orion capsule, which may someday carry humans to the moon again and beyond. A spacecraft launched in 2011 to orbit Jupiter is called Juno, after the Roman god’s wife.

Perhaps the naming of spacecraft seems like a passing detail in the scheme of things, especially in a cosmic sense. After all, these things eventually run out of fuel. Some of them even crash into planets and disintegrate into nothing. But some will remain in space for hundreds, perhaps thousands, of years. They are built to last, and in turn to outlast. They will become part of humankind’s record as a spacefaring civilization. The late Carl Sagan wrote in 1976 about the historical importance of naming things in the solar system:

Some may think that the naming of the solar system is a pointless, or at least a thankless, task. But some of us are convinced it is important. The place names assigned are likely to apply for a very long time. And our remote descendants will be using our nomenclature for their homes on the broiling surface of Mercury, by the banks of the Martian valleys, on the slopes of Titanion volcanoes, or on the frozen landscape of distant Pluto, where the sun appears as a point of bright light in a sky of unremitting blackness. Their view of us, of what we cherish and hold dear, may be determined largely by how today we name the moons and planets.

His argument concerned the surfaces of other planets, which the Voyager spacecraft were about to reveal in phenomenal detail. But it applies well to the missions themselves too. Already, Apollo and Challenger are part of space history; it’s impossible to tell the story of Charles Darwin without mentioning The Beagle. Without spacecraft to reach faraway places, the hypothetical homes Sagan imagined would not be possible. If and when humanity moves off Earth, the vehicles that take us there will forever be part of our story in space.



In politics, you need a good villain. It is far easier for environmentalists to rail against Donald Trump for weakening the Clean Water Act than it is to rail against Proposed Rule 83 FR 32227. And it was far easier for Democrats to criticize Scott Pruitt—the former Environmental Protection Agency administrator who resigned in June under not so much a cloud of corruption as a thundering cumulonimbus of it—than it has been for them to focus attention on Andrew Wheeler, his quieter and more effective replacement.

In the new year, Ryan Zinke, the secretary of the interior, seemed certain to catapult into that top tier of political nemeses for Democrats. Like Pruitt, Zinke excels at generating bizarre scandals; also like Pruitt, his own heroic vision of himself seems to survive any amount of bad press. House Democrats, salivating over their new oversight power, had already promised to subpoena Zinke over a number of issues, including a sweetheart $300 million contract for electricity in Puerto Rico that he allegedly gave to a small power company based in his home state of Montana.

But Zinke’s star turn is not to be. On Saturday morning, President Trump announced that Zinke will step down at the end of the year. David Bernhardt, the current deputy secretary and a former oil lobbyist, will take over the department.

Little is likely to change under Bernhardt. The Interior Department oversees the nation’s public lands, which encompass nearly a quarter of its total area. This makes the agency a kind of extra-powerful environmental regulator, especially out West, where it owns 47 percent of the territory. The department also includes the National Park Service, the U.S. Fish and Wildlife Service, and the Bureau of Indian Affairs.

Under Zinke, the agency has gone on a spree of deregulation. It has cut more than 1 million acres of wilderness out of Bears Ears National Monument in Utah and with help from Congress, it has opened up 19 million acres in the Alaska National Wildlife Refuge to oil exploration. The agency is also in the process of overhauling the Endangered Species Act, the muscular 1973 law that helped save the bald eagle, the gray wolf, and the American crocodile from extinction.

Many of Zinke’s efforts seemed particularly helpful for fossil-fuel companies, which can lease public land from the government and then sell the oil or coal they find there. Near the end of his term, President Barack Obama blocked the Interior Department from releasing any land for coal mining. Zinke, by contrast, has sped up the process of obtaining these leases for new oil and gas drilling.

Every single one of these initiatives is almost certain to continue under Bernhardt. What will not continue is Zinke’s penchant for publicity. The man embraced his role as the Cabinet’s cowboy. He arrived to his first day at the department on horseback, wearing a Stetson. A former Navy SEAL, he transplanted an arcane military ritual onto his new life as a downtown bureaucrat: Whenever he walked into the Interior Department’s downtown-D.C. headquarters, he ordered his staff to fly a special flag.

In practice, he was less outdoorsman, more hapless dad. He struggled to rig a fishing reel correctly. One of his minor scandals involved “Make America Great Again”–branded socks. Last summer, he reportedly threatened Senator Lisa Murkowski, a Republican of Alaska, over her vote against Obamacare repeal. Then, seemingly after realizing that she is in charge of funding the Interior Department, he promptly backtracked. (Zinke has called the claim that he threatened Murkowski “laughable,” but his threats were first reported by Dan Sullivan, Alaska’s other Republican senator.)

That hubris made him a terrific target for Democrats. They hoped to use his personal misdeeds to point to the larger pattern of deregulation and industry friendliness at his department. Maybe, eventually, some day, when the public hated him enough, they could force him to resign.

Zinke went and resigned for them. “After 30 years of public service, I cannot justify spending thousands of dollars defending myself and my family against false allegations,” he said Saturday.

In resigning, Zinke reveals the power of Democrats’ new ability to oversee the Trump administration. Zinke is the first casualty of the 2018 blue wave: the first Cabinet official who stepped down in the face of subpoenas. He left, in fact, to avoid facing subpoenas. Yet in resigning, he also shows the limits of that same new power. Democrats can no longer use Zinke’s hubris to get people to pay attention to the Trump administration’s larger set of policies at the Interior Department.

Zinke, with all his antics, was set to be the great environmental villain of 2019. Now Democrats will need to find a new one.



If you’re looking for a scenic lakeside destination for your summer vacation, you have two options: Earth, and a moon of Saturn called Titan.

These are the only two places in the solar system with bodies of liquid on the surface. Like Earth, Titan has an atmosphere, weather, and a natural cycle in which drops fall from puffy clouds onto the surface, before evaporating back up to start again. But the “rain” isn’t water; it’s methane, which exists as a liquid on Titan.

Scientists suspected that Titan had lakes years before they sent a spacecraft to check it out. The nature of Titan’s intriguing atmosphere suggested that it might deposit droplets to fill streams, lakes, and entire oceans. When Cassini, the now-defunct NASA spacecraft, arrived at Saturn in 2004, it turned toward Titan, the largest of the planet’s moons. The spacecraft’s radar instrument, permeating the haze, detected a very smooth surface, with narrow shapes at its edges that spread like capillaries from a vein. Another instrument absorbed the little bit of sunlight reflected from this mysterious surface and analyzed it. “It looked exactly like afternoon light reflecting off lake waters on Earth,” according to Amanda Hendrix and Charles Wohlforth, the authors of Beyond Earth: Our Path to a New Home in the Planets.

Like water on Earth, the methane has slowly etched canyons into the landscape and filled them with lakes. Lakes that, perhaps someday, human beings might visit for a little R&R, hundreds of millions of miles away.

It’s unlikely, but summer, arguably the best season for daydreaming, is upon us, so I reached out to a few scientists who study Titan to gauge the moon’s qualifications for a cosmic getaway. Set aside the long and dangerous journey, which would require astronomical leaps in technology if you planned to leave tomorrow. What might it be like to stand on the shores of a Titanian lake and look out across the expanse?

Well, you wouldn’t be able to see much, actually. Our dinky human eyes weren’t made for Titan, which is covered in thick haze, tinted the color of Dijon mustard because of chemical interactions between sunlight and compounds in the moon’s atmosphere. Unlike on Earth, sunlight strains to break through to the surface.

“Our vision is adapted to the situation on Earth—a lot of visible light,” says Daniel Cordier, a scientist at the University of Reims in France. “On Titan, only a tiny fraction of visible light entering the atmosphere reaches the ground.”

To get a better look, vacationers would need high-tech sunglasses designed to see in other forms of light, like infrared. You wouldn’t need to pack sunscreen; the sun appears 10 times smaller on Titan than it does here on Earth.

You wouldn’t need a spacesuit either, which sounds inconceivable, considering that every person who has ever left the comfort of Earth’s atmosphere has had to wear protective material to prevent a swift death. But air on Titan is dense enough to allow people to walk around without pressurized spacesuits, free from bulky, constricting garments and the danger of their bodily fluids boiling. By this measure, Titan isn’t as inhospitable as other worlds in the solar system, like our own moon or Mars.

No stepping outside without an oxygen mask, though: Titan’s atmosphere is made of about 95 percent nitrogen. You’d also need the right clothes to contend with the temperature. This moon’s fleece of an atmosphere keeps the surface temperature about the same day after day, changing only by a degree or two. This might sound pleasant, but that temperature is about –292 degrees Fahrenheit (–180 degrees Celsius). Visitors would need garments layered with insulation or designed to generate heat for its wearers.

Let’s say you’ve chosen a Titan lake called Ligeia Mare as your holiday spot. Ligeia Mare is about the combined size of two Great Lakes, Huron and Michigan, but looks nothing like them. The surface is smooth, nearly textureless. There are no big waves, no whitecaps at their shifting peaks. When Cyril Grima, a scientist at the University of Texas, imagines himself there, he looks down at his feet and spots a block of ice the size of his fist. He thinks about throwing it out into the lake; at these temperatures, water on Titan exists only as ice and litters the surface like rocks. But he wouldn’t want to disturb the eerie tranquility of the alien lake. “You don’t want to break this quiet liquid body, as peaceful as pristine snow before being lacerated by footprints,” Grima says.

Scientists are still trying to explain the uncanny smoothness of Titan lakes. The Huygens probe, a little spacecraft Cassini dropped on the moon in 2005, was designed to float and measure the size of waves in the predicted bodies of water. But Huygens landed on solid ground and exhausted its batteries in less than three hours. The probe’s cameras captured and sent home mesmerizing photos of the terrain, including gullies, winding ravines chiseled into the landscape by flowing liquid. What scientists know about Titan’s liquid features, they glean from data collected by Cassini, which ended its mission in 2017, and telescopes here on the ground or in orbit around Earth.

According to Cassini data, most waves reach only about a centimeter in height, a fraction of an inch. This seemed unusual to scientists, who had seen, in other data, plenty of evidence of wind, including dunes. Gusts generate some patches of ripples, particularly in the spring and summer seasons, but no undulating patterns, like that of terrestrial lakes. Cordier suspects that something on the surface of the lakes is dampening potential ripples. One potential culprit, he says, are organic particles formed in the atmosphere that float down to the surface. The particles, known as aerosols, might not like mixing with water, and so they settle over the lakes like oil. They might also be less dense than liquid methane, so they simply float on top in a layer, muffling the waves.

Swimming is probably out of the question, not without the right, technologically advanced attire. If you made it in, the act would feel unnatural and difficult. Liquid methane is about half as dense as water, which means swimmers would have to exert more effort to keep themselves from sinking.

And watch out for bubbles rising from below. Titan’s lakes are made of a swirling mixture of methane, ethane, and small amounts of nitrogen. The methane-rich liquid at the surface flows downward into the depths, toward ethane-rich liquids. The movement jostles nitrogen, and it ascends to the surface and fizzes. “Methane and nitrogen mix better than ethane and nitrogen, so once you get rid of some of the methane, nitrogen is like, ‘Meh, I’d rather not stick around with you, ethane. I’m going to peace out and go back to the atmosphere,’” says Shannon MacKenzie, a planetary scientist at Johns Hopkins Applied Physics Laboratory.

In the midst of all that nitrogen fizz, keep an eye out for something even more startling: life. No life-forms have been detected on Titan, but scientists say the moon might provide the conditions for it. Telescope observations have detected a compound coursing through the atmosphere that could interact with the methane and ethane to create cell-like membranes.

Getting around on foot would be far easier than on Earth. Titan has even less gravity than our own moon. Vacationers could bounce around as the Apollo astronauts once did, decades ago. They could even, as Hendrix and Wohlforth suggest in their book, flap around in winged suits to “effortlessly glide great distances.” Falling would not be perilous; objects take longer to descend in such a thick atmosphere. (Scientists with multimedia skills: Please simulate someone executing a perfect cannonball off a diving board and into Ligeia Mare.)

The appeal of a lake vacation is not just the water itself. These spots are usually low on light pollution, providing more unfiltered views of the night sky. But under Titan’s opaque skies, the stars and other planets wouldn’t be visible. Neither would the sight that might draw tourists to the moon, which has dazzled humans from afar for centuries: Saturn’s rings. For starry views, it might be best to stay on Earth.



In 1959, an American physician named Harry Eagle mixed up one of the most pivotal cocktails in medical history—a red blend of sugar, salts, vitamins, and amino acids that allowed scientists to efficiently grow the cells of humans and other animals in laboratory beakers. This red elixir, known as Eagle’s minimal essential medium (EMEM), became a bedrock of biological research. Sixty years later, the medium and its variants are still heavily used whenever researchers want to study animal cells, whether to investigate the viruses that infect us, or to work out what goes wrong when cells turn cancerous.

As its name suggests, EMEM was designed to be as simple as possible—it has everything a cell needs to grow and nothing more. And in recent years, scientists have started realizing that such pared-down concoctions might be skewing their results, by warping the ways in which cells process nutrients. It’s as if they had spent decades studying the health of people who had only ever been given rations to eat.

Instead of using generic “culture media” like EMEM (or its more concentrated variant, Dulbecco’s Modified Eagle’s Medium, known as DMEM), it might be better to start creating concoctions that more accurately reflect the chemical profiles of our bodies. That’s what Saverio Tardito did in 2012, when he joined the Cancer Research UK Beatson Institute in Glasgow. “Around 90 percent of the papers in cancer research are using the same two or three commercially available media,” he says. “We researchers are aware that the medium you choose at the beginning of the experiment will affect the output, but it’s too easy to open the door of the fridge and use what’s there. I think we have been all been a bit too lazy.”

Over several years, he fine-tuned a mixture called Plasmax, which contains around 60 nutrients and chemicals at the concentrations usually found in human blood. “It was a side project—just a way of obtaining a better tool to do better research,” Tardito says. “But from the beginning, we noticed that the medium was making a difference.”

His colleague Johan Vande Voorde realized that cancer cells, when grown in Plasmax, behave more like they would in actual tumors, without several weird behaviors that are triggered by commercially available media. For example, DMEM contains a substance called pyruvate at 10 times its normal concentration in blood. These abnormal levels force cancer cells to grow as if they were starved of oxygen, even when the gas is abundantly present. In DMEM, the cells act as if they were being choked. In Plasmax, they do not.

Unlike DMEM, Plasmax also contains selenium, an essential mineral. By comparing the two media, Vande Voorde showed that when breast cancer cells are grown at low densities, they die in the absence of selenium, but flourish in its presence. That’s a little worrying. Several researchers have tested selenium supplements as a way of preventing cancer, but despite many studies there’s no strong evidence for a protective effect. Instead, Tardito wonders if such supplements could be risky: If selenium allows cancer cells to survive in sparse populations, it might make it easier for fragments of tumors to spread to other parts of the body. “We’ll need to follow that up in animal studies,” he says.

David Sabatini of the Whitehead Institute for Biomedical Research has also been mixing up his own culture medium that mimics the nutrient levels of human blood. In 2017, he showed that cancer cells grown in this mixture are much less sensitive to a chemotherapy drug called Adrucil.

These results come at an interesting time. In recent years, cancer biologists have been grappling with a possible reproducibility crisis, in which results from several experiments involving lab-grown cells can’t be repeated by other teams. More broadly, researchers have struggled to translate the results of basic experiments involving such cells into new treatments that actually help cancer patients. Although there are many possible reasons for these problems, Tardito wonders whether he and his colleagues might get better results if they grow their cells in more realistic media.

“Could these new media uncover vulnerabilities of cancer cells more robustly than before?” adds Chi Van Dang of the Wistar Institute, who also wants to know how immune cells might react under these more physiological conditions. “Could these media help us to understand immunotherapy better?”

“These studies are absolutely a step in the right direction,” says Gina DeNicola of the Moffitt Cancer Center. “For this approach to be applied more broadly, these types of media will need to be commercialized. While it’s possible to make these media in a lab, it’s very costly and time-consuming. Commercial media preparations are also more consistent and higher quality, which will help with reproducibility between labs.” (Indeed, that’s partly why researchers have been so slow to move beyond traditional media like DMEM.)

Commercial preparations would also help Sabatini and Tardito, whose teams have been laboriously making up stocks of their own artisanal media and shipping them to collaborators around the world. “I struggle to keep up with the requests,” Tardito says. Sabatini adds, “We are working with vendors, but it is not easy, as physiological media is more expensive and is likely to have a shorter half-life.”

For researchers looking to understand how cancers gobble up nutrients, “testing one’s finding in a medium such as Plasmax would, without any doubt, add unparalleled rigor, and hopefully become a more widespread practice,” says Natasha Pavlova of the Memorial Sloan Kettering Cancer Center.

But she notes that such media aren’t perfect. They’re still largely missing many important components of blood, including fats and proteins. They don’t capture the different chemical profiles that exist in other tissues and organs. They don’t reflect the chemical wastelands that exist at the heart of tumors, which grow so quickly that their blood supplies can’t provide them with enough nutrients. Just last month, Alexander Muir of the University of Chicago showed that the fluids inside a tumor, which circulate between its cancerous cells, contain different levels of nutrients to those in blood.

Perhaps most important, Pavlova says, many cancer researchers rely on lineages of tumor cells that were created decades ago. These lines have been grown in conventional media like DMEM ever since, and have likely adapted accordingly. If they were now dunked in Plasmax, would that get researchers closer to real-life biology, or further away?  Would researchers have to create entirely new cell lines that are grown in Plasmax from the start?

Tardito acknowledges these issues. “There will never be a perfect medium that mimics the tumor environment beginning to end,” he says. “All we can do is try and minimize those imperfections as much as we can.”



The brain, supposedly, cannot long survive without blood. Within seconds, oxygen supplies deplete, electrical activity fades, and unconsciousness sets in. If blood flow is not restored, within minutes, neurons start to die in a rapid, irreversible, and ultimately fatal wave.

But maybe not? According to a team of scientists led by Nenad Sestan at Yale School of Medicine, this process might play out over a much longer time frame, and perhaps isn’t as inevitable or irreparable as commonly believed. Sestan and his colleagues showed this in dramatic fashion—by preserving and restoring signs of activity in the isolated brains of pigs that had been decapitated four hours earlier.

The team sourced 32 pig brains from a slaughterhouse, placed them in spherical chambers, and infused them with nutrients and protective chemicals, using pumps that mimicked the beats of a heart. This system, dubbed BrainEx, preserved the overall architecture of the brains, preventing them from degrading. It restored flow in their blood vessels, which once again became sensitive to dilating drugs. It stopped many neurons and other cells from dying, and reinstated their ability to consume sugar and oxygen. Some of these rescued neurons even started to fire. “Everything was surprising,” says Zvonimir Vrselja, who performed most of the experiments along with Stefano Daniele.

There have long been signs that oxygen deprivation doesn’t necessarily kill neurons as quickly as is often assumed. Still, Jimo Borjigin of the University of Michigan says that when she started studying brain activity in dying rats, “my colleagues told me that as soon as oxygen isn’t there, every cell dies within minutes.” Sestan’s team “showed that cells are still intact not just a few minutes later, but a few hours later. This kind of study is long overdue.”

Disembodied brains in jars are a familiar and disquieting science-fiction staple, but in those stories, the brains are alive, conscious, and self-aware. Those in Sestan’s experiments were zero for three. Though individual neurons could fire, there were no signs of the coordinated, brainwide electrical activity that indicates perception, sentience, consciousness, or even life. The team had anesthetics on standby in case any such flickers materialized—and none did. “The pigs were brain-dead when their brains came in the door, and by the end of the experiment, they were still brain-dead,” says Stephen Latham, a Yale University ethicist who advised the team.

For that reason, “I don’t see anything in this report that should undermine confidence in brain death as a criterion of death,” says Winston Chiong, a neurologist at the University of California at San Francisco. The matter of when to declare someone dead has become more controversial since doctors began relying more heavily on neurological signs, starting around 1968, when the criteria for “brain death” were defined. But that diagnosis typically hinges on the loss of brainwide activity—a line that, at least for now, is still final and irreversible. After MIT Technology Review broke the news of Sestan’s work a year ago, he started receiving emails from people asking whether he could restore brain function to their loved ones. He very much cannot. BrainEx isn’t a resurrection chamber.

“It’s not going to result in human brain transplants,” adds Karen Rommelfanger, who directs Emory University’s neuroethics program. “And I don’t think this means that the singularity is coming, or that radical life extension is more possible than before.”

So why do the study? “There’s potential for using this method to develop innovative treatments for patients with strokes or other types of brain injuries, and there’s a real need for those kinds of treatments,” says L. Syd M Johnson, a neuroethicist at Michigan Technological University. The BrainEx method might not be able to fully revive hours-dead brains, but Yama Akbari, a critical-care neurologist at the University of California at Irvine, wonders whether it would be more successful if applied minutes after death. Alternatively, it could help to keep oxygen-starved brains alive and intact while patients wait to be treated. “It’s an important landmark study,” Akbari says.

Such applications are a long way off, and even if they never materialize, “this is already an extraordinary breakthrough,” says Nita Farahany, a bioethicist at Duke University. Although neuroscientists can study lab-grown neurons or peer at thin slices of brain tissue, these capture nothing of the three-dimensional intricacy that makes the brain, the brain. By restoring some activity to postmortem pig brains, Sestan’s team has created a much better proxy for the real thing. The irony, of course, is that “the better the proxy, the sharper the ethical dilemmas,” Farahany says.

Johnson adds that no animals died for the sake of the study: The team used brains from pigs that had been killed for food. “Thousands of sentient animals have been killed in studies searching for neuroprotective treatments that have not borne fruit,” she says. “Meanwhile, millions of animals are killed for food every year, and that’s a potentially rich source of experimental brains that would involve no additional harm.”

The study still needs to be replicated by other independent teams. And before anyone takes the technique further, or even contemplates the possibility of human trials, there are several ethical issues to consider. For example, is the team really sure that the partly revived brains have no consciousness? Latham, the Yale ethicist, feels confident. Even people under anesthesia show signs of coordinated, brainwide electrical activity, he says, so the absence of such signals strongly suggests that “we don’t even have the possibility of consciousness showing up.”

But consciousness is still hard to define, much less measure. And no one has ever had to measure it in a brain that lacks a body. How would you assess awareness, pain, or suffering “in a brain that has restored circulation and neural function, but that’s disconnected from external sensation?” asks Steven Hyman, a neuroscientist at the Broad Institute of Harvard and MIT. “This is a very hard scientific problem and policy issue.” As Johnson says, “I think it’s very unlikely that consciousness or sentience could be restored in a several-hours-dead brain, but I’m also pretty sure that if it was, we wouldn’t know that it was.”

It’s also unclear why the pig brains never regained coordinated activity. Is it because team members waited for four hours? Is it because they only treated the brains for six hours? Was it something about the way the pigs were killed? Or is it because they added chemicals that dampen neural activity to the fluid that they pumped through the brains? (They did this because excessive firing helps to kill neurons in oxygen-starved brains.) And if that’s the case, could isolated brains gain consciousness if the blockers were removed?

Possibly, and that would certainly blur the line between living and dead. But that experiment is emphatically not in the cards. The team’s next and only step is to try BrainEx for longer periods of time. If that leads to signs of coordinated activity, “we’d have to close down the research for a while,” Latham says, “because there’s no institutional body for us to consult. We’d need to create one.” Current regulations on animal research exclude individuals that either were raised for food or have died. Nothing covers the gray area posed by an isolated brain with signs of cellular activity and that may or may not be conscious.

This illustrates a problem that I wrote about last year: Advancements in neuroscience—from preserving postmortem tissue to growing blobs of brain tissue in a dish—are outpacing the ethical frameworks that help us think about such research. Sestan’s team “recognized that they were up against a blurred line, and did everything they could to seek guidance—more than many researchers would have,” Farahany says. “But the truth is that there wasn’t guidance.”

In a commentary that accompanies the new study, she and others suggest several immediate guidelines. Don’t remove the neural-activity blockers until we know what they do. Don’t do similar studies without anesthetics. Prioritize research into ways of detecting neural signals that might indicate sentience or consciousness. Be transparent. With those principles in place, an organization like the National Institutes of Health or the National Academies of Sciences, Engineering, and Medicine should convene groups of scientists and citizens to discuss the ethical boundaries of this research and draw up clear guidelines.  

“First we have to figure out how to do this work ethically in animals,” Farahany says. If one eventually could revive a dead brain to the point of consciousness, “what comes with that, and what doesn’t? Are memories intact? Are self-identities intact? How would we answer those questions if you can’t ask an animal?”

And what might change if researchers move from isolated brains to brains that are still inside the skulls of their owners? Or to human trials? Could that increase the already big shortage of transplantable organs, if the point at which medical interventions are futile becomes blurry? These are all questions for the distant future, but it’s worth having answers before the future becomes the present.



It took $1.1 billion and a 1,000-strong team to prove Einstein right about gravitational waves. In 2016, the scientists behind the Laser Interferometer Gravitational-Wave Observatory, or LIGO, announced that they had finally detected these ripples in the fabric of space and time, formed by colliding black holes. “LIGO was a masterpiece of 21st-century engineering and science,” says James Evans, a sociologist at the University of Chicago who studies the history of science. “But it was perhaps the most conservative experiment in history. It tested a 100-year-old hypothesis.”

“Big science,” of which LIGO is a prime example, is becoming more common. Funding agencies are channeling more money toward ever larger teams working on grand projects such as cataloging the diversity of our cells or sequencing the genomes of all species. There’s even a growing field of meta-research dedicated to studying how teams work—the science of team science.

Some projects require these large teams, and three members of the LIGO team eventually won a Nobel Prize. But the comparative neglect of small teams and solo researchers is a problem, Evans says, because they produce very different kinds of work. He collaborated with his colleague Lingfei Wu to look at more than 65 million scientific papers, patents, and software projects from the past six decades. In every recent decade and in almost every field, Wu’s analysis found, small teams are far more likely to introduce fresh, disruptive ideas that take science and technology in radically new directions.

“Big teams take the current frontier and exploit it,” Evans says. “They wring the towel. They get that last ounce of possibility out of yesterday’s ideas, faster than anyone else. But small teams fuel the future, generating ideas that, if they succeed, will be the source of big-team development.”

That “runs counter to the usual thinking that large teams, which are typically better funded and work on more visible topics, are the ones that push the frontiers of science,” says Staša Milojević, who studies information metrics in science at Indiana University Bloomington. She recently found a similar pattern by analyzing the titles of 20 million scientific papers and showing that bigger teams work on a relatively small slice of topics in a field. Other scientists have made similar points, but what Evans describes as a “Go teams!” attitude still persists. The results of the new analysis should “temper some of that enthusiasm for large teams and demonstrate that there may be a tipping point after which their benefits decline,” says Erin Leahey from the University of Arizona, who has previously written about the “overlooked costs of collaboration.”

The new analysis is based on the ways in which researchers cite past work. For example, when scientists cite Einstein’s groundbreaking 1915 papers on general relativity, they tend not to refer back to the papers that Einstein himself cited. “They see it as a conceptually new direction that’s distinct from the things on which it built,” Evans says. But if scientists “think that something is an incremental improvement, they’ll tell the whole story in the references.” For example, a 1995 paper describing a long-theorized state of matter called a Bose–Einstein condensate is almost always cited together with the papers in which the physicist Satyendra Nath Bose and Einstein predicted the stuff’s existence.

Wu quantified these differences using a “disruption score,” originally created by other researchers to measure the innovativeness of inventions. Wu showed that it works well for scientific research. When ranked by their scores, papers that describe Nobel Prize–winning work appeared in the top 2 percent, as did those chosen by scientists who were asked to name the most disruptive papers in their field. Reviews that summarize earlier work are in the bottom half of the rankings, while the original studies they’re based on appear in the top quarter. It’s a “simple yet brilliant” method, especially because it works across data sources as diverse as papers, patents, and software, says Satyam Mukherjee of the Indian Institutes of Management.

Having tested this score in various ways to show that it’s valid, Wu used it to show that small teams produce markedly more disruptive work than large ones. That’s true even for patents, which are innovative by definition. It’s true for highly cited work and poorly cited work. It’s true in every decade from the 1950s to the 2010s. It’s true in fields ranging from chemistry to social sciences.

So why are small teams more disruptive? It’s possible that they do more theoretical work, while big teams (such as LIGO) are needed to test the resulting theories, but Evans and his colleagues couldn’t find any evidence for this in their data. Another possibility: The most groundbreaking scientists prefer working in small teams. But Evans doesn’t buy that, either. Even when the same people move from small teams to larger ones, he says, they end up doing less disruptive and more incremental science.

Instead, he and his colleagues found that large teams tend to build on recent, prominent work, while small teams delve more deeply into the past, drawing inspiration from older ideas that may have long been ignored. (Evans didn’t use a fixed definition of “small” or “large,” but most of his analyses compared teams ranging from one to 10 people; some scientists might consider a 10-person team to be on the small side.) At first, Evans was surprised by that difference; surely, large teams have more eyeballs and more collective memory? But he now suspects that scientists on large teams also argue and interfere with one another, and that they’re more likely to find common ground in yesterday’s hits. Large teams also require lots of funding, which makes them more pressured to pay the bills and drives them toward safer work. “What does a big movie-production studio bet on: Slumdog Millionaire or Transformers 9?” he asks.

But small teams also pay a heavy cost. Their disruptive work has no ready-made audience, and is less obviously relevant to their peers. As Evans and his colleagues found, such work takes much longer to be recognized and cited. Even if it eventually influences larger teams, as it often does, enough time passes that other researchers are less likely to cite the original, disruptive work.

You Na Lee, who studies scientific innovation at the National University of Singapore, says that research teams are now effectively behaving like firms, which also tend to be more disruptive at a small size. “This study is evidence that the ecology of science and the ecology of innovation are becoming very similar,” she says. The big difference is that the business world actively encourages entrepreneurship and small start-ups. That’s not true for science, but “unconditionally allocating pots of government grants for small wild spirits can be a bold policy move,” she says.

But Evans cautions that money won’t work in isolation. When he and his colleagues analyzed funding trends from 2004 and 2014, they found that when small teams were funded by top government agencies such as the National Science Foundation, they were no more likely to produce disruptive work than large teams. Something about the current funding environment seems to strip small teams of their natural advantages, forcing them to behave like big ones. “It’s not that we can just shove money in their direction,” Evans says.

Still, he argues that agencies must find better ways of encouraging small teams. They don’t just do different kinds of science, but they create work that large teams then build upon. Disenfranchise them, and you destabilize the foundations upon which big science rests. “In 10 years, we’ll be wondering where all the big ideas are,” Evans says. “Some people will wonder if science is slowing down and we’ve eaten all the low-hanging fruit. And the answer will be yes, because we’ve only built engines that do that.”



The ancestral home of the plague, most infamous for causing Europe’s Black Death, has likely always been much farther east, in Central Asia. There, it lives in rodents, such as the marmots that make their burrows in the vast, open grasslands. For thousands of years, the fleas that bite those rodents have also been biting people. There are 5,000-year-old Bronze Age skeletons in the region that contain traces of the bacteria that cause the plague.

And yet, for a few brief decades in the 20th century, the Soviet Union thought it could eradicate the plague. In that era of Five-Year Plans, tens of thousands of people were mobilized to poison rodents, spray DDT, and burn any grass that surviving animals might try to eat. It was a literal scorched-earth campaign. Officially, it “worked.”

The Soviet anti-plague system grew from a network of facilities that began in the czarist era, when the plague was causing many small but not catastrophic outbreaks. (Scientists are still figuring out why the Black Death bacteria were so exceptionally deadly.) Later, the system took on other endemic diseases such as anthrax, and eventually started working on bioweapons. In 2002, biodefense researchers with CNS (the James Martin Center for Nonproliferation Studies) started visiting several outposts still operating as research institutes in the former Soviet republics. That’s when they learned about a series of unofficial books titled Interesting Stories of the Activities and People of the AP System of Russia and the Soviet Union.

“AP” is shorthand for “anti-plague,” and many of the photographs and details about these efforts are only preserved in these 12 volumes. They contain scientific manuscripts, as well as more unexpected historical material: biographies, poems, sketches, lists of scientists purged for political crimes, and a meditation on “Socialism or a Just Society.” The editor, Moisey Iosifovich Levi, was a former anti-plague scientist who began compiling the series after the fall of the Soviet Union. “The idea is to shine light on the activity and people of the AP system,” he wrote in the introduction to the fifth volume, “so that it does not suffer the same fate as legendary Atlantis, which is now known only from the tales of ancient Greek historians.”

Levi died before the last volume was published in 2002, but indeed, these stories have been saved. CNS researchers also translated excerpts into English and donated an original copy in Russian to the Hoover Institute at Stanford. Altogether, the volumes tell a very different tale about the plague in the Soviet Union than what the country was telling the rest of the world.

Eradication began in earnest in the 1930s, as part of Soviet efforts to change the economies of the Northern Caucasus and Central Asia. To eliminate the plague, they decided to eliminate the rodents that act as a natural reservoir for the bacteria. The weapon of choice was grain mixed with poison—zinc phosphide, black cyanide, and barium fluoracetate. “Literally tens of thousands of people were employed to just spoon poison into the burrows,” says Susan D. Jones, a historian of science at the University of Minnesota who recently published about the Soviet anti-plague system in the Proceedings of the National Academy of Sciences. Many of these workers were locals: women, young boys, and the otherwise unemployed. Scientists in Interesting Stories occasionally groused about their unreliability.

In addition to eradicating rodents, the Soviets also tried to eradicate fleas that spread the plague. The workers mixed insecticide with the rodent poison they put in flea-infested burrows. In the years after World War II, says Jones, surplus military trucks and airplanes also sprayed DDT over vast tracts of land. Lastly, they would burn the vegetation (so that any surviving rodents would have no food) and plow the burrows (so they would have no shelter).

In 1960, Soviet scientists boasted in the Bulletin of the World Health Organization that the U.S.S.R. had not seen a case of human plague since 1928. But that was only true on paper. In reality, scientists were still responding to outbreaks. Because mandates were passed down centrally and because the fear of admitting failure was intense and legitimate, no one wanted to report one.

“Local authorities would say, ‘It’s eradicated’ or ‘We don’t have an outbreak.’ Because they ignored the outbreak, it would spread to other republics of the Soviet Union,” says Sonia Ben Ouagrham-Gormley, a biodefense researcher now at George Mason University who also coauthored the CNS reports on the Soviet anti-plague system. When the plague broke out on the border of Kazakhstan and Uzbekistan, for example, Kazakh scientists would try to contact their colleagues across the border, who were kept from telling the truth. But, says Ben Ouagrham-Gormley,“if they were told the colleague was on vacation, most of the time that meant he was out in the field responding to the outbreak.”

In 1998, the Russian newspaper Sovershenno Sekretno (Top Secret) published a list of “just a few” of the plague outbreaks that had in fact happened: “Moscow, 1939; the Southern Volga-Ural Region 1945, Central Asia 1945; Caspian Sea Region-Turkmenia 1946; Astrakhan Oblast in Kazakhstan, 1947-48; Turkmenia, 1949; Central Asia, 1953, 1955, and 1958; Mount Elbrus region, 1970; Kalmykiya, 1972; Dagestan, 1975; Kalmykiya, 1979; Caspian Sea Region, 1980; Uzbekistan and Kazakhstan, 1981.” In Interesting Stories, scientists wrote about their experiences responding to several of these outbreaks. “We are only in the past 10 years recovering the data for how many human cases there really were,” says Jones.

The eradication efforts didn’t work because the area was simply too big, too vast to cover with humans or airplanes. The Soviet anti-plague system had more than 100 institutes spread over 11 republics, but it still wasn’t extensive enough. Jones points out that successfully eliminating all the plague-carrying rodents in the Soviet Union would have meant wholesale ecological collapse, as many species rely on rodents for food and their burrows for shelter. Thankfully, that didn’t happen. Rodents would be temporarily eliminated in an area and then come back, along with the plague.

Beginning in the 1960s, as reality intruded, the Soviet anti-plague system shifted from total eradication to control. The scientists knew that plague outbreaks among humans tended to follow rodent outbreaks in any local area. So they would conduct plague surveillance by systematically testing animals. If the results came back positive in an area, they would focus their efforts there. People were taught to avoid sick rodents. Patients were treated with antibiotics and quarantined. Vaccines eventually became available for people at high risk. People had to learn to live with the threat of the plague, as they had done for millennia in Central Asia.

There are still occasional cases of the plague in Central Asia today, in and around the former USSR. In Mongolia, recently, a young couple died of the plague. The culprit: an infected marmot that they had eaten raw.



A three-person crew has successfully launched to space and toward the International Space Station, about two months after a similar attempt failed and subjected the crew to a nerve-racking emergency landing back on Earth.

Three crew members—Oleg Kononenko of Russia, Anne McClain of the United States, and David Saint-Jacques of Canada—squeezed into a capsule at the Baikonur Cosmodrome, a Russian launch facility in Kazakhstan, on Monday. The view from inside the capsule showed the astronauts stone-faced in their white spacesuits, waiting for the countdown. A plush raccoon hung over one of their heads; the toy was brought to serve as a “zero-gravity indicator,” and show the crew, who were tightly secured to their seats, when the capsule reached weightlessness.

The capsule, perched atop a rocket, lifted off at about 6:31 a.m. ET, timed precisely for a long-distance alignment between the cosmodrome and the space station. About 10 minutes later, the crew was safely in orbit. The launch system, known as Soyuz, had completed all the necessary maneuvers to leave Earth, including shedding the rocket booster that had caused trouble in the last flight.

The launch is the first leg in a lengthy and complex journey. The crew will coast for six hours and circle Earth four times before the capsule nears the ISS and docks. Three other astronauts, already on board the station, will greet them.

One of them, Alexander Gerst of Germany, captured the view of the Soyuz launch from the station:

Congratulations to the Russian Space Agency @roscosmos and all international partners for a flawless launch of #SoyuzMS11. And welcome to space, @Astro_DavidS, @AstroAnnimal and Oleg! #Exp57 #Exp58 #Horizons pic.twitter.com/rzEjtm2PcO

While the crew still has a ways to go, a successful launch is a relief after the failed attempt in October. The capsule, carrying one American and one Russian, successfully lifted off from the cosmodrome and began its ascent toward the edge of space. But a few minutes into the flight, emergency lights lit up and alarms began to blare inside the capsule. The capsule fired its engines and shoved itself away from the rocket.

NASA’s administrator, Jim Bridenstine, said communication was lost briefly between Russian mission control and the capsule during the emergency landing. “Might have been as many as five minutes, but it seemed like it was forever—it seemed like it just kept going on and on,” Bridenstine said. It was long enough for him to wonder what he would have to say if the flight ended in tragedy.

The capsule eventually parachuted to the ground. The crew was shaken—the unexpected descent subjected them to a crush of seven times the force of gravity—but unharmed. They returned home.

The incident marked the first launch failure of a crewed Soyuz mission in 35 years. It also presented an unsettling possibility for the ISS. The three people on board at the time—Gerst, Serena Auñón-Chancellor of the U.S., and Sergey Prokopyev of Russia—were scheduled to return to Earth in early December. The members of the aborted launch, Nick Hague of the U.S. and Alexey Ovchinin of Russia, were supposed to be on board to see them off. If the three space travelers returned home before another crew went up, the ISS would be unoccupied for the first time in 18 years. With Monday’s launch, that scenario has been avoided; instead, the two crews will share the ISS for a couple of weeks before Gerst, Auñón-Chancellor, and Prokopyev head home.

Officials at Roscosmos, the Russian space agency, eventually traced the launch failure to the Soyuz’s boosters, which help propel the capsule into orbit before falling away one by one. Officials said a faulty sensor on one of the boosters prevented the hardware from cleanly separating. Instead, the booster struck the main rocket, and the impact produced enough of a jolt to trigger the Soyuz system’s automatic abort sequence.

Roscosmos said the sensor glitch originated during manufacturing, and vowed to inspect all versions of its Soyuz system. Before Monday’s flight, the agency conducted four successful uncrewed fights with various configurations of the Soyuz system, including the same one that malfunctioned in October. Bridenstine and other NASA officials have repeatedly said they believe the Soyuz system is safe. “It really is one of the most resilient and capable human launch capabilities that has ever existed,” Bridenstine said in October.

It’s also the only option. The Soyuz program is currently the only operational astronaut-transportation system in the world. American astronauts began flying on the Soyuz in 2003, when the U.S. space-shuttle program was put on hold after the Columbia disaster. naSA shifted exclusively to Soyuz use in 2011, after the American program ended altogether. Today, the U.S. government pays about $70 million to $80 million per ticket.

Since the space shuttle was retired, an American reliance on Russian transportation has agitated lawmakers in Congress, who hold the purse strings for NASA. naSA, in response, has repeatedly promised an American-built launch system.

In 2014, the space agency gave SpaceX and Boeing several billion dollars to develop systems to ferry American astronauts to the ISS. Both companies have made significant progress, but the efforts have experienced multiple delays and currently face safety reviews of workplace culture, influenced, in part, by several tragedies in NASA’s history. Bridenstine said last week that his decision to order the reviews at both companies was influenced by his reading of investigation reports of the Apollo 1 fire and the Challenger and Columbia disasters. (SpaceX CEO Elon Musk’s very public use of marijuana also factored into this thinking.)

“Every single one of those accidents had a number of complications. Of course, the technological piece was a big piece of it. [But] the other question that always comes up was: What was the culture of NASA?” Bridenstine said. “What was the culture of our contractors, and were there people that were raising a red flag that we didn’t listen to, and ultimately did that culture contribute to the failure and, in those cases, to disaster?”

SpaceX and Boeing can’t fly astronauts until they successfully demonstrate uncrewed flights. Those flights are expected in early 2019, but the timelines have already been slipping. naSA officials say they will keep using the Soyuz system until early 2020. But if neither company is ready to launch astronauts to space by then, the U.S. will need to buy even more rides on the Soyuz.



Recently, a user of an online forum for science-fiction writing posed an intriguing question to the rest of the community. In the user’s imaginary world, spiders rule the planet. The arachnids have grown intelligent enough to build a spacefaring empire, and they need space suits to travel into space. So, then: “How to design a space suit for an arachnid?”

The inquiry made me giggle. It reminded me of those silly thought experiments involving animals and garments, such as the long-running debate over how a dog would wear pants. I scrolled down, anticipating some funny responses.

But there was none of that. The people on this forum were serious, and they were serious about spider space suits.

“Terrestrial spiders breathe via almost all of their body. They don’t have particularly dedicated airways or efficient circulatory systems and as such are used to being surrounded by air in order to get enough oxygen into their vital organs,” one user wrote. “You need to keep a flow of air between the suit and the spider or they will suffer from the equivalent of hypoxia.”

“Have an enclosed pod that the spider can sit inside with legs folded and have mechanical arms/legs that support the pod and allow it to walk around,” someone else suggested.

“Are the suits needed for short space walks or would the [spiders] be wearing them semi-permanently?” another user asked. “This will determine if the suit needs air, heat, and durability to elements.”

The suggestions went on, and in great detail. Users discussed all aspects of spider physiology, from exoskeletons and joint movement to respiratory and circulatory systems. They wondered which space-suit designs would provide the many-limbed creatures with maximum mobility and comfort. One user even suggested that the spiders take some anti-nausea drugs while in zero gravity, as astronauts do.

The discussion now resembled something other than the dog-in-pants scenario: the very real conversations, decades ago, between engineers and scientists about how to make space suits for human beings. Those deliberations were not so different from the ones in the science-fiction forum, because they were both trying to answer the same question: How do you keep something designed to live on Earth alive in space?

In the United States in the 1960s, the space-suit business was booming. NASA was in the market for a variety of outfits for its first classes of astronauts, for use inside and outside space capsules and, eventually, on the surface of the moon.  

According to ILC Dover, the Delaware-based company that designed the iconic Apollo space suits worn by Neil Armstrong and Buzz Aldrin, engineers put different fabrics through rigorous tests to find those that would protect wearers from the extreme conditions of space. They exposed them to sweltering heat and bone-chilling cold, and folded and creased them every which way, bending them at each joint to see how the material would hold up.

Engineers also had to figure out how to prevent conditions inside the space suit from killing the wearer. They needed life-support systems that would circulate oxygen throughout the suit, and remove excess heat and carbon dioxide and eject them into space. If temperatures in the suit rose, astronauts could become dehydrated. If exhaled carbon dioxide accumulated, they could die.

On top of that, engineers had to determine exactly how much life support astronauts would need. “At the start of 1962, a significant challenge to the development of the Apollo [ Extravehicular Mobility Unit] was lack of a detailed understanding of the metabolic performance requirements of a man in a suit,” according to NASA. “No one in the U.S. space community knew the correct requirements.”

Decades after humans proved that they could survive in space with the right outfit, engineers are still working on space-suit designs. Boeing and SpaceX, which are expected to launch American astronauts to low-Earth orbit next year as part of a NASA program, have spent the past several years designing space suits of their own. Both are pressurized suits designed for the in-flight experience, not space walks. Boeing’s cobalt-blue suit comes with a zipper down the back for entry; a soft, hoodlike helmet; and footwear that resembles sneakers, a departure from the traditional, bulky boots of the past. SpaceX’s white-and-black space-suit design resembles that of a Power Ranger or Stormtrooper suit, with tall, rain boot–like shoes and a traditional, motorcycle-esque helmet.

Others are thinking beyond the space above Earth. In 2015, NASA announced the development of a suit for Mars, known as the Z-2. Engineers began by turning to earlier designs for inspiration. “We start by testing those suits and understanding the different features,” Lindsay Aitchison, a space-suit engineer at NASA’s Johnson Space Center, explained to Mental Floss in 2014. “What type of shoulder works best for what type of activity, different designs of the hips and boots and the style of entry. Do you want to have a zipper? All those things.”

But the Martian environment presents new challenges. Mars astronauts will need hardy space suits capable of protecting them from space radiation and winds carrying tiny dust particles that could scratch helmets or slice into the suit fabric. The suits that astronauts use today to maneuver outside the International Space Station aren’t especially bendy; astronauts “walk” with their hands, pulling themselves along railings and handholds protruding from the station. Mars suits will have to be flexible enough to allow astronauts to walk around, kneel down to collect samples, raise their arms in the air to wave to their fellow travelers, climb in and out of rovers, and so on. The soles of their shoes will resemble hiking shoes, made for traversing rugged terrain.

The whole getup will have to be as lightweight as possible. The weight of space suits and life-support systems matters less in low-gravity environments, such as on the moon or around the space station. The complete space-shuttle suit, for example, weighed a whopping 310 pounds, but weightlessness removed the burden. While the gravity on Mars is just 38 percent that of Earth’s, astronauts will still feel some of the weight of a 300-pound space suit on their body.

Engineers will have to make some aesthetic considerations, too. Aitchison, the space-suit engineer, has suggested adorning flashy, bioluminescent stripes of different colors to Martian space suits, so that astronauts can tell who’s who when they’re out and about at night.

In a strange convergence of human and spider anatomy, an engineer at Lockheed Martin, a frequent NASA contractor, has even suggested that Mars astronauts could wear eight-legged, rocket-powered space suits and crawl and hop across the surface of some of the planet’s moons.

In any case, fictional, sapient spiders, like humans, will have to contend with a multitude of factors to keep their space travelers healthy and alive. At least we only have to worry about four limbs.



The smoke was visible for miles.

The day, April 20, was sunny on the Florida coast, with few clouds. The plumes, thick and glowing orange, rose over the horizon and crawled across the sky. Beachgoers stopped to stare. A photographer for Florida Today, on assignment to cover a surf festival, turned the lens away from the waves and snapped some pictures.

The ashy clouds were coming from Cape Canaveral. The only time you want to see smoke wafting from that vicinity, the site of historic space launches, is after a successful liftoff—and there were no rockets in the sky that day.

The smoke turned out to be from a failed test of a SpaceX spacecraft designed to carry humans to orbit. Strapped to a test stand so it couldn’t fly away, the capsule had ignited its engines. “The initial tests completed successfully, but the final test resulted in an anomaly on the test stand,” SpaceX said in a statement at the time.

The smoke suggested an outcome more serious than an “anomaly”—like a full-blown explosion. But SpaceX wouldn’t say anything else.

A day later, a grainy video, which looked like a recording of a screen, appeared on Twitter. The footage showed what appeared to be the SpaceX capsule, known as Dragon, on the test stand.

For about 10 seconds, everything is still. And then, suddenly, there’s an explosion, and the whole thing is engulfed in flames. Off camera, people exclaim in shock and swear. (No one was near the capsule, so there were no injuries.)

SpaceX declined to verify the authenticity of the video. But this week, a NASA contractor that supports launch operations in Florida sent an internal email warning its employees that they can be fired if they share the video. The message, reported by the Orlando Sentinel, confirmed that the footage was real.

More than a week after the explosion, SpaceX remains silent about the incident. At this moment, even an “anomaly” in its test capsule should rattle the engineers, astronauts, and administrators invested in Dragon’s success. SpaceX was well on its way to launching American astronauts into space, a historic first in U.S. spaceflight history.

“Unless something goes wrong, I would think that we’ll be flying hopefully this year, this summer,” Elon Musk, the company’s founder and CEO, said last month.

Barely two months ago, the same capsule was docked to the International Space Station, circling Earth. It arrived without people—this was only its first flight, after all—but plenty of fresh supplies, and the astronauts on the station opened the hatches and floated in. Several days later, the Dragon returned to Earth and parachuted to the Atlantic Ocean, ready for more tests, in preparation for a flight with people on board.

No NASA astronauts have launched from American soil since 2011, in the final flight of the space-shuttle program, an illustrious but expensive 30-year effort. In the years since, the United States has relied on its former space rival, Russia, to transport astronauts to and from the International Space Station. This arrangement was never meant to be NASA’s only option, or to last as long as it has. The George W. Bush administration directed NASA to develop a transportation system to replace the shuttles, but the Obama administration canceled the project, citing ballooning budgets and schedule delays.

So instead of making its own systems, NASA hired someone else to do it. In 2014, the agency awarded billion-dollar contracts to SpaceX and Boeing to build astronaut-transportation systems. NASA would pay to use them, but at a significantly lower rate than the Russians charge.

At the start of this year, SpaceX had made the most progress. Spectators and press flocked to Florida for the Dragon’s first flight in March. A pair of NASA astronauts, already in training for the crewed mission, chatted with reporters, eager to suit up and fly. “I’m a little emotionally exhausted,” Musk told reporters soon after the successful launch. “Because that was super stressful. But it worked—so far.” The company was on a high.

Now it’s investigating a fiery spacecraft failure that could severely set back its efforts. NASA, which is aiding the investigation, says it has “full confidence” in SpaceX, but doesn’t know yet how the incident will affect its schedules.

SpaceX has shown that it can rebound fairly quickly after fiery setbacks. In 2015, a Falcon 9 carrying supplies to the International Space Station exploded minutes after launch; another rocket flew about six months later and executed, for the first time, a maneuver that SpaceX has now perfected, landing a booster vertically on the ground. In 2016, a Falcon 9 went up in flames on the launchpad as it fueled up for an engine test; another rocket launched successfully four months later, and a Falcon 9 hasn’t malfunctioned since.

But the previous failures, while devastating, destroyed only space-station supplies and science experiments. Soon SpaceX is supposed to carry far more precious cargo. The failure occurred during a test of a very important system: the Dragon’s escape system. The capsule is designed to hurl itself from the rocket in the event of a rocket malfunction or another emergency. To push off, the Dragon fires a series of engines called SuperDracos. SpaceX had planned to conduct an in-flight demonstration of this test in June.

It’s not known whether the capsule, itself a test version, is salvageable or completely lost. SpaceX has other capsules “in various stages of production and testing,” according to a spokesperson, but did not say how far along they are.

In a rare moment of reticence, Musk has not yet publicly addressed the incident. It could be that the entrepreneur has enough on his plate; he spent the weekend of the spacecraft failure tweeting about Tesla, and last week reached an agreement with the U.S. Securities and Exchange Commission in a legal standoff involving the electric-car company. Federal regulators won’t go after Musk if he tweets something about SpaceX, which is not public, but NASA might, as Musk is likely well aware. He has gotten into some trouble with the agency’s leadership before.

The lack of public details—even any acknowledgment of the smoke—has irked some, including the staff of the editorial board at the Orlando Sentinel, which regularly covers space activities along Florida’s shores, also known as the Space Coast. In a biting editorial published last week, the paper lambasted SpaceX’s response, comparing the company’s relative silence to the days and weeks after the Challenger shuttle disaster in 1986, when “NASA officials circled the wagons, dispensing little information and giving the appearance the agency had something to hide.”

“The secretive aspects of Elon Musk’s ventures is fine when he’s spending his own money (or investors’ money) to build electric cars or bore tunnels through the ground,” the Sentinel wrote. “It’s not fine when the public is bankrolling his efforts, as it is with SpaceX’s crewed spaceflight program.”

The comparison to Challenger—an explosion that killed five NASA astronauts and two civilians—is certainly extreme, perhaps even inappropriate. But SpaceX should expect to be more transparent about its work for NASA, especially as it nears the finish line. Unlike its other projects, such as the Falcon 9 and Falcon Heavy rockets, the astronaut capsule is a taxpayer-funded effort. Yes, investigations take time. No one expects a full-blown explanation a week after the fact. But the public deserves some more openness, such as confirmation of a fire, or even a simple acknowledgment of the smoke over Florida’s coast.

The same standard goes for Boeing (and for all the NASA contractors, for that matter). Boeing discovered a propellant leak in its astronaut capsule, the Starliner, during a test of its escape system last June. Boeing told The Washington Post it was “confident we found the cause,” but disclosed no information beyond that. There were no scathing editorials about that, but the circumstances of the SpaceX incident are different; Starliner has never flown to space, and there was no video footage of the capsule on fire.

The clip of the Dragon spacecraft allegedly blowing up is painful to watch. It is a fiery reminder of the difficulties of engineering and the stakes of exploration. SpaceX understands these well, but this effort is different from the rest of its portfolio. The company has taken on a job historically done by the government, which means absorbing the cultural sentiment that comes with it. The first SpaceX launch of American astronauts will be celebrated not only as a win for the commercial space agency, but also as a national achievement, a dazzling showing of American ability. A lack of transparency, a frequent hallmark of private technology companies, won’t work here.



testing



The year is 2100. The United States has been devastated by climate change. Super-powerful hurricanes regularly ravage coastal cities. Wildfires have overrun Los Angeles several times over. And it is dangerous to go outside on some summer days—children and the elderly risk being broiled alive.

In such a world as that one, will we give up on the idea of historical progress? Should we even believe in it now? In his new book, The Uninhabitable Earth, the writer David Wallace-Wells considers how global warming will change not only the experience of human life but also our ideas and philosophies about it. It’s possible, he told me recently, that climate change will make us believe that history is “something that takes us backward rather than forward.”

“The 21st century will be dominated by climate change in the same way that … the 19th century in the West was dominated by modernity or industry,” he said. “There won’t be an area of human life that is untouched by it.”

I recently talked to Wallace-Wells about his new book, the difficulty of writing stories about climate change, and which science-fiction prophecy he believes came true. Our conversation has been edited for clarity and brevity.

Robinson Meyer: You had the big cover story in New York, and then you wrote a book. What did you learn writing the book that maybe wasn’t as clear when you were writing the first story?

David Wallace-Wells: I’d written a previous cover story about bee death, but I hadn’t done a ton of straight-ahead climate writing. And in a sort of perverse way, I think that was one of the qualifying things about my background for that story and this book. I was coming at it fresh. I had a different perspective than people who had devoted their lives to it—which is that I don’t actually, like, intuitively care all that much about nature per se. And so [in the story] I wasn’t writing about the plight of the animals or the tragedy of the rainforest. I was focused on people.

In that first piece, I also really focused on worst-case scenarios. I looked at scenarios north of 4 degrees [Celsius of global warming], 5 degrees, 6 degrees, even 8 degrees—and I thought it was very important to introduce those scenarios to the broader public because they were so far from what even the general, engaged, liberal understanding of climate change was.

It made me think that there were all of these other downstream effects of climate change that even academics hadn’t begun to contemplate. We have this idea over the last few centuries that history may be erratic, it may punish some people here and there, but generally over time, as time marches forward, we see progress, we see lives getting more prosperous and safer and healthier.

While I don’t think it’s safe to say that climate will completely undo that, I think it’s quite likely that it does transform that perspective in some way. It’s certainly within the realm of conceivability that damages accumulate so significantly that we totally drop that idea about history as an arrow of progress and start thinking of it as something that is much less reliable, even something that takes us backward rather than forward.

Meyer: I want to talk about that more, but first I want to follow up on this idea of the “general, engaged understanding” of climate change. I think about that a lot. What do you think the general understanding of the issue is?

Wallace-Wells: It’s actually changing quite quickly. I think that my article played a small role in that, but the [Intergovernmental Panel on Climate Change] report was a way bigger deal. It really does seem to have awakened a huge amount of alarmism and panic, and it also sort of invited scientists to speak more openly about the issue. But when I first started writing, I was motivated by the divergence between what I saw coming out of academic research and how those stories were being told in most mainstream publications. And that was along three points.

The first point is about the speed of change. The emphasis was always about how slow climate change was, and how it was hard to deal with because there was no urgency to it. But the animating fact to me is that more than half of all the emissions ever produced from the burning of fossil fuels have been produced in just the last three decades. That transformed my perspective—I realized that this is something that we’re doing very much in real time.

The second thing that we sort of misunderstood was the scope of it. So much of the storytelling is focused on sea-level rise and the melting of ice in the Arctic and Antarctic. Obviously that’s a huge part of the climate story. But it also gives this false sense that it’s a problem that has local impacts—like if you stay off the shoreline, you’re likely to be safe.

The third problem was the severity. Scientists had often talked about this 2-degree [Celsius of global temperature rise] threshold as a kind of meaningful mark of climate horror, and I think that most readers understood that to mean that that was about as bad as it could get. But we can now see that 2 degrees of warming is functionally a floor for where we’ll be, and not a ceiling.

Meyer: You process a lot of scholarly or humanistic writing about climate change in your book. Whose work has stuck with you?

Wallace-Wells: The people who’ve written about the politics of climate—especially the relationship of climate and capitalism. Naomi Klein is to me sort of like the North Star. Jed Purdy’s work—he is more sort of earnestly theoretical, but he is valuable in placing the challenge of climate in the long tradition of political philosophy.

Honestly, the person whose work most flicked this light on for me was Amitav Ghosh and his book The Great Derangement, which is about narrative. I found a lot to disagree with in his interpretation, mostly because I come from kind of a literary background. I used to work at The Paris Review, and I studied all this stuff in college, and I had a slightly different idea of what the basic function of novel writing is. Therefore I had a different interpretation of why we don’t have good novels written about climate change.

Meyer: He argues that climate change is uniquely hard to write stories about, right? Where did you disagree with him?  

Wallace-Wells: Ghosh’s basic argument is that the novel is a form about the inner life of an individual. And the problem of climate change is a very different category of problem for him. You can place the stories of individuals within it, but you end up with something like The Day After Tomorrow, where it’s like, Oh, here’s a person who’s dealing with a struggle, but the story is also about climate change. And the disconnect feels almost corny and staged.

I tended to think about it more in terms of responsibility and villainy. I think that we have a very hard time processing our own complicity as Westerners reading novels and wondering about climate change. We really prefer to see ourselves as truly innocent, and therefore want our climate storytelling to reassure us about our own culpability, and tell us in fact that it’s someone else’s problem in our culture, outside of narrative.

I think this often takes the form of vilifying oil companies. I don’t want to come off as someone who thinks oil companies are forces for good. But I also realized that when I buy a flight to take a vacation, I’m not doing that as a tool of the oil companies. When I eat a hamburger, I’m not doing that as a tool of the oil companies. Everything about the way that we all live in the modern world [has] a carbon footprint, and therefore we all share in responsibility for this damage.

I hope that that sort of revelation will inspire people to some kind of collective action. Lifestyle choices are ultimately so small that anything other than political action and organizing seems to me effectively a diversion. But I also am not approaching the subject really as an advocate, but as a truth teller and storyteller.

Meyer: Do you think there’s a way to write that kind of narrative that doesn’t wind up feeling like The Jungle? Which ends with a giant Socialist rally, and the narrator being absorbed into the fervor of the crowd. Or, I really enjoyed [the 2018 film] Sorry to Bother You, but it has a very similar kind of arc in which the politics save the main character.

Wallace-Wells: I guess it depends on whether what you’re looking for in a narrative is polemic or humanity. I actually think that one of the features of my writing on this subject is that it—I hope this doesn’t sound too grand to say—but it demonstrates that if you handle them right, the simple accumulation of facts can take on an enormous narrative force. And I don’t really think that that’s something that many other writers about climate have done before.  

We are still in the infant stage of figuring out how to tell stories about this issue. Going forward, I suspect that the more interesting narrative forms are likely to background climate change and make it appear like the theater in which human dramas are unfolding. Think about, for instance, a climate refugee camp, where the story is effectively some rivalry between two quasi-criminal-like figures in the camp. Or a honeymoon where people are going snorkeling through Miami Beach.

There are whole imaginative theaters for storytelling about climate that we haven’t yet begun to explore. But if all that is considered “responsible” is optimistic hopeful storytelling about how we can solve the problem, then that’s just—from a narrative perspective, it’s kind of corny. The best climate storytelling is likely to be written by people like J. G. Ballard, or William Gibson, or Margaret Atwood, who are really thinking about all the weird ways that these forces could transform our lives.

Meyer: Gibson’s really recent novel, The Peripheral, seems like one of the better presentations of how you’re talking about history now—about how day-to-day, lived existence would feel like in a world where progress has gone wrong, where there are cataclysms in the past from which people really haven’t recovered.

Wallace-Wells: I know [Gibson] a little bit because I did the Paris Review interview with him. We were emailing a few weeks ago and I was like, Oh, I’m just adding a couple sentences to the book, last minute, about how science-fiction writers are likely to be understood even more as prophets because of climate change, and he wrote back and he was like, You know what, every time people say that to me, I always say “We haven’t successfully predicted anything! We got all of our predictions wrong. The only thing we’ve gotten right is the mood.” And I wrote back and I was like, No, the mood is a prediction! It’s a really important prediction, and actually you guys got it extremely right.

Meyer: What’s the meaning of climate change to you? What’s its larger import? Is it the stuff about history or is it something else?

Wallace-Wells: My short-form answer is that I think that the 21st century will be dominated by climate change in the same way that, say, the end of the 20th century was dominated by financial capitalism, or the 19th century in the West was dominated by modernity or industry—that this will be the meta-narrative of the coming decades, and there won’t be an area of human life that is untouched by it. Often people talk about climate change as a global problem, which it obviously is, but I don’t think we’ve really started to think about what that means all the way down to the level of individual life.

My basic perspective is that everything about human life on this planet will be transformed by this force. Even if we end up at a kind of best-case outcome, I think the world will be dominated by these forces in the coming decades in ways that it’s hard to imagine and we really haven’t started to think hard enough about.

I am a child of the 1990s. I’m American. I grew up in New York. And in that way I am, you know, the product of the end of history. I felt that there were all these forces unfolding in the world around me—and that while I had my skepticism about them, while I had my critiques about them, I did believe that they were carrying us forward into a better, more prosperous, more just world. I knew that that would not be an easy path, and I knew that we’d have to fight to make sure that, for instance, market forces and globalization benefited more people rather than fewer. I knew that there were political fights to be had there. But in general I just intuited in a deep emotional way—that I might not have even been willing to admit publicly, because I would have found it embarrassing—that history did move forward and therefore my life was going to be an experience of witnessing progress. I feel very profoundly not that way anymore.



The Senate rejected the Green New Deal on Tuesday, in a decisive 57–0 vote that Democrats decried as a political stunt meant to divide their caucus.

All the Republican senators opposed the measure. They were joined by four senators who caucus with the Democrats—Senator Joe Manchin, from the coal-heavy state of West Virginia, along with Senators Kyrsten Sinema of Arizona, Doug Jones of Alabama, and Angus King of Maine. 

Uniting the four dissenters: a sense that the Green New Deal, in its current form, is neither practical nor attainable.

“I agree with proponents of the Green New Deal that we need decisive action and ambitious goals to protect our planet for future generations,” said King, an independent who usually votes with Democrats, in a statement. “But at the same time, I believe that the best way to fully address this challenge is to set realistic goals.”

Very little of the drama on Tuesday mattered in a lasting way. The Green New Deal resolution was always doomed to fail, since Republicans hold a majority in the upper chamber. And even its successful passage may not have meant much. The Green New Deal, as it stands today, is a nonbinding plan to make a plan. While its supporters envision a Herculean effort to remake the economy while fighting climate change, its current text is extremely vague, authorizing no new programs in any useful detail.

Nor was Senate Majority Leader Mitch McConnell, who orchestrated the vote, interested in furnishing any of those specifics. The details were never the point: McConnell sought to force individual Democrats into taking a stand on the expansive proposal, which remains controversial in the caucus. 

In protest, 43 Democrats declined to oblige him, abstaining from the roll call and voting only “present.” All six Senate Democrats openly running for president—that is, Bernie Sanders, Kamala Harris, Elizabeth Warren, Cory Booker, Amy Klobuchar, and Kirsten Gillibrand—co-sponsored the resolution but still voted present on it. Yet because of its four dissensions, the caucus still failed to mount a unified front. 

Not that Republicans perfectly executed their strategy either. Polling on the Green New Deal has not nearly been as catastrophic as GOP leaders initially hoped. Sixty-three percent of Americans believe the Republican position on climate change is “outside the mainstream,” according to a recent NBC/Wall Street Journal poll. 

McConnell originally meant to hold the test vote in February, but he delayed it by four weeks after Democrats threatened a boycott. And while Republicans have shot down Democratic climate proposals, they have offered no consensus alternatives of their own. “It’s clear why we’re opposed to the Green New Deal,” Senator Lamar Alexander told Politico on Monday, “but it’s not as clear what we’re for.” 

While Democrats agree on the danger of climate change, they have their own problems. As a counter to McConnell’s gambit, Senate Democrats have offered a resolution that does little more than say that climate change is real and caused by humans, and that someone with power in the federal government should do something about it. Here is its full text:

That it is the sense of Congress that—

(1) climate change is real;

(2) human activity during the last century is the dominant cause of the climate crisis; and

(3) the United States and Congress should take immediate action to address the challenge of climate change.

The resolution has so far attracted the support of only one Republican, Senator Susan Collins of Maine. McConnell has not yet scheduled it for a vote. And even if he did, it seems to miss the underlying critique guiding the Sunrise Movement, the youth-led activist group that supports the Green New Deal: that Democrats, despite agreeing on the danger of climate change, do not have a consensus plan to do anything about it (though The Atlantic has learned that House Democratic leaders are set to announce on Wednesday a climate plan meant to unite their caucus).

After the vote on Tuesday evening, the senators who opposed the Green New Deal explained their break with party unity while emphasizing the need for some action on climate change.

“I firmly believe that as a country, we need to act decisively to mitigate the effects of climate change,” said Jones, who faces reelection in Alabama next year. Sinema, of Arizona, called for a “realistic, achievable solution.” Manchin, a longtime ally of the coal industry and the ranking member of the Senate Committee on Energy and Natural Resources, said in a statement, “We need to focus on real solutions that recognize the role that fossil fuels will continue to play.”

He then affirmed: “Manmade climate change is real and it’s a serious threat.”

King, the independent of Maine, explained his no vote in a statement that ran more than 500 words. “As someone who has spent a significant amount of his life working in renewable energy and is well-versed in the technology, I am concerned that the overly aggressive goals in the resolution I voted against today are unrealistic and far too broad,” he said, alluding to his experience founding an energy-efficiency company in the early 1990s.

“I want to emphasize that my skepticism surrounding the current resolution should not be misconstrued as being uninterested in pursuing the most ambitious and realistic action on climate change; I simply differ with the most effective way to accomplish that goal,” King added. He also decried that “the Senate Majority Leader’s first vote on climate change mitigation isn’t a serious attempt to solve the problem facing our future generations, but rather a cynical act of political theater.”

King, who has co-sponsored other renewable-energy bills, does not face reelection until 2024.

There is some precedent for a split on these types of votes in the Democratic caucus. In July 2017, McConnell held a vote on a doomed Medicare-for-all proposal. While most Democrats voted present, a few of the caucus’s red-state senators opposed it. The final whip count was the same: 57 nay, 0 yea, 43 present. The episode is now mostly forgotten.



In the year 2514, some future scientist will arrive at the University of Edinburgh (assuming the university still exists), open a wooden box (assuming the box has not been lost), and break apart a set of glass vials in order to grow the 500-year-old dried bacteria inside. This all assumes the entire experiment has not been forgotten, the instructions have not been garbled, and science—or some version of it—still exists in 2514.

By then, the scientists who dreamed up this 500-year experiment—Charles Cockell at the University of Edinburgh and his German and U.S. collaborators—will be long dead. They’ll never know the answers to the questions that intrigued them back in 2014, about the longevity of bacteria. Cockell had once forgotten  about a dried petri dish of Chroococcidiopsis for 10 years, only to find the cells were still viable. Scientists have revived bacteria from 118-year-old cans of meat and, more controversially, from amber and salt crystals millions of years old.

All this suggests, according to Ralf Möller, a microbiologist at the German Aerospace Center and collaborator on the experiment, that “life on our planet is not limited by human standards.” Understanding what that means requires work that goes well beyond the human life span.

Physically, the 500-year experiment consists of 800 simple glass vials containing either Chroococcidiopsis or another bacterium, Bacillus subtilis. The glass vials have been hermetically sealed with a flame. Half are shielded with lead, to protect them from the radiation of radon or cosmic rays, which can cause DNA damage. (A duplicate set of the vials sits in the Natural History Museum in London for backup.) Every other year for the first 24 years, and then every quarter century for the next 475, scientists are supposed to come test the dried bacteria for viability and DNA damage. The first set of data from the experiment was published last month.

[ Read: The quest to kill the superbug that can survive in outer space ]

Opening vials, adding water, and counting colonies that grow from rehydrated bacteria is easy. The hard part is ensuring someone will continue doing this on schedule well into the future. The team left a USB stick with instructions, which Möller realizes is far from adequate, given how quickly digital technology becomes obsolete. They also left a hard copy, on paper. “But think about 500-year-old paper,” he says, how it would yellow and crumble. “Should we carve it in stone? Do we have to carve it in a metal plate?” But what if someone who cannot read the writing comes along and decides to take the metal plate as a cool, shiny relic, as tomb raiders once did when looting ancient tombs?

No strategy is likely to be completely foolproof 500 years later. So the team asks that researchers at each 25-year time point copy the instructions so that they remain linguistically and technologically up to date.

Möller and his colleagues are among the most ambitious scientists to plan a long-term experiment, but there have been others. In 1927, a physicist named Thomas Parnell poured tar pitch into a funnel and waited for the highly viscous substance to slowly drip down. When Parnell died, custodianship of the pitch-drop experiment passed along a chain of physicists, who dutifully recorded each drop. The last one fell in April 2014, and the experiment can last as long as there is more pitch in the funnel.

[ Read: ‘The pitch dropped’ ]

Plant biology has several long-term studies, too. At a fertilizer magnate’s country estate in England, scientists have been studying how different fertilizers affect the particular crops grown in the same fields year after year since 1843. In Illinois, agricultural scientists have been carrying out a corn-breeding study since 1896. And at Michigan State University, a botanist in 1879 buried 20 glass bottles of 50 seeds to be dug up at regular intervals and tested for viability. The location of the bottles is kept secret to prevent tampering. The last bottle will be dug up in 2020.

Michigan State University also houses an E. coli experiment that could run for centuries. Since February 1988, the lab of the microbiologist Richard Lenski has been watching how E. coli acquire mutations and evolve over the generations. They’re currently on generation 70,500. Because E. coli replicates so quickly, it’s like watching evolution on hyper-speed.

Despite the time-warping nature of this experiment, Lenski didn’t start out thinking about the far-off future. He thought the experiment would run a few years, and at one point, when he felt he had gleaned as much as he could, he considered shuttering it. “But whenever I mentioned to people I might end the experiment,” he recalls, “they said, ‘You can’t.’ That made me realize people were appreciating it for its longevity and for the potential of surprises.” And in 2003, his lab made one of its most surprising findings yet. The E. coli suddenly evolved the ability to eat a molecule called citrate. By looking at previous generations that his lab had frozen and archived, Lenski’s graduate student was able to reconstruct the series of mutations that gradually led to what had looked like a quick switch.

Every day someone in Lenski’s lab transfers the E. coli into a new flask, using the same type of glassware and the same growth media they’ve been using for 30 years. Like the bacteria, the techniques for studying them have evolved—scientists can now sequence E. coli’s entire genome, for instance—and they will keep changing. Lenski has identified a scientist he will bequeath the experiment to when he retires.

“Of course, for an experiment to go on like this, I’m assuming that science still looks somewhat like today, in the sense that universities will exist, there will be professors with labs, and so on,” says Lenski. “Yet if one looks not so far into the past, that isn’t how science was done.” Just a few hundred years ago, money for scientific research came largely from wealthy patrons, not government agencies.

A centuries-long experiment needs a long-term financial plan, too, and Lenski has been looking for a wealthy patron of his own. His experiment has enjoyed government funding, but he knows it’s unreliable, especially if public support for science erodes. Ideally, he’d like to create an endowment, and he’s done the math: A $2.5 million endowment would provide returns of about $100,000 a year, which should cover the costs of materials and the salary of a technician to work on the experiment every day. “So any shout-out for a big donor would be much appreciated,” he wrote at the end of an email to me.

The 500-year-long microbiology experiment is far cheaper and less involved, as it requires only a researcher to work on it once every 25 years. But it does require people to remember, to value science as an endeavor, and to have the resources to carry it out. Because the experiment began in 2014—before certain world events made everyone realize a collaboration among the U.K., Germany, and the United States perhaps should not be taken for granted—I mentioned to Möller that even planning for a 500-year experiment seems to require a certain optimism about the stability of our current world.

Imagine, he said, the first human who set out exploring: “What is behind the next hill? What is behind the next river? What is behind the next ocean? Our curiosity is always optimistic.” To continue venturing into the unknown is to be continually optimistic.



Let’s get some things straight.

Passover is a springtime Jewish festival celebrating the early Israelites’ exodus from Egypt and freedom from slavery. Jews observe it by hosting a ritual dinner, called a seder, and then by abstaining from eating all leavened bread for about a week. (Some of us abstain from some other stuff, too.) Instead, we eat matzo, a thin, unleavened cracker.

Easter is a springtime Christian holiday celebrating the resurrection of Jesus Christ and freedom from sin and death. It is preceded by a series of holidays commemorating Jesus’s path to the cross. One of these holidays is Maundy Thursday, which, aside from being a great name for a holiday, is a remembrance of the Last Supper, which was a seder. In the United States, many Christians observe Easter by attending a ritual meal between breakfast and lunch, called a brunch.

These holidays have a lot in common: They share themes of liberation and triumph; they both involve buying a lot of eggs; they were both a pretty big deal for Jesus. This year, they also overlap. Passover’s week-long festival begins on the night of April 19, while Easter falls on Sunday, April 21. And this makes sense: In the Gospels, the existential drama of Easter happens against the backdrop of Passover. Yet about 15 percent of the time, the two holidays actually occur a month apart.

What causes this mismatch? There are two ways of answering this question. The first is that there’s a basic misalignment between the Christian and the Jewish festival calendars. Both holidays are supposed to fall on, or near, a full moon in the spring. Passover always begins on the 15th day of the Hebrew month of Nisan. Because the Hebrew months are pegged directly to the lunar cycle, the 15th day of Nisan is always a full moon.

For a time, early Christians used the Jewish calendar as a reference, celebrating Easter on the first Sunday after Nisan 15. But at the First Council of Nicaea in A.D. 325, the Church decided to set its own date for Easter, independent of the Jewish reckoning. Today most Christian communities celebrate Easter on the first Sunday after the first full moon after March 21. But sometimes this full moon isn’t the same as the Jewish one.

And here arises the second, deeper answer. The lunar mismatch occurs because both calendars must grapple with the same underlying problem: A lunar year is not the same length as a full solar year. In fact, nothing is exactly the same length as a solar year, because not all solar years are the same length. This challenge ails not only both religious calendars, but also every human attempt at timekeeping on Earth.

Allow Benjamin Dreyfus to explain. A professor of physics at George Mason University, he runs the Hebrew Calendar Facts page on Facebook.

“The Hebrew calendar uses lunar months, and they’re about 29 or 30 days each. If you have 12 of those months, it adds up to 354 days,” Dreyfus told me. But that’s about 11 days too short: A solar year is about 365.2425 days.

If left unaddressed, this would quickly cause the Hebrew calendar to drift out of sync with the solar calendar, violating the biblical commandment to celebrate Passover during the spring. The Hebrew calendar resolves this tension by periodically adding an extra month to the calendar.

Two thousand years ago, this decision was made on the fly, almost Groundhog Day–style. During the month of Adar (which directly precedes the Passover month of Nisan), the ancient rabbinical court would decide if it was springy enough outside for Passover. If spring seemed to be on track, Nisan could occur. But if it wasn’t warm enough outside yet, the rabbis would tack on another month of Adar. They called this leap month Adar II.

Around the third century of the Common Era, this observational system was replaced with a fixed calendar. The Hebrew calendar now adds a leap month seven years out of every 19. (Or, more exactly, Adar II is now added in the third, sixth, eighth, 11th, 14th, 17th, and 19th years of the cycle.)

“It works out so that over the course of 19 years, that comes out almost to the length of the solar years, ” Dreyfus said. “But it doesn’t work perfectly. The Jewish calendar drifts about one day later every 200 years, and so far there isn’t any mechanism to correct that.”

Right now, that means Passover falls a month later than Easter three times in every 19-year cycle. But the gap is slowly growing. “In about 6,000 years, they’ll be fully out of sync if nothing is done to correct the Jewish calendar. But right now there’s nobody who has the authority to do that for the Jewish world. There’s no pope or anything,” Dreyfus said.

This problem—that 12 lunar months does not add up to a full solar year—also ails the Gregorian calendar, the calendar system now used by most of the world. First proclaimed by Pope Gregory XIII, it uses a standard 365-day year most of the time. But about 24 times a century, it adds a leap day on February 29. This nearly, but not totally, brings the calendar year in sync with the solar year.

Today Roman Catholics and most Protestant traditions now celebrate Easter after March 21 on the Gregorian calendar. But the Eastern Orthodox Church uses the older version of that calendar, known as the Julian, to determine the date of Easter and other festivals. This year, Orthodox Easter is April 28.

Yet the Gregorian isn’t perfect. In fact, it still requires regular tweaks by hand. There is still a high rabbinical court of sorts that adjudicates the Gregorian calendar every year, deciding whether it should be adjusted to better match reality—except today the court is staffed not by rabbis, but by physicists. No solar year, remember, is the same length: Thanks to tiny wobbles in Earth’s orbit, some years are a second or two longer or shorter than others. So every year, the International Earth Rotation and Reference Systems Service announces whether to add a leap second in order to align Earth time with solar time. (The United States officially opposes this practice.)

The three calendars occasionally line up in strange ways. In 2018 and 2019, the first night of Passover fell on Good Friday. This won’t happen twice in a row again until 2113 and 2114, according to Dreyfus.

And as it happens, the first night of Passover can never fall on Maundy Thursday, even though that holiday commemorates a seder. That’s because Passover can never begin on Thursday, ever. “The calendar is rigged so that [seder] can fall only on certain days of the week,” Dreyfus told me. “If Passover started Thursday night, it would push Rosh Hashanah the following year to start on Saturday night.” And neither Rosh Hashanah nor Yom Kippur, the two High Holidays of the Jewish year, can fall the day after Shabbat.

(What’s up with maundy, by the way? Despite its contemporary-sounding construction, maundy is derived from an Old French word referring to Jesus’s new command at the Last Supper “to love your neighbor as I have loved you.” The Latin word for “commandment” is mandatum, which emerged from several hundred years of medieval Europe’s linguistic spin cycle as maundy.)

I imagine that for most Americans, the occasional mismatch between Easter and Passover is a curiosity, an oddity of religious history. But for people like me—Jews who attend an extended family’s Easter brunch—it is a matter of supreme importance. Consider the traditional foods served at that Christian ritual meal—the poached eggs, the toast with jam, the make-your-own waffle. All the really good ones, alas, have leavening in them, and thus we can only consume them three years out of every 19. Freedom from slavery and a nice family brunch are joyous enough, of course. But freedom from slavery, brunch with family, and permission to eat pancakes? As we say, Dayenu. 



Marijuana can linger in the human system for a few months at most, but cannabis residue will stick to other surfaces for millennia. High up in the Pamir Mountains, in what is now western China, archaeologists were excavating the tombs of Jirzankal Cemetery when they came upon a set of braziers and asked themselves what purpose the tools served. After analyzing the residue, a team of researchers found that it not only came from cannabis, but contained unusually high levels of THC—the compound that gives cannabis its psychoactive, or mind-altering, qualities.

Indeed, these braziers, or wooden incense burners, mark some of the earliest, most robust physical evidence of humans burning cannabis specifically for its psychoactive effects. Researchers from China and Germany described their findings in a study published today in the journal Science Advances.

One of the most compelling pieces of evidence pointing to the use of psychoactive cannabis in ancient Central Asia is purely textual: a section in Herodotus’s Histories about the Scythians, who, after funerals, would “throw the seed … upon the red-hot stones” and “shout for joy” as the vapor rose. But archaeological evidence has been harder to come by. While excavating temples in Turkmenistan, the famed archaeologist Viktor Sarianidi reignited interest in the region’s ancient drug culture when he claimed to have found ritual plant remains inside ceramic vessels, which could have been used for drinking the hallucinogenic soma. Similar ceramics, however, have since been identified elsewhere in the region as cheese strainers, and later tests found that the ceramics did not actually hold remains of the ingredients originally reported. In fact, they did not contain plant remains at all—only plant impressions. And while a major 2006 study confirmed the presence of cannabis seeds in another ancient Chinese tomb, there was no evidence of burning or smoking the plant. The debate surrounding ancient drug use in Central Asia has been “extremely … I guess lively is the best way to put it,” Robert Spengler, a co-author of the new study and an archaeobotanist at Germany’s Max Planck Institute for the Science of Human History, told reporters.

The team identified the chemical traces clinging to the burners using a technique that articulates a sample’s chemical signature. By vaporizing the sample, separating its components, and recording their differences in mass, researchers can identify the relative levels of the chemicals they’re looking at. “To our excitement, we identified the biomarkers of cannabis,” says Yimin Yang, another co-author of the study and a researcher at the University of the Chinese Academy of Sciences. And not just cannabis, but a strain bursting with CBN, the compound that forms after THC metabolizes. (These Jirzankal Cemetery samples contained, however, noticeably low levels of CBD—a medicinal, nonpsychoactive compound favored by some cannabis users.) Higher than what are typically found in regional, wild cannabis plants, the CBN levels suggest that the ancient grave keepers deliberately sought out these mind-altering varieties, and potentially even domesticated them.

Those elevated levels are what make this discovery so exciting and unique next to other confirmed examples of ancient cannabis, according to Mark Merlin, a professor of botany at the University of Hawaii at Mānoa. With those findings, says Merlin, a co-author of Cannabis: Evolution and Ethnobotany, determining the cannabis’s function was harder, as the samples weren’t so clearly tilted toward the psychoactive end of the spectrum. These results, meanwhile, are rather more persuasive, and suggest that ancient humans were lighting up to honor the dead long before that became a stoner’s cliché.

The excavations dug up more than just THC residue. Notably, analysis of human bones found at Jirzankal revealed that not all of the cemetery’s tenants had been born locally. This hint of ancient immigration supports the idea that the high-elevation Pamirs were once part of the Silk Road, along which goods and traditions passed between geographically distant communities. Spengler told reporters that these findings suggest that cannabis, and ideas regarding its various uses, may well have been among the items exchanged along the Silk Road. Another discovery supporting this idea—a grave in northwestern China laid with large cannabis plants—was described in 2016 by the archaeologist Hongen Jiang, another co-author of the new paper.

This new investigation of ancient cannabis use, says Patrick E. McGovern, the scientific director of the Biomolecular Archaeology Project at the Penn Museum, “is a much-needed contribution to our scientific understanding of the vast expanse of central Asia—some 4,000 miles from the Caucasus Mountains through the Pamirs and across the forbidding Taklamakan Desert. It provides yet another piece in the archaeological puzzle of the ‘abiding mystery of Central Asia’ and its impact on human cultural and biological development through the millennia.” But much more remains to be learned about the ways cannabis might have been used (perhaps as a medical additive or in fermented beverages) and the ways ideas about fermentation and the related domestication of plants moved across this area, without leaving their trace on artifacts. “We are still very much in the dark about the underlying dynamics of the transfer of fermented beverages and their mind-altering additives”—including cannabis—“from oasis to oasis along the prehistoric Silk Road and back into the Central Asian hinterland,” McGovern wrote in his book Uncorking the Past.

As tempting as it is chuckle at the thought of ancient drug use, Merlin says, viewing it as recreational is too simple, no matter how high the THC levels may be in these samples. What many see as the “recreational” nature of psychoactive drugs could have been a spiritual practice: a vessel for ushering the deceased safely into the afterlife, or for altering the mind in order to facilitate a closer conversation with the gods—much like a priest aims to do. Another indication of cannabis’s spiritual connotations is the centuries-old Chinese practice of wearing hemp—which is not psychoactive—while in mourning. (Merlin also posits that cannabis may have been used simply to deodorize corpses, though that’s likely not all it was doing at Jirzankal, given the THC levels.)

Further research could help give a clearer view of the plant’s ritual significance, but the traces of cannabis left on the braziers from Jirzankal Cemetery are enough to begin “to piece together an image” of cannabis-inflected funerary rites, the new paper’s authors write. The rituals, they think, might have included “flames, rhythmic music, and hallucinogen smoke, all intended to guide people into an altered state of mind.” Call it what you will, but that’s certainly something more than recreational.



It’s a four-hour drive from Toni Lyn Morelli’s home near Amherst, Massachusetts, to her field sites on the slopes of the White Mountains in New Hampshire. She rises long before dawn to make that drive, arriving by 8 a.m. to meet her student assistants. With her team assembled, Morelli, a research ecologist with the Department of the Interior’s Northeast Climate Adaptation Science Center, spends the day, and several more to come, livetrapping red squirrels, which she tags, radio-collars, measures, and releases.

Every three weeks, someone from her team returns, telemetry antennas in hand, to track how the animals are moving about the mountains. While red squirrels shift their distribution from year to year as spruces and other conifers they feed on shed their seeds, the climatic conditions they’re sensitive to aren’t changing uniformly. Observing how the squirrels move through this environment, then, will help the researchers find areas of relative stability. These are known as climate refugia.

“Refugia provide a safe haven during periods of an unfavorable climate,” Morelli and her co-authors wrote in the journal PLOS One in 2016. Indeed, such areas—whether they be on mountain slopes, in shady forests, or in deep, cool canyons—are characterized as being naturally buffered from local and regional climate changes. As global temperatures rise, these pockets could help to ensure the continued existence of valued species. In identifying refugia, Morelli and her collaborators—part of a cadre of conservation scientists working on this issue—hope their efforts will contribute to improvements in land management. “We’re looking to create a product that is as useful as possible,” Morelli says.

To be sure, those seeking to implement climate-mitigation strategies face challenges, particularly when it comes to federal property overseen by the current administration. Last month, the Bureau of Land Management published a plan to strip protections for the sage grouse—a ground-dwelling bird in the American West—to open up millions of acres to drilling and mining. And in 2017, President Donald Trump drastically reduced the size of two national monuments in Utah, shrinking Bears Ears National Monument and Grand Staircase-Escalante by 85 and 50 percent, respectively.

Still, in those areas that remain under protection, land managers play an important role in deciding how lands are allocated for conservation. Identifying and protecting refugia, Morelli admits, is not necessarily a long-term solution. But it can buy conservationists time to develop more comprehensive adaptation plans.

“On a certain timescale, everything will change,” she says. But land managers “are really on board with this and want to apply it under the existing management framework.”

The concept of climate refugia originated in the study of paleoecology, which looks at the relationships between organisms and their environment across geologic timescales. Research shows that we can credit these safe harbors with producing much of our planet’s biodiversity. The Great Smoky Mountains in the southeastern United States, for example, are home to one of the world’s most diverse temperate ecosystems because that range was a place of refuge during the glaciations and subsequent warming periods of the Pleistocene. Such areas occur from the Amazon to the Arctic, and millennia after the last glaciations they remain strongholds of biodiversity.

Today researchers have adopted the refugia model as a way to understand how species may (or may not) persist in our current era of climate change. “We’ve been working to move the theoretical concept of paleoclimate refugia into a modern context,” Morelli says of her work. “We are looking for areas where the ecological, physical, and even sociocultural aspects of the current climate will continue into the future.”

While large areas like the Smokies are relatively rare, refugia are not all that uncommon, particularly in mountainous landscapes. A mountain valley, for example, may receive the benefit of cold air descending from higher-elevation slopes or the cooling impact of a cold, spring-fed river. Mountaintops and high ridges can be refuges for alpine species. Even in the face of global change, such areas can remain relatively stable.

Through a combination of fieldwork, mapping, statistical modeling, and interdisciplinary collaboration, Morelli has been defining potential refugia in the Northeast, and working with fellow researchers on projects in western North America.

But the information she and other scientists are after does not come easily. “In many places, we just do not have the fine-scale data needed to map these attributes,” Morelli says. “We just don’t know enough about what is there now, let alone what will be there in the future. For ecology and behavior, we need supportive research.” Trying to understand the survival threshold for every species in a study area is all but impossible. As a shortcut, then, researchers look for a representative species—a creature well studied and understood, or one confined to a specific habitat. They might also look for a species that, like the red squirrel in the Northeast, can tell us something about the forests in which it lives—an indicator for the ecosystem as a whole.

In addition to her work in the eastern United States, Morelli has also studied potential refugia high in the mountains of California’s Sierra Nevada. The Belding’s ground squirrel makes its home in these meadows. A true hibernator, the species is awake for as little as three months a year, during which time it must forage, put on sufficient fat, breed, and construct underground burrows. The squirrels rely on snowpack for efficient hibernation. Too little snow, or midwinter melts, and they find themselves exposed to dangerous shifts in the temperatures outside. However, if snowpack remains stable, Belding’s ground squirrels survive, and co-existing species are likely to persist as well. Morelli describes Belding’s squirrels as having a narrow “pinch point”—if their environment falls much outside of a certain range, they can no longer survive.

Rather than looking at single species or even a single habitat within the Sierra Nevada, Julia Michalak, a research scientist at the University of Washington’s Urban Ecology Research Laboratory, takes a broader approach, employing geographic information systems, a tool for building digital maps of the environment. Placing a grid overlay upon a map of the Sierras and indexing each cell according to the existing climate, Michalak can flag areas that warm or cool less than 1 degree Celsius and have little or no change in precipitation as potential refugia.

Finding refugia is about defining thresholds, Michalak says. “We looked at historic range boundaries of a whole bunch of different species—trees, amphibians, birds, and mammals—and calculated a metric of precipitation and temperature variables,” she says. Using these two important climate metrics, Michalak says, researchers can apply different climate scenarios to determine how the landscape will change or not. Just how those thresholds are set, however, “can really affect how many refugia or analogous climates are found,” Michalak notes.

Of course, defining potential refugia based on arbitrary assignments of what is an acceptable change in temperature or precipitation is problematic. After all, what seems a minor change from the perspective of a computer model may push a species across ecological thresholds where it can no longer survive. But factoring in the historic data, Michalak says, can help make those thresholds less arbitrary and more biologically informed. Still, one of the biggest challenges, she admits, is working with “a limited understanding of how any individual species will respond.” That includes species like the Belding’s ground squirrel.

If models indicate that snowpack will be consistent and sufficient for the squirrel’s survival, then those areas are almost certain to be effective refugia. The combination of Morelli’s and Michalak’s differing strategies may be one of the most effective methods to find natural areas resistant to climate change. In such areas, alpine meadows, the squirrels, wildflowers, and innumerable other dependent species may persist, even if surrounded by shifting ecosystems.

While it may be hard to square why society should value such species, or care if their habitats disappear, conservationists say their fates may be indicative of our own. Belding’s ground squirrels’ survival depends on snowpack, and that same snowpack provides water to parched communities in the West. If researchers like Michalak and Morelli can determine where Belding’s ground squirrels are likely to survive, then that information could also be used to predict which rivers and streams will continue to flow through the summer, providing much-needed water to the farms, ranches, and towns in the valleys below. Back in the Northeast, red squirrels serve as an indicator of the health of the boreal forest ecosystem, reflecting how the economies that depend on it (namely, timber and tourism) will fare.

Even with refugia identified, however, simply setting land aside is not enough. While many potential refugia fall in mountainous areas that bear some level of protection as public lands, Carlos Carroll, a conservation biologist at the Klamath Center for Conservation Research in California, notes that “in order to move to and between refugia, [some] species will be forced into unprotected lowland areas.” Assuring the existence of intact corridors, then, may be as important as conserving the refugia themselves.

“That,” Carroll says, “is a much greater conservation challenge.”



This post appears courtesy of Undark Magazine.



Imagine going to live on a planet where the sun never moves in the sky. No sunrise, no sunset.

Several years ago, I became obsessed with tidally locked planets. The notion of a world permanently caught between two extremes—with one half always illuminated, the other always in the dark—took hold of my imagination. I realized that planets like these were the surest bet in the search for Earth-like places that our descendants could settle on. Worlds of eternal darkness and never-ending sunlight could be the future of the human race—if we’re serious about living in other solar systems.

Astronomers believe that most of the planets in our galaxy that have Earth-like temperatures are likely to be tidally locked. Because their orbital period is the same as their period of rotation, these planets will always present the same face to their sun—just as we always see the same side of the moon, as it orbits Earth.

And the reason for this glut of tidally locked worlds is pretty simple. Up to three-quarters of suns in our galaxy are red dwarfs, or “M-dwarfs,” smaller and cooler than our sun. Any planet orbiting one of these M-dwarfs would need to be much closer to its star to support human life—as close as Mercury is to our sun. And at that distance, the star’s gravity would pull it into a tidally locked orbit.

For example, astronomers recently discovered seven Earth-size planets in the habitable zone of the TRAPPIST-1 system, all of which are likely to be tidally locked.

My obsession with these planets led to my new novel, The City in the Middle of the Night. To picture all their strange geological features and weird knock-on effects, I talked to Lindy Elkins-Tanton, the director of the School of Earth and Space Exploration at Arizona State University, as well as other scientists studying them, and I read as much of the latest research as I could. More than anything else, I became captivated by trying to imagine what it would be like for people living on a planet where the sky never changes.

For now, talking about these planets means indulging in speculation—which is the perfect situation for a science-fiction writer. But we are learning enough about the dynamics of tidally locked worlds to start to understand how they would work, and what kind of civilization we could build there.

The first question: Where would humans settle on a tidally locked planet? When I started working on my book, the clearest answer appeared to be the terminator, the strip of twilight between the dayside and the nightside. “That might be the Goldilocks zone,” neither too hot nor too cold, but stuck “between eternal dusk and eternal dawn,” says Daniel Angerhausen, an astrophysicist at the Center for Space and Habitability at Bern University.

In the terminator zone, Angerhausen suggests, humans might be able to generate geothermal energy, using cold water from the nightside and hot water from the dayside in “some kind of thermal reactor.”

To have access to liquid water on a tidally locked world, you need a system to cool down the dayside and heat up the nightside, says Ludmila Carone of the Max Planck Institute for Astronomy. Otherwise, all the liquid might become tied up in ice on the nightside, or worse yet, the atmosphere itself could get frozen in the dark.

“The habitability of these planets hinges very strongly on how well you can transport heat,” Carone says. Her computer models show that a tidally locked planet might have two strong wind jets, one in each hemisphere, that might act a bit like the jet stream here on Earth. But if the planet is too close to the sun, it might have only one wind jet, directly over the part closest to the sun. In that scenario, heat could be trapped on the dayside.

Even a relatively modest temperature differential (say, 50 degrees Fahrenheit) between the two sides could make these planets harder to live on. A comfortably mild climate on the dayside might still leave the nightside cold enough to freeze water, according to Laura Kreidberg, a junior fellow at Harvard University who studies the atmospheres of exoplanets. “Could all the planet’s water freeze out on the nightside? We don’t yet know,” she says. Ocean currents could help transport heat, too, but those effects depend on how much water the planet has to begin with and where the continents are.

One possible scenario for a tidally locked planet is what’s known as the “eyeball Earth” model, in which a planet starts out entirely covered with ice—which then melts on the side facing the sun. To an observer from space, this could look like an eyeball, explains Angerhausen. Or, with an ocean that transports enough heat, you could end up with a lobster-shaped ocean surrounded by ice.

In the most extreme scenarios, the heat on the light side becomes so extreme that water can’t exist. But with enough of a temperature difference, it can re-form on the nightside.

That’s what happens on a tidally locked planet called WASP-103b, a “hot Jupiter”–type world. According to Vivien Parmentier at Aix Marseille University, an author (along with Kreidberg) on a recent study of WASP-103b, water molecules are destroyed on the dayside of the planet, only to drift back to the nightside and recombine into water molecules that form clouds ... and then the process repeats.

Beyond the problems with finding liquid water, a tidally locked world around a red dwarf could have other issues, says Carone. Red dwarfs are “notoriously temperamental” and tend to go through long phases in which they flare up and eject material into space.

These flare-ups could heat the atmosphere of a planet in the habitable zone, while the star could also eject material that strips away the atmosphere. This happened to Earth early on, when our original atmosphere was torn away from us. Afterward, Earth “sweated out” another atmosphere from trapped carbon dioxide. But on a tidally locked world, a violent-enough solar disruption could get rid of a second atmosphere, too.

Even with an atmosphere, the dayside of the planet could be exposed to deadly radiation, says Parmentier. The light from a red dwarf wouldn’t provide enough of the UV wavelengths needed to make ozone—so this planet, unlike Earth, might not have an ozone layer. (In my novel, direct sunlight isn’t just too hot; it actually causes nasty burns, so people have to stay in the shade.)

Any humans living on the planet would also need to eat and breathe, and the physicists Joseph Gale and Amri Wandel of Hebrew University have been studying whether plant life could survive the flares and radiation exposure. At first, plants might evolve in the ocean to take advantage of the protective layer of water. But eventually, if the star became less violent, the planet could develop an atmosphere thick enough to allow plants to grow on land. Gale and Wandel have also calculated that there would probably be enough light in the visible spectrum to allow normal photosynthesis.

With an atmosphere that could sustain life, though, there would also be air currents strong enough to cool the planet’s dayside. The temperature might end up being about the same as in Earth’s tropical regions. An atmosphere could also help create a layer of cloud that would serve as a permanent sun shade. As scientists such as Carone have been making computer models of tidally locked worlds, they increasingly believe humans could live outside the terminator region.

Adiv Paradise, a Ph.D. student in astronomy and astrophysics at the University of Toronto, has a guess at what that could look like: People might live on the dayside, but would need to construct mining and pipeline operations to bring ice over from the nightside. A lot depends on how bad the radiation bombardment on the dayside might be. Paradise also thinks people could learn to live on the frozen nightside: “I’m from Minnesota. People manage to live in all sorts of places astronomers would describe as ‘not habitable.’”

The biggest challenge for humans living in a tidally locked world, says Paradise, could be the very different sky. If they lived on the dayside, they might “lose all knowledge of the universe,” because they would never see the stars. Their perception of the passage of time would also be altered, because “nothing in the sky would ever change.”

Inspired by these concerns, in The City in the Middle of the Night, I created two different human societies with wildly divergent approaches to the problem of circadian rhythms and the passage of time. And my human settlers definitely take advantage of the temperature differentials to create geothermal power, as Angerhausen suggests. Still, my tidally locked world didn’t reflect these more recent computer models and ended up being a little more fanciful in some of the details. There’s always a trade-off between scientific accuracy and storytelling, and in some ways, I may have ended up writing a bit of an exoplanet fable.

But I wanted to help people imagine the strangeness, terror, and splendor of inhabiting a planet that orbits an alien star. I believe that novels about tidally locked worlds will become a fast-growing subgenre as we make more discoveries and gather more observational data. There are so many great stories to be told about visiting these worlds of never-ending sunlight and darkness. And dreaming about life on another planet is a way of thinking about our own place in the universe, as humans, both now and in the millennia to come.



Even before he was born, it was clear that the boy’s brain was unusual—so much so that his expecting parents flew from rural Alaska to Seattle, where specialists could attend to their son from birth. That is how James Bennett first met the boy, then a days-old infant struggling to breathe. The baby’s head was too big. The structures in his brain looked wrong. Bennett, a pediatric geneticist at Seattle Children’s, was tasked with figuring out why.

The answer was ultimately stranger than doctors could have imagined: The boy’s brain was missing an entire type of cell, called microglia, the result of mutations in a single gene, called CSF1R. Doctors had never seen anything like it.

Microglia make up 10 percent of the brain’s cells, but they are not neurons and therefore have long been overlooked. The boy’s case makes their importance unmistakable. In the absence of microglia, the boy’s neurons still grew to fill his skull, but they ended up in the wrong places and made the wrong connections. Microglia, scientists have started to realize, guide the development of the brain.

“There wasn’t any part of the brain that wasn’t involved and affected in this child,” Bennett says. A part of the baby’s cerebellum jutted at an odd angle. His ventricles, normally small fluid-filled cavities in the brain, were too large. And a dense bundle of nerves that is supposed to connect the brain’s left and right hemispheres, called the corpus callosum, had entirely failed to develop.

In petri dishes and in animals, scientists had previously observed how microglia guide developing neurons to the right locations, creating the highly organized layers that make up the brain. They also prune connections between neurons. “Things get off track pretty quickly when you start manipulating the functions of microglia,” says Stephen Noctor, a developmental neurobiologist at the University of California at Davis who was not involved in examining the boy. To better understand the CSF1R gene, Bennett teamed up with zebra-fish biologists. In fish, turning off the gene disrupts a cellular pathway necessary for corpus-callosum neurons to grow in humans.

Kim Green, a neurobiologist at the University of California at Irvine, notes that mutant mice lacking microglia have broadly similar patterns of disorganization in their brains. These mice models essentially predicted what would happen in a human. Green had just never expected to see a person without microglia. “It’s absolutely remarkable,” he says.

The boy’s brain helped unlock these scientific mysteries. But he was ultimately still a boy, a very sick one with worried young parents. Their son’s condition was so severe, it turns out, because he had inherited two faulty copies of the CSF1R gene—one from each parent. His parents happened to carry the same rare mutation because they are cousins.

In adults, just one copy of a CSF1R mutation can lead to a brain disorder called adult-onset leukoencephalopathy with axonal spheroids and pigmented glia, which causes memory loss and eventually dementia beginning in one’s 40s. When the boy’s DNA-sequencing results came back, Bennett realized that he had to explain to the parents their own CSF1R mutation and their risks of developing the disorder. They were relieved, he says, to understand what was wrong with their child, but perhaps too overwhelmed to fully take in what it meant for their lives. The couple spoke with a genetic counselor before their son’s DNA sequencing, and Bennett says he arranged to have them meet with another genetic counselor back in Alaska, where they returned home.

This story has no miracle cure or happy ending. The boy died in Alaska at 10 months old of likely related causes, and Bennett says the family agreed to an autopsy. They have since lost touch. The phone numbers he has for them no longer work. He told me that he recently got hold of the mother’s sister, in an attempt to tell the family about the research made possible by their child. It’s a delicate balance: He feels a duty to inform, but he understands that the parents might not want to be reminded of their dead son.

A pediatric geneticist’s job, Bennett said, is often to diagnose extremely rare conditions, which push up against the limits of the human body. “On any day, you can find a patient you spend the rest of your career thinking about,” he said. The boy is one of them.



Earlier this week, a pair of raccoon dogs were reported to be “terrorising” a village in the United Kingdom after they escaped from a nearby enclosure. Raccoon dogs, also called tanukis, look like supermodel raccoons with their lanky limbs, slender necks, and soulful eyes. But they’re actually wild canines, most closely related to foxes. The stories that came out of Nottinghamshire—a goat and pony attacked, a dog walker spooked, the invading beasts chased off with big pieces of wood—demonstrate all the ways you shouldn’t interact with tanukis. But if one did need to keep a raccoon dog happy, fed, and well tended, how would a responsible animal caretaker do it right?

I asked Rebecca Snyder, the curator of science and conservation at the Oklahoma City Zoo and Botanical Garden. She’s also the former curator of mammals at Zoo Atlanta, where she worked directly with raccoon dogs for several years. They’re native to eastern Asia, but have also been introduced to Europe. In the United States, Oklahoma City and Atlanta are the only two accredited zoos that have raccoon dogs in their collection.

Snyder told me that the animals are curious yet shy, fun to take care of, and have the potential to wreak havoc if they get out—not just the kind the residents of Nottinghamshire experienced, but ecological havoc as well.

This interview has been edited for length and clarity.

Rachel Gutman: What is taking care of raccoon dogs like?

Rebecca Snyder: They’re a small, wild canid, so they’re curious, they’re intelligent, and they’re pretty easy to train. And we found them to be really inquisitive, so they were fun to work with. Pretty much anything you put in their exhibit, they will explore and play with.

Gutman: How does interacting with a raccoon dog compare with interacting with a normal dog that you’d have as a pet?

Snyder: They’re wild animals. So we don’t treat them like pets. We typically don’t encourage them to touch us, and we don’t often touch them unless it’s for a medical check or procedure. So they’re curious and smart like a domestic dog would be, but we don’t pet them or play with them. They’re unpredictable and a little shy.

Gutman: When you worked with the raccoon dogs at Zoo Atlanta, what kinds of things would you do to keep them happy and stimulated?

Snyder: We gave them lots of different toys and things. We did use toys that you would use with dogs. They like those kinds of things to chew on and carry around and play with. Pretty much any kind of object that we put in there, they were interested in. We also sprayed scents in their enclosure because, like other carnivores, they use their olfactory sense a lot. So they’re curious about smelling new smells. We put bedding from other animals in there [for them] to investigate.

Gutman: How would they react to that?

Snyder: They’re just interested in everything. So they just smell and explore new things. They like to chew things up and carry things around.

Gutman: Sounds like a dog. Are they aggressive in the wild?

Snyder: No. They’re very similar to the red fox that we have here in the United States. They’d mostly avoid people, they’d be active when people aren’t around, and they would just be looking for any kind of food source that was available to them.

Gutman: Is it possible to keep a raccoon dog as a pet?

Snyder: You have to have a special permit from the U.S. Fish and Wildlife Service to have them in the United States. USFWS classifies them as injurious wildlife. That doesn’t mean that they are capable of causing great injury. Basically it means that because they’re so omnivorous and they adapt really well to a wide variety of environments and they do well in urban areas, they have the ability to become an invasive species.

Gutman: According to news reports, the raccoon dogs on the loose in the U.K. “dug out” of their enclosure. Are they big diggers?

Snyder: I actually don’t consider them to be especially good at digging. I don’t know what kind of enclosure they were in that they were able to dig out of; we don’t know how secure that was. But they don’t typically dig big burrows or anything like that.

Gutman: What kind of precautions do zoos take to make sure they don’t get out?

Snyder: In the U.S., you have to have a double-containment system. So that means you just have to have two barriers all the time. [At Zoo Atlanta and the Oklahoma City Zoo], all of those enclosures would have what we call a dig barrier. So that would be fencing that goes underneath the ground that prevents the animals from being able to dig out.

Gutman: One eyewitness in the U.K. told The Independent that one of the escaped raccoon dogs attacked her goat, and was acting very aggressively. As she said, “It was absolutely crazy. It was hissing and screaming and snarling. It was going absolutely mad.” Is that behavior consistent with what you’ve seen from the zoos’ raccoon dogs?

Snyder: I think that would be an unusually large animal for a raccoon dog to try to overcome.

Gutman: In what kind of situation would it go after something like a goat?

Snyder: I can’t imagine that it would. That would be more like the behavior of a coyote. In my experience with raccoon dogs, I can’t imagine that.

Gutman: What about the snarling and hissing?

Snyder: [Laughs.] If the animal felt threatened, it might hiss and snarl and growl. We don’t really see that in the zoo, because we’re not ever putting the animal in a situation where it really feels threatened by us. That would happen, I think, if somebody tried to capture one, or cornered it, or something; it might be vocalizing and trying to defend itself. But we don’t put them in that situation in the zoo.



Here is the hypothesis: Not so long ago, the very nature of planet Earth suffered a devastating rupture. The break was sudden, global, and irreversible. It happened on a Sunday within living memory. Mick Jagger, Meryl Streep, and Caitlyn Jenner were all born before this crack in time. Vladimir Putin, Liam Neeson, and Mr. T were all born after it.

That idea might soon carry the weight of scientific fact. Later this month, a committee of researchers from around the world will decide whether the Earth sprang into the Anthropocene, a new chapter of its history, in the year 1950. If accepted, this delineation will signal a new reality, that human activities, not natural processes, are now the dominant driver of change on Earth’s surface—that carbon pollution, climate change, deforestation, factory farms, mass die-offs, and enormous road networks have made a greater imprint on the planet than any other force in the past 12,000 years.

Starting next week, the committee’s 37 members will vote on two questions. First, should the Anthropocene be added as a new epoch to the Geological Time Scale, the standard scientific timeline of Earth’s 4.5-billion-year history? Second, should the Anthropocene, if it does exist, commence in the middle of the 20th century?

William Ruddiman, a professor of environmental sciences at the University of Virginia, is extremely worried about climate change, but he nonetheless hopes the committee votes against both questions. For the past two years, he has lobbied its members to think of the Anthropocene not as a sudden upheaval, but as a gradual change, a slow transformation of the planet that began 5,000 years ago. “Where could you possibly pick a single start date in this ever-evolving story?” he once asked me in an email.

Last week, he and 23 other researchers argued the topic at length in the scientific journal Progress in Physical Geography. At stake is a seemingly simple question: When did human influence over the environment reach a tipping point?

For Jan Zalasiewicz, a professor of geography at the University of Leicester, the answer is clear. Zalasiewicz chairs the Anthropocene Working Group, the committee that will soon vote on the existence of the epoch.

“If you look at the main parameters of the Earth-system metabolism, then … things only began to change sharply and dramatically with industrialization,” he told me. He believes that the most significant event in humanity’s life on the planet is the Great Acceleration, the period of rapid global industrialization that followed the Second World War. As factories and cars spread across the planet, as the United States and U.S.S.R. prepared for the Cold War, carbon pollution soared. So too did methane pollution, the number of extinctions and invasive species, the degree of surface-level radiation, the quantity of plastic in the ocean, and the amount of rock and soil moved around the planet.

It was “the Big Zoom,” he said, borrowing a phrase from the journalist Andrew Revkin. There is “nothing really comparable” to that shift in any other period of Earth history. Even setting carbon pollution aside, he said, the spike in fertilizer use led to the largest jump in surface nitrogen levels in 2.5 billion years. Zalasiewicz hopes the committee will start the Anthropocene in the middle of the 20th century.

Ruddiman isn’t so sure. He believes that humanity’s effect on the planet is spread throughout time and is driven primarily by agriculture. Before the year 1750, he argues, humans had already cleared so much forest as to produce 300 billion tons of carbon emissions. Since 1950, deforestation has only led to 75 billion tons of emissions.

Humans remade the planet in other ways, too. About 12,000 years ago, we drove a huge swath of American mammals, including the giant ground sloth, into extinction. About 11,000 years ago, we entered into unprecedented relationships with crops and some livestock, domesticating them and taming their genome. Between 6,000 and 7,000 years ago, humans began clear-cutting forests to create new agricultural land; they may have transformed much of Europe by doing so. And by about 1,000 years ago, as humans embraced tilling and made rice paddies, they began moving more dirt and rock around the surface of the planet than is moved naturally.

“I don’t think it’s possible to put an exact date” on the Anthropocene, Ruddiman told me last week. “It goes on continuously for 12,000 years. There’s no obvious break point. Even just the invention of tilling—it’s huge.” For that reason, he believes that the committee shouldn’t add a capital-A Anthropocene to the geological timeline. Instead, scientists should talk about the “lower-a anthropocene”—a set of profound changes wrought to Earth over the course of millennia, across many different places. They culminate in the biggest anthropocene of all: modern, human-caused climate change.

It is important to say modern, for Ruddiman believes that humans have already shifted the climate once before. About a decade ago, he proposed what’s called the “early anthropocene hypothesis”—a theory that ancient agricultural clear-cutting added so much carbon to the atmosphere that it effectively stopped Arctic glaciers from expanding more than 3,000 years ago. If not for that deforestation, then there would be an additional Greenland’s worth of ice in the Canadian Arctic today, he said.

While Ruddiman’s hypothesis is not widely accepted, it is taken seriously by the community. And his broader skepticism of codifying a late Anthropocene is shared by several members of the working group. In a separate paper published last week, five members of the committee rejected the idea of the 1950s Anthropocene. Today’s scientists are simply too close to the events at hand to place a division in geological time, they argue. We don’t yet know how significantly the planet’s climate will change in the centuries to come: Will the shift be of the same magnitude as what occurred at the end of the last Ice Age, 12,000 years ago? Will it be equal to the first time that ice seized the surface of Earth, 2.1 million years ago? Or does it signal something far larger, a cataclysm on par with the asteroid impact that ended the dinosaur-dominated Mesozoic Era, 66 million years ago? “There is no testable way of knowing at present,” they wrote.

The five authors also point out that the last 12,000 years would be understood as a single geological instant if they had happened millions of years ago. (Indeed, it would be one of the most shocking geological moments in the whole rock record.) And they worry about the sudden divisions that a great split in 1950 would impose on geology. If the Anthropocene is adopted as a formal time division, it will mean that any process that began in 1947 and ended in 1953 would straddle two epochs.   

So far, the committee at large has not seemed to accept these criticisms. In another paper published last week, Zalasiewicz and 16 of his colleagues wrote that any human-induced changes prior to 1950 paled in comparison with those that came after.

“The difference between before and what’s happening now … it’s geologically quite dramatic,” Zalasiewicz told me. “We hadn’t realized that at the beginning. In 2009, I didn’t know that the Anthropocene would be as clear and sharp as it has been. I thought it might fade away into a fuzzy gradational change.” Instead, the committee has accumulated more and more evidence that a new epoch lurched into existence during the mid-20th century, he said.

Carbon pollution, methane pollution, and world population all spiked after 1950 as they never had before, he argues. Ruddiman told me he doubted some of the committee’s reconstructions of human population, but appreciated their “good-faith effort to respond.”

The idea of the Anthropocene was first proposed by the Nobel-winning chemist Paul Crutzen in 2000. Since then, it has caught on more broadly in culture, even though it is not a formal term in geology. (The musician Grimes is releasing an Anthropocene-themed album later this year.) But it could soon have its day: If the working group accepts its existence, that will clear the way for the International Commission on Stratigraphy and the International Union of Geological Sciences to accept it in full.

Of the working group’s 37 members, 17 members signed their name to Zalasiewicz’s paper, and only five signed their name to the more skeptical review. That leaves 15 committee members unaligned in advance of the upcoming vote. “You’d think people who served on a committee for years would be more willing to put their name on paper,” Ruddiman said. The vote will take place electronically and continue through May. If it succeeds, then the committee will busy itself with the next task: finding evidence in the rock record of the precise moment that humanity pushed Earth into a bewildering new era.



Updated at 11:35 a.m. ET on January 11.

On the afternoon of the failed launch, Jim Bridenstine of NASA and Dmitry Rogozin of Roscosmos had only known each other for a few days. Less than one mile from the launchpad, the heads of the American and Russian space agencies watched as the Soyuz system lofted the crew, one man from each country, into the blue sky over Kazakhstan.

But then, inside the crew capsule, alarms blared and emergency lights flashed. Instead of climbing into space, the capsule began to plunge back to Earth. In those stressful moments—before the capsule parachuted gently to the ground, before rescue crews arrived, before the would-be space travelers reunited with their family—each official considered what he might say if the failed launch ended in tragedy.

“If we’re going to strengthen the partnership with the United States and Russia on space exploration, I think this was probably one way to do it,” Bridenstine told me later, after he had returned to the United States. “Everybody became a lot closer on this day.”

On the ground, the United States and Russia might have conflicting interests, but in space, 250 miles above Earth, they get along nicely. On the International Space Station, American astronauts and Russian cosmonauts share meals, routines, and a stunning view of our little planet. That same spirit of cooperation characterized the handling of the failed launch in October—the quick rescue response, the careful investigation of hardware, the eventual return to spaceflight less than two months later—and after Bridenstine’s visit to Russia, he sought to reciprocate the invitation. Bridenstine had addressed Rogozin’s alma mater, Moscow State University, and he suggested that in early 2019 Rogozin deliver a speech at his own, Rice University in Texas.*

But even in a bromance as sunny as this one, sometimes politics finds a way to creep in, and Bridenstine rescinded his invitation. And according to Russian media, Rogozin isn’t happy about it.

Some current members of Congress and former national-security officials, mostly Democrats, saw the proposed visit as a mistake, Politico reported, and more lawmakers soon joined the chorus of opposition. The issue: Rogozin is not a typical space-agency official. He’s an outspoken nationalist and a former deputy prime minister to Vladimir Putin who was sanctioned by the United States in 2014 for his involvement in the Ukraine crisis. Those strictures bar Rogozin from entering the United States, and here was Bridenstine, inviting Rogozin to an American campus and telling Russian media that he had convinced the Treasury Department to temporarily lift the sanctions.

“Rice University is located on the same street as the Johnson Space Flight Center, so I think everything will work out,” Bridenstine said while in Russia, according to TASS, the state-run Russian news agency.

Earlier in 2018, another sanctioned Russian official, Sergey Naryshkin, the head of Russia’s foreign-intelligence service, had come to Washington for a secretive meeting with then–CIA Director Mike Pompeo. Democratic lawmakers protested, accusing Donald Trump’s administration of undermining U.S. policy. But a meeting about space exploration must have seemed less fraught than one on counterterrorism. According to The Washington Post, Bridenstine, a former member of Congress himself, said he didn’t consult with the White House about inviting—and disinviting—Rogozin. He had hoped they could have “a strong working relationship that was kept separate from geopolitics,” he said.

Space exploration is indeed insulated at times from politics, but it is not immune. In the middle of the 20th century, when nations began trying to reach orbit, space policy was foreign policy, thanks to the two-faced nature of the effort; rockets could launch both science instruments and bombs. But even as the focus of space policy has shifted to scientific discovery, world events and political changes have often derailed the United States’ and Russia’s best intentions.

As early as 1962, at the height of the space race between the United States and the Soviet Union, President John F. Kennedy and Premier Nikita Khrushchev exchanged letters about working together on uncomplicated space matters, such as weather satellites. But earnest cooperation didn’t emerge until 1970, after Americans had landed on the moon and there was little left to compete over. President Richard Nixon had a new policy of closer relations with the Soviet Union, and he thought an international space project would be a political winner. (The world may have Hollywood to thank for this, too: According to historians, the Soviets warmed up to the idea after U.S. officials invoked Marooned, the 1969 film in which Soviet cosmonauts help rescue stranded American astronauts.)

Soon, talks led to a high-flying maneuver between American and Soviet spacecraft in 1975. Two capsules launched 10,000 miles apart, rendezvoused in space, and locked onto each other somewhere over the Atlantic Ocean. Astronauts and cosmonauts on either side opened the hatches and exchanged handshakes.

The mission was heralded as a historic moment of unity between spacefaring nations, and plans for collaboration picked up. Officials discussed the possibility of docking an American launch vehicle, the Space Shuttle, to the Russian space station, Salyut. But the election of Jimmy Carter slowed these plans. Unlike his predecessor, Carter disliked the idea of exchanging technical information. Then, in 1979, the Soviet Union invaded Afghanistan, and by the next summer the U.S. government was boycotting the Olympic Games in Moscow instead of brainstorming space missions.

Only after the dissolution of the Soviet Union did the most significant partnerships begin to take shape. In the early 1990s, the United States sought to build an international space station and invited Russia to join, along with Japan, Canada, and nine European nations. It was a self-serving decision; while showing support for a country in crisis, the United States would also gain access to impressive space technology, reduce costs, and employ former Soviet scientists and engineers who might otherwise work for enemy governments. That politically motivated choice, though, has led to decades of productive collaboration. Today the International Space Station has been continuously occupied, by rotating crews from both nations, for 18 years.

The American-Russian partnership was tested in the spring of 2014, though. After Russia’s unlawful annexation of Crimea, the United States cut Putin out of global meetings and imposed punitive measures against his cronies. The disintegrating diplomatic relations raised concerns about the International Space Station. By then, the space shuttles that had transported Americans to space for decades were sitting in museums. The U.S. government now relied on the Russian Soyuz system, which cost American taxpayers $70 million a seat. NASA officials, flooded with questions, tried to assuage concerns, while Rogozin, in response to U.S. sanctions prohibiting work with Russian aerospace companies, wrote, “After analyzing the sanctions against our space industry, I suggest the U.S. delivers its astronauts to the ISS with a trampoline.”

Before he traveled to Russia last year, Bridenstine was asked about this and other inflammatory tweets, including one in which Rogozin, annoyed that the United States had asked Romania to bar his plane from entering the country’s airspace, joked that he would fly in on a bomber next time. Bridenstine downplayed Rogozin’s combative remarks as the grit of any elected official, whether in the House of Representatives or the Duma. “Some of his language has historically been aggressive about the United States,” he told SpaceNews. “Some of my language has been aggressive about activities of Russia.”

Bridenstine’s professional relationship with Rogozin began with a beguiling incident last summer. The International Space Station crew discovered a tiny hole in the Russian segment that was leaking pressurized air into space. It appeared to have been drilled. While Russian officials investigated, Rogozin speculated to the press: “What was it: a defect, or some intentional acts? Where were these acts carried out? On the Earth or already on the orbit? Yet again, I am saying: We are not dismissing anything.”

The remarks quickly mutated into rumors of sabotage. Bridenstine and Rogozin scheduled a phone call, their first, and released a joint statement that promised no further speculation until an investigation was complete. Russian cosmonauts patched up the hole and even conducted a spacewalk to investigate it, but the cause remains unknown.

After Bridenstine’s bungled invitation to Rogozin, though, the burgeoning relationship between the space-agency leaders may be under strain. A Roscosmos spokesperson told Russian media that Bridenstine hadn’t talked to Roscosmos before the Post ran a story about Bridenstine’s decision to cancel. Rogozin criticized the decision in a television interview on Thursday, according to The Moscow Times, calling it a “disgrace” and “complete international lawlessness.” “We are waiting for an explanation,” he said, adding that Bridenstine is welcome to return to Russia.

The NASA administrator’s office did not respond to a request for comment on this claim.

This tension is particularly awkward in light of the precarious future of American spaceflight. Today Russia has leverage. The U.S. government still pays to launch NASA astronauts to the ISS, at $80 million a seat now. This arrangement has persisted far longer than American politicians would like, and in 2014, NASA awarded two American companies, Boeing and SpaceX, billions of dollars to develop transportation systems that would launch from U.S. soil. This effort, known as the Commercial Crew Program, is scheduled to finally get off the ground this year. The first SpaceX test flight, without a crew, is expected in February. If those flights go well, the United States could ditch its reliance on Russia.

Meanwhile, on the ISS, it’s business as usual. The current residents include an American and a Russian, working together, sharing meals, and splitting housekeeping chores such as vacuuming while their respective governments feud over matters from trade tariffs to election interference. Someday, like previous space stations, the ISS may be abandoned and deliberately plunged into the ocean. Or if future generations come up with some way to preserve it, perhaps in an orbiting museum, the ISS may keep circling Earth for centuries. Whether the station will be considered a vestige of long-lost cooperation or a mark of continued partnership depends on what happens below.

* This article originally misstated the location of Rice University. 



When Jennifer Leyton was going through IVF, her doctors would tell her very little. They turned off the ultrasound screen facing her so she could not count the number of eggs retrieved. They kept secret the number of fertilized embryos. They did not even say how many they transferred to her womb. This secrecy might have been maddening for many IVF patients, but for Leyton, it was her choice.

She chose secrecy because she wanted to avoid finding out whether she had inherited a mutation for Huntington’s. The neurological disease usually manifests between ages 30 and 50—with a jerky movement, or a slurred phrase—and progresses as the cells in the brain slowly die. She was still healthy, but her chances of having inherited her mother’s Huntington’s mutation were 50-50. Over a decade and a half, Leyton had watched as her mother’s hands became unsteady, dropping cigarettes that set her clothing on fire. She lost her driver’s license. She eventually stopped walking. The disease is always fatal.

Leyton did not want this fate for her future children. So she found a fertility clinic three states away that would perform in vitro fertilization, screen the resulting embryos for the Huntington’s mutation, and transfer only the healthy ones. Lastly, because she might deduce whether she herself carried the mutation by comparing the number of embryos fertilized with the number transferred, the clinic would give her none of the usual updates during the IVF process.

“I didn’t want to spend my time calculating whether or not I had the gene,” she says. She was okay with the secrecy. She was okay with undergoing IVF—even though she could have kids naturally if she got tested and found out she was negative for the Huntington’s mutation. But getting tested meant a 50-50 chance of finding out she was positive. She couldn’t risk that.

Not wanting to know is quite common among people at risk for Huntington’s. A genetic test that predicts almost perfectly whether someone will develop the disease has been available since the late 1980s, but only 8 percent of people at risk choose to test, according to the Huntington’s Disease Society of America. There is currently no cure for Huntington’s, and very little can be done for anyone with the disease. All someone at risk for Huntington’s might gain is certainty of how he or she will die. For this reason, a niche IVF market has sprung up for people like Leyton who want no foresight of their own future but want to keep their children from ever worrying about the disease.

After creating embryos through IVF, a patient can choose to screen them through a procedure called nondisclosure preimplantation genetic testing for monogenic disorders, or PGT-M. (It is also sometimes called preimplantation genetic diagnosis or PGD.) Most people who get PGT-M for Huntington’s are already aware of their status, and do not want to pass on the risk to their children.

Nondisclosure PGT-M is for people who do not want to know their status. These procedures are quite rare, but they exist in possibly one of the most unusual corners of modern medicine—where information is deliberately kept from the patient.

Leyton was one of the first people to undergo nondisclosure testing for Huntington’s in the late 1990s. She was living in New York at the time, but the only clinic she could find offering the procedure was the Genetics & IVF Institute in Fairfax, Virginia. She and her husband got extremely familiar with the drive down from New York. To monitor her hormone levels in between, she would regularly get her blood drawn in New York City and FedEx it to Fairfax. “You would have thought I was the dumbest person on Earth,” she says of having to mail her blood to Virginia. “All I wanted was to have a baby.” She ultimately had healthy twins, a boy and a girl.

Leyton chose what’s called direct nondisclosure testing, in which doctors would find out her Huntington’s status but keep it from her. Doctors at the Genetics & IVF Institute first proposed using this type of testing for Huntington’s in a 1996 paper. It was controversial, especially in Europe. Physicians there objected particularly to mock transfers, in which the fertility clinic still pretends to implant embryos, even if none of the resulting embryos are free of the Huntington’s mutation. To skeptics, this scenario captured the extreme lengths necessary to maintain nondisclosure.

Ultimately, says Harvey Stern, Leyton’s former doctor and the director of reproductive genetics at the Genetics & IVF Institute, his clinic only performed mock transfers once or twice, out of 40 to 50 total cases of direct nondisclosure testing for Huntington’s. In the early 2000s, doctors started routinely testing embryos for unrelated chromosomal abnormalities. Once they had a reason other than Huntington’s to screen out embryos, ending up with zero implantable ones was no longer so suspicious. Mock transfers were no longer necessary.

But Stern and his colleagues still had to establish other rules to make sure that the medical team did not accidentally reveal a patient’s Huntington’s status. Only Stern and people working in the lab had that information. The IVF doctors, nurses, and ultrasound technicians interacting directly with the patient did not. Nothing about genetic testing for Huntington’s even went into the patient’s chart; all of the paperwork was kept locked in a safe in the office of the then–lab director, Gary Harton.

All this secrecy changed the usual dynamic between the medical team and the patient. “With any other IVF cycle, they’re constantly getting updates,” Harton says. “Patients really live and die by that stuff. But in this case, it was completely the opposite, which was quite odd and difficult for everyone.” Nurses and ultrasound technicians who might otherwise make an encouraging comment such as “It looks great” had to keep quiet, lest they give the wrong impression about the number of embryos or eggs.

Sometimes patients would change their mind. “I vividly remember where certain patients, after their [IVF] cycle, would call up and say, ‘I know I have the mutation—you can tell me.’ We didn’t foresee that happening,” Harton says. Even then, they didn’t tell. Patients normally have to undergo a psychiatric evaluation to even take a genetic test for Huntington’s, to make sure they can withstand the shock of bad news.  A strict protocol is followed. “I can certainly understand that,” says Stern, about the patients who change their mind. “But I don’t want to be the one to make them jump off the bridge.”

With direct nondisclosure testing, that tension always exists between the doctors who know and the patients who do not. For this reason, some patients choose indirect nondisclosure testing, also called exclusion testing, where even the lab technicians and doctors do not know the patient’s status.

This is accomplished by testing not the Huntington’s gene itself but specific DNA markers next to the gene. It also requires testing the grandparents on the side of the family affected by Huntington’s. If Grandma has Huntington’s, then she carries one faulty copy and one normal copy of the gene linked to the disease. Her daughter, the mother, inherits one copy from Grandma (either faulty or normal) and one copy from Grandpa (normal). When she has a child, she has a 50 percent chance of passing along either Grandma’s copy or Grandpa’s copy. So without actually knowing whether the mother had inherited the faulty copy or the normal copy from Grandma, doctors can just exclude all embryos with Grandma’s DNA markers. The advantage is that doctors have nothing to conceal, nothing to accidentally reveal.

The disadvantage is that the lab needs the affected grandparent’s DNA, and he or she might not be alive to give it. And if the patient had inherited the normal copy of the gene, clinics that discard any embryo with the grandmother’s DNA markers would be discarding healthy embryos. This could lead to additional IVF cycles if not enough healthy embryos make it through testing in the first cycle.

Since the chances of inheriting a sick parent’s Huntington’s mutation is 50-50, half the people choosing nondisclosure testing don’t actually have the mutation. If they are otherwise fertile, they could be having children naturally. They don’t need IVF at all. And the process of IVF, says Helena Kääriäinen, the former president of the European Society of Human Genetics, is very expensive and quite hard on a woman’s body. In other words, there are additional costs to nondisclosure testing, both financial and physical.

Stern says nondisclosure testing is ultimately about giving patients a choice not to know: “People have said, ‘How can you make people go through IVF when they do not need it?’ My answer has always been: ‘I’m not making anybody go through it.’”

Marissa, who is 39 and lives in Seattle, decided on indirect nondisclosure PGT-M, while her brother chose another option, called chorionic villus sampling. (The Atlantic agreed to use first names only in some cases, to avoid outing the health status of family members.) The sampling is done on fetuses 10 to 12 weeks old, and it reveals whether a fetus has the Huntington’s mutation. If it does, then the at-risk parent can conclude that he or she does as well. Marissa’s brother was able to have two Huntington’s-free children this way, with the understanding that any fetuses that tested positive could be aborted.

But Marissa realized she couldn’t face the possibility of learning she had Huntington’s and having to decide in that moment whether to have an abortion. “That was just a position that—for myself—I was not wanting to be in,” she says. As soon as she got engaged, Marissa started saving up so that she and her husband could afford the IVF cycles and nondisclosure PGT-M testing. She now has twin girls.

The unequal demands of IVF on the woman can also make it tricky for couples deciding on nondisclosure testing. Faye went through indirect nondisclosure testing in the U.K. to have her two children because her husband is at risk for Huntington’s. He was the one who first learned about IVF and nondisclosure testing, and he was the one who first pushed it. But Faye would be the one physically going through IVF, which requires multiple daily hormone injections and constant appointments.

“Initially I was refusing to do it,” she says. “It was a big shock to me.” The two of them went to a genetic counselor who explained the risks of the Huntington’s mutation, and that made Faye viscerally understand why her husband would not want to be tested for Huntington’s. She agreed to IVF and indirect nondisclosure testing. Their son was born after one round of IVF.

Then they tried to have a second child, which took one failed embryo transfer, another failed transfer, surgeries to examine why those transfers failed, a failed egg retrieval, another successful egg retrieval, and a transfer with a single healthy embryo, before she finally got pregnant. “It was honestly the most horrendous experience of my life, and it nearly destroyed me,” Faye says. After each failed procedure, she found it difficult to work. There were times, she admits, when she thought about how she might not have to go through all this if only her husband would get tested. “When I was very low, I didn’t even know I needed to do that. When those emotions settled, I still came back to protecting him, protecting me, protecting the family. You don’t need to know this.”

In the U.K., the National Health Service provides people at risk for Huntington’s disease with up to three rounds of IVF to have one healthy child. After Faye and her husband had their son, though, they had to pay out of pocket to conceive their second child. “She was my £33,000 baby,” says Faye. They could afford the cost, the equivalent of about $45,000, for multiple rounds of IVF. But most people cannot.

In the United States, most insurance does not cover the cost of IVF with any kind of Huntington’s testing, which together run on average $20,000 to $25,000. The HelpCureHD Foundation recently announced grants for parents who want the procedure but cannot afford it. The foundation’s founders, Allie LaForce and Joe Smith, revealed that they were going through IVF with indirect nondisclosure testing to have children. (LaForce is an NBA reporter for TNT, and Smith is a pitcher for the Houston Astros.) When I called her, LaForce was going through her second round of IVF. She had been traveling around the country for work with hormone injections in tow.

The couple was shocked when they discovered the cost of IVF with a Huntington’s test. “We could afford it,” said LaForce, “but no wonder nobody does it.” They hope to fund five families a year, and the foundation has also partnered with the Cleveland Clinic and the Houston Fertility Institute for discounted treatment. The foundation will fund any type of PGT-M for Huntington’s—disclosure, direct nondisclosure, or indirect nondisclosure—though LaForce and Smith themselves chose indirect nondisclosure testing.

They chose that option because Smith has never taken the Huntington’s test himself. He had seen how Huntington’s disease had taken over his mother’s life. When she could still go to his games, people would accuse her of being drunk because of her slurred speech. She now lives at a full-time care facility. “He just has watched his mom struggle,” said LaForce, “and I think it’s hard for him to imagine that is his life 10 to 15 years from now.” They don’t know whether their children will have to watch Smith struggle, but they do know that with IVF and preimplantation testing, their children will never have to imagine Huntington’s disease taking over their own lives.



Updated on December 4 at 10:55 a.m. ET.

Before last week, few people had heard the name He Jiankui. But on November 25, the young Chinese researcher became the center of a global firestorm when it emerged that he had allegedly made the first CRISPR-edited babies, twin girls named Lulu and Nana. Antonio Regalado broke the story for MIT Technology Review, and He himself described the experiment at an international gene-editing summit in Hong Kong. After his talk, He revealed that another early pregnancy is under way.

It is still unclear if He did what he claims to have done. Nonetheless, the reaction was swift and negative. The CRISPR pioneer Jennifer Doudna says she was “horrified,” NIH Director Francis Collins said the experiment was “profoundly disturbing,” and even Julian Savulescu, an ethicist who has described gene-editing research as “a moral necessity,” described He’s work as “monstrous.”

Such a strong reaction is understandable, given the many puzzling and worrying details about the experiment. Even without any speculation about designer babies and Gattaca-like futures that may or may not come to pass, the details about what has already transpired are galling enough. If you wanted to create the worst possible scenario for introducing the first gene-edited babies into the world, it is difficult to imagine how you could improve on this 15-part farce.

1. He didn’t address an unmet medical need. 

He focused on a gene called CCR5, which the HIV virus uses as a doorway for infiltrating human cells. To lock the virus out, several scientists have tried extracting the immune cells of HIV patients and deactivating CCR5 using gene-editing techniques before injecting the cells back into the body. Although Nana and Lulu’s father is HIV-positive, neither of the infants actually had HIV. As I’ve written before, He’s team deactivated a perfectly normal gene in an attempt to reduce the risk of a disease that neither child had—and one that can be controlled through safe-sex education or antiviral drugs. Even if you wanted to block CCR5 specifically, there are drugs out there that could do the job, many of which have been repeatedly tested in clinical trials. The rationale for using a method as extreme and untested as gene editing doesn’t hold up.

Deactivating CCR5 doesn’t confer complete immunity to HIV, either, since some strains of the virus can enter cells via a different protein. And although people with natural deficiencies in the gene appear healthy, they might be more susceptible to West Nile virus, and more likely to die when they catch influenza. Essentially, He gave Nana and Lulu resistance to a virus that they could have avoided in myriad other ways, and may have opened them up to other dangers.

2. The actual editing wasn’t executed well. 

He’s data haven’t been published or peer reviewed, so many of the details of his experiment are unclear. But based on the slides that he presented at the Hong Kong summit, other scientists have denounced the work for being amateurish.

For example, it appears that He only managed to edit half of Lulu’s CCR5 genes; the rest are normal. That could either be because every cell in her body has one normal copy of CCR5 and one edited one (she’s heterozygous) or because half of her cells carry two edited genes and half carry two normal ones (she’s mosaic). If it’s the former, she would not be resistant to HIV. If it’s the latter, it depends on whether her immune cells specifically carry the edits. The same might apply to Nana, who, based on the slides, seems to also have normal copies of CCR5 somewhere.

What’s more, the edited cells don’t seem to have been edited in the right way. He planned to delete a small section of the CCR5 gene, mimicking a naturally occurring mutation called delta 32 that’s found in about 10 percent of Europeans. But according to Sean Ryder, a biochemist from the University of Massachusetts Medical School, He’s slides show no sign of delta 32 in either girl. Instead, Lulu has an entirely different CCR5 mutation, and Nana has two. These mutations are in roughly the same part of the gene as delta 32, but “it’s a fairly outrageous assumption that any change to this region would lead to some benefit,” Ryder says. “He made new mutations, and there’s no reason to think that they’d be protective—or even that they’d be safe.”

3. It’s not clear what those new mutations will do. 

At least two of the three mutations that He introduced into Nana and Lulu’s genomes are substantial changes that could alter how CCR5 works. Typically, scientists would introduce the same mutations into mice or other lab animals to see what would happen. If they felt reassured enough to move into human patients, they could recruit patients with HIV, take out some immune cells, introduce the new CCR5 mutations, transplant the cells back, and monitor the volunteers to see if they’re healthy. “That could take months or years, but to do anything less would be cutting corners,” Ryder says.

But He appears to have leapfrogged over all of those basic checks and implanted the edited embryos into a woman. “The children are test subjects for variants that haven’t been vetted in animals,” Ryder says. What’s shocking about this “is the blatant disregard of all the rules and conventions we have in place for how one should approach any proposed intervention,” said Leonid Kruglyak, a geneticist at the University of California at Los Angeles, on Twitter.

4. There were problems with informed consent. 

It’s not clear if the participants in He’s trial were actually aware of what they were signing up for. He relied on an AIDS association to reach out to the patients and falsely described his work as an “AIDS-vaccine development project.” He told delegates at the Hong Kong summit that he personally took the volunteers through the informed-consent process, along with another professor. But taking consent is a specific skill that requires training; He had none.

The consent document that he used describes CRISPR and gene editing, but it does so in heavily technical language. He has said that his patients were “very well educated” and already knowledgeable about gene-editing technology. But according to a news report from the Chinese magazine Sanlian Life Week (which has since been removed, but not before a digital copy was saved and translated), one of the people who dropped out of the experiment had only a high-school understanding of biology, and only heard the term “gene editing” when news stories about He’s experiment broke. The man claimed that he was not informed about the risks of off-target effects, or about the fact that gene editing was a prohibited and ethically controversial technology.

Also, the consent form “is not a consent form,” says Kelly Hills, a bioethicist at Rogue Bioethics. “It’s a business form, of the kind that a company might use when subcontracting.” For example, the section about possible risks says nothing about any negative consequences of deactivating CCR5, and is instead more focused on absolving He’s team of legal responsibility for problems arising from the procedure. The form also gives He’s team rights to use photos of the babies in magazines, calendars, billboards, propaganda, product packaging, and posters in cars and elevators.

5. He operated under a cloak of secrecy …

By his own admission, He didn’t tell his institution, the Southern University of Science and Technology, about the experiment, and took a stint of unpaid leave in February to begin work in secret. The university plans to launch an investigation into the project, which it called a “serious violation of academic ethics and standards” in a statement.

He also claims that he received ethical approval from Shenzhen Harmonicare Hospital. But in a statement, the hospital says that the Medical Ethics Committee never met to discuss such a project, and that the signatures on He’s approval form “are suspected to have been forged.” Meanwhile, He’s laboratory web page has disappeared, as have statements praising his other work on government sites.

6. … but organized a slick PR campaign.

Given how many people He kept in the dark, it is all the more striking that he was simultaneously organizing a public-relations effort. He engaged the services of an American PR consultant, Ryan Ferrell. He created a set of five YouTube videos describing his actions and the rationale behind them. And all of this while the actual technical details of his work have yet to be released in any official publication.

7. A few people knew about He’s intentions but failed to stop him.

Even though He spoke at scientific conferences about his gene-editing research in other animals, he only discussed his ambitions to edit human embryos with a select few. Those included his former adviser Michael Deem of Rice University, who played an active role in the project and was reportedly present in China when several patients were consented. (Deem holds a small stake in He’s two companies, and is under investigation for his involvement in the matter.)

Other scientists were not supportive. As reported in STAT, He also consulted Mark DeWitt of UC Berkeley, who told him not to go ahead with the project. The Associated Press also reported that He expressed an interest in editing human embryos to his former adviser Stephen Quake from Stanford University, who cautioned him in broad terms to seek ethical advice. This February, He also told Stanford’s Matthew Porteus that he had hospital approval to proceed with his experiment. Porteus told the AP that he was angry at He’s naïveté and recklessness, but after chiding him assumed that he would not go ahead.

The chair of the Hong Kong summit, David Baltimore, called the episode “a failure of self-regulation by the scientific community.” Baltimore urged other scientists in the field who learn about experiments like He’s to alert the authorities. But this “See something, say something” approach won’t work, says Hills, the bioethicist. “Would scientists actually recognize a bad actor if one was working with them?” she says. “The answer is no. We simply assume that if someone is a colleague, they have shared values.”

“And who do you say something to?” she adds. “We don’t have an international group that oversees gene editing.” China is unusual in that it actually does have a medical-ethics agency that oversees all medical research in the country, and that Porteus or others could have contacted. The United States does not specifically prohibit the gene-editing work that He did, unless it was federally funded. But Hank Greely, an ethics and law professor at Stanford, notes that the step of implanting the embryos would count as distributing a new drug without FDA approval. That’s a federal crime, Greely notes.

8. He acted in contravention of global consensus. 

To the extent that there was any global consensus about using gene-editing technologies on human embryos, it was: Don’t rush into it. That was the feeling in 2015 when the U.S. National Academies of Sciences, Engineering, and Medicine convened an international summit of scientists, ethicists, and others to discuss the topic. And it was the view of a landmark report that the same group published in 2017.

The report did not call for an outright ban on germ-line gene editing—that is, altering the DNA of sperm, eggs, or embryos in ways that could cascade through generations—but said that “there is a need for caution.” It should only be done in clinical trials with “rigorous oversight,” “maximum transparency,” and an “absence of reasonable alternatives,” and only after “much more research to meet appropriate risk/benefit standards” and “broad participation and input by the public.”

He’s work, which was both rushed and cloaked in secrecy, clearly did not fit these criteria. And as reported by Antonio Regalado at MIT Technology Review, He wrote in the ethics proposal that accompanied his experiment that the National Academies in their 2017 report had “for the first time” approved germ-line gene editing in human embryos to treat or prevent serious disease. It’s as if he took the absence of a red light as a green one.

9. He acted in contravention of his own stated ethical views. 

In July 2017, He spoke at a conference at Cold Spring Harbor Laboratory. He didn’t mention his plans to edit human embryos, but he brought up the case of Jesse Gelsinger, an American teen who died in a botched gene-therapy trial in 1999. To avoid such deaths, and the chilling effect that they can have on research, He urged scientists to move cautiously before editing the genome of embryos.

He also published a paper in The CRISPR Journal that lays out ethical principles, such as transparency, that he himself violated. The paper was in the works well before the news of the babies broke, and was published two days afterward. Ryan Ferrell, He’s PR consultant, is one of the co-authors.

10. He sought ethical advice and ignored it. 

Sharon Begley at STAT reports that He spoke at length with bioethicists William Hurlbut at Stanford University, as well as his son Benjamin Hurlbut at Arizona State University, neither of whom was aware of He’s plans. The elder Hurlbut spent time telling He about opposition to the instrumental use of human embryos in the United States, and the grounds for believing that human life begins at conception. But despite those discussions, He proceeded with his experiments and seems, by Hills’s reading, to have “developed his own personal code that reads like what you would expect from a freshman in the first weeks of Bioethics 101.” *

11. There is no way to tell whether He’s work did any good. 

Both Nana and Lulu will be monitored at least until they turn 18. But “the children were already at virtually no risk of contracting HIV,” said Alta Charo, a bioethicist from the University of Wisconsin at Madison, in a statement. This means that “there is no way to evaluate if this indeed conferred any benefit. If they remain HIV-negative, there is no way to show it has anything to do with the editing.”

At the Hong Kong summit, He was asked whether the two children would be treated differently by their parents, who will know that they have been edited. “I don’t know how to answer this question,” He said.

12. He has doubled down.

If He shows any contrition about how these events have unfolded, it has not been obvious. Speaking at the Hong Kong summit, he apologized, but only because news about his work “leaked unexpectedly” before he could present it in a scientific venue. That, He said, took away from the community. Regarding the experiment itself, he said: “I feel proud.”

13. Scientific academies have prevaricated.

In the wake of He’s bombshell, several scientists, including the CRISPR pioneer Feng Zhang and the stem-cell biologist Paul Knoepfler, have called for a temporary moratorium on similar experiments. By contrast, after the news first broke, the organizing committee of the Hong Kong summit, which includes representatives from scientific academies in Hong Kong, the United Kingdom, and the United States, released a bland statement in which it simply restated the conclusions from its earlier report. A second statement, released after the summit, was stronger, calling He’s claims “deeply disturbing” and his work “irresponsible.”

But the second statement still discusses the creation of more gene-edited babies as a goal that should be worked toward. The risks are “too great to permit clinical trials of germ-line editing at this time,” it says, but “it is time to define a rigorous, responsible translational pathway toward such trials.” George Daley from Harvard Medical School, who was one of the meeting’s co-organizers, made similar points during the event itself. Given that the world is still grappling with the implications of what has happened, “no, it’s not time yet and it’s tone-deaf to say so,” says Hank Greely.

“Although the chair opened the summit by invoking Huxley’s Brave New World, few of the discussions at the meeting, and nothing in the concluding statement, suggest a meaningful engagement with social consequences,” says the Center for Genetics in Society, a watchdog group.

14. A leading geneticist came to He’s defense.

In an interview with Science, George Church, a respected figure from Harvard and a CRISPR pioneer, said that he felt “an obligation to be balanced about” the He affair. Church suggested that the man was being bullied and that the “most serious thing” about his experiment was “that he didn’t do the paperwork right.” “[Church’s] comments are incredibly irresponsible,” says Alexis Carere, who is president-elect of the Canadian Association of Genetic Counsellors. “If someone contravenes the rules that we have laid down, we are very justified in speaking out about it. The unfortunate effect of this is that it makes it seem like there is some kind of balance, and George is just in the middle. There is not.”

Carere was also dismayed at the rest of the interview Church gave, where “every sentence was a new ethical maxim that I had never heard of,” she says. For example, Church noted that “as long as these are normal, healthy kids it’s going to be fine for the field and the family.” But unethical actions are still unethical, even if nothing goes wrong. Arguing otherwise gives a pass to scientists who blow past ethical norms, provided that they find something interesting. “It’s bizarro-land consequentialist ethics,” Carere says.

15. This could easily happen again.

Last year, the world learned that a group of scientists had resurrected a virus called horsepox. Several researchers and ethicists criticized that work, arguing that it would make it easier for others to recreate the related (and far more dangerous) smallpox virus. As I wrote in October, regardless of the risks or merits of the experiment, it reveals a vulnerability at the heart of modern science. That is: Small groups of researchers can make virtually unilateral decisions about experiments that have potentially global consequences, and that everyone else only learns about after the fact.

He Jiankui’s experiment reveals that vulnerability in the starkest-possible light.

* This section previously and erroneously grouped the views of William and Benjamin Hurlbut together. It mischaracterized the nature of the conversation between He and Benjamin Hurlbut. It has also been revised to clarify William Hurlbut’s stance on the ethics of embryo use, which do not, as previously stated, arise from conservative religious beliefs.



Two photos—one long anticipated, the other a surprise—became instantly famous in astronomy last week. First, there was the first-ever look at a black hole, a shadowy void encircled in a fiery ring of cosmic matter. Then, in the celebration that followed, another image emerged: a young computer scientist, hands over her mouth and eyes flashing with giddiness, as the image of the most mysterious object in the universe rendered on the computer screen in front of her.

This researcher, Katie Bouman, was a postdoctoral fellow at MIT and a member of the team running Event Horizon Telescope, the effort to capture visual evidence of a black hole for the first time. After astronomers released that image last week, Bouman’s spread across the internet just as rapidly, on social media and in news stories. Her face, slightly blurry but beaming, was everywhere.

At first, the message was simple—Bouman stood out as a role model for young women and girls working in or aspiring to jobs in male-dominated science fields. A round of stories celebrated Bouman’s work on the algorithms that forged a mesmerizing photograph from a vat of telescope data. She was a symbol of female empowerment, a shatterer of STEM ceilings, a badass.

But within hours, another strain of interpretation started metastasizing. Memes and videos across Reddit, Twitter, YouTube, and other platforms called Bouman a fraud and “debunked” her contributions to the discovery.

In the midst of all that, something strange started happening: Dozens of accounts (some now deleted) appeared on Instagram and Twitter bearing Bouman’s name and picture. None of them, her colleagues said, was real.

And Bouman didn’t ask for any of it.

In many ways, this is an old story: A successful woman becomes a target of harassment online because she’s a successful woman. But the reaction to Bouman seems specific to this particular cultural moment, in which divergent views of gender, media, and science, usually flowing in their own little streams, smash together to form a massive riptide. This one image tapped into a multitude of questions about the role of women in science, the myth of the lone genius, and the pressure scientists have to promote themselves and their work on social media.

In moments like these, strangers on the internet can end up shaping the current as they feverishly share and retweet and upvote, eager for the chance to revere a person or expose them. The reality of the person at the center—the Katie Bouman that exists outside these few pictures—can get lost. And when the rush subsides, it leaves behind a tangled web of truths, falsehoods, and exaggerations. Reality is split into two. In one, Bouman is a hero; in the other, she’s a villain.

This onslaught started with a tweet from MIT’s Computer Science and Artificial Intelligence Lab, intended to promote, as these institutions love to do, one of their own. Bouman, the post said, “led the creation of a new algorithm to produce the first-ever image of a black hole.” (Bouman did not respond to requests for an interview.)

Tens of thousands of users amplified the message. The excitement fed into a hunger to celebrate women in science, heightened by a national movement to listen, finally, to women long unheard. At a press conference in Washington, D.C., where the image was unveiled by Event Horizon Telescope team members, only one of the four scientists was a woman; black-hole enthusiasts were ready to hear from more.

Bouman’s new fans wanted to rescue the young computer scientist from the pantheon of unsung women in science—including Rosalind Franklin and Vera Rubin and Henrietta Leavitt, to name just a few—whose contributions went unrecognized in their moment and were honored only many years later, sometimes long after their male colleagues had received awards for the same work. In another viral tweet, the MIT account juxtaposed a picture of Bouman with stacks of the hard drives bearing the data that spotted the black hole with one of Margaret Hamilton, the MIT computer scientist who helped write the software for the Apollo program.

“Take your rightful seat in history, Dr. Bouman!” Congresswomen Alexandria Ocasio-Cortez cheered to her nearly 4 million Twitter followers. Like the lawmaker, Bouman is an appealing embodiment of a rising generation—young, fresh-faced, and female. As a symbol of a new wave of women in science, she was perfectly cast.

Science is still filled with women whose work has received less recognition than that of their male peers. The real-time recognition of Bouman reminded me of the attention the physicist Donna Strickland received in the fall, when she won the Nobel Prize in Physics, becoming only the third woman to do so in history. Denizens of the internet banded together to fashion a new Wikipedia page—the commemorative plaque of the internet—that went into detail about her work. The male colleagues with whom she shared the prize already had pages.

The well-intentioned cheers for Bouman propagated a different conventional narrative, though—that of the myth of the lone genius. The idea that scientific breakthroughs originate with a single brilliant mind (usually male, usually white) is widespread but inaccurate. As Bouman became the unwitting face of the Event Horizon Telescope, some of her collaborators chimed in to point out that “big science happens in BIG teams.” The groundbreaking photograph of a black hole, they said, was not the eureka moment of one smart person, but the effort of more than 200 researchers—plus countless additional staff, from telescope technicians to the shipping guy who made sure the computer disks, bursting with data, arrived safely at laboratories.

Bouman made this very point herself in a TED Talk from 2016 that also made the rounds, and in a Facebook post she published Thursday after her name had ricocheted around the internet for hours. “No one algorithm or person made this image,” she wrote. “It required the amazing talent of a team of scientists from around the globe and years of hard work to develop the instrument, data processing, imaging methods, and analysis techniques that were necessary to pull off this seemingly impossible feat.” Bouman was otherwise mostly absent from social media, where many scientists cultivate a presence to promote their work—but where women are more likely to be targets of harassment.

MIT would eventually clarify that its first tweet had overstated Bouman’s role. Her contributions, while significant to the project, inspired the methods that the team eventually used to construct the final image. Perhaps the narrow spotlight had not sat well with other people on the team and MIT was hearing about it. Or perhaps the institution wanted to deflect further attention from Bouman, whose name, by that point, was being dragged through the mud in other communities.

Internet trolls declared that the credit for the algorithms belonged not to Bouman, but to one of her colleagues—who, coincidentally, happens to fit the classical description of a gifted computer scientist: a bespectacled white man. This man, they said, had written most of the code for the project, not her. Within hours, his visage, buoyed by sexist claims and misogynist commentary, was chasing Bouman’s online.

The colleague, Andrew Chael, defended Bouman. None of the claims was true, he tweeted. “If you are congratulating me because you have a sexist vendetta against Katie, please go away,” he added. It’s difficult to imagine internet sleuths digging for proof of dishonesty if the poster child of the black-hole discovery had looked like Chael. (Chael, in an interview with The Washington Post, called it “ironic” that his new fans chose him, a gay astronomer, as their hero.)

Bouman has laid low throughout the saga. Her phone became so flooded with messages that she simply turned it off, she told The New York Times. Her story moved forward without her. Before the week was over, Bouman, who will soon join the California Institute of Technology as an assistant professor, had a brand-new digital presence fueled by well-meaning supporters on one side, trolls on the other, and a slew of parasitic impersonators with ambiguous motives jammed somewhere in between.

Bouman’s Wikipedia page was once flagged for deletion because the site’s standards found that she was “not notable” enough. Now it carries a paragraph detailing her viral story and the harassment that followed, like a cautionary tale for other women in the sciences. It is both a reminder and a warning. Hard work deserves recognition, but what happens when there’s too much?



On Monday, speaking at a town hall led by Senator Bernie Sanders, Representative-Elect Alexandria Ocasio-Cortez framed her chosen climate policy—the Green New Deal—through the lens of gallant American exceptionalism. “This is going to be the New Deal, the Great Society, the moon shot, the civil-rights movement of our generation,” she said.

The Green New Deal aspires to cut U.S. carbon emissions fast enough to reach the Paris Agreement’s most ambitious climate goal: preventing the world from warming no more than 2.7 degrees Fahrenheit by 2100. In a blockbuster report released in October, an international group of scientists said that meeting this goal could skirt the worst climate effects, such as massive floods, expansive droughts, and irreversible sea-level rise.

To actually make the target, though, the world must start reducing its carbon pollution immediately, and cut it in half by 2030. And we’re nowhere close. Global emissions levels just hit a record high, and even the Barack Obama administration’s most breakneck climate policy did not put the United States close to making its part of the goal.

The Green New Deal aims to get us there—and remake the country in the process. It promises to give every American a job in that new economy: installing solar panels, retrofitting coastal  infrastructure, manufacturing electric vehicles. In the 1960s, the U.S. pointed the full power of its military-technological industry at going to the moon. Ocasio-Cortez wants to do the same thing, except to save the planet.

I have no idea whether the Green New Deal will result in a federal climate law two or five or 10 years from now. The proposal clearly has momentum on the left. Since early November, I’ve seen the Green New Deal talked about as a story of Democrats in disarray, or as another example of the party’s turn toward socialism. Both analyses miss the mark. The Green New Deal is one of the most interesting—and strategic—left-wing policy interventions from the Democratic Party in years.

As I wrote last year, the Democrats have a problem: They are the only major political party that cares about climate change, but they don’t have a national strategy to address it. Party elites know that they want to fight climate change, of course, but after that the specifics get hazy, and almost no one agrees on what new laws should get passed.

For the past two years, this lack of agenda hasn’t really hampered them, because they could unite around blocking Donald Trump’s deregulation extravaganza. But as Democrats consider the possibility of controlling Congress and the White House in 2020, they will feel more pressure to zero in on a strategy.

For the first time in more than a decade, Democrats can approach climate policy with a sense of imagination. They can also approach it with a sense of humility, because their last two strategies didn’t work particularly well. When the party last controlled Congress, in 2009, Democrats tried to pass a national cap-and-trade bill, a type of policy that allows polluters to bid on the right to emit carbon dioxide into the atmosphere. It failed to pass in the Senate. Starting in 2011, President Obama tried to use the EPA’s powers under the Clean Air Act to fight carbon-dioxide emissions. After President Trump was elected, he terminated that effort by executive order.

Since then, Democrats in Congress have proposed no shortage of climate bills. A few of them even picked up Republican support. Some blue states have also tried to pass climate policy of their own, though the most ambitious of those efforts have failed. And as I wrote last year, the party has encountered new problems in its coalition. Some environmental groups have focused on closing coal plants and blocking pipeline projects, frustrating the labor movement, which appreciates the jobs that those projects bring.

From the successes, a pattern has emerged. Economists tend to prefer policies that work across the entire economy at once by integrating the costs of climate change into the price of gas, food, and other consumer goods. But voters—who have more quotidian concerns than optimally elegant economic policy—don’t always feel the same way. They don’t want gas prices to go up. And that means they support policies that remake one sector of the economy at a time, usually by mandating the use of technology. Economists like to disparage these policies as “kludges” or “command and control.” But Americans like them.

Recently, a bipartisan group of 17 governors decided that they needed to fight President Trump on climate change. In September, a few of them got onstage in San Francisco to announce new programs to rival the president’s deregulation.

Republican and Democratic governors, fighting Trump, on climate! The story had conflict, personalities, global stakes: Everything you’d want for a CNN-ready brawl. Everything except excitement. Only one of the programs—a pledge to spend $1.4 billion on new electric-car infrastructure—was compelling and easy to explain. The others rapidly strayed into the technical or the vague. The governors said they would overcome Trump’s tariffs on cheap solar panels. They promised to reduce “short-lived climate pollutants,” such as methane and soot. And—I will never forget this—they pledged to research how carbon can stay stored in plants and soil on state parkland.

In other words: The governors leered and growled at Trump, talked about climate change’s epic consequences, and then, with much fanfare, announced new state rules for dirt.

And what should they have done? Governors, like presidents, are constrained; they can’t do much without the support of state legislatures. And dirt is a worthy topic for climate regulation. As it happens, a large amount of carbon sits in American dirt. If that carbon escapes into the atmosphere, it will worsen climate change. Should a small nation ever appoint you despot of all climate laws, please do something about dirt. But generally and politically speaking, dirt does not get the people going. Upon hearing the slogan “Dirt: Now More Than Ever,” most voters will not picture overflowing cornucopias of prosperity. They will picture bath time.

I have come to think of this tension as climate policy’s Boring as Dirt problem: the BAD problem. The BAD problem recognizes that climate change is an interesting challenge. It is scary and massive and apocalyptic, and its attendant disasters (especially hurricanes, wildfires, and floods) make for good TV. But the policies that will address climate change do not pack the same punch. They are technical and technocratic and quite often dull. At the very least, they will never be as immediate as climate change itself. Floods are powerful, but stormwater management is arcane. Wildfires are ravenous, but electrical-grid upgrades are tedious. Climate change is frightening, but dirt is boring. That’s the BAD problem. 

Some version of the BAD problem probably exists for every issue. Paying for exorbitant cancer drugs is an outrage, but advocating for state-level insurance laws that could reduce their cost is onerous. In a way, addressing the BAD problem is part of what elected officials are supposed to do in a republic. But it’s a special problem for climate change, with its all-encompassing cause and countless diffuse harms. To fix climate change, you have to pass laws about dirt. Then you have to keep them passed.

The Green New Deal, first and foremost, can be understood as trying to fix the BAD problem. In the long term, it’s an ambitious package of laws that will touch every sector of the economy. The Sunrise Movement, a youth-led activism group that has pushed for the policy, has listed seven demands that any Green New Deal must satisfy. They range from requiring the U.S. to get 100 percent of its electricity from renewable sources to “decarbonizing, repairing and improving transportation and other infrastructure.” They also call for a massive investment in technology that could directly remove carbon dioxide from the atmosphere.

These are enormous demands that would require either many small pieces of technical legislation or a new executive climate-change agency. Yet they do not alone make the Green New Deal. The single most crucial aspect of the Green New Deal is its proposed job guarantee, a controversial policy that says that every American can have a job with the government if they want one. Data for Progress, a leftist advocacy group, claims that the Green New Deal could generate 10 million new jobs across the country over 10 years.

This policy—a job for every American who wants one—reflects what the party learned from fighting Obamacare’s repeal. Obamacare provides a revealing view into how economists think about policy versus how people experience it. That is, as far as policy makers are concerned, Obamacare comprises a set of clever tweaks and rules meant to change how insurance markets work and lower the cost of health care. Before the law passed, Democratic lawmakers cared deeply about getting those tweaks right.

Yet Obamacare didn’t survive because those new rules worked. They did work, but, in fact, voters hate them. Instead, Obamacare survived because it gave two new superpowers to voters. The first was the power never to be denied health insurance for preexisting conditions, and the second was free or cheap health insurance through Medicaid. The reason Americans jammed the Capitol Hill switchboards last year to protest the repeal—and pulled the lever for Democrats in November—wasn’t that they valued Obamacare’s elegant cost-control mechanism. They wanted to keep their superpowers.

“People who are receiving benefits, they’re going to react pretty strongly to that being taken away from them,” said the political scientist and UC Berkeley professor Paul Pierson in a conversation with Vox last year. “A taxpayer is paying for a lot of stuff and cares a little bit about each thing, but the person who’s receiving the benefits is going to care enormously about that.”

Fixing climate change will include lots of technocratic tweaks, lots of bills about dirt. They will be hard to defend against later repeal. So it would be nice if lawmakers could wed them to a new benefit, a superpower that people will fight for years after passage. Hence the job guarantee—a universal promise of employment meant to win over Americans in general and create more union jobs in particular.

In the near term, though, the Green New Deal isn’t doing that. It’s only a demand for more procedure. At least 17 members of the next House of Representatives, and three Democratic senators, currently support the idea of forming a select committee on a Green New Deal. The idea is partly to take back Congress as a place for policy making. Supporters want the committee to draft legislation over the next two years, build expertise—and then present a near-finished bill to the next Democratic president.

The policy aligns with emerging Democratic strategy, too. The Green New Deal is policy-by-slogan, like “Medicare for All” or “Free Community College” or “Abolish ICE.” Those phrases capture a worldview, a promise, and a vision of how life would be different after their passage. They mirror the pungency, if not the politics, of Trump’s promise to “Build the wall.”

The Green New Deal also looks like an economic stimulus plan, which isn’t nothing. The last two Democratic presidents took power during an economic downturn or its immediate aftermath. Most climate bills look like new taxes—and new taxes are not easy to pass in the middle of a recession. But Franklin D. Roosevelt’s New Deal was not a tax, even if it included taxes; it’s remembered instead as the greatest of all stimulus and jobs bills. If Democrats take the White House during a recession, they will have a far easier time passing a Green New Deal than a carbon tax.

Many Americans first heard of the Green New Deal early last month, after Ocasio-Cortez made a surprise appearance at a demonstration in Nancy Pelosi’s office. Just a few days had passed since the midterm election, and Pelosi had yet to lock down the speakership. Hundreds of activists in yellow T-shirts—all bearing the logo of the Sunrise Movement—piled into Pelosi’s office to demand that Democrats support a Green New Deal.

“For me, as a member, I want to thank you all, for giving us as a party the strength to push,” Ocasio-Cortez told the group. “Should Leader Pelosi become the next speaker of the House, we need to tell her that we’ve got her back in showing and pursuing the most progressive energy agenda that this country has ever seen.”

For her first day on Capitol Hill, and her first public act as a representative-elect, Ocasio-Cortez chose to focus on climate change. The decision is notable all by itself. Ocasio-Cortez, the youngest woman ever elected to Congress, is also the first member of Congress who was born during the George H. W. Bush administration. And the Bush administration is when the modern era of stagnant climate politics began: It’s when Exxon and other oil companies began publicly advocating climate denialism, when the United States blocked a treaty that would have restricted global carbon emissions, when the Senate ratified the UN Framework Convention on Climate Change. Almost exactly a month after Ocasio-Cortez turned 1, Congress approved the Global Change Research Act, a law requiring regular federal reports on climate science. It hasn’t passed a major climate bill since. Ocasio-Cortez has spent her entire life watching climate change not get fixed. Now she’s getting her shot at addressing it.



In the autumn of 2017, about 250 walruses in Russia, having climbed up to rocky slopes overlooking a beach, just walked over the edge.

Usually, gravity is no enemy of the walrus. When these animals encounter hard surfaces, they rise up to meet them, hauling their two-ton bulks onto floating pieces of ice. When they fall, they flop off those low platforms into the accommodating water. So you might imagine that a walrus, peering off a tall cliff, doesn’t really understand what will happen to it when it steps off. It doesn’t expect to plummet for 260 feet, cartwheel through the air, bounce off the rocks, and crash abruptly. Climb, plummet, cartwheel, bounce: These are not walrus-associated verbs.

Nor is landing. The biologist J. B. S. Haldane once wrote a famous essay in which he described what large falls do to progressively larger animals. A mouse “gets a slight shock and walks away,” he wrote. “A rat is killed, a man is broken, a horse splashes.” And a walrus? “Many just die on impact, or they crush the ones they fall on below. Some have internal injuries, get to the sea, and wash up later,” says Sophie Lanfear, who led a documentary crew that recorded the behavior for Our Planet—Netflix’s big-budget answer to Planet Earth. The team had heard hints about such falls, but were still unprepared for the shock of seeing them. “It’s the worst thing I’ve ever filmed,” says Jamie McPherson, a cameraman, on a behind-the-scenes video.

Our Planet makes a point of saying what other nature series have not—the wonders they’re showing are endangered because of humans—and the footage is perhaps the most shocking part of a series full of discomfiting moments. Contrary to popular belief, not even lemmings dive off cliffs. Why would a walrus? Polar bears weren’t harassing them. The camera crews were filming from afar so their scents and sounds wouldn’t spook the skittish animals. Then why? What were walruses even doing on cliff tops in the first place? Our Planet offers a clear answer. “This is the sad reality of climate change,” Lanfear told me. “They’d be on the ice if they could.”

In the summer, Pacific walruses forage for shellfish in the waters between Alaska and Russia, before hauling up onto sea ice to rest and raise their young. But in recent years, Arctic sea ice has been thinner and sparser. The 2017–18 season marked a record low. As these icy platforms have retreated, walruses have increasingly been forced to haul out onto solid land—in the thousands.

These haul-outs aren’t new events, but they were once rarer, smaller, and less dangerous, according to Anatoly Kochnev, a Russian naturalist who has studied walruses for 36 years. When he started, only males gathered on these sites; now females and calves do too, and many are trampled in the scrum. When he started, haul-outs were rare in the northerly Chukchi Sea; now many sites there regularly heave with walruses.

With Kochnev’s help, the seven-person Our Planet team filmed one of the largest haul-out sites—a single beach where 100,000 walruses tessellate into a solid red mat of tusks and blubber. The animals arrived almost overnight, while the team slept in a cramped hut. “It was like 100,000 Chewbaccas outside,” says Lanfear. “We could hear tusks scraping along the side of the walls. We could hear walruses snoring. We opened the door, and it was a wall of blubber.” The walruses gather “out of desperation, not out of choice,” David Attenborough says over the resulting footage. “A stampede can occur out of nowhere. Under these conditions, walruses are a danger to themselves.” And so they climb “to find space away from the crowds.”

As the walruses spread across the beach, some start heading up a shallow slope, which curves into a steeper escarpment, which eventually culminates in 260-feet cliffs. It’s not an easy climb, but Kochnev suspects that once one group leads the way, the rest follow their scent. And since this area gets very little rain, odor trails from previous years might lead new arrivals up a dangerous path. “At least up here, there’s space to rest,” Attenborough intones. “A walrus’s eyesight out of water is poor, but they can sense the others down below. As they get hungry, they need to return to the sea. In their desperation to do so, hundreds fall from heights they should never have scaled.”

Our Planet draws a straight line between climate change, sea-ice loss, bigger haul-outs, overcrowding, climbing walruses, and falling walruses. “It is not a normal event,” says Lanfear. “It’s such a tangible, obvious thing to show people. It’s clear as day.”

But a few walrus scientists who saw the clip have questioned parts of this narrative—including the claim that walruses are climbing “to find space away from the crowds.” “Walruses thrive on crowds and haul out in tight groups, even when space is available,” says Lori Quakenbush from the Alaska Department of Fish and Game. Also, in the sequence, it looks as if the beach beneath the teetering walruses is relatively empty. What crowds are they escaping from?

This confusion arises from the ways in which documentaries elide space and time. Lanfear clarifies that the sequence includes footage from two separate beaches—one with the 100,000-strong congregation and one with the falls. At the latter, walruses started climbing only once the area beneath the cliffs had completely filled up; gregarious or not, they had no room. Once at the top, they rested for a few days, and walked off only after the beaches below had emptied. Indeed, as the narration suggests, the sounds of their departing comrades may have lured the cliff-top walruses off the edge. “They seemed to all want to return to the sea to feed as a group,” Lanfear says.

Quakenbush and others also doubt that the climbs and falls are related to climate change, because such tragedies have been reported since before sea ice showed substantial declines. “Walruses have shown similar behavior on the U.S. coastline when space and ice were not an issue, and the reason is unknown,” says Lori Polasek from the University of Alaska Fairbanks. For example, in three successive years, from 1994 to 1996, dozens of male walruses fell to their death from cliffs in southwestern Alaska. But Kochnev and Lanfear argue that the incident captured in Our Planet is exceptional in both the height of the cliffs and the number of walruses that plummeted and died—hundreds as opposed to dozens.

The reason for the falls might be complicated, but it’s clear that climate change is affecting the walruses. “We do believe that haul-outs have increased in size due to the loss of sea ice—in part, due to females and their calves moving to land during summer,” says Nicole Misarti from the University of Alaska Fairbanks.

These changes have affected the indigenous communities that have traditionally hunted, protected, and lived alongside walruses. The 200 Chukchi people who live in the Russian village of Vankarem are familiar with local haul-outs. But according to one resident, Vladilen Ivanovich Kavry, the gatherings have become more crowded, and the walruses look weaker. They’re edging closer to the village, and those killed during stampedes attract polar bears, which are also coming ashore because of the vanishing sea ice.

The community have since set up a patrol to watch for incoming bears and tow walrus carcasses to far-off sites. They’ve also worked with the local aviation service to restrict flights over haul-out sites, to avoid spooking the walruses. And they’ve shared their expertise with their counterparts in Alaska. “In the spring of 2010, we invited Chukchi colleagues to travel to Alaskan villages to talk about their work in protecting polar bears and walruses,” says Margaret Williams, who directs the World Wildlife Fund’s Arctic Program. “They said, ‘Soon our walruses will come to you.’”

That spring, tens of thousands of walruses appeared at Point Lay, Alaska. Such haul-outs were once rare; now they’re an annual fixture, which the U.S. Fish and Wildlife Service says is “most likely” connected to global warming. Walruses, it seems, can no more resist the changing of the world than they can defy gravity.



Earlier this week, an image of a tiny dog in some kind of wild neon dog armor began to ricochet around the internet. A popular dog-rating Twitter account pronounced her coyote-proof. The comedian Andy Richter named the little pup the next host of the Academy Awards. Reddit challenged its users to Photoshop the spiky chihuahua into creative scenarios, sending her into the hands of the pin-faced villain from Hellraiser and under the sea as an anemone. The original photo has 97,000 likes and counting on Twitter.

Back home in Arizona, Beanie was just trying to go for a walk. The now-iconic dog is an 8-year-old chihuahua owned by a longtime friend of mine, the novelist Amina Akhtar. The two live in a remote area outside Sedona, Arizona, where the Sonoran Desert presents certain practical challenges to Beanie’s daily constitutional. “I have to watch out for the zoo outside my windows,” says Akhtar. “We have coyotes, bobcats, and javelinas, which are these weird, aggressive pig things. They’ll attack dogs, too.” Because Beanie only weighs a little over eight pounds, hawks picking her up and flying away are also a concern.

That’s what led Akhtar to buy the viral vest, which features a bright-pink Kevlar body, rows of metal spikes, and several sprays of neon-orange wire. “I had this moment of guilt after I moved back to Arizona from New York City,” she says. “I brought her here, and if anything happens to her, I’m going to feel really bad.” Some Googling led to a company called Coyote Vest, which was founded after its CEO, Paul Mott, lost his dog to a coyote attack in Southern California.

The vests start at $100 for spiked Kevlar. They come in a variety of colors and are somewhat modular: An LCD blinker, a bite-activated shock device, and “whiskers,” which are the sprays of wire that stand up on Beanie’s back in the famous photo, can be added for an additional cost. The vest was designed with coyote attacks in mind, but the manufacturer says it can also help ward off birds of prey and the giant dog down the street whose owners just let it run around the neighborhood. (There’s always one.)

Although Beanie’s protective outfit is decidedly modern, the idea of dressing dogs to ward off attacks has a long, cross-cultural lineage. The ancient Greeks invented the spiked collar to protect their hunting companions from wolf attacks. Today, many Anatolian shepherd dogs in Turkey are equipped with spiked metal collars to protect themselves while they protect livestock. Similar devices are used on working dogs in Italy, Spain, and some parts of the United States. Unfortunately, those don’t come in a variety of fashionable colors.

These attack-prevention methods have historically been used on dogs that guard livestock in remote areas, where they’re in danger from wild predators. But shifting coyote habitats have brought some of those same threats to much more populated areas, according to Stanley Gehrt, an urban-coyote researcher at Ohio State University. “Coyotes have been common in residential areas for a while now,” Gehrt says. “In the last 10 years, they’ve increased dramatically in almost all major cities.”

Still, he says, the threat to pets is very low in most places, and you can do some proven-effective things to safeguard your pet for free, if you’re worried. “In the cases where people do know they have coyotes using their yards, they need to keep a close watch on their dogs and try to haze coyotes when they see them,” Gehrt explains. You can wave your arms at the coyote, yell, and make yourself look bigger and more aggressive to define your yard as your territory. The worst thing you can do? Run back into your house, says Gehrt. “Over time, when you do that, coyotes learn they can make people disappear.”

Akhtar, to her credit, has some instinctual experience with coyote hazing. “Normally, Beanie stays close to me, but this one time, she was about 20 feet away, not wearing her vest. I looked up, and there’s a coyote like 12 feet from her,” she says. Beanie was bounding toward the coyote, ready to make a new friend. “I swear, I didn’t know I would do this, but I charged the coyote. Which was probably really stupid, but all I could think of was, Must save Beanie.” The good news is that, by Gehrt’s logic, this wasn’t stupid at all. All parties came out of the encounter unscathed.

Through some simple behavioral tactics (and, if you want, some viral dog armor), coyotes, humans, and pets can coexist peacefully. “We’re all encroaching on animals’ property, on their territories,” says Akhtar. “So you can’t begrudge them. I don’t hate the coyotes; I just don’t want them to eat my dog.” She’s similarly understanding of the thousands of online strangers who have found Beanie’s outfit so funny. “If this brings joy to people ... then by all means, Photoshop my dog into Mad Max.”



Sixty years from now, climate change could transform the East Coast into the Gulf Coast. It will move Minnesota to Kansas, turn Tulsa into Texas, and hoist Houston into Mexico. Even Oregonians might ooze out of their damp, chilly corner and find themselves carried to the central valley of California.

These changes won’t happen literally, of course—but that doesn’t make them any less real. A new paper tries to find the climate-change twin city for hundreds of places across the United States: the city whose modern-day weather gives the best clue to what conditions will feel like in 2080. It finds that the effects of global warming will be like relocating American cities more than 500 miles away from their current location, on average, mostly to the south and toward the country’s interior.

For instance, the Philadelphia of the 2080s will resemble the historical climate of Memphis. By the time kids today near retirement age, Philadelphia’s average summer will be about 7 degrees Fahrenheit warmer than it is now. Winters in Philly will be nearly 10 degrees more temperate. Memphis’s scorching, sticky weather provides the best guide to how those climatic changes will feel day after day.

Meanwhile, Memphis’s climate will come to resemble that of modern-day College Station, Texas, by 2080.

The paper was accompanied by the release of a new tool that lets Americans find their city’s climate-change twin.

“Everything gets warmer,” says Matthew Fitzpatrick, an author of the paper and a professor at the University of Maryland Center for Environmental Science. “I don’t think I’ve seen a place that doesn’t.” In the West and Midwest, cities also tend to get drier as the Great Plains shift east. So Chicago comes to Kansas, Denver drifts to Texas, and San Francisco starts to feel like Los Angeles.

Fitzpatrick cautions that no city will perfectly match its climate twin, especially when it comes to rainfall. Many cities in the South simply do not have a good twin: “The climate of many urban areas could become unlike anything present” in North America, the paper says.

In the Northeast, you can envision the future as one big Arkansas-ification. The paper finds that if the world meets its goals under the Paris Agreement, then Washington, D.C., will enter the 2080s feeling a lot like Paragould, Arkansas. But if the world follows a worst-case scenario, then D.C. will more closely resemble northern Mississippi—and New York City will feel like Jonesboro, Arkansas.

That worries Virginie Rolland, a resident of Jonesboro and a professor of ecology at Arkansas State University. “That’s in line with what I know, that the eastern U.S. will become hotter and wetter, while the [Midwest] will become drier and hotter,” she told me. Her own research focuses on eastern bluebirds, which have historically spent the summer in New York before migrating south for the winter. But “they’ve started staying in New York” for the winter, she said, “so I know it’s getting warmer there.”

She also warned future New Yorkers about what Jonesboro has in store: “Summer-wise, it’s like Florida here. And I cannot imagine New York like Florida … it’s hard to think about how humid it will be.”

“I wouldn’t wish the hot and humid summer climate of Arkansas on anyone,” agreed David Stahle, a climate scientist at the University of Arkansas, in an email.

“I was shocked, to be honest,” at how southerly many cities would soon feel, Fitzpatrick told me. The research spun out of his own weather worries: “I really like snow, and I thought, Is that still going to happen up here?” he said. But when he looked up his current home in Cumberland, Maryland, he found that it would soon feel like southern Kentucky. He groaned. “I lived in Knoxville for several years, in central Tennessee, when I was doing my Ph.D., and I couldn’t wait to get out of there because it was so hot and humid. I thought, Ugh, the climate’s following me up here.”

Even though Fitzpatrick works with climate data all the time—and knew, as he put it, that “it’s gonna get warmer, whatever”—he had never thought about it like this. “If I have grandkids and they lived in the same place I do,” he said, “they might not recognize this climate that we’re living in now.”



The nearly 2,000-mile border that separates the U.S. and Mexico is not an easily navigable environment. It meanders across deserts and canyons, riverbeds and wetlands. It’s dotted unevenly with fences, walls, and checkpoints built to control immigration between the countries.

President Donald Trump, a year and a half ago, proposed putting solar panels here, on the border wall that had been a rallying cry of his campaign. “Look, there’s no better place for solar than the Mexico border—the southern border,” he said at the time.

It’s not infeasible, technically. The notion of a solar-paneled border wall might have seemed underdeveloped, but a group of scientists based out of Purdue University and other large research institutions are now proposing a plan that, they say, would unite the Republican Party’s call for more border security with the Democratic Party’s calls for a Green New Deal.

Instead of a concrete barrier, these engineers and scientists envision a massive energy infrastructure project at the United States border, in one of the sunniest regions of the southern U.S. With solar panels, wind turbines, water desalination facilities, and pipelines for natural gas, this extensive, snaking complex would theoretically produce clean energy for both countries, spurring economic growth and development in the region.

The infrastructure and accompanying facilities would be placed in between and around existing sections of border fences and walls. Their paper suggests placing wind turbines along high-potential wind-energy sites on the Texas Gulf Coast and in Baja, California. That energy could then be used to desalinate water in the region, which frequently faces droughts and shortages. Solar panels would dot the border in West Texas and New Mexico—an area with the best solar-energy potential in the United States, but little installed capacity.

Given its size and scale, the infrastructure in this plan effectively is the barrier between the two countries. And the paper proposes that it all be accompanied by high-level security, such as drones and sensors, warning of any suspicious activity or threat to the sensitive energy and electric infrastructure—whether that’s humans attempting to cross through it, or the wildlife that inhabits both sides of the border.

Luciano Castillo, a professor at Purdue and the lead author of the paper, doesn’t see the border energy park as a way to stop immigration, which would require a much more holistic set of policies. It could, however, provide jobs and opportunities to people fleeing their home countries. “This isn’t us versus them—we want people to be able to come and work [on this] innovation,” he says. On paper, the idea might seem equal parts fantastical and unfeasible; Castillo sees the proposal as inherently optimistic. To an engineer, it looks like a chance to change the more and more polarized rhetoric around the border, and spur cooperative economic development on both sides.

The proposal, co-written with more than two dozen engineers from large research universities including Texas Tech, Arizona State, and Stanford University, is mostly focused on the technical and economic challenges at hand. It doesn’t address the complexities that drive migration in the region, or the fate of the people who will still ultimately be stopped at a border wall—even if that wall functions as a hub of economic activity. “We’re not arguing that this is going to make everything nice for everyone,” he says.

But it’s not the first time that people have reimagined what the border can or should look like, Geraldo Cadava, a history professor at Northwestern University who focuses on the borderlands, tells me.

In 2006, The New York Times asked 13 architects to reconsider what a border fence could look like, as Congress was debating adding thousands of miles of border fence to the southern border. Some architects declined to participate, because of the politicized nature of the question, but those who were up to the challenge came up with ideas that at least attempted to defy the stark reality of a barrier between nations. Most of the submissions weren’t traditional fences or barriers: one was entirely conceptual, created by heaps of crushed rock that, once heated from below, would cause a mirage-like divider of hot air. Another architect proposed “a strolling, landscaped arcade of lighted glass columns,” marking the border and encouraging social gatherings in the space.

And one of the proposals was described as a “Bush meets Gore hybrid” that tied together the functionality of a border wall with the utility of solar panels—much like the new white paper.

“There’s a long history of alternative imaginations of what the borderlands could become,” Cadava says. “I think this draws our attention to how unproductive our contemporary conversations are.”

When Big Bend National Park was established in the southwestern corner of Texas in the 1940s, then-President Franklin D. Roosevelt envisioned it as an international park that spanned both sides of the Rio Grande. Though the river is, politically, the dividing line between the two nations, ecologically it travels through deserts, mountains, and forests that existed long before any border did.

The inspiration for a binational park came from a similar project along the United States’ northern border: In 1932, Canada and the U.S. established the Waterton Glacier International Peace Park, straddling Alberta, Canada, and Montana. The park is recognized, even today, as a symbol of the goodwill that exists between the U.S. and Canada.

And in Derby Line, Vermont, flowerpots mark the border between the two countries. “That is a really, really different image than a steel fence protruding from the earth, separating people,” says Mary E. Mendoza, a historian at Penn State University.

But if Roosevelt saw the environment of the southern borderland as a natural wonder, its more hostile character has also been used as a strategic tool of border security. In 1994, under the presidency of Bill Clinton, the government adopted a border-patrol strategy known as “prevention through deterrence.” By strategically increasing security and patrolling in large, urban centers such as El Paso and San Diego, the government hoped that immigrants seeking to cross illegally would be driven to more dangerous, and life-threatening, points of entry.

A few years later, a Government Accountability Office report listed “deaths of aliens attempting entry” as one of the indicators of the strategy’s effectiveness. The predicted outcome if the strategy was successful was that “deaths may increase (as enforcement in urban areas forces aliens to attempt mountain or desert crossings).”

By contrast, there is a certain level of optimism in the proposal for an infrastructure plan at the border. If the plan were to come to fruition, it could transform perceptions of the borderlands as an empty, desolate, or dangerous place to one that’s a source of economic growth and productivity.

But even the Sonoran Desert, which stretches from California to Arizona, is a sensitive and complicated environment that would be disturbed by the level of development that Castillo’s plan would require. And a major hurdle to current border-construction projects—even small-scale fences or barriers—is the fact that landowners in the borderlands are unwilling to allow the federal government to seize their property for construction.

“If you were to pick the area where there are the fewest people and ecosystems that wouldn’t be completely destroyed, then perhaps part of the border could be used for energy trading and investment for both nations,” Mendoza says. “But the real problem is that [the paper] proposes to do this along the entire length of the border.”

The borderlands have never been empty: they are dotted with large urban areas such as El Paso, Nogales, and Tijuana, but also small, unincorporated communities known as colonias, which often lack access to clean running water, adequate health care, and housing. In theory, bringing water resources, jobs, and development to these communities would be a positive effect of the proposal. But no one asked these residents what they need, and how they’d like it delivered.

“Before even considering what these communities need, the bigger question is whether there will be a process for consulting with people who would benefit from or could be impacted by these ideas and projects,” Pedro Rios, the director of the American Friends Service Committee’s U.S./Mexico Border Program, says. “That’s a problem we’ve seen coming from both Washington and Mexico City, where decisions are made about policies that don’t reflect the needs of border communities.” For example, he points out, who would operate the drones and sensors the plan proposes to bring in with the infrastructure? Would it bring more private security firms into a region that’s already heavily militarized?

Looking to solve the so-called border crisis with technical and economic solutions tends to elide the very human aspects of the borderlands. A variety of factors, from climate change to political violence, has created the northward migration from Central America that this proposal seeks to address. Those factors show no signs of changing anytime soon. And an energy corridor won’t change the fact that many of the communities that exist along the U.S.-Mexico border have been intertwined for generations. The border is more fluid than most politicians—and engineers—allow. A wall, even with the added value of a green infrastructure project, would still serve as a stark divider.



Let us first establish that sea lions are supposed to live in the sea.

Since the 1990s, however, male sea lions—a handful at first, now dozens—have been captivated by the attractions of the Willamette River. They travel all the way from Southern California to Oregon and then swim up 100 miles of river to arrive at an expansive waterfall, the largest in the region. Here, salmon returning to spawn have to make an exhausting journey up the fish ladders of the Willamette Falls. And here, the sea lions have found a veritable feast.

“They’re kind of sitting ducks,” the wildlife biologist Sheanna Steingass told me, describing the salmon. She paused to consider the metaphor. “Or sitting fish.” Every sea lion eats three to five fish a day.

In another world, this could just be a story about the intelligence of sea lions and their adaptability to river life. But in this world—where many salmon populations in North America have plummeted, and where the winter steelhead run at Willamette Falls has fallen from 25,000 fish in the 1970s to just hundreds in 2018—it’s a dire story for the fish. After spending years trying and failing to deter the sea lions by nonlethal means, the Oregon Department of Fish and Wildlife, where Steingass leads the marine-mammal program, started “lethal removal” of sea lions in December. As of mid-January, they have trapped and euthanized five sea lions at Willamette Falls.





Killing animals to save other animals is always controversial. Animal-rights groups like the Humane Society of the United States denounced the sea-lion killings, calling them a distraction from the salmon’s real problems. And it’s true that a long chain of human actions—overfishing, destruction of salmon habitats, dams blocking their migration, hatchery mistakes—have led to what everyone can admit is this nonoptimal situation.

“In a perfect world, in an unaltered world, this wasn’t a problem, because historically there were 16 million salmon in the Columbia River,” says Doug Hatch, a senior fisheries scientist at the Columbia River Inter-Tribal Fish Commission. The sea lion’s appetites would have barely made a dent. It’s only because humans have so unbalanced the natural world that as drastic an action as culling sea lions could appear to be the fix.

[Read: How climate change canceled the grizzly salmon run]

It’s not the first time this has happened, though. In the 1980s, a sea lion who earned the nickname Herschel began hanging out at the entrance to the Ballard Locks in Seattle. The locks forced all fish through a narrow channel, which was great for Herschel. He would linger by this stream of food, picking off steelheads at his leisure. (Steelheads are technically a type of rainbow trout, but they are similar enough to salmon to have been grouped with them in the past.) Soon, other sea lions started joining in.

The Marine Mammal Protection Act of 1972 protects sea lions from killing, capture, and harassment. But the sea lions at Ballard Locks were eating so many salmon and steelhead—whose own populations were falling—that in 1995 wildlife managers got a federal exemption to remove the three most problematic animals, Hondo, Big Frank, and Bob. (Herschel had stopped coming to the locks by then, either because he died or because he found other hunting grounds.) The three fish eaters were taken to SeaWorld, and wildlife managers deemed the problem solved.

[Read: The fantastical vision for the original SeaWorld]

In the early 2000s, sea lions started showing up en masse at the Bonneville Dam, which, like Willamette Falls, is in Oregon and more than 100 miles upriver. And as at Ballard Locks, the fish have to funnel through one of about 16 entrances to the fish ladders, making them easy pickings for sea lions. Watch the dam for just 15 minutes, says Hatch, and you might witness three to 10 fish kills.

Here too, it was just a few sea lions at first. Perhaps the first one chased a salmon upriver and—what luck!—stumbled upon a buffet. Then he returned with his buddies, and they with their buddies. One hundred to 200 sea lions now hunt at Bonneville Dam. Scientists have actually studied how this specific learned behavior spread through the male sea lions. They compared the diffusion of information through sea-lion social networks to the spread of a disease and recommended intervening early, before an outbreak becomes an epidemic.

This is why, said Steingass, it’s important to address the situation at Willamette Falls quickly. If more sea lions find out about the easy hunting grounds, the fish-and-wildlife department might end up with hundreds of sea lions they have to kill, rather than the 40-odd creatures that currently hunt there. “We’re going to have a better outcome for the salmon but also for the sea lions,” she says. It’s a justification grounded in cold, hard math, but it’s also grounded in the recognition that sea lions are intelligent and social creatures.

And also persistent ones. At Willamette Falls and Bonneville Dam, the wildlife managers tried a number of ways to scare the sea lions off. They set off “seal bombs”—basically firecrackers that sink and go off underwater. They chased sea lions in a boat. Hatch says they have even trapped sea lions at Bonneville Dam and dropped them off in the ocean as far as 500 miles away. The same sea lions were back to gorging on salmon within days. “The truth is that the positive incentive to eat these fish is so great, it’s very difficult to think of a negative conditioning that would be great enough,” Steingass said.

In December, Congress passed a bipartisan bill that streamlines the lethal removal of sea lions. It hasn’t completely gone into effect yet, but once it does, fisheries managers will no longer need to observe an individual sea lion hunting salmon five times before euthanizing it. Both state and tribal fisheries managers in the Pacific Northwest will be able to apply for the lethal-removal permits. The culling of the sea lions had been one of the most visible and controversial parts of salmon conservation, but Steingass and Hatch both said they see it as one small part of the larger effort that also includes habitat remediation and dam removals. If sea lions are gobbling up all the salmon, it negates everything else.

Sea-lion populations were once declining, too, but they have rebounded under the Marine Mammal Protection Act. Such is the challenge for humans trying to manage vast, interconnected ecosystems. Put a thumb on one part of the scale, and something somewhere else goes out of whack. Try to correct that, and you create another problem. Eventually, you end up with a policy of fisheries managers killing sea lions.

The sea lions feasting on salmon had found a clever way to thrive in the human-altered world—until the rules changed and they were on the wrong side.



The Cape honeybee of South Africa seems at first like an ordinary bee. Like many bees, it lives in a colony where the only fertile individual is the queen, who returns from mating flights to lay eggs containing more workers, each pairing the genes of the queen and her mates. But in certain situations, in which the queen is absent or a worker happens upon another bee subspecies’ hive, a worker bee can rise up. Freed from the hormonal stranglehold that the queen usually maintains over the rest of the colony, she begins to lay eggs.

Each new bee is a perfect clone of herself. When they hatch, the rapidly reproducing clones can take wing and raven through the countryside in search of other subspecies’ hives, where they invade hapless victims’ nests, lay their own eggs, and act as parasites until the host colony collapses. But by then, other copies of the insubordinate worker have been born and flown over the horizon in search of new queens to dethrone.

In a bee, this is monstrously strange. Generally, colonies of bees and other social insects function like a single superorganism, with the many supporting the reproduction of the few. They are all so closely related that this amounts to helping themselves. When a Cape honeybee transforms from a placid social insect into a parasite, it’s doing something that appears outside the natural order. Ever since people discovered parasitic Cape honeybees inside collapsing colonies in South Africa, about a hundred years ago, beekeepers and biologists have considered: How does this happen? In a new paper out in Molecular Biology and Evolution, biologists provide the beginnings of an explanation, revealing that a single blip in the genetic code is the only difference between these bees and their peaceful siblings.

From a colony of wild Cape honeybees, the researchers sequenced the genomes of a number of individuals, half of whom were the parasites’ clones and half of whom were not. “We compared these two groups,” says Denise Aumer of the Martin-Luther-Universität Halle-Wittenberg, in Germany, a biologist and a lead author of the paper. “We found only a single locus in the whole genome where they differed significantly.” After decades of mystery, seeing this difference was striking, says Eckart Stolle, Aumer’s colleague and co–lead author: “It was super cool to find a strong signal like this, because you wouldn’t necessarily expect it.”

At that place, they found a one-letter difference between the bees’ genetic codes. Looking closer at the gene, the researchers determined that it codes for a little-studied protein lodged in the membrane of cells, which may be involved in trafficking substances in and out. They also discovered that for bees to switch into this parasitic mode, they must carry a certain version of a second gene. On its own, this gene is innocent of any wrongdoing, unless it winds up in a bee with the one-letter change. Other factors in the bee’s environment, like a weakening of the queen’s hormonal control or the changed bee’s arrival in a fresh host colony, must also align. But with these two genes, a bee is capable of the switch.

Intriguingly, the study explains an odd fact that beekeepers and scientists had independently noticed. It is not possible to breed a Cape honeybee with a closely related bee subspecies and wind up with parasitic offspring—they are always determinedly normal. The reason, it turns out, is quite simple. In Cape honeybees, that second, complementary gene originally comes from the father of the initial worker bee, while the one-letter difference comes originally from the queen, her mother. Thus, any Cape honeybee queen mated with a male from another subspecies will never yield children with both the pieces necessary for the transformation. And it’s probably not a bad thing—it means that no other bee species can pick up this exact behavior. But parasitic Cape honeybees are still a real pest in some parts of South Africa, with campaigns to eradicate them, Stolle notes.

Perhaps this ability, odd as it seems, has been beneficial for Cape honeybees in the evolutionary past. The researchers observed that the bees’ natural habitat is quite windy, and the ability of a worker to transform herself into a kind of queen might save colonies when their queens are blown off course and lost during mating flights. That single genetic change and the hormonal storm it must unleash might have meant the difference between total obliteration and bouncing back from a loss. Rather than a perversion, it might represent a kind of awe-inspiring, if slightly terrifying, flexibility in the face of disaster.



In 1492, best known as the year Columbus sailed the ocean blue, Spain also decided to expel all practicing Jews from its kingdom. Jews who did not leave—and were not murdered—were forced to become Catholics. Along with those who converted during earlier pogroms, they became known as conversos. As Spain expanded its empire in the Americas, conversos made their way to the colonies too.

The stories have always persisted—of people across Latin America who didn’t eat pork, of candles lit on Friday nights, of mirrors covered for mourning. A new study examining the DNA of thousands of Latin Americans reveals the extent of their likely Sephardic Jewish ancestry, more widespread than previously thought and more pronounced than in people in Spain and Portugal today. “We were very surprised to find it was the case,” says Juan-Camilo Chacón-Duque, a geneticist at the Natural History Museum in London who co-authored the paper.

This study is one of the most comprehensive genetic surveys of Latin Americans yet. The team also found a mix of indigenous American, European, sub-Saharan African, and East Asian ancestry in many people they sampled—a legacy of colonialism, the transatlantic slave trade, and more recent pulses of immigration from Asia. This is the history of Latin America, written in DNA.

In the case of conversos, DNA is helping elucidate a story with few historical records. Spain did not allow converts or their recent descendants to go to its colonies, so they traveled secretly under falsified documents. “For obvious reasons, conversos were not eager to identify as conversos,” says David Graizbord, a professor of Judaic studies at the University of Arizona. The designation applied not just to converts but also to their descendants who were always Catholic. It came with more than a whiff of a stigma. “It was to say you come from Jews and you may not be a genuine Christian,” says Graizbord. Conversos who aspired to high offices in the Church or military often tried to fake their ancestry.

The genetic record now suggests that conversos—or people who shared ancestry with them—came to the Americas in disproportionate numbers. For conversos persecuted at home, the fast-growing colonies of the New World may have seemed like an opportunity and an escape. But the Spanish Inquisition reached into the colonies, too. Those found guilty of observing Jewish practices in Mexico, for example, were burned at the stake.

Chacón-Duque and his colleagues pieced together the genetic record by sampling DNA from 6,500 people across Brazil, Chile, Colombia, Mexico, and Peru, which they compared to that of 2,300 people all over the world. Nearly a quarter of the Latin Americans shared 5 percent or more of their ancestry with people living in North Africa and the eastern Mediterranean, including self-identified Sephardic Jews. DNA alone cannot prove that conversos were the source of this ancestry, but it fits with the historical record. This pattern of widespread but low North African and eastern Mediterranean ancestry in the population suggests that its source is centuries old, putting the date around the early days of New Spain. In contrast, more recent immigration to Latin America from Italy and Germany in the late 19th century shows up concentrated in relatively few people in a few geographic areas.

Geneticists have also noticed rare genetic diseases prevalent in Jews popping up in Latin America. “It’s not just one disease. It’s like, wow, this isn’t a coincidence,” says Harry Ostrer, a geneticist at Albert Einstein College of Medicine. In 2011, Ostrer and his colleagues decided to study two populations—in Ecuador and Colorado—with unusually high prevalence of two mutations often found in Jews. (One mutation was in the breast-cancer gene BRCA1, and the other caused a form of dwarfism called Laron syndrome.) And indeed, they found enriched Sephardic Jewish ancestry in the 53 people they tested. With advances in DNA technology, Chacón-Duque and his colleagues were able to carry out similar research, but on the scale of thousands of people.

The idea of Jews secretly living in the New World has attracted considerable mythologizing. Some of it verges into fanciful territory, like the rumors that Christopher Columbus was secretly a Jew looking for a place of refuge for his people. The Atlantic actually published a takedown of some of these stories in 2000, attributing the Jewish-seeming customs of “hidden Jews” in New Mexico to folk beliefs and the Church of God (Seventh-Day). DNA has borne out the fact that the conversos were ancestors to people in Latin American and the American Southwest today, leaving their descendants with the question of what to do with that identity.

By the 17th century, Graizbord says, most conversos had assimilated and lost any connection to Jewish customs. Today, some of their descendants are reclaiming their Jewish identity. They can join Jewish genealogy groups. Some have even converted to Judaism. DNA tests are fanning interest, too. Alexandria Ocasio-Cortez, the New York politician whose family comes from Puerto Rico, recently revealed during a Hanukkah event that she has Sephardic Jewish ancestry.

Before Chacón-Duque joined this study as a scientist, he had actually submitted his own DNA as a participant. He, like the thousands of others who volunteered, was curious about his own ancestry. He grew up in northwest Colombia, and he had heard the stories. It was a local custom to slaughter a pig for festivities, and it was said that you ate pork publicly to prove you were not a Jew. From that and other tales passed through his family, he had wondered. It turns out he has converso ancestry, too.



The giant panda, a consummate vegetarian, belongs to a group of mammals called Carnivora, so-called because almost all of them—dogs, cats, hyenas, weasels, mongooses, raccoons, and more—eat meat. But the giant panda’s diet of bamboo, and little else, makes it a vegetarian.

At least, outwardly.

Yonggang Nie and Fuwen Wei of the Chinese Academy of Sciences have spent years tracking wild pandas, analyzing exactly what kinds of bamboo they eat, and measuring the chemicals within those mouthfuls. And they found that the nutrient profile of a panda’s all-bamboo diet—very high in protein, and low in carbohydrates—is much closer to that of a typical carnivore than to that of other plant-eating mammals. “It was a surprise,” Wei says. Nutritionally, “bamboo looks like a kind of meat.”

In other words, “the giant panda does what human vegetarians do,” says Silvia Pineda-Munoz of the Georgia Institute of Technology. “We have high protein requirements, so we wouldn’t be able to survive if we just ate kale salad. Thus, we choose to eat tofu, beans, nuts, and other plant-based foods that compensate for the protein we aren’t getting from animal products. In the end, vegetarians and nonvegetarians don’t have such different diets when it comes to nutrients.” And so it is with China’s black-and-white bear.  

This discovery explains some puzzling parts of panda biology. The panda’s ancestors switched to a vegetarian diet more than 2 million years ago. In that time, the panda has evolved stronger jaws for chewing tough, fibrous mouthfuls, and one of its wristbones has become a false thumb, for gripping bamboo stems. But despite these superficial hardware changes, it still has a meat eater’s digestive system.

Plant-eating mammals almost always have enlarged, elongated guts to slow the passage of food, and to give their inner bacteria more time to digest their meals. The panda, however, has the short, vanilla gut of a carnivore. Even its gut microbes are closer to a bear’s than, say, a cow’s or deer’s. Nie and Wei’s study makes sense of this paradoxical combination of traits. The giant panda has the plumbing of a half-committed herbivore because it has the diet of a closet carnivore.

The team used tracking collars to follow pandas in China’s Foping National Nature Reserve, which harbors the highest density of these bears in the world. The pandas, it turned out, migrate over long distances to exploit the shoots and leaves of two bamboo species, which grow at different altitudes. Every year, the bears cycle from low-growing leaves, to low-growing shoots, to high-growing shoots, to high-growing leaves, and back again. The team analyzed these varied mouthfuls and determined that the pandas’ decisions seem largely motivated by protein. They’re always selecting the species and tissues that offer the most protein and the least fiber.

Their selective tastes mean that at least 50 percent of their energy comes from protein, while just 39 percent comes from carbohydrates, and 13 percent from fat. That’s comparable to feral cats and wolves, which also get half their energy from protein. And it’s starkly different from other plant-eating mammals, which typically get 20 percent of their energy from protein.

Panda poop, which the team also collected and analyzed, told the same story. So did panda milk. Nutritionally, it stands apart from most herbivore milk, and falls in with typical carnivore milk.

This suggests that the move from meat to plants might have been easier for ancestral pandas than commonly assumed. By simply choosing parts of plants that are richer in protein, they could switch to vegetarianism without needing to radically overhaul their bodies. “If you’re going to switch to a specific plant, bamboo isn’t too bad, as it does have respectable plant protein levels, as well as a swath of different vitamins,” says Garret Suen of the University of Wisconsin at Madison.

These results should help to counter the tiresome myth that pandas are evolutionary dead ends: lazy, poorly adapted creatures that eat deficient diets, are inept at sex, and should be allowed to go extinct. Nonsense. Pandas have beautifully adapted to eat an extremely plentiful food source—bamboo—and they go to great, careful lengths to get exactly the right balance of nutrients.

Perhaps by felling large expanses of China’s bamboo forests, humans have disrupted the panda’s ability to find the specific protein-rich morsels that it needs. And perhaps captive pandas are so famously prone to digestive problems, and loath to breed, because they’re not being fed the right kinds of bamboo.

Pandas aside, Nie and Wei’s study should also make us rethink how we classify animals. Terms such as herbivore and carnivore can be misleading if they only account for what a species is eating, and not the nutrients that it’s actually using for energy. The same goes for labels such as generalist or specialist. The former implies versatility, and the latter, inflexibility. But a generalist animal might eat a wide range of foods precisely because it needs to keep its nutritional levels within narrow boundaries. Its versatility in choices might reflect a hidden, underlying inflexibility.  

Samantha Price of Clemson University wants to know what kind of nutrient levels other bear species shoot for, especially because their diets are so varied. “Sloth bears predominantly eat insects; spectacled bears predominantly eat plants, especially bromeliads; sun bears eat fruit and insects; polar bears rely on marine mammals; while grizzly bears [and] American and Asiatic black bears are omnivorous and will eat fruits, seeds, leaves, insects, and mammals,” she says. Do they all resemble the panda, or do they differ?

Even in these species, appearances can be deceiving. Black and brown bears in the U.S. “have a diet that is about 80 percent vegetation,” Pineda-Munoz says. “During the summer, they load [up] on animal protein for a few weeks, but in general they are herbivores. Diet is more complex than we think.”



Every evening, nocturnal Hawaiian bobtail squids (Euprymna scolopes) emerge from their burrows in shallow waters of the Pacific to hunt for shrimp. These soft-bodied, golf-ball-size cephalopods don’t have much to protect them from predators such seals, eels, and fish. So they rely on another organism to help out: the bacterium Vibrio fischeri. This microbe lives in an organ embedded in the squid’s ink sac and emits light throughout the night to match the illumination of the moon.

“It is basically acting like a little invisibility cloak for the squid,” said Jamie Foster, a microbiologist at the Space Life Sciences Lab at the University of Florida. In return for help with camouflage that protects against predators, the squid offers up sugars to feed the bacteria and lure them into the organ.

This mutually beneficial relationship has evolved over millions of years and is one of numerous examples of how multicellular animals and microbes work together to increase their chances of survival. But scientists still know little about how these relationships evolve or what spurs animals to grow specialized organs that encourage these symbioses.

Now Foster and an international team of researchers have mapped the genome of a Hawaiian bobtail squid, creating a new tool to explore these questions. By parsing the squid’s genome, the team has already discovered that the evolution of its light organ followed a completely different pathway than that of a second symbiotic organ, which supports reproduction. Published in the Proceedings of the National Academy of Sciences, the findings lay the groundwork for future studies of animal-microbe interactions, including those in humans.

This work also marks the completion of the first genome for a squid—and only the second for a cephalopod of any kind, following the publication of a genome map for the octopus in 2015. “Having the genome available will be a tremendous resource for the field of studying symbiotic relations,” said Cliff Ragsdale, a researcher at the University of Chicago who helped map the octopus genome but wasn’t involved in this new study.

Given their tentacles, color-changing skin, and other biological novelties, bobtail squids may not seem like the most obvious candidates for helping with the study of symbiosis in humans or other animals. But scientists have studied this species as a model of symbiosis for more than three decades. “We share a lot of genes, and we share a lot of [genetic] pathways, so we can learn a lot from these model systems about our own health,” Foster said. For example, she noted, humans and squids share some of the same immune-system components. In fact, our immune systems are so comparable that Foster sends squids into space to learn more about the human immune response to space flight.

In addition to these helpful commonalities, the bobtail squid has a unique quality that lends itself to symbiosis studies. Rather than going into partnership with a consortium of bacteria, as the human gut and most other symbiotic organs do throughout nature, the bobtail squid’s light organ cultivates a strictly monogamous relationship with V. fischeri. The squid’s immune system recognizes and nurtures only this one type of bacteria within the light organ, warding off all other suitors. “Because we just have one host and one symbiont, it is easier for us to tease apart what is going on,” said Spencer Nyholm, a symbiosis specialist at the University of Connecticut and a co-author of the study.

With the genome now mapped, researchers can take the next step and explore the origins of the anatomical sites where these relationships unfold. In the case of the light organ, the squid had to be able to monitor and regulate the light it emits to match the light in the sky. “They needed a way to basically do a similar thing as the eye,” Nyholm said. And, indeed, the team found active genes in the light organ that are also used extensively in the squid’s eye, including ones that produce a high concentration of reflective proteins called reflectins. The squid seems to have duplicated and modified genes it already had available to create this helpful new organ—which also happens to include an eyelike lens.

The second symbiotic organ the team studied, the accessory nidamental gland (ANG), arose in a different way. The ANG is found only in females, and it produces a gelatinous, bacteria-laden coating that protects the squid’s eggs from being befouled by other colonizing microbes. The organ houses many types of bacteria, and it intensely expresses novel genes that are active nowhere else in the bobtail squid’s body—nor in any other squid. “It had to make up these genes in order for this organ to evolve,” Nyholm said.

While the two organs evolved separately, they both appear to have sprung into being relatively recently in squid evolution—roughly 30 million years ago, in the case of the light organ. That’s roughly 240 million years after squids and octopuses diverged.

“I think it’s a tremendous contribution,” said Angela Douglas, an entomologist who studies symbiosis at Cornell University and the author of the book The Symbiotic Habit. She noted that, with the genome, researchers should be able to rule out certain scenarios about how these organs evolved and dig deeper into how animals form healthy relationships with their microbes.

“We have this paradigm that ‘microbes are bad,’ ‘cleanliness is next to godliness,’ and that animals are supremely good at detecting microorganisms and killing them,” Douglas said. And yet many creatures commonly provide a habitat for microorganisms. “Not only do we tolerate them,” she added, “but we actually need them.”

The new genome will also help researchers study how microbes influence host evolution and vice versa, said David Bourne, a marine biologist at James Cook University in North Queensland, Australia, and the author of a recent mBio paper documenting evidence for this type of co-evolution across a variety of marine species. “The mind-boggling diversity and abundance of microbes makes it daunting to begin to understand these concepts of co-evolution,” he said. But the simplicity of the bobtail-squid model, and now the availability of the genome, will help unravel some of this complexity.

The different ways organisms rely on microbes go far beyond camouflage and egg protection. For example, honeybees rely on eight different types of gut bacteria to stay healthy, and aphids rely on bacteria to produce amino acids they can’t readily find in their diets, according to Nancy Moran, an evolutionary biologist at the University of Texas at Austin, who edited the new paper. In Moran’s genomic studies of aphids, she has found that the insects build their amino-acid-producing organ with a combination of recycled genes and new ones—“or at least they have evolved so much that you can’t see what they are related to anymore,” she said.

In addition to feeding and housing their microbes, animal hosts have evolved to support the beneficial work they do. Researchers think the bobtail squid might use its ink sac like a camera shutter to regulate the amount of light coming out, Nyholm said. And some of the squid’s blood cells seem to make their way into the light organ and sacrifice themselves, releasing sugar granules in the process. The bacteria then use the sugar for fermentation, which creates an acidic environment that helps the bacteria’s light-producing enzyme, luciferase, generate light.

Humans have evolved specific microenvironments that support microbial activity too, Nyholm pointed out. The stomach is quite acidic, whereas the colon is more alkaline—and the different microbial communities in each organ prosper under these respective conditions. As in the squid, the human immune system has evolved to recognize and welcome its symbionts in these different locations.

But when signals go awry and our immune system can’t recognize these beneficial bacteria, conditions like inflammatory bowel disease and other immune disorders can arise, Nyholm noted. So by understanding how squids communicate with their bacteria in these different environments, researchers may eventually come to understand the basis of some of these immune diseases, he said.

The advantage of studying this symbiosis in the squid is its natural simplicity: While the human gut teems with diverse microbes and is hard to view, the squid’s light organ has a one-on-one relationship with V. fischeri and is surrounded by transparent skin. “The squid system is exquisite for being able to actually watch the bacteria enter the host,” said Mark Mandel, a microbiologist at the University of Wisconsin at Madison, who studies microbial symbiosis in bobtail squids as an analogue for other systems and was not involved in this study.

To take the next step in understanding how animals communicate with their microbes, researchers are now working to develop methods to manipulate and knock out genes in squid to explore which ones are essential to which functions. “You can start asking bigger questions,” Foster said.

And with several other cephalopod genomes in the pipeline for completion—including those belonging to the giant squid, the blue-ringed octopus, and others—and with the technology to produce these more easily than in the past, researchers will soon be better equipped to sleuth out what’s unique to the bobtail squid and what might be more universal among cephalopods and other animals, Ragsdale said.

Once these other genomes become available, likely within the next several years, he added, “that will really open up the field.”

This post appears courtesy of Quanta Magazine.



It’s remarkable: A number of polls suggest that Democratic voters now consider climate change to be a top-tier issue, as important as health care. Perhaps even more remarkably, the party’s presidential candidates seem to be taking that interest seriously. Jay Inslee has staked his candidacy on the issue; Beto O’Rourke has used a climate proposal to revive his flagging campaign; and Elizabeth Warren has cited the warming planet across a wide set of her famous plans.

This week, Joe Biden joined their ranks, releasing a lengthy climate plan on his website. Though Reuters teased his policy last month as a “middle ground” approach more moderate than the Green New Deal, the proposal looks pretty aggressive and sounds almost Bernie Sanders–esque in its ambition. What the United States needs, Biden says, is a “clean energy revolution.”

That revolution’s main objective: achieving a “100% clean energy economy” in the United States by the year 2050. It’s an ambitious goal, both more stringent and longer-sighted than what the previous Democratic White House—which Biden unfailingly calls the “Obama-Biden administration”—pledged under the Paris Agreement on climate change. To meet its old Paris target, the United States had to cut its annual carbon emissions by 1.3 percentage points every year from 2016 to 2025. To meet the 2050 goal, it must cut at more than double that rate—2.9 percentage points—for each of the next 31 years.

Of course, pending both a revision to the Twenty-Second Amendment and a surge of investment in brain-in-a-jar technology, Biden will not be president 31 years from now. He does not propose a specific binding mandate, such as a carbon tax or a cap-and-trade regime, to carry the country all the way to that mid-century goal.

Instead, Biden says he will work hard to point the federal ship of state toward climate action. He promises to implement a muscular set of executive orders on his first day in the White House. He will require public companies to disclose climate-incurred costs, deploy the federal government’s purchasing power on the side of clean energy, and restrict the release of the superpowerful greenhouse gas methane from oil and gas wells. He will also “require any federal permitting decision to consider the effects of greenhouse gas emissions and climate change”—a policy that could have led to a different outcome in the Keystone XL and Dakota Access pipeline battles.

Biden also promises to wring $1.7 trillion in investment from Congress, “the largest-ever investment in clean energy research and innovation.” This money will fund a new technology-development program modeled on the Pentagon’s R&D agency, DARPA. This new “ARPA-C” will focus on the big and mostly unsolved challenges of decarbonization, such as electricity storage, advanced nuclear power, carbon capture, aviation emissions, and zero-carbon cement and steel manufacturing. The longtime Amtrak commuter would also push Congress to “spark the second great railroad revolution,” catching up to high-speed rail in Europe and China. He says he will halve rail-travel times from New York to Washington and extend his old train line—the Northeast Corridor—into the “fast-growing South.”

Finally, Biden says he will use the various instruments of global governance, including the International Monetary Fund, to pressure China and India to reduce their carbon emissions.

I have not glossed all the details here; the full proposal exceeds 10,000 words—although, as Business Insider and The Daily Caller have reported, the plan appears to have lifted language directly from climate-advocacy groups in at least five different places. (Biden’s campaign says the error was inadvertent and that the proper citations have now been added.) As the political scientist Leah Stokes has remarked, those lapses suggest that the policy was compiled hastily, almost in reaction to other candidates’ work.

And there is plenty of other work to draw from. Inslee, the governor of Washington who is running for president on a single-issue climate campaign, can claim to have a more detailed and ambitious proposal than Biden. Today Inslee debuted a plan to reenter the Paris Agreement and enshrine climate at the center of U.S. diplomacy. It runs more than 50 pages single-spaced.

Inslee earlier outlined his aim to decarbonize some parts of the U.S. economy by the 2030s, and he has endorsed some aspects of the Green New Deal. Representative Alexandria Ocasio-Cortez, the Green New Deal’s champion, told a reporter yesterday that Inslee’s plan is the “golden standard.” (Inslee’s plan is also untainted by plagiarism accusations.)

If anyone comes close to Inslee-level detail, it’s Warren, who also announced an ambitious climate policy yesterday. Like her other climate plans, which have targeted the Pentagon and public-land management, this one seems, at first, to focus on another issue.

Warren calls this issue “economic patriotism.” Under its banner, the senator from Massachusetts and presidential candidate proposes a huge new program of climate-friendly manufacturing investment, meant to turn the United States back into a major industrial exporter. She would spread R&D funding across all regions of the country and focus American trade policy on maintaining exporting power. This program would go hand in hand with her also just debuted “Green Manufacturing Plan,” which promises to allocate $1.5 trillion in federal spending for climate-friendly technology. She would also use federal power to encourage other countries to purchase this new American gear.

Essentially, Warren wants to bring Germany or South Korea’s mixed-economy model to the United States and then point it at the challenge of climate change. As I wrote in February, this suite of approaches—often called industrial policy, though Warren brands it as “economic development”—has roots in the ideas of Alexander Hamilton. It’s also clearly inspired by the same economic thinker, Mariana Mazzucato, who has consulted with Ocasio-Cortez and her allies about the Green New Deal.

Which is no coincidence. Even if neither Biden nor Warren becomes president, their proposals demonstrate how the Green New Deal seems to be winning the battle of ideas among Democrats, at least for now. On his website, Biden even praises Ocasio-Cortez’s proposal by name, calling it “a crucial framework for meeting the climate challenges we face.” And both his plan and the Warren plan—and the Inslee climate plan, and O’Rourke’s proposal—adopt its theory of change, emphasizing that gushing federal investment can help the U.S. economy solve the problem of climate change. All four proposals, to varying degrees, promise a new age of plenty, a dawning era of renewed American dauntlessness. And they show how the window of political possibility has already moved significantly, such that Biden’s $1.5 trillion in climate-focused federal spending can start to seem moderate to right-wing observers.

In the Washington Examiner yesterday, the conservative writer Tiana Lowe paid relatively high praise to Biden’s plan. Unlike the Green New Deal, she said, Biden’s proposal is “not insane,” but a “legitimate, big-boy climate change plan” in its own right. She complimented its mention of nuclear power and focus on Chinese and Indian emissions. Lowe should look more discerningly: Any Democrat, except for maybe Sanders, would fund advanced nuclear approaches, and all of them would undoubtedly try to nudge down Asian pollution. Yet compared with the Green New Deal, those relatively milquetoast climate policies may suddenly seem friendly and effective to the right. “If nothing were executed into action here except for the international aspect, nuclear research and development, and the infrastructure developments that [Biden] details, it would do more to decrease greenhouse gas emissions in real life than any $93 trillion Green New Deal,” Lowe wrote.

That may come as news to actual supporters of a Green New Deal, who know a victory when they see one. In the opinion of the youth-led Sunrise Movement, Biden’s plan is far better than the “middle ground” proposal he was considering last month. “We forced [Biden] to backtrack and today, he put out a comprehensive climate plan that praises the Green New Deal,” it tweeted yesterday. It is not the last time, I suspect, that self-described moderate Democrats will find themselves praising that “pie in the sky” proposal.



Not long ago, I found myself in the south of Greenland, in a tidy cottage at the edge of a fjord, in the company of four scientists. We were talking about sea-level rise when one of the younger scientists asked whether I could settle a debate: Should we keep developing nuclear power? He thought we should. I said that I didn’t have a strong opinion, but it seemed like a good way to produce electricity without emitting greenhouse gases. A lot of economists seemed to think it would be essential to fighting climate change.

The most senior scientist in the room, who had spent his life studying the fragility of Earth’s climate, cut in. You can’t be serious, he said. We’d learn to deal with climate change in time. But nuclear power made nuclear waste—and that was the worst, most poisonous stuff on the planet.

I thought of that moment this week, as the behind-the-scenes battle over the Green New Deal erupted into public view for the first time. Since its debut last year, the Green New Deal has become remarkably popular among Democrats, reviving progressive dreams of a muscular federal climate policy that also improves the lives of workers.

There’s just one wrinkle: There’s not a single, official Green New Deal. Much like “Medicare for All,” “Green New Deal” refers more to a few shared goals than to a completed legislative package. (The original New Deal basically worked the same way.) Now a number of environmental groups are trying to make those goals more specific. But they’re running into a snag: The bogeymen that haunted old progressive climate policies are suddenly back again. And the fights aren’t just about nuclear power.

Late last week, more than 600 environmental groups published a letter laying out an environmental agenda for the new Congress. The groups did not explicitly describe a Green New Deal, but their sought-after legislative program looked and quacked a lot like one. They demanded an all-renewable power grid, an end to fossil-fuel exports, and a ban on gas-powered cars by 2040. “If we are to keep global warming below 1.5 degrees Celsius, we must act aggressively and quickly,” the letter said.

Of the hundreds of groups that issued the demands, one stood out: the Sunrise Movement, a new, youth-led activism corps that flung the Green New Deal into national prominence last year. More established organizations—including Friends of the Earth, 350.org, and the Center for Biological Diversity—also signed.

The letter seemed like the standard collection of progressive climate goals, but on closer inspection it veered into new and controversial territory, especially in the places where the groups said what they would not support. They promised to “vigorously oppose” any legislation that promoted nuclear power, hydroelectric power, and carbon capture and storage, a still-experimental technology that could remove carbon dioxide directly from the atmosphere. They also forbade Congress to use any “market-based mechanism” to administer climate policy.

The absolute nature of these demands reportedly kept a number of established green nonprofits—including the Sierra Club, the Audubon Society, and the Environmental Defense Fund—from signing the letter. And the Sunrise Movement has backed off the letter somewhat. Stephen O’Hanlon, a spokesman for the group, told me that the letter to Congress is “not the full vision of the Green New Deal. It is a set of climate priorities for the new Congress.”

But the demands point to a broader shift for Sunrise—particularly around the issue of carbon capture and storage. In November, when Sunrise first demanded that Nancy Pelosi create a Green New Deal committee, it said that any potential plan must fund “massive investment in the drawdown and capture of greenhouse gases.” Sunrise seemed, in other words, to endorse carbon-capture research.

But the final version of that same document omits capture at all: It calls only for investment in the “drawdown of greenhouse gases.” This change has not been previously reported, and it appears to have been made quietly. Greg Carlock, who developed a different Green New Deal plan for the left-wing think tank Data for Progress, told me he was not aware of the change. 

“Oh my goodness,” he said. “There is no scenario produced by the IPCC or the UN where we hit mid-century decarbonization without some kind of carbon capture.”

Indeed, the demand to back off carbon capture is at odds with climate science. Sunrise’s explicit goal is to keep average global temperatures from rising by 1.5 degrees Celsius. But the Intergovernmental Panel on Climate Change has not produced any projection that shows us hitting that target without massively deploying carbon-capture technology. The same goes for a two-degree goal.

Despite its scientific necessity, carbon-capture technology does not yet exist at any real industrial scale. Yet research into carbon capture is sporadic and poorly supported, especially in the academy. Because very few tenured professors study carbon capture, very few graduate students pursue it as a dissertation topic. This leads to a curious allocation of resources. If I want to talk to an expert about Europe’s climatic conditions in the 1650s, I could choose from any of several dozen people. But if I want to talk to an authority on carbon capture, there are only a small handful of respected experts.

Sunrise confirmed the change in a statement. “We want to ensure that the Green New Deal doesn’t continue the practice of placing fossil-fuel infrastructure in working-class communities and communities of color. We want to strive toward forms of energy that don’t exacerbate these inequities,” O’Hanlon said. “As it is defined right now, it is not clear whether carbon capture and storage would do so.”

This new skepticism tracks with the views of other progressive groups. Many see carbon capture as a way for oil companies to escape blame for climate change and remain in business. President Donald Trump himself has used the excuse of so-called clean coal to repeal EPA policies, even though those facilities can still produce toxic air pollution. There’s also real confusion (and overlap) between technology that sucks carbon out of coal-fired smokestacks and technology that could scrub it from the atmosphere. But this is why Sunrise’s original support was intriguing: It seized the mantle of carbon capture for the left. It is rare to see nearly the entire official scientific apparatus, in the United States and around the world, call for the same policy—yet it has done so about carbon capture. As long as Sunrise demanded “massive investment” in carbon capture, it could accurately claim that its policy took the side of science.

Sunrise says a more comprehensive plan will come out soon. If that plan also opposes carbon capture, it will represent the left’s abdication of a key battlefield. The American public should be arguing about who should invent and control carbon-capture technology: private industry? the federal government? the IPCC? Instead, the debate will be stuck on the less practical question of whether it should exist at all.

The same goes for the letter’s other absolute demands. The ban on market rules may make sense as a goal for this coalition: The Green New Deal, after all, is supposed to represent the most anti-neoliberal climate policy possible. But as David Roberts has written at Vox, the nuclear and hydroelectric ban are more head-scratching. A wide range of research suggests that Sunrise’s 1.5-degree goal is not possible with wind and solar energy alone. It will require other “no carbon” forms of energy.

“It is firmly understood that going 100 percent renewable in 10 years is technically impossible—like, physically and engineering-wise, it is impossible,” Carlock told me. “You will make decisions you will later regret.” If the goal is to tackle carbon emissions, then it can be counterproductive to take other forms of no-carbon energy out of the mix, he added, since there’s evidence it is replaced by fossil fuels.

Climate policy always comes down to two things: how you think an economy should be run, and how important you think it is to fight climate change. The Green New Deal excited young progressives because it told a big, happy, forcefully pro-government story of an ideal economy—and then it put fighting climate change at the very center of that story. Ruling out anything but wind and solar energy moves the climate out of that spotlight. It suggests activists are willing to trade carbon emissions for other, local environmental risks.

There was one last reason it felt strange to see Sunrise reject other forms of low-carbon energy: It is a youth movement, after all. Many older environmentalists, raised on The China Syndrome and the Reagan-era ‘No Nukes’ campaign, have opposed nuclear power reflexively all their lives. Climate-concerned Millennials, meanwhile, have been more willing to grant its risks as preferable to a ruined climate. They have been joined by some, but not all, mainstream green groups.

And this is why I thought of that moment in Greenland. The Green New Deal gives the left an opportunity to put the urgency of climate change at the absolute center of a social-democratic society. It gives the public a chance to have new debates—about who should own carbon-capture technology, about who should pay for the costs of climate change, and about who should control the energy system writ large. If Millennial-led groups automatically adopt the old fights of environmental Boomers, the next few decades of climate policy could be doomed to look a lot like the last few.



The picture of a black hole, captured for the first time, shows a ring as radiant as gold against the darkness of space. At its center, the charcoal shadow of a void so powerful, nothing can escape its pull.

The dreamy photograph represents a tremendous technological achievement, assembled using eight radio telescopes in four continents—two each in Hawaii and Chile, and one each in Arizona, Mexico, Spain, and Antarctica—all synced together to scan the skies for several days in a row.

But the picture would not exist without technology much less sophisticated: computer disk drives.

The telescopes’ data had to go to two astronomy institutions to be processed, MIT’s Haystack Observatory in the United States and the Max Planck Institute for Radio Astronomy in Germany. An email attachment wasn’t going to work. The observatories had collected five petabytes of data. The average iPhone has 64 gigabytes of data storage. One million gigabytes are in one petabyte. It would have taken years for the data to cross the internet.

And so the data were carried on hundreds of hard disk drives, shipped to and from the observatories through plain old FedEx. Which is kind of marvelous, when you think about it. In a world where transferring information from one end of the world to another takes only a click, some things still have to be done the old-fashioned way. Humanity owes its first glimpse of one of the most mysterious objects in the universe not to something flashy and high tech, but a technology that has been around since the late 1950s, and transportation methods far older.

And to find out how it’s done, you have to talk with Don Sousa.

Sousa is a computer-support specialist at the Haystack Observatory. He’s also the shipping guy. He handled virtually every shipment for the Event Horizon Telescope, the effort to photograph a black hole.

Sousa grew up a few towns over from Haystack and has the trademark Boston-area accent to prove it. Over decades at the observatory, he has packaged equipment, put in orders, wrangled foreign customs regulations, and filled out reams of paperwork so that all kinds of hardware, from atomic clocks to disk drives, gets where it is needed. Before disk drives became widely available, he shipped reels of magnetic tape. “It’s amazing the differences from the mid-eighties, when I started, to what we do now,” Sousa says.

For the Event Horizon Telescope, Sousa packaged the disk drives in groups of eight. (“These are off-the-shelf hard drives,” he says. “You could buy them for your own personal computer if you wanted.”) The stacks were placed inside custom cases that allowed data to be recorded on all eight drives at once. Each module—eight disks, plus their custom coating—weighed about 23 pounds. Sousa shipped them in boxes labeled fragile and lined with a two-inch layer of foam, with cutouts in the middle to snuggle the modules, like precious jewelry in an antique box.

Sousa says he uses mostly FedEx and UPS. Some routes were trickier than others. Chile and Mexico had stricter rules about what could cross their borders. Sousa had to obtain a special license from the U.S. Department of Commerce to ship a particular piece of equipment to Mexico.

The toughest destination was the South Pole Telescope in Antarctica. Without a nation to decide customs law, the continent relies on shipping agencies in Christchurch, New Zealand, which dispatch cargo ships and planes to the ice. Sousa had to coordinate with the National Science Foundation, which operates the research station where the telescope is based. Shipments had to meet very detailed specifications; Haystack had to build a wooden crate to carry the modules, because plastic containers weren’t allowed. “If it gets to Christchurch and something’s wrong, your equipment just sits there,” Sousa says.

The journey to the eight observatories was fine. It was the return trip that was worrisome. There were too much data to go through the burden of making extra copies; the disks that flew out of the stations were the only ones they had. “Going out there, they’re just blank,” says Mike Titus, the researcher who operated the supercomputer that helped synthesize all the data into a single, composite image. “Coming back, they’re precious commodities.”

I asked Titus whether the team considered asking a file-sharing service like Dropbox to build them something capable of transferring all those petabytes. “Don’t tell me that Amazon Cloud and Google Cloud, they wouldn’t love to have our data and store it for us,” Titus said, laughing. But even groundbreaking scientific teams don’t have that kind of budget. “Too much data and too much money—that’s why we don’t do it that way. Nothing beats the bandwidth of a 747 filled with hard disks.”

The return of the disks from the South Pole was particularly welcome. The shipment arrived months after all the rest thanks to the Antarctic winter, which had prevented anyone from flying in. The staff at Haystack was jubilant when FedEx arrived with a truck full of cosmic goodies from the bottom of the Earth. “It’s like they thought we were expecting penguins to jump out of the box or something,” says Nancy Wolfe Kotary, the communications officer at Haystack.

Sousa understood the concern, but he wasn’t too worried himself. “I’ve shipped to every continent,” he says, and in his 32 years on the job, he hasn’t lost one package.

Well, there was one, but it wasn’t his fault, or even the fault of any shipping company. The equipment, bound for a new research station in South Africa, cleared customs in Johannesburg and was loaded onto a truck. On the road, the truck was hijacked, and its contents stolen. “To this day, we figure it’s sitting somewhere on a coffee table as a conversation piece,” Sousa says.  

Sousa plans to retire in three years and enter a new phase of his life that doesn’t require checking tracking alerts every day. He doesn’t have a background in science; before joining Haystack, he worked as a police officer for the state of Massachusetts. For him, the photo is the culmination of years’ worth of effort by astronomers and shipping experts alike. But the actual shot, he says, is pretty impressive, too.



Governments around the world spend an enormous amount of money every year making it cheaper for fossil-fuel companies to exhaust the planet. But they’re not spending nearly as much as a recent report may make it seem.

The International Monetary Fund recently updated its comprehensive report on global fossil-fuel subsidies. It arrives at a staggering conclusion: In 2017, the world subsidized fossil fuels by $5.2 trillion, equal to roughly 6.5 percent of global GDP. That’s up half a trillion dollars from 2015, when global subsidies stood at $4.7 trillion, according to the IMF. If governments had only accounted for these subsidies and priced fossil fuels at their “fully efficient levels” in 2015, then worldwide carbon emissions would have been 28 percent lower, and deaths due to toxic air pollution 46 percent lower.

The report suggests a morally grim situation: As the planet careens toward climate catastrophe, governments are forking over trillions of dollars—one-fifteenth of the global economy!—directly to oil, coal, and gas companies. But the challenge of combatting climate change through politics is much more difficult than some tidy math can make it seem. This calculation suggests that recalibration would be simple. If we only cut those subsidies, then carbon pollution would plunge, and we’d be much further along in addressing the climate challenge.

Alas, such a clean fix is impossible, because the $5.2 trillion figure includes much more than a cash transfer from government to businesses. By the commonsense definition of the term, governments actually subsidized fossil fuels by $296 billion in 2017, according to the report.

I’m not going to say that represents a more or less grim situation than the alternative. But it is undoubtedly a much smaller number, and it can misstate the overall problem of climate change. It’s not that someone is already paying the huge costs of fossil fuels; it’s that everyone and no one is.

Why does the IMF seem to overstate subsidies 17-fold? It comes back to its definition of subsidies. The report says they come in two flavors. First, there are pre-tax subsidies, which reflect the difference between what people pay for a fuel and what it cost to produce. This is what we usually mean when we say subsidy: Exxon might only be able to break even selling a gallon of gas for $3.50, but the government might decide that the best price for gasoline is actually $2.50. If it provisions public funds to pay this discount, then we would call the resulting $1 a subsidy.

But wait! Then the report adds that there is actually another kind of subsidy, which it calls a post-tax subsidy. This subsidy reflects the difference between “actual consumer fuel prices” and the full societal and environmental costs of a fuel.

These costs are very large: The burning of fossil fuels releases deadly air pollution, hastens the destruction of the climate, and (sometimes) increases traffic fatalities. And since all of those things kill people, they also depress a country’s tax base. Account for both the harms and the smaller tax base, says the IMF, and you produce an overwhelming number. In 2017, post-tax subsidies came to $4.9 trillion, or 94 percent of the total.

Those costs are very real. And they represent a subsidy of sorts: They are a grant of something valuable (our lungs, our home planet, our lives) to assist an enterprise deemed advantageous (the burning of fossil fuels). But they’re not entirely a grant of money to the oil companies.

They’re sort of like a grant of something valuable exchanged among ourselves: If the air pollution from my gas stove causes you to have a fatal heart attack, then I reaped most of the excess benefits of that arrangement (I didn’t have to go chop wood to cook dinner), my gas company earned a smaller share (collected via my monthly bill), and you paid for the difference. Every year, 70,000 to 107,000 Americans subsidize air pollution with their life. Of course, before you were stricken, you were on the “winning” side of that deal many times—the exact number dependent on how often you burned fossil fuels during your life.

Which sharpens the point: The burning of fossil fuels demands the grant of something valuable not from one equal to another, but from the poor to the rich, from the weak to the powerful. The wealthy can and do burn more fuels, after all. A remarkable study published this year in Proceedings of the National Academy of Sciences found that black and Hispanic Americans experience about 55 percent more air pollution than they cause. White Americans, meanwhile, suffer 17 percent less air pollution than they cause. No wonder black children are four times as likely to die from asthma as white children.

Does that represent a subsidy? The IMF report hopes to treat it like one. So it assigns a dollar amount to every harm inflicted by fossil fuels. The cost of air pollution varies by country—poorer countries are more willing than rich countries to accept dirty air—but it comes out to $2.3 trillion worldwide. Then the report reviews three different ways of calculating the future cost of climate change, before deciding (somewhat arbitrarily) that each additional ton of carbon in the atmosphere imposes $40 of global costs. That comes to $1.1 trillion in costs overall. Another $735 billion comes from the estimated costs of traffic, of road upkeep, and of car fatalities.

These are the post-tax subsidies that dominate the IMF’s math. Note that they can’t be fixed by the removal of anything. They can be remedied only by the imposition of new policies, such as a carbon tax, an air-pollution tax, or a congestion tax. That is what the IMF means when it says that setting “fully efficient” prices could cut greenhouse-gas emissions by 28 percent.

Meanwhile, the pre-tax subsidies—the ones we can remove—are much smaller. They have “declined substantially” over the past decade, the IMF says, and in many cases, they are getting removed. In 2017, they stood at $296 billion, almost half of their 2012 levels of $572 billion. What’s more, nearly all of these subsidies (96 percent of them) help people buy fossil fuels, not companies extract them. As I wrote last year, this makes the situation even harder to predict. It’s not easy to say what will happen when those subsidies, especially in countries like the United States, go away.

Yet some subsidies are going away, according to the IMF. Several countries, including Brazil and Malaysia, have recently contemplated increasing subsidies. But at least seven oil-producing countries in the Middle East recently slashed their subsidies. At the end of 2015, Saudi Arabia increased regular gas prices by 67 percent and electricity tariffs by 35 percent, according to the report. Jessica Jewell, a political-economy researcher, told me last year that activists would do the most good by targeting subsidies like these in oil-producing countries.

And what about that $4.9 trillion? Is that a subsidy? I suppose you can see it that way—but I’m not sure who the framing helps. Activists who target that $4.9 trillion will soon discover that it doesn’t exist. Nor do I think it captures the insidiousness or ubiquity of fossil fuels. A subsidy sounds like a simple grant. But that $4.9 trillion represents something much weirder. Fossil fuels ensnare all of us in the same invisible network of consequence: They feed wildfires and acidify the ocean; they reward wealthy adults and punish powerless children; they punish the adults, too, by stopping their heart. They bind our decisions to the lives of strangers who haven’t yet been born.

Fossil fuels also produce an enormous amount of energy at a fairly low cost—that’s why we use them in the first place. We depend on them because rich countries, such as the United States, have failed to invest in any other arrangement. But the fossil-fuel companies that have plotted and lobbied and coddled to prevent that investment aren’t doing so to preserve their trillions in subsidies. They want to keep us using their product, without thinking too hard about the cost.



Last December, the environmental group Rainforest Trust celebrated its 30th anniversary by auctioning off the rights to name 12 newly discovered species, including orchids, frogs, and an ant. The Virginia-based nonprofit group reported that the auction raised $182,500 for its conservation programs. The most valuable animal turned out to be a wormlike amphibian from Panama, which drew a winning bid of $25,000 from a British sustainable-building-materials company called EnviroBuild.

Shortly afterward, the company proudly announced the name it wanted to bestow on the blind amphibian: Dermophis donaldtrumpi. EnviroBuild said it chose it to bring attention to climate change, which President Trump is “blind” to. “Realizing the similarities between the amazing but unknown creature and the leader of the free world, we couldn’t resist buying the rights in your president’s honor,” Aidan Bell, the co-founder of EnviroBuild, told The Washington Post.

With more than 27,000 species at risk of extinction, auctioning off naming rights seems like a fairly harmless way to increase public awareness and raise much-needed funding for conservation efforts. But as the auctions continue—there are several a year at the moment, according to news reports—some scientists worry about the potential for overly commercial or offensive names. Once a name is recorded in the scientific literature, it will last forever unless declared invalid after further research. There’s also the possibility that assigning the wrong name might actually threaten a species’ survival, as in the case of ​a beetle named by a collector after Adolf Hitler in 1937 that is sought after by modern neo-Nazis.

“I’m not a fan,” Christian Kammerer, a research curator in paleontology at the North Carolina Museum of Natural Sciences, says of naming auctions. “I think it cheapens taxonomy as a science and an art.” Even so, he understands the motivation: “Taxonomy is in a rough place right now. In general, when we are not funding crucial climate-change and emerging-disease research, taxonomy is very low on the list.”

The protocols of modern taxonomy were established more than 280 years ago by the Swedish naturalist Carl Linnaeus, who created a hierarchical network for classifying all living organisms known as the binomial-nomenclature system. So far, approximately 1.5 million species have been cataloged, and as the number has grown, zoologists, botanists, and paleontologists have become more creative in assigning names to their discoveries. Biologists with a whimsical bent have named deep-sea worms after Star Wars characters (Yoda purpurata) and frogs after their favorite musicians (Dendropsophus ozzyi). Recently, a newly discovered frog less than half an inch long was aptly named Mini mum. There’s even an extinct parrot called Vini vidivici.

In most cases, researchers don’t realize they’ve found an unnamed species while out in the field: “Species discovery usually happens in a museum after comparing collected specimens in a lab,” says Prosanta Chakrabarty, an associate professor and a curator of ichthyology at Louisiana State University. New examinations can find new species in museum collections that were deposited decades ago. It’s then up to a scientist to figure out a name and provide a written description of the species, he says. The scientist also needs to identify a type of specimen that serves as the exemplar for that species and register it for storage in a permanent collection.

Chakrabarty explains that scientists do their research autonomously—because they are the experts on the organismal group in question—and rarely consult their institutions before they publish a description and name of a new species. If naming rights are to be auctioned off, this would have to be an arrangement that scientists, and a university or nonprofit, have to come to on their own, he says, adding that permission from the country where the discovery is made should be granted before auctions.

The naming of new animal species is regulated by the International Code of Zoological Nomenclature, which states that discoveries should be published in a widely available “public and permanent scientific record,” which generally means a peer-reviewed scientific journal. (Other codes exist regarding the naming of plants, fungi, viruses, and bacteria.) While the ICZN code doesn’t set out specific guidelines for “allowable” names, a section in the appendix on ethics states that “No author should propose a name that, to his or her knowledge or reasonable belief, would be likely to give offence on any grounds.” It adds, however, that “the observation of these principles is a matter for the proper feelings and conscience of individual zoologists, and the Commission is not empowered to investigate or rule upon alleged breaches of them.” Adherence to the ICZN code as a whole is also not compulsory.

As a result, researchers have wide latitude, and not much can be done once a species has entered the permanent record. Scientists usually stick to formal scientific names derived from Latin and Greek, but get the most attention when they target famous people. Barack Obama, for example, has at least 13 animals (and one fungus) named in his honor as a president who worked hard to expand conservation protections in the United States. But occasionally these decisions can backfire, as in the case of the Hitler beetle or that of a parasite named after the reggae legend Bob Marley, much to the chagrin of some Jamaicans.

Some taxonomists, such as Kammerer and Chakrabarty, acknowledge the financial benefits that auctions can bring, but also warn of the long-term risk. “A few thousand can go a long way for a taxonomist, but for permanent entry into the scientific literature? It seems like a pittance,” Kammerer says. Chakrabarty says auctions that result in a species being named after someone not involved in the work can be “abhorrent to the culture of science” and argues that there are other ways to get funding for field work.

Many taxonomists prefer the tradition of naming species to honor individuals who have worked in the given scientific field, or the native lands where the species was discovered, because the plants, animals, and fossils are often an important part of their cultural heritage. “Whenever you name something after someone, it can take away from the purpose of naming species in the first place,” Chakrabarty says. “The genus and species of an organism are a way to communicate their unique features.”

Naming auctions seem to have become more popular since 2005, when the discovery of a new titi monkey in Madidi National Park in Bolivia drew considerable attention from the news media. Researchers at the Wildlife Conservation Society, working with a nonprofit called Fundación para el Desarrollo del Sistema Nacional de Áreas Protegidas, decided to auction off the naming rights.

Robert Wallace, the director of the Greater Madidi-Tambopata Landscape Conservation Program for the WCS in Bolivia, was part of the team that discovered the monkey. “It was an opportunity to bring attention to an amazing place, because we saw this primate primarily in and adjacent to Madidi National Park,” Wallace says.

“It was also an opportunity,” he adds, “to help build financial sustainability for the protected area, which is always something that is unfortunately a challenge for protected areas in Latin America and worldwide.”

The winner, with a bid of $650,000, was the online casino GoldenPalace.com. The casino opted to call it the “golden palace monkey,” as it’s commonly known today, though Wallace and his colleagues went with Callicebus aureipalatii in their official taxonomic description, with aureipalatii meaning “of the golden palace” in Latin. Nearly 15 years later, the money from the auction is still being used for conservation in the region.

As for Dermophis donaldtrumpi, which has yet to be officially described in the scientific literature, not everyone is on board with EnviroBuild’s decision. “It is just mean to the creature,” Kammerer says. “I think all animals, all organisms, are precious and irreplaceable and worthy of respect.”

This post appears courtesy of Undark Magazine.



Last week, at Christie’s auction house in London, an anonymous buyer paid almost $625,000 for the skeleton of a dodo bird. More precisely, the buyer purchased a set of fossilized bones belonging to at least two different birds, dug up and assembled into a skeleton by collectors. The last such assemblage sold in 2016 for about $430,000. Before that, no dodo skeleton of any kind had been offered for public sale for nearly a century.

Even for a species that, famously, has been extinct for more than 350 years, dodo remains are scarce. The University of Oxford has a dodo head—the only specimen that includes any soft tissue—and a skeletal dodo foot. There’s a dodo skull in Copenhagen, and a dodo beak in Prague. The British Museum used to have its own dodo foot, but lost it around 1900.

“The dodo remains that were collected while the bird was still alive would fit in a shoebox,” says Leon Claessens, a paleontologist at the University of Maastricht, in the Netherlands.

The rest of what remains of the dodo, in public and private hands, is fossilized, made up of bones that were buried in caves and bogs for thousands of years. Today, the most complete dodo specimens on public display are two fossilized skeletons, one on the dodo’s native island of Mauritius and the other in Durban, South Africa. And both were excavated during a craze for dodo memorabilia that occurred centuries after the species went extinct.

In the late 16th century, when Dutch sailors returned home from Mauritius with stories about a large, ground-nesting bird, the dodo was just one of thousands of unfamiliar species that travelers were describing and displaying to European audiences. “There were all sorts of wonderful animals coming into Europe—you had the first giraffe, the first cassowary—so the dodo was just another interesting animal,” says Julian Hume, a British artist and paleontologist.

As dodo numbers plummeted, their eggs gobbled up and their habitat destroyed by the rats, cats, dogs, and pigs that disembarked from arriving ships, nobody in European scientific circles suspected that the species was in trouble. At the time, most people in Europe and elsewhere still believed that all species were divine creations, and that extinction of any kind was impossible. Not until the late 1700s did scientists realize that extinction was possible, and not until the mid-1800s did they accept that it could be caused by humans. By that time, the dodo was so long gone that it was only hazily remembered—as a kind of vulture, or albatross, or even a small ostrich. Some people suspected that it was more like a mermaid, in that it had never existed at all.

The dodo was rescued from mythical status by two Victorian researchers, Hugh Strickland and Alexander Melville, who collected surviving firsthand accounts of the species in an 1848 book called The Dodo and Its Kindred. The book brought public attention to the dodo, inspiring Lewis Carroll to include a plump fictional dodo in Alice’s Adventures in Wonderland—and prompting amateur and professional scientists to begin searching, belatedly, for real dodo remains.

Perhaps inevitably, the search got competitive, and the competition got nasty. In 1865, after years of looking, a schoolteacher named George Clark discovered a jumble of fossilized bones, including dodo bones, in a Mauritian marsh called the Mare aux Songes. Richard Owen, an anatomist at the British Museum, was so eager to get ahold of Clark’s finds that he laid claim to bones meant for his colleague Alfred Newton—knowing that Newton, whom Owen had recently recommended for an academic appointment, would be in no position to protest. Newton’s brother Edward, a colonial administrator in Mauritius, was outraged: “I must say that I feel very indignant about the conduct of Owen in the case of Clark’s Dodos,” he wrote to Alfred. “He has shown himself to be a very mean-minded illiberal sort.”

While scientists squabbled over the bones from the Mare aux Songes, Louis Etienne Thirioux, a Mauritian barber and avid amateur naturalist, was quietly looking elsewhere. Thirioux, who reportedly entertained customers with his “genius for conversation,” nonetheless spent his Sundays and holidays alone, reading scientific literature and hiking through the mountain range that bisects the island. In the late 1800s, he started excavating fossilized bones from caves and river valleys, eventually assembling the two dodo skeletons now displayed in Mauritius and Durban. (Almost all the bones in the skeleton in Mauritius are thought to be from a single individual; the skeleton in Durban, like all other dodo skeletons known today, is a composite.)

Claessens speculates that Thirioux traded or shared some of the individual dodo bones he found with Paul Carié, a Frenchman who owned the land surrounding the Mare aux Songes in the early 1900s. Using dodo bones from his marsh and some loaners from Thirioux, Carié assembled a number of piecemeal skeletons. He sold or donated all but one—which remained in his family until it was sold in London last Friday.

The dodo is better understood than it used to be. From its few remains, scientists have learned that it was neither vulture nor ostrich but a member of the pigeon family; that it was probably svelter and faster than early descriptions suggested; and that despite the dodo’s reputation as a hapless victim, its anatomy and behavior were beautifully adapted to its environment.

But the species is gone, and the dodo’s story will always be as fragmentary as its remains. “Every time you think you’re getting close, your hands almost touching it, it just seems to move away, so that you can’t quite work out what this bird was doing,” Hume says ruefully. “It’s always a little out of your grasp.”



It was in the archives of the Archbishop of York that Matthew Collins had an epiphany: He was surrounded by millions of animal skins.

Another person might say they were surrounded by books and manuscripts written on parchment, which is made from skins, usually of cows and sheep. Collins, however, had been trying to make sense of animal-bone fragments from archaeological digs, and he began to think about the advantages of studying animal skins, already cut into rectangles and arranged neatly on a shelf. Archaeologists consider themselves lucky to get a few dozen samples, and here were millions of skins just sitting there. “Just an obscene number,” Collins told me, his voice still giddy at the possibilities in their DNA.

In recent years, archaeologists and historians have awakened to the potential of ancient DNA extracted from human bones and teeth. DNA evidence has enriched—and complicated—stories of prehistoric human migrations. It has provided tantalizing clues to epidemics such as the black death. It has identified the remains of King Richard III, found under a parking lot. But Collins isn’t just interested in human remains. He’s interested in the things these humans made; the animals they bred, slaughtered, and ate; and the economies they created.

That’s why he was studying DNA from the bones of livestock—and why his lab is now at the forefront of studying DNA from objects such as parchment, birch-bark tar, and beeswax. These objects can fill in gaps in the written record, revealing new aspects of historical production and trade. How much beeswax came from North Africa, for example? Or how did cattle plague make its way through Europe? With ample genetic data, you might reconstruct a more complete picture of life hundreds of years in the past.

Collins splits his time between Cambridge and the University of Copenhagen, and it’s hard to nail down exactly what kind of -ologist he is. He has a knack for gathering experts as diverse as parchment specialists, veterinarians, geneticists, archivists, economic historians, and protein scientists (his own background). “All I do is connect people together,” he said. “I’m just the ignorant one in the middle.”

Collins began his scientific career studying marine biology, thanks to a formative teenage viewing of Jaws. He specialized first in marine fossils and, later, in the ancient proteins hidden inside them. This turned out to be a dead end. For the most part, the fossils were too old and the proteins no longer intact enough to study. He was forced to look at younger and younger material, until he crossed from paleontology into archaeology. He applied the techniques of protein analysis to pottery shards, in which he found milk proteins that hinted at the diet of the people who used those pots.

Collagen, a protein abundant in bone, also turns out to be especially useful. A student of Collins’s named Michael Buckley developed a technique called ZooMS to analyze bone collagen and rapidly ID the type of animal it came from. Scientists recently used ZooMS to identify a human bone sliver found in a Siberian cave; further DNA analysis revealed it to be the bone of a half-Neanderthal girl.

Collins quickly realized that DNA held even more potential than ancient proteins, which can be “a blunt tool compared to DNA.” The DNA of any single animal is, after all, a library coding for all the proteins their cells can make. “DNA is a phenomenally powerful tool,” he said. “There’s so much information there.” So when Collins embarked on the parchment project, he gathered a team that included geneticists as well as archivists, bookmakers, and historians.

It didn’t take long for the group to hit their first culture clash. In science and archaeology, destructive sampling is at least tolerated, if not encouraged. But book conservators were not going to let people in white coats come in and cut up their books. Instead of giving up or fighting through it, Sarah Fiddyment, a postdoctoral research fellow working with Collins, shadowed conservationists for several weeks. She saw that they used white Staedtler erasers to clean the manuscripts, and wondered whether that rubbed off enough DNA to do the trick. It did; the team found a way to extract DNA and proteins from eraser crumbs, a compromise that satisfied everyone.

The team has since sampled 5,000 animals from parchment this way. They’ve found that a type of ultrafine parchment, sometimes purported to come from squirrels or rabbits, actually comes from the typical cow, sheep, or goat—and that the thinness of the parchment is the result of the parchment makers’ skill. They’ve compared the genomes of cows in parchment with that of modern ones, finding similarities to Norwegian Reds and Holsteins. They’ve found that the parchment comprising a 1,000-year-old book known as the York Gospels seemed to come mostly from female calves, which was puzzling because you usually want female calves to grow up to give birth to more cattle. A zooarchaeologist on the team suggested that an outbreak of cattle plague might have killed those calves first.

Collins is not the first person to think of getting DNA from parchment, but he’s been the first to do it at scale. Timothy Stinson, an English professor at North Carolina State University, published a paper on parchment DNA in 2009. He had batted the idea around with his brother, a biologist, and they sent off parchment samples to a commercial DNA lab. But even once he demonstrated that it was possible, Stinson had trouble getting more funding for the project.

It was a case study in why interdisciplinary research is difficult. The National Science Foundation would tell him that they didn’t work on livestock, and he should call the USDA. He’d talk to the USDA, and they’d tell him that medieval books fell under the purview of the National Endowment for the Humanities. He’d talk to humanities people, and they’d say, Genetics research? That already has all the money. “I really did get on this constant loop of everyone wanting me to call someone else,” Stinson says. Then Collins got in touch to collaborate—he had gotten a big grant from the European Research Council that encouraged interdisciplinary teams. Stinson is interested in how monasteries and courts sourced the parchment in their documents, and what that reveals about economic contacts in different medieval settings.

Earlier this year, Collins won a grant from the Carlsberg Foundation to study beeswax. In honor of the bees, he dubbed the project ArcHives. The idea originally came from an archivist who showed Collins a document with a wax seal. Collins is excited about the possibilities of DNA in beeswax—from humans handling the wax seal, from the bees themselves, and from pollen trapped inside. The DNA could reveal who worked with beeswax, where in the world it came from, and even the flowers that grew in that region year to year. And as with parchment, Collins went searching for experts in the history and production of beeswax. Alexandra Sapoznik, a medieval historian at King’s College London, has studied the historic beeswax trade. When Collins reached out to her, she remembers thinking, Wow, someone else, wax! She is particularly interested in how beeswax made its way from beekeepers in North Africa to Europe.

When it comes to the world of archaeology and DNA, “Matthew Collins knows everybody,” says Thomas Gilbert, a geneticist at the University of Copenhagen who has studied DNA from artifacts such as aurochs horn. Gilbert recruited Collins to the University of Copenhagen. Since then, they have worked together on another project getting DNA out of millennia-old chewing gum from birch-bark tar.

Studying the DNA in artifacts is still a relatively new field, with many prospects that remain unexplored. But in our own modern world, we’ve already started to change the biological record, and future archaeologists will not find the same trove of hidden information in our petroleum-laden material culture. Collins pointed out that we no longer rely as much on natural materials to create the objects we need. What might have once been leather or wood or wool is now all plastic. 



When I was in sixth grade, the cool girls at my school drew up a document they called the popularity pyramid. Everyone was sorted into a handful of social categories; suffice it to say, I, along with the plurality of the class, was relegated to the lowest tranche and designated a Loser Beyond Belief.

Now a pair of scientists are doing something similar with the birds of the United States. In a paper published Monday in the Proceedings of the National Academy of Sciences, they ranked 621 avian species by their popularity. But unlike the pyramid of my past, this list isn’t meant to give any animal an inferiority complex; instead, the authors hope that it can be used to boost the profiles of lesser-known species in a way that’s best suited to their unique traits and talents.

The most popular birds in America are more or less what you’d expect: They’re large, they’re widespread, they’re popular mascots or children’s characters. The snowy owl, the common raven, and the bald eagle are all among the top 10. The authors of the paper, Alison Johnston of Cornell University and the Maine-based biologist Justin Schuetz, measured popularity by looking at the number of Google searches a species generates compared with the number of sightings recorded in a bird-watching database called eBird. Bigger birds tended to produce more hype, as did species that are mascots for sports teams. Bright colors, migration, frequent feeder visits, and endangered or threatened status also added small popularity boosts.

Many birds in the lowest ranks of the avian “it list” are found only in small areas in the southwestern United States. That puts them at a disadvantage, since, like the kids in middle school who hung out only in the band room, relatively few people are likely to have ever heard of them. Take the Couch’s kingbird, a gray-and-yellow number that came in dead last. Tim Brush, an ornithologist at the University of Texas at Rio Grande Valley, says the bird is ecologically “very successful” in South Texas, but doesn’t often travel to other parts of the country. Its cousin, the eastern kingbird, dresses in a much more subdued black-and-white getup, but its range covers more than half of the continental United States. The eastern kingbird ranks more than 200 places higher than the Couch’s.

Other less exalted species suffer from shyness, a condition that will be familiar to many an uncool sixth grader. The MacGillivray’s warbler—bird No. 617 out of 621—is what ornithologists call a “skulker” because it likes to stay under the cover of thick vegetation. When Jay Pitocchelli, who studies the species at Saint Anselm College, goes out in search of the birds, he says, “I’m looking for a mountain range, and then I’m hoping that there’s a logging road or there’s a U.S. Fish and Wildlife Service road or there’s a mining road” that will take him far into the hills. That’s not a route most people are likely to take, which means that the MacGillivray’s warbler isn’t a bird most people are likely to see and Google.

The popularity (or lack thereof) of many species can’t be helped. Their appeal to humans “is, to a large extent, going to be determined by the evolutionary history of the bird as well as a lot of the behavior of the bird,” says Sean Mahoney, who studies Lucy’s warblers (No. 619 out of 621) and other birds at Northern Arizona University. That is to say, you can’t change the fact that these birds are small, dull-colored homebodies who hate social interaction. And you can’t change the fact that humans think all those characteristics are boring.

That, according to Mahoney, is the point of the paper. “This is a really important paper because it allows us to identify what it is about birds that people value,” he says. Given what these rankings reveal about how humans judge different species, he says he would plan conservation efforts around Lucy’s warblers in a very specific way. He wouldn’t emphasize the bird’s small stature or its gray-and-brown feathers, he says, because “people don’t care about these things.”

Instead, he’d point to the important ecological role Lucy’s warblers play in the Southwest: The birds are the only western warblers that nest in cavities, and they help maintain those cavities for other animals such as lizards, snakes, and even small mammals that use them to escape the heat. “I think that would be something that people could get on board with,” he says.

Other less glamorous species have different redeeming qualities, which could be leveraged to craft and improve their public image. MacGillivray’s warblers, despite their shyness, like to broadcast their originality—“almost every individual bird has an individual song, different from the one next to him,” Pitocchelli says. Couch’s kingbirds, the biggest losers of all, are devoted parents. They aggressively defend their young from much larger predators such as hawks, and use their body to shade their eggs from the boiling Texas sun.

Deborah Finch, of the U.S. Forest Service, says there are plenty of ways dull-colored birds can make up for their less compelling exteriors. “There’s a lot of species that can be flashy and drab at the same time,” she says. “They’re flashy because of their behavior.” The plain chachalaca, for example, is a pheasant-like bird with brown feathers. Its favorite activity is hopping up into a tree and screaming at the top of its lungs. At No. 604 out of 621, it’s still pretty unknown, but at least it’s got a big personality. That’s something the uncool among us can all get behind.



We are made of star stuff, as Carl Sagan told us. The first stars ignited billions of years ago, out of the cold, primordial gas in the dark universe. The stars blazed until they exploded in bursts powerful enough to forge heavy chemical elements. The process repeated itself, over and over, all across space. The new elements found their way into other stars, and then planets, and, eventually, life.

It’s a remarkable cosmic tale, with a recent twist. Some of the stardust has managed to become sentient, work out its own history, and use that knowledge to better understand the stars.

Astronomers know stars so well, in fact, that they can tell when one doesn’t belong—when it’s migrated to our galaxy from a completely different one.

Today astronomers study the chemical compositions of stars near and far, from our own sun to the most distant points of light. They do it with the help of spectroscopy, a technique that is much cooler than its clinical name suggests. Astronomers take starlight, absorbed and collected by telescopes, and break it down into its constituent lines, same as a prism of glass stretches light into the colors of the rainbow. These lines correspond to different elements, from the light kind, such as hydrogen and helium, to the heavy stuff, such as gold and platinum.

Some stars have a signature that’s entirely distinct from their neighbors’, and there are a few of them in our very own galaxy, including one identified recently by a group of scientists based in Japan and another by an international team. The chemical compositions of these stars, their ratios of one element to another—those markers make them unlike any other star in the Milky Way, which is home to some tens of billions.

The stars in the Milky Way have similar chemical makeups because they emerged from the same clouds of gas, infused over time with a range of elements from the stellar explosions we call supernovae. “Stars are formed from gas, and whatever spilled into the gas prior to the formation ends up being in the star,” says Anna Frebel, an astronomer at MIT who has detected and studied one of these rogue stars. “It’s like genes that are being passed on.”

The chemical signatures of the interlopers suggest that they originated in environments without too many stellar explosions. For astronomers, this is a clear indication that the stars flickered on somewhere else.

How does this happen? The Milky Way, like many galaxies, is surrounded by other, smaller galaxies. “Just like the Earth has satellites, artificial and natural—man-made satellites and the moon—our galaxy also has satellites,” says Marion Dierickx, a postdoctoral fellow at the Harvard-Smithsonian Center for Astrophysics. “These occasionally fall in.”

The Milky Way has little trouble absorbing these galaxies and their contents when gravitational forces draw them near. “Our galaxy was built up over time as smaller galaxies collided and merged with each other,” says Douglas Boubert, a junior research fellow at Magdalen College at Oxford. “The oldest stars we see flying round the Milky Way today were all born in precursor galaxies.”

When galaxies merge, stars are jostled and settle into new orbits. So do planets and moons. The process is so slow, unfolding over millions of years, that any inhabitants of these planets, if they could fathom such things, wouldn’t know about the cosmic merger until millions of years after it happened. “We always think things are static in the cosmos, but they really are not,” Frebel says.

Astronomers have used spectroscopy to detect rogue stars in the satellite galaxies around our own. In 2011, they discovered that the composition of more than 5 percent of the stars inside the Large Magellanic Cloud didn’t match that of its other stellar residents. Those rogues resembled stars in the Small Magellanic Cloud, a nearby galaxy, instead. At some point, the larger cloud had stolen them away.

Astronomers say many more stars of this nature are in the Milky Way, but they are tricky to find. They orbit at the very edges of the galaxy; by the time their light reaches telescopes on Earth, it’s incredibly faint. “You can’t mount, at this point with our technology, a systematic campaign to identify these,” Dierickx says. “You find one candidate, you do thorough follow-up observations, and you come up with a detailed characterization—doing this kind of study for many stars would take a very long time.”

Dierickx recommends looking at these stars as a reminder of the Milky Way’s place in the cosmos. Vast expanses of space separate our galaxy from everything else, but the distances are not as insurmountable as they seem.

“That might be interesting, to the average layperson, to not think of our galaxy as living in splendid isolation in dark, empty space, but thinking of this richer picture with dozens of galaxies, satellites flying around in all directions and falling in every once in a while,” she says. “They really have contributed to building our Milky Way as we know it.”



When Tim Gullicksen began donating to a sperm bank in 1989, he never expected to meet his biological children. He never imagined renting a 15-passenger van to take them to California’s Bass Lake every summer. Or envisioned the kids hiking, playing pranks, and competing viciously over silly games they invented together. But this July, Tim will—as has now become an annual tradition—rent that van, fill it with food from Costco, and take the kids out to Bass Lake for a week.

The “kids” are 18 to 25 years old now, adults really. Some have been coming to Bass Lake for a decade.

Over the years, they have found Tim in one of two ways: a website called the Donor Sibling Registry, which connects people by donor number, or, more recently, DNA tests from 23andMe or AncestryDNA. These tools have allowed many donor-conceived people to connect with their donors and donor siblings. But Tim, a 52-year-old real-estate agent in San Francisco, is unusually involved, and the sibling group unusually tight-knit. When I asked whether I could interview any of the siblings, he shot off a message in their Instagram group chat. Eleven of them quickly agreed.

“I just feel really lucky. This is a really, really cool situation,” says Emma Walker, who met Tim after taking a DNA test four years ago, when she was 16. She went to her first Bass Lake reunion in 2016. “It was overwhelming in the best of ways,” she says. “We pulled up in a car, and people just ran up to us and were hugging us.”

As Tim remembers it, he decided to donate sperm after reading about lesbians looking for donors in a San Francisco gay-pride magazine. How great, he thought, to help families have kids. As a young gay man in the ’80s, decades before marriage equality, he didn’t think he would otherwise have children. But he soon learned that he could not donate to a sperm bank—for the same reason he could not donate to a blood bank. Because he had sex with men, he was seen as a risk for HIV.

The controversial policy is in place even today, even though banks have long quarantined and tested sperm for HIV. It didn’t sit well with Tim, so he lied. He passed all the health screenings, began donating regularly, and for years never thought about it much. His sperm went all over the country. Unlike other donors, who provide sperm mostly for cash, he did eventually want to meet his donor kids, but he didn’t expect to—at least not until they were 18 and came looking for him on their own.

In the mid-2000s, Tim heard about the Donor Sibling Registry, and for the first time, he realized he might get to know his donor kids as kids. He signed up. He matched with a handful of the moms who had picked him as their sperm donor. Still, he says, “they all seemed really reluctant.” They had their own lives and their own families; they weren’t ready to bring in a stranger. He stopped checking the site regularly because he wasn’t getting frequent messages.

But Si’Mone Braquet and her 9-year-old son, McKay, were different. When Tim didn’t respond immediately to her message on the Donor Sibling Registry, she emailed the site’s founder, who in turn forwarded the message to Tim. He remembers her saying in their first phone call, “Your son wants to meet you.” Those words stuck him. “That’s the first and only time,” he says, “that someone who has gotten their donor sperm from me has referred to the child as mine.”

McKay had started asking about his dad when he was about 5. At school, he would make cards for Father’s Day, only to have no one to give them to—so he started keeping a “daddy box.” Once Si’Mone got in touch with Tim, father and son started talking for an hour every day. Tim came down to visit during his spring break. “I’m super nervous,” he recalls. “I have no idea what to expect.” McKay remembers waiting by the big window at the front of his house, scanning the street for his dad. For two strangers, even for two genetically related strangers, they hit it off. They rode bikes. They went by McKay’s school. And McKay gave Tim the daddy box.

Once the other moms saw photos of Tim with McKay on the Donor Sibling Registry, they got comfortable with the idea of their kids meeting him too. He started going to see other kids—a boy near Los Angeles, a girl near San Francisco, and so on. He also began coming out one by one to their moms. “I was super nervous about it at first because I had lied,” he says, but none of them made a huge deal about it. Once, before Tim went to visit McKay in Texas, Si’Mone’s family did bring up a photo that her family had found, of him with “cross-dressers.” He corrected her. “I was like, ‘Honey, they’re drag queens. They’re different because they have a sense of humor,” he recalls, laughing. It didn’t bother Si’Mone after that, and as the kids themselves have gotten older, they have also realized in their own time that Tim is gay.



Tim started taking the boys and girls on separate group trips—Iceland, Paris, London, New York City—but he quickly became overwhelmed. So he hatched the idea for Bass Lake. Years ago, when Tim was young, his father would take the family camping there. The lake is a reservoir operated by PG&E, and the company’s employee association rents out the old workers’ cabins. In his 30s, Tim decided to revive the Bass Lake tradition for his family and friends, and soon started inviting his donor kids along. He has now met 17 of them. He has matched with several more donor offspring on 23andMe and Ancestry, and even more are likely out there.

McKay, who has known Tim since he was 9, calls him “Dad.” “For me, it was definitely about having a dad,” he says, though he acknowledged that most of the siblings didn’t feel the same way. “A lot of the siblings weren’t as interested in the dad portion as they were in the siblings.”

Amelia Meier, for example, wasn’t particularly curious about her father. But she did desperately want siblings. “I would do sweet but crazy stuff. I would give my mom my spare change—‘I’ll help you adopt a kid.’ I used to write notes to her. I used to write letters to fairies ... I would look at adopting sites and fostering sites,” she says. “I was very motivated.” Amelia’s mother was one of the first who got in touch with Tim on the Donor Sibling Registry, and Amelia began going to Bass Lake with her siblings in 2009. It seemed like her wish came true, I said. “Yeah,” she replied. “Yeah, it did.”

As Tim’s donor kids got older, they have started finding him on their own, rather than through their moms. Sam Leicht learned she was donor-conceived when she was 16, when her parents were in the middle of a custody battle. She found Tim by tracking down his donor number. As they began to talk, he told her about all her half siblings and invited her to Bass Lake.

Sam grew up with a twin sister (also related to Tim), but now she suddenly found herself with eight or nine more half siblings. And naturally, she started looking them all up on Facebook. “I actually made an Excel document of every name and face, just so I could get them straight before I met them all,” she says. They started chatting on Facebook and Instagram and Snapchat. She met them all for the first time at Bass Lake in 2015.

Sam wasn’t sure exactly how to describe her relationship with Tim, which isn’t quite that of father and daughter. “He’s kind of my funny gay uncle,” she says. Growing up in the Midwest and going to Catholic school her whole life, Sam hadn’t known a single person who was gay and out. But several of the siblings are also queer, and several had been raised by lesbian moms. Sam came out during her senior year of high school. “I don’t think I would have had as supportive of an environment for getting on that path to self-discovery if I hadn’t known all these lesbian moms or Tim,” she says. She had messaged Tim about coming out to her parents, and the two of them talked about it a lot as they got closer.

Sam is 21 now and in college in Portland, Oregon, which she also credits to Tim’s influence. “I always thought my own life would be on the East Coast or in the Midwest,” she says. But she visited Tim in San Francisco, went to Bass Lake, and fell in love with the landscape. She ended up applying to a few schools on the West Coast, and it all worked out. “I’m outside my house right now, and there’s giant pine trees all around. It’s gorgeous,” she says.

After Emma found her half siblings in 2015 through an AncestryDNA test, she remembers seeing a photo of Sam in which she immediately recognized herself. “She looks so much like me. It was so freaky and cool,” she says. Emma recently graduated from college with a degree in sociology, and she’s gotten interested in studying donor-conceived people. For her, going from a small, quiet family with one sister to a big, loud group of siblings was new and strange and exhilarating.

The one word the siblings kept using to describe themselves is competitive. “Anything that is compete-able is competed,” says Amelia. At Bass Lake, they’ve spent hours competing to balance the longest on a floating log or on an inner tube being pulled on a boat. And for the rest of the year, they have Snapchat. A couple of the brothers have years-long Snapstreaks with each other, and recently they’ve been trading high scores for games inside the app. Tim is in the Instagram group chat, but Snapchat is kids only, they told me. After all, says McKay, “it’s pretty weird when any grown man has Snapchat.”

Tim, for his part, is a consummate planner, and he is already thinking about how the Bass Lake tradition will continue when the siblings have relationships and families of their own. He has created something bigger than he could have known. “Bass Lake was more out of efficiency,” he says. “And I realized a few years into it, their connection with each other is more important, which is an awesome gift.”



Saturn has confounded scientists since Galileo, who found that the planet was “not alone,” as he put it. “I do not know what to say in a case so surprising, so unlooked-for, and so novel,” he wrote. He didn’t realize it then, but he had seen the planet’s rings, a cosmic garland of icy material.

From Earth, the rings look solid, but up close, they are translucent bands made of countless particles, mostly ice, some rock. Some are no larger than a grain of sugar, others as enormous as mountains. Around and around they go, held in place by a delicate balance between Saturn’s gravity and their orbiting speed, which pulls them out toward space.

Scientists got their best look at the planet nearly 400 years after Galileo’s discovery, using a NASA spacecraft called Cassini. Cassini spent 13 years looping around Saturn until, in September 2017, it ran out of fuel and engineers deliberately plunged it into the planet, destroying it. More than a year later, scientists are still sorting through the data from its final moments, hoping to extract answers to the many questions that remain about Saturn.

The latest findings, published Thursday in a study in Science, answer a fundamental but surprisingly evasive question: How much stuff is actually in those stunning rings? Estimates of the mass of the rings have varied wildly for decades, starting with the twin Voyager spacecraft, which whizzed by Saturn in the late 1970s and early 1980s on their way through the solar system. Even Cassini, nestled inside Saturn’s orbit, couldn’t provide accurate measurements until the very end.

For most of its life, Cassini’s orbit was outside both Saturn and its rings. “You got a combined mass of Saturn plus the rings, and there was really no way to separate it out,” says Linda Spilker, the lead scientist for the Cassini mission, who was not involved in the latest research. “Here was our first chance.”

In its last maneuvers, Cassini wove in and out of Saturn’s rings. The spacecraft was jostled by the gravity of the bands, as well as powerful winds emanating from deep within the planet’s atmosphere. Scientists used the data produced by these effects to calculate the mass of the rings. They say that the mass is about 40 percent that of Mimas, a moon of Saturn, which is about 2,000 times as small as Earth’s moon.

In more earthly terms, the rings are about half the mass of the entire Antarctic ice shelf, spread across a surface area 80 times that of Earth.

“It is the most accurate measurement of the rings of Saturn,” says Bonnie Buratti, a planetary scientist at NASA’s Jet Propulsion Laboratory who worked on the Cassini mission but who was not involved in the study. “The error margins are kind of pretty big—there’s about a 25 percent, almost 30 percent uncertainty—but it’s way more accurate than anything we’ve had before.”

The new estimate helps to answer another Saturnian question that has puzzled scientists: How old are the rings? For decades, the scientific community was split into two camps. One believed that the ring system formed when Saturn did, 4.6 billion years ago, when the solar system as we know it emerged from swirling clouds of dust left over from the fiery birth of the sun. The other suggested the rings were a youthful feature, formed only 100 million years ago, when dinosaurs walked the Earth.

The latest research bolsters the case for a more recent origin. According to current models, the more massive the rings, the older they must be, and vice versa. The new study suggests that the rings are less massive than scientists suspected, which means they’re also younger. The study authors say their new estimate, combined with previous research, suggests the rings are 10 million to 100 million years old.

There’s plenty of wiggle room in that range. Other analyses focused on the margins of error in Cassini data suggest that parts of the ring system may be as old as 1.5 billion years.

Still, most scientists now agree that the rings did not form alongside Saturn. This leads us to yet another unresolved question: Where did the rings come from? A primordial origin story would have been a very convenient one: The young solar system was a chaotic mess of flying debris, and it would have been possible for Saturn to lasso some of it into a lasting orbit.

Scientists now suspect the rings are the fragmented bits of a cosmic interloper. A moon, a comet, or an asteroid must have strayed too close to the planet. Trapped between two gravitational forces—one tugging it toward Saturn, and the other drawing it away—the object broke into shards. Over time, the pieces flattened out into a delicate disk. “It’s like a graveyard spread around the planet,” says James O’Donoghue, a scientist at NASA’s Goddard Space Flight Center, who studies the Saturn system.

To truly probe the rings’ origins, scientists could use another Cassini. “If money was of no object—and it is a big object—you could send a probe over there and excavate a bit of the rings,” O’Donoghue said. “You could pick up the boulders and look inside them and really narrow down the composition.”

The youthfulness of the rings raises yet another question, Spilker said. “Were there other ring systems, perhaps that were older and then just, over time, slowly disappeared?” she said. If that’s right, the one we see now could be only the latest in a series of ring systems, the most recent victim of Saturn’s massive pull.

As majestic and eternal as they seem now, Saturn’s rings are constantly shedding material. Sunlight and other cosmic effects can transform idle, icy debris into electrically charged particles. In their new state, the particles are less able to resist the tug of Saturn’s gravity and become swept into its atmosphere, where they vaporize, “raining” water onto the planet. According to O’Donoghue’s research, this process dumps as much as 4,400 pounds of water onto Saturn every second. He predicts the rings will vanish in 300 million years.

If the thought of Saturn losing its trademark feature is disappointing, consider that there are others out there. Not just Jupiter, Uranus, and Neptune, which have very thin rings of their own, though they pale in comparison to the grandeur of Saturn’s. If there’s one thing that the study of exoplanets—planets beyond our solar system—has taught us, it’s that our planets aren’t special. Buratti is convinced that someday, with telescope technology powerful enough, we’ll make out the curves of the rings around a distant planet, in another solar system. There are other Earths, other Jupiters, other Neptunes, a cornucopia of rocky and gaseous planets coasting through the cosmos. Surely there must be other Saturns, too.



In the year 1289, King Philip IV of France was worried about fish. “Each and every watershed of our realm,” he proclaimed, “large and small, yields nothing due to the evil of fishers.” Environmental change, expanding cities, and overfishing had sent aquatic populations into a tailspin. Because they were scarce, the fish, King Philip noted, “are much more costly than they used to be, which results in no moderate loss to the rich and poor of our realm.” This state of affairs could not stand. The king promulgated the country’s first fisheries ordinance.

In medieval Europe, an era stretching from about A.D. 500 to 1500, fish was a prestigious food. Chefs experimented with ways to disguise beef as fish: At least half a dozen cookbooks of the era include recipes for turning veal into imitation sturgeon for wealthy lords and ladies. Sturgeon was so rare in England and France that it was reserved for the monarchs, and the Cistercians, a Catholic religious order that used sign language to communicate, referred to it using the sign for fish and then the sign for pride.

People of all social classes, though, ate freshwater fish—trout, whitefish, pike, eel, lamprey, and shads. This taste started to have consequences. Today, fish populations around the world are rapidly declining; a millennium ago, Europeans faced similar challenges. Overfishing resulted in local extinctions, and popular food fish had to be domesticated through aquaculture. The population pressures created by humans may have even changed the size of fish.

Human appetites and needs are indisputably transforming ecosystems and wildlife in the modern world. But the more clues archaeologists uncover from the European past, the more they understand how dramatically these same influences have been shaping fish populations for hundreds of years.

Richard Hoffmann, an environmental historian, has been studying the complex interplay between humans and the aquatic environment for most of his career. He’s read a medico-dietary analysis of the Catholic saint Hildegard that names 37 fish taxa; he’s found tax records for the price of fish; and he’s reviewed zooarchaeological analyses on the rise and fall of fish populations across Europe. All these details help him reconstruct which fish were on the menu for different social classes, how big those fish grew, and when they disappeared.

Asking those questions often means confronting myths. “Some people think everyone in the past was rapacious,” Hoffmann says. “You also get the opposite myths of hyper-abundance.” One false tale that originated in the 17th century alleged that salmon and sturgeon were so abundant during the Middle Ages that servants had contracts stipulating they wouldn’t be served those fish more than a few times a week.

The reality is more complicated. In Europe, aquatic animals have been traded at least since the days of the Roman Empire. But it was during the early Middle Ages, with the arrival of widespread Christianity, that the animals became a popular source of protein. That’s partially due to the roughly 130 days a year when the faithful were exhorted not to eat meat, because fish didn’t count in that category.

At the same time, expanding agrarian populations were cutting down forests to create fields and diverting rivers to fill defensive moats around castles and towns, Hoffmann writes in one paper. From the ninth century A.D. to the 11th, the number of grain mills built along rivers in England exploded from about 200 to 5,624. Species that came into fresh water to spawn, such as salmon and sturgeon, began declining. New regulations, such as King Philip’s, were put into place to manage fish populations. A Scottish statute from 1214 required all dams to include an opening for fish and barrier nets to be lifted every Saturday, for instance. Soon highly sophisticated aquaculture ponds stocked with carp also provided regular access to fish for the landed elite.

This decline in freshwater populations coincided with a sudden, commercial-scale boom in sea fishing, which began around A.D. 1000 and is known as the “fish event horizon.” In one study, archaeologists collected cod bones in London from 95 Roman, medieval, and postmedieval sites. The number of bones jumped circa the year 1000, and isotopic sampling showed that in the following centuries, fish came from farther and farther away, indicating long-distance trade. In the southern English town of Southampton, the remains of marine species (such as cod) began to outnumber freshwater species (such as eel) by 1030.

That “fish event horizon” could have been caused by a number of forces. It came at a time of population growth, urbanism, new ship technology, and increased trade, says the archaeologist James Barrett, from the University of Cambridge. But, he adds, “I’ve argued consistently that this must also be about human impacts on freshwater and migratory fishes. The degree of vulnerability of fishes depends on how bounded the ecosystem they occupy is.”

In other words, because their habitat was smaller, freshwater fish were more likely to respond to human pressures sooner. When the reliable stocks of freshwater fish began dwindling, hungry Europeans turned to the much larger oceans. And while those populations had larger ranges, humans still had an impact.

In a recent paper for the Journal of Fish Biology comparing archaeological records and modern trawling surveys, Barrett notes that cod from the North Sea in the 11th and 12th centuries measured more than 31 inches in length. For fans of McDonald’s Filet-O-Fish sandwich (made with pollack, not cod), a 31-inch fish would sprawl across nine buns lined up side by side. By the 13th century, the average was somewhere between 20 and 31.5 inches (about five buns’ worth); today, the average is six to 12 inches. On the smaller end, the fish might just poke over the edges of a single bun.

Analyzing fish remains is incredibly labor-intensive. Around Britain alone, there are something like 350 species; each fish has more than 50 vertebrae. Unlike the mostly connected skull bones of mammals, fish skulls are an assemblage of dozens of loose bones. Because of the sheer amount of labor involved, zooarchaeological work on fish in Europe didn’t really find its footing until the 1970s, Barrett says. And before the labor-intensive practice of sieving sites with fine mesh began, researchers would turn up the remains of only large fish.

Since the 1970s, the field has seen an explosion of new technology. Now, by looking at varying levels of nitrogen and carbon preserved in fish bones, scientists can tell where the fish lived (and were likely caught) based on what they ate. A newer method, zooarchaeology by mass spectrometry, or ZooMS, uses collagen—the structural protein in bone—to identify the species based on an existing library of collagen fingerprints.

“You can potentially tell what species a bone is from about 10 milligrams of bone,” says David Orton, a zooarchaeologist at the University of York. For comparison, a teaspoon holds about three grams of flour, or 3,000 milligrams. One of his doctoral students will try to use ZooMS to distinguish the bones of two extremely closely related species. Trout live exclusively in fresh water, whereas salmon come to fresh water only to spawn, so distinguishing the two species could reveal more about medieval fishing practices.

At times, medieval fishery managers actually succeeded in course correcting. In the medieval Salzburg Alps, fishers paid the local archbishop 27,000 whitefish and 18 trout a year for the right to catch and sell even more of those fish; within one generation, whitefish populations collapsed, and the pike that were brought in to replace them ate nearly all the trout. The community decided to forbid fishing for three years, then set regulations for a limited season in a restricted area. “The rules were changed, there was proper enforcement, and it was restored and operated for hundreds more years,” Hoffmann says. But for all the efforts of King Philip and like-minded monarchs, sturgeon remains critically endangered across Europe.



Ah, the Milky Way, our glittering home in the cosmos. Seen in an unencumbered night sky, far from the glare of city lights, it seems magnificent and eternal in its enormity. Nothing could shift this ancient web of stars, nothing could disturb its transcendent stoicism.

Except, that is, another galaxy. Galaxies orbit millions of light-years apart, but gravity, the immutable magnet of the cosmos, can pull them together, producing spectacular collisions that reshuffle stars. According to the leading theory, the Milky Way will collide with one of its closest neighbors, Andromeda, sometime between 6 billion and 8 billion years from now.

But the Milky Way may face another galactic threat before that, from a different neighbor. A new study predicts our galaxy will collide with a galaxy called the Large Magellanic Cloud between 1 billion and 4 billion years from now.

This is a rather surprising change in schedule, considering that the Large Magellanic Cloud, which is close enough to be seen with the naked eye, is currently moving away from the Milky Way. What gives?

Marius Cautun, an astrophysicist at Durham University’s Institute for Computational Cosmology, says that recent observations of the Large Magellanic Cloud have revealed that the galaxy has more mass than previously thought. Cautun and his fellow researchers decided to run computer simulations that took this new factor into account and fast-forwarded the conditions of our cosmic neighborhood. They tested multiple scenarios, making adjustments in mass, velocity, and other measures. In the end, the simulations predicted that in several hundred million years, the Large Magellanic Cloud will turn around and head straight for the center of the Milky Way.

“The collision between our galaxy and the [Large Magellanic Cloud] takes place in the majority of cases—over 93 percent,” Cautun says.

The collision would be a slow showdown, unfolding over the course of billions of years. Stars from the Large Magellanic Cloud would ricochet like pinballs, dislodging some of the Milky Way’s stars from their orbits. Our galaxy as a whole would survive, but some stars may be flung right out of the Milky Way, Cautun says.

Meanwhile, the sleeping, supermassive black hole at the center of the Milky Way would wake up. Like volcanoes, black holes alternate between peaceful dormancy and ferocious activity, depending on the surrounding conditions. Ours is in a quiet period. But the chaos of the merger would send cosmic gas swirling toward it, and cosmic gas is dinner to black holes. The resulting feast is a spectacular show. A disk of luminous, hot cosmic material swirls around the black hole at great speed, and bursts of high-energy radiation erupt from its center. Cautun says one serving of a Large Magellanic Cloud could lead our black hole to gobble up enough material to grow 10 times its current size.
And what would happen to us, if there is any kind of “us”—life in some form—on Earth when this all goes down?

It is possible that our sun could be among the small fraction of stars that gets lobbed from the galaxy. The jostling would disturb the orbits of our solar system’s planets, which could be perilous for any inhabitants. Even a small change in the relationship between the sun and the Earth could knock it out of the region where liquid water (and, therefore, life) can exist.

If life on Earth survived, though, it would take ages for anyone to realize the planet’s position in the cosmos has shifted. Like the merger, the solar system’s ejection would occur over such a large timescale that it’d be almost meaningless to humans. “Only at the end of the collision could our descendants tell if we have been kicked out of our galaxy,” Cautun says.

The change in scenery would be remarkable. In this scenario, “our descendants will see a very different night sky, much darker than currently, with only a modest bright patch that will correspond to the Milky Way galaxy,” Cautun says. “It will be tremendously more difficult for our descendants to travel to other stars—if they haven’t yet done so by that time.”

If this imagined future scares you, consider that a collision with Andromeda would be much worse. The Milky Way would easily devour the smaller Large Magellanic Cloud and maintain its signature spiral shape, even if its insides will be all jumbled. Andromeda, on the other hand, is about the same size as the Milky Way. Astronomers expect that mashup to be destructive, and the Milky Way as we know it—the neat, shimmering band of stars—is unlikely to survive.

Cautun says that a collision between the Milky Way and the Large Magellanic Cloud would shift our galaxy’s position in space. But Andromeda will still come for it, a few billion years later.

“Ultimately, there is no escape,” he says.



Long ago, in a distant geological era—when Donald Trump hosted a reality show, when Senator Barack Obama doubted whether Hillary Clinton could be president, when the Earth was one-third of a degree Celsius cooler—Al Gore made a prediction.

When Americans understood what climate change would mean for their children and grandchildren, the former vice president warned, “they will demand that whoever is running for office, whoever is elected to serve, will have to respond.”

For 12 years, politicians did not, and now Americans’ “children” have themselves been elected to serve. When Gore made that remark, Alexandria Ocasio-Cortez was a teenager, a legal minor, one of a million kids living in New York.

Now she is an influential member of Congress.

On Thursday, Representative Ocasio-Cortez debuted a blueprint for a Green New Deal, an ambitious plan that aims to transform the American economic juggernaut into a massive weapon to combat climate change. In four dense pages, the blueprint commits the federal government to a “10-year national mobilization” on par with the effort made during World War II. She was joined by dozens of environmental-activist groups, a handful of fellow House members—and by Senator Ed Markey, a Democrat of Massachusetts who led a failed push to pass an ambitious climate bill in 2010.

“Climate change and our environmental challenges are one of the biggest existential threats to our way of life, not just as a nation, but as a world,” Ocasio-Cortez said at a press conference. “In order for us to combat that threat, we must be as ambitious and innovative as possible.”

The blueprint takes the form of a nonbinding resolution, which Ocasio-Cortez said was “a first step to define the problem.” Even in its vague and broad language, it remains the most detailed guide to a Green New Deal yet. It is the first such plan endorsed by environmental organizations across the left, from the old-guard Sierra Club to the upstart Sunrise Movement, a youth-led activism corps that brought national notoriety to the Green New Deal plan last November.

Yet even in broad language, the resolution clearly describes a transformation that would leave virtually no sector of the economy untouched. A Green New Deal would direct new solar farms to bloom in the desert, new high-speed rail lines to crisscross the Plains, and squadrons of construction workers to insulate and weatherize buildings from Florida to Alaska. It would guarantee every American a job that pays a “family-sustaining wage,” codify paid family leave, and strengthen union law nationwide. The resolution’s ambitions stretch beyond purely economic concerns, too, with a promise to honor all prior treaties with indigenous nations and to require their “free, prior, and informed consent” for decisions affecting their territory.

When asked whether she was offended that Nancy Pelosi had, a day earlier, referred to the new plan as “the green dream, or whatever they call it,” Ocasio-Cortez just smiled. “No, I think it is a green dream,” she replied. She added that the original New Deal had seemed pretty dreamy itself.  

For now, the resolution will remain relatively ethereal. While Democrats might vote on the measure in the House, the plan will almost certainly not even receive debate in the Senate, where Republicans hold a comfortable majority. Eventually passing anything that even resembles a Green New Deal will require Democrats to wrest a number of surprising victories. They must win the Senate and the White House in next year’s election, and then they will likely have to kill the legislative filibuster, a nonconstitutional requirement that every new law needs 60 votes. Despite co-sponsoring the resolution, Senator Markey gave conflicting answers Thursday when asked whether he supported ending that rule.

Yet that doesn’t mean the Green New Deal should be counted out. The policy only received mainstream attention for the first time three months ago, when the Sunrise Movement demonstrated in Nancy Pelosi’s office. Since then, it has become the biggest idea in U.S. climate policy, and four Democratic presidential contenders have spoken in support of it (if tepidly). In practical terms, today’s plan matters most for the 2020 election. It shows that the broad left is on board with a policy; activist groups can now send detailed questionnaires to candidates and prepare report cards on the depth of their Green New Deal support.

The resolution also suggests that a Green New Deal is now a centerpiece climate policy for the Democratic Party. Because Markey led the last push to pass emissions-cutting legislation, his endorsement of this resolution signaled “a passing of the torch,” says Greg Carlock, a policy adviser to the leftist group Data for Progress and an early supporter of the Green New Deal.

“Millennials have been hearing for 20 years” that climate change would be an issue for their generation to deal with, he told me. “And I would say, thanks, we’re here now. This is us taking over the issue that, decades ago, people said would be ours to deal with. This is what the next generation of the issue looks like.”

“The world right now is watching what a bunch of American Millennials do in Congress,” he added.

The Green New Deal approach is already notably different from paths taken by other countries. For years, economists have advocated for a carbon tax, a type of tax meant to factor the dangerous costs of heat-trapping emissions into the price of goods. While eventual Green New Deal legislation could involve a small carbon price, Ocasio-Cortez seemed to reject the wholesale approach in remarks. She instead cast climate policy as a sort of mega-infrastructure bill.

“This is an investment,” she said. “For every dollar we spend on infrastructure, we get more than a dollar back for that investment. For every dollar we collect in taxes, we get less than a dollar back.”

This resolution also marks the first step in fights over the Green New Deal to come. Its main text does not weigh in on divisive questions about the use of nuclear energy, a power-generation technology that does not emit carbon dioxide, or carbon capture and storage, a still-fledgling technology that could suck CO2 out of smokestack fumes or the atmosphere. “We are open to whatever works,” Markey said Thursday.

The left might not be as amenable. Many environmental-justice groups worry that carbon-capture technology will allow fossil-fuel plants to keep polluting their neighborhoods. Yet the Intergovernmental Panel on Climate Change says that the world can keep global warming below 1.5 degrees Celsius only by deploying carbon capture.

This can make for difficult politics. On Thursday morning, Ocasio-Cortez’s office published an FAQ about a Green New Deal that seemed to oppose carbon capture specifically. “We believe the right way to capture carbon is to plant trees and restore our natural ecosystems,” it read. By late afternoon, the FAQ had vanished from the congresswoman’s website.

Many progressives would consider themselves lucky if they ever get to talk seriously about carbon-capture policy. For now, they have the same goal: making its mix of climate and labor policy as much a part of the mainstream Democratic agenda as health care is.  

“The Green New Deal is kind of like the Cardi B of American politics right now,” Julian NoiseCat, an activist at the climate group 350.org, told me. “It’s fresh. It knows its roots in hardworking communities. And it’s really tapped into the culture in a different way from old approaches.”

“And like Cardi B,” he added, “I personally hope it sticks around for a while.”



This might offend some astronomers, but exoplanets are kind of old news. Over the course of two decades, telescope observations have pinpointed thousands of planets orbiting other stars across the cosmos. Some of these planets are as giant as Jupiter and smoldering hot. Others are more massive than Earth and covered in ice. A few reside in their solar system’s habitable zone, the not-too-hot, not-too-cold environment for liquid water. There have been so many discoveries in the past few years, in fact, that newly found exoplanets are announced now in batches of several hundred.

Not that exoplanets are boring. There’s just ... a lot of them. So it was pretty juicy when astronomers reported, for the first time, that they might have found an exomoon—a moon orbiting a planet around another star, thousands of light-years from our own.

The press (us included) covered the news, announced last fall, with a sense of wonder. An accompanying illustration of the moon, pale blue and silky, only heightened the fascination. Scientists are still trying to understand how our own moon works—still discovering moons in our own solar system, even, around Jupiter—and now here they were, excavating one from the depths of the cosmos.

The researchers, a pair of astronomers at Columbia University, stressed that they only found evidence for the moon’s existence, not the moon itself. To help confirm their potential discovery, they needed that exacting hallmark of science: someone else to replicate their work.

Eventually, someone else tried—with mixed results.

Two separate teams have since delved into the same data. One could only replicate half the evidence. The other found the same signals the Columbia astronomers did, but won’t confirm there’s a moon there. For now, the existence of the exomoon remains uncertain.

“Frankly, I can’t tell you who’s right,” says Alex Teachey, the Columbia graduate student who led the initial study.

The story of the maybe-moon begins about two years ago, with Kepler, a NASA space telescope responsible for uncovering most of the known exoplanets. Before it ran out of fuel and shut down last year, the telescope absorbed the light from thousands of stars in the Milky Way. When something—such as a planet—passes in front of a star, it blocks a tiny fraction of the star’s light. Kepler could spot this faint, brief dimming.

Teachey and his colleague, David Kipping, were sifting through Kepler’s catalog for exoplanets that could have moons. One planet, Kepler-1625b, located about 8,000 light-years away from Earth, seemed more intriguing than the rest—there was something unusual about the light coming from its sun. Teachey and Kipping turned to an even more powerful instrument, the Hubble Space Telescope.

The Hubble observations recorded a dimming as the planet trekked across, as expected. But it began its journey earlier than expected, and the dimming was followed by a second, fainter dip in the light. To Teachey and Kipping, this signal meant that a moon trailed behind, its gravity tugging gently on the planet and shifting its course ever so slightly. An alien astronomer watching the Earth and moon pass in front of the sun would see these same types of blips, too.

The astronomers said the moon, if it existed, was likely the size of Neptune and made of gas. “It looks very convincing on this one detection, but it’s so strange compared to what moons are like in our own solar system that it’s kind of hard to believe it,” Kipping told me last year.

Laura Kreidberg, an astronomer at Harvard and Smithsonian’s Center for Astrophysics, wanted to see it for herself. Kreidberg isn’t an exomoon hunter; she studies the atmospheres of exoplanets, and has extensive experience analyzing Hubble observations. “I have been analyzing data like this for many years, and so I was really curious to see if I put it through my pipeline, if I would get the same answer,” Kreidberg tells me.

Kreidberg emulated the other researchers’ methods. “I did my best to reproduce their analysis as exactly as I could,” she says. Her team confirmed that the exoplanet arrived earlier than expected. But “I could not reproduce that little dip in the brightness that they attributed to the moon,” she says.

Kreidberg doesn’t know why that’s the case, and neither does Teachey; the two have chatted and checked each other’s work but found no explanation for the discrepancy. (I asked Kreidberg what it’s like for one scientist to tell another that she thinks his potential scientific breakthrough isn’t real. “I mean, it’s a little awkward,” she says. “But I think Alex and I are cool.”)

Kreidberg suspects the mismatch might have something to do with Hubble, which was designed to observe distant galaxies, not nearby stars like the one that hosts this potential moon. Plus, the telescope zooms at about 17,000 miles per hour around Earth. While Hubble is designed to lock onto celestial targets at this great speed, its instruments are not immune to subtle perturbations. The jostling, apparent in a fraction of a pixel, could be mistaken for something cosmic.

“At this level of precision, things like the sensitivity of individual pixels become important,” she says. “If the position of the star on the detector moves just a little bit, that can mimic the type of drop in brightness that would be caused by a moon.”

The Kepler telescope might be another factor, Kreidberg says. After Teachey and Kipping picked Kepler-1625b as an interesting target, the Kepler data were reprocessed, and the signatures in the surrounding starlight that had intrigued the two researchers vanished. (Teachey and Kipping acknowledged this disappearing act in their original work, and say that the observations by Hubble, which is four times more precise, stand.)

It is this disconnect that makes René Heller, an astrophysicist at the Max Planck Institute for Solar System Research, stop short of endorsing the exomoon. Heller and his own team of researchers tried to repeat Teachey and Kipping’s analysis. They confirmed the early arrival of the planet, the mark of an object floating nearby. And they found the small dip in the starlight that Kreidberg didn’t.

But they came to different conclusions when they analyzed the Kepler and Hubble data separately. Like Kreidberg, Heller doesn’t rule out that the Hubble signal might be corrupted data masquerading as a moon. He suspects that Teachey and Kipping have discovered something—not a moon, but another planet around the star, tugging on the other as they go round and round. (The Columbia astronomers have also entertained this possibility.)

The first tentative detection of a moon in another solar system was always going to be controversial. The first reports of exoplanets, in the 1990s, were met with skepticism, and it took some candidates a decade to be confirmed. More than 3,300 exoplanets are in limbo right now; space telescopes have recorded their movements, the telltale darkening in their star’s glow, but astronomers need to see several more passes before the objects are declared the real deal. Which is to say, it might be a while before the theory of the maybe-moon makes history or fades away. And a future of thousands of known exomoons, their discoveries as routine as those of exoplanets, seems even more distant.

Teachey welcomes the independent analyses and competing interpretations. This is how science should work, he says. What the alleged moon needs now—what every intriguing cosmic conundrum needs, any astronomer would tell you—is more data. Teachey hopes to continue monitoring the movements of Kepler-1625b and the potential moon using ground-based telescopes, which require less wrangling than Hubble does. The telescope splits its time among thousands of requests from astronomers around the world, and quick schedule changes are reserved for very special occasions, such as the surprise arrival of an interstellar asteroid.

“The good news is, if the moon is really there, it’s not going anywhere,” Teachey says. “So eventually, maybe when it’s a bit easier or cheaper to perform the observations, we really ought to know one way or another whether the moon is there by watching the planet transit again and again and seeing if the moon shows up. It won’t be a mystery forever.”



The day was cold, gray, and rainy, and the wolf smelled exactly like a wet dog. I sat on my heels, my shoulders just a few inches higher than hers, and hesitantly scratched her belly, her thick, black-tipped gray fur soft and greasy between my fingers. She nosed at my face, bumping my chin and lapping my cheeks. She tried to slide her long, flexible tongue into my mouth, and when that failed, an unguarded nostril.

This wolf lives with four of her siblings on five acres of remote spruce forest in northern Norway, well above the Arctic Circle. Though she hunts the small animals that find their way through the high steel fence that encloses her world, she mainly eats carcasses supplied by her human keepers. Through the long winter twilights and summer days, she fights with her pack mates; she stretches, yawns, and rolls on her belly; she sits on her haunches and stares across the valley. But unlike free-roaming wolves, she has no reflexive fear of humans. When she was born in captivity five years ago, her keepers named her Frigg, after the Norse goddess, and in their care she has learned that most humans are simply objects of curiosity, sporadically available for inspection.

Which is not to say that Frigg is tame. Wolves long accustomed to humans can still be frightened by unfamiliar behaviors—and in a confined space, they may feel cornered and attack. Even when at ease, wolves can be dangerous at close range, and what starts as a playful lick can end in a painful nip. Before entering the wolves’ enclosure, I was told not to make sudden movements or actively approach the animals. I was told to allow them to advance and retreat as they pleased; to speak quietly, if at all; and to kneel, not sit, so that if necessary I could make a hasty escape through the nearby gate. I was instructed to take off my earrings, my hair clip, and any wool clothing, lest I smell like a sheep. I was warned not to wear heavy scents, and told that synthetic polar fleece is, for reasons not entirely understood, perilously exciting to wolves. Only with hesitation were my leather boots permitted.

This place is called Polar Park, and though visitors can see many species here—lynx, moose, bears, reindeer—what draws them from all over Europe and beyond are the wolves. Wolves were trapped, shot, and chased out of much of Europe long ago, and a lot of people, it seems, are willing to pay a lot of money to watch wolves at play in a European forest.

I had, and still have, mixed feelings about these wolves’ captivity, their training, and the resources required to get near them. I’d heard and seen free-roaming wolves in the past—closer to home, in Yellowstone National Park—and I had wondered whether an encounter with captive wolves, even a hands-on one, could compare. Yet once inside the enclosure, I was overwhelmed by the immediacy of the animals. I don’t cry easily, but when Frigg butted her heavy body against my chest, vying for attention as her pack mate made her own attempt to spiral her tongue into my nasal cavity, I choked up.

Though Polar Park might be one of the few places in the world where it’s possible to pet a wolf in relative safety, it’s no longer one of the only places in Europe where it’s possible to see a wolf. As organized persecution of wolves has eased, and as people continue to leave the European countryside for cities, wolves and other predators are wandering back to the countries that once exterminated them. Wolves from surviving populations in Italy crossed the Alps into southern France in the 1990s, and wolves from Poland took up residence in eastern Germany a few years later. In 2011, a Dutch mortician photographed a wolf crossing a road in the eastern Netherlands—the first verified sighting in the country in well over a century. In 2012, Danish officials confirmed their country’s first wolf sighting in 200 years, and last spring, researchers filmed a litter of wolf pups at play on the Danish mainland. Wolves have returned to the Scandinavian peninsula, too, and today, more than 400 wolves live in the unfenced forests of Sweden and Norway.

Europe is now home to an estimated 12,000 wolves, 17,000 bears, and 9,000 lynx, and wolf sightings have been documented in every country on the European mainland. Large predators provoke powerful emotions, and in Norway, where captive wolves are a beloved and lucrative tourist attraction, humans have greeted the returning wolves with both great joy and exceptionally furious resistance. The resulting conflict is testing humans’ ability to coexist with our fellow predators—and, along the way, our ability to coexist with one another.

More than 500 miles south of Polar Park, well beyond the easternmost fingertips of the coastal fjords, the broad glacial valleys of inland Norway are thinly populated and thickly forested. Along the Norway-Sweden border, the high plateaus are speckled with lichen, and in the fall, yellowing birch leaves glow in the low-angle light, buttery flames against the gray clouds.

Petter Wabakken has lived in this area for 40 years, ever since he moved here with his young family in the fall of 1978. Tall, thin, and scruffy-haired, he is now, somewhat to his chagrin, the public face of wolf recovery in Norway. Back in 1978, though, he was a student at the University of Oslo, hired by the Norwegian government to look into a spate of reported wolf sightings along the border. The last wolf bounty in Norway had been paid more than a decade earlier, and for nearly a century there had been no more than a handful of wolves in southern Norway. Most experts dismissed the reports from southeastern Norway and southwestern Sweden as sightings of “unidentified pet animals,” and Wabakken was not expected to find much of interest.

Wabakken, however, was not intimidated by scientific authority: While still in high school, he’d published a paper questioning the official counts of threatened bird species in Norway. “When things are described in black-and-white terms, then I get very curious,” he told me when I met with him at the Inland Norway University of Applied Sciences, the small technical college where he teaches.

Wabakken had heard and read enough about the local sightings to suspect that at least some were accurate, but there was no obvious way to confirm them. DNA testing of hair and scat was not yet possible; motion-sensitive camera “traps” were not yet widely available; individual tracks in the snow could not be confidently distinguished from the tracks of dogs or wolf-dog hybrids. But Wabakken had time, and he had patience. Whenever he found a set of canine tracks in the snow, he followed it on skis—sometimes for hundreds of miles and weeks at a time. He hypothesized that wolves, which, unlike domestic dogs, had no reliable source of food or shelter, would behave in ways that allowed them to save energy. He noticed that some of the animals he was tracking sought out shallower or more compacted snow, sticking closely to riverbanks, forest roads, and tire tracks. Some even used old moose prints to hopscotch over the landscape, stretching from one track to the next without dropping into the snow. “I’d like to see a dog move its paws so efficiently and elegantly,” he said.

After four winters of work, Wabakken concluded that between three and five wolves had taken up residence in Norway, but he didn’t have definitive proof. And because he had purposely kept his distance from the animals he tracked—he didn’t want to influence their behavior—he had not yet laid eyes on a Norwegian wolf.

In 1982, Wabakken was invited to present his findings at an international mammal conference in Helsinki. As a young, unproven researcher, he expected that only a handful of people would listen to his report. Due to a scheduling mix-up, however, his talk was squeezed between presentations by two eminent scientists, and he spoke to a captive audience of hundreds. Wabakken won over the experts who heard him, and their endorsement convinced Scandinavian managers that wolves were back in Norway. The following year, a litter of wolf pups was spotted on the Norway-Sweden border, and for the first time in nearly a century, the peninsula had a documented breeding population of wolves.

For a while, the public reaction was muted. Few managers believed that the fledgling binational population would survive, and with good reason; to get to Sweden and Norway from Finland or Russia, which have substantial wolf populations, a wolf must either survive a long and dangerous journey through the Sámi reindeer-herding districts of northern Scandinavia, where legal protection for wolves is relatively weak, or cross at least 90 miles of unpredictable Baltic sea ice. But by 1990, at least one more wolf had managed the trip, and the small band founded a thriving population. By 2002, as many as a hundred wolves in eight family packs were in southern Sweden and Norway. Last winter, researchers counted 305 wolves in Sweden and 94 in Norway, living in a total of 41 packs. Lynx, bears, and wolverines have rebounded, too.

As the wolf population expanded, resistance to it grew. During the decades in which wolves and other predators had been scarce or absent, Norwegian farmers had begun allowing their sheep to scatter in the mountains each summer, believing that dispersed animals could make the most of the sparse vegetation; they even developed breeds known for their disinterest in herding. Norwegian moose hunters, who traditionally work with elkhounds on leashes, had begun to train their dogs to run loose in the forest after quarries. “The return of the wolves represented a change in a system that had taken many, many years to build up,” says John Linnell of the Norwegian Institute for Nature Research. Polls consistently showed that the majority of Norwegians supported wolf recovery, but as the sheep and dog casualties mounted, the pitch and volume of the complaints increased.

Wabakken recognized that the wolves’ survival depended on their human neighbors’ ability to cooperate across borders: Sweden and Norway, despite their proximity and linguistic similarities, are divided by history, culture, and, most recently, the boundary of the European Union (Norwegian voters, famously, rejected EU membership twice, first in 1972 and again in 1994). While Sweden is bound by the environmental regulations of the EU, Norway answers primarily to its own national laws and to the Bern Convention, a wildlife-protection treaty signed by all European countries; the practical result is that Sweden is required to accommodate many more wolves than its neighbor.

To ensure that scientists, at least, treated the countries’ shared wolf population as a single unit, Wabakken co-founded SKANDULV, a Swedish-Norwegian wolf-research project, in 1998. Over the past two decades, Wabakken, his colleague Barbara Zimmerman, and their collaborators in Sweden and Norway have monitored the growth of the population, tracked the movements of radio-collared wolves, and conducted genetic studies so extensive that they can describe the family tree of every wolf on the peninsula.

Yet this heavy investment of time and money—by both countries—has done little to reduce public opposition to wolf recovery in rural Norway. Though the Scandinavian wolf population remains among the smallest in Europe, the political divide over the animals is at least as deep and stubborn as anywhere on the continent.

To anyone familiar with the rural United States, rural Norway is almost disconcertingly prosperous. On an early evening in mid-September of last year, in the eastern Norwegian town of Elverum—a winding half-hour drive south of Wabakken’s college campus—teenagers chased soccer balls across vivid green fields, and Teslas purred past the neat storefronts that line the wide main street. On the outskirts of town, in the lingering autumn sunlight, nearly 300 people stood outside the Norwegian Forest Museum, waiting to be let through the front doors. They filed into the museum’s spacious atrium, helped themselves to black coffee and sweet bread, and settled into chairs arranged in careful rows. The only suggestion that this gathering was anything other than a well-attended community meeting were the two uniformed police officers stationed discreetly in the atrium’s balcony.

Though wolves were the ostensible subject of the meeting, they were present only in effigy, and only on the distant edges of the crowd. In the museum foyer, a taxidermied wolf eyed arriving visitors. Upstairs, in a darkened gallery, another stood in a too-small glass case, head thrown high and teeth bared as if about to howl.

The September meeting’s organizer was Gunnar Gundersen, a former member of Parliament who swam the 400-meter medley in the 1976 Olympics in Montreal and still cuts a powerful figure at the podium. A wealthy private-forest owner, he works for a national timber cooperative and heads a regional alliance of forestry and farming organizations. The meeting, he told me later, was intended to “put a bit of pressure” on the national environment ministry. For most of three hours, as the deputy environment minister hunched uncomfortably at a long table in the front of the room, a succession of invited speakers endeavored to do exactly that.

While the translator I was working with whispered subtitles into my ear, a local hunter reported that his beloved elkhound had been killed by a wolf—then got some laughs by poking fun at the absent environment minister Ola Elvestuen, known for both his sympathy for wolves and his dandified good looks. Diminutive, white-haired Gunnar Glöersen, a representative from the Swedish Hunters Association, warned that if the government didn’t permit more wolf hunting in Norway, hunters would take matters into their own hands and start poaching the animals.

Several area farmers said that the continued killing of livestock by wolves threatened their livelihood. More than 2,600 sheep and lambs were documented by government officials as having been killed by wolves in 2018—Norway’s agricultural daily often led with bloody photos of disemboweled lambs—and while those casualties represent a small fraction of the roughly 2 million sheep and lambs that graze freely in the forest each summer, some farmers were hit disproportionately hard. (The government compensates farmers for documented losses of sheep to wolves, but as many farmers point out, the payments don’t cover the costs of extra shepherds and other indirect impacts to their businesses.)

The evening’s argument revolved around the number of wolf packs permitted to live in Norway. In late 2016, a resolution by the Norwegian Parliament set a target of “four to six” litters in the binational population each year, with at least three born to packs living entirely within Norwegian borders. Regional authorities were allowed to permit hunters to “cull” or shoot additional animals, and a total of 30 wolves were legally shot by private or state-employed hunters between June of 2017 and March of 2018. Another 20 have been shot since June of 2018. Wolf numbers still exceed the target set by Parliament, however, and most of those who spoke at the meeting—including several irate members of Parliament—wanted the national environment ministry to allow more hunting and fewer wolves.

Elvestuen, however, has been reluctant to expand the wolf hunt. In contrast to the parliamentary agreement, both Norway’s national environmental law and the international Bern Convention state that no species can be hunted until its populations are self-sustaining within national borders—which some legal scholars interpret to mean that more wolf packs should be allowed to survive and reproduce in Norway. The matter is currently in court, with conservation groups and agricultural and hunting organizations lining up on opposing sides.

The disagreement runs far deeper than numbers. For Norway, which declared its independence from Sweden just over a century ago and was occupied and nearly starved out by German forces during World War II, domestic food production is a matter of both national security and national pride. In recent decades, the government has gone to great lengths to keep farmers and rural communities solvent. (Norwegian voters opposed EU membership partly because they feared it would lead to cuts in state agricultural subsidies, which currently make up about 60 percent of farmers’ gross income.) But farming is and always has been a marginal enterprise in cold, soil-poor Norway, and despite the generous government support, more than half of the country’s farmers work second jobs.

When sheep farmers say that wolves are threatening their livelihood, or hunters say their traditions are endangered, they’re rarely talking about their individual survival: Norway’s extensive, tax-supported welfare state guarantees every Norwegian a basic level of economic and social security. What most mean, fundamentally, is that wolves look like yet another threat to Norway’s hard-won independence.

Such fears surfaced throughout the meeting, and toward the end of the evening, when the floor was opened to public comment, they were echoed by many in the mostly older, predominantly male, and almost entirely white audience. But the room held other fears, too. “My family is going to tell me to shut up,” said a young, dark-haired woman who declined to identify herself. “But not everyone in Elverum is against wolves.” The crowd muttered, and there was scattered applause.

The next speaker, Kari Wenche Fossum, wore her long gray hair in a loose twist, and surveyed the audience through round glasses. “I’m going to say something you don’t want to hear about being outside, about feeling safe,” she said calmly. Because of her support for wolves and other predators, she continued, “I’ve been physically threatened, I’ve been injured twice. I want to encourage everyone to think about this. It’s not just you guys who are suffering.”

The relationship between Norwegian humans and Norwegian wolves is, in some ways, distinctive. Because of Norway’s investment in rural life, its countryside is more populated than Sweden’s, and Norwegian sheep farmers have hung on while most of their Swedish counterparts have simply moved out of wolf habitat. And some Norwegian politicians have found that it is both possible and politically convenient to keep compensating farmers and hunters for wolf damage, all the while promising a radical reduction in wolf numbers—a strategy that gives their constituents little incentive to adapt.

Public attitudes toward wolves in Norway, and in northern Europe as a whole, also seem to be less tolerant than attitudes in southern and eastern Europe, where some farmers have never known a world without wolves. There, defensive practices such as keeping sheep in tighter, more closely supervised herds are considered routine. “Wolves might be a pain, you might not like them, but eventually, there is not much sense in protesting against them,” says the researcher Nathan Ranc, who studies carnivores in Italy, France, and elsewhere. “They’re like a storm or an avalanche. They’re there, and it’s part of the job to deal with them.”

At the same time, what’s happened to the public discussion about wolves in Norway in recent years is exactly what’s happened to discussions of all kinds, all over the world: It has become more and more polarized, sometimes violently so. In 2009, an Elverum-area resident named Tore Hauge was so outraged by the illegal killing of a local wolf that he personally offered a reward of 50,000 Norwegian kroner—about $8,000 at the time—for information leading to the culprit. After his offer appeared in the newspaper, garbage was dumped in his driveway, and his outbuildings and fences were vandalized. One night, when he was out of town, his wife awoke to a loud buzzing noise and realized that a group of people had encircled the house and were marching around it, waving chain saws. Wenche Fossum, who spoke at the Elverum meeting, told me that she has been the target of threats for more than a decade.

Critics of the government’s wolf policy have fewer and less extreme stories of harassment, but they feel the sharp edges of polarization, too. Three herding-cooperative leaders told me that every time they appear on television to talk about their problems with wolves, they are blasted with vicious texts and calls from wolf supporters.

The Norwegian sociologist Ketil Skogen, who has studied the wolf controversy for two decades, says that its deepest divisions are between rural and urban Norwegians. Since World War II, in Norway and the rest of the developed world, the growth of the urban middle class—both in numbers and political and cultural influence—has fostered a sense of inferiority in rural communities. Many rural people feel, not without reason, that their practical knowledge and experience are dismissed by more formally trained urban “experts,” and some have responded to perceived and real disrespect with a deep skepticism of science and scientific authority. These urban-rural resentments, Skogen has found, can obscure even vast class differences, creating political alliances between large rural landowners such as Gundersen and working-class hunters and farmers.

Gundersen has worked with farmers’ and landowners’ groups to mobilize this alliance, and this past January, they drew an estimated 7,000 protesters to a torchlight parade in Oslo. Supporters of wolf recovery have also organized large protests, with several thousand people turning out for demonstrations across the country this winter. Vi er vikinger, ikke veikinger, (We are Vikings, not weaklings), read one pro-wolf demonstrator’s sign.

In Norway, like everywhere else, these divides are deepened by social media. During my week of conversations in rural Norway—in farmyards, in offices, and over teatime waffles in cozy kitchens—I heard repeatedly that the nastiest arguments about wolves take place on Facebook. Social media have bred conspiracy theories, too, with many wolf opponents insisting, for instance, that the wolves were secretly trucked into Scandinavia and released. (There are many variations on this rumor, all fanciful extrapolations of a real but stillborn Swedish proposal to reintroduce wolves in the 1970s.) The theory is so persistent that a group of landowners in eastern Norway commissioned a second set of wolf DNA analyses, separate from those already conducted by SKANDULV, in hopes that the results would suggest that the animals were descended from captives or came from far outside the region. Wolf opponents have also convinced the Norwegian government to sponsor two additional studies. But none has found any evidence of deliberate reintroduction.

Even for a visitor, the polarization can be exhausting—and frustrating, for the stereotypes that help maintain it usually collapse in conversation. One of the most passionate wolf opponents I spoke with, a sheep farmer and the leader of a local herding cooperative, grew up outside Oslo and took up farming only after pursuing a career in the city. Marte Conradi of the World Wildlife Fund, whom I met with in a swank coffee bar at the Oslo airport as she was returning from a conference on European predators, grew up in a tiny town in eastern Norway and worked for several years as a county-level wildlife manager. Tore Hauge, who put up the reward for the wolf poacher, grew up in Rena, near Elverum, and before his recent retirement made a living mining coal and building highway tunnels. And not many wolf opponents are more skeptical of scientific authority than their sworn enemy Petter Wabakken.

Even those who think wolves have no place in Norway insisted to me that they have no problem with wolves in general, and many spoke of them with admiration. This might have been what they thought I wanted to hear, but I heard it expressed so many times, and in such detail, that I came to believe it was at least partly sincere. Jørn Stener, a hunting guide and a fierce critic of the government’s handling of the wolf recovery, sounded almost reverent when he recalled the first of his many encounters with wolves in the woods. “They’re smart, they’re adaptable—they’re amazing animals,” he said.

Though politics may or may not allow the Scandinavian wolf population to expand in eastern Norway, Norwegian wolves are almost certainly here to stay. “You can sit and dream about the time when we didn’t have large carnivores,” Wabakken said. “But that dream is over.” Even if resident wolves were to be killed or driven out, as they were in previous centuries, young wolves born to Swedish packs would soon wander over the border to take their place. Eventually, farmers in wolf habitat will have to adjust: They will have to switch from raising sheep to raising cows, which are less vulnerable to wolf predation, or follow the lead of farmers such as Morten and Linda Ulvedalen, who recently bought a farmstead inside the wolf-management zone.

Morten Ulvedalen is the CEO of a specialty construction-supply company in Oslo, and the couple was able to afford enough land to both keep their sheep enclosed in the summer and grow grass for winter feed (many sheep farmers point out that they need to graze their animals in the mountains in the summer in order to use their pasture to grow feed). With the help of a government grant, they were also able to afford a burly electric fence from New Zealand, and their sheep now graze placidly within it. Linda Ulvedalen, who breeds sheep, is especially interested in reviving older breeds that are less likely to scatter in the woods. Though their surname translates to “Wolf Valley,” neither of the Ulvedalens is particularly happy about the expansion of the wolf population, and when I visited their farm, Morten Ulvedalen was quick to point out that government grants don’t cover the full cost of their adaptations. Such practical measures, however, give livestock the best chance at coexisting with wolves.

Larger pastures and stronger fences don’t heal the deeper divide over wolf recovery, though. The first step toward doing that, says John Odden, a predator researcher with the Norwegian Institute for Nature Research, is for opposing groups to agree on a shared set of facts. Odden uses camera traps to gather data on predator populations, and about five years ago he began to set up cameras around a community where government estimates of lynx numbers, and the consequent limits on lynx hunting, had been met with great skepticism. Odden, who grew up in the countryside not far from Elverum, decided to involve the community in his project, convincing local hunters to advise him on the placement of the cameras and help him collect the camera data cards. Some hunters got involved because they hoped to prove the government wrong; others just wanted to geek out about the fancy cameras. But one participant, Jan Erik Olbergsveen, says that those who took part in the data collection gained more confidence in its accuracy, and skepticism faded.

Odden has since organized a similar project to track wolf movements near communities in eastern Norway, and while wolves are much more controversial and politically complex than lynx, he has once again enlisted locals to help place and check the cameras. Some of the angriest anti-wolf voices at the Elverum meeting, in fact, belonged to his volunteer data collectors.

The reasons for opposing wolf recovery in Norway, as in most of the rest of the world, are pretty straightforward: inconvenience, cost, fear of change, fear of fangs. The reasons for championing wolves—for going to court on their behalf, for inviting anger and worse by speaking up for their protection, for spending excruciating amounts of money visiting the captive pack at Polar Park—are harder to pin down.

In the United States, supporters of wolf reintroduction and recovery often point to the importance of large predators in ecosystems, especially to the measurable changes in the flora and fauna of Yellowstone National Park since the return of wolves. But in Europe, where most ecosystems are highly human-dominated, few wolf supporters expect wolf restoration to lead to a broader recovery of ecological processes. Some value wolves as symbols of wildness, or nature, or the limits of human influence, but most make another argument for wolf recovery: They say that wolves have a right (up to a point) to survive and repopulate the places where their kind once lived, and that humans have a duty (up to a point) to accommodate them.

The idea that humans should accommodate other large predators is nothing new, and it’s far from exclusively urban. In 1893, Swedish authorities ended a long-standing bounty on brown bears because they realized that the country’s bear population was about to go extinct. “It is a matter of honor for our country that this interesting animal be protected from complete extermination,” the Swedish Royal Academy of Sciences stated in 1905. Concern about the extinction of other species—useful to humans and not—was by that time widespread throughout North America and Europe. Since then, measures to protect other species have been almost constantly challenged, but the general notion of species survival and recovery as a good thing has persisted worldwide.

Even opponents of wolf expansion in Norway indirectly acknowledge the existence of these rights and duties: One reason for the longevity of the clandestine-reintroduction conspiracy theory, for example, is that reintroduced wolves are seen as having a much lesser claim to the Norwegian countryside than animals that returned on their own, and would therefore be politically easier to drive out. Even the complaint that “wolves have more rights than we do,” often heard in eastern Norway, implies that both parties have at least some rights.

The trouble with wolves, of course, is that their pursuit of survival collides with ours. While some species demand little of people in order to survive, large, free-roaming predators can require humans to change their habits, their livelihood, and even their place in the food chain. Norwegians, who live in one of the wealthiest and best-educated countries in the world, have an opportunity to reduce these conflicts: to hack through the accumulated mistrust and resentment, identify the genuine burdens that accompany meaningful predator recovery, and figure out, as a society, how to share those burdens more equitably. If they can do that, they will have taken a step toward solving one of the wickedest problems in conservation. If they can’t, conservation will remain a job that gets done when convenient—and rarely otherwise.

“If we can conserve predators, we can conserve everything,” says Guillaume Chapron, a wildlife researcher at the Swedish University of Agricultural Sciences. “If we can’t conserve predators, it doesn’t look good.”

Toward the end of my visit to Polar Park, I asked Stig Sletten, who had accompanied our small group into the wolf enclosure, whether he had time to talk. Sletten, the park’s head animal keeper, was clearly reluctant to be interviewed, but after disappearing for several hours to finish what he said were some much-needed repairs to the musk-ox shelter, he consented to a conversation.

Polar Park, which was dreamed up in a bar by a group of locals hoping to bring more tourists to the area, opened in 1994 and is now supported primarily by entrance fees and corporate sponsorships. Sletten, who grew up nearby, was one of the park’s first employees, and after more than a decade in the Norwegian military, he returned to the park full-time in 2008. Soft-spoken, with white hair that contrasts with his unlined face, Sletten is as alert and wary as a wolf, noticing everything but giving little away. He’s aware of the resemblance, and said it serves him well inside the enclosure: “I do have to sniff around a bit, notice what people are feeling and thinking, whether someone’s nervous,” he said, raising his pointer fingers above his temples to resemble ears.

When I asked him what he hopes people will take from the experience, he turned serious. “I don’t want to force anyone to like it or not like it,” he said. Many visitors, like me, cry when the wolves approach them. Some cry when the keepers judge them too small or frail to enter the enclosure safely. Some brag to their friends and family that they have a special way with animals, and are embarrassed when the wolves ignore them. Some are preoccupied with their cameras. And some are scared, which doesn’t bother Sletten. “They’re going to meet a predator—they’re going to meet a wolf. It’s okay that they’re scared, maybe even a good thing,” he said. Far more dangerous, he added, would be to have no fear at all.

I wasn’t especially afraid in the enclosure, though maybe I should have been; as much as the wolves look, behave, and even smell like large dogs, they can turn on one another with shocking speed, snapping and growling with fleeting but genuine menace. With humans, however, they are simply nosy. They placidly investigated our small group, then loped off, then returned, coming and going for about an hour. Prompted by a couple of convincing howls from their keepers, they let out a piercing, unruly chorus of yips and yelps that seemed to linger in the fog.

When we finally filed through the heavy gate and departed, skirting the outside of the enclosure, Frigg and her pack mates followed us on their side of the fence, whining indignantly and gnawing at saplings. They didn’t need us, and they certainly didn’t love us, but they wanted us to stick around. The fascination, like the trepidation, is instinctive—and mutual.

Life Up Close is a project of The Atlantic, supported by the HHMI Department of Science Education.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?



Billions of years ago, something—perhaps the vibrations of an exploding star—jostled a cloud of cosmic gas and dust suspended in space. The cloud collapsed on itself and flattened into a spinning disk. The center grew heavy and ignited, forming our sun. The stuff that remained ricocheted, collided, and congealed. The biggest clumps of space stuff smoothed into spheres—the planets and moons. The smallest, the asteroids and comets, stayed as they were, like crumbs left over from an elaborate feast.

And right now one of those crumbs is exploding.

An asteroid named Bennu has been caught spewing particles into space—hundreds of gravel-size bits, hurtling from the surface at high speed.

The tiny explosions were spotted by a NASA spacecraft named OSIRIS-REx. The probe settled into an orbit around the asteroid in late December and noticed the first ejection within days. Over the next two months, OSIRIS-REx observed nearly a dozen of these events. And more are still being detected.

“It’s one of the biggest surprises of my scientific career,” says Dante Lauretta, the lead investigator of the mission.

The solar system is littered with asteroids, from near Earth to the edges well beyond Pluto. Bennu, a blob-shaped object slightly larger in diameter than the height of the Empire State Building, resides close by, and its orbit occasionally crosses paths with the orbit of Earth.

But particle-spewing asteroids are extremely rare. Only about a dozen of the 800,000 known asteroids in the solar system are classified as “active” like this. That’s why, when NASA launched a spacecraft to study Bennu, scientists didn’t expect it would be one of them. The numbers were against them.

Astronomers don’t know what’s causing the ejections, but they have several potential explanations. Some asteroids spin so fast that pieces of them start to fly apart. Others are sideswiped by floating debris, a collision that can expose icy particles buried beneath the surface and sweep them into space. Andy Rivkin, a planetary astronomer at the Johns Hopkins Applied Physics Laboratory who studies asteroids, suspects the sun might have something to do with it. When the light hits a rocky object without a protective magnetic field, the particles become positively charged, while those in the shade remain negatively charged.

“Near the terminator or the shadows, the charge difference leads to a voltage difference that can be really huge,” Rivkin says. “On the moon, this effect has been seen to levitate dust. On asteroids … who knows what happens.”

The OSIRIS-REx team says the plumes of particles aren’t dangerous to the spacecraft. Some particles rain down on Bennu. Others are thrown deeper into space, beyond the tug of the asteroid’s gravity. Still others get stuck in between and settle into an orbit around Bennu, creating a new population of tiny moons around the asteroid. “That has never been seen before in any solar-system object,” Lauretta says.

Some of the evicted particles might eventually make their way to Earth and plunge into the planet’s atmosphere in a dazzling meteor shower. Lauretta predicts the particles could reach Earth as soon as September.

The past few months of observations have turned up other surprises. Scientists predicted the surface of Bennu would be quite smooth. Instead, it’s rugged and cluttered with boulders. The textured terrain presents a new challenge to the OSIRIS-REx team. The spacecraft hovers safely around the asteroid, but it was designed to swoop in and collect samples of the surface material. Scientists and engineers say they will now reconsider potential landing spots for the maneuver. After scooping up some asteroid grains, OSIRIS-REx will depart Bennu and head back to Earth. The samples will arrive in 2023, and scientists can’t wait to get their hands on them.

Unlike planets and moons, asteroids have remained virtually unchanged since the beginning of the solar system, preserved by the vacuum of space. Scientists suspect that asteroids such as Bennu, which is covered in water-rich minerals, delivered some of the water present on Earth today, though they’re not sure on the specifics. (Japan’s Hayabusa2 spacecraft found evidence that another asteroid, named Ryugu, had less water than expected, according to newly released results from the mission.) To study these objects is to explore the past of our cosmic neighborhood. “It’s almost like doing archaeology,” says Eva Lilly, a scientist at the Planetary Science Institute.

Scientists have another motive in their research: self-preservation. Because of its close proximity to Earth, Bennu is classified as a potentially hazardous asteroid. The risk isn’t immediate; scientists estimate a 1-in-2,700 chance of an impact late in the 21st century. But they want to be prepared, for the sake of future generations.

“In case there is, one day, an asteroid heading toward Earth, we want to know what we are dealing with,” says Lucille Le Corre, a scientist at the Planetary Science Institute who works on the OSIRIS-REx mission.

The rocky relics of the ancient past might also hold some clues about the solar system’s future.

“The more that we can understand the early parts of the solar system and the evolution that we’ve taken to get to this point in our history, the more we can understand what happens next,” says Cristina Thomas, an assistant professor of astronomy and planetary science at Northern Arizona University.

What happens next?

“That’s a good question,” she says. “Who knows?”



For about a month, Katherine Joy spent hours snaking up and down the Antarctic ice on a snowmobile, trying to spot gatherings of meteorites.

The bottom of the Earth is a jarringly alien realm—an “expansive place where the sky and ice seem to go on forever,” says Joy, a Royal Society University Research Fellow and meteorite hunter at the University of Manchester. And in some stretches of ice, “every rock you come across is from space.”

The majority of the world’s meteorites are discovered in Antarctica. A single dark rock would be easy enough to spot amid the white background, but the movements of the ice can also act as a conveyor belt, creating concentrated pockets of space debris. Meteorite-hunting expeditions over the past few decades have revealed, though, an enigmatic lack of iron meteorites in Antarctica compared with other locations around the world.

Though iron meteorites are falling through the atmosphere at equal rates across the planet, they simply weren’t showing up on the icy surface as often as they should be compared with their stony meteorite cousins. This raised an intriguing possibility: These missing iron meteorites were hiding beneath Antarctica’s ice.

To test this idea, Joy and her colleagues had come to Antarctica as part of the first-ever expedition to search for “lost meteorites.” They spent late December to early February scouting out accessible spots that might contain the best hauls. If they eventually find these missing meteorites on the full-blown expedition in a year’s time, they’ll have located new geochemical clues contained within that chronicle the early chaos of the solar system and its inner rocky planets, including our own.

Treacherously frigid conditions aside, finding meteorites buried beneath ice while scooting across a truly vast landscape will require plenty of serendipity, because buried meteorites can only be detected if you’re standing right above them. That’s why, to game the odds as much as it can, the team is bringing along some extremely fancy iron meteorite detectors: snowmobiles equipped with the sort of tech you’d normally find in war zones.

The hunt for lost meteorites began after a group of mathematicians and glaciologists started to wonder whether meteorites could burrow through Antarctic ice. The first test, in 2014, deployed a humble household freezer, a Pixar-like desk lamp, and “some small and cheapish meteorites,” says Geoffrey Evatt, a senior lecturer in applied mathematics at the University of Manchester.

The researchers shined the lamp on those discount meteorites, and nothing appeared to happen. Realizing that the lamp didn’t mimic the sun properly, they upgraded to a solar-simulator beam that provided the vital missing infrared spectrum.

That’s when they saw meteorites heat up and start to nestle down into the ice.

Iron meteorites generally come from the hearts of massive asteroids. Their composition is not dissimilar to that of Earth’s own core, which suggests that they can tell us much about the formation of rocky planets. They are rather shiny and typically have pronounced, sometimes crosshatched textures that catch the eye. Often, because of these properties, strange-looking rocks that the general public brings to meteorite researchers turn out to be iron meteorites, says Matthew Genge, a senior lecturer and meteorite expert at Imperial College London not involved in the expedition.

Iron meteorites are also tougher than other meteorites, which means they survive atmospheric entry better than their relations. All things considered, we should be finding plenty of them, so it’s strange to encounter so few in Antarctica, an otherwise veritable wonderland for all things spaceborne.

This deficit matters. Joy notes that the handful of different meteorite groups we know of originate from at least 100 different sources, from the innards of long-lost annihilated planets to the inner reaches of asteroids.

“Any new meteorite we find could provide us with a previously unsampled asteroid type that tells us something new about how planets first formed and geologically evolve,” she says. The lack of iron meteorites means a key part of that cosmic puzzle is missing.

After those early desktop experiments, the researchers upped their game. Within a cloud-simulator contraption, which replicated real-world Antarctic environmental conditions, they carefully placed meteorites between two ice layers. Shining a solar lamp on the site, they noticed that the stony and iron meteorites sometimes caused melting above and below them, meaning they could move up and down in their icy prison an inch or two in just a few hours.

The team then used a simple, elegant mathematical model to scale up these results to Antarctica. In the lab, stony and iron meteorite migrations were pretty indistinguishable, but this model showed that on a longer timescale, the iron meteorites could sink into the ice far quicker than the stony ones. These results, described in a 2016 study, made it seem possible that a huge number of iron meteorites were in hiding.

The next step: prove it. By December 2018, funded by a significant grant, the first U.K.-led Antarctic search mission was out in the wilds of that frosted land, hunting for meteorites—a proof-of-concept run for the climactic meteorite search a year later.

Scouting out meteorites on the surface is one thing, but finding buried iron meteorites is an entirely different ball game.

In Antarctica, some areas of blue ice—named for its ethereal, vivid hue—are so compressed and lacking in trapped air bubbles that they look like glass. It feels like “you’re walking on air,” Genge says, and any patches of snow on top “looks like clouds.” Standing there makes you feel like being on top of the world at the end of the world. In more practical terms, the ice can be almost transparent, providing an ideal window into the realm below. But no one had ever been out in blue-ice areas looking for sunken meteorites before, so the team didn’t know whether they would contain any, Evatt says.

It's not simply a matter of zooming around and taking in otherworldly views. Fun though this is, Joy says it’s “a bit of a chilly business when the wind is blowing.” At the same time, concentrating on scanning the ground for meteorites while making sure to drive safely and not get lost can sometimes be exhausting.

The iron meteorite-detection technology attached to the snowmobiles is both bespoke and complicated. It is analogous to land-mine detectors, but has some key design differences. Meteorite detectors don’t need to be as sensitive. Land mines try very hard not to be found, Evatt says, but large lumps of iron are fairly conspicuous to metal detectors, so long as you know where to look. However, land-mine detectors don’t like being bashed around, which is why the metal detectors on the snowmobiles had to be built to be far hardier. They need to deal with being “banged around left, right, and center” across the continent, Evatt says.

Land-mine detectors also dislike being moved too rapidly, which is problematic for the team: Researchers have to be able to detect iron meteorites in real time while they zip about. Thanks to all the computing power you can fit on the snowmobiles, that’s possible, but they have to maintain a speed of about nine miles per hour, because the signal-sorting algorithms can’t handle moving any faster or slower. Tests in Svalbard, a series of islands in the high Arctic, revealed other quirks; the detectors, for example, experience different types of signal noise on snow compared with ice.

The alternative to all this, though, would be exploring the continent by foot, using traditional metal detectors, a torturously slow endeavor. There’s likely fewer than one iron meteorite buried in ice every 0.4 square miles, on average. Even if the team does find a buried meteorite, it’s not always clear how to excavate it out of what could be several feet of bulletproof ice.

Already, though, researchers have some promising signs that their models and experiments are correct. Bits of mountain rock have been found falling into Antarctic ice and melting through, and Joy says that some meteorites they found have been partially buried within the ice, too. In both cases, heating during the austral summer days likely drove the rocks downward. During this season’s fieldwork, Joy and her colleagues have collected a good haul, at least 36 meteorites with a variety of compositions.

The team has yet to spot any fully buried iron meteorites, but that’s the aim of the fieldwork in 2020. It is nevertheless prepared for the possibility that it ultimately ends up empty-handed.

“We are literally in the hands of the gods,” Evatt says. “If a collision hadn’t happened in the asteroid belt millions of years ago, or if the orbital path of Earth hadn’t lined up with the trajectories of any resulting asteroidal debris, then it’s a definite possibility that these meteorites [never] landed at all, and there’s nothing we or all our equipment can do about that.”

They could, of course, end up finding plenty, and that hypothetical buried treasure would suddenly become very tangible. Success isn’t a numbers game at the end of the day. To show that iron meteorites might be found lurking beneath the surface, and to demonstrate that the model they have spent years working on applies to the real world, all they need to do is get lucky once.

“As soon as we’ve found one,” Evatt reckons, “I’ll be happy. Just one.”



A northern elephant seal needs to remember the calls of his rivals. An encounter between two males, fighting to control female harems, can be bloody—skin marked by an opponent’s canines, chunks torn from the trunklike nose, wounds on the chest shield. Such battles are rather rare only because less violent cues are often enough to deter an adversary.

Vocal displays are fundamental in these ritualized confrontations, and each male in the population has his own unique call that serves as an ID. “You can think of them as drumbeats,” says Caroline Casey, a researcher at the University of California at Santa Cruz. If a male can remember and recognize the vocal signature—characterized by this drumming rhythm—of those he has previously confronted, he can avoid energy loss in the best scenario, and death in the worst.

In the late 1960s, while studying the northern-elephant-seal population along the coasts of Mexico and California, Burney Le Boeuf and his colleagues couldn’t help but notice that the threat calls of males at some sites sounded different from those of males at other sites. “It was just so obvious. It would be like me distinguishing a dialect from people who live in Alabama as opposed to people who live around Boston,” recalls Le Boeuf, who has studied the marine mammals ever since and is affiliated with UC Santa Cruz.

That was the first time dialects were documented in a nonhuman mammal. Fifty years later, however, those dialects are lost.

Half a century ago, Le Boeuf and his colleagues were documenting the size of the elephant-seal population, which had shrunk to almost nothing during the 19th century. The population now counts more than 210,000 individuals, three times as many as in 1969. Such a dramatic expansion, after the species had been so close to extinction, might have affected how these males talk to one another.

Little is known about the abundance of northern elephant seals prior to 1840. “There were apparently quite a lot of them,” A. Rus Hoelzel from Durham University told me, but “then they were noticed as a nice resource for oil.” As with other seals and whales, they were hunted for their blubber. The oil obtained from this thick layer under the skin served as fuel for lamps or was used to make soap. A single large male could provide up to 210 gallons of oil.

By 1850, northern elephant seals were scarce. Two decades later, individuals were barely seen, even on Isla Guadalupe, a volcanic, somewhat lonely island in the northwest region of Mexico, where most of the seals had escaped from poachers. It is, even today, not easily reached. But the remoteness of the place did not discourage collectors, whose interest in the species increased as the seals became rarer.

“They were keen to get samples,” Hoelzel said, adding that “1892 was probably the nadir.” That year, an expedition to Isla Guadalupe found nine individuals: a surprise, given that the seals were presumably extinct. The collectors killed seven of them for the Smithsonian’s museum collection. Decades later, Alfred W. Anthony, who had been part of the team, argued that this type of action was “considered justifiable at the time, as the species was considered doomed to extinction … and few, if any, specimens were to be found in the museums of North America.”

By the turn of the century, the population had been driven down to a tiny number—maybe 100 individuals, perhaps even fewer than 20. All the northern elephant seals that exist today are descendants of the small herd that survived on Isla Guadalupe.

The first decades of the 20th century proved to be kinder to the species, and in September 1922, the Mexican government sent a patrol boat to Isla Guadalupe “to post a large sign in both Spanish and English, informing those that might land at that point that a heavy penalty followed the killing or capture of any elephant seals,” Anthony wrote. A month later, the island was declared a biological reserve. The number of northern elephant seals has only increased since then.

As that tiny population grew, northern elephant seals started to recolonize former breeding locations. It was precisely on the more recently colonized islands where Le Boeuf found that the tempos of the male vocal displays showed stronger differences to the ones from Isla Guadalupe, the founder colony.

In order to test the reliability of these dialects over time, Le Boeuf and other researchers visited Año Nuevo Island in California—the island where males showed the slowest pulse rates in their calls—every winter from 1968 to 1972. “What we found is that the pulse rate increased, but it still remained relatively slow compared to the other colonies we had measured in the past,” Le Boeuf told me.

At the individual level, the pulse of the calls stayed the same: A male would maintain his vocal signature throughout his lifetime. But the average pulse rate was changing. Immigration could have been responsible for this increase, as in the early 1970s, 43 percent of the males on Año Nuevo had come from southern rookeries that had a faster pulse rate.

This led Le Boeuf and his collaborator, Lewis Petrinovich, to deduce that the dialects were, perhaps, a result of isolation over time, after the breeding sites had been recolonized. For instance, the first settlers of Año Nuevo could have had, by chance, calls with low pulse rates (assuming that variation existed within the original colony on Isla Guadalupe). At other sites, where the scientists found faster pulse rates, the opposite would have happened—seals with faster rates would have happened to arrive first.

As the population continued to expand and the islands kept on receiving immigrants from the original population, the calls in all locations would have eventually regressed to the average pulse rate of the founder colony. In the decades that followed, scientists noticed that the geographical variations reported in 1969 were not obvious anymore. But nobody explicitly tested the differences among the multiple sites again. In the early 2010s, while studying northern elephant seals on Año Nuevo Island, Casey noticed, too, that what Le Boeuf had heard decades ago was not what she heard now. “It was an amazing opportunity to study how their vocal behavior had changed over the recovery from near-extinction,” she told me.

Casey and her collaborators teamed up with Le Boeuf to reanalyze the historic recordings and record the vocal displays of modern males in those same sites. By performing more sophisticated statistical analyses on both sets of data, they confirmed that dialects existed back then but had vanished. Yet there are other differences between the males from the late 1960s and their great-great-grandsons: Modern males exhibit more individual diversity, and their calls are more complex.

While 50 years ago the drumming pattern was quite simple and the dialects denoted just a change in tempo, Casey explained, the calls recorded today have more complex structures, sometimes featuring doublets or triplets. Think, she said, of each drumbeat-like vocal display of each male as a name. In the 1960s, the males would have had names such as Jan, Dan, or Sam, which would support recognition but still sound pretty similar to one another. That was presumably not a problem, as a male had “to keep track of five dudes in his little social network,” Casey said. These days, however, with many more males to encounter, there might be a Jan or a Sam in the population, but also a Gilbert or a Trevor. Without these new signatures, “it would be really difficult to distinguish everyone,” Casey added. The diversity of names—rhythms—nowadays allows modern males to keep track of their 25 to 30 competitors without making deadly mistakes.

The development of dialects in northern elephant seals was perhaps just a snapshot of a behavior happening during the first decades of population expansion and recolonization. In contrast with that geographical variation, the individual diversity we hear now might be more representative of the vocal communication of these marine mammals. “I think that what we are seeing today is probably more closely matched to the vocal behavior of males prior to the bottleneck,” Casey said. It’s only a guess, she acknowledged, as there are no records of how the males were talking to one another before the extermination driven by humans.



Up on the International Space Station, the United States controls one half, and Russia controls the other half. Like the U.S., Russia has one of its astronauts on board right now, and as a rule, 250 miles above Earth, collaboration is synonymous with consensus. But recently, as the U.S. prepared to launch a new and somewhat risky mission, Russia hesitated before deciding whether it would endorse the project.

The cargo mission is expected to leave Earth this weekend. A rocket will lift off from historic Cape Canaveral, in Florida, and propel a capsule loaded with supplies toward the ISS. After the capsule arrives, astronauts on board the station will unpack the shipment, replace it with items to return home, and seal the capsule back up. Once the capsule detaches, it will fall into the planet’s atmosphere and splash into the Atlantic Ocean.

The mission, scheduled to launch in the very early hours of Saturday morning, is a decisive moment for the American space program. If the voyage goes well, the next time the capsule launches to space, it will carry more precious cargo: people.

In 2014, the agency awarded two companies, SpaceX and Boeing, multibillion-dollar contracts to build the next generation of astronaut transportation. The United States has relied on Russia to launch its astronauts to space since its space shuttles stopped flying in 2011, after three decades of operations. As the shuttles began new lives as museum displays, NASA turned to the private sector for help. Now the first test run of this new era has arrived.

“We’re ready to fly,” Kathy Lueders, the NASA manager of the program, said at a press conference last week.

Russia, on the other hand, wasn’t so sure.

The United States and Russia work together on the ISS, along with 13 other countries. They share information on station operations, including the particulars of the SpaceX mission. Last week, NASA officials said that, while they had cleared SpaceX for launch, their counterparts at Roscosmos, the Russian space agency, had a “dissenting opinion.”

The disagreement centered on the SpaceX capsule’s approach to the ISS. Spacecraft that connect with the station are equipped with flight software that can prevent dangerous accidents. European, Japanese, and other spacecraft that previously have rendezvoused with the ISS carry independent systems designed to kick in if their primary computers fail. The backups would take over and maneuver the spacecraft away from the ISS to avoid a collision.

The SpaceX capsule, known as Crew Dragon, doesn’t have this configuration. Instead, it relies on redundant systems in its main computer system.

NASA officials said this configuration is sufficient, while Russian officials weren’t sold. The apprehension is understandable. A bungled approach could put the capsule, the ISS, or both at risk.

“The ISS still has three people on board, and so this vehicle coming up to the ISS for the first time has to work,” Kirk Shireman, the manager of the International Space Station program, said last week. “It has to work. This time up here and the people who worked around the country to make this successful are very much aware of that.”

Russia took a few days to consider NASA’s reasoning. On Wednesday, just days before blastoff, Roscosmos formally agreed to proceed with the launch and docking, Shireman tells The Atlantic.

The docking maneuver is new for SpaceX. The company regularly delivers cargo to the ISS on another spacecraft, Dragon 1. As the capsule approaches, a powerful robotic arm on the station reaches out and grabs it. Success is not guaranteed. In 2017, an approaching Dragon detected an error and automatically aborted the attempt just three-quarters of a mile away from the ISS. The capsule docked successfully in a second attempt the following day.

Unlike its counterpart, Crew Dragon will greet the station by locking up to a brand-new adapter—a metallic ring more than five feet across—that SpaceX itself actually delivered in 2016. (Boeing’s uncrewed capsule, Starliner, is expected to complete the same mission in April.) If Crew Dragon sticks the docking, it will become the first commercially built spacecraft designed to carry humans to join with the ISS.

Bill Gerstenmaier, the associate administrator for NASA’s human-exploration division, said Roscosmos broached the subject in December, but admitted he “wasn’t diligent enough to stay in touch with them” over the 35-day government shutdown that kept 95 percent of NASA’s workforce from their jobs. As the historic launch approached, Gerstenmaier renewed discussions.

“One of the actions that I assigned the team was to go look a little more rigorously at some of the fault detection, identification, and responses to various failures … to make sure the computers do all the right things, that we don’t get in a situation where the vehicle goes dead or dormant and then just continues its approach and just collides with station,” he said.

Even before they received Russia’s blessing, NASA officials seemed confident the opposition wouldn’t hold up the launch. But whether the U.S. agency would have moved ahead if Roscosmos decided to push back is unclear. The nations have shared their high-flying home for nearly 20 years. American astronauts and Russian cosmonauts share meals and tedious housekeeping duties like vacuuming. When the SpaceX capsule arrives at the station this weekend, they will work together to greet it.

But the partnership has not been free of tension, thanks to political matters back on Earth. Even now, the relationship between the leaders of the space agencies isn’t perfect. Last fall, Jim Bridenstine, the NASA administrator, visited Russia at the invitation of Dmitry Rogozin, the head of Roscosmos. Bridenstine tried to reciprocate in January, but he withdrew his offer after some members of Congress argued that Rogozin, a Putin ally who is under sanctions by the U.S. government, shouldn’t set foot on U.S soil. Rogozin was reportedly displeased with the reversal.

There’s even been some awkwardness between Rogozin and Elon Musk, the founder of SpaceX. Last week, Rogozin told Russian media that he doesn’t believe SpaceX can build better rocket engines than Russia can. “Musk is not a technical expert in this matter,” Rogozin said. “He just doesn’t understand what this is about.” Musk responded on Twitter: “I have been chief engineer/designer at SpaceX from day 1.”

Despite some stormy exchanges, the weather forecast in Cape Canaveral looks good for a launch on Saturday so far.



In a perfect world, the Arctic Council would meet around a massive spruce table in a castle of ice. It would include Erik the Red, Superman, several Inuit elders, Justin Trudeau, and Magnus Byrnison, King of the Polar Bears, and they would discuss villainous threats to the North. In fact, it is just another committee meeting for diplomats, and at the most recent meeting, Trudeau wasn’t even there.

Secretary of State Mike Pompeo did attend the meeting, held last week in Finland. (Finland actually has an ice castle, but it was not used.) It was a strange event: Pompeo gave an ominous speech that made frequent reference to the effects of climate change, even as the U.S. delegation refused to recognize that it exists. The disjuncture pointed to the larger failure of American policy in the Arctic: a U.S.-border region in upheaval, both ecologically and strategically, that the government can’t quite ever focus on.

And Pompeo only underlined that stance when he said that the United States would soon reestablish a permanent diplomatic presence in Greenland, a mostly autonomous territory of Denmark, for the first time since the 1950s, while also announcing that he would be postponing his first trip to Greenland.

He had intended to visit last week, on his way back from London, but there was “a need for the secretary to be in Washington, D.C., today,” according to the statement. Apparently the growing military buildup near Iran and the trade war with China demanded the secretary’s attention.

Greenlandic and American interests have long been intertwined: The Arctic island is the home of the northernmost U.S. military base. It also housed some of the Cold War–era Ballistic Missile Early Warning System, because an intercontinental ballistic missile inbound from Russia would likely pass over its massive area. In 1940, when the Nazis invaded Denmark, the United States acted to preserve the Danish colony’s independence, knowing that Greenland would have served as an excellent refueling station for German bombers on their way to New York.

Yet the United States has paid less attention to the island lately—until 2018, when it looked up to find that China was in line to fund three big airports in Greenland, including one in the capital, Nuuk. James Mattis, then the U.S. secretary of defense, personally intervened. He successfully lobbied the Danish prime minister to provide better loans and terms to the island. Now, perhaps, the United States is realizing that it can’t lose its strategic North Atlantic linchpin.

Pompeo postponed his visit anyway. It seems we want the benefits of leading Greenland, but we don’t want to put in the work. The diplomatic equivalent of an “I can’t come to your party, but let’s hang soon!” text seemed to capture the current state of our Arctic policy: We’re not treating it like it’s a priority.

This was true at the Arctic Council meeting as well. The council brings together foreign secretaries from the seven countries in the Arctic, as well as representatives from six indigenous councils whose members mostly live in the Arctic. Denmark, a small peninsula 600 miles south of the Arctic, attends because of its relationship to Greenland.

Perhaps more than anywhere else in the world, the Arctic is currently feeling the effects of climate change. The Arctic has warmed roughly twice as fast as the rest of the planet, according to the National Oceanic and Atmospheric Administration. It looks less and less like “the extensively frozen region of recent past decades.”

In American-controlled aspects of the Arctic, the same principles hold. The U.S. National Climate Assessment, released last year by 14 federal agencies, including the Department of Defense, devoted a special chapter to Alaska, which “is warming faster than any other state.” It projected that climate change could eventually cost the state $270 million a year.

Yet Pompeo—and the United States, by proxy—refused to join the statement from the Arctic Council acknowledging this straightforward reality. “A majority of us regarded climate change as a fundamental challenge facing the Arctic,” said a statement from Timo Soini, the foreign minister for Finland, which all but named the United States as the outlier.

“A majority of us noted with concern” last year’s Intergovernmental Panel on Climate Change report, which warned of mass suffering if the world warmed by 1.5 degrees Celsius, Soini added. And the other members of the council “emphasized” the importance of both fighting climate change and preparing for it in order to limit the damage to Arctic communities.

These are some of the most blandly accurate statements about climate change imaginable. They are supported by reams of research from federal agencies. It seems from public reporting that even Russia, normally no ally of the climate, could sign on to them. And still Donald Trump’s administration did not.

Pompeo alluded to a handful of climate-related effects in his speech to the council. “Steady reductions in sea ice are opening new passageways and new opportunities to trade,” he said. He referred to “13 percent of the world’s undiscovered oil” held in the Arctic, which is becoming more exploitable. He simultaneously bragged that U.S. energy-related carbon emissions have fallen since 2006, a fact that only makes sense in the context of climate change.

Yet these effects were always drawn back to the threat of Russia and China. Ice-free Arctic shipping lanes could become “the 21st century’s Suez and Panama Canals,” he warned. The Arctic Ocean could “transform into a new South China Sea, fraught with militarization and competing territorial claims,” he said, alluding to China. “Russia is already leaving snow prints in the form of army boots,” he said, citing its Arctic military expansion since 2014.

Pompeo even attacked their climate policies. “It isn’t clear that Russia is reducing emissions at all, despite being the largest emitter of black carbon in the entire Arctic,” he said. He attacked China for tripling its emissions since 2006. These would have been much more powerful points if Pompeo had approved the Arctic Council statement in the first place.

The whole argument makes sense if you’re careful not to think too hard:

Why is the Arctic becoming a strategic flash point?  Because huge amounts of sea ice now vanish every summer, far more than vanished a few decades ago. (“There is likely to be a nearly sea ice–free Arctic during the summer by midcentury,” said last year’s National Climate Assessment.)

Oh, so why is the sea ice vanishing? Ha! Good question. Next?

Democrats rail against how President Trump has called climate change “a hoax,” but the White House’s relationship with scientific truth is much more opportunistic. They are happy to assert some facts in one breath, then turn around and reject them in the next. That’s how you can disagree with the idea that climate change poses threats to the Arctic, while lambasting Russia and China for refusing to tamp down their carbon emissions. That’s how you can repeal fuel-efficiency rules by arguing that the world is going to warm 4 degrees Celsius anyway, as the White House did last year.

Climate change is not the only point of illogic in the U.S. Arctic strategy. Russia currently has 41 military ice breakers, with more on the way. The United States has two. It makes sense now, provided you don’t think too hard about it. But someday reality will catch up.



The crew of the International Space Station spends most of their time inside, but sometimes they venture out. Astronauts have conducted more than 200 space walks in the past two decades, often to spruce up the station, and on the next one, two astronauts are scheduled to replace some old solar-panel batteries. It was going to be a historic excursion: For the first time in history, both of the spacewalkers would be women.

I just found out that I’ll be on console providing support for the FIRST ALL FEMALE SPACEWALK with @AstroAnnimal and @Astro_Christina and I can not contain my excitement!!!! #WomenInSTEM #WomenInEngineering #WomenInSpace

That was the plan. But on Monday, just days before Anne McClain and Christina Koch were supposed to float outside, NASA announced that McClain had been replaced with a male astronaut, Nick Hague. According to the space agency, the ISS doesn’t have enough space suits on board that would fit both women.

At first glance, this seems like a massive oversight. Shouldn’t NASA have figured out which size space suit its astronauts needed before they launched, and had the appropriate gear waiting for them on the ISS? And how is it that the world’s premier space agency can dress two men for space walks without issue, as it did several times last year, but not two women?

To answer these questions, it helps to start at the beginning. Not the Big Bang—we’ll save that for another day—but the 1960s, when NASA first started launching astronauts to space.

Back then, women weren’t wearing space suits; they were making them. The Apollo space suits were manufactured by the International Latex Corporation, the maker of Playtex bras and girdles. Seamstresses went from sewing undergarments to stitching together thin layers of high-tech fabric on their noisy Singer sewing machines. The space suits were custom-made for individual astronauts, all of whom were men.

After astronauts planted the American flag on the moon, NASA turned its focus toward the next phase in space travel, the space-shuttle program. The shuttles were designed for a future of frequent flights to and from the space above Earth, with more astronauts than ever before.

Tailoring custom space suits for so many passengers would be too expensive and time-consuming. So in the 1970s, NASA took a Mr. Potato Head approach and developed pieces for arms, legs, and torsos that astronauts, from the smallest women to the largest men, could mix and match. The spacewalking suits—known as extravehicular mobility units, or EMUs—came in five sizes: extra small, small, medium, large, and extra large.

Space-suit engineers thought that outfitting the new space travelers would be simple. “Some groups initially assumed that women could fit in the same sizes as small men—or at worst, that some of the men’s sizes would have to be scaled down proportionately to fit women,” Elizabeth Benson, a NASA design engineer, wrote in a 2009 paper on sizing considerations in space-suit design.

This approach doesn’t account for differences in the body shape of men and women. “For the same height and weight, women can have significantly wider hips and narrower shoulders than men,” Benson wrote. “If, for example, a one-piece coverall designed for a man is meant to fit at the shoulders and the hips, then one of these fit areas is likely to be compromised for a woman.”

Extra room can actually make space walks more difficult. “As a woman, doing space walks is more challenging mostly because the suits are sized bigger than the average female,” Peggy Whitson, a NASA astronaut who helped build the ISS and who holds the American record for time spent in space, said in a recent documentary interview. And Whitson would know: She also holds the record for the most space walks for a female astronaut, 10.

In the 1990s, several years after the first American women flew to space, budget cuts forced NASA to trim its space-suit program. Extra small was the first to go, and small followed soon after. Most astronauts fit into the mediums and larges, but not all.

“People my size are in fourth grade. Literally, I mean, some fourth graders are bigger than me,” Nancy Currie, a NASA astronaut who is 5 feet tall, told NPR in a 2006 interview.

The limited sizing affected some astronaut duties. While it didn’t impact space-shuttle crew assignments, since crew members who didn’t spacewalk, such as Currie, could do research or run the robotic arm, “it did impact assignments on the ISS where all crew members—Russian and U.S.—had to be able to conduct [space walks],” says Bonnie Dunbar, a former NASA astronaut who flew on the shuttle five times and an aerospace-engineering professor at Texas A&M University, where she runs a space-suit-design lab.

The restrictions piled up after the space-shuttle program ended in 2011 and the ISS became the only destination for astronauts. NASA was forced to judge prospective astronauts not only by their qualifications and experience, but by their size, too. “Applicants had to be bigger to be selected,” Dunbar says. (The agency faced a similar situation in the 1960s, with the opposite problem: The first space capsules, tiny and cramped, required astronauts to be no taller than 5 feet 11 inches.)

Today astronauts still use the same 40-year-old space suits; NASA hasn’t made any new ones since they were designed. Several have been lost over the years, including in the Challenger and Columbia disasters and in a SpaceX cargo mission that exploded in 2015.

“We have to make do with what we have,” Dunbar says.

So what do we have, specifically on the ISS?

The space station currently has six people on board. Their space-suit wardrobe contains six space-suit torsos, two each in medium, large, and extra large. But only some are ready for space walks; one medium and one extra large are spares, and require hours of work to prep for use, according to the NASA spokesperson Brandi Dean. McClain trained on the ground in both the medium and large, but she wore the medium torso on a space walk with Hague last week. When she came back inside, she told mission control that the medium fit her better—the same size that her fellow female astronaut, Koch, planned to use.

“We do our best to anticipate the space-suit sizes that each astronaut will need, based on the space-suit size they wore in training on the ground, and in some cases—including Anne’s—astronauts train in multiple sizes,” Dean says. “However, individuals’ sizing needs may change when they are on orbit, in response to the changes living in microgravity can bring about in a body. In addition, no one training environment can fully simulate performing a space walk in microgravity, and an individual may find that their sizing preferences change in space.”

Instead of adapting the spare, NASA decided to change the space-walk lineup. Koch will wear the medium torso on Friday’s space walk, and McClain will wear it again on another space walk, scheduled for early April.

The space agency is long overdue for new space suits, but it has hesitated, thanks to budgetary restrictions and changing policies. Medium or large, the garments “have far outlasted their original 15-year design life,” according to a 2017 report from NASA’s inspector general. In the past decade, NASA has spent nearly $200 million on space-suit development for future missions, including to Mars, but “the agency remains years away from having a flight-ready spacesuit capable of replacing the EMU or suitable for use on future exploration missions,” the report found.

Some of the stagnation stems from uncertainty over where NASA will send future astronauts. The moon and Mars are different worlds with their own environmental conditions, and require different space-suit designs to keep humans healthy and alive. And it doesn’t help that the preferred destination seems to change with each new presidential administration. “The lack of a formal plan and specific destinations for future missions has complicated spacesuit development,” the inspector general said.

NASA today is far more accommodating for female astronauts than it once was, and the agency employs more of them than before. Consider the 1980s, when engineers sheepishly asked Sally Ride whether 100 tampons were enough for her seven-day mission to orbit. But the space suits they wear today are a relic of that time, built for some bodies better than others. Yes, NASA has to work with what it has, but in 2019, it employs female astronauts and should anticipate more. It doesn’t seem too much to ask to have enough space suits to fit them, too.



Science is sometimes caricatured as a wholly objective pursuit that allows us to understand the world through the lens of neutral empiricism. But the conclusions that scientists draw from their data, and the very questions they choose to ask, depend on their assumptions about the world, the culture in which they work, and the vocabulary they use. The scientist Toby Spribille once said to me, “We can only ask questions that we have imagination for.” And he should know, because no group of organisms better exemplifies this principle than the one Spribille is obsessed with: lichens.

Lichens can be found growing on bark, rocks, or walls; in woodlands, deserts, or tundra; as coralline branches, tiny cups, or leaflike fronds. They look like plants or fungi, and for the longest time, biologists thought that they were. But 150 years ago, a Swiss botanist named Simon Schwendener suggested the radical hypothesis that lichens are composite organisms—fungi, living together with microscopic algae.

It was the right hypothesis at the wrong time. The very notion of different organisms living so closely with—or within—each other was unheard of. That they should coexist to their mutual benefit was more ludicrous still. This was a mere decade after Charles Darwin had published his masterpiece, On the Origin of Species, and many biologists were gripped by the idea of nature as a gladiatorial arena, shaped by conflict. Against this zeitgeist, the concept of cohabiting, cooperative organisms found little purchase. Lichenologists spent decades rejecting and ridiculing Schwendener’s “dual hypothesis.” And he himself wrongly argued that the fungus enslaved or imprisoned the alga, robbing it of nutrients. As others later showed, that’s not the case: Both partners provide nutrients to each other.

Today, such a relationship is called a “symbiosis,” and it’s considered the norm rather than the exception. Corals rely on the beneficial algae in their tissues. Humans are influenced by the trillions of microbes in our guts. Plants grow thanks to the fungi on their roots. We all live in symbiosis, but few organisms do so to the same extreme degree as lichens. If humans were to spend their lives in the total absence of microbes, they’d have many health problems but would unquestionably still be people. But without its alga, a lichen-forming fungus bears no likeness to a lichen. It’s an entirely different entity. The lichen is an organism created by symbiosis. It forms only when its two partners meet.

Or does it?

Lichen-forming fungi mostly belong to a group called the ascomycetes. But in 2016, Spribille and his colleague Veera Tuovinen, of Uppsala University, found that the largest and most species-rich group of lichens harbored a second fungus, from a very different group called Cyphobasidium. (For simplicity, I’ll call the two fungi ascos and cyphos). The whole organism resembles a burrito, with asco fillings wrapped by a shell that’s rich in algae and cyphos.

For many, it was a game-changing discovery. “The findings overthrow the two-organism paradigm,” Sarah Watkinson of the University of Oxford told me at the time. “Textbook definitions of lichens may have to be revised.” But some lichenologists objected to that framing, arguing that they’d known since the late 1800s that other fungi were present within lichens. That’s true, Spribille countered, but those fungi had been described in terms that portrayed them as secondary to the main asco-alga symbiosis. To him, it seemed more that the lichens he studied have three core partners.

But that might not be the whole story, either.

Look on the bark of conifers in the Pacific Northwest, and you will quickly spot wolf lichens—tennis-ball green and highly branched, like some discarded alien nervous system. When Tuovinen looked at these under a microscope, she found a group of fungal cells that were neither ascos nor cyphos. The lichens’ DNA told a similar story: There were fungal genes that didn’t belong to either of the two expected groups. Wolf lichens, it turns out, contain yet another fungus, known as Tremella.

This isn’t entirely new. Over the years, other lichenologists have detected Tremella in wolf lichens, but only ever in three specimens, and only in the context of abnormal swollen structures called galls. “It was thought to be a parasite,” Tuovinen says. “But we found it in completely normal wolf lichens that don’t have any kinds of bumps.” Tremella is right there in the shell of the lichen burrito, next to the cyphos. It seems to make extremely close contact with the algae, hinting at some kind of intimate relationship. And it’s everywhere. Tuovinen analyzed more than 300 specimens of wolf lichens from the U.S. and Europe, and found Tremella in almost all of them.

Wolf lichens are among the most intensively studied of all lichens, so how could such a ubiquitous component have been largely missed? The problem, Tuovinen says, is that under a normal microscope, “the fungal cells all look the same.” She saw it only when she tagged the lichens with glowing probes that were designed to recognize Tremella genes. And she knew to do that only after finding those genes amid wolf lichen DNA. Earlier genetic studies, she says, might have missed them because they had specifically focused on the genes of the ascos. “There hadn’t been a reason to expect anything else based on the knowledge at the moment,” she says.  

It’s an exciting discovery, says Erin Tripp, a lichenologist from the University of Colorado Boulder, but it’s still unclear what Tremella is actually doing. Most likely, she argues, it’s an infection, albeit a very widespread one. The alternative is that Tremella is a core part of the lichen. “This would, of course, be very exciting,” Tripp says, but to demonstrate that, the team would need to try to reconstitute wolf lichens with or without Tremella or, alternatively, use gene-editing techniques to disable the fungus and check how the lichens respond. “Without this sort of experimental approach, it seems premature to suggest that Tremella represents a third, fourth, or whatever-th symbiont.”  

Tuovinen agrees that one shouldn’t overplay Tremella’s role. But she argues that lichenologists have too readily downplayed such organisms. More than 1,800 species of non-asco fungi have been described within lichens, and they’ve been labeled with terms that imply some kind of externality: commensalistic. Parasymbiotic. Endolichenic. Lichenicolous. If they’re not ascos, “we somehow just decided, without testing, that they’re parts of a lichen that can be excluded,” Tuovinen says. “We really don’t know that.”

“Language matters a lot when dealing with these organisms,” Spribille, now at the University of Alberta, adds. “If we set up our language so that our definition of a lichen is fixed, and these other elements are extrinsic, we’re setting ourselves up to find that they’re extrinsic.” He thinks that researchers should move away from “the imperative of classification” and the compulsion to shoehorn organisms into fixed buckets. He suspects that the relationships between all the components of a lichen are probably highly contextual—beneficial in some settings, neutral or harmful in others.  

That’s a lesson other scholars of symbiosis should also heed. There’s a tendency to categorize the bacteria within an animal’s microbiome as good or bad, as beneficial mutualists or harmful pathogens. But such labels imply an inherent nature that likely doesn’t exist. The same microbes can be benign or malign in different contexts, or perhaps even at the same time. Biology is messy—as are lichens.

Tripp agrees that “we, as a community of lichen biologists, need to revisit the role of all symbionts in the lichen microcosm.” No matter how one describes Tremella and other lichen-associated fungi, it’s clear that they do affect the form and function of the lichen as a whole. How they do so is “the great unsolved problem” of lichenology, says Anne Pringle of the University of Wisconsin at Madison. “Are the multiple species of fungi interacting mutualistically? With each other? With the algae? Are some parasites? Probably the answer to all questions is yes. Regardless, the data support an emerging consensus: Lichens are ecosystems as well as organisms.”

How many partners are there in a lichen? “I don’t know, but I think it depends on the lichen,” Spribille says. “I don’t expect there to be any one configuration that makes a lichen, a lichen.” That’s especially likely because lichens have evolved many times over, from different lineages of ascos that independently formed partnerships with different algae, over hundreds of millions of years. To expect them all to share the same basic plan is like expecting birds to be the same as fish.

They’re especially hard for us to understand because they’re so different from the organisms we’re familiar with. Unlike animals and plants, lichens don’t really have tissues. They don’t grow from embryos, and instead form through fusion. Different combinations create different forms—brittle or flexible, flat or round—and these traits are likely just as important to them as wings or legs or eyes are to animals. “We don’t understand their needs,” Spribille says. “In the absence of that, it’s difficult to say what kinds of configurations are within the realm of the possible.” And we can only ask questions that we have imagination for.



The great white shark—a fast, powerful, 16-foot-long torpedo that’s armed to the teeth with teeth—has little to fear except fear itself. But also: killer whales.

For almost 15 years, Salvador Jorgensen from the Monterey Bay Aquarium has been studying great white sharks off the coast of California. He and his colleagues would lure the predators to their boats using bits of old carpet that they had cut in the shape of a seal. When the sharks approached, the team would shoot them with electronic tags that periodically emit ultrasonic signals. Underwater receivers, moored throughout Californian waters, detected these signals as the sharks swam by, allowing the team to track their whereabouts over time.

In 2009, the team tagged 17 great whites, which spent months circling Southeast Farallon Island and picking off the local elephant seals. But this period of steady hunting ended on November 2 of that year, when two pods of killer whales (orcas) swam past the islands in the early afternoon. In the space of eight hours, all 17 great whites abruptly disappeared. They weren’t dead; their tags were eventually detected in distant waters. They had just fled from Farallon. And for at least a month, most of them didn’t return.

Jorgensen wondered if this was a one-off, but the tags recorded similar examples in later years—orcas arrive, and sharks skedaddle. Some orcas also hunt seals, so it’s possible that the sharks are just trying to avoid competition—but that seems improbable, given how quickly they bolt. The more likely explanation is that the most fearsome shark in the world is terrified of orcas.

Killer whales have a friendlier image than great white sharks. (Perhaps because of their respective portrayals in movies: Jaws 2 even begins with the beached carcass of a half-eaten orca.) But orcas are “potentially the more dangerous predator,” says Toby Daly-Engel, a shark expert at the Florida Institute of Technology. “They have a lot of social behaviors that sharks do not, which allows them to hunt effectively in groups, communicate among themselves, and teach their young.”

Combining both brains and brawn, orcas have been known to kill sharks in surprisingly complicated ways. Some will drive their prey to the surface and then karate chop them with overhead tail swipes. Others seem to have worked out that they can hold sharks upside-down to induce a paralytic state called tonic immobility. Orcas can kill the fastest species (makos) and the largest (whale sharks). And when they encounter great whites, a few recorded cases suggest that these encounters end very badly for the sharks.

In October 1997, fishing vessels near Southeast Farallon Island observed a young white shark interrupting a pair of orcas that were eating a sea lion. One of the whales rammed and killed the shark, and the duo proceeded to eat its liver. More recently, after orcas passed by a South African beach, five great-white carcasses washed ashore. All were, suspiciously, missing their liver.

A great white’s liver can account for a quarter of its body weight, and is even richer in fats and oils than whale blubber. It’s “one of the densest sources of calories you can find in the ocean,” Jorgensen says. “The orcas know their business, and they know where that organ lies.”

Rather than ripping their prey apart, it seems that orcas can extract livers with surprising finesse, despite lacking arms and hands. No one has observed their technique, but the wounds on otherwise intact carcasses suggest that they bite their victims near their pectoral fins and then squeeze the liver out through the wounds. “It’s like squeezing toothpaste,” Jorgensen says.

An orca, then, is an apex predator’s apex predator. No wonder sharks flee from them. But orcas don’t actually have to kill any great whites to drive them away. Their mere presence—and most likely their scent—is enough. Many predators have similar effects. Their sounds and smells create a “landscape of fear”—a simmering dread that changes the behavior and whereabouts of their prey. The presence of tiger sharks forces dugongs into deeper waters, where food is scarcer but cover is thicker. The mere sound of dogs can keep raccoons off a beach, changing the community of animals that lives in the tide pools.

The fear of death can shape the behavior of animals more than death itself. “Lions, for example, do not eat a lot of impala, but impala fear lions more than any other predator on the landscape except humans,” says Liana Zanette from Western University in Canada, who studies landscapes of fear. Similarly, killer whales don’t have to kill many white sharks to radically change their whereabouts. In 2009, for example, orcas passed by Southeast Farallon for less than three hours, but the great whites stayed away for the rest of the year. For the elephant seals, the island became a predator-free zone. “The two predators faced off, and the winners were the seals,” Jorgensen says.

And what about the sharks? “They had to move to find a new food source when the killer whales ruined the neighborhood,” Zanette says. “This could interfere with their ability to successfully migrate, which requires a bulk-up of fat and nutrients.”

“We think of white sharks as these great ocean predators, but their bag of tricks includes knowing when to pack it in,” Jorgensen says. “That play might have contributed to their long-standing success.”

Or, in other words: Run away, doo doo doo doo doo doo, run away, doo doo doo doo doo doo, run away, doo doo doo doo doo doo, run away.



In 2015, scientists discovered a pig in China that would set off a frantic, worldwide search. The pig carried bacteria resistant to colistin, a drug used to cure infections when almost all other drugs have failed. Colistin is an old antibiotic with sometimes severe side effects in humans. Chinese doctors didn’t even prescribe it for human patients; instead, farmers were relying on literal tons of it, used in low doses, as a growth promoter in pigs.

Bacteria are constantly crossing continents in people, animals, and food, though. In England, where colistin is reserved for patients in rare and dire circumstances, public-health officials worried. Could colistin-resistant bacteria also be lurking in that country?

The answer was hidden somewhere in Public Health England’s archives. The agency routinely collects and sequences bacteria on food and humans, and it just needed to search those sequences for the DNA segment that confers bacterial resistance to colistin. In theory, this shouldn’t have been much harder than a Google search. To a computer, a DNA sequence looks like a very long word, which just happens to be made up of only four letters: A, T, C, and G.

Yet, the search took 256 computers working together for an entire weekend, says Zamin Iqbal, a computational genomicist at the European Bioinformatics Institute who collaborates with Public Health England. The researchers there did find colistin resistance among their 24,000 samples, and eventually, countries all over the world found it, too.

Why did this process take so long? The computers at Public Health England had to open up and search the sequencing files of 24,000 genomes one by one. If Google had to search every page on the internet for the word pie every time you search for pie, that search would also take forever. Instead, Google is constantly indexing pages. If a blog post is written about pie, Google files that post under the pie entry in its index. So when someone comes along looking for pie recipes, it just has to serve up the pages under the pie entry. That’s part of the reason a Google search takes less than a second.

So Iqbal decided to build a Google of sorts for bacterial and viral genomes. He and his colleagues downloaded all available genomes—nearly 500,000 at the time—from a public database called the European Nucleotide Archive. The 170,000-gigabyte data set took six whole weeks to download. Then, the team indexed the data. The resulting tool is called BIGSI, for BItsliced Genomic Signature Index.

Searching for colistin resistance through nearly 500,000 sequences now takes just a few seconds.

Suppose a patient has an unusual brain infection, says Jennifer Gardy, a genomic epidemiologist who until recently was at the University of British Columbia and who was not involved with the project. Suppose it’s a pathogen that the doctor doesn’t recognize. Before BIGSI, the pathogen’s particular sequence might have been hiding in one of those 500,000 genomes. But a mountain of data is only as good as your ability to search it. “We can now go back and look through all of the DNA, through all of the other experiments that had done sequencing. Loads and loads of DNA,” Gardy says. For the first time, it’s possible to easily answer a question as simple as: “Have we seen this thing before?”

Since Iqbal and his colleagues started sharing their project—making a demo version of BIGSI available online, posting a non-peer-reviewed paper on the website bioRxiv, giving talks—they’ve been hearing from researchers who’ve started to use it.  After Andrew Page, a bioinformatics researcher now at the Quadram Institute, learned about the tool, he walked back to his office and fired it up. Page was interested in a particular plasmid, a round loop of DNA, that helps make typhoid-fever bacteria drug resistant. These plasmids seemed to have popped up out of the blue in Pakistan.

“Within two seconds, I got a list of 20 other samples where they were seen,” Page says. The plasmid wasn’t just in other typhoid bacteria. It was in soil bacteria, animal bacteria, E. coli—painting a much more complex picture of how resistance plasmids emerge and get swapped between different bacterial species.

Iqbal’s paper is just getting published today in Nature Biotechnology, after making its way through the sometimes slow process of peer review. But published papers have already cited the bioRxiv preprint, and another scientist wrote a program to more easily search mutations of a gene in BIGSI. Tara Smith, an epidemiologist at Kent State University, says that BIGSI is a fantastic idea, although the tool is only as good as the data that go in. “The genomes we choose to sequence are very biased,” she says—often toward serious clinical infections, from patients in research-intensive hospitals, in big urban centers.

The team is updating BIGSI with new data that have been made public since Iqbal made the first version, and the total number of sequences available at one quick click will be up to 1.2 million. As sequencing becomes more common, the number of publicly available bacterial and viral genomes has doubled. At the rate this work is going, within a few years multiple millions of searchable pathogen genomes will be available—a library of DNA and disease, spread the world over.



It’s before dawn on a late August morning, the Washington sky blanched with smoke drifting from distant wildfires, and Molly Alves and David Bailey have caught a beaver.

The two biologists haul the ornery package of fat and fur, still penned into the trap that closed around him overnight like a giant clam, up the banks of a meandering, tea-colored stream. The drainage is cluttered with Himalayan blackberry and Japanese knotweed, whose rhubarblike stems the beaver has commandeered to build his lodge—a native mammal thriving amidst invasive plants. The beaver, his lustrous fur shimmering in the pale light, flaps his tail and gnaws at the trap with burnt-orange incisors. His forepaws grasp the wire mesh, a prisoner straining against his cell walls.

“That is a very feisty sub-adult,” Bailey grunts as he and Alves lug the beaver toward the road. “When they’re trying to nom on the trap like that, it means they’re pretty stressed.”

Although not indigenous themselves, Alves and Bailey relocate beavers under the auspices of the Tulalip Tribes, a sovereign nation with nearly 5,000 members. This week, they’ve set their traps in the Puget Sound suburb of Marysville—half an hour north of Seattle if you leave before daybreak, an eternity at rush hour. Across the street from the Marysville Public Library waits their Silverado pickup, its right two wheels perched on the curb. Alves and Bailey, foreheads damp with sweat, set the beaver down and lower the tailgate. Morning traffic roars past, drivers craning their necks.

An elderly pedestrian wanders toward us, snatching up candy wrappers and soda cans with a long-handled trash picker. Ah, I think, a Good Samaritan, out for a spot of neighborhood cleanup. If anyone would appreciate local fauna, it’s this guy. I sidle up and point out the beaver, now being boosted into the truck.

The man gazes at me, his eyes a milky blue. “What are you going to do with him?”

Relocate him, I reply.

The man smiles. “Why don’t you just shoot the son of a bitch?”

I am momentarily flabbergasted. I sputter something about transferring the beavers to nearby public lands where they can build dams, create wetlands, and do some ecological good. He cuts me off.

“Good?” he laughs. “What good do they do? They’re always clogging up culverts and being a pain in the ass. You’re lucky you got to him before I did.” Before I can craft a response, he snaps up a crushed water bottle and strolls off.

The sentiment that Castor canadensis is little more than a tree-felling, water-stealing, property-flooding pest is a common one. In 2017, trappers in Washington State killed 1,700 “nuisance” beavers, nearly 20 times more than were relocated alive. In neighboring Oregon, the herbivorous rodents are classified as predators, logic and biology notwithstanding. California considers them a “detrimental species.” Last year alone, the U.S. Department of Agriculture eliminated more than 23,000 conflict-causing beavers nationwide.

Running countercurrent to this carnage is another trend: the rise of the beaver believer. Across North America, many scientists and land managers are discovering that, far from being forces of destruction, beavers can serve as agents of water conservation, habitat creation, and stream restoration. In Maryland, ecologists are promoting beaver-built wetlands to filter out agricultural pollutants and improve water quality in the Chesapeake Bay. In North Carolina, biologists are building beaverlike dams to enhance wet meadows for endangered butterflies. In England, conservationists have reintroduced the Eurasian beaver (Castor fiber) in hopes that their pond complexes will attenuate destructive floods. And in Washington, where a century of habitat loss has devastated salmon, the Tulalip Tribes are strategically dispatching beavers to support the fish so integral to their history and culture.

Back at the truck, I recount my exchange with the beaver-abhorring walker. Alves laughs. She has heard such slander before, and has a rebuttal at the ready.

“I would have asked him if he likes fresh water and salmon.”

That beavers benefit salmon is, in some quarters, a provocative claim. Many biologists historically regarded beaver dams as stream-choking barriers to fish passage. In the 1970s, Washington, Oregon, and California even passed laws mandating the removal of in-stream wood, beaver dams included. More recently, a 2009 proposal funded by the Atlantic Salmon Conservation Foundation suggested eradicating beavers from 10 river systems on Prince Edward Island and employing trappers to enforce “beaver-free zones” in others.

The notion of purging beaver dams to allow salmon to pass, however, doesn’t stand up to scientific scrutiny. One 2016 study documented individual salmonids traversing more than 200 beaver dams on their way to spawn in Oregon streams, suggesting that fish have little trouble negotiating the obstacles. Far from harming salmon, in fact, beavers create indispensable fish nurseries. By filling up ponds and digging canals, beavers engineer the deep pools, lazy side channels, and sluggish backwaters that baby salmon need to conserve energy and evade predators such as great blue herons. Today, the National Marine Fisheries Service considers “encouraging formation of beaver dams” vital for recovering Oregon’s endangered coho populations.

“Beavers create complex habitat and enhance local biological diversity in a way that’s really unique,” says Michael Pollock, an ecosystems analyst at the National Oceanic and Atmospheric Administration who’s among the beaver movement’s grandfathers. “They do a much better job of managing these systems than we do.”

The Pacific Northwest once boasted far more beaver-built salmon habitat than it does today. When Europeans landed on North America’s shores, as many as 400 million beavers inhabited the continent. By 1900, three centuries of unabated trapping had converted all but 100,000 or so into fancy fur hats and other garments. As derelict beaver dams crumbled and ponds drained, untold thousands of streams eroded into desolate gullies. In a 2004 study, Pollock found that beaver ponds in a single river basin, Washington’s Stillaguamish, once supported as many as 7.1 million juvenile coho each winter. By the early 2000s, the watershed’s depleted ponds could sustain fewer than a million—an 86 percent crash in fish-rearing potential.

The joint demise of beavers and salmon also harmed the Pacific Northwest’s indigenous groups—particularly the Tulalip, so bound to the mighty fish that they refer to themselves as People of the Salmon. To the Snohomish, Snoqualmie, Skykomish, and other Puget Sound tribes that compose the modern-day Tulalip, salmon were no mere resources. The fish were partners, symbionts that loyally sustained their human dependents so long as the tribes protected their rivers and treated them with due reverence.

The white colonists who overran Puget Sound did not share that respect. On January 22, 1855, Isaac Stevens, the governor of the new Washington Territory, and dozens of tribal chiefs signed the Treaty of Point Elliott, an agreement that forced many of the Sound’s Native people onto the 22,000-acre Tulalip Reservation. While a judge later called the treaty “unfair, unjust, ungenerous, and illegal,” it did have a redeeming feature: permanently preserving tribal members’ rights to fish at their “usual and accustomed” places. Although the provision was seldom honored—Native fishermen were arrested and harassed, sometimes violently, by their white counterparts—a federal court finally intervened on the tribes’ behalf in 1974, granting Native people half the annual harvest.

Yet the victory was, in some ways, a hollow one. The Puget Sound’s salmon were in free fall, the victims of dams, overfishing, and the Seattle area’s explosive growth. Thousands of acres of marsh had been paved over, hundreds of embayments wiped out. Beaches had been bulwarked, lowland forests demolished. What use was having your right to fish confirmed by the courts if there were no fish to catch? “We’d lost so much natural water storage,” says Terry Williams, the Tulalip’s treaty-rights commissioner. “We needed to come up with plans for longer-term watershed recovery, to have natural approaches that allow ecosystems to restore themselves.”

Williams, a genial and gravel-voiced tribal member, grew up on the Tulalip Reservation in the 1960s, eating not salmon but government rations—hardtack, crackers, butter dyed with yellow food coloring. “We’d have to filter all the flour and take the bugs out before we could use it,” he recalls. Williams spent his youth tromping through the reservation’s woods and tracking its fauna, including beavers. He and a young cousin caught juvenile beavers alive, wrangled them into sacks, and relocated them to wetlands near their home to watch them work—for no other reason, he says, than that he was “13 years old and curious.” They caught raccoons, too, which they kept in the house: “My mom’s sister went a little crazy when they started going through the cupboards.”

After a stint in Vietnam, Williams returned to Washington to work for a railroad company and attend college via the G.I. Bill. He tried commercial fishing in Puget Sound for a season, netting salmon to sell and flounder to take home. In the early 1980s, some friends asked if he’d consider working for his tribe’s fisheries department—just for a year, they promised. The Tulalip Tribes were then embroiled in legal struggles all over Washington State in defense of their members’ fishing rights, and Williams spent seven days a week on the road, preparing arguments and sitting in on court sessions. A year on staff turned into two, 10, a career. In the decades since, Williams has directed the Environmental Protection Agency’s American Indian Environmental Office, served on the United Nations’ Convention on Biological Diversity, and held a seat on just about every board, council, and commission pertaining to salmon recovery in Puget Sound. “I just got addicted to it,” he laughs.

Around 2007, Williams began to ponder beavers. One of his friends, a farmer in Whatcom County, had harvested a bumper crop after beavers built ponds on his property and lengthened his irrigation season. Williams recalled his own childhood experiments in beaver relocation, and began to wonder if rodent restoration might be the “natural approach” the region’s salmon habitat so badly needed. “He brought up beaver in just about every meeting for years, to the point that he drove people crazy,” recalls Abby Hook, a former hydrologist with the Tulalip’s treaty-rights division. “They’d say, ‘Okay, let’s talk about [Clean Water Act] permits.’ And he’d say, ‘No, let’s talk about beaver.’”

In 2013, Williams found a sympathetic soul in Ben Dittbrenner, the founder of Beavers Northwest, a group dedicated to helping landowners coexist with the meddlesome mammals. Dittbrenner hoped to study the benefits of beaver relocation for his doctoral degree at the University of Washington; now all he needed were some beavers to relocate. The tribe had the desire and the resources, Dittbrenner the beaver expertise. He and Jason Schilling, a tribal biologist, developed a computer model to identify gentle, low-gradient streams ideal for beaver releases, then spent months traipsing the Skykomish River basin, ground-truthing prospective relocation sites.

Before the project launched, though, it had to overcome a legal obstacle. The previous year, the state of Washington had passed a bipartisan “Beaver Bill” praising beavers’ ecological value and encouraging their relocation. Although the legislation was well intentioned, it contained a grave flaw, a provision inserted by a beaver-fearing legislator on the Olympic Peninsula. While the law permitted biologists to move beavers around sparsely settled eastern Washington, it prohibited releasing them west of the Cascades—the region that’s home to Seattle, Tacoma, Olympia, and most of the state’s other population centers. The message: Beavers can do good, but keep the damn things away from people.

Still, the Tulalip’s lawyers were undaunted. The tribe’s authority to manage wildlife superseded the state’s, they argued, and their treaty rights gave them the ability to restore salmon habitat as they saw fit. The tribe struck a deal with the U.S. Forest Service, which was hungry for more beavers on public land. In 2014, its inaugural year, the Tulalip Beaver Project relocated 23 beavers onto federal acres in the Skykomish River basin. “They’re doing us a service all the way around,” says Joe Neal, a district ranger in the Mt. Baker-Snoqualmie National Forest. “Anything we can do to hold water up here, that’s good.”

Through 2018, the project—which brought aboard Molly Alves in 2014 and David Bailey the next year—has moved 122 beavers to 20 locations around the Skykomish. Seven of those sites were first populated this year, meaning it’s still too early to know whether the relocations have taken. At the 13 sites whose success the Tulalip can assess, beavers have established six colonies and constructed more than 12 acres of wetlands—more than 10 football fields’ worth of the West’s most important ecosystem.

Merely quantifying the impact of released beavers, however, misses the project’s point. When the Tulalip Tribes began releasing rodents, Dittbrenner’s modeling suggested that around three-quarters of the suitable beaver habitat in the Skykomish was vacant—a gap too large for any relocation effort to fill. Instead, the Tulalip’s hope is to jump-start a natural re-beavering of the Puget Sound’s uplands.

“The whole idea is to seed the watershed in high-quality areas where colonies will persist and crank out lots of baby beavers, sending out offspring and repopulating the watershed,” Dittbrenner explains. “That’s the really important assumption about what’s going to happen.”

The beaver now safely ensconced in the pickup, Alves and Bailey drive back to the nearby Tulalip Reservation to examine their bucktoothed prize. The heart of the Tulalip Beaver Project is the tribe’s fish hatchery, a compound of pools and pens that pumps out 11 million chinook, coho, and chum salmon fry each year. When they’re not holding salmon, the gnaw-proof concrete walls and flowing water within the hatchery’s raceways also make them perfect beaver enclosures.

At the hatchery, Alves and Bailey swiftly process their ward. They place the trap on a scale, which registers the creature’s weight at around 30 pounds—a juvenile, Bailey says—snip a hair sample, and staple color-coded tags in the animal’s ears for future identification: white in the left, yellow in the right. Although the biologists handle him as tenderly as possible, the beaver doesn’t enjoy the poking and prodding, and begins to chatter his teeth as though he were cold—another sign of stress.

Once he’s had a few minutes to calm down, Alves and Bailey usher the beaver into a cloth sack, with only his withers exposed, for the most sensitive step: sexing. Because even males possess internal genitalia, conclusively determining a beaver’s sex can’t be done visually; instead, it requires some serious olfactory skills. Alves presses on the beaver’s belly, feeling for his anal glands—nubbins of flesh whose secretions beavers use to mark their territories and tell friend from foe. The anxious beaver has clenched his tail, making matters more difficult, but at last the glands emerge, like pinkish teats, from the plush underfur. Alves squeezes gently, milking a dollop of viscous, yellowish fluid onto her gloved finger.

Males, they say, are redolent of motor oil. Females smell like old cheese.

Alves wrinkles her nose. “Male,” she confirms.

“It’s kind of musky and urine-y,” Bailey opines later. “At this point, it’s all over my waders, and it’s never coming out. Sometimes I’ll be in the car and suddenly smell it and think, Oh, where’s the beaver?”

His ordeal mercifully concluded, the beaver is released into one of the raceways, gliding up the narrow pen to huddle against the far wall. A cinder-block hut, floored with wood chips, stands at the raceway’s center. When we return the next morning, we’ll find that he’s settled into the makeshift lodge to await a family reunion. Beavers are kin-oriented creatures, with as many as 10 family members sharing a lodge: the mating adults, their newborn kits, 1-year-olds, and 2-year-olds. (The latter depart the colony each spring in search of their own territories, like college-bound teenagers.) Relocate a beaver by himself and he’s liable to wander the landscape, searching for companionship, until he’s devoured by a bear or cougar. Move him with his clan, and he’s more likely to stay put and build.

The Tulalip beaver relocation effort, like most projects of its kind, thus strives to capture and release cohesive families. When they catch unattached beavers, they attempt to match them at the hatchery, like a rodent dating service. “If you give them a few nights together, they usually pair up,” Alves says. “They get lonely—they want to be with other beavers.”

When all goes well, relocation can produce spectacular results. Later that week, Bailey and Alves drive me to a stream high in the Mt. Baker-Snoqualmie National Forest, the 1.7-million-acre block of Douglas fir and western red cedar that sprawls across the western flank of the Cascade Range. The Tulalip had dropped off a family of seven beavers in this creek in fall 2015. Nothing happened at first, and Alves and Bailey concluded the site was a bust. When they found signs of dam-building the next spring, they figured another colony had moved in on its own. Grainy camera-trap footage, however, revealed that the nocturnal construction workers bore the Tulalip Tribe’s ear tags. The relocation had worked after all.

Now a lonely beaver outpost has blossomed into an empire. Eleven separate dams have transformed the stream from a string-straight, free-flowing riffle into a patchwork of sun-dappled pools and serpentine side channels. We teeter along felled trunks and bushwhack through thickets of vine maple, exploring a complex that seems only to expand as we press on. The vast maze of channels and ponds would be an impressive feat for an engineer in a backhoe; for a handful of rodents armed only with incisors, it’s practically miraculous.

The largest dams are graceful crescents of latticed wood, buttressing serene ponds with yellow alder leaves swirling across their surface—the Platonic ideal of beaver infrastructure. Others are loose stickjams that hold back only a turbid bathtub. “I think they were drunk when they made this one,” suggests Bailey, eyeing a crooked, homely ridge of mud.

For the salmon thriving in this beaver-built paradise, even the humblest dams provide key habitat. Everywhere we look, we see shoals of coho fry milling about the pools, their orange-edged fins waving like pennants as they flee our shadows. Behind one dam glitters freshly swept gravel marking a pair of redds, or salmon nests—a visible rebuke to those who still claim that beaver dams block fish passage. We’re high in the western Cascades, hours by car from the Puget Sound lowlands, yet beavers and salmon have connected this slender stream to the sea.

While expanded ponds are beavers’ most visible hydrologic impact, their ability to recharge groundwater might be an even greater contribution. At the Tulalip’s relocation sites, Ben Dittbrenner has found that for every cubic meter (264 gallons) of surface water that beavers impound, another 2.5 cubic meters (660 gallons) sinks into the earth. As that water trickles through the soil, it cools off, eventually reemerging to mingle with streamflows downriver. Elsewhere, such hyporheic exchange between surface water and groundwater keeps streams hydrated later into the dry season, turning seasonal creeks perennial. Dittbrenner’s research suggests that beaver-facilitated cooling and mixing also reduces water temperatures by more than 2 degrees Celsius (about 3.5 degrees Fahrenheit), a huge boon for heat-sensitive salmon and trout.

Although beavers won’t singlehandedly save us from climate change, such findings suggest that they might be able to help our stressed water supplies adapt to a warmer future. “By 2100, we’re expecting to see snowpack, which is basically our water storage reservoir, disappear throughout a lot of the Cascades,” Dittbrenner says. “I’m curious whether beavers could make up an appreciable storage component of that lost snowpack.”

Yet beavers’ drought-fighting powers only go so far. After our visit to the salmon mecca, Alves and Bailey take me to another stream complex, dubbed Mahoney, where the Tulalip introduced beavers in 2015. The creatures had done their job with aplomb, reconnecting several disjointed, fishless channels into a massive pond buttressed by a sturdy 100-foot dam. I’d visited Mahoney the previous summer and found its waters vibrating with coho fry—a shining example of all that beaver relocation can achieve. “You know it’s succeeded when you need a flotation device to monitor your site,” Bailey had joked then.

When we emerge into the Mahoney clearing this year, though, it’s apparent that no watercraft will be necessary. Catastrophe has plainly befallen the colony. The vast pond has receded into a handful of scattered puddles, exposing the beavers’ once-impregnable lodge—now a sad, vulnerable pile of brittle sticks. Thickets of ghostly dead alder stand marooned atop muddy hummocks. Deer and bear tracks pock the soggy ground, suggesting that new visitors are already taking advantage of sprouting sedges and grasses. The scene has the mysterious, dilapidated grandeur of a medieval ruin.

“This is still a functioning space, and it’s obviously beautiful in a different way,” Alves says as we survey the abandoned kingdom. “It’s eons better than it was when we found it.” Still, there’s no mistaking the disappointment in her voice.

Beavers abandon sites for all kinds of reasons, from disease to predation to food depletion. At Mahoney, though, Alves and Bailey suspect a different culprit: drought. The previous summer, the stream that fed Mahoney had completely dried up, cutting off the site’s spigot. Beavers are geniuses at capturing running water, but they cannot conjure it from thin air.

Even in the best of times, getting beavers to stay where you put them poses immense challenges. When biologists dumped more than 200 beavers into Wyoming streams in the 1990s, for instance, many fell prey to bears, cougars, and other carnivores. Altogether, fewer than 20 percent took to their new environs. As drought diminishes western Washington’s beaver-carrying capacity, persuading the rodents to stick around has become harder still.

“With these sites drying up earlier in the year, we’re running out of places to put these beavers,” Alves says. “We didn’t anticipate that four years ago.”

So how do you get beavers to cooperate? One option: Give them a leg up. After touring Mahoney, we jounce up yet another endless string of dirt roads to yet another remote tributary, this one shielded from the road by a verdant screen of maple and Devil’s club. The Tulalip had installed beavers here a year ago, with disheartening results. “They just kind of waddled off, never to be seen again,” Bailey says.

To entice the next colony to stay, Bailey and Alves have decided to attempt a new tactic—human-built walls of wooden posts and sticks known as beaver-dam analogues. The idea behind beaver-dam analogues, or BDAs, is simple: In situations where suboptimal habitat discourages beavers from settling down, a human-assisted starter kit can persuade them to stay put and build dams of their own. In one Oregon stream where scientists built more than 120 beaver-dam analogues, beaver activity increased eightfold—and juvenile steelhead trout survival spiked by more than 50 percent. Little wonder that BDAs are now among the American West’s hottest stream-restoration techniques, deployed to enhance wet meadows for greater sage-grouse in Wyoming, remediate mining waste in Montana, and improve fish habitat in Northern California.

The appeal of beaver-dam analogues is not merely that they’re effective—they are also easy to install. Armed with sledgehammers, the Tulalip biologists and a few volunteers begin to thwack upright silver-fir logs into the gravel stream bed, pounding them a few inches deeper with each satisfying swing. The hollow thump of hammer meeting wood resounds in the summer air. Between the thuds the crew shouts encouragement.

“You’re a monster, David!”

“You’re a beast, Bethany!”

“Shiloh, you been working out?”

Soon the creek is picketed with two rows of vertical posts, slightly askew, like a mouthful of crooked teeth. Coho fry flit around our boots, picking at insect larvae stirred up by the activity. Mike Sevigny, the Tulalip’s wildlife program manager, plops down on the bank, his shirt darkened by sweat, and pulls off the surgical mask he wears to filter the wildfire haze. While Sevigny spends much of his time managing elk—another creature of vital cultural importance to the tribe—he considers beavers to be the center of terrestrial ecosystems as well as aquatic ones.

“Beaver ponds increase forbs, grasses, and shrubs, which are forage for bear, elk, deer, and everything else,” Sevigny says. “The beaver gave us so much we don’t understand because they’re gone. We don’t know how good the land could be because we never saw it. A lot of these habitats are screaming for help.”

We return the next day to complete the job. Shayna Schultz and Bethany Tegt, the project’s technicians, thread willow and maple sticks between the posts like basket weavers, then pack the interstices with straw to form a semipermeable seal. Soon knee-deep water has backed up behind the ramshackle dams. The crude structures don’t look durable—they’ll likely blow out in a flood a few springs hence—but permanence isn’t the point. “They just need to last long enough to get beaver back into the system,” Alves explains as we slosh through the nascent pool. By furnishing a safe, attractive pond and a semi-stable base of operations, these beaver-dam analogues will, with luck, convince the next relocated colony to stick around, get to work, and reproduce.

Thanks in large measure to the Tulalip’s example, tribal-led beaver restoration in Washington will soon take another leap forward. Among the volunteers at the beaver-dam analogue installation is Erik White, wildlife manager with the Cowlitz Tribe. The Cowlitz’s Southwest Washington territory encompasses the Lewis River, which in turn is home to bull trout, a cold-loving fish imperiled by climate change.

“A lot of projections show that 80 percent of bull trout habitat in the Lewis River basin is going to disappear in the next 25 years because of increasing water temperatures,” White says during a break in our post-pounding. Inspired by the Tulalip, he and the Cowlitz Tribe have launched a beaver-relocation project of their own, and plan to begin moving the animals to the Gifford Pinchot National Forest in spring 2019. “We’ve got less and less snowpack every year,” White adds. “Beavers could be a way to spread flows out into a more natural hydrograph.”

Not only have the Tulalip spurred other tribes to action, they have also expended considerable political capital refining the Beaver Bill, the law that prevented relocations in western Washington. Although the Tribe’s unique legal status meant that it was never bound by the prohibition, the law’s illogic irked Terry Williams, the treaty-rights commissioner. More beavers on more Washington rivers would mean more salmon in Puget Sound, he figured. So, in 2017, the tribe flexed its political muscle, dispatching a lobbyist to Olympia, the state’s capital, to advocate for a revision. The stubborn lawmaker who had opposed moving beavers west of the Cascades had retired, and a new Beaver Bill, this one permitting relocations on both sides of the mountains, sailed through. Starting in 2019, nontribal groups, such as environmental nonprofits, will be able to relocate the animals west of the Cascades, too. The doors to re-beavering have been flung open.

Williams was pleased by the outcome, but not surprised. When he began his career in fisheries management decades ago, he recalls, he’d found that the Tulalip were subject to a skein of laws intended to thwart tribal fishing. He’d griped to the tribe’s chairman about the legal obstacles. “Well, that’s not so difficult,” the chairman retorted. “If the law doesn’t work for you, change it.”

Williams chuckles hoarsely as he recounts the story. “Because of that simple statement,” he says, “I’ve changed so many laws I can’t count ’em anymore.”

In early October, I rendezvous once more with the Tulalip crew, this time on a winding forest road that parallels the Snoqualmie River. The summer’s wildfires have been quelled, and the morning is crisp and blue, lit by the sun cresting over the granitic spires of the western Cascades. I arrive in time to catch Schultz and Tegt unloading four wire cages, which between them hold seven hulking beavers. Fourteen beady eyes rove over their captors. The creatures—two adults, four 1- or 2-year-olds, and a skittish kit—were trapped at a golf course near Tulalip, where they’d been irking the groundskeepers. “They all get along pretty well, so we think they’re from the same colony,” Schultz says.

We lug the crates down to a marshy tributary. A fork in the stream has created a natural impoundment, offering a prime release site and obviating the need for any beaver-dam analogues. At the base of an alder copse, the crew has built a slapdash lodge, temporary barracks that will keep the beavers safe from bears and cougars until they can build a permanent home. The crew lifts each cage to the lodge entrance, opens the door, and watches the beavers trundle into the dark interior. Although a previous relocation here failed, Alves and Bailey hope the threat of oncoming winter will motivate this batch to immediately start building. “We usually have more late-season establishment success,” Alves explains in a whisper. “They’re in hunker-down mode.”

Collaborating with beavers, many scientists point out, confers extraordinary benefits: Rodent restoration is a natural, cost-effective strategy capable of tackling problems as diverse as nitrogen pollution and stream erosion. But beaver work can be as frustrating as it is rewarding. No matter how thoughtfully you choose release locations, no matter how many beaver-dam analogues you install, beavers are wont to do what beavers are wont to do. For all the science that guides it, beaver relocation entails, on some level, an act of faith. Dig a wetland with a backhoe, and you can be reasonably certain it will still exist in five years. Outsource the job to beavers, and they might succeed beyond your wildest expectations—or, as at Mahoney, permit your pond to lapse into a meadow.

It is thus with considerable trepidation that we wait before the makeshift lodge to see how its new inhabitants react. For a time, all is quiet; then a chorus of grunts and gurgles, eerily akin to the cries of a human infant, rises from the hut. We hear the staccato rasp of incisors on wood. Through gaps in the slats we catch a flash of fur, a glittering eye.

Abruptly a snout, culminating in a quivering nose, pokes from the logs, followed by a plump torso and a leathery tail. It’s one of the adults, a male whose mahogany fur seems more suited to an orangutan. He slips into the still water and cruises up the creek, head high, alert to our presence but unafraid. We hold our breath as he reaches the cul-de-sac at the far end of the impoundment, performs a tight pirouette, and glides back toward his new home. His inspection complete, he squirms back into the lodge and vanishes from view—master, now, of his own fate.

Portions of this story appeared in the book Eager: The Surprising, Secret Life of Beavers and Why They Matter.

This post appears courtesy of  BioGraphic.



This past Thursday, the University of California, one of the largest research institutions in the world, blew up negotiations with Elsevier, one of the largest publishers of research articles in the world. The university would no longer pay Elsevier millions of dollars a year to subscribe to its journals. It simply walked away.

Not so long ago, blowing off a publisher as important as Elsevier would have been unthinkable. But academics have been joining in an open revolt against Elsevier’s extremely profitable business model. In 2012, mathematicians started a petition to boycott the publisher that has since been signed by more than 17,000 researchers. In December 2016, universities in Germany stopped paying for Elsevier’s journals. In 2018, the same thing happened in Sweden and then Hungary.

Elsevier still made $1.17 billion in publishing in 2017, which is precisely the problem, according to its critics. At its loftiest, academic publishing is supposed to be about disseminating hard-won knowledge. But publishers charge hefty subscription fees, making that knowledge often inaccessible to researchers at all but the wealthiest institutions. Last year, the University of California paid Elsevier $11 million.

At the same time academic institutions are paying for access to journals, their employees are providing labor to journals for free. When journals receive a manuscript, they send it to experts in the field in a process called peer review. Peer reviewers vet the articles, make detailed suggestions, and offer a recommendation for or against the manuscript’s publication. Journals do not pay peer reviewers, even though their work takes substantial time and is absolutely vital to academic publishing.

Nor do journals pay for the research that they publish. In the United States, research funding often comes from government agencies—in other words, from taxpayers. Yet if members of the public tried to read new academic research, they would very quickly hit paywalls. This puts the public in the odd position of having to pay for research twice—first to fund it, and a second time to access its results.

Alternatives have started to emerge. There are illegal ones, such as the website Sci-Hub, that allow users to pirate journal articles. (Elsevier sued Sci-Hub and won $15 million in 2017.) But the strongest push for a new, aboveboard system has come from the open-access movement.

[ Read: The research pirates of the dark web ] 

Open access means a journal article is free to read, but researchers pay the journal a fee to cover the cost of publishing. For publishers, it means changing their business model from charging readers to charging authors. In 2001, scientists founded the Public Library of Science to publish open-access journals. The idea caught on, and even traditional publishers, including Elsevier, have since introduced open-access journals under their umbrella. But the most prestigious journals, such as Nature and Science, remain behind a paywall.

The agencies that fund scientific research are growing enthusiastic about open access. In the United States, government agencies such as the National Institutes of Health and the National Science Foundation require grantees to deposit their papers in a public repository within 12 months of publication. Last fall, 11 European agencies that collectively fund $8.8 billion in research put forward a far more radical proposal, Plan S. By 2020, the scientists they fund would be able to publish only in journals that are free to read upon publication. (“The S in Plan S can stand for ‘science, speed, solution, shock,’” its leading proponent told Nature.) The Bill & Melinda Gates Foundation later signed on to Plan S as well.

[ Read: Academics want you to read their work for free ] 

The University of California cast its negotiations with Elsevier as a battle over open access, too. It went in with the goal of making all research from UC authors open access by default. The university wanted one contract to cover both the cost of publishing open-access articles and the cost of journal subscriptions. Elsevier says it offered UC a “unique model” that would offer researchers options for publishing. But the two sides couldn’t agree on specifics or a number. On one hand, this is a dispute about library fees. On the other, this is a dispute about the future of how knowledge is disseminated. UC Berkeley’s university librarian, Jeffrey MacKie-Mason, did not hesitate to put it in high-minded terms: “This really affects the progress of science in society and the advancement of humanity.”

When Elsevier was founded, in 1880, it took its name from the legendary Dutch publishing house Elzevir, which had ceased publishing more than a century earlier. As its logo, Elsevier used the Elzevir family’s printer’s mark, a tree entwined with a vine alongside the words Non Solus, or Latin for “not alone.” The logo represents, Elsevier has suggested, “the symbiotic relationship between publisher and scholar.” It is a nice sentiment, but certainly not a universal one.



In the desert town of Lajamanu, Australia, at the bend of a narrow dirt road, Carmel O’Shannessy worked at a school as a teacher-linguist in the early 2000s. Lajamanu’s indigenous Warlpiri people, who live in the country’s Northern Territory, were skilled at drawing sustenance from the landscape’s parched red soil, and O’Shannessy soon discovered hidden cultural riches the Warlpiri had stored up.

As she got to know the children in the community, O’Shannessy noticed that they had a different way of expressing themselves than their elders. People in Lajamanu generally spoke English, Warlpiri (an established local Aboriginal tongue), and some Kriol (a blend of English and Aboriginal languages). But O’Shannessy, who speaks both English and Warlpiri, grew convinced that the kids joking in the schoolyard were communicating in an unusual way. “When I listened more closely to how the children were speaking, they seemed to be using two languages in every sentence,” remembers O’Shannessy, now a lecturer at the Australian National University in Canberra. “I thought, This is really interesting. This is something worth investigating.”

As O’Shannessy recorded conversations and took notes, she realized that the children’s speech was distinct from anything she’d heard before. She created a storybook in pictures about a dog that escapes from a monster, then asked the kids to describe what was happening in the story. That exercise helped her confirm a few key features of their language. The children were using sentence structures from Warlpiri, but the verbs came from Kriol. The nouns, meanwhile, came from English, Warlpiri, and Kriol.

Speakers mixed in some completely new rules as well, such as using the suffix -m to refer to past and present events but not future ones. That custom was not present in any earlier languages, O’Shannessy says: “That really consolidated that this is a new [language] system all by itself.”

The media hailed O’Shannessy for highlighting a newly “discovered” language, called Light Warlpiri. And that discovery is not an isolated incident. Within the past decade or so, linguists and anthropologists around the world have described a handful of recently recognized tongues for the first time, including Jedek in Malaysia, Koro Aka in northern India, and Zialo in Guinea.

Understanding how languages emerge and survive holds great interest for researchers, since many languages are slipping away in increasing numbers around the world. The United Nations Educational, Scientific, and Cultural Organization (UNESCO) states that more than 40 percent of the world’s estimated 6,000 languages are endangered. But each new-language debut represents a bright spot against the global backdrop of widespread language die-offs. Tongues such as Light Warlpiri, Jedek, and Koro Aka fill gaps in our knowledge of how languages arise and endure, revealing some of the factors that can help keep rare languages alive.

Uncommon languages are better equipped to survive, researchers are learning, when young people are actively speaking them, whether in a family setting, in a school system, or in immersion programs. Elders who transmit cultural traditions to young people through a language can help it thrive, as well. But when the number of speakers drops from year to year—sometimes due to outside forces, such as globalization, that are difficult to control—rare languages might vanish, whether they’ve lingered for centuries or popped up seemingly overnight.

In some ways, the origin story of any language mirrors the broader story of how language evolved in the first place. Within close-knit groups of humans, whether on the savanna or in bustling towns, two factors have been present since ancient times: the need to communicate clearly and specifically, and the cognitive capacity to develop language systems that satisfy that need.

Relatively young languages, however, such as Light Warlpiri, are distinct in that they typically emerge out of the swirl of other, older languages that surround them. Many of these new languages arise in settings where there is some degree of cultural blending or displacement—and Light Warlpiri certainly fits that description. After British settlers arrived in northern Australia in the 1800s, indigenous Australians began to speak English and Kriol.

In this fluid setting, indigenous people became very comfortable switching between languages, a practice that helped drive Light Warlpiri’s emergence in the 1970s and ’80s. When adults spoke to children, O’Shannessy says, “they would speak in Warlpiri, but insert verbs and pronouns from English and Kriol. So the children internalized that system as if it was a single system.”

A similar melding prompted the rise of a language known as Jedek on the Malaysian peninsula, where many languages are spoken in a limited geographic area. Linguists from Sweden’s Lund University first stumbled across Jedek in the early 2000s, while studying a variety of other languages spoken on the peninsula. Jedek bears some resemblance to Jahai, a language commonly spoken nearby, and is akin to other Malaysian languages heard somewhat farther away. But it is also its own separate entity, with distinct grammatical structures and r sounds that Jahai does not possess. In late 2017, the Swedish researchers published their first paper confirming that Jedek is a totally distinct language.

The village where Jedek is spoken places a high value on cooperation and exchange. As such, the language includes many words that describe sharing and few that describe individual ownership.

Creating a full-blown new language often cements a kinship felt among its speakers—whether that kinship is rooted in religion, common social practices, or ancestral ties. Usually, O’Shannessy says, speakers of a fledgling language draw on older word forms and start to incorporate patterns they hear, or they might make small changes to a language pattern that already exists. “And then, because they’re all speaking to each other, that new pattern stays,” she says.

Some newly discovered languages, meanwhile, have very old roots. The linguist David Harrison of Swarthmore College and his research team, supported by the National Geographic Society, happened upon Koro Aka about 10 years ago in a remote region of northern India where dozens of indigenous languages are spoken. Although Harrison is not sure exactly when Koro Aka originated, he thinks it might have existed for centuries.

In the northern Indian region where Koro Aka arose, people share a common identity, living in bamboo homes on stilts, growing rice, and raising livestock. But all of Koro Aka’s speakers—about 1,000 people—already speak another language called Hruso Aka. That has researchers wondering why a community went on to develop a new language, especially since Koro Aka speakers identify culturally with people who speak only Hruso Aka.

“The Koro Aka population is subsumed within a larger population of Hruso speakers,” Harrison says. “That’s the usual scenario where people would switch over to the majority language.” What’s more, Koro Aka does not resemble the languages spoken in closely surrounding villages; it is as different from them, Harrison says, as English is from Japanese. But Harrison thinks Koro Aka might have linguistic predecessors that have not yet been uncovered, so he and his colleagues are tracing ever-expanding circles around the Koro Aka community to gather clues about the language’s true roots.

Parallel quests to understand what nurtures new languages and what sustains existing ones have led social scientists to one key answer: Languages often survive when young people are speaking them on a regular basis. This language transfer can be actively encouraged, as in immersion schools in Native American communities, or it can simply occur naturally.

O’Shannessy is optimistic about Light Warlpiri’s future for this reason. Even though only a few hundred people know the language, nearly all of the youths in the community are absorbing it and speaking it frequently.

In general, fostering language vitality is one of the anthropologist Gwyneira Isaac’s goals as director of the Smithsonian Institution’s Recovering Voices program. Though Isaac does not work specifically with emerging languages, she witnessed how cultural practices can help revive language after meeting a Canadian man who spoke the endangered Anishinaabe language. The man found some of his tribe’s maple-syrup-making tools in a cabinet at the Smithsonian and was so excited that when he returned home, he produced a series of videos about syrup making using phrases from his native tongue.

Young people in his community hear the language when they watch the videos, but they also encounter aspects of their cultural heritage. “This small thing of opening a cabinet turned into this journey,” Isaac says, “building the collective knowledge which is really at the base of language.”

When young people no longer speak a language, however, its prospects for survival might dwindle. Traditional societies around the world have suffered repeated traumas related to displacement, for example, when the U.S. government pushed Native American people onto reservations and forced their children to attend Western schools from the late-19th to the late-20th centuries. Indigenous peoples in Canada and Australia received similar treatment. These policies disrupt generational links and might lead to the death of established languages. Globally dominant languages, such as English, introduced from outside can also threaten the survival of less common languages over time.

And sadly, just because the linguistic community has only recently identified a language does not mean it’s invulnerable. Recently identified languages can disappear just as easily as those recognized for decades. Koro Aka, for instance, might already be at risk of slipping away, since there are few Koro Aka speakers under the age of 20. “A process of language shift is under way,” Harrison says. “Younger generations are using it only sporadically. It’s definitely in decline.” Even so, he reports, a small group of young Koro Aka speakers is putting up a valiant fight to save the language. Some even appeared on the National Mall in Washington, D.C., recently to share the Koro Aka language and culture with visitors from around the world.

The youthful Koro Aka speakers on the Mall might have grasped something many of us have not: the rewards of keeping a rare language alive even if a more common tongue would suffice. Languages are often considered to supply the very framework on which our thoughts coalesce—a framework that is completely distinct in each language and gives rise to distinctive modes of thinking and expression.

Over time, the structure of each newly discovered language grows to support a community’s history, folklore, and scientific innovations—a world unto itself that might be threatened if the language disappears. “People don’t fully appreciate the vast body of knowledge contained within any language,” Harrison says. “What does Koro Aka have to say that we never knew? These languages have a contribution to make.”

This post appears courtesy of Sapiens.



In 2014, as summer transitioned into fall, many of Riley Bove’s friends, colleagues, and family members came down with a particularly nasty cold. People were off sick from work, and kids were staying home from school, so when Bove’s 4-year-old son, Luca, developed some breathing problems, she wasn’t especially concerned. But a few days later, Luca’s symptoms took a strange turn. When he tried getting out of bed, his head flopped back down on his pillow. When he tried to grab a cup, his arm was weak.

Bove, a neurologist at the University of California at San Francisco, took Luca to a pediatrician, who dismissed the weakness as just another sign of his infection. But in the evening, when Luca failed to improve, Bove sent a video of his strained movements to a friend who works in pediatric immunology. The friend said the symptoms looked exactly like those of AFM.

AFM, or acute flaccid myelitis, is a rare, polio-like illness that affects about one in a million people, mostly young children. Luca’s story is typical: Patients get cold-like symptoms that, within a week or so, progress to paralysis. Some kids lose control of their limbs. Others, like Luca, became paralyzed from head to toe, needing a ventilator to breathe and a feeding tube to eat. The cause of these symptoms is still unclear, but a common virus known as EVD-68 remains the most likely suspect.

AFM isn’t new, but it rose to prominence (and gained its name) in 2014 when it afflicted 120 people in the United States—a record number. Doctors wondered whether that was a freak occurrence, but the condition came back in 2016, affecting 149 additional patients. And this year, it returned again, with 158 confirmed cases and more under investigation. The disease now seems to run on a biennial schedule, and although the third wave peaked in mid-fall, scientists, clinicians, and parents are anxiously looking ahead to a likely fourth surge in 2020.

Unlike many seasonal illnesses, which come, sicken, and leave without long-term consequences, AFM means lasting (if not lifelong) disability for those it touches. And that community grows with every new wave: A Facebook group for parents of children with AFM, which formed in January 2015, has swelled to more than 600 members.

“We dread late summer,” wrote Bove in a recent opinion piece, co-authored with two other parents of children with AFM. “We grieve those final days when our still-normal children climbed their last playground structures or took their last runs down the block or their last independent breaths. We relive the trauma of the hospitalization, when at night we kissed our brave children, not knowing whether they would awaken stable, intubated, or unable to ever walk again. In addition, we fear the coming wave of new bewildered parents.”

But Bove says that something was different this year. In 2014 and 2016, the affected families were still getting to grips with this strange and unfamiliar condition. “This year, when we saw many new parents join the Facebook group, it was like: Not this time!” she says. “It really galvanized the parent community to become more outspoken in their advocacy. They’ve plastered the news with stories.” In no small part because of their efforts, awareness of AFM has soared, including within the medical community. “We’re seeing a very appropriate amount of increased attention,” says Kevin Messacar, a pediatrician at Children’s Hospital Colorado.

That matters because AFM is still rare, and often misdiagnosed. Despite how dramatic the later symptoms can be, they still might be easily mistaken for other paralytic illnesses. When I spoke to Priya Duggal from the Johns Hopkins Bloomberg School of Public Health earlier this week, she had just heard from a family whose child might have been misdiagnosed with the autoimmune disorder Guillain-Barré syndrome. “They live in a rural area in a state that doesn’t see a lot of AFM cases,” she says. “They’d seen multiple neurologists, and no one had even suggested it. It was only because of a press story that they now think that their kid has AFM.”

Meanwhile, the earlier signs of AFM can be so innocuous that they’ve often been dismissed—as they were with Luca. “A lot of parents were told all kinds of things,” Bove says. “That it’s [in their children’s heads],  or that it’s because of their fever, or even that a dad had broken the kid’s arm!” Bove and her co-authors write in their op-ed that clinicians aren’t even checking to see whether children can raise all their limbs, let alone performing more complex medical scans.

“We’re trying to get across to clinicians that if you see a child with limb weakness, in the right season, do an MRI of their spine or a lumbar puncture, in consultation with a neurological specialist,” says Messacar.

Diagnostic delays have confounded the search for the disease’s cause. The Centers for Disease Control and Prevention hasn’t been able to detect the most probable culprit—EVD-68—in the bodily fluids of every patient. But, as I’ve reported before, that might be because doctors are collecting the wrong fluids, or because they’re collecting fluids too late, at a time when the consequences of infection linger but the virus itself has disappeared. If wary clinicians can collect a slew of tissue samples—spinal fluid, nasal swabs, stool, and more—when patients first arrive in their offices, rather than days or weeks later, it might become much easier to confirm what’s behind AFM.

Faster diagnoses would also be a huge boon to parents, many of whom have been bounced from one provider to another before their paralyzed children are properly diagnosed and treated. “We still don’t know if those delays were medically relevant,” says Bove, “but they were very relevant in terms of the parents’ trust in the system.”

That trust can also falter when it comes to decisions about treatments. Some families have faced a kind of weary resignation from their physicians: “Their kids have spinal injuries, and they’ll get back what they get back,” says Bove. But early and frequent rehabilitative therapies have, in some cases, made a big difference. Luca, for example, is back in school; he can run around with his friends, even though his arms and neck are still weak. Others haven’t been so lucky, and full recoveries are still uncommon. But Bove says that most children have made gains of some kind, and continue to do so over years. “The message should be one of cautious hope,” she says.

This year has also been a unifying one for scientists and clinicians who have dealt with AFM. In September, Carlos Pardo-Villamizar from the Johns Hopkins School of Medicine convened a working group of medical colleagues, and they now run weekly conference calls to discuss the disease. They’re putting plans in place for which tissue samples to collect, creating guidelines for treating patients, and readying clinical trials to work out which treatments work best. When the next wave hits in 2020, if not earlier, they’ll be ready.

The CDC has also convened an AFM task force with similar goals (and some of the same participants). To support the agency’s efforts, Kirsten Gillibrand, the Democratic senator from New York, has asked Congress to approve a substantial amount of emergency funding—just as it did for the Zika virus in 2017.

“No parent would say that AFM is more important than all the other conditions that children face,” says Bove. “Sickle cell and type 1 diabetes affect even more children. But the fear is that AFM could get bigger, which is why parents want more attention now. Before polio affected tens of thousands of kids, it affected hundreds.”



When, in 2016, the F/V Blue North ventured into the Bering Sea on her maiden voyage, onlookers in Dutch Harbor, Alaska, could have been forgiven for mistaking the sleek $40 million long-liner for a yacht. The Blue North is perhaps the country’s highest-tech fishing boat, outfitted with fuel-efficient engines, automated freezers, and cargo elevators. Its most radical feature, however, is its “stunner”—an electrified table that knocks cod unconscious with a direct current of about 35 volts.

On a typical long-lining boat, fish are hauled up over the side. Crew members impale each struggling cod with a gaffe, tear out the hook, and fling the creatures aside to bleed or suffocate. The Blue North’s lines, by contrast, emerge into a “moon pool,” an enclosed chamber that allows fishermen to control their catch rather than hurl it willy-nilly across the deck. Cod pass over the stun table within seconds of their arrival; only once a fish is insensate does a crew member remove the hook and deliver the fatal cut.

It’s easy to forget, while gazing down at your spicy tuna roll, that fishing is a brutal business. Commercial fishers suffocate halibut, bleed out salmon, and crush pollock in trawls. Since 1958, the federal Humane Methods of Slaughter Act has required that terrestrial livestock be rendered insensible to pain before death, but the law excludes fish. Now, however, one growing seafood company is beginning to consider the welfare of its catch—and, perhaps, fomenting a revolution in how we treat our finned brethren.

Commercial fishermen and recreational anglers—myself included—tend to justify our cruelty with comforting myths. Fish, according to conventional wisdom, are unfeeling loners with three-second memories and about as much interior life as kelp. That unkind stereotype, however, doesn’t withstand scientific scrutiny. Bluehead wrasse transmit culture across generations, groupers and eels cooperate, and cleaner fish appear to recognize themselves in mirrors. The axiom that fish don’t suffer pain—a claim based primarily on their lack of a cerebral cortex, the structure with which mammals process stimuli—is also belied by mounting evidence. In her 2010 book, Do Fish Feel Pain?, the Penn State biologist Victoria Braithwaite argued that “there is as much evidence that fish feel pain and suffer as there is for birds and mammals—and more than there is for human neonates and preterm babies.”

Such findings haven’t ended the fish-pain debate—indeed, it’s almost irresolvable, given that pain is a subjective experience as well as a physical response. Still, Mike Burns, the founder of the Seattle-based Blue North Fisheries, gives his slippery quarry the benefit of the doubt. “Maybe they don’t feel pain—although I believe they do—but they certainly undergo stress,” Burns told me. “Just look how a fish acts when you take it out of water.”

Burns arrived at his concern for piscine well-being via a roundabout route. In 1994, Mike and his brother, Patrick, purchased a ranch in eastern Oregon to supplement their small commercial-fishing business. As they boned up on the beef industry, they became acquainted with the work of Temple Grandin, the legendary Colorado State University animal scientist who revolutionized livestock treatment, developing, among other innovations, standards for pre-slaughter stunning and curved loading chutes to make cows’ final moments less stressful. The Burns brothers incorporated Grandin’s techniques on their ranch, then adapted her principles for fish when they designed the Blue North, their flagship.

“I think it’s a good approach,” Grandin told me. Rendering fish unconscious before slaughter, she says, is among the best steps fishermen can take to facilitate a humane death.

Although Grandin points out that inventors have filed dozens of patents for stunning devices, the Blue North is, so far as Burns knows, one of only two commercial boats in the world to use one. Fish welfare has progressed further in the aquaculture industry, particularly abroad. Some Canadian fish farms, for example, knock salmon out with a pneumatic hammer before slaughter. The U.S.-based Humane Farm Animal Care, which has developed humane labels for land-based livestock, is currently working on fish-farm protocols, although Mimi Stein, the nonprofit’s director, said they have yet to be implemented.

For wild-caught fish, market pressures might ultimately spur considerate killing; a survey released last fall suggested that half of American consumers are more likely to buy well-treated fish. At the moment, Burns said, Blue North’s “Humane Harvest” cod is sold at a handful of Seattle-area restaurants and markets, and, like organic produce, fetches a modest price premium. Still, real reform must come from seafood purveyors themselves, Grandin said. In 1999, McDonald’s, its public image singed by a legal battle with animal-rights activists, hired her to overhaul its slaughterhouses. “I saw more change [then] than I had in a 25-year career prior to that,” Grandin said. The fish-welfare revolution will have truly arrived when the Golden Arches and its ilk source their pollock sandwiches from boats that humanely kill their catch.

This post appears courtesy of High Country News.



Every so often, the American West seems to lurch into something called a “mega-drought.” The rains falter, the rivers wither, and the forests become tinder boxes waiting for a spark. Mega-droughts are notoriously hard to study—the last one happened in the 16th century—but what we do know is worrisome. In the 1540s, a few wet years in the middle of a mega-drought may have triggered one of the worst disease epidemics ever recorded.

According to research unveiled last week, mega-droughts may no longer be history. On Thursday, a team of climate scientists argued that the American West may currently be experiencing its first mega-drought in more than 500 years. A record-breaking period of aridity set in around the year 2000 and continues to this day, they said.

“The last 19 years have been equivalent to the worst 19 years of the worst mega-droughts on record,” said Park Williams, a professor of bioclimatology at Columbia University, at a presentation of the work. Only three recent mega-droughts—in the late 800s, the mid-1100s, and the late 1500s—were worse than the current period, he added.

Climate change seems to be driving a good chunk of the problem. “The current drought is substantially worse than it would have been without global warming,” Williams said. The drought was 62 percent more severe than it would have been, he said, due to human-caused climate change.*

Williams presented the results to a standing-room-only session at the American Geophysical Union’s fall meeting, the year’s largest planetary-science conference. The work has not yet been peer-reviewed. While it’s a common practice to share preliminary work at a scientific meeting, Williams didn’t comment directly for this article; academic norms discourage researchers from publicly discussing a study before its formal publication.

But other scientists told me that the work makes sense, saying it was “quite plausible” that the American Southwest is in a mega-drought right now. And no matter what, it’s clear that the region is in the middle of a far-reaching climatic transformation.

“The definition of mega-drought technically is open to debate,” said Jonathan Overpeck, a climate scientist at the University of Michigan. Two decades ago, he and the climate scientist Connie Woodhouse coined the term mega-drought in a paper, specifying that such a drought must last 20 years or more.

“The drought in the Southwest is now in its 19th year. So it’s right on the cusp of technically being a mega-drought,” Overpeck told me.

The current drought is “relentless,” he said, with consequences that reverberate across the West. “It’s reflected in the levels of Lake Mead and Lake Powell, the two largest reservoirs in our country … You see it in the way the forests are outright dying in some places, in big insect outbreaks as [plants] are weakened by a lack of moisture in the soil, in more catastrophic wildfires. There’s a lot of signs this drought is unusual.”

He said that two different events seem to be driving the crisis. First, the region is receiving less rain than normal. Second, the Southwest as a whole is systematically warming up and drying out. It’s becoming a more desertlike place, a process that scientists call aridification. “Most of the work points to aridification being dominant” in driving the modern drought, Overpeck said.

The new work from Williams and his colleagues may support the same idea. They began by looking at the climatic record preserved in tens of thousands of tree rings across the American West. By using a simple form of machine learning on that data and calibrating it to modern weather records they pieced together the past 1,200 years of soil moisture in the West. (Williams’s team includes Ed Cook, who practically invented the modern study of tree rings.)

Consulting this record, they found that the current drought does not perfectly resemble historic mega-droughts. While previous droughts were concentrated in just one or two places in the West, the current drought covers almost half of the country. Climate models suggest that this huge territorial extent may be caused by the extreme heat and dry air that’s plagued western states in the past few decades. “What may have just been a drought in the Southwest is now a drought across the entire study region,” Williams said at the conference.

Scientists have long suspected that aridification could cause problems across the West—mega-droughts included. Two years ago, a paper in Science Advances warned—with 99 percent certainty—that a southwestern mega-drought would occur by 2100 if greenhouse-gas emissions continued to balloon through the next several decades. In another paper, Williams and some of his same colleagues found that increased heat in the West has exploded the size of wildfires since the mid-1980s.

But Williams believes that climate change is not solely to blame. “The current drought would have been occurring anyway without global warming, but it would only have been the eighth- or ninth-worst on record,” he said. Instead, it’s the fourth-worst in the past 1,200 years.

Woodhouse, who coined the term mega-drought with Overpeck, told me that this effect may be the most important finding of the new paper. “The current 19-year period is different [from] 19-year periods in the past for the simple reason that it is occurring under warmer temperatures,” she said in an email. “In essence, a garden-variety drought (in terms of precipitation deficits) + warming = a much more severe drought.”

Overpeck agreed. “The warming is having a huge effect—a huge effect on water resources and a huge effect on forests,” he said. “People knew there would be an effect, but we didn’t know it would come this big, and this fast.” 

* This article previously misstated the amount by which human-caused climate change worsened the current drought.



In 1909, the Japanese scientist Kuniomi Ishimori collected spinal fluid from sleep-deprived dogs and injected it into active, rested pooches. Within hours, the latter fell into a deep sleep. By coincidence, a pair of French researchers did the same experiments a few years later and got the same results. These studies, and others like them, suggested that the blood of sleepy animals contains some kind of soporific secret sauce of chemicals. Ishimori called these “hypogenic substances.” Others labeled them “somnogens.”

The sources of these sleep-inducing chemicals have proved surprisingly elusive, and scientists have found only a few that fit the bill. Now Hirofumi Toda from the University of Pennsylvania has discovered another—a gene called nemuri that triggers sleep, at least in fruit flies. Unexpectedly, it also becomes active during infections and acts to kill incoming microbes. It seems to be part of a self-regulating system, analogous enough to an internal thermostat that we might call it a sleep-o-stat. It can send animals to sleep when they most need shut-eye, whether because they’re sick or because they just haven’t slept enough.

This sleep-o-stat works separately from the daily body clocks that make us feel more tired at night. And while the latter has been thoroughly scrutinized by scientists, the former is still largely mysterious. “What makes us sleepy when we’ve been awake for a long time?” asks Amita Sehgal, who led Toda’s project. “We still don’t really have answers to that.”

Toda began by looking for genes that, if switched on, would make flies sleepier. To that end, he worked with flies from 8,000 different strains that had each been engineered to activate a different gene when fed a triggering chemical. Toda placed these flies individually into tubes that were monitored with infrared beams. When awake and mobile, the insects regularly tripped the beams; when asleep and still, they did not. A computer monitored the entire captive swarm, recording their movements and noting any that were sleeping more than usual.

This monumental effort was successful—just. From 8,000 possible genes, Toda found only one that induced sleep. That was nemuri, which the team named after the Japanese word for sleep. It had never been thoroughly studied before. “When we first got it, we didn’t know what it was,” says Sehgal.

If flies are deprived of sleep, because the team was either regularly shaking their tubes or feeding them with caffeine, the nemuri gene becomes more active—but only in a single pair of neurons within the insects’ brains. When it whirs into action, it produces a protein (of the same name) that then acts on a fan-shaped part of the brain that’s known as a control center for sleep. If Toda switched nemuri on deliberately, flies slept 20 to 30 percent longer than normal peers. They slept more deeply, too: They were much less likely to wake up when their tubes were bumped, and the few that were roused were slow and sluggish.

“It’s very interesting work,” says Chiara Cirelli from the University of Wisconsin at Madison. She and others have identified genes in flies that are important for a good night’s rest and, when disabled, result in less sleep. But this is the first time anyone has done the reverse: increase the activity of a gene, and trigger more sleep. 

“Until this study was conducted, relatively few somnogens were known,” says Susan Harbison from the National Institutes of Health. “This study also suggests that few such molecules may exist.” After all, if Toda tested 8,000 genes and found just one hit ... maybe there aren’t that many hits to find?

But there must be at least a few more, because nemuri can’t be the whole story. If it’s responsible for sending tired flies to sleep, then disabling it should disrupt sleep, says Cheryl van Buskirk at California State University at Northridge. And it didn’t. When Toda used the gene-editing technique called CRISPR to deactivate the gene, flies still slept, and for the usual amount of time. They were much easier to wake and took longer to nod off again. But “since sleep and sleep rebound are both largely intact, nemuri isn’t likely a major component of the sleep homeostat,” Van Buskirk says.

Sehgal thinks nemuri is probably a bit player when it comes to daily sleep, but becomes very important during times of stress, sleep deprivation, and sickness. Indeed, her team showed that the Nemuri protein is an antimicrobial peptide, or AMP—one of several small molecules that, as their name suggests, kill microbes.

This ability is intertwined with nemuri’s effects on sleep. Like us, flies sleep more when they get infections. The team found that these bouts of sickness-induced bed rest were longer when they deliberately switched nemuri on, and shorter if they disabled the gene. “There is an intimate link between sleep and the immune system,” Sehgal says.

Read: Why some people respond to stress by falling asleep

A few of the other possible somnogens also moonlight as part of the immune system. “This may represent the tip of the iceberg,” adds Van Buskirk, in terms of substances with dual roles, “directly combatting [infections] and promoting sleep while the battle ensues.”

It may seem strange to devote all this effort to understanding sleepy flies, especially when nemuri doesn’t have an obvious human equivalent. But Sehgal notes that humans do produce more than 100 AMPs, which might play a similar role. And she notes that there’s a long history of sleep researchers making discoveries in flies that later turn out to be important in humans.

Twenty-five years ago, while working in the lab of Michael Young, Sehgal helped to show that a gene called “timeless” controls the daily body clocks of flies. There wasn’t an obvious human equivalent of that either, and Sehgal says some researchers were skeptical that the discovery had any relevance. But in time, a human version was discovered, and it’s involved in several important diseases. For this work and others, Young won a Nobel Prize in 2017. “We have been down this road before a couple of times,” Sehgal says.



Chrysippus, a Greek philosopher from the third century B.C., is said to have recounted how a hunting dog arrived at a spot where three roads met. The dog smelled the two roads by which the quarry had not passed, then without hesitation or any further sniffing set off on the third. According to the philosopher, the dog had drawn a logical conclusion, reasoning that if the quarry had not taken two of the roads, it must have taken the third.

Facing a fork in a maze, mice often hesitate for a few seconds before continuing. Recent studies suggest that in order to decide which way to go, a mouse has to project itself into the future. We know that rodents replay previous action sequences in their hippocampus, so the wavering mouse in the maze probably compares the memory of old routes with imagined future ones. In order to do so, it will have to be able to tell the difference between experienced and projected actions, which requires a primal sense of self.

At least this is what the scientists doing these experiments assume. I find this fascinating, because in this thought experiment, we postulate that humans would need a sense of self to make the same decision, which we then take as evidence for a sense of self in another organism. This extrapolation is generally satisfying, but not risk-free, because it hinges on the assumption that there is only one way to solve a problem.

Chrysippus’s dog is a great example of apparent inferential reasoning. Fortunately, we now have tests of inferential reasoning. In the 1990s, the psychologists David and Ann Premack presented their chimpanzee, Sarah, with two boxes, putting an apple in one and a banana in the other. After a few minutes, Sarah would watch one of the experimenters munch on either an apple or a banana. This experimenter then left the room, and Sarah was given a chance to inspect the boxes.

She faced an interesting dilemma, since she had not seen how the experimenter had obtained his fruit. Invariably, however, she would go to the box with the fruit that the experimenter had not eaten. She must have concluded that the experimenter had taken his fruit from the corresponding box and that the second box would still contain its original fruit. Most animals don’t make any such assumptions, the Premacks note; they just see an experimenter consume fruit. Chimpanzees, by contrast, always try to figure out the order of events, looking for logic, filling in the blanks.

In another test, apes were presented with two covered cups after they had learned that only one would be baited with grapes. Both cups were covered and shaken. As expected, the apes preferred the cup in which they could hear the grapes make noise. But then the experimenter shook just the empty cup, which obviously made no sound. The apes picked the other cup.

I once watched another such causal inference unfold at the Burgers’ Zoo when the chimpanzees in the indoor colony watched us carry a crate full of grapefruit, which they find delicious, through a door that went outside onto their island. They seemed interested enough. But when we returned to the building with an empty crate, pandemonium broke out. As soon as they saw that the fruit was gone, 25 apes burst out hooting and hollering in a most festive mood.

Animal consciousness is hard to investigate, but we are getting close by exploring examples of reasoning, such as those given above, that we humans cannot perform unconsciously. We cannot plan a party without consciously thinking about all the things we need; the same must apply when animals plan for the future. The latest neuroscience suggests that consciousness is an adaptive capacity that allows us both to imagine the future and to connect the dots between past events. We are said to have a “workspace” in the brain where we consciously store one event until another one comes along.

Take, for example, taste aversion in rats. It is well known that rats avoid certain toxic foods, even if they don’t become nauseous until hours later. Simple association fails to explain this. Could it be that rats consciously go over the recent past in their minds, thinking back to every food encounter to determine which one was most likely to have made them sick? We certainly do so ourselves after food poisoning and gag at the mere thought of the particular food or restaurant that we believe caused a shock to our digestive system.

The possibility that rats have a mental workspace where they review their own memories is not so farfetched, given the growing evidence that they can “replay” memories of past events in their brain. This kind of memory, known as episodic memory, is different from associative learning, as when a dog learns that by responding to the command “sit,” he will be rewarded with a cookie. To create the association, the trainer has to give the dog the reward right away—an interval of even just a few minutes is not going to be helpful. In contrast to this kind of learning, episodic memory is the capacity to think back to a specific event, sometimes long ago, the way we do when we think of, say, our wedding day. We remember our clothes, the weather, the tears, who danced with whom, and which uncle ended up under the table.

Episodic memory must be at work for the wild chimpanzees that forage among the fruit-bearing trees of Taï National Park, in the Ivory Coast. The Dutch primatologist Karline Janmaat has described how the chimps build their night nests en route to such trees and get up before dawn, something they normally hate to do because of the danger of meeting a leopard. Despite their deep-seated fear, the apes would set out on a long trek to a specific fig tree where they had recently eaten. Their goal was to beat the early fig rush by other animals, from squirrels to hornbills. Remarkably, the chimps would get up earlier for trees far from their nests than for those nearby, arriving at about the same time at both. This suggests calculation of travel time based on distance. All this makes Janmaat believe that Taï chimpanzees actively recall previous experiences in order to plan for a plentiful breakfast.

In a classical experiment, Nicky Clayton at Cambridge University studied western scrub jays (a corvid) to see what they remembered about foods they’d cached. The birds were given different items to hide, some perishable (wax worms), others durable (peanuts). Four hours later, the jays looked for the worms—their favorite food—before they looked for the nuts, but five days later their response was reversed. They didn’t even bother to look for the worms, which by that time would have spoiled and become disgusting. But they did remember the peanut locations after this long time.

We also have studies of metacognition, which refers to the knowing of knowing. Let’s say someone asks me whether I’d rather answer a question about 1970s pop stars or about science-fiction movies. I’d right away pick the first category, because that’s what I’m better at. I know what I know. These kinds of experiments have been conducted with animals (including monkeys, apes, birds, dolphins, and rats), showing that they, too, have different levels of confidence about what they know. They perform some tasks without hesitation, but at other times they can’t make up their mind, exhibiting doubt.

In one early study, a dolphin named Natua was asked to discriminate between a high tone and a low tone. His level of confidence was quite manifest. He swam at different speeds toward the response, depending on how easy or hard it was to tell the tones apart. When they were quite distinct, Natua swam at full speed with a bow wave that threatened to soak the electronic apparatus. The scientists had to cover it with plastic sheets. If the tones were similar, though, Natua slowed down, waggled his head, and wavered. Instead of touching one of the paddles to make his choice, he selected the opt-out paddle (asking for a new trial), which meant he knew that he’d probably flunk the task.

Even if this and other studies fail to directly tell us how aware animals are of their own memories, it is hard to deny the possibility that animals consciously travel along the time dimension and rack their brains for knowledge and experiences. We now have the beginnings of an idea of what consciousness is good for and why it evolved. I suspect that animals capable of consciously probing their experiences and memories also have the capacity to explicitly recognize the bodily upheavals that we call emotions. If they’re going to make decisions based on memories of the past, it probably helps to realize how those experiences made them feel.

This post is adapted from De Waal’s new book, Mama’s Last Hug: Animal Emotions and What They Tell Us About Ourselves.



For Tim Caro, it was surprisingly easy to dress horses like zebras. Several vendors were already selling coats with black-and-white stripes, often as fun gimmicks. But, as Caro learned, such coverings have an unexpectedly serious effect. “There are enormous benefits to having a striped coat for a horse,” he told me.  

Caro, a biologist at the University of California at Davis, has spent years thinking about why zebras are striped, and has even written a book about this mystery. In his latest bid to get clear answers, he and his colleagues traveled to Hill Livery, a stable in southwest England that keeps several captive zebras alongside domestic horses. By comparing these two species, as well as horses that were comically cloaked in zebra-striped coats, the team found fresh evidence for what Caro thinks is the only plausible explanation for the striking stripes: They evolved to deter bloodsucking flies.

Scientists have been puzzling over the role of zebra stripes for more than 150 years. But, one by one, the most commonly proposed explanations have all been refuted. Some researchers have suggested that the stripes act as camouflage—they break up zebras’ outlines or resemble fields of tree trunks. But that can’t be true: Amanda Melin of the University of Calgary recently showed that lions and hyenas can’t even make out the stripes unless they get very close. Another hypothesis says that the black stripes heat up faster than the white ones, setting up circulating air currents that cool the zebras. But a recent study showed that water drums cloaked in zebra pelts heat up just as much as those covered in normal horse skins.

That leaves the fly idea. When it comes to biting insects, zebras are doubly cursed. For one, they’re highly susceptible to a variety of fatal diseases, including trypanosomiasis, African horse sickness, and equine influenza, that are spread by horseflies and tsetse flies. They’re also very vulnerable to insect attacks: Compared with other grazers such as antelopes, the hairs on their coat are unusually short, allowing flies to more easily find blood vessels with their piercing mouthparts.

Stripes, for some reason, seem to help. In 2014, Caro and his colleagues showed that striped horses—three zebra species and the African wild ass with thin stripes on its legs—tend to live in regions with lots of horseflies. And several researchers, over the years, have shown that these flies find it hard to land on striped surfaces. No one, however, had watched the insects trying to bite actual zebras. That’s why Caro’s team went to Hill Livery.

By watching and filming the stable’s horses and zebras, the team confirmed that horseflies were much worse at alighting on the latter. The flies had no problem finding the zebras or approaching them, but couldn’t stick the landing. “You get a quarter as many landings,” Caro said. “The flies just can’t probe for a blood meal with the zebras.”

The team found the same trend when they put striped coats on the horses. Cloaked in stripes, the very same animals suddenly became more resistant to flies, except on their uncovered heads. And uniformly colored coats had no effect; the stripes, specifically, befuddled the flies.

“When we looked at the videos, we found that the flies simply aren’t decelerating when they come in to the stripes,” Caro said. Either they miss and overshoot the zebras, or they bump into the hides and bounce off. Something’s clearly throwing them off, but the details are still a mystery. Caro said that they might treat the black stripes like a pair of trees, try to fly between them, and end up colliding with the white stripes. Alternatively, the stripes might mess with their optic flow—their sense of objects moving across their visual field.

Paloma Gonzalez-Bellido of the University of Minnesota, who studies insect vision, favors the latter idea. These insects use optic flow to gauge their own speed and their distance from nearby objects. “I think that the key is that the stripes’ thickness and orientation is not consistent, either within a stripe or across them,” she says. “This is probably what makes it difficult for the flies to control their landing.” (She also notes that cuttlefish use their color-changing skins to create striped patterns that move across their bodies, and these “passing clouds” might also work by disrupting the optic flow of their prey.)

If Gonzalez-Bellido is right, a more evenly striped coat should offer less protection. Caro’s team is now planning to test this hypothesis, and others. “Now that we know striped coats work just as well as stripes on real zebras, we can really play around with them,” he said. “We can put on coats with very wide stripes, or different orientations, or gray stripes. We can see how those affect fly behavior.”

In the meantime, he is wary of making firm recommendations to the equine industry. “I wouldn’t want to suggest that horse-wear companies sell striped livery for their riders yet,” he said. “We need to do the work first.”

More important, I ask him, Would a striped shirt protect me from biting flies? “I’ve been very cautious about saying that until we got these results, but now I’m not so sure,” he said. “I think that a striped T-shirt might work very nicely.”



Almost seven months have passed since the November day when a few hundred young people, associated with a new climate-activism group called the Sunrise Movement, crammed into Nancy Pelosi’s office. America’s youngest congresswoman-elect ever joined them. “This is not about me,” said Alexandria Ocasio-Cortez, who was effectively leading a protest on her first day on Capitol Hill. “This is about uplifting the voice and the message of the fact that we need a Green New Deal.”

Ocasio-Cortez is still a star. Presidential candidates are courting the Sunrise Movement’s favor. And the Green New Deal has transformed the climate fight both in the United States and around the world. 

Yet it remains unclear what would actually be in a Green New Deal. While a handful of candidates have released their own attempts at a Green New Deal, the tight network of progressives most closely linked to the plan have offered little new detail. In particular, the think tank known as New Consensus—ostensibly in charge of turning the Green New Deal into real policy—has published almost nothing substantial about it.

“I think they’ve done a pretty good job of compiling the scope, the scale, and the goals of the Green New Deal,” Corbin Trent, a spokesman for Ocasio-Cortez, told me. “I think we’re still in the process of getting people to imagine what we’re talking about.” But in the current informational vacuum, the plan’s supporters have sometimes faltered, allowing pundits, lobbyists, and other politicians to rush in and define the Green New Deal’s terms. “One reasonable summary of what has happened is that everybody except the people who say they are doing the Green New Deal are doing the Green New Deal,” said an activist who asked not to be named to avoid damaging relationships with New Consensus.

New Consensus aims to be the policy quarterback for the Green New Deal. It wants to combine ideas from dozens of fields—including economics, sociology, ecology, and climate science—to write a new, all-encompassing domestic agenda. It promotes industrial policy, a school of thought that says a country should invest public dollars in its high-tech manufacturing capacity to flourish. (Elizabeth Warren, who has proposed something similar, calls this idea “economic patriotism.”)

But for a quarterback, New Consensus is inexperienced on the field. Founded last fall, its only public work to date consists of an industrial-policy reading list and a 14-page white paper that briefly elaborates on a congressional Green New Deal resolution championed by Ocasio-Cortez.

That white paper was published on February 9, two days after the resolution itself. It says that the Green New Deal will eventually consist of “specific projects” that will come together into one “coherent whole,” but it does not name the projects or say what they will do.

“Don’t worry,” read New Consensus’s Twitter account on the day the white paper was published. “Policy deets are coming!”

Four months later, policy details have yet to arrive. New Consensus now aims to have a playbook for the Green New Deal described “at an appropriate level of detail” in January 2020, according to Demond Drummer, its executive director.

Why are policy specifics important? For now, the most detailed form of the Green New Deal can be found in the February resolution. Released by Ocasio-Cortez and Senator Edward Markey, it sticks to broad goals. It says that the United States must repair its infrastructure, upgrade all its existing buildings to be energy efficient, and generate 100 percent of its electricity through clean or renewable sources. But it never says how to get there. In interviews, Ocasio-Cortez has seemed open to a range of approaches. “It’s not as though the federal government’s going to wave a wand and say, ‘We’re going to do it all ourselves,’” she told Chuck Todd in February.“It could be Tennessee Valley Authority–style public programs, but it could also be public-private partnerships. It can work down on a municipal level. There could be some potential contracting involved.”

That level of detail is supposed to be New Consensus’s job. While New Consensus and Ocasio-Cortez have no formal relationship, the think tank sprang from the same cadre of left-wing activists (and alums of Bernie Sanders’s 2016 campaign) who initially launched Ocasio-Cortez herself.

“I don’t want to say that we’re deeply coordinating with Alexandria Ocasio-Cortez, because”—as a tax-exempt 501(c)(3) nonprofit—“we can’t,” Drummer says. But Ocasio-Cortez’s chief of staff has identified New Consensus as a direct inspiration for their work, and the Sunrise Movement has invited New Consensus employees to speak at its events.

“It’s like any other think tank. They do briefings and that sort of thing,” said Trent, the spokesman for Ocasio-Cortez. He described the division of labor among the Green New Deal’s allies: The Justice Democrats PAC works on electoral strategy, the Sunrise Movement leads the youth campaign, New Consensus “[creates] some space in the think-tank world,” and Ocasio-Cortez herself works on the inside in Congress.

These groups have a claim on the “real” Green New Deal in a way that others don’t. That has sometimes led to tense interactions with the already-existing climate and environmental movements. None of the five people who work at New Consensus have worked extensively on energy or environmental policy before. Drummer was a community organizer in Chicago, where he worked on land-use policy and founded a program to teach high schoolers on the South Side how to code. Rhiana Gunn-Wright, a Rhodes Scholar who now leads the think tank’s Green New Deal effort, was previously policy director for Abdul El-Sayed’s 2018 progressive gubernatorial campaign in Michigan.

Many of the difficulties came to a head in March, when New Consensus held an initial meeting on the Green New Deal. Its leaders invited more than 80 participants, including legal scholars and environmental-justice activists, to the trendy Line Hotel in Washington, D.C.’s Adams Morgan neighborhood.

As Drummer understood it, the meeting was a “research-planning meeting,” a getting-to-know-you with the field. New Consensus had four big questions for people already working on climate policy, Drummer told me: “What are the questions we should be asking? What are the debates we should be aware of? Who are the people we should be talking to? … And also, what are your thoughts on how we as an organization can get this done?”

The invite list, he said, “was a sampling” of groups who might ultimately advise New Consensus. But in the delicate world of environmental politics—where coalitions are carefully managed and the most technical phrases can carry huge rhetorical weight—news of the meeting reverberated. It seemed as if Ocasio-Cortez’s favorite think tank was developing the official Green New Deal. It mattered who was invited and who wasn’t. Many activists still say that the 2009 climate bill failed in part because legislators ignored the environmental-justice movement while drafting it.

The meeting was bumpy from the first hour, when two environmental-justice activists interrupted proceedings to protest the absence of the Climate Justice Alliance, a national network of urban, rural, and indigenous groups. The alliance had been asked to endorse the Green New Deal, but it had not been asked to help write it, the activists charged.

There were other odd gaps, too. Todd Vachon, a labor-studies researcher at Rutgers University who attended the meeting, told me he was surprised that no union officials were present. “We were kind of there, looking around and saying, Where are the labor people?” he said. “There weren’t really any active presidents of unions—people who have the authority to speak on behalf of an organization. It was academics and researchers on one side, and grassroots organizations on the other.” Other participants told me they were surprised at the broad lack of climate-policy knowledge among the assembled.

Angela Adrar, the executive director of the Climate Justice Alliance, told me her group is now communicating with New Consensus. But one of the major demands the environmental-justice activists raised at the meeting has gone publicly unanswered. They asked a simple question: Who’s funding New Consensus? Months later, Drummer still has said nothing about the group’s financial backers and, in a recent conversation, declined to tell me who funds his think tank.

The March meeting wasn’t the only time that Green New Deal advocates have unknowingly stumbled into divisive fights in the climate movement.

This past winter, both during the protest at Pelosi’s office and in a much-discussed letter co-signed by Friends of the Earth, Ocasio-Cortez and the Sunrise Movement said the U.S. electricity grid should be powered by 100 percent renewable energy. But this turned out to be a more divisive claim than some realized—it was one of those technical-sounding phrases with a controversial history. Many energy experts, even those desperate to fight climate change through policy, believe that an all-renewable grid would be prohibitively expensive and subject the United States to rolling brownouts. Instead, they propose a 100 percent clean-energy requirement, which could include nuclear power and other technologies.

The final Green New Deal resolution says the country should aim for 100 percent “clean, renewable, and zero-emission energy sources,” a stress-tested phrase in which the meaning of and is left carefully ambiguous.

Another fight concerns carbon-capture technology. Environmental-justice groups are skeptical of the still-notional technology that could suck carbon dioxide directly from smokestacks or the ambient air. Approving carbon-capture technology is akin to acceding to another 20 years of toxic pollution in poor communities, Adrar told me. They want to remove carbon from the atmosphere through lower-tech means, such as by planting more trees.

Unions tend to endorse the need for carbon capture, in part because it could preserve some fossil-fuel jobs for longer. And the scientific community leans to their side: In its report last year, the Intergovernmental Panel on Climate Change warned that “negative-emissions technologies,” including atmospheric-carbon removal, must be deployed on a massive scale to keep the Earth’s temperature from rising more than 1.5 degrees Celsius.

At first, the Green New Deal seemed to endorse carbon capture. In November, an early version of Ocasio-Cortez’s resolution called for “massive investment in the drawdown and capture of greenhouse gases.” A month later, that phrase was edited to reference only the “drawdown of greenhouse gases.”

By the final version in February, the snub was explicit: It demanded that carbon dioxide should be reduced “through proven low-tech solutions … such as land preservation and afforestation.”

Yet despite this haggling over policy, the Green New Deal has triumphed politically. The Service Employees International Union backed the plan last week, joining earlier endorsements by the flight attendants’ and communication workers’ unions. And the Sunrise Movement has emerged as a powerful force within the Democratic coalition. Last month, it ended a nationwide tour in support of the Green New Deal with a three-hour, 1,200-person rally at Howard University in Washington. Markey, Ocasio-Cortez, Sanders, and Gunn-Wright of New Consensus all spoke. Sunrise now plans to hold another major rally in July at the Democratic primary debate in Detroit.

Much of that excitement around the Green New Deal tracks back to Sunrise’s activism—and Ocasio-Cortez’s initial endorsement. So it’s notable that the Sunrise Movement adopted the idea of a Green New Deal because of one well-timed conversation. Only a few days before the group was to occupy Pelosi’s office, as it hammered out the particulars of the protest with Ocasio-Cortez, a few members of Sunrise’s leadership had a conversation with Drummer. It finalized their commitment to the Green New Deal.

“We were considering various focuses within the frame of the Green New Deal, and it crystallized through conversations with New Consensus and others in the days leading up to the action,” said Varshini Prakash, the executive director of the Sunrise Movement, in a statement. (That said, Sunrise endorsed candidates who backed a Green New Deal as early as last June.)

Since then, a handful of presidential candidates—including Joe Biden and Elizabeth Warren—have called for more than $1 trillion in climate investment. But with so little specificity, it’s hard to say how these proposals actually resemble what Sunrise, Ocasio-Cortez, and New Consensus have in mind.

Since February, Ocasio-Cortez has offered relatively few new details about the idea. She has narrated a video describing what the world will look like after the Green New Deal and spoken at Sunrise events. Last week, she told a reporter for The Hill that a Green New Deal must cost at least $10 trillion to be effective. “It’s just the fact of the scenario,” she said. Corbin Trent, Ocasio-Cortez’s spokesman, told me that if the United States spent as much fighting climate change today as it did at the peak of World War II—when federal spending came to 40 percent of U.S. GDP—then a Green New Deal could cost as much as $8 trillion per year. “None of [the candidates] have quite got there yet,” he said.

Meanwhile, New Consensus is dreaming bigger even as it plans the next six months of research. Drummer ultimately conceives of the Green New Deal as far more than a climate policy. It is a governing domestic agenda, he said, a chance to “see the elephant whole.”

Yet it’s still climate policy. And climate policy is hard. Paul Getsos, the national director of the Peoples Climate Movement, told me that it took his coalition eight months to write a consensus policy platform in 2017.

So for now, New Consensus is confident in its deliberate pace. “We’ve spent our time organizing and planning our approach,” Drummer told me. “The Green New Deal is an enormous proposal of epic scale. We are new to the space, and we’re well aware of that, and we’re building an army of expertise,” he said. “We could rush this and do it poorly, or we can be intentional.”



Although coral reefs are home to bustling communities of gaudy marine life, half the fishes that live there are hardly ever seen. Aptly known as cryptobenthics—literally “hidden bottom-dwellers”—these species are mostly shorter than two inches and usually hidden in crevices. If you snorkel past, they’ll scurry away. But Simon Brandl of Simon Fraser University has made a career of studying them. And he and his team have now shown that cryptobenthics are a crucial component of healthy reefs because they, more so than other fish, are extremely good at dying.

Pretty much every predator on the reef eats cryptobenthics, and a full 70 percent of these tiny morsels are devoured every week. But since they also reproduce, hatch, and grow at equally phenomenal rates, new individuals are constantly replenishing the ones that are consumed. Entire generations can turn over in a matter of weeks. And this extreme life cycle, Brandl found, is the secret engine of the world’s coral reefs, fueling the food webs that allow their inhabitants to flourish in otherwise nutrient-poor waters.

Large, colorful fish such as groupers, wrasses, and parrotfish “are what people focus on because they’re the ones you see when you’re diving,” says Julia Baum, a coral researcher at the University of Victoria. “But I love it when a study like this comes out of the blue and says that maybe these tiny fish might be the ones that are fueling everything else on the reef. That’s very cool.”

Seventeen families of fish count as cryptobenthics, but aside from seahorses (and perhaps gobies), most are obscure. Blennies, dottybacks, clingfishes, and dragonets—they’d be household names if only they were a little bigger, Brandl thinks. “I suspect that if we were to blow them up to 20 times their size, we’d consider some of them to be the most beautiful fish on the reef,” he says.

The small size of these fish also limits how many eggs they can produce, “which means they have to be extremely religious about making sure those actually hatch,” Brandl says. Some incubate their eggs in their mouths, forgoing meals until the larvae break out. Seahorse males lug around their eggs in breeding pouches. Sandgazers carry around a ball of eggs under their pectoral fins—a behavior called “armpit breeding.” These tactics mean that cryptobenthics are far better than other fish at converting eggs into larvae. When researchers count the baby fish in the waters near a reef, about 70 percent will be cryptobenthics.

For most of these larvae, life will be brief—even if they escape the jaws of predators. The pygmy goby, for example, crams its entire existence into just two months—the shortest life span of any backboned animal. Much of that time is spent as a larva, which quickly quintuples in size into an inch-long adult that lasts for just a few weeks. Living fast and dying young: That’s the cryptobenthic way. “They’ve broken with the fundamental rule of being a vertebrate, which is that you spend most of your time as an adult,” says Brandl. “They’re almost getting into mayfly territory.”

All of this explains why standard surveys fail to capture how important these fish are. Ecologists typically study reef animals by measuring their “standing biomass”—that is, they grab all the adults in an area and weigh them. By this measure, cryptobenthics seem unimportant: Though there are plenty of them, they barely shift the scales, even together. But that metric is profoundly misleading, because it ignores just how many cryptobenthics are eaten, and how often they’re eaten.

By simulating the lives of these fishes, Brandl found that their generations tick by so quickly, and they’re so frequently preyed upon, that every individual is replaced seven times a year. That’s a huge mass of fish that we rarely ever notice, because it’s eaten almost as quickly as it is generated. Weigh the survivors at any one moment, and you’ll be unimpressed. But estimate the total mass of the dead, as Brandl and his team did, and you’ll find that cryptobenthics account for 60 percent of the fish flesh that is eaten on a reef. Abundant, calorific, and rapidly produced, “they’re the fast food of coral reefs,” says Gabby Ahmadia, who has studied cryptobenthics and is now a director of marine-conservation science at the WWF.

The hidden influence of cryptobenthics might explain a long-standing puzzle called Darwin’s paradox. Simply put, “corals need clear, tropical waters to survive, but those waters are usually poor in nutrients,” explains Luiz Rocha of the California Academy of Sciences. So how can such watery deserts support such heaving communities?

One possibility: Seabirds could import nutrients by feeding in faraway waters and then dropping guano on the reefs. (A recent study supported this idea by showing that when invasive rats kill island seabirds, the surrounding reefs also suffer.) Cryptobenthics could fulfill a similar role. As larvae, they feed in richer offshore waters before moving back to the reefs once they mature. All the energy locked in their bodies “gets transferred to the reef when they die as adults or are eaten,” says Rocha. They’re like a massive, invisible conveyor belt, channeling nutrients into the shallows.

For this conveyor belt to work, cryptobenthics have had to break yet another rule of marine life. The larvae of most reef fish spread over long distances by riding ocean currents, but those of cryptobenthics “don’t really go anywhere,” Brandl says. They stay within a few hundred meters of the reefs where they were born, and eventually swim home to fill the empty spots that the former generation has vacated.

This lack of wanderlust has shaped their evolution. Populations can become easily isolated from one another, so existing species are quick to split into new ones. But since those species are typically confined to a narrow geographical range, they’re also prone to extinction. What will happen to them in the future, as coral reefs are pummeled by heat waves, acidifying water, and increasing tropical storms? Ahmadia says that based on previous studies, they’re actually pretty resilient. “Cryptobenthic fish are more likely to withstand reef degradation and may play a role in the recovery of coral-reef systems,” she says.

Repeatedly, we see that the limits of our senses limit our understanding of nature. We neglect what we cannot see, whether cryptobenthic fish or the microbes that grow on corals. “I work on cryptic invertebrates, which have been ignored for the same reasons,” says Nancy Knowlton of the Smithsonian National Museum of Natural History. “If you go to a reef and break off a head of dead coral, it’ll be full of little hiding crabs, shrimps, and snails. But unless you really make an effort to find these things, they’re hard to study.”



The cane-toad invasion of Palm Beach Gardens, Florida, began, according to one resident, with a few toads in her pool last Thursday. “We weren’t sure what they were, so we removed them,” she told The Palm Beach Post. “Friday morning, it was like a mass exodus of toads. Baby toads.”

In photographs, tiny amphibian bodies swarmed a swimming pool, clambered up walls, and carpeted a hallway—countless toads so numerous and overwhelming that the residents of Palm Beach Gardens needed to call in help.

OUTBREAK OF TOADS 🐸An bizarre infestation is leaving a Palm Beach Gardens community concerned @HughesWPTV https://t.co/bo4064yxdO pic.twitter.com/4RYY4rHhxe

In the spring, with toad-breeding season under way, Jeannine Tilford starts getting calls to her pest-removal company, Toad Busters. Cane toads, also known as bufo toads, are yet another invasive species that has found a hospitable home in balmy southern Florida. Deliberately introduced from South and Central America in the 1930s, they were supposed to control beetles damaging the sugarcane crop—that’s how they got the name “cane toads.” Escaped pets likely helped establish the current population. When we talked on Tuesday morning, Tilford was getting ready to catch toads in the overrun Palm Beach Gardens neighborhood later that night.

[ Read: Florida’s dragon problem ]

The specific problem, she diagnosed, was an undisturbed lake in the neighborhood. With nothing to bother the toad eggs and tadpoles, nearly all of them had metamorphosed into toads, suddenly hopping en masse into yards and pools.

Cane toads can pose a particular danger because the adult ones shoot toxin from their back when attacked. The tiny, just-metamorphosed toads don’t carry enough toxin to be deadly yet, but big adult ones can easily send a dog into a seizure or even kill it. The toxin is “very viscous and would stick inside the dog’s mouth,” says Steve Johnson, a wildlife ecologist at the University of Florida. Owners should try to wipe out an affected dog’s mouth and immediately take it to the vet.

(Nevertheless, there are reports of brave or foolhardy dogs licking cane toads to get a brief high. Multiple cane-toad experts told me, sternly, that this is not recommended for humans.)

Tilford started Toad Busters in 2017 to supplement her income as a high-school science teacher. Her most memorable job was on a property near Miami. The woman who lived there had nine cats, which she fed by dumping almost a bag of cat food every night. Cane toads normally eat bugs, but they are happy to eat pet food, too. The toads were so fat, Tilford said, “they couldn’t even jump.” She ended up catching more than 130 by hand.

Tilford takes some of the toads she removes to her toad dealer, because, it turns out, there is a demand for the creatures. The toads can end up in research labs, on biology-class dissection tables, or as pets in Europe, where it’s generally too cold for the toads to survive in the wild. The rest, about 30 percent, she estimates, have to be humanely euthanized according to American Veterinary Medical Association guidelines—first anesthetized with a benzocaine spray and then put in a freezer. (Here are step-by-step instructions, for anyone looking to deal with cane toads on their own.) “I really hate killing anything,” Tilford said, “but it’s illegal to release them because all I’ll be doing is spreading more of the invasive species.”

Cane toads have adapted beautifully to the Florida suburbs, so a lot of Tilford’s work also involves getting people to rethink their suburban backyard. No more cat food, for example. Pet poop can also attract insects, which can in turn attract toads. As do lights. And toads love to breed in ornamental pools of water, such as the lake in the affected Palm Beach Garden neighborhood. For “these larger communities that want to build these beautiful ponds and want to have houses on ponds,”Tilford said, “this is almost a pest-control service.” The cane toads aren’t going away, but they can be managed like mosquitoes or rats.

Dealing with toads amounts to a nuisance in Florida, but they can also create more dramatic problems. In Australia—where they were also deliberately introduced in the 1930s to protect sugarcane—they are a genuine scourge.

The issue is that Australia has no native toad species, so none of the predators knew to avoid the toxic toads. As the cane toads advanced east to west across the continent, “they left a wake of dead animals in their paths,” says Sean Doody, an ecologist at the University of South Florida at St. Petersburg who has studied cane toads in Australia. Turtles, lizards, and crocodiles just started dying out, which was good news for their prey. “If you were a small species that was previously being eaten, suddenly you’re on a honeymoon,” says Rick Shine, a biologist at Macquarie University in Sydney, Australia, who has also studied the impact of cane toads on Australian wildlife.

The ecological impact isn’t quite so dramatic in Florida, which has plenty of native toads. (As Shine puts it, “Cane toads are just bigger and uglier than local toads.”) They simply have to be dealt with: Last night, Toad Busters’ three-person crew spent three hours picking up hundreds of baby toads in Palm Beach Gardens. Tilford has also noticed native species, such as green tree frogs, starting to come back to areas where she’s removed cane toads. And the humans, of course, are happier too. 



The official suitor bios of The Bachelorette, whose 15th season premieres Monday night, are studied attempts at masculine posturing: Chasen became a pilot to impress the ladies. Garrett once snuck into a football stadium to make out with his girlfriend. Connor’s grandmother (but not Connor himself!) says he deserves a “sexy lady” to give her grandkids.

So what should viewers make of Matteo, 25, a management consultant from Atlanta, who says he has fathered 114 children as a sperm donor? If true, the claim—or is it a boast? or an admission?—is startling, a fact The Bachelorette’s producers were surely aware of when they released the contestant bios ahead of the season premiere. As once-secret sperm donations have become discussed more openly, DNA tests and online registries have also revealed cases in which single donors have produced 50, 100, even 189 biological children. These stories provoke an obvious question: How many children is too many for a single donor?

The U.S. has never considered this issue a necessary one to regulate. While countries such as the U.K., Germany, and the Netherlands limit how many children a single donor can have, the U.S. only has voluntary guidelines from the American Society for Reproductive Medicine, a professional group for fertility specialists. “It’s concerning to have single donors used too much,” says ASRM’s president, Peter Schlegel, adding that more than 100 times is indeed too many. ASRM guidelines suggest no more than 25 births per sperm donor in a population of 800,000 people, to prevent accidental incest. Several prominent sperm banks, which ship material all over the country and even the world, have set their own limits now—sometimes, only in response to news reports uncovering large sibling groups.

The limits—voluntary, self-imposed—come up against an even more basic problem: No one knows exactly how many donor-conceived children are even born in the U.S. every year. A woman might buy sperm from a bank, get inseminated at her fertility clinic, and then have her baby with her ob-gyn. The sperm bank relies on customers to report back, but it has no way of compelling them to do so. Anecdotally, at least, parents and kids curious about their donors have found these records fairly incomplete.

“You really can’t do anything until you have accurate records,” says Wendy Kramer, the founder of the Donor Sibling Registry, a website that connects donors and donor-conceived people. In 2017, Kramer submitted a citizen petition asking the Food and Drug Administration to regulate sperm donation, including the number of offspring per donor. The agency declined, saying those matters were outside its scope.

Given the lack of official records, it’s unclear exactly how Matteo knows that he has 114 biological children. He is only 25, so any biological children would be too young to take DNA tests on their own. He does not appear to be on the Donor Sibling Registry either, according to Kramer. ABC, which airs The Bachelorette, declined to clarify when asked for comment. And yet, given what is known about the sperm-donation industry, 114 is certainly within the realm of possibility.

Cynthia Daily used a sperm donor to conceive her son in the 2000s, and she now runs a private Facebook group for his half siblings and their families. The total number of children from that donor is, so far, 189. The group has been fairly healthy, but Daily pointed to examples of other donors who have passed on genetic conditions. “What if you have a donor who’s passing on something they don’t test for? Or it’s a later-in-life potential issue?” Daily asks. “We don’t have any clue what happened in his later life. All we know is what went on when he was a freshman, sophomore, junior in college.” Sperm banks could at least mitigate some of the risk by limiting offspring from a single donor.

It’s also just hard to imagine what it means to be one of more than 100 children. What are the psychological effects, Kramer asks, “for a child to be part of a herd of children?” Or for a donor, who might have donated for spending money in college, to find out he has 100 offspring? One donor has taken to keeping track in an Excel spreadsheet. “It’s kind of overwhelming to think about,” says Naomi Cahn, a law professor at George Washington University and the author of The New Kinship: Constructing Donor-Conceived Families. But, she adds, finding so many half siblings could also be welcome for some people.

For Daily and her now-teenage son, who grew up as an only child, meeting dozens of half siblings all over the country has indeed been welcome in many ways. They have gone on annual vacations with donor siblings. When he travels for ice-hockey games, they meet up with whoever is nearby for lunch. (They have not been in touch with the donor, and Daily says her son is not particularly interested.) The number of siblings in Daily’s case is unusual, but such stories are not. As donor-conceived people have found their donors and their siblings, they have created new types of family bonds.

[ Read: The changing norms around donor-sibling networks ]

This openness to relationships created by donor sperm is relatively new. For decades, doctors told their patients—usually married, usually heterosexual—to keep the use of donor sperm secret even from the children they conceived. “The child might feel rejected, the sterile husband might feel humiliated, and the wife might be condemned as an adultress,” Kara Swanson, a professor at the Northeastern University School of Law, recounts in her book, Banking on the Body. But as sperm donation became available to single mothers and lesbian couples, these new patients bristled against the secrecy. To them, it wasn’t embarrassing; it was a simple fact of conception. An egg and a sperm might still be the only way to have a baby, but a mother and a father are not the only way to have a family.

That is, of course, why it’s so interesting to see sperm donation addressed on The Bachelorette, a show about the spectacle and promise of heterosexual coupling. In this context, is conceiving 114 children a masculine boast? Or fodder for jokes and queasy references to incest? Or will it be just another semi-interesting fact—like Matteo’s VR start-up or milk-chugging skills—that is briefly noted before we move along, accepting that families can now come in all sizes and forms? As I’m sure ABC would like me to say, we’ll just have to tune in to see.



On New Year’s Day 2001, the first crew of the International Space Station spent a quiet day in orbit. The commander, U.S. Navy Captain William Shepherd, decided to honor a naval New Year’s tradition, in which the person at the helm recites a poem. Shepherd had written something for the occasion, which included the following, recorded in the ship’s log:

Though star trackers mark Altair and Vega / Same as mariners eyed long ago / We are still as wayfinders of knowledge / Seeking new things that mankind shall know.

The station had been under construction, in orbit, for four years at that point, but Expedition 1 marked the beginning of continuous human habitation.

Today the space station’s “wayfinders of knowledge” are still steering an orbiting laboratory for experiments in biology and materials science. But just as explorers of the sea did their job to blaze a path for merchants, the ISS could soon play host to wayfinders of a different sort, whose voyages will be enabled by a whole lot of cash. About $58 million, according to NASA, which announced last week that it would allow private citizens to fly to the only other realm where humans have lived.

NASA will charge about $35,000 a night per passenger to sleep on board the ISS and use its amenities, starting as soon as next year. The station can accommodate two paying visitors for up to a month, but people won’t be able to just show up. Visitors will sign contracts with SpaceX, Boeing, or other companies to pay for the rocket ride, fees, and other costs. That means these trips will remain the purview of the very rich and very powerful for a very long time to come. That makes space tourism unsustainable, and to a certain mind, depressingly out of reach. Once, astronauts chosen for their courage, verve, intelligence, and vigor embodied the mystique of space. Now the right stuff will come with a price tag. The stars may be an everlasting connection to our ancestors, but the prize of soaring among them will be reserved for the wealthy.

NASA’s decision to open up the space station is in some ways a natural next step for space exploration. Earlier, earthbound vessels all experienced a similar transformation. Transoceanic ships, railroads, and airplanes spawned cottage industries to enable their spread and wide adoption, and each eventually reached the masses. And in widening access to space, NASA is actually behind the Russians, whose space agency has transported a few space tourists through a company called Space Adventures.

But space is different. Space, as they say, is hard. To get there, you have to strap yourself to a bomb, and sometimes those bombs malfunction.

Personal space exploration is also hard to justify. Space is not obviously a place of riches ready for the taking. There are no ports full of exotic foods to bring home, and there are no people or animals to oppress or exploit (at least not yet). There are no vast tracts of arable land where intrepid explorers can make, hunt, or gather everything they need. There is no water, or wind, or soil, or anything except sunlight and radiation. There is no good reason to take on the risk and the debt to get there in the hopes of making it rich.

This has not stopped private companies from exploring space, and it shouldn’t. The region where the space station circles Earth is mostly free from gravity’s influence, transforming many basic physical processes and enabling interesting science. Already, astronauts frequently conduct experiments for pharmaceutical firms that could lead to new medicines, because some proteins grow better in microgravity.

While these projects are financed by private companies, government workers do the job. Astronauts undergo extensive training on Earth before flying to space to conduct biology experiments. It’s not clear yet whether the tourist visits will be open to private firms, turning the ISS into a co-working space in orbit. A private company could, in principle, buy tickets for its own scientists, or for that matter, manufacturers. Under the new tourism plan, NASA will also allow, for the first time, purely for-profit ventures that do not meet any educational or research goals. That could include flying objects or food to space, then selling them to collectors or connoisseurs back on Earth.

But space-based tourism doesn’t have the same utility as private, space-based research or as space-based mining, which may happen someday on the moon or on asteroids. Space-based tourism has no obvious external benefit—at least, none beyond the pure, personal exhilaration of a real-life glimpse of Earth’s curvature. Space tourism is a lark. It’s something for very rich people to do with their money. Amazon CEO Jeff Bezos has literally said so. “The only way that I can see to deploy this much financial resource is by converting my Amazon winnings into space travel. That is basically it,” he told Business Insider in 2018.

Bezos also said he believes that his rocket company, Blue Origin, is his most important contribution to society; he argues that humans should spread throughout the solar system and leave Earth “zoned residential.” But occasional tourism by extremely wealthy people is a giant leap from something like Saturn-ward expansion.

This latest decision, to allow paying visitors, reveals the most about the attitudes of current political leadership toward space: as a place like any other, best suited for commerce.

Several multimillion-dollar tickets to the ISS could offset some of NASA’s bills, for starters. The agency currently spends about $8 million a day to operate the station, NASA officials said during the announcement last week. Some of those funds could be redirected to pay for a sped-up moon mission, aimed at landing astronauts back on the moon by 2024. That year also looms large for the station: Donald Trump’s administration has proposed ending federal funds for the ISS in 2024 and moving toward private stations or private ownership.

This poses somewhat of a conundrum for private companies. If you knew your cruise ship would be unusable within the next five years, how much time and money would you invest in selling tickets to sail on it? How much money would you invest, or be expected to invest, to maintain the station in a visitor-friendly state? Even if NASA could promise a shipshape ISS, the number of people visiting would hardly cover all the expenses. “This is not going to be a profit-making venture for NASA at all,” said Jeff DeWit, NASA’s CFO, at a news conference last week. “But it will help defray expenses.”

Handing tourists the keys to the ISS reflects a much broader shift in space exploration, one that prioritizes resource extraction and commercial profit over pure research and collective scientific efforts. It’s a step toward making space more mundane, a travel destination defined by money and vacations, rather than discovery and glory.

The space-station commander Bill Shepherd, who spent 159 days, seven hours, and 49 minutes in space throughout his career, ended his New Year’s ode with these lines:

We commend to crews that will follow / Merit of the good ship we sail / Let Sun shine strong on Alpha’s wings / A symbol, and bright star we long hail.

Alpha was his nickname for the ISS, though it didn’t stick; the station remained a place named without romance. But it remains a symbol. It’s a bright star you can spot yourself, on any clear night, tracing a steady and sure path across the wide dome of the sky.

I’ve often been asked whether I would visit space, or the moon, or even Mars, if given the opportunity. I’ve never applied for astronaut training, which is one form of an answer. The idea has certainly grown more plausible, as companies such as SpaceX have grown up and built successful rockets. And I can’t deny that a part of me dreams of experiencing the curvature of Earth, or visiting the gray and looming hills of our moon. I often answer that I have a telescope, and for me, right now, that is enough. I can come up with plenty of other ways to spend my money right here, on the only home we have ever known.



A few years ago, Michael Gabbett got a call from a very confused ob-gyn. A woman had come in pregnant with twins who should have been identical—they shared a placenta, meaning they must have split from a single fertilized egg. But doctors could also see, as plain as day on the ultrasound, that one looked like a boy, and the other, a girl.

How could the twins be identical but different sexes? “My initial reaction was, ‘I think your ultrasound is wrong,’” says Gabbett, a clinical geneticist at Queensland University of Technology, in Australia. “They didn’t take too kindly to that.”

So he began to dig. Gabbett eventually found a report on “sesquizygotic twins”:  not identical, but not fraternal either. They’re somewhere in between. (Sesqui means “one and a half.”) Biologists had first proposed their existence in 1984, but it wasn’t until 2007 that doctors documented the first case of sesquizygotic twins. These twins in Australia are the second known case.

The sesquizygotic twins are likely the result of three separate events in the womb, each one rare by itself. First, an egg was fertilized by two sperm, one with an X chromosome, and one with a Y. The usual result is a fetus with three sets of chromosomes rather than the normal two. These fetuses do not survive.

In this case, however, a second unusual thing probably occurred. It seems that the three sets of chromosomes (egg, X sperm, and Y sperm) were able to sort themselves into three types of cells. Two of these cell types were more typical; they each contained one chromosome set from Mom (the X through the egg) and one from Dad (the X or Y from the sperm). The third type only had chromosomes from Dad, one from the X sperm and one from the Y sperm. This last type of cell cannot grow normally. But the two more typical cell types continued to divide and divide as a single ball.

Lastly, this ball of cells split to create two embryos. One grew in the womb to look like an ordinary girl, and the other like an ordinary boy.

Genetically, however, the twins were not so ordinary. The ball of cells had not split neatly into an XX and an XY embryo. The twins are actually chimeras, meaning they both have a mix of XX and XY cells in their body, but in different proportions. The one who looks like a boy has an XX:XY mix of 47:53; the girl has a mix of 90:10. In the 2007 case, one of the twins actually had ambiguous genitalia, which is what first tipped doctors off to something previously unknown about the twins.

Gabbett and his colleague wondered whether more sesquizygotic twins were out there, mistakenly classified as fraternal twins. Unless their DNA has been analyzed, the genetic subtleties are easy to miss. The team decided to analyze the DNA of 968 pairs of presumed fraternal twins and their parents, but they found no evidence of more sesquizygotic twins. It is indeed very rare, as the proposed biological mechanism would suggest. “You’ve got these three very unusual things happen,” Gabbett reiterates. “That’s why it’s so extraordinary.”

The twins in Australia are 4 years old now. One had an arm amputated shortly after birth due to a blood clot unrelated to her chimerism, and later had surgery for an ovarian abnormality that was related to chimerism. Otherwise, they are living healthy lives.

Michael Golubovsky, the biologist who had proposed a mechanism for sesquizygotic twins back in 1984, is not surprised to see a second case. He has also suggested that sesquizygotic twins who are not chimeras—that is, the initial embryo split neatly between two cell types—can exist. And he has proposed yet other scenarios too, in which one sperm divided before fertilization to create sesquizygotic twins.

“The whole process of fertilization is based on extraordinary molecular dialogue,” he wrote in an email. So many things can go awry—a missing chromosome there, an extra set here—and most of those fetuses are not viable. Some are born, with chromosomal abnormalities such as Down syndrome. And some, it appears, can be the result of two sperm fertilizing one egg, and you would never even know it from looking at the resulting children.

Life will find a way, even while deviating far from the standard formula of one egg plus one sperm equals one baby.



A surging number of Americans understand that climate change is happening and believe that it could harm their family and the country, according to a new poll from Yale and George Mason University.

But at the same time, Americans are not any more willing to pay money to fight climate change than they were three years ago, says another new poll, conducted by the Associated Press and the University of Chicago.

The polls suggest that public opinion about climate change is in a state of upheaval. Even as President Donald Trump has cast doubt on climate change, most Americans have rejected his position. Record numbers of Americans describe climate change as a real and present danger. Nearly a quarter of the country says they already see its tidings in their day-to-day life, saying “personal observations of weather” helped convince them of climate change’s reality.

Despite this increasing acceptance, there is no clear political path forward. Last year, the Intergovernmental Panel on Climate Change warned that “rapid, far-reaching and unprecedented changes” were needed to keep the Earth’s temperature from rising 1.5 degrees Celsius. Such a transformation would be, in other words, expensive. But almost 70 percent of Americans say they wouldn’t pay $10 every month to help cool the warming planet.

The data are still striking, suggesting that U.S. concern about climate change has leapt by several points in just the past year. More than seven out of 10 Americans now say that global warming is “personally important” to them, an increase of nine points since March 2018, according to the Yale poll. More Americans than ever—29 percent—also say they are “very worried” about climate change, an eight-point increase.

These changes are basically unprecedented. “We’ve not seen anything like that in the 10 years we’ve been conducting the study,” says Anthony Leiserowitz, a senior research scientist at Yale who helped oversee the poll.

It reflects a large shift, as an outright majority of Americans—a record-high number—believe that climate change could endanger their loved ones. Historically, most Americans have said that global warming “will harm people in the United States” while insisting that it would “not harm me, personally.” Now 57 percent of Americans say global warming will harm their neighbors, 56 percent say it will harm their family, and 49 percent say it will harm them personally.

These changes show up in both new polls. The AP survey found that seven out of 10 of Americans understand climate change is happening. Even more notable: A slim majority of Republicans—52 percent—understand that climate change is real. (The AP asked questions about “climate change,” while Yale polled about “global warming.” The difference in language didn’t seem to change how people replied.)

Climate change itself may be driving this remarkable shift. Nearly half of Americans say that the science supporting climate change is “more convincing” now than it was five years ago, the AP poll found. The vast majority cited “recent extreme weather events”—such as hurricanes, droughts, and heat waves—as especially persuasive.

Yet it’s not clear that Americans are willing to do anything about fighting climate change. Many economists support a carbon tax, a policy that makes polluters pay for emitting greenhouse gases into the atmosphere. Forty-four percent of Americans say they would support such a tax, according to the AP.

Americans become more supportive of a carbon tax, though, when they know where the money it collects will go. Sixty-seven percent of Americans would support a carbon tax if it were used to restore forests and wetlands. Majorities also endorse a tax that would support renewable-energy R&D or public-transit improvements. But even then, most people are not willing to spend much. Seventy percent say they would vote against a $10 monthly fee tacked on to their power bill. Forty percent would oppose a $1 monthly increase.

These results don’t lend themselves to straightforward answers about what actions to take next.

Recently, some oil companies and Washington elite have endorsed a deficit-neutral carbon fee, a type of carbon tax that regularly mails revenue collected back to every American as a check. The same proposal would also roll back Environmental Protection Agency rules. The AP poll found Americans were least supportive of this plan: Three out of four said they would oppose a carbon tax that “eases climate-related regulation,” and only half liked the idea of a monthly rebate.

Yet the opposite strategy hasn’t worked either. In November, voters in Washington State considered a carbon tax that would have supported forest restoration, wind and solar energy, and public transit—everything that people just told the AP pollsters they like. Oil companies spent $31 million to defeat the measure, and voters rejected it by a 12-point margin.

The AP and the University of Chicago did not directly ask people about a Green New Deal, a still-hazy progressive plan to fight climate change while expanding federal programs. “But this [poll] sort of supports the idea that it could be politically popular among voters,” says Sam Ori, the executive director of the Energy Policy Institute at the University of Chicago.

So what’s going on here? One possibility is that Americans are slowly, grindingly, coming around to the reality of climate change. But political scientists talk about an idea called “thermostatic opinion.” It holds that U.S. public mood works like a seesaw: When one party occupies the White House, voters immediately start to turn against its favored policies and outlook. Though more of an observation than a law, it helps explain why Americans were more conservative in 2013—just after Barack Obama’s second victory—than they had been in decades. Since Trump is both unpopular and linked to climate denial, isn’t it possible that the public mood will just shift again once he leaves office?

Leiserowitz, the Yale scientist, isn’t so sure. Americans are more certain about climate change now than they have been since 2008, he said. But 2008 was a different moment: Both major parties endorsed the reality of climate change, and the Republican candidate in that year’s election, John McCain, even had his own climate plan. So strong cues from both parties’ political elite suggested that it was okay to accept climate change—and public opinion followed.

Now the country’s president has vacillated on the reality of climate change, calling it an “expensive hoax,” then revising his view. Climate change “is one of the most politically polarized issues in Americans,” Leiserowitz said. “So the fact that Trump is now a hoaxer in chief and yet these numbers are going up is actually really interesting.”



The year is 2055, and climate change has fully set in. Months-long heat waves regularly kill infants and the elderly, and food shortages are testing governments on every continent. While the world is finally reducing its carbon emissions, the cuts aren’t happening fast enough, and scientists say Earth will keep rapidly warming for at least another century.

To stave off a crisis, China and the United States jointly propose an audacious scheme: They will inject sulfate aerosols into the high atmosphere to dim the sun’s rays, as happens naturally after a huge volcanic eruption. The two countries say the plan will restore order and lower the planet’s fever. But critics assert that the aerosols will distort the planet’s climate even further, weakening the monsoon and setting off droughts across Asia and Africa.

The scenario may sound like science fiction, but the debate over the prudence of this technique—called solar geo-engineering—has already begun.

On Monday, a new paper from a team of researchers claimed that it is possible to dim the sky in such a way that no region of the planet will be made significantly worse. No major land area will face more intense temperature, precipitation, or drought extremes under a specific solar geo-engineering scenario than would occur instead under climate change, the paper asserts.

“That’s stunning. If it’s really true, it’s a huge deal,” says David Keith, an author of the paper and a professor of applied physics at Harvard. The study, which relies on a relatively rosy and moderate geo-engineering scenario, was co-authored by several widely recognized climate scientists who had never published on the topic before: Kerry Emanuel, an MIT professor who specializes in tropical cyclones, and Gabriel Vecchi, a geoscience professor at Princeton.

Keith believes that these optimistic early results should justify the establishment of a new international research program on solar geo-engineering.

Yet the paper, published in Nature Climate Change, has already been criticized by those who worry that geo-engineering researchers are moving too fast and overselling the still-notional technology. They also fret that optimistic talk of geo-engineering could discourage the public from embracing emissions cuts.

“They are desperately trying to conjure demand for their research topic, but I think they’re hamstringing themselves over the long term by overclaiming,” said Jane Flegal, a climate-policy researcher and an adjunct faculty member at Arizona State University, in a message. She worried that the study’s cheerful conclusion downplays the chance that geo-engineering will require economic or political trade-offs.

“I don’t think it is correct to imply that geo-engineering is a good or safe idea,” said Alan Robock, a professor of environmental sciences at Rutgers, in an email. He questioned how the study used computer climate models—that is, its authors did not simulate solar geo-engineering by modeling volcanic aerosols in the high atmosphere. Instead, they told the computer model to reduce the strength of the sun’s rays, a sort of brute-force proxy for geo-engineering. “And there is no way to do what they modeled, as we cannot turn down the sun,” Robock said.

Keith and his colleagues acknowledge some of these criticisms in the paper. Simulating geo-engineering by turning down the sun in models is “a very widely used technique,” he told me. It allows easier comparison between different computer models that may use varying processes to simulate high-atmospheric aerosols.

The new paper does not investigate whether solar geo-engineering could restore the climate to pre-global-warming levels. (Right now, the only way to avoid climate change altogether is to cut emissions.) The new paper asks instead whether geo-engineering could essentially cut the dangers of climate change in half. It uses high-resolution climate models, including one developed by the National Oceanic and Atmospheric Administration, to compare two different scenarios: one where atmospheric carbon levels have doubled above preindustrial levels and geo-engineering is not used, and another where they have doubled, but geo-engineering is used.

In every region of the world, the study found, temperatures grew less extreme with geo-engineering. And while geo-engineering disturbed the climate of some regions in new but small ways, it overall reduced the effects of climate change in places it was worst. “Those regions experiencing the greatest climate change are the most likely to see it reduced by [solar geo-engineering],” the study says.

There are many asterisks here. The study focuses on very vast regions: One of its areas encompasses the entire Pacific coast of South America; another includes almost all of Pakistan, India, and Bangladesh. It also does not study the lines on the planet that may matter far more: national borders. Even if rainfall remained constant in each of the studied regions, it could still cause conflict by shifting from one country to another, disrupting agriculture and water supplies. The study cannot examine that possibility.

The study also examines a form of unadulterated climate change that will likely be easier than what we are on track for: It uses a scenario that assumes carbon-dioxide levels will sit at about 560 parts per million, but even some moderate scenarios assume they will pass that point in the middle of the century. (The absolute worst-case scenario projects 1370 parts per million by 2100.)

“I am not saying that we know solar geo-engineering reduces risk,” Keith said. He acknowledged that the paper presents idealized risks, and those may be wrong. But the paper also, he said, makes “the most important case that solar geo-engineering could be really useful.”

“It’s important to keep in mind that this study actually tells us very little about the feasibility of the idea of geo-engineering,” Flegal said. “It is reasonable to ask whether we expect the real world to behave like these models. [And] even if the real world behaved like these models, it is not clear to me that we should expect that this research will inform ‘rational’ decision making in this domain.”

“People’s experience of climate is not entirely driven by physical climate variables,” she added. “It is mediated by all sorts of other cultural, political, social, and economic factors.” In other words, even if solar geo-engineering didn’t cause a particularly bad weather outcome, people may still blame it.

While scientists have long hypothesized about the role of solar geo-engineering, serious researchers avoided the topic for all of the 20th century. That changed 13 years ago, when the Dutch chemist Paul Crutzen, a recipient of the Nobel Prize, called for a new program of “active scientific research” into the technique. Since then, governments and philanthropists have begun funding programs on the topic.

“There’s much more interest among really senior science-policy leaders than there used to be,” said Keith. In 2017, during President Barack Obama’s final days in office, the White House proposed a multiyear, comprehensive investigation into the topic. The National Academies of Science, Engineering, and Medicine also recently formed a committee to study it.

But the topic has not yet been subject to widespread study across many institutions. It also poses a dilemma for environmental organizations. While some major green groups have tepidly endorsed geo-engineering research, a tweet-length endorsement of the technology by President Donald Trump—or any antagonistic leader using it as an excuse to avoid cutting emissions—would immediately force them to retract their support.

“Solar geo-engineering has been fairly critiqued as this clique,” Keith said. Only a small number of scientists have spent time on the topic, “and I’m one of them. People could easily write this off and say, ‘Well, it’s Keith, so he knows the answer before we start.’” This is why he was so pleased that Vecchi and Emanuel also worked on the study.

In Keith’s view, more researchers of their caliber should be involved in geo-engineering research. “We need to get beyond a few researchers doing this as a hobby, which is what’s happening now, and move to a serious international program with democratic controls and open-access research,” he said.

And he was clear: The results don’t yet justify actually trying out solar geo-engineering on the planet. “Deployment would be ridiculous,” he said. It would also be impossible; there is still no way to seed sulfate into the high atmosphere. Robock, who is skeptical of the approach, said that some proposals to do so could cost $50 billion to $200 billion a year.

“Everybody wants to leap to an answer, ‘Should we do it or not?’ But we need some humility,” said Keith, who is 55. “Our generation, people my age, are not making this decision. It’s going to be our kids, maybe in 20 years, who make a serious decision about solar geo-engineering. We can’t bind their hands one way or another. And if we maintain the existing taboo and have no research on it, they’ll still have to make decisions.”



When bacteria talk, Bonnie Bassler listens. She just never figured that viruses were listening, too.

Since the 1990s, the Princeton University biologist has been studying a phenomenon called quorum sensing, in which bacteria release molecules that indicate how many of their peers are around. Through these messages, they can coordinate their behavior and launch certain actions—such as infectious attacks—only when their numbers are large enough.

Bassler’s student Justin Silpe has now discovered that a virus can listen in on these signals, for sinister ends. The virus in question is a phage—a spidery thing that infects and kills bacteria. Once it infects its host, it has two modes: wait or kill. If it chooses the latter, it makes multitudes of daughter viruses that fatally burst through the host bacterium, ready to infect others. But what if there are no others around? “If you’re a virus, if you don’t get into another host, you’re doomed,” says Bassler.

As Silpe found, the phage avoids this fate by detecting the same quorum-sensing signals that the bacteria use to gauge their numbers. It can effectively wait for its hosts to announce that they’re plentiful, so that when it kills one, its progeny will assuredly find many more. “It’s so cunning to eavesdrop on a quorum-sensing molecule,” says Bassler. “No one has seen that before.”

Quorum sensing was already a revolutionary concept. As Bassler uncovered its details over decades, she and others were shocked to realize that supposedly simple organisms such as bacteria could communicate and coordinate. But viruses are even simpler. They’re not even technically alive! They’re entirely different entities from bacteria, yet they are intercepting and interpreting the same molecular messages. It’s like a rock eavesdropping on a bird.

The seeds of this discovery were planted a few years ago, when Bassler’s team identified a new kind of quorum-sensing system in Vibrio cholerae, the bacterium that causes cholera. It secretes a signaling molecule called DPO, which it detects using a protein called VqmA.

When the bacteria start to infect a host, there aren’t many of them around, and the DPO signals they produce drift off into the ether. But as their numbers swell, the signals become more concentrated and start landing on the VqmA detectors. When this happens, it triggers a sequence of genes that reprogram the bacteria, turning off their ability to infect and turning on their ability to disperse. This is partly why “cholera is such an insidious disease,” says Bassler. Through quorum sensing, Vibrio cholerae can wait until the time is right, before “getting out of the host by the gazillions to infect the next host.”

By searching through online databases, Silpe showed that many closely related Vibrio bacteria also have detectors that resemble VqmA. But so, apparently, did a virus—a phage called VP882, which some Taiwanese researchers had found from a marine Vibrio a decade ago. Was that a random coincidence? A mistake in the database? Or, as Silpe suggested, could the virus somehow be tapping into the messages of its hosts? “I thought, We’re going to waste a lot of time on this, because it’s a crazy mistake,” says Bassler, cheerfully. “But that’s what we do.”

The researchers who found the VP882 virus had retired, but not before putting a sample of the host bacteria in a repository. It took six months for Silpe to track down that precious sample, and fortunately, those bacteria still had some virus inside them.

Through careful experiments, Silpe showed that his hunch was right: The virus’s version of VqmA can indeed detect the same DPO signals that the bacteria release. And when it does, it prompts the virus, which usually lies harmlessly in wait, to start killing its host. “There’s a funny logic to it,” says Bassler. “At high densities, cholera, a parasite, wants to leave its host and get into another host. And at high densities, the virus, a parasite of a parasite, wants to leave its host and get into another host. They’re doing the same thing [using the same signal molecule].”

The virus isn’t just eavesdropping either. Remember how the cholera bacterium uses its VqmA detector to shift from infection to dispersal. Silpe found that the virus’s version of VqmA can launch the same genetic program, forcing its bacterial host to disperse. “The phage, while it’s preparing to kill cholera, is also messing with hundreds of bacterial genes,” Bassler says. Perhaps that’s all part of the same strategy: The phage not only ensures that its progeny have plenty of hosts to infect, but also ensures that those hosts spread far and wide.

VP882 has another odd quality: Unlike most phages, which are limited to specific hosts, it can infect a wide range of bacteria. It only listens to the messages exchanged by Vibrios, but Silpe managed to engineer it to eavesdrop on other species, including Salmonella and E. coli. And when it detects molecules that are present only in its targets, it kills them. This random virus is now a programmable assassin that Silpe can set to go after particular targets. “It was like a gift from evolution to us,” says Bassler.

For decades, scientists have tried to use phages to treat bacterial diseases, and these phage therapies are especially promising now that many bacteria have evolved to resist traditional antibiotics. But there’s a catch: Phages are usually finicky in their hosts, so researchers would need to find a different virus for every bacterial infection they want to treat.

Silpe’s work offers an alternative strategy. “They propose using a promiscuous phage that can infect many different bacterial species, but will only kill in response to a predefined cue,” says Adair Borges, who studies phages at the University of California, San Francisco. “It’s an interesting new take on phage therapy [that] allows for even more specificity and control over the bacteria that are killed.”

“This isn’t a phage therapy yet,” Bassler cautions. She and Silpe have only tested their programmed phages in test tubes, and it falls to other researchers to see whether the same approach could work in the clinic. They’re more interested in learning more about how phages work in nature, and they note that researchers have long underestimated these viruses. Last year, for example, another group, led by Rotem Sorek from the Weizmann Institute of Science, discovered that some phages have their own version of quorum sensing, trading messages that tell them when to kill their hosts.

“These are inanimate, non-living viruses,” says Bassler. “There’s something beautiful about how ancient communication is.”



In the fall of 2010, Rowan Barrett was stuck. He needed a piece of land, one with plenty of mice, and after days of futile searching, he found himself at a motel bar in Valentine, Nebraska, doing what people do at bars: telling a total stranger about his problems.

A young evolutionary biologist, Barrett had come to Nebraska’s Sand Hills with a grand plan. He would build large outdoor enclosures in areas with light or dark soil, and fill them with captured mice. Over time, he would see how these rodents adapted to the different landscapes—a deliberate, real-world test of natural selection, on a scale that biologists rarely attempt.

But first, he had to find the right spots: flat terrain with the right color soil, an abundance of mice, and a willing owner. The last of these was proving especially elusive, Barrett bemoaned. Local farmers weren’t keen on giving up valuable agricultural land to some random out-of-towner. After knocking on door after door, he had come up empty. Hence: the bar.

Barrett’s drinking companion—Bill Ward, or Wild Bill to his friends—thought the idea was bizarre, but also fun. “He told me, ‘I’ve got this alfalfa field. You’re welcome to come by tomorrow. I’m okay with you building this thing,’” Barrett said to me. “I just about fell out of my chair.”

When researchers study evolution through natural selection, they typically focus on just one part of it. The essence of the process is this: Some genes confer beneficial traits. Those traits make their owners more likely to survive and reproduce in a given environment. Over time, those genes and traits become more common. So researchers might, for example, find genes behind certain traits (such as striped coats). Or they might link certain traits to success in a given environment (such as longer-legged lizards in hurricane-hit islands). Beyond some experiments with lab-grown microbes, they have rarely connected all the dots together.

That’s what Barrett accomplished. With hundreds of mice and years of research, he and his colleagues were able to show and measure, in the real world, “the full process of evolution by natural selection,” says Hopi Hoekstra of Harvard University, who led the study. “It’s all in one.”

It was also a pain in the ass. “Utter ignorance was a good thing,” said Barrett, who had, until this point, only ever worked with small fish. “Anyone who had worked with mice would have never attempted this.”

Once the team had Bill Ward on board, they ended up buying 30,000 pounds of stainless steel plates from a local hardware store, and carting them over to the farm using flatbeds and forklifts. There, they erected the plates in trenches two feet deep, creating square enclosures that were 164 feet across on each side. They built three such pens on light sand, and three on dark soil.

At first, the steel pens seemed to work. Mice could neither dig beneath the plates nor climb over them. They were, however, exceptionally good at sneaking through gaps where adjacent plates didn’t quite meet, so the team had to dig everything back up and pour concrete around the joints.

Nature itself seemed eager to select against the team. On one trip, high winds almost flipped the truck carrying the steel plates. Once, a team member fainted and cut himself on a piece of steel. During winter, ramps of snow would accumulate along the walls, so the team had to add an extra layer of mesh along the plates. They also had to catch all the rattlesnakes in the enclosures and throw them over the walls; Bill helped. “Everything goes wrong in the field,” Hoekstra says. “And we’re used to dealing with pipettes, not backhoes.”

When everything was finally set, the team evicted every mouse already inside the enclosures, and caught around 500 more from the surrounding hills. They photographed each rodent, took a DNA sample, implanted a tiny radio chip between its shoulders, and released it into one of the enclosures.

As time passed, many of the mice fell prey to owls, but after three months, the team returned and recaptured the ones that were left. Sure enough, they found that, compared with the average founding rodents, the average survivors were noticeably lighter in the light-sand enclosures, and darker in the dark-soil ones. Through the deaths of the most conspicuous individuals, the survivors from two initially identical populations had shifted in different directions thanks to their different environments. “It’s intuitive that if you match your background, you’re more likely to survive,” Hoekstra says. “But that’s been a just-so story for years.” This experiment showed that it matters—a lot.

A simpler study could have stopped here, but the team went deeper. Team member Stefan Laurent sequenced a gene called Agouti, which has been linked to fur color, in all 481 of the mice. He found seven mutations that had become more common in the light enclosures, and rarer in the dark ones.

One, known as delta-Ser, seemed to have an especially strong effect. And when another team member, Ricardo Mallarino, engineered that mutation into the Agouti genes of normal lab mice, the rodents grew up with noticeably lighter coats. What had happened?

The Agouti gene is known to affect fur color through the production of a yellow-brown pigment. But to do that, it needs to partner up with other genes. Mallarino found that the delta-Ser mutation disrupts the part of the gene that facilitates those partnerships. It forces Agouti to work alone, which means that it produces much less pigment. This one mutation had lightened the mice’s fur enough that a human eye could see the difference. “And now we know why,” Hoekstra says.

In the lab, scientists can poke Agouti and show that it controls fur color, notes Luisa Pallares of Princeton University, who also studies evolution. But does this mean that variations in the gene are actually driving color differences in the wild? That question would be very hard to address through more piecemeal experiments. But thanks to Hoekstra’s study, the answer is an unambiguous yes. At the start of the experiment, the delta-Ser mutation was equally common in all six enclosures. After three months, it had become more common in two of the light ones, and rarer in all the dark ones—and the rodents’ fur had shifted accordingly. It clearly provides the variation that natural selection sculpts. “The study is very ambitious, and the results totally paid off,” Pallares adds.

Just showing that color-matched mice were more likely to have survived, and finding mutations that were associated with that pattern, “would have been excellent, and actually very rare in the literature,” says Martha Muñoz, an evolutionary biologist at Virginia Tech. “But they dug even deeper. They took a very clear pattern of evolution and broke it down in several different layers. That’s unprecedented.”

After almost a decade, Barrett, Hoekstra, and their colleagues had shown that darker-furred mice were more likely to survive on the soils of Wild Bill’s alfalfa farm, while lighter-furred individuals thrived against the whiter sands of a nearby park. They found that these variations in fur color depend heavily on mutations in one particular gene. They uncovered exactly how one of these mutations changes the color of a mouse’s hair.

In other words, they showed that one mutation became more common over time because it creates a physical trait that makes its owners better suited to their environment. It’s the essence of evolution, measured comprehensively.

“It demonstrates how quickly natural selection can occur when there is variation present in a population, and how genetic changes can be tracked in real time in natural systems,” says Erica Bree Rosenblum from University of California, Berkeley.

The experiment is still ongoing. All the original mice have died, but not before spawning new generations that are now scurrying about their steel-walled pens. The team wants to see how these progenies differ from their parents, and look beyond the Agouti gene to analyze their entire genome.  

It helps, Barrett said, that the people of Valentine have become so invested in the study. “They thought we were a little crazy at first,” he told me, “but we’ve made a lot of very good friends. Everyone in town knew about the experiment. People would go out between our trips to check on our enclosures. They call us the Mouseketeers.”

Roughly a third of Nebraskans believe that living things were created as they are now. Another third think that evolution occurs, but through God’s design. Given those beliefs, I asked Barrett whether he ever encountered resistance when talking to his new friends about his work. “In the early trips, when first meeting people, I would talk generally about genetics and natural selection. I wouldn’t use the E word,” he said. “It’s one of those trigger words where, in certain parts of the U.S., people just stop listening to you.”

But he added that all of them comprehended the essence of evolution, even if they explicitly rejected it. “A lot of them are farmers, who have a very good understanding of inheritance, and genetics,” he said. “A lot of them hunt, so they’ve got the survival-of-the-fittest thing down. They understand variation, and they know that a slow deer is easier to shoot than a fast deer. Inheritance, variation, fitness … all the pieces are there.”

“I’d never push too hard. I never explicitly said, ‘Do you believe in it or not? Have I now convinced you?’” he told me. “I just had some long conversations over beers at BBQs and high-school football games. And I found that in subsequent trips, I could use the E word and not get the flinch.”



In science, the question of who gets credit for important work—fraught in any field—is set down on paper, for anyone to see. Authorship, given pride of place at the top of scientific papers, can advance reputations and careers; credits buried in the rarely read acknowledgments section do not.

Over the past few years, a team of students led by Emilia Huerta-Sánchez from Brown University and Rori Rohlfs from San Francisco State University has been searching through two decades’ worth of acknowledgments in genetics papers and discovering women who were never given the credit that would be expected for today’s researchers. They identified dozens of female programmers who made important but unrecognized contributions. Some were repeatedly thanked in the acknowledgments of several papers, but were never recognized as authors. They became literal footnotes in scientific history, despite helping make that history.

“When Emilia and I look at our elders in population genetics, there are very, very few women,” says Rohlfs. “But there were women and they were doing this work. To even know that they existed is a big deal to me.”

The project started with Hidden Figures, the 2016 movie about three black female mathematicians who helped NASA win the space race in the 1960s. After seeing the film, Huerta-Sánchez and Rohlfs felt surprised that they had never heard of its three protagonists. How many other historical female scientists were they similarly unaware of, they wondered?

One name sprang readily to mind: Jennifer Smith. Huerta-Sánchez remembered reading a classic, decades-old paper in which Smith was thanked in the acknowledgments “for ably programming and executing all the computations.” That seemed odd. Today, programming is recognized as crucial work, and if a scientist did all the programming for a study, she would expect to be listed as an author. “It was weird to me that Smith was not an author on that paper,” Huerta-Sánchez says. “[Rori and I] wanted to see if there were more women like her.”

The duo recruited five undergraduate students, who looked at every issue of a single journal—Theoretical Population Biology—published between 1970 and 1990. They pored through hard copies of almost 900 papers, pulled out every name in the acknowledgments, worked out whether they did any programming, and deduced their genders where possible. Rochelle Reyes, one of the students, says that she was “extremely motivated” to do this work, having grown up on stories of under-recognized pioneers like Rosalind Franklin, who was pivotal in deciphering the structure of DNA, and Henrietta Lacks, whose cells revolutionized medical research. “I was fortunate to grow up in a diverse environment with a passion for science as well as social justice,” Reyes says.

She and her colleagues found that in the 1970s, women accounted for 59 percent of acknowledged programmers, but just 7 percent of actual authors. That decade was a pivotal time for the field of population genetics, when the foundations of much modern research were laid. “Based on authorship at the time, it seems that this research was conducted by a relatively small number of independent individual scientists, nearly all of whom were men,” the team writes. But that wasn’t the case.

“It’s hard to know what sort of contributions people in the past have made behind the scenes,” says Jessica Abbott, a geneticist at Lund University. But this study “shows that it’s possible to get the right kind of data if you think creatively.”

Margaret Wu, for example, was thanked in a 1975 paper for “help with the numerical work, and in particular for computing table I.” She helped to create a statistical tool that scientists like Huerta-Sánchez still regularly use to estimate how much genetic diversity there should be in a population of a given size. That tool is called the Watterson estimator, after the 1975 paper’s one and only author—G. A. Watterson. The paper has since been cited 3,400 times.

Skeptics might argue that the programmers listed in these old papers were just doing menial work that wasn’t actually worthy of authorship. Rohlfs says that’s unlikely, especially in the cases of Wu, Jennifer Smith, and Barbara McCann, who were repeatedly name-checked in many papers. “They were doing work that was good enough that they were being called back again and again,” she says. The team even talked with William Hill, Smith’s former supervisor at the University of Edinburgh, who described her work as both technical and creative. (He didn’t, unfortunately, know where Smith ended up, and the team never managed to track her down.)

They had better luck with Margaret Wu, who finally responded to repeated emails and phone calls. She told them that she was a research assistant when she worked on the Watterson-estimator paper, and taught herself programming on the job. “I think people think that, back then, women were just secretaries, who typed code, punched cards, and didn’t do intellectual work,” Huerta-Sánchez says. “But when [Wu] described her work, it was what grad students and postdocs do nowadays.”

Afterwards, Wu didn’t consider trying for a Ph.D., although she told the team that “had someone suggested that I do it, I possibly would have found that an attractive idea.” She only got her doctorate in her 40s, after two decades working as a statistician and a math teacher. Now, she’s a faculty member at the University of Melbourne, where she develops statistical methods to analyze educational data. Wu didn’t return my request for an interview, but apparently has no regrets about the 1975 paper, Huerta-Sánchez tells me. She didn’t even know how heavily cited it had become. “She smiled,” says Huerta-Sánchez. “There was a little laugh. I felt like I was more upset than she was.”

In the 1980s, the practice of shunting programmers to the acknowledgments section declined. That’s partly because the task steadily fell more to graduate students and postdocs, who were rewarded with authorship. But also, programming began changing from a “pink collar” job, done largely by low-paid women, to the male-dominated profession it remains today. Programmers, essentially, only became rewarded with authorship when they started becoming male.

“This is an opportunity for us to think about the norms we use in authorship and other metrics of academic success,” says Rohlfs. Even today, there are no clear rules about how much work someone must do to become an author. A professor could email some data to a colleague and become an author. A lab technician could do enormous amounts of labor, without which experiments could never be done, and be ignored. “There’s no standard, and surely the way we deal with authorship will be exclusive to some groups of people,” says Rohlfs. “If I look around at lab technicians, I’ll see a lot of women and people of color who aren’t being given authorship for creative work.”

Even when women do become authors, the systemic biases that pervade modern science can work against them. For a start, they’re outnumbered: One recent study found that, given current trends, it would take 16 years for the number of male and female authors to equalize across the sciences, and 258 years for fields like physics. That discrepancy is especially stark in the highest-profile journals, where women account for just 25 to 35 percent of people in the coveted first-author slot. And at least in some fields, studies authored by women tend to be cited less frequently than those authored by men.

For these reasons and others—less training, lower salaries, less mentoring, fewer speaking opportunities, more negative stereotypes, and more harassment and abuse compared with men—many women leave scientific careers early. Those who stay are judged more harshly and less favorably than equally qualified male peers. Some are forgotten.

But there’s growing awareness of these problems, and several best-selling books have recently resurfaced the stories of unrecognized women in science, technology, engineering, and mathematics. Both Hidden Figures (Margot Shetterly’s book that inspired the film of the same name) and Nathalia Holt’s Rise of the Rocket Girls tell of the elite mathematicians of NASA’s history. Broad Band, by Claire L. Evans, reveals the tales of the women whose computing and engineering skills helped to create the internet. Liza Mundy’s Code Girls is about the women who broke German and Japanese codes during World War II.

Rohlfs hopes that scientists in other fields will do similar work to rediscover the contributors whose work has been obscured for so long. “Women have always been influential in science but their achievements have simply not been given the recognition they deserve,” adds Ezequiel Lopez, one of the five students who worked on the project. “That can be changed.”



2018 was hotter than any year in the 19th century. It was hotter than any year in the 20th century. It was hotter than any year in the first decade of this century. In fact, with only three exceptions, it was the hottest year on Earth since 1850.

Those three exceptions: 2018 was slightly cooler than 2015, 2016, and 2017. The past four years, in other words, have been the four hottest years ever reliably measured.

That’s according to Berkeley Earth, a nonprofit research group that published its annual temperature analysis on Thursday. The new finding “remains consistent with a long-term trend toward global warming,” the report says.

Berkeley Earth is a respected scientific organization, but it’s unusual that this news should come from it alone. Normally, Americans hear about these milestones from their own government. NASA and the National Oceanic and Atmospheric Administration were both due to publish their version of this analysis last week, on January 17. The United Kingdom’s Met Office and Berkeley Earth also planned to release their own findings that day.

But it was not to be. The ongoing federal shutdown has indefinitely delayed the NASA and NOAA reports, so Berkeley Earth decided to go ahead with its report. “We actually finished our analysis last week, but held off releasing it in the hope that things would be resolved,” said Zeke Hausfather, an analyst for the group, in an email. “But at this point it is clear that nothing will happen soon.”

The report’s overall findings will not surprise most scientists. The European Union’s climate center has already concluded that 2018 was the fourth-warmest year on record.

But the report contains plenty of records worth noting in their own right. 2018 was the hottest year ever recorded in Antarctica, a finding with worrisome implications for sea-level rise. Twenty-nine countries—including France, Germany, Italy, Greece, and the United Arab Emirates, where temperatures hit 123 degrees Fahrenheit in June—experienced their warmest year ever last year, too.

The report also underscores that climate change has already begun—and that we are running out of time to keep it under control. It finds that Earth was about 1.16 degrees Celsius warmer in 2018 than it was during the late-19th century. Last year, the Intergovernmental Panel on Climate Change (IPCC) warned that if global warming exceeds 1.5 degrees Celsius—just 0.4 degrees Celsius above where we are now—then widespread environmental upheaval could result. Perhaps as soon as 2040, climate change could leave hundreds of millions of people with scarce food and water.

To avoid that world, the IPCC said, “rapid and far-reaching” energy changes were needed. So far, nothing resembling those changes has occurred—though admittedly only a few months have elapsed. Meanwhile, carbon dioxide pours into the atmosphere at record rates. And given that a warm El Niño might develop in a few months, Berkeley Earth predicts that 2019 will “very likely be warmer than 2018.”

There’s a coin toss’s chance, it says, that we’re living in the second-warmest year ever measured right now.



A spider’s web is more than a trap or a home. It is also an extension of the spider’s senses. By paying attention to vibrations traveling through the silken threads, the arachnid can learn about its surroundings. Certain vibrations might mean ensnared prey. A different frequency might reveal a nearby mate. And since spiders extrude their webs from their bodies, they can also change the stiffness, tension, and other properties of the silk to bring certain details into focus.

A spider, in other words, can actively tune its web to channel specific kinds of vibrations, just as a musician might tune an instrument.

But as Natasha Mhatre from the University of Western Ontario has found, a spider can also tune itself. Simply by changing its stance, the infamous black widow can make its sense organs more receptive to particular frequencies of vibration. It’s like a postural squint, which allows the spider to focus its attention on certain sources of information.

When Mhatre started studying black widows, as part of Andrew Mason’s team at the University of Toronto, she initially focused on how vibrations move through the silk. But she soon realized that “there was another problem, which was staring us in the face and which no one had considered.” Which is: How do those vibrations move through the spider itself?

Together with Senthurran Sivalinghem, Mhatre allowed captive black widows to build webs on square arenas, with a pillar in each corner. These webs aren’t the elegant, vertical, circular constructions that most people might picture. Instead, they’re a chaotic mess of strands, surrounding and supporting a loose, horizontal mesh, almost like an acrobat’s safety net, from which the spider hangs upside down.

When the webs were finished, the team placed a tiny magnet on them. By holding a powerful electromagnet nearby, they could move each web and then, by bathing the animal in lasers and analyzing the reflected beams, measure how the vibrations affected different parts of the suspended spider. Through the process, the widows were remarkably chill. Despite their infamous venom, “they’re very docile,” Mhatre says.

As with most spiders, the black widow’s entire body acts as a sensor. It’s dotted with thousands of organs called slit sensilla, which appear as tiny cracks in the exoskeleton. As vibrations pass through the animal, the cracks narrow and widen, and those minuscule movements are picked up by sensitive cells inside the slits. These slits are everywhere, but they’re especially concentrated in the joints of the legs.

Scientists have been studying slit sensilla for decades, and most experiments have shown that they respond to a wide range of frequencies, without much in the way of tuning. But that’s only true if you study the sensilla in isolation, as most researchers have. Mhatre showed that in an actual spider, hanging from its web, different joints are indeed tuned to different frequencies. “While the sensors themselves aren’t particularly tuned, the body gives the joints tuning,” she says.

When the spider changes its posture, it also retunes its joints. Typically, it sits in a neutral stance with its body horizontal and its legs outstretched. But it can also “crouch” by drawing all its legs in. In this pose, almost all of its joints become more sensitive to higher frequencies. By taking up a kind of predatory power-pose, the widow alters its senses.

“Hearing organs, in animals that use vibrations, are usually thought of as passive devices,” says Damian Elias from the University of California at Berkeley, who studies spider communication. That’s especially true for the slit sensilla, “as they’re just strain gauges sitting on joints, without any obvious way to modulate their sensitivity.” But Mhatre’s study shows that there is a way—and a very simple one.

She suspects that the crouched posture allows the widow to pay closer attention to higher frequencies, such as those produced by small prey insects. Alternatively, it could be trying to ignore low frequencies, such as those produced by wind. Both explanations make sense, since widows usually crouch when they’re hungry or when their webs have been significantly disturbed. In this position, they could better detect the movements of meals. And if a spider needs to get back in touch with low-frequency vibrations, all she has to do is extend a leg.

The widow’s abilities are part of a concept called “embodied cognition,” which argues that a creature’s ability to sense and think involves its entire body, not just its brain and sense organs. Octopus arms, for example, can grab and manipulate food without ever calling on the central brain. Female crickets can start turning toward the sound of a male using only the ears and neurons in their legs, well before their central nervous system even has a chance to process the noise. In the case of the black widow, the information provided by the sense organs in the legs depends on the position of the entire animal.

Earlier, I described this as a postural squint. That’s close, but the analogy isn’t quite right, since squinting helps us focus on particular parts of space. Here, the spider is focusing on different parts of information space. It’s as if a human could focus on red colors by squatting, or single out high-pitched sounds by going into downward dog (or downward spider).

The ability to sense vibrations that move through solid surfaces, as distinct from sounds that travel through air, is “an often overlooked aspect of animal communication,” says Beth Mortimer from the University of Oxford, who studies it in creatures from elephants to spiders. It’s likely, then, that the widow’s ability to control perception through posture “almost certainly [exists in] other spiders and web types, too, and other arthropods, including insects, that detect vibrations along surfaces through their legs.” Scientists just need to tune in.



A century ago, a strain of pandemic flu killed up to 100 million people—5 percent of the world’s population. In 2013, a new mystery illness swept the western coast of North America, causing starfish to disintegrate. In 2015, a big-nosed Asian antelope known as the saiga lost two-thirds of its population—some 200,000 individuals—to what now looks to be a bacterial infection. But none of these devastating infections comes close to the destructive power of Bd—a singularly apocalyptic fungus that’s unrivaled in its ability not only to kill animals, but to delete entire species from existence.

Bd—Batrachochytrium dendrobatidis in full—kills frogs and other amphibians by eating away at their skin and triggering fatal heart attacks. It’s often said that the fungus has caused the decline or extinction of 200 amphibian species, but that figure is almost two decades out-of-date. New figures, compiled by a team led by Ben Scheele from the Australian National University, are much worse.

Scheele’s team estimates that the fungus has caused the decline of 501 amphibian species—about 6.5 percent of the known total. Of these, 90 have been wiped out entirely. Another 124 have fallen by more than 90 percent, and their odds of recovery are slim. Never in recorded history has a single disease burned down so much of the tree of life. “It rewrote our understanding of what disease could do to wildlife,” Scheele says.

“It’s a terrifying summary,” says Jodi Rowley from the Australian Museum. “We knew it was bad, but this really confirms how bad. And these are just the declines we know about.”

The scale of these losses can be hard to appreciate, especially if you think that a frog is a frog is a frog. But amphibians are ancient survivors that have been diversifying for 370 million years, and in just five decades, one disease has nearly decimated their ranks. Imagine if a new disease started wiping out 6.5 percent of all mammal species—that would be roughly everything with hooves and everything with flippers. The world would freak out.

And amphibian experts “have been freaking out a long time,” says Karen Lips from the University of Maryland, who was involved in the new study. “Despite all the attention, I don’t think we fully appreciate what was lost.”

In the 1970s and ’80s, amphibian experts began sharing ominous anecdotes about once-plentiful populations that had mysteriously disappeared. Streams once full of eggs were clear. Nights once resonant with ribbits were silent. Nothing about the habitats had changed, save for their sudden, inexplicable froglessness. No one knew what the problem was, let alone the culprit. “It was more than a search for a needle in a haystack—we were still debating the existence of the haystack,” Lips wrote recently. Steele’s analysis shows that by the point the fungus was finally identified, in 1998, it had already done the brunt of its lethal work. At least 60 species were already extinct, and hundreds more were going south.

Bd is perhaps the perfect frog killer. It kills with gusto and without fuss. While some diseases affect only specific hosts, Bd covets nutrients found across amphibian skins, and so targets the entire group indiscriminately. It spreads easily through the water, and it persists outside its hosts.

The fungus hasn’t acted alone; humans have been its unwitting accomplice. A genetic study led by Matthew Fisher from Imperial College London suggested that Bd had originated somewhere in Asia. From there, one especially virulent and transmissible strain spread around the world in the early 20th century—a time when international trade was booming. Infected animals could have stowed away aboard ships, or been deliberately transported as food, pets, or pregnancy tests. Either way, the killer strain eventually spread to five other continents.

In the new study, Scheele’s team compares the modern world to Pangaea—the single, epic supercontinent that existed at the dawn of the dinosaurs. It has long split up, but humans have effectively re-created it. For wildlife diseases, all the world is once again a single connected mass, easily traversed. For that reason, new fungal diseases seem to be emerging at an ever-increasing pace, affecting bats, snakes, salamanders, and more. “These fungi would normally have fried on a sailing craft across the Atlantic, but now they’re viable,” Scheele says. “We’re just able to move things around at higher speed and volume than we used to.”

Humans have also repeatedly sown islands with introduced hunters such as cats, rats, and mongooses, to the detriment of local fauna. In many ways, it’s more fitting to think about Bd as one of these introduced predators—and perhaps the most destructive that people have ever unleashed. “Cats have been a plague on biodiversity over generations, and they eat everything,” Scheele says. “And yet Bd, whose impact we have only been able to measure for decades, already far outstrips the cats and rats in terms of the species affected.”

The comparison is especially apt because once in a new place, Bd is hard to dislodge. A typical disease might cause an epidemic and burn out, only to be later reintroduced from a reservoir. But once Bd arrives, it doesn’t fade out, and it cannot be removed. Like rats on islands, it becomes a nigh-permanent fixture of the areas it invades.

Limiting its movements remains the best strategy, and that means curbing the wildlife trade. “Moving wildlife around the globe can and does have devastating consequences,”Rowley says. “There’s more awareness of the impact of invasive species like cane toads and rabbits, but this paper highlights that it may be the inadvertent hitchhikers—the parasites and pathogens we don’t see—that cause the most biodiversity loss.”

Encouragingly, the pace of decline has eased. Better still, 60 species have begun to show glimmers of recovery. But no one knows whether this means that frogs have managed to eke out an evolutionary truce with Bd, or whether further outbreaks are to come. That’s possible if the fungus makes it to Papua New Guinea—a thus far Bd-free stronghold that is heaving with amphibians. The virulent, globe-hopping strain has also hybridized with indigenous varieties, raising concerns that hybrids could behave unpredictably.

“There’s no obvious way to deal with this,” Lips says. Some researchers have set up captive-breeding programs to buy time for species in contaminated habitats. Others are looking at ways of manipulating the fungus, or breeding more tolerant frogs, or pairing the frogs with defensive bacteria, or relocating frogs to sites that are inhospitable to the fungus. None of these solutions is a silver bullet, and none is close to readiness. “It says a lot about the scary nature of the disease that even after intense, long-term collaborations we haven’t come up with a viable solution,” Lips adds.



For several years in the fall, Marie-Anne Félix would walk through an apple orchard near Paris in search of rotten fruit.

Félix, an evolutionary biologist at École normale supérieure, studies tiny, translucent worms called nematodes. These worms feed on bacteria, so they tend to congregate, as their prey do, on the flesh of decaying fruit. In 2009, Félix picked up one such apple rich in nematodes. She took samples back to her lab, where she tried to grow worms and bacteria from the apple in petri dishes.

What she saw, though, was a massacre. Dead nematodes’ bodies were strewn everywhere. What’s more, bacteria inside the worms seemed to be eating their hosts inside out. Over the course of several days, she saw the worms’ corpses disappear, literally dissolving before her eyes. Félix has studied a lot of bacteria that live on worms, and this, she says, is “the most spectacular I have ever seen.”



In a study published today in the journal BMC Biology, Félix and her co-author Antony Page describe this “golden death” bacterium. The scientific name they chose is Chryseobacterium nematophagum, meaning “golden bacteria, nematode-eating.” Under the right conditions, colonies of Chryseobacterium take on a golden hue and, well, the second part of the name is self-explanatory.

Page, a parasitologist at the University of Glasgow, saw Félix give a talk about this strange new bacterium in 2015. He became intrigued because he studies the cuticle, the strong but flexible exoskeleton of nematodes. “The cuticle of these nematodes is really a tough structure,” he says. Yet the Chryseobacterium nematophagum seemed to be dissolving it.

Page first fed the bacteria to a species of nematodes called Caenorhabditis elegans—most famous, among scientists at least, as a model organism so well studied that each of its 302 neurons has been mapped out. With even a rudimentary nervous system, C. elegans can learn to avoid bacteria that make them sick. But the nematodes seemed to be actually attracted to Chryseobacterium nematophagum. Once they ate the bacteria, it was too late to learn anything. Within seven hours, they were all dead.

When Page and his team sequenced the DNA of Chryseobacterium nematophagum, they found genes for enzymes that likely break down the exoskeleton and structural proteins of the worm’s body. They also tracked the dissolving of the worms in real time by using various stains and molecular tags. The bacteria’s enzymes ate through the worms’ pharynx, or mouth, over a matter of hours. Once they breached the lining of the mouth, the bacteria simply digested the rest of the worm. They could even dissolve some of the tough outer cuticle, which normally protects the worm from outside pathogens but can’t do anything about a pathogen eating it inside out.

This strategy also bypasses the grinder, a structure in the back of the mouth that nematodes use to crush pathogenic bacteria trying to sneak into the gut. Chryseobacterium nematophagum never goes through the grinder—it hangs out in the mouth long enough to dissolve through it. Hinrich Schulenburg, an evolutionary biologist at the University of Kiel, says this is the first nematode pathogen he’s seen that begins its attack in the mouth.

As far as nematodes go, C. elegans is mostly harmless, but other species can be parasites for sheep, cattle, goats, and horses. Page wondered whether Chryseobacterium nematophagum could be a way to control parasites that sicken livestock, so he tested it against 13 nematode species. It worked against all but one.

Jonathan Ewbank, who studies C. elegans immunity at Centre d’Immunologie de Marseille-Luminy, notes the long history of studying nematode pathogens as a way of controlling nematodes. The organic pesticide Bt is derived from a bacterium called Bacillus thuringiensis that makes toxins harmful to nematodes as well as a wide range of insects. Other pathogens have invented additional clever ways to kill nematodes. Some fungi can physically lasso nematodes before digesting them. Microsporidia use sharp tubes to pierce nematodes and inject their genetic material, so they can replicate inside the worm.

Even among these, Chryseobacterium nematophagum rates among the most dramatic in its effects. “This bacteria completely destroys the nematodes,” Ewbank says. “It’s like the flesh-eating disease of worms.” A rotten apple—so soft and brown and unassuming—hides a whole violent world inside.



When the fate of the planet is at stake, a single precedent starts to seem like a blueprint.

Most Americans, as far as pollsters can tell, want the United States to honor its commitment under the Paris Agreement on climate change. According to that pact, the United States must, by 2025, cut its carbon emissions 26 percent below their all-time peak. That will be hard. To make the Paris goal, the U.S. would have to cut carbon by 2.6 percent every year for the next seven years. And it has simply never cut its emissions that fast in such a sustained way before.

In fact, since the end of World War II, only one country has pulled off such a feat: France. Starting in 1974, France undertook an extensive build-out of its nuclear-power industry, and slashed its carbon emissions by an average rate of 2.9 percent every year from 1979 to 1988, while still growing its economy. No country has done anything like that before or since.

It has the promise of a good strategy. And last week, it’s just what the center-right commentator Andrew Sullivan ordered. Writing in New York, Sullivan argued that the United States should undertake “a massive nuclear energy program” as a “radically moderate answer to climate change.” Unlike renewables, nuclear power doesn’t cease to work when the sun sets or when the wind stops blowing. It is already technologically feasible, and it’s been quickly scaled up in the past. The ambition of a nuclear expansion could match that of the Green New Deal, except with all the twiddly socialism bits removed.

To his credit, Sullivan’s case for nuclear power includes long lists of its drawbacks. New nuclear plants are very expensive to build. Nuclear accidents, while extremely rare, are extremely expensive to remediate (if they can be remediated at all). But because the well-being of humanity is in jeopardy, these cons should bow to the pros, Sullivan says. After all, he asserts, nuclear power “can potentially meet all our energy demands.”

Isn’t it nice to think so? Sullivan’s sincere concern for the issue is welcome, and he is right to compliment the no-half-measures aspiration of the Green New Deal. He is also correct to argue that a nuclear build-out could lower the United States’ carbon emissions. But, alas, nuclear power is not a full answer—or even half an answer—to climate change. It simply cannot meet all of the U.S.’s energy demands. And by casting a nuclear build-out as a kind of moderate climate counteroffer, he reveals a misunderstanding about the Green New Deal itself—and what makes it notable.

Let there be no mistake: Nuclear power plants can generate enormous amounts of carbon-free electricity. A rapid increase in nuclear energy would slash emissions from the power sector, as the French example makes clear. Even today, France’s carbon density—its carbon emissions per capita—ranks well below that of Germany, the United Kingdom, and the United States, according to the Global Carbon Atlas.

But you can’t put a nuclear reactor in a tractor-trailer or a steel plant. Nuclear can only reduce emissions from the power sector, and “the energy system is bigger than just electricity,” says Sam Ori, the executive director of the Energy Policy Institute at the University of Chicago. “While I think nuclear has real potential as a means to decarbonizing electricity, you still have a lot of sectors to worry about.”

In fact, electricity makes up a smaller and smaller part of the climate problem. Right now, the power sector contributes only about a third of annual U.S. carbon emissions related to energy production. When you factor in land change and agriculture (read: deforestation and all those pesky cows), electricity is responsible for only about a quarter of annual U.S. emissions. And its share is declining. Carbon emissions from the U.S. power sector have fallen 28 percent since 2005. Meanwhile, emissions from other parts of the economy—transportation, agriculture, industry—have fallen by only 5 percent.

“Even if you figure out electricity, you still have to figure out industry. You still have to figure out transportation,” Ori told me. Although we have partial answers to some of the problems posed by those sectors—everyone could buy electric cars, for instance, and charge them off the new nuclear-powered grid—we don’t have total ones. We still have no electrified way of moving around freight. Electrified air travel remains notional. All the nuclear plants in the world could not reduce the importance of oil in steel production. Solving all these problems will require some kind of public policy, Ori said; even electric cars won’t replace their gas-powered brethren without a regulatory nudge. Sullivan’s nuclear build-out has nothing to say about such challenges.

Yet a Green New Deal does. If you look at Representative Alexandria Ocasio-Cortez’s actual Green New Deal resolution, you’ll see that its vision extends far beyond the power sector. It pledges to invest in U.S. industry and manufacturing so as to remove “pollution and greenhouse gas emissions … as much as is technologically feasible.” It makes an almost identical promise for the agricultural sector. The resolution is notably imprecise in how it will accomplish those goals, but it was written as a list of goals, not policies. At least it recognizes that those sectors exist. (The Washington Post editorial board’s “efficient, effective, and focused” Green New Deal also makes passing mention of them.)

So why does Sullivan believe that nuclear power constitutes a “radically moderate” counteroffer? I suspect he believes that it represents a concession on the part of environmentalists. For years, “No nukes” was the unifying demand of Big Green groups. In his piece, Sullivan claims that “nuclear power was left out entirely” from the Green New Deal, which he calls “staggering.” He links to a Popular Mechanics article that says the same thing.

The problem is that it was included in the Green New Deal. Ocasio-Cortez’s proposal demands 100 percent “clean, renewable, and zero-emission energy sources.” The watchwords here are clean and zero-emission, both coded language for nuclear power. I have covered debates over nuclear’s inclusion in the Green New Deal, and I agree that its status is shaky: The activist group Sunrise Movement has sometimes decried it and sometimes endorsed it. But the most detailed version of a Green New Deal online, from the leftist group Data for Progress, recognizes the importance of “clean sources such as nuclear.” And the author of that report told me explicitly on Twitter: “I support more nuclear.”

The fact is that many environmentalists have already made the concession to nuclear power that Sullivan demands, precisely because they believe that climate change is so dangerous as to be worth the trade-offs. And because many environmentalists are also progressives, they might also recognize the big-government allure of nuclear power.

“It is interesting to me that conservatives flock to nuclear power. They point to France! I can’t get over that,” Ori told me last week, sounding bewildered. “It’s a state-run industry in France. The way they were able to get to 80 or 90 percent nuclear is that they didn’t worry about market forces. They just did it.”

It was, in other words, industrial policy. So even if Sullivan misses the mark, the larger irony shouldn’t be lost. Once, the environmental movement rallied under the banner of “No nukes.” Now, in its hunt for precedents for the Green New Deal, it must admire Gallic nuclear appeal.



It’s something of an annual tradition for the president. On Sunday morning, as the eastern half of the country endured driving snow and frigid winter winds, Donald Trump asked on Twitter how climate change could be real if it was so cold outside.

“Be careful and try staying in your house,” he said. “Large parts of the Country are suffering from tremendous amounts of snow and near record setting cold. Amazing how big this system is. Wouldn’t be bad to have a little of that good old fashioned Global Warming right now!”

Trump has raised similar concerns about that “good old fashioned Global Warming” nearly every year since 2012. If it snows near Manhattan, the president says he isn’t sure about climate change.

Unfortunately, even as New York has occasionally been blasted with frozen precipitation, the world has kept warming. The past four years have been the four warmest years on record—a fact that NASA and the National Oceanic and Atmospheric Administration were due to announce this past week, were the government not shut down. Earlier this winter, Washington, D.C., experienced a shocking 22 days of above-average temperatures, and the Northeast as a whole saw a balmy January. President Trump did not seize that opportunity to affirm that global warming was real.

The simple, tedious fact is that two things can be true at the same time: The world’s average temperature can be clearly and dangerously increasing, and it can still snow sometimes in the northeastern United States. Climate emerges from averages, and the averages are unambiguous. Snowpack and ice cover are decreasing, especially in the Mountain West. The Great Lakes’ winter-ice cover has declined by 71 percent over the past 40 years. The average time between the last frost of spring and the first frost of fall has increased in every region of the country since the early-20th century.

None of these facts is likely to convince Trump, for Trump seems to have decided that he does not want to be convinced. As I wrote last year, he has expressed no interest or curiosity in updating his beliefs to reflect new facts. Instead, he has fought to keep those facts from the public: In November, every U.S. scientific agency affirmed the fact of human-driven climate change. The White House responded by trying to bury the report by releasing it on Black Friday.

“One of the problems that a lot of people like myself, we have very high levels of intelligence but we’re not necessarily such believers,” Trump told The Washington Post while rejecting his own government’s dire climate conclusions last year. Believers is an unfortunate choice of word because facts, alas, keep being true whether you believe in them or not. It is dangerously icy in the Northeast, and by all means local residents should stay inside. But a brief cold spell does not undo decades of scientific fact.



About 75 million years ago, in what is now Alberta, Canada, a dinosaur called Euoplocephalus took its final breath. That exhalation, like every other, was fleeting and insubstantial, but eons later, scientists can still reconstruct the path it took out of the dinosaur’s head. And that path, it turns out, was extraordinarily convoluted.

Euoplocephalus was one of the ankylosaurs—a group of tank-like species covered in bony plates. Their skulls and backs were armored. Their eyelids were occasionally armored. Even the nasal passages inside their skulls were lined with bone, preserving these delicate structures, usually lost to time.

More than a century ago, paleontologists first noticed that those passages included a weirdly complicated series of chambers and tubes. They interpreted these as a set of sinuses that branched from a simple central channel—a slightly more elaborate version of the setup that exists inside your nose. But in 2008, Lawrence Witmer and Ryan Ridgely from Ohio University worked out what was really going on when they put the skulls of several ankylosaurs in a medical CT scanner.

The scans revealed the unusual structure of the creatures’ nasal passages—not sinuses forking off a central channel, but a single airway that repeatedly twists and turns, like roller-coaster tracks or a Krazy Straw. These passages are more complex than the airways of other backboned animals, and they’re remarkably long. The skull of Euoplocephalus “is the length of your arm from the wrist and elbow, but its nasal passage, if stretched out, would run from your shoulder to your fingertip,” says Witmer. “I remember standing up at a paleontology meeting, holding up my hands, and saying, ‘I don’t believe it, but this is what we got.’”

Witmer and Ridgely thought that these convoluted airways acted as an elaborate air-conditioning system for the ankylosaurs’ brains. These were big, car-size animals whose bodies would have retained a lot of heat in the Mesozoic sun. “Hot blood would have come up from the core of their bodies to their brains,” says Witmer. “And while these dinosaurs’ brains were famously small, they were still brains.” Brains are especially sensitive to rises in temperature, which is why confusion and fainting are among the first signs of heatstroke. So how did ankylosaurs and other giant dinosaurs keep their noggins from cooking?

It was all in the nose, Witmer guessed. The vessels carrying blood from an ankylosaur’s body to its head ran alongside its long nasal canal. Every time the dinosaur inhaled, cool air would have meandered through that twisty airway, absorbing the heat from the adjacent blood and cooling it before it hit the brain.

Witmer’s colleagues Jason Bourke and Ruger Porter have now tested this idea. They used medical scanners to create digital replicas of the skulls of two ankylosaurs—Euoplocephalus and Panoplosaurus. Then they simulated the flow of air through these virtual noses, using techniques that are more commonly used by aerospace engineers.

These simulations revealed that, on an inhale, the dinosaurs’ long nasal passages gradually heated air by up to 36 degrees Fahrenheit, taking it from room temperature to body temperature and substantially cooling the adjacent blood. When the dinosaur exhaled, along the same twisty tubes, the air would return most of that heat back to the body. (Our own simple noses work on a similar principle, which is why your breath feels hotter coming from your mouth than from your nose.)

The team members also played around with their virtual skulls. In one experiment, they gave their ankylosaurs short and simple airways, much like ours. In another, they straightened the animals’ airways so they kept their normal length but lacked any twists. In both cases, the heating effect became far less efficient. Inhaled air picked up less heat, and it did so at the very end of the passages—too late to cool the adjacent blood vessels. It’s the passages’ length and their curviness that make them efficient air conditioners.

“This is a fascinating deep dive into an aspect of dinosaur biology that’s been difficult to study—how a dinosaur’s breath traveled through its skull,” says Victoria Arbour, an ankylosaur expert at the Royal Ontario Museum in Toronto. “It makes a lot of sense [especially since] many ankylosaurs lived in arid or tropical environments. It’s easy to see how this adaptation arose.”

Matthew Vickaryous from the University of Guelph notes that of the two species that the team studied, Euoplocephalus was bigger and had more complex nasal passages. Are those two things related? Do bigger species, which are more likely to suffer from overheating, need twistier noses? What kind of zany structures lurked inside the snout of the largest ankylosaur—the eponymous, eight-meter-long Ankylosaurus­? Today it’s possible to answer these questions, because “CT data are now available for an increasing number of ankylosaurs,” Vickaryous says.

Tetsuto Miyashita from the University of Chicago agrees. He credits Witmer’s team for “pioneering a new genre in paleontology” in which they fuse the hard physics with messy biology. “What’s next?” Miyashita asks. “Well, no one has reconstructed resonation in those virtual nasal airway models to see whether [the passages] work like a trumpet. I hope they give that a try.”



Updated 4:31 p.m. ET on February 5, 2019.

Four years after he first came across an unidentified dinosaur in southern Argentina, the paleontologist Pablo Gallina uncovered one of its neck bones and got a surprise.

In 2010, he had found a set of dinosaur teeth in Bajada Colorada. This area is rich in fossils, but because many of them are in fragile condition, Gallina had decided not to expose the teeth any further. Instead, he and his colleagues from CONICET, the Argentine government’s science agency, excavated a large chunk of surrounding earth, packed it in a plaster jacket, and took it back to their lab to carefully extract whatever bones lay within.

Gradually, the team exposed more teeth, a jawbone, and most of the creature’s skull. Then, finally, the neck bone. The six-inch-long vertebra had a pair of huge spines protruding from it, each almost two feet long.

Each spine was probably like the horn of a modern-day antelope, with a thick sheath of keratin (the material in your hair and nails) covering a core of bone. But Gallina thinks that unlike antelope horns, which grow as a single pair from their owner’s head, these spines ran all the way down the dinosaur’s long neck, with one pair per vertebra. It’s as if the animal had a sharp, horny mohawk growing where a mullet should be.

The team named the dinosaur Bajadasaurus pronuspinax—an etymological chimera of Spanish, Greek, and Latin that means “lizard from Bajada with forward-bending spines.” It lived in the very dawn of the Cretaceous period, around 140 million years ago. And Gallina thinks that it likely used its outrageous spines to defend itself from predators.

Bajadasaurus is one of the sauropods—a group of large-bodied, long-necked dinosaurs that include such celebrity species as Brontosaurus, Diplodocus, and Brachiosaurus. More specifically, it’s one of the dicraeosaurs—a family of little-known sauropods distinguished by their neck spines.

The first of these, Dicraeosaurus, was discovered in Tanzania in 1914. Its spines were relatively short, but prominent enough to give the creature its name, which means “two-forked lizard.” For almost eight decades, it was the only known member of its group. Argentine scientists finally described a second species, Amargasaurus, in 1991. And more recently, for whatever reason, dicraeosaurs have been popping up all over the place. Three more were described in the 2000s. Lingwulong, from China, was revealed last July. Pilmatueia, also from Argentina, was announced to the world just last month. That’s seven species, and Bajadasaurus makes eight.

There are almost as many hypotheses about what dicraeosaur neck spines were for as there are dicraeosaur species. Some scientists suggested that they supported a camel-like hump, or that they held aloft a pair of sails, which served to regulate body temperature or signal to mates and rivals. Other researchers reckoned that the spines might have clattered together to make sounds, or supported air sacs connected to the dinosaur’s lungs.

Gallina isn’t discounting any of these ideas, but he argues that “the most logical explanation” is that each spine was its own separate horn, and together, they were used in defense. As dicraeosaurs bent down to graze, their spines would have flared out to provide cover for the vulnerable necks. The forward-pointing spines of Bajadasaurus might have been especially intimidating: They “would represent a disturbing fence for a loitering carnivore,” the team writes in a paper on the discovery.

Admittedly, that’s a lot to infer from just a single set of spines, on a single vertebra. Without the rest of the skeleton, the team can’t say for certain whether such spines really adorned the rest of Bajadasaurus’s neck. They’re basing their reasonable reconstruction on the closely related Amargasaurus—an animal that’s known from a full skeleton, and whose neck spines were just as long and dramatic as Bajadasaurus’s. They differ only in their direction, sloping backwards instead of forward.

Given the similarity between the two animals, Gallina thinks it’s unlikely that Bajadasaurus had only one set of spines, which just happened to be on the one neck bone the team found. It’s also unlikely that the other spines bent in different directions, because that would have stopped the beast from raising or dipping its neck. And it’s equally improbable that the spines Gallina found had become distorted in the fossilization process, because none of Bajadasaurus’s other bones were warped. “We think we’ve done an accurate restoration,” Gallina says.

Bajadasaurus does have a modern equivalent—the potto, a small African primate that also has long, forward-pointing vertebral spines at the base of its neck. “The spines don’t protrude through the skin, but they do make a series of bumps that have been inferred to serve a defensive function,” says Matt Wedel of the Western University of Health Sciences, who runs a blog about sauropod vertebra. “The existence of such a similar defensive adaptation in a living animal is probably the strongest argument for a defensive function in Bajadasaurus.”

“In modern animals that exhibit these types of bizarre structures, they often serve multiple roles, sometimes functioning in display for mates and species recognition, as well as defense,” says Kristina Curry Rogers, a paleontologist at Macalester College. Given that the spines of different dicraeosaurs were so different, “display may have been just as important, if not more important, than defense, but we’ll have to wait for more discoveries to test these ideas more thoroughly.”

Gallina says that the rest of Bajadasaurus’s skeleton is probably still sitting in Bajada Colorada, but the area is such a mess of fossils that “it’s very difficult to recognize what is from this specimen and what is from another.”

But “even if we had the entire skeleton,” Wedel says, “it’s hard to find smoking-gun evidence of a defensive function in a fossil animal. In horned dinosaurs like Triceratops, we can go look for healed injuries on the frill, but short of finding a broken-off Bajadasaurus spine embedded in the face of a meat-eating dinosaur, we will probably not know for certain. Still, that’s part of the lure of paleontology: trying to see how much we can reasonably infer about the lives of these vanished creatures.”

In 2014, Gallina’s team unveiled another new dinosaur from Bajada Colorada. They named it Leikupal after the words for “vanishing family” in the language of the indigenous Mapuche people. It is also a sauropod, and at 30 feet, a relative pip-squeak in a lineage of giants.

At the opposite end of the size spectrum is what other Argentine paleontologists recently discovered, possibly the largest dinosaur of all time—the 130-foot, 69-ton Patagotitan. Other recent discoveries also include: Yi, a small, feathered predator with batlike wings; Kosmoceratops, with its row of comb-over horns; Concavenator, a predator with a small, pyramidal hump over its hips; and Halszkaraptor, an implausible murder-swan with a long, elegant neck; flipper-like arms; and Velociraptor-style sickle claws.

“We are still finding new dinosaurs, and the diversity is increasing year by year,” Gallina says. Which means that we’ll need to make room in the pantheon of exalted dinosaurs for more newcomers as metal as Bajadasaurus.



“Believing that it is always best to study some special group, I have, after deliberation, taken up domestic pigeons,” wrote one Charles Darwin in On the Origin of Species. Four years earlier, Darwin had taken to raising pigeons in his own dovecote, hobnobbing with other pigeon fanciers, and carefully measuring the birds. In the diverse breeds, with their fantails, feather-duster feet, and frilly backs, Darwin saw validation for his ideas about evolution. If people could artificially select for such astonishing diversity in just a few generations, nature was surely capable of far more over longer timescales.

Now, 160 years after Darwin published his opus, a team of biologists from the University of Utah have once again turned to pigeons to demonstrate evolution in action. But instead of focusing on the birds themselves, they turned their attention to the pigeons’ parasites.

In a simple experiment, Sarah Bush and Scott Villa placed feather-eating lice on different-colored pigeons and left them there to breed and evolve—for four years. Over that time, the insects adapted to better match the color of their host, which made them harder to spot and pluck off.

For Bush, this was “incredibly exciting”—an experiment that reminded her of the peppered moths she learned about in high school. Those insects normally have speckled white-and-black wings to camouflage against tree bark. But in 19th-century England, when coal factories blanketed trees with soot, the peppered moth quickly evolved into all-black forms. In doing so, it became a textbook example of evolution. Now perhaps Bush’s feather lice can join them.

Feather lice are small, wingless insects that spend their whole lives among the plumage of birds, eating feathers and flakes of skin. The discovery of a 44-million-year-old fossil louse with feathers in its gut suggests that “they’ve been doing the same thing since forever,” says Bush. Today, “there’s pretty much one species of louse per species of bird.” Their presence isn’t welcome, though, and birds will try to preen them from their plumage. The lice, in turn, hide through camouflage: In 2010, Bush and her husband, Dale Clayton, showed that lice tend to match the color of their host’s feathers.

To see how quickly the lice can adapt, Bush, Clayton, and their colleagues captured regular urban pigeons from around Salt Lake City and fumigated their feathers with carbon dioxide. Lice fell off them in droves, and the team transferred 2,400 of these insects onto 96 captive pigeons—some white, some black, and some gray.

For four years, the pigeons did whatever pigeons do. Meanwhile, for the lice, oceans rose, empires fell, and 60 generations came and went. Over that time, their colors changed. The lice on black pigeons became slightly darker, the ones on white birds became much brighter, and the ones on gray birds stayed the same.

But these changes occurred only if the pigeons could preen themselves. Bush stopped half the birds from doing so by fitting them with poultry bits—plastic clip-ons that prevented them from closing the very tips of their beaks. On those birds, the lice suffered no risk of removal, and their colors stayed the same. (The birds that couldn’t preen also ended up with 20 times as many lice—a clear sign of the strong evolutionary pressure that a beak can exert.) This clearly shows that the lice don’t automatically blend in when they arrive in a new environment. They do so specifically to avoid the attention of their hosts.

All the lice that Bush used belonged to the same species—Columbicola columbae. But by the end of the experiment, these individuals began to resemble other species that have been parasitizing different pigeons for millions of years. For example, the lightest individuals were just as light as Columbicola wolffhuegeli, a species that lives on one of the whitest pigeons—the pied imperial of Australia.

C. columbae and C. wolffhuegeli have been evolving independently for at least 20 million years, but in just four years, the former had changed enough to resemble the latter in color (although many other differences separate the two species).

This study reminds me of another ambitious evolutionary experiment that I wrote about earlier this year. In the hills of rural Nebraska, Rowan Barrett and his colleagues placed mice in large outdoor enclosures, built on light sand or dark soil. Over time, individuals that better matched their backgrounds were less likely to be eaten by owls—just as lice that blended in among their host plumage were less likely to be preened off.

Barrett’s team went one step further, though. It identified a gene that’s responsible for the rodents’ fur color, and it showed how variations in that gene became more or less common over the course of the experiment. It would be great if Bush and her colleagues could do the same for their lice, says Jessica Light from Texas A&M University. Still, as it stands, their experiment is already groundbreaking: Biologists “rarely, if ever” do evolutionary studies of this kind with parasites, says Light.

Which is odd because, as Bush says, “parasitism is the most common lifestyle on this planet.” It has evolved hundreds of times, and it’s likely that the majority of animal species are parasites. Many of these are confined to specific hosts. Feather lice, for example, are usually spread through direct contact between, say, parent birds and their chicks. But occasionally they can hitch a ride on more mobile parasites, such as flies, and end up on an entirely new host.

For them, that’s an event akin to a bigger animal arriving on a new island. Evolution tends to run wild on islands, as newly arrived animals quickly adapt to the new opportunities on offer and diversify into a riotous range of forms. The finches of the Galápagos, the tree snails of Hawaii, and the anole lizards of the Caribbean all arose in this way. But for a parasite, a host species can be an island—an isolated chunk of flesh with new opportunities to explore, and new challenges to overcome.



If you were to condense the planet’s 4.5-billion-year history into a single calendar year, then sometime from the 18th to the 20th of November, as conventional wisdom would have it, the animal kingdom would undergo a dramatic transformation. A world dominated by blobby, sedate creatures that sift seawater for food would suddenly give way to a new menagerie of active predators and prey, sporting innovations such as eyes, jaws, legs, and shells. The ancestors of all the major modern animal groups would appear, and seemingly take over from their predecessors.

This 20-million-year period is known as the Cambrian explosion, and few events in the history of the Earth have been so retrospectively hyped. It has been billed as “arguably the most important biological event after the origin of life,” “the most important geobiological revolution of the past billion years,” and “evolution’s ‘big bang.’” But a team of researchers led by Rachel Wood at the University of Edinburgh think the famed event wasn’t all that singular.

In a provocative new paper, they argue that the traditional explosion was bracketed by several equally important pulses of evolutionary innovation. In each of these, existing communities of species gradually bled into new ones, rather than being suddenly replaced. “It’s very difficult to pick out a discrete Cambrian explosion,” says Wood. “It’s more fruitful to think of it in terms of a very long narrative of change that started before, and continued long afterwards.” The Cambrian explosion, in other words, was just one burst in the middle of a protracted fireworks display.

“I think it’s a valuable reframing of the story,” says Phoebe Cohen, a paleontologist at Williams College. “The more we look at the Cambrian explosion, the less explosion-y it looks.”

The time before the explosion is known as the Ediacaran period. Running from 571 million to 541 million years ago, it marked the appearance of the first big, complex, living things. But what were those things? A weird miscellany of unfamiliar blobs, tall fronds, and ribbed mats, they were entirely unlike today’s animals, and some may not have been animals at all. Whatever they were, based on the fossil record, they seem to have suddenly disappeared when the Ediacaran gave way to the Cambrian period, and more recognizable animals arrived. That stark transition led some researchers to cast the Ediacaran biota as “failed evolutionary experiments” that were outcompeted by the ancestors of modern critters.

The divide between the Ediacaran and Cambrian has been so heavily mythologized that scientists who study the two periods became divided too. “You have people working on the Ediacaran and people working on the Cambrian, and they don’t really come together,” says Wood. But at a recent conference in the U.K, “a lot of us realized that those boundaries had started to become blurred.”

New fossils, she says, showed that some Cambrian-defining traits were actually pioneered in the Ediacaran. For example, fossilized tracks and burrows suggest that animals were already on the move about 25 million years before the Cambrian explosion. Hard shells and skeletons had also appeared pre-explosion, and some of these had boreholes, which hint that their owners were killed by drilling predators. Mobility, armor, hunting: These innovations were part of “a crescendo that started in the Ediacaran,” Wood says.

Recent finds have also reinforced the continuity between the pre- and post-explosion worlds. New fossils of a Cambrian animal called Stromatoveris showed that it’s related to an Ediacaran group called the petalonamids, named for their petal-like fronds. That connection shows that the Ediacarans were “alive and well over 20 million years into the Cambrian period,” wrote Jennifer Hoyal Cuthill from the University of Cambridge in The Conversation.

The Ediacaran biota wasn’t just a single set of organisms either. They were extremely variable, and appeared in distinct waves. First came the Avalon biota, characterized by stationary, fronded creatures that resembled kelp. Next up: the White Sea biota, which included mobile creatures such as Dickinsonia—a ribbed oval that was recently confirmed as an animal. Then the Nama biota—a so-called wormworld that ushered in tubular animals, including some with hard shells.

When the Cambrian fauna eventually arrived, Wood thinks it appeared in two pulses. The mollusks, for example, evolved just before the explosion, but most of the group’s early members died out in an extinction event 513 million years ago, in the early Cambrian. The lineages that gave rise to today’s mollusks—octopuses, clams, and more—flourished only after that point, in the late Cambrian.

That makes at least five distinct bursts of diversification that straddle the divide between the periods.

“There must have been some sort of biological continuity between the Ediacaran and the Cambrian, but the question is a matter of degree,” says Michael Lee from Flinders University. Did only a few Ediacaran lineages survive the transition to the Cambrian, or did many of them do so? Wood’s team is arguing for the latter; Lee still leans toward the former.

Lidya Tarhan from Yale University is more convinced. “There was considerable ecological overlap between the two communities,” she says. Rather than being distinct sets of losers and winners, Ediacaran and Cambrian animals were instead “part of an evolutionary continuum.”

Wood’s team also ties their biological narrative into a geological one. Others have argued that the Cambrian explosion was sparked by a rise in oxygen, which fueled the evolution of active behaviors and larger, gas-guzzling bodies. But the seas didn’t accumulate oxygen steadily or evenly. Instead, for much of the Ediacaran, levels of the vital gas fluctuated over time, and across different layers of the oceans. Wood and her colleagues suggest that these yo-yoing levels drove animal evolution: They created oxygen-rich oases that allowed new species to diversify in isolation, much as they do on today’s islands.

Those same dynamics might have repeated themselves at other pivotal moments. About 252 million years ago, at the end of the Permian period, the planet experienced its greatest mass extinction—a disaster that depleted much of the ocean’s oxygen and killed the majority of living species. But life rebounded immediately afterward, and that might have been driven by unsteady oxygen levels after the catastrophe. If this is right, Tarhan says, it suggests that “rather than being anomalous, the Ediacaran-Cambrian transition fits remarkably well within our understanding of other intervals of radiation and extinction.”

“This is an area of absolutely active debate,” Wood acknowledges. “Some people will agree, and others won’t, but I think that’s great. The diversification of animals is a profoundly important event, and we’re just adding a more holistic view of what happened.”



In the study of forests, a central mystery has long stood unsolved: The seed that falls far from the tree does a whole lot better in life than the seed that stays close. Though scientists have never fully understood the reasons behind this pattern, they believe that something about the soil of an adult tree makes it unfriendly to seeds of the same species.

In a recent study published in the Proceedings of the National Academy of Sciences, researchers grew seedlings in soil from various trees to probe this question. And they found an additional, fascinating wrinkle. The deadly effect is very particular: Seeds can actually grow relatively well in soil from trees of their own species. It’s the specific soil of their parents that afflicts them most.

Furthermore, the team believes that what ails the offspring is bacteria living in the soil of their parent trees—not dangerous to the adult, but somehow adapted to sicken its own seedlings.

In the past, scientists have considered many possible advantages to seeds flying farther from the feet of the adults of their species. This arrangement might encourage the growth of a wide variety of species, with the rare sheltering in the shadow of the common. Indeed, in tropical rain forests, there’s an enormous diversity of trees, all of them thriving together.

The team set out to examine several different variables, including the nutrients in the surrounding soil and the presence of symbiotic fungi, in a sampling of trees from a forest in Panama. The researchers put seedlings of the baboonwood—a tall, lanky tropical tree—in pots whose soil had been mixed with soil carefully collected from under the seedlings’ parents, from under other baboonwood trees in the forest, or from under trees of other species.

After eight months, they checked the total weight of each of the plants. That was when it became clear that there was a difference between growing in a parent’s soil versus another baboonwood tree’s soil.

“Being near another member of your own species is a much better situation for seedlings than being near their maternal plants,” says Jenalle Eck, a postdoctoral researcher at University of Zurich who led the study. In the past, experimenters had sometimes pooled the soil from all the trees of a given species, for simplicity. This would have obscured the effect that Eck and her colleagues saw, making it look like growing near any tree of the same species is harmful.

In contrast, there was no correlation between the nutrients in the soil or the symbiotic fungi and the final size of the plants. That confirmed a suspicion the researchers had—that something else living in the soil, probably bacterial, is to blame. The soil in the pots had been dosed with forest soil whose bacteria were intact. The bacteria in that dose would have spread throughout the soil, and if pathogens were present, they would have been able to infect the seedlings, hampering their growth.

The fact that such pathogens would affect only seedlings of a given parent suggests that they target something specific to the offspring’s genome. A computer model built by the researchers to show how such genotype-specific pathogens might work confirmed that their presence would produce the patterns the team saw.

Such pathogens might build up over time in the soil around a tree, Eck says. They might not be present in the soil around a newly sprouted tree, but once it has matured into adulthood, the tree might draw them with its constant rain of young unable to fend off an attack. “Essentially, as these trees live over decades and they every year produce offspring, it attracts ... pathogens that affect those offspring,” Eck suggests. The identity and the workings of such pathogens are still unknown, but Eck and her colleagues are hoping to answer these questions in future research.

For a forest, the implications of being controlled by bacteria might be profound. If pathogens can limit the growth of offspring near their parent trees, then they can shape the pattern of species intimately. Of course, the exact effects would depend on just how bad it is for seeds to fall near parents, compared with falling somewhere else, Eck points out. But over evolutionary time, the bacteria might select for plants that can cast their seeds far and wide.

“There is increased selection pressure for seeds to disperse,” she says, “because basically no matter where they land, they’re better off.”



Eighty-six Americans lost their lives last year in the Camp Fire, the largest and deadliest wildfire in California’s modern history. More than 11,000 people lived through the blaze but saw their homes destroyed. On Wednesday, President Donald Trump threatened to cut off relief for survivors and communities affected by that blaze, amid an ongoing political standoff with high-ranking California politicians.

“Billions of dollars are sent to the State of California for Forest fires that, with proper Forest Management, would never happen. Unless they get their act together, which is unlikely, I have ordered FEMA to send no more money,” he said on Twitter. “It is a disgraceful situation in lives & money!”

It was not immediately clear whether Trump had actually stopped the funds from flowing. Neither the Federal Emergency Management Administration (FEMA) nor the Department of Homeland Security responded to repeated press calls on Wednesday. “Due to the federal funding hiatus, we are not able to respond to general press queries,” said an automated email reply from FEMA staff.

But if Trump does tamper with emergency relief, there is little doubt that Californians will feel the bite. FEMA has already approved almost $49 million in assistance for more than 6,600 individual projects across the state. And until Trump sent his tweet, that number seemed certain to grow. Many residents have yet to apply for aid, since FEMA’s deadline for new grant requests is January 31.

Ernest Abbott, an attorney at Baker Donelson and FEMA’s general counsel from 1997 to 2001, told me that the White House could decline to authorize new funds for California without running into major legal obstacles. But it would struggle to withhold the $49 million that FEMA had already approved, he said.

“Under the Stafford Act, the president and FEMA have the discretionary authority to provide assistance to state and local governments,” he told me. The key word there is discretionary, meaning that when a disaster strikes, the president is not legally required to spend any money under the law.

That initial decision, to grant funds or not, cannot be challenged in court except on constitutional grounds (such as accusations of racial bias), Abbott said. But once FEMA has approved funds, courts can oversee any decision to withdraw them.

But Abbott admitted that it was difficult to know what, if any, legal action the president actually intended in his tweet. “I really don’t know how this one-sentence directive will be implemented,” he said.

In that way, Trump’s threat—or is it an order?—captures his presidency in microcosm. If Karl Marx wrote that history repeats itself, “first as tragedy, then as farce,” then Trump offers the experience of watching farce and tragedy happen simultaneously.

Farce: The president’s tweet isn’t just factually wrong. It points to an understanding of California’s fire problem that conflicts directly with what experts and firefighters describe. It is not clear that better forest management—especially raking and clearing, the techniques that Trump favors—would entirely prevent California’s ravenous wildfires. In any case, the U.S. Forest Service has currently stopped all forest-management work due to the government shutdown.

There are policies that could improve California’s resilience to wildfires. PG&E, the local electric utility, could update its infrastructure, reducing the chance of a power line sparking an errant blaze. For the past century, fire departments have fought virtually every forest fire; western forests are now packed with brush, debris, and dense stands of trees. The state or federal government could try to clear that fuel by attempting controlled burns—although experts say those burns would have to be of a much larger scale than virtually any equivalent burn now attempted in the United States.

The United States could also try to slow climate change, which has turned hot days into heat waves and verdant forests into dry tinderboxes. Between 1984 and 2015, the effects of climate change may have doubled the acreage burned by western wildfires, according to a recent study cited in the National Climate Assessment. But Trump, of course, has rejected both that assessment and most of the conclusions of climate science. He has fixated instead on raking forest floors.

Which brings us to tragedy: Not only is the president wrong, but he may have also turned an ordinary duty of the federal government—providing disaster relief to its citizens, swiftly and fairly—into a cudgel of partisan politics.

Trump makes no secret of his special ire for the Golden State, dubbing it “High Tax, High Crime California.” He has undermined its environmental laws and attacked its protections for unauthorized immigrants. Now, after reneging on a deal to fund the federal government last month, Trump finds himself battling Nancy Pelosi, the new speaker of the House and a Democrat from San Francisco, over $5 billion in funding for a border wall with Mexico.

Trump has always elided Pelosi and her home state together—he once labeled her “High Tax, High Crime Nancy Pelosi.” It’s hard not to read his sudden, surprising threat to cut off California’s FEMA funding in the context of his siege on Pelosi. Never mind that Paradise, California, the city destroyed by the Camp Fire, voted for Trump in the 2016 election and is represented by a Republican in Congress.

On Wednesday, that Republican, Representative Doug LaMalfa, said that Trump’s threat “is going to get a lot of people upset and concerned.”

“That tweet came out of left field. It didn’t really help in that situation,” he told reporters near the House floor. “Now we’re working to make sure our constituents know—and I will be [reminding] them—that he made the promise [to them] when he came to visit Paradise, which is greatly appreciated, and that FEMA has been great so far in helping.”

Vann Newkirk contributed reporting to this article.



It is not the job of presidents to know the specifics of space exploration and its mind-bending physics, or to contemplate deeply the timescales and technology required for a high-stakes mission to another planet. But usually they have some sense of what’s remotely possible, and of what they’ve asked their space agency to do.

In the spring of 2017, President Donald Trump signed a significant piece of legislation about the future of NASA. The bill, among other things, reaffirmed a top priority for the American space program: sending humans to Mars by the 2030s.

Then, it seems, the president forgot all about it.

A month after signing the bill, Trump reportedly asked the then–acting administrator of NASA whether the space agency could send American astronauts to Mars by the end of his first term, and even offered him “all the money you could ever need” to make it happen. The NASA official politely turned him down, explaining that such a fast turnaround to a distant planet wasn’t possible.

The exchange, which took place in the Oval Office, appears in Team of Vipers, a forthcoming book by the former White House official Cliff Sims, and was first reported by New York magazine this week.

For anyone who knows about space travel, this encounter amounts to a breathtaking misunderstanding by a leader of the state of his nation’s space program. But it’s only the latest such mishap in Trump’s presidency. More than many presidents, Trump has been eager to talk about American ambitions in the cosmos. But his enthusiasm has clashed with his disinterest in the details of the complicated, risky requirements of actually sending people off this planet.

According to Sims, the discussion he describes took place at the White House in April 2017, as Trump prepared to make a very long-distance video call from the Oval Office to the International Space Station. Peggy Whitson, a NASA astronaut, had broken the American record for the longest time spent in space, and the president was going to congratulate her.

About 10 minutes before the call, which was live-streamed to the public, Trump “suddenly turned toward” Robert Lightfoot Jr., the acting administrator, and asked him, “What’s our plan for Mars?”

Lightfoot explained that NASA hopes to put people on the planet by the 2030s.

“But is there any way we could do it by the end of my first term?” Trump asked.

Sims writes that a fidgeting Lightfoot tried to explain some of the technical challenges of a Mars mission.

Trump was undeterred: “But what if I gave you all the money you could ever need to do it? What if we sent NASA’s budget through the roof, but focused entirely on that instead of whatever else you’re doing now. Could it work then?”

Lightfoot said he was sorry, but no. The interaction, according to Sims, left the president “visibly disappointed.”

NASA directed my questions about this exchange to the White House. The White House did not respond to multiple requests for comment.

The call with the International Space Station began soon after. The question of Mars seemed to have stuck with Trump and, apparently unsatisfied with Lightfoot’s answer, the president decided to ask Whitson, the astronaut.

“What do you see a timing for actually sending humans to Mars? Is there a schedule? And when would you see that happening?” Trump asked.

“Well, I think as your bill directed, it will be approximately in the 2030s,” Whitson replied.

“Well, we want to try and do it during my first term or, at worst, during my second term,” Trump said. “So we’ll have to speed that up a little bit, okay?”

“We’ll do our best,” she said, with a laugh.

At the time, the brief exchange came off as a mix of enthusiasm and confusion on Trump’s part. “Based on how he said it, it seemed like it was a tongue-in-cheek comment,” a White House spokesperson told me then. “I wouldn’t really look beyond that.” But according to Sims’s account, the president was apparently serious about getting to Mars during his presidency.

To echo Lightfoot, that’s not possible. The money would certainly be welcome, of course. (Congress would also have to approve it.) What government agency would turn down presidential support for a budget influx? Especially NASA. During the Apollo era, the agency’s annual funding accounted for 4.5 percent of the federal budget. It shrunk to less than half a percent by the end of Richard Nixon’s term, and has remained there since.

But cash is no substitute for time, and space travel is difficult to rush, even with Cold War tensions hovering menacingly in the background. Eight years elapsed between John F. Kennedy’s declaration to go to the moon and Neil Armstrong’s first steps on the lunar surface, and several Americans died in the effort to get there.

Timing beyond Earth matters, too. A Mars mission would ideally leave Earth when the two planets are close together in their orbit around the sun, a cosmic alignment that occurs every two years. The configuration would help shave off a few months on the journey to the red planet. Trump would have only two chances in the rest of his term and in a potential second term to deploy a crewed mission, 2020 and 2022. NASA isn’t ready for either.

The United States currently can’t launch its own astronauts from its own launchpads, and pays the Russian government tens of millions of dollars per seat on the Soyuz launch system to carry astronauts to the International Space Station. NASA is working on a rocket designed to someday send astronauts to the moon and Mars, the Space Launch System, but a test flight, with people on board, won’t come until 2022.

Off the ground, the technical challenges of a Mars mission would be immense. Armstrong and two other astronauts got along just fine in a cozy space capsule, but it took the astronauts just over three days to reach the moon. A trip to Mars would take as long as nine months, and astronauts would require a far more complex vessel. It would need to be hardy enough to protect them from cell-warping cosmic radiation, and roomy enough so people don’t get on one another’s nerves. This miraculous technology does not exist.

There’s an easy explanation for why Trump wants to send Americans to Mars during his presidency. It’s the same reason he enjoys speaking publicly about space exploration in general, and has actually done so more than other presidents, according to historians: People think space is cool. That includes congressional lawmakers, and space exploration enjoys some rare bipartisan support on Capitol Hill. For Trump, space policy is a safe topic. It’s an instant applause line. It gets good ratings, and to Trump, that’s what matters.

In February 2017, days after the inauguration, the White House made a surprising request to NASA. The administration asked the space agency to consider including a crew on the first flight of the Space Launch System. NASA had planned to put people on board only after a successful, uncrewed flight, a standard move for testing new rocket technology. NASA conducted a review exploring the option, but decided to stick to the original plan.

The Space Launch System, it turned out, had made it onto a list of moments that could bolster Trump’s legacy. “The common thread among many of the policy options, transition and industry officials said, is a focus on projects able to attract widespread voter support that realistically can be completed during Mr. Trump’s current four-year presidential term,” The Wall Street Journal reported at the time.

The attraction to visible, historic achievements has led Trump to confuse space policy more than once. In February 2018, Trump, like much of the public, was enamored with the spectacular launch of the Falcon Heavy, a massive rocket built by Elon Musk’s SpaceX. He praised the feat during a televised meeting at the White House with Cabinet leaders. He praised it so much, in fact, that he ended up undermining NASA’s own rocket efforts.

“Rich guys, they love rocket ships,” the president said. “That’s good. That’s better than us paying for them. And I noticed the prices of the last one, that they said it cost $80 million. If the government did it, the same thing would have cost probably 40, 50 times that amount of money. I mean, literally, when I heard $80 million—you know, I’m so used to hearing different numbers with NASA.”

Indeed, he is; NASA has already spent several billion dollars on developing the Space Launch System. Each launch is expected to cost about $1 billion. Whether he meant to or not, Trump appeared to suggest that commercial companies would do a better and cheaper job of launching rockets than NASA. And he did it while a small replica of the Space Launch System sat on the table in front of him.

Despite Trump’s outsized interest in Mars, his administration’s space policy has taken a different direction since that spring meeting in 2017. In October of that year, the White House announced a dramatic shift in NASA’s directive for the future. This was not a complete surprise; new presidents have tended to introduce fresh directives for NASA’s future that diverge from those of their predecessors. George H. W. Bush proposed an ambitious plan that instructed NASA to simultaneously develop a space station above Earth, a mission to the moon, and a mission to Mars. Bill Clinton made no mention of sending Americans anywhere beyond Earth. George W. Bush instructed NASA to establish a program that would return Americans to the moon by 2020. Barack Obama canceled it, and told NASA to work on a Mars mission for the 2030s instead.

Under the Trump presidency, NASA would shoot for the moon, again. Mars would come eventually, but not before American astronauts stepped onto the lunar soil once more. NASA leaders spent eight years talking up a trip to Mars. Now they’re touting a return to the moon. Jim Bridenstine, the NASA administrator, has said the agency seeks to land rovers on the surface of the moon as early as sometime this year, and “definitely” by 2020. As for a crewed mission, Bridenstine has said, “I don’t have a time frame for that at this point.”

If the Lightfoot encounter is any indication, that’s the kind of answer that Trump doesn’t like. But that is the reality of space exploration. It takes years, sometimes decades, and delays are common. If technical difficulties don’t derail the schedule, politics will; programs supported by one president can get tossed out by the next. The actual, real work of building missions usually outlasts presidents. The commander in chief who will lead the nation to humankind’s first steps on Mars is not in the White House, and may not be for years to come.



Carbon-dioxide emissions from the United States spiked sharply in 2018, bucking a three-year trend and making it more likely that the country will fail to meet its promises under the Paris Agreement on climate change, according to a preliminary analysis published Tuesday.

The new study—written by the Rhodium Group, an energy-research firm—found that emissions of the heat-trapping gas leaped by 3.4 percent, the second-largest increase in more than two decades. The emissions surge was driven by a number of factors: Americans flew more, shipped more goods by truck, and burned more heating oil during a frigid winter.

Even emissions from power plants went up, after years of declines. A record number of U.S. coal plants closed in 2018, but a booming natural-gas sector gobbled up those declines and generated most of the year’s growth in electricity, too. 

U.S. carbon emissions are still down from their historic peak in 2005. But they have not fallen nearly far enough. Under the Paris Agreement, the Obama administration voluntarily promised to cut U.S. emissions by at least 26 percent by 2025, as compared with 2005 levels. Though President Donald Trump pulled out of the Paris Agreement in 2017, the United States is still technically subject to the treaty until next year, and dozens of liberal states and cities have pledged to uphold its terms. 

Despite those commitments, the United States has lost ground on its Paris goals. In 2017, emissions were 14 percent below their 2005 peak; now they are only 11.2 percent below peak. The country could still make its Paris targets, the report says. But meeting that goal will require either an aggressive new federal climate policy or “favorable market conditions” in the next few years. There is no seven-year period on record when U.S. carbon emissions have fallen as quickly as they must between now and 2025.

“The U.S. was already off track in meeting its Paris Agreement targets. The gap is even wider headed into 2019,” the report warns.

The Rhodium report is not the first clue that 2018 was basically a terrible year for the climate. Last month, two studies also found that worldwide carbon emissions surged in 2018. This change is a discouraging sign, since global emissions stagnated through the middle of the decade.

“From 2014 through 2016, we saw emissions that were flat while the global economy grew,” says Rob Jackson, an author of one of the studies and a professor at Stanford University. It was a “great outcome,” he said, because it suggested that the worldwide economy could grow without also boosting carbon emissions. Some analysts had even hoped that worldwide carbon emissions were about to peak.

“Now we’re back to a much faster rate of increase,” Jackson told me.



In July 2016, Kiyomi Murakumo of the Okinawa Churaumi Aquarium was giving a pregnant tawny nurse shark an ultrasound, when she saw the unmistakable outline of a moving baby shark.

It’s not unusual to see a shark swimming around. It’s far more unusual when that shark hasn’t been born yet. And in this case, the unborn shark wasn’t just fidgeting—it swam from one of its mother’s two uteri to the other.

“When [Kiyomi] told me about it, I asked her to repeat herself,” Taketeru Tomita, the aquarium’s shark expert, told me. “I couldn’t believe my ears.”

Murakumo’s experience wasn’t a one-off. Tawny nurse sharks grow up to nine feet in length but have a docile temperament, which makes them easy to work with. Over the next two years, the team found evidence of these in utero migrations in three pregnant females.

Sometimes, a single embryo would show up in the right uterus during one scan, and in the left one during the next. One female had four embryos inside her, sometimes split evenly between her uteri and sometimes all on one side. And on several occasions, the team actually caught the embryos swimming over, at a leisurely pace of three inches per second.

This is one of several discoveries that contradict the idea of embryos as immobile entities, incapable of anything more than gently moving their limbs or heads. For example, turtle embryos can shift around inside their cramped eggs to snuggle up against the warmest sides.  

The babies of the sand tiger shark are also mobile—for more sinister reasons. After these sharks mate, several fertilized eggs settle in each uterus. The first embryo to hatch, still inside the mother, will always attack, kill, and cannibalize the other eggs. These unborn sharks are active enough that Stewart Springer, the first biologist to discover their behavior, was bitten by one while sticking his finger into the birth canal of a recently caught female.

This grisly behavior gives sand tigers an invaluable head start in life. After gorging themselves on their siblings’ nutritious bodies, the surviving embryos—one per uterus—get unchallenged access to a steady supply of unfertilized eggs that their mothers release. On this diet, they grow at an exponential rate. By the time they’re born, they’re already three feet long, and invulnerable to many predators.

The tawny nurse shark embryos don’t cannibalize their siblings, but like the grey nurses, they also eat unfertilized eggs released by their mothers. That’s probably why they move between uteri. They’re foraging for eggs while still inside the womb—a useful skill, especially when other embryos share the same space. “Instead of the embryos eating one another, they appear to be competing,” says Toby Daly-Engel, a shark expert at the Florida Institute of Technology. “That’s just the coolest thing ever.”

Opportunities to uncover the surprises hiding inside sharks are only getting scarcer, though. The tawny nurse shark is classified as vulnerable, and like many sharks, it’s in decline. Its flesh and fins are used as food, and its skin is turned into leather. Even thriving populations have problems: At the Bikini Atoll, once the site of much nuclear testing, many tawny nurse sharks are born with a missing dorsal fin.

“This one obscure species can teach us so much,” Daly-Engel says. “The information is out there, but it’s at risk.”

No one knows if pregnant females from other shark species are also full of active, competitive babies. Certainly, few scientists have the ability to even check. Murakumo and Tomita could do so only with a bespoke ultrasound machine that they co-developed with a company that makes underwater cases for cameras. “The embryonic behaviors of live-bearing sharks are still almost unknown,” Tomita said. “Every discovery is unexpected.”

For example, in the female with four embryos, one of them briefly stuck its head out of its mother’s cervix. The team noticed its fleeting foray into the outside world on their ultrasound, and then saw its face sticking out of the female with their own eyes. What was it doing?

“It’s the mystery,” Tomita said. “We would like to know, too.”



In August 2011, with Hurricane Irene bearing down on the mid-Atlantic coast, Scott Glenn, an ocean-engineering researcher at Rutgers University, made a bold decision. While most other research teams moved their ships, personnel, and expensive hardware to safety ahead of the hurricane, Glenn left his data-collecting drone—a torpedo-shaped underwater “glider” about six feet long and worth about $150,000—directly in its path.

Because that remote-controlled glider survived Irene—much to the relief of the New Jersey Department of Environmental Protection, which technically owned it—it may have helped change the science of hurricane-intensity prediction.

Hurricanes are considered atmospheric storms even though they can’t live without drawing fuel from warm ocean water. While scientists have long known that hurricanes leave the ocean below them substantially cooler as they pull up energy from warm water, forecast models have long assumed that ocean conditions are slow to change and therefore factor them in as constants rather than driving factors in determining a storm’s strength.

But Glenn challenged that assumption when his drone detected a rapid and sharp drop in ocean temperature ahead of Irene’s eye that coincided with a decrease in the storm’s intensity just before it hit the New Jersey shore. He confirmed that discovery in reverse 14 months later when a rise in water temperature as Hurricane Sandy approached the same New Jersey shore coincided with an increase in the storm’s intensity.

“It’s very simple,” Glenn says. “If the ocean’s warm, it increases intensity. If the ocean’s cool, it decreases intensity. So if you want to get the intensity right, you have to get the ocean right.”

If Glenn is correct, and data like his can be made available to meteorologists and researchers in a timely way, it could dramatically improve the accuracy of hurricane-intensity forecasting, which has barely budged in recent years even as track forecasting has gotten better by orders of magnitude. It could also benefit emergency agencies, particularly in cases where residents have ignored warnings because previous forecasts were overblown.

“It makes all the sense in the world,” says Jennifer Francis, a senior scientist at the Woods Hole Research Center in Massachusetts who specializes in Arctic climate change and how that affects weather patterns in the middle latitudes. Until recently, Francis worked in the same department as Glenn at Rutgers, but she conducted no joint research with him.

“This really key factor is probably going to offer a big step forward in doing a better job with intensity forecasting,” Francis said.

Until drone gliders came along, forecasters had no way of knowing what was going on below the ocean surface during a storm. Unlike the hurricane-hunter aircraft that fly into and around storms, it’s too dangerous to leave ships in their path to take measurements. And satellites—which can measure surface temperatures only under the best of conditions—can’t detect anything through storm clouds.

Glenn and other ocean researchers have been using underwater gliders since around the turn of the millennium, recording data such as temperature and salinity over deep and large areas not otherwise easily accessible. The gliders have no engines. They use a battery to operate a pump system that sucks in water to shift weight to make them move up and down in the water at about half a mile an hour. An inflatable bladder allows the tail of the glider to surface and transmit some of its information by satellite, making it readable in close to real time on monitors virtually anywhere. The battery also operates the glider’s computer, instruments, and satellite communications, and can last for months.

At the time of Irene’s approach, Glenn was measuring water quality when he decided to leave his glider in place to collect further readings during the storm. His data, which weren’t fully analyzed until afterward, showed the water temperature dropped 6 to 11 degrees Celsius in the hours before Irene’s eye passed through. “We saw that there was a big change,” says Glenn, a distinguished professor in the Department of Marine and Coastal Sciences and co-director of the Center for Ocean Observing Leadership at Rutgers.

“Most of the literature talks about the cooling that happens after the hurricane passed,” he says. In this case, “the eye’s not even there yet, and it’s already cooled. That was new.”

Not only that, but the forecast that Irene would reach the New Jersey coast as a Category 1 storm turned out to be wrong. It hit instead as a tropical storm, one category weaker than predicted.

The mid-Atlantic region where Irene came ashore—along with a few other regions around the world, such as the Yellow Sea—have dramatic seasonal ocean-temperature swings and a clearly defined “cold pool,” or reservoir of cold water that sits below layers of warmer water in summer. As Irene approached from the south along the continental shelf, the data showed that it churned up the cold pool into the warmer upper water so that the overall water temperature dropped dramatically before the storm hit land.

“That’s like going from summer to winter in 12 hours for the ocean,” says Travis Miles, an assistant professor at Rutgers who was a Ph.D. student working with Glenn at the time. “In the open ocean, hurricane researchers, when they look at temperature drops that might affect intensity—1 degree Celsius can have a significant impact.”

Even though the colder water caused the storm to de-intensify, Irene still caused plenty of problems—especially inland as far as Vermont—but it was less than advertised in coastal New Jersey.

Beyond the glider data, Glenn’s team conducted more than 130 computer simulations, using all kinds of variables, from currents to salinity levels, to figure out what contributed the most to the de-intensification. “Just changing the temperature was the most important thing by a factor of two or three to any of the other factors,” he says.

Then they went through 30 years of data from the National Oceanographic and Atmospheric Administration’s (NOAA) National Data Buoy Center. Even just looking at near-shore temperatures before and after storms, the team could see that all 11 hurricanes that went through the mid-Atlantic in summer experienced ahead-of-eye cooling. They also examined data from Typhoon Muifa in the Yellow Sea in 2011, finding that the storm de-intensified as a result of cold pool and warm water mixing as it approached Asian coastal areas.

“So it wasn’t just Irene,” says Glenn. “It was physics that was happening in hurricane after hurricane after hurricane. Nobody thought to even look at it.”

When Sandy hit a little more than a year after Irene, the team had an ideal chance to retest its findings. “We purposely put the glider in before Sandy,” Glenn says.

Sandy came in slowly from the east, perpendicular to the New Jersey coast. In the three days it took the hurricane to come ashore, the winds piled the upper-level warm water onto the shoreline, forcing the lower-level cold pool offshore. When Sandy finally hit, that cold pool was all but gone, leaving nothing but pure warm water—hurricane fuel.

“You can mix warm water all day, and it’s going to stay warm,” Glenn says. “All it’s going to do is contribute to intensify the storm. Sandy actually intensified a little bit as it came onshore.”

This time Glenn’s team could see it as it happened, but there was no way to officially provide that information to forecasters. “I was sitting in a friend’s apartment in Manhattan with my computer open, watching that cold water move offshore in real time the day before, and I knew it was going to be bad,” Miles says. “There was no cold water left to cool that down like we saw in Irene. We knew in real time what was going to happen.”

Chris Slocum, a postdoctoral fellow in the Tropical Cyclone Group at the Cooperative Institute for Research in the Atmosphere at Colorado State University, is researching the atmospheric processes that control hurricane-intensity change. “It will fill an information gap,” he says of Glenn’s findings, noting, as did others, that the ability to collect data that were never available before was itself a huge advance. But, he adds, “there are other pieces of information we also still lack that are equally critical for hurricanes.”

He and others point to research on hurricane-eye walls and what’s known as the radius of maximum winds, the distance between the storm’s center and its most intense winds. And he says the energy exchange between the ocean and the atmosphere needs fine-tuning. But, he admits, “if we don’t get the ocean right, we’re going to be wrong.”

While no one discounts the value of monitoring ocean temperatures, most researchers caution against applying the Irene and Sandy findings too broadly. Mid-Atlantic conditions are fairly unique worldwide. Farther south, where water stays warmer, there is a less-defined cold pool that can produce the kind of mixing the Rutgers team detected. And in the Gulf of Mexico, a strong flow of warm water known as the Loop Current has effects on storms that don’t exist in the mid-Atlantic region.

“This isn’t like some silver bullet that’s suddenly going to make our intensity forecast better all the time, because there’s a lot of other processes that also affect intensity,” says Mark DeMaria, the technology and science branch chief at the National Hurricane Center and a member of the Hurricane Forecast Improvement Project. While DeMaria and others believe there has been some improvement in intensity forecasting, he adds that “we still have a long, long way to go.”

Rutgers researchers have continued analyzing data to confirm their findings. In 2017, for example, they determined that Hurricane Jose, which never hit land directly, intensified because of conditions similar to Sandy’s. And they documented Typhoon Soulik’s de-intensification in 2013, the result of cold pool and warm water mixing as it approached coastal areas of East Asia—similar to what happened with Irene.

They have published their findings in peer-reviewed journals, given talks all over the world, shared their research with other academic institutions, and made their case repeatedly to government agencies involved in hurricane forecasting.

Part of their goal is to make sure officials know when expensive and difficult evacuations are warranted and when they’re not. To do so, the data need to be assimilated into existing models that atmospheric scientists use for hurricane predictions. Glenn and others say the current computer models are so faulty that the Rutgers temperature data have typically been rejected because they have been so different—a disconnect that exposed a longtime rift between the atmospheric and oceanographic camps.

But the Rutgers team has strong allies. One is the Integrated Ocean Observing System, or IOOS, part of NOAA’s National Ocean Service. Rutgers is a member of one of its 11 regional partnerships, the Mid-Atlantic Regional Association Coastal Ocean Observing System, a consortium of academic, governmental, and industry partnerships that runs from Cape Hatteras to Cape Cod.

“We see this as a huge opportunity to make a major impact at a relatively modest cost,” says Gerhard Kuska, the mid-Atlantic consortium’s executive director. “I think it’s a missing link in our region and may be in others.”

A critical mass of glider data from the 2018 hurricane season may finally convince hurricane forecasters and researchers that there is a large enough body of data to show that Glenn’s findings are more than isolated instances.

He has the Navy to thank for that. This past hurricane season, it tripled its glider-fleet deployment to about 100, making 30 of them available for hurricane patrol. That enabled Glenn’s team to collect data from dozens of gliders—at least 10 times more than it had ever had—in observational “picket lines” off Africa, where hurricanes form, as well as in the Caribbean, the Gulf, and the Atlantic.

“The key is that they’re there. If there’s any uncertainty in the track—it’s not like they’re going to miss one glider and then not hit any,” says Miles. “This is the first year where I didn’t have anxiety that we were going to have a storm and not capture data.”

Gliders were sent in as both Hurricanes Florence and Michael made landfall. The team’s initial analysis found that Florence de-intensified very rapidly and came ashore weaker than expected, though the major issue was still rain, which caused catastrophic damage. Michael did the opposite—rapidly intensifying as it came ashore.

“I can’t tell you why Florence de-intensified,” says Glenn. “There was no cold pool—the water was all warm.” As for Michael, the water around the storm was also quite warm. “Eighty percent of cooling was after the eye passed,” he says.

Glenn’s team expects to have that figured out by late spring, after they sort through 123,000 data profiles from gliders and an additional 7,800 data sets from floating monitors. The live data from the 2018 gliders were added for the first time to a database called the Global Telecommunication System, which is accessible to forecasters worldwide. But it’s unknown whether anyone has used it or even knows how.

“It’s good that I know it, and it’s good that I can transfer this knowledge to another human forecaster, but what we want to do is put this knowledge in the physical models so the models can better predict these things,” says Glenn, who admits being frustrated with the slow pace of his data’s inclusion when lives are at stake in these storms.

“The programs are dominated by meteorologists. They should be dominated by meteorologists—it’s mostly a meteorology problem. It’s a hurricane in the atmosphere,” he says, chuckling. “But they have to let a few of us oceanographers in the room.”



This post appears courtesy of Undark Magazine.



In 1976, Alejandra Melfo and her family joined the tens of thousands of Uruguayans fleeing their country’s military dictatorship. Melfo, who was 11 when her family arrived in Venezuela, remembers delighting in the lighthearted Venezuelan national anthem, and realizing that her blond hair and pale skin were unremarkable in a country where generations of Portuguese, Spanish, and Italian immigrants had also found refuge and opportunity.

When Melfo was a teenager, she and her family moved to the prosperous university city of Mérida, in the mountains of western Venezuela, and she became one of the many foreign-born students at the University of the Andes. The Venezuelan government had invested a sizable portion of the country’s oil wealth in education and research, and the university—the first in Latin America to be connected to the internet—was known throughout the continent and beyond for its scientific accomplishments. For Melfo, it became a professional home: A theoretical physicist, she joined the faculty even before she completed her doctorate, and served as a professor at the university for 25 years.

Though Melfo officially retired in 2016, she is one of the few faculty members still on the job. As Venezuela has descended into political and economic crisis, the university has endured rising street crime and armed raids of campus buildings. Professors and students have left in droves, and classrooms are dark and empty; because of the country’s crushing inflation, the remaining professors earn as little as $3 a month.

Melfo, who once focused her considerable energies on supersymmetric theory, now has a more tangible and pressing concern. High in the mountains above Mérida lie the fast-melting remnants of Venezuela’s once-extensive glaciers, and when they’re gone, the unique organisms they contain will also be lost to time. Melfo can no more save her adopted country’s glaciers than she can reverse its political and economic unraveling—but she knows Venezuela’s glaciers have a scientific legacy, and that she is determined to protect.

Mérida lies on a high plateau at the foot of the Sierra Nevada de Mérida, a range that includes five of Venezuela’s highest peaks: Humboldt, Bonpland, El Toro, El León, and Bolívar, all more than 15,000 feet above sea level. Thousands of years ago, the ridgelines of the Sierra Nevada were crusted with as much as 50,000 acres of permanent ice, which was protected from the tropical sun by aspect and elevation, and which advanced and retreated in response to global temperature cycles. By the 1830s, when the Italian soldier and geographer Agostino Codazzi surveyed the area on behalf of the newly independent Venezuelan government, a prolonged global cooling period now known as the Little Ice Age was coming to an end, and the glaciers were shrinking.

Locals noticed the difference: “For some time now, people have been saying that the snow in the Sierra is decreasing,” the Mérida storyteller Tulio Febres Cordero wrote in 1890. “The older neighbors point out, with sadness, all the places where the snow has completely disappeared.”

In 1910, detailed maps made by the Venezuelan explorer Alfredo Jahn showed that the Sierra Nevada glaciers had shrunk to a total extent of about 2,500 acres. In the small mountain towns above Mérida, some men still made a living as hieleros, or ice men: With machetes, they would chop blocks of ice from the glaciers, wrapping hundred-plus-pound blocks in thick leaves and storing them in leather suitcases. The hieleros would make the six-hour journey to Mérida, transporting the ice-filled suitcases by mule or on their own backs. The ice blocks, much diminished, would then be used to make the glacier-sourced ice cream sold in the central market.

Over the past century, as human activities increased global average temperatures far beyond those experienced during previous warming cycles, glacial melting in the Sierra Nevada accelerated. An aerial survey in 1952 showed that the total glacier area had shrunk by almost three-quarters in the previous four decades, to about 700 acres. By 1985, it was down to 200 acres, and in 2008, fewer than 80 acres of glacier remained.

Average temperatures in Mérida are about 10 degrees warmer than they were 20 years ago, but the area is still much cooler than the rest of the country, and until the recent upheaval in Venezuela, the city was a popular destination for domestic and foreign tourists. Merideños pride themselves on their politeness and hospitality, and would often point the way to local attractions: glacier-fed mountain lagoons, the country’s national astronomical observatory, or the highest cable car in the world, which carries visitors from the edge of the city toward the top of the 15,633-foot-high Pico Espejo. Near the summit, in 1961, Venezuela held a national skiing competition. Under the right conditions, it is still possible to see snow.

In 2008, the Venezuelan ecologist Ángel Viloria predicted that the country’s glaciers would be entirely gone by 2020, making Venezuela the first country on Earth to lose all of its glaciers. Viloria, the director of the Venezuelan Institute for Scientific Research in Caracas, not only backed up his prediction with decades of research and observations, but also bluntly assigned blame: Human-caused climate change, he said, was largely responsible for the melting.

Government officials quickly disputed Viloria’s prediction. They claimed that the data he’d cited weren’t reliable; that the melting was caused not by human activities but by a long-term warming cycle; that a new era of “global cooling” would soon restore the glaciers.

Global cooling, however, did not come to the rescue. In 2009 and 2011, when the Venezuelan geologist Maximiliano Bezada and his American colleague Carsten Braun conducted the most recent aerial and ground surveys of the glaciers, they estimated that there were only 25 acres of ice left, all of it in a single glacier on Pico Humboldt.

“Glaciers have been a part of the identity of the Venezuelan mountains and their people for a long time, and their disappearance will leave a gap—both physically on the landscape, but also—and perhaps more importantly—spiritually. It was ‘normal’ to go to the mountains and see the glaciers. The ‘new normal’ for future generations will be a different Sierra Nevada,” Braun says.

Andrés Yarzábal, a microbiologist at the University of the Andes who had studied the effects of climate change in Antarctica, recognized that unique organisms were likely disappearing along with the ice. Though spending cuts by the Chávez government had made government research grants almost impossible to come by, Yarzábal managed to secure some support from the National Fund for Science and Technology for what he called the “Vida Glacial” project, including an expedition to Pico Humboldt and its glacier in 2012. The trek took five days, and the frigid, blustery conditions were grueling; to sterilize their collecting instruments, Yarzábal and his colleagues had to hunch over camp stoves in the freezing wind.

Alejandra Melfo, meanwhile, was expanding her research interests beyond physics to molecular biology and genetics, and a friend introduced her to Yarzábal. Like many others, she had noticed the retreat of the Sierra Nevada’s snow and ice, and she was both intrigued by Yarzábal’s research and impressed by the urgency of his mission. Melfo helped organize and search for private funding for a second expedition, this time to the glacier on Pico Bolivar, which has since disappeared. Melfo trained for several months with a professional climber before the expedition, and even helped Yarzábal through a life-threatening bout of altitude sickness during the trip.

Together, the two expeditions yielded 600 microbial strains, now stored in deep freezers at the university. About 30 percent of the strains have been identified so far; most are previously unknown to science, and among them are bacteria capable of dissolving phosphorus, an essential plant nutrient. “We were able to show that they behave as growth promoters of certain plants at low temperatures, so it’s possible that they could be useful as biofertilizers,” Yarzábal says. Such fertilizers, he says, could improve the sustainability of agriculture in mountain regions.

After Chávez’s death and the 2013 election of his successor, Nicolás Maduro, scientific research in Venezuela became even more challenging. Inflation made it difficult to buy basic lab supplies, much less the thousands of dollars of food, medicine, and equipment required for another glacier expedition. Outbreaks of street crime and paramilitary violence in Mérida made it dangerous for university researchers to work in the labs during weekends or at night. “We sometimes had to abandon experiments for weeks at a time,” Yarzábal says.

Yarzábal had even greater fears. His two children, 7 and 8 years old, were leaving school one afternoon when they heard gunshots. It turned out that another father from the school had witnessed an attempted kidnapping nearby, and used his own gun to kill two of the kidnappers.

Yarzábal, who, like Melfo, had emigrated from Uruguay to Venezuela as a child, realized that he had to leave the country that had once given him refuge. Yarzábal signed up with Prometeo, an Ecuadorian government program aimed at attracting scientific talent, and he and his family moved to Ecuador during his sabbatical year in 2014; he now works at the University of Cuenca.

This past fall, the only trained microbiologist left in the laboratory was Johnma Rondón, the second-youngest researcher on the entire Vida Glacial project team. Rondón, who helped identify the microbial strains from the glaciers as part of his doctoral dissertation, was responsible for maintaining the strains stored in the freezers in Yarzábal’s lab—no easy task in a country where power failures are frequent. “Many times I would come to the lab on Mondays to find puddles of water around the freezers caused by prolonged blackouts,” he says.

On October 28, Rondón left Venezuela, too, becoming one of the estimated 3 million Venezuelans—some 10 percent of the population—to have emigrated in recent years. The border between Venezuela and Colombia, once one of the busiest in the world, is now closed to traffic, so Rondón planned to cross the border by foot. He made a farewell visit to the lab, leaving some climbing gear with Melfo in hopes that she would once again be able to access the glacier. Melfo hugged him goodbye.

When Rondón reached the border city of Cúcuta, Colombia, he traveled to the Colombian capital of Bogotá, and from there to Buenos Aires, Argentina. He is now a postdoctoral student in Argentina, and unless conditions change in Venezuela, he doubts he will return.

Melfo kept a blog during this time, writing not only about fermions and glaciers but also about longing. She described the absence of her colleagues; the quiet labs; the empty homes inhabited by caretakers who water the plants in exchange for shelter.

“M. doesn’t work in the lab anymore,” she wrote in November. “Neither does A. or W., or J., who was the last to leave. Inside, the work tables are clean, the test tubes sit on their shelves, the Petri dishes are inside their sterile bags; the samples are inside the fridge, in the right order, frozen. J. didn’t erase the blackboard, and it still has an equation on it. The lab still has the quality of a home, even though A. has taken his kids’ pictures. It still echoes with the joy M. felt when the money for the incubator finally arrived, and the laughter of W. His lighter is still in the place he left it.”

Melfo and a few university colleagues continue to maintain the freezers, though blackouts are frequent and often lengthy. With no resources to continue her work in molecular biology, she is once again expanding her research interests, this time into ecology, and she and a handful of remaining biology students are monitoring the impacts of climate change on high-altitude biodiversity as part of the GLORIA-Andes project. They must write up their field data forms by hand because their printers have run out of ink. Their rubber boots are broken; their camping tents, and even their gloves and scarves, are borrowed. Supplies are stored in a recycled cardboard box once used for government-subsidized food staples. “Someone will donate a bit of cooking oil, others will give some rice, and when we have collected enough, we head out,” Melfo says. If the weather turns bad during a day of fieldwork, they put up umbrellas and and keep going, because rescheduling the trip would require too much gasoline.

“Five years ago, even three years ago, we had scholarships for postgraduates and funding for expeditions,” Melfo reflects. “Now we are a poor country, without money for fieldwork.”

Melfo continues to seek international funds and support for glacier research in Venezuela. She edited a book, Se Van Los Glaciares (The Glaciers Are Going), that includes chapters written by Yarzábal, Bezada, and others, and drew national media attention when it was published last summer. She says she still hopes to return to the highest peaks of the Sierra Nevada: She wants to see what kind of bacteria are left in the remaining ice, and what the retreating glacier has revealed. Even when the glaciers completely disappear, she argues, the decades of data and the surviving microbial samples can be used for comparative studies in the Andes and elsewhere. “The investigation of the glaciers of Venezuela has no expiration date,” she says.

On December 11, International Mountain Day, the president of Venezuela’s National Parks Institute, Josué Lorca, visited Mérida to announce measures intended to lengthen the life of the glacier on Pico Humboldt—the same glacier whose pending disappearance the government denied a decade ago. During Lorca’s press conference, officials presented plans to clean up waste from the national park near the glacier, demarcate safe camping areas, and ban tourist visits to what’s left of the ice. They refused to take reporters’ questions.

Melfo spent the Christmas holiday with her family in Uruguay, but she has returned, once more, to the empty lab, the broken boots, and the handwritten data sheets. She has returned, voluntarily, to the country that welcomed her as a child. She says she doesn’t want to leave a place that truly feels like hers, or abandon the few remaining students who insist on continuing their studies. The Sierra Nevada of Mérida, she says, is her home—even though it rarely snows here anymore.

Translated from Spanish by Ruxandra Guidi.

Life Up Close is a project of The Atlantic, supported by the HHMI Department of Science Education.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?



Anela Choy studies the things that deep-sea creatures eat, which means that, in effect, she is often studying plastic. Over the years, pieces of debris would show up again and again in the stomachs of certain fish, species that rarely come to the surface to feed. The plastic, she realized, must be going down to them.

Microplastics—tiny pieces less than five millimeters in size—have largely been studied as a problem of the ocean surface. Plastic tends to be buoyant, the thinking goes, and the ocean surface is frankly easier to study. But Choy, who is a biological oceanographer now at the University of California at San Diego, wanted to go deeper. In 2017, she and a team sent a specially designed remote-operated vehicle (ROV) down 3,200 feet in California’s Monterey Bay, systematically sampling up and down the water column.

It turns out that far more microplastics are hidden deep in the ocean than on the surface. The ROV found the highest concentrations of microplastics in water 200 to 600 meters, or 650 to 2,000 feet, below the surface. What’s more, those levels were comparable to the concentration closer to the surface of the infamous Great Pacific Garbage Patch, where ocean currents trap microplastics.

If anything, Monterey Bay is famously clean. “The Monterey Bay is considered a success story. It’s a beautiful place. The sardine and fish population have come back from crashes in the mid-1900s,” says Kyle S. Van Houtan, the chief scientist at the Monterey Bay Aquarium and a co-author of the study. “However, if you go below the surface, there’s more of a concentration of plastic than where many people consider the dirtiest: the Great Pacific Garbage Patch.”

In another way, though, all the plastic in the deep ocean is not a surprise. Scientists estimated the amount of plastic going into the ocean, and the number far exceeded what they were seeing in the water. “We’ve known for a long time if we just sample from the ocean surface, it doesn’t add up, so it must be going somewhere,” says Tamara Galloway, an ecotoxicologist at the University of Exeter who was not involved with the study. Where the missing plastic went was down.

The team also found microplastics as deep as they could sample with their ROV, which was 3,200 feet. Earlier this year, another group found plastic fibers in the guts of animals that live in the 36,000-foot-deep Mariana Trench, the lowest point on Earth. The Monterey Bay study suggests that microplastics are not just present below the surface of the ocean, but may be abundant.

Choy says it’s unclear exactly why most of the plastic seems to be hanging out in the 200-to-600-meter zone. There could be physical explanations, such as the density of the plastic and the movement of water. There could also be biological explanations, such as the way plastic moves through the food web. Choy and her team’s ROV also collected “sinkers,” which are sticky mucous houses that animals called larvaceans build and discard every day. Larvaceans use their mucous houses to filter feed, and they invariably catch microplastics. As sinkers fall through they water, they bring nutrients down to the deep sea. Anglerfish, vampire squid, and deep-sea cucumbers all eat sinkers and, consequently, they all eat microplastics.

When animals eat microplastics, they are, obviously, not eating food. The material can clog their guts. The chemistry of plastic also means the material tends to attract pollutants in the ocean water, making it even more dangerous to eat.

After Choy and her colleagues collected all of their microplastic pieces, they wanted to identify the kind of plastic, too. “That was a very—oh my gosh, that was a very manual effort, if you’d like,” she says, clearly remembering exactly how much work it took. Her co-authors at Arizona State University sorted hundreds of pieces of microplastic by hand and identified the plastic using a laser. They found that most of the plastic was polyethylene terephthalate, the type that goes into single-use plastics such as food packaging.

As the problem of plastic pollution has gained attention, so have viral solutions, such as the Ocean Cleanup, a 2,000-foot-long floating boom meant to collect plastic on the surface. The tube broke in testing, without collecting much plastic (a result experts could have predicted). The deep ocean is harder to reach, dark, cold, and under immense pressures. It’s hard to imagine how to even begin removing plastics there. “The best approach is to stop chucking so much in the ocean in the first place,” Galloway says. “That’s always going to be the best approach.”



In the debate over whether human beings should set off to other worlds beyond Earth, one of the most compelling cons is this: Our bodies don’t like it.

Few people know this better than Scott Kelly, the NASA astronaut who spent nearly a year on the International Space Station from 2015 to 2016. Like other astronauts, Kelly served as a test subject in the study of space travel’s effects on the human body. Unlike other astronauts, Kelly has an identical twin, Mark, an astronaut himself. This gave researchers an uncommon opportunity to monitor the two brothers as they lived in two very different environments—one on Earth and the other 250 miles above it.

According to their results, published Thursday in Science, Scott experienced a number of changes that Mark did not. Most of those changes went away after Scott returned to Earth. The long stint in space, the researchers say, produced some unexpected changes—but did not lead to any clinically significant health differences.

The body, sensing and reacting to weightlessness, bristles at life in space. Fluids float freely and clog the sinuses, giving faces a puffy appearance. Bones, relieved of the job of bearing weight, thin. Muscles, faced with the same, atrophy. Parts of the eyeball, for reasons scientists are still trying to pin down, become squished or swollen. And from head to toe, cells, exposed to unearthly levels of radiation, become more at risk for cancer.

Only the brain seems to love it; after all, it’s the one that fervently processes the beautiful views of the gleaming planet below, delights in the somersaults made natural by microgravity, and comprehends—or at least attempts to comprehend—the wonder of being there, in outer space.

Scientists had expected some of the changes observed in Scott, based on earlier research of astronauts. Some of the effects were no more dramatic than stress-related changes studied on Earth—and space travel is certainly stressful. The others, such as the eyeball squishing, can clearly be attributed to Scott’s unique experience in space.

But that’s where the explanations end. With all the variables involved, isolating a single cause is nearly impossible. Researchers can’t know whether the changes were caused by microgravity, increased exposure to radiation, lack of air circulation, sleep disruption, a diet of freeze-dried food, or the stress of living in a cramped metal tube with the same people, day in and day out.

Some of the most intriguing changes occurred at the chromosomal level, in the protective bits at the ends of chromosomes that make sure they replicate properly when cells divide. These caps, known as telomeres, are known to shorten as a result of stress. Researchers expected to see this change in Scott. Instead, the astronaut’s telomeres lengthened. “You might at first think, Oh, this is great. He’s going to live longer,” Susan Bailey, the Colorado State University professor who led the telomere research, once told me. “But the opposite side of that coin is always that it also increases cancer risk, because one of the very first things cancers do is turn telomerase on to maintain telomere length so they can essentially be immortal.”

Most of the telomeres bounced back after Scott returned to Earth, but he now has more short telomeres than he did before his mission. In general, this puts someone at greater risk for quicker aging, Bailey said.

Researchers found some surprises in Scott’s gene expression. On Earth, changes in gene behavior occur in response to shifts in routine activities, such as sleep and diet, and Mark’s gene expression changed as well. But the changes to Scott’s gene expression were distinct, and scientists were stunned at the number of changes they recorded, especially in mitochondrial genes, which help the body produce energy, and in genes related to the immune system. More than 90 percent of these genes returned to normal when Scott came back. (This doesn’t mean, researchers are careful to note, that the rest are somehow “mutated,” as some news reports erroneously suggested last year.)

Researchers also detected changes in the mechanism that cells use to control gene expression, but they were too tiny to matter by the time Scott came back.

“We don’t know yet if these changes are good or bad,” explains Christopher Mason, a geneticist at Weill Cornell Medicine in New York who led this part of the research. “This could just be how the body responds. But the genes are perturbed, so we want to see why and track them to see for how long.”

That seems to be the theme of most of the findings: Something changed, probably because Scott was in space, but it’s not clear whether that’s a good or bad thing.

Like other astronauts, Scott’s retinal nerve thickened, but whether his long-term vision will be affected is unclear. One category of bacteria in Scott’s gut increased, while another decreased; the ratio returned to normal after the mission, and the shift remains a mystery. Scott’s cognitive abilities, which improved during his mission, sharply declined after he came back, and though they rebounded, they never returned to preflight levels. Scientists suspect that the sudden return to gravity played a role, but so could have the sudden return to interacting with more than the six people he saw constantly. Part of it could even have been the fault of people like me—the deluge of journalists who wanted to talk to Scott after he landed.

“Post-mission schedules—science and media events—are often very hectic and could have contributed to the decline,” says Mathias Basner, a psychiatry professor at the University of Pennsylvania’s Perelman School of Medicine who designed the cognitive-performance tests.

From the outset, researchers expected to find uncertainty in these results. The research, funded by NASA, is a case study of a single patient: Scott. Any detectable changes could be the result of space travel—or of differences in experiences, or of random chance. The findings cannot be extrapolated to the wider astronaut population, let alone the general population. Nor are they very useful for predicting what might happen to humans if they venture beyond the orbit of the ISS, where the protective properties of Earth’s magnetic field are still felt. Here, astronauts receive 10 times the usual amount of radiation, high-speed particles from the sun or from other sources in the cosmos. Out there, the exposure would be far worse.

Scott Kelly retired from NASA in 2016, about a month after he returned to Earth and his body began to adjust. For some time, his legs felt jiggly, his joints ached, and his skin burned, unused to the touch of fabric, hugged close to him by gravity. Space, he said back then, had been disorienting. “Even after I’ve been here nearly a year, you don’t feel perfectly normal,” he said. “There’s always a lingering something you feel. It’s not necessarily uncomfortable, but it is a harsh environment.”

The study of the twins doesn’t have to be over. Another important mission is coming up: the 2020 election. Mark Kelly, also retired, is running for a Senate seat in Arizona. Maybe some researchers would like to see how astronauts do in a different kind of stressful situation.



Here in Maryland, where I live, monarch butterflies were everywhere last summer. Some days I saw several black-and-orange visitors wafting past or opportunistically sucking nectar from nearby flowers. It was a dramatic—and welcome—contrast to recent years, when I would have counted myself lucky to notch that many encounters in a season.

Monarch butterflies are in trouble, and when scientists report each new drop in overwintering monarch-butterfly populations, the alarmed headlines emerge as predictably as monarchs used to in summer. This season, the population that congregates in Mexico and breeds in the eastern and midwestern U.S. is doing relatively well, but the one that migrates up and down the West Coast appears to be on the brink of collapse. The attention these migrations receive, and the desire it reveals for a connection to ever-dwindling nature, mark a growing, collective sense that humanity’s impact is reaching a breaking point. The monarch, the polar bear: Like the whales that inspired 1970s conservation, they have become our bellwethers.

But choosing one insect to represent a huge swath of nature is both reductive and potentially dangerous. Scientists, environmentalists, and the public have vested the butterfly’s fortunes with such symbolic weight that the disappearance of its migration could be interpreted as an irreparable catastrophe. Yet the monarch is actually an outlier among insects—one whose abundance humans have unwittingly enhanced.

The end of the monarch migration would be a huge loss. But it need not take away our faith in nature’s resilience. Millions of other insects and ecological relationships all around us—literally in our backyards—represent nature just as fully as the monarch. We need to get to know them too.

Since it was first definitively reported, in 1857, the monarch butterfly’s annual migration has become a potent symbol of what we in North America mean when we say “nature.” Millions of monarchs alight northward from Mexican and Californian forests every spring. They find milkweed plants and mate; females lay eggs. Caterpillars hatch, feast, chrysalize, and metamorphose into new butterflies, which set off northward toward yet new breeding grounds. Come fall, the great-grandchildren and great-great-grandchildren of the original migrants head south, returning to trees that neither their parents nor even their grandparents ever knew.

But the bounty we have come to expect exists in part because earlier generations altered our landscape to make it possible. Monarch-butterfly caterpillars eat only leaves of plants in the milkweed genus, and the most important milkweed species for monarchs—common milkweed—grows best in open, recently disturbed areas. Nature, of course, creates disturbances such as wildfire and grazing bison. But few forces restructure landscapes as efficiently and on such large scales as humans—especially technologically advanced ones.

Since the first people walked across an icy land bridge onto this continent, we humans have profoundly altered it, wiping out dominant animal species, setting fires to keep land open, and farming. Native Americans used common milkweed for food and likely increased its abundance. Then European settlers cleared forests and native prairies, and reworked the landscape into a patchwork quilt of small farms where “weeds” such as common milkweed readily grew in margins, along fences, and between crop rows—where they benefited from fertilizers added to aid crops. Could a better monarch-butterfly habitat have been designed?

Before 1492, most of the eastern U.S. was forested. In Maryland, for example, forest cover was about 95 percent; milkweeds—and monarchs—would have at most occupied small clearings. More than half of that forest has since been replaced by farms and other land cover. “There is little doubt that land-use changes over the last 200 years have greatly aided the expansion of milkweeds,” a Canadian biologist wrote in 1996, adding that this expansion led to a “demonstrable increase in the abundance and distribution of Monarchs in Ontario over the last 5 decades.”

In the West, where the butterfly has lately generated headlines, humans also helped monarchs, starting around the time of the Gold Rush, by planting Australian eucalyptus trees along the California coast. Groves of eucalyptus are now among the butterflies’ favorite roosting spots; they also seem to enjoy Russian olive. This has put conservationists in the odd position of championing non-native trees to try to save a native insect.

Farming and land clearing did reduce the abundance of some milkweeds, such as those that live in prairies. But only in recent decades have human activities become a clear threat to monarch butterflies. During that period, American farms consolidated, and farmers began planting from fencerow to fencerow, applying powerful insecticides and adopting genetically engineered crops that allow for mass herbicide spraying, which has reduced monarchs’ breeding habitat. Logging in the Mexican forests has cut into monarchs’ winter habitat. Warming weather, a parasite that infects monarchs that overwinter in the U.S. South, and collisions with cars on highways are also taking a toll. Choose almost any large-scale environmental concern—climate change, agricultural chemicals, GMOs, deforestation, suburban development—and the beleaguered monarch seems to embody it.

Nothing, perhaps, is more natural than wanting to save nature. Nearly everyone, in one way or another, cherishes and wants to preserve a remembered or mythologized environment that seems less impacted and more whole.

But most of us—and I want to be clear that I include myself—are confused about what the actual nature is that we want to protect. Humanity’s environmental footprint has been so heavy for so long, and we know so little about the life around us—much less about the myriad complex interactions that sustain this life—that we may have little sense of what was here before us, and what is here because we are here. Often we seek to preserve a version of nature that is already profoundly altered and simplified.

Many of us have grown so used to the tiger-colored insects casually flitting through our fields and gardens that the thought of their absence is almost too much to bear. So rather than reforest places that were once forested, conversation-minded people plant yards and parks with milkweed and nectar-producing plants, seeking to attract monarchs.

That in itself is surely harmless, and plants that attract monarchs also benefit many others. (More than 450 insects are known to eat common milkweed.) There is danger, however, in pinning so many hopes on one charismatic species. This is obviously not how nature operates. It goes instead for strength in numbers and diversity; it hedges its evolutionary bets with a profusion of forms.

The sheer numbers can defy belief. According to the Biota of North America Program, Prince George’s County, where I live, is a national hot spot for plant biodiversity. Somehow, even in this highly populated and developed suburban jurisdiction, with a several-century history of deforestation and farming, more than 1,200 native plants have been documented. Every one of those plants harbors its own retinue of native insects, which feed everything else.

The closer you look, the more astounding it can get. The entomologist Douglas Tallamy has found 879 species of moths alone on his property. And there are probably many more out there. “I can still go out in my backyard and find an undescribed species without a whole lot of trouble,” he told an audience at the Audubon Naturalist Society in Chevy Chase, Maryland, in December. Tallamy does not live in a remote nature preserve; he lives on a fairly modest 10-acre lot in the Pennsylvania exurbs, where he has judiciously cultivated insect-harboring native plants.

The rest of the insect world might be subtler than the gaudy monarch; more time and work are required to get to know it. But that knowledge can open up a richer and more empowering conception of nature than one gets from hanging everything on the success or failure of a single species of butterfly. This work starts with recognizing the hidden biodiversity that lurks everywhere—under the leaves in our gardens and the bark of our trees, in the soil, and even inside shivering dried-out flower and grass stalks that provide homes for native bees in winter.

“If you want the zebra swallowtail, you have to have pawpaw,” says Tallamy. “If you want the oak-leaf skeletonizer, you need oaks.” Few of us can effortlessly rattle off plant-insect mutualisms like this. But we can learn which plants host the most insect species—oak, cherry, and willow top the list in my neck of the woods—and choose them over conventional landscaping fare.

“Our life is frittered away by detail,” Thoreau wrote. “Simplify, simplify.” In nature, life is not frittered away by detail; it is detail. Complexify, complexify.

So where does that leave us with the monarch? Compared with most of the species Tallamy has found in his yard, the monarch butterfly was probably an occasional visitor to this part of the world back when forests dominated. Seeking to preserve the monarch migration means holding on to something that we have, to a large extent, helped create. There’s nothing wrong with that. I view it as the same impulse that drives us to protect farmland from suburban sprawl, or antiquities from decay and destruction. I believe the great (and, sadly, recently deceased) monarch expert Lincoln Brower might even have been hinting at this with his favorite answer to a persistent question: What difference would it make if the monarch migration ended?

“What difference would it make if we lost the Mona Lisa?” he countered. The modern, continental-scale monarch migration could indeed be one of humanity’s greatest works.

However, I would argue that, with its endlessly superfluous and stunning and, frankly, often absurd life forms—from speckled and polka-dotted and eyespotted moths to apocalyptically armored beetles to the hundreds of thousands of wasp species that lay eggs inside caterpillars and other insects so that hatching larvae can eat their hosts from the inside—nature has produced a strange and wonderful body of work that outshines even the monarch migration.

And here I think the Mona Lisa analogy suggests a second point: We care about the monarch and its migration not because it is useful to us, but because it is something far more important than useful—it is meaningful, and beautiful, to us.

The same is true for nature’s riotous, unruly, unreasonable abundance. Utility will never provide a compelling rationale for preserving biodiversity. We’ve grown wealthy even as we’ve driven species to extinction. The authors of a major recent UN report warn that if we continue to pummel the biosphere, we will pay the price at some point, in the form of food insecurity, polluted water, and other lost ecosystem services. In the long term, they are right, of course. But I suspect we can probably continue on our current exploitative path for some time before the toll becomes obvious.

This wealth may look good on a balance sheet. But if it comes at the expense of nature, it is an impoverished kind of wealth.

Think about how your heart might lift upon seeing a monarch butterfly. Now imagine that moment multiplied by thousands. That’s what awaits those who open their eyes to the full bounty of nature around them. It’s what happens when the dormant plants you put in the ground last fall open up in April, and previously unseen bees and butterflies and flies show up from who knows where to feed, so numerous and so busy that at times the Earth itself seems to vibrate. I myself have experienced only the first fleeting glimpses of this, but I’m already hooked.



No one today quite understands how they did it, but people in the Stone Age could turn ribbons of birch bark into sticky, black tar. They used this tar to make tools, fixing arrowheads onto arrows and blades onto axes. And they chewed it, as evidenced by teeth marks in some lumps.

These unassuming lumps of chewed birch-bark tar turn out to be an extraordinary source of ancient DNA. This month, two separate research groups posted preprints describing DNA from the tar in Stone Age Scandinavia. The two papers have not yet been peer reviewed, but they are already generating excitement about what they herald.

“It’s really amazing,” says Pontus Skoglund, an ancient-DNA researcher at Francis Crick Institute who was not involved with either study. Ancient DNA from human bones and teeth have recently revolutionized the study of the past, but many cultures over time did not bury their dead and left no remains to analyze. Chewing gum could fill in some of the gaps. It could also reveal a wealth of additional information, such as who helped make the Stone Age tools, what they ate, and what bacteria lived in their teeth.

The first new paper describes human DNA from three 10,000-year-old pieces of birch-bark tar, all found at a site called Huseby Klev in western Sweden. Having never extracted DNA from tar before, the team tried a protocol originally designed to extract DNA from feces—and it worked. Each piece of tar appears to have been chewed by just one person. In total, the tar pieces captured the DNA of two females and one male.

The site where the lumps were found was littered with the raw material and leftovers from making stone blades. From this, the authors suggest that it was actually a site for making tools, and chewing birch-bark tar was a step in the production process. If so, it would mean both men and women made tools during the Stone Age. And because some of the teeth marks appear to be from baby teeth, it suggests that children had a role, too. All this hints at the social structure of Stone Age society. “The most exciting part is how close we can come to the culture,” says Natalija Kashuba, a researcher at the University of Oslo and first author on the paper.

Ancient DNA can be prone to contamination from modern humans handling the sample. In this case, however, the DNA in the chewing gum appears to be genuinely ancient. “It’s very clear the DNA they get out has ancestry that was only there around 8,000 or 5,000 years ago, and it’s not really there anymore,” Skoglund says. The DNA of the three people looked a lot like the DNA of other hunter-gatherers who lived in northern Europe around that time.

In a second paper, researchers predicted the physical appearance of a 5,700-year-old woman based on chewed birch-bark tar found in Denmark. To modern eyes, she would have looked unusual. She had dark skin, dark hair, and blue eyes, all of which were characteristic of Europe’s hunter-gatherers then. A recent reconstruction of Cheddar Man, a 10,000-year-old hunter-gatherer skeleton found in Britain, also revealed dark skin and blue eyes.

The second team analyzed nonhuman DNA in the chewing gum, too. “You can recover microbial DNA,” says Hannes Schroeder, an ancient-DNA researcher at the University of Copenhagen who led the study. “And this opens up whole other possibilities.” Other groups have studied ancient plaque that built up over years on teeth, but the chewing gum provides an instant snapshot of what was in the mouth. It’s comparable to how scientists study the oral microbiome of people today, and unsurprisingly, the microbial species they found were broadly similar. There were differences in two types of microbes called Veillonellales and Neisseriales, which the team suggests may be due to hunter-gatherers eating fewer carbohydrates before the advent of farming.

They also found direct evidence of what the woman ate, in the form of DNA from mallard duck and eel in the chewed tar. This matches up with archaeological evidence at the site, including duck bones and tools for catching eels.

In the Stone Age, the area where this woman was chewing and spitting out birch-bark tar was a lagoon. Today, it’s the site of a massive construction project for a tunnel connecting Denmark and Germany. Theis Jensen, a graduate student in Schroeder’s research group, had helped with pre-construction excavations, and he was the one who convinced colleagues at Museum Lolland-Falster, which is responsible for the excavations, to hand over a piece of birch-bark tar to test. Using the DNA contained within, the team has been able to piece together what one 5,700-year-old woman looked like, what she ate, and even the microbes living in her mouth. “It’s like having the ghost in front of you,” Jensen says.

For all the questions it could answer, birch-bark tar is still at the center of many mysteries. Making it requires a steady application of heat and an oxygen-free environment, and archaeologists aren’t quite sure how people in the Stone Age achieved this without ceramic pots. It’s also unclear exactly why they chewed it: Was it for recreation or health or for making tools or all of the above? Whatever it was, the people who chewed birch-bark tar unwittingly left behind a rich record of the past.



The great thing about tobacco pipes, according to Julie Schablitsky, is that they are hard to not find. They were ubiquitous in the 17th, 18th, and 19th centuries—to the point, she says, that “wherever you have people during this historic period, you’ll find these clay tobacco pipes in the ground.” And wherever these people left broken tobacco pipes, they were also unwittingly leaving their DNA.

Traditionally, the archaeological study of DNA has focused on human remains such as bone and teeth. But geneticists are now able to extract DNA hidden inside ordinary objects, including tobacco pipes, which can contain centuries-old saliva. Schablitsky, an archaeologist with the Maryland State Highway Administration, and her collaborators recently analyzed the DNA from one such 19th-century pipe—uncovered in the slave quarters of a Maryland plantation called Belvoir.

The DNA showed that a woman had used the pipe, and her genetic ancestry most closely matched people living today in Sierra Leone. She was most likely enslaved on the plantation.

Schablitsky got the idea to analyze DNA on the pipe from talking to descendants of people enslaved at Belvoir. When her team first found the slave quarters in 2014, they got in touch with a historian who specializes in local African American history and spread the word. The news eventually reached Shelley Evans, a retired Baltimore City schoolteacher. She had found records of her ancestor Thomas Burley, a freeman, buying his wife and daughter out of slavery at Belvoir. “My third great-grandmother, she lived here,” says Evans. “She was born there. Her mom and dad had to have been there as well.” The pipe could have belonged to one of her ancestors.



So while excavating the slaves’ quarters, Schablitsky and her team collected pipe fragments, using sterilized forceps to prevent contamination. They particularly focused on the pipes, because clay is porous, which means the DNA in saliva can easily penetrate inside. By contrast, DNA only sits on the surface of metal artifacts such as jaw harps or forks, and it’s unlikely to be present after decades in the ground.

Schablitsky sent four pipe samples off to an ancient-DNA lab at the University of Illinois at Urbana-Champaign. One of the four yielded enough DNA for further analysis. Unfortunately, the DNA was still too degraded to link to individuals alive today. But the Illinois lab got in touch with Hannes Schroeder at the University of Copenhagen, who specializes in working with ancient and degraded DNA.

Schroeder’s lab uses algorithms to compare genetic material from old samples with that of modern reference populations around the world. He had previously used DNA to trace the origins of enslaved people buried on the Caribbean island of St. Martin. A 2015 paper connected these people to Bantu-speaking groups in Cameroon and others in present-day Nigeria and Ghana.

Schroeder applied the same techniques to DNA taken from the pipe in Belvoir. Of the African reference populations, the woman in Belvoir was most similar to the Mende people in Sierra Leone.

Recent research on ancient DNA has invested artifacts with new significance. The DNA in the clay pipe, for example, contains within it a record of the transatlantic slave trade. “You start with one small insignificant piece of tobacco pipe, and you end up talking about one of the most significant events in American history,” says Schroeder.

Given the ubiquity of tobacco pipes, Schablitsky hopes that fellow archaeologists will start using them as a source of old DNA to fill gaps in history. Few records exist, for example, of exactly where in Africa enslaved people came from. You might imagine an alternative record written in the DNA inside clay pipes that dot the landscape. Theresa Singleton, a professor at Syracuse University who studies the archaeology of slavery, said the discovery in Belvoir holds “great promise” for future research—but the cost of DNA analysis may put it out of reach for some archaeologists.

Another limitation is that geneticists have historically sampled relatively few Africans. “The reference database for Africans and also for the diaspora is still very weak,” says Fatimah Jackson, a biologist at Howard University. (Jackson is collaborating with Schroeder on another project, but was not involved in this one.) For example, the woman smoking the pipe in Belvoir most closely matched Mende people in the existing reference database—but she might be more closely related to another group whose DNA is not even in the database. The only way to know is to go out and collect more samples. This problem is compounded by the fact that people in Africa are more genetically diverse than people on other continents. Geneticists such as Jackson are currently working to diversify reference data sets, but it is a problem that still besets both genetics research and consumer DNA tests such as those offered by 23andMe and AncestryDNA.

In 2018, four years into the Belvoir excavation, archaeologists discovered they might not be limited to DNA from the tobacco pipe after all. Just a short walk from the slave quarters is a burial ground with as many as dozens of people. The archaeological team asked the descendants, including Evans, whether they wanted to test the DNA in the bones buried there. “I hope that comes to pass,” says Evans. Her ancestors might be buried there. The woman who smoked the pipe might be buried there.



In the middle of the night, the view from the rooftop of my eight-story building is bursting with light. The bright beams of passing cars throw luminous tracks across the pavement, and the windows of homes and offices, restaurants and shops, glow gold even from miles away. The Washington Monument cuts the night sky like a birthday candle in a dark room. The stars, the radiant objects that gave rise to this cityscape—to all things, really—are nowhere to be seen. If a pinprick of light does shine through, it might be a star—or, as you’d soon realize, it might be another artificial fixture of the modern world, a plane or a satellite.

Many city dwellers have all but given up on seeing a night sky glittering with countless cosmic specks. We settle for a sprinkle here and there, if we’re lucky, or the moon. Even outside dense urban centers, light pollution has become inescapable for most people on Earth, and things aren’t getting any dimmer. Some light-loving crusaders have proposed adding more artificial light—even an artificial moon—to the night sky, raising an uncomfortable but intriguing question: What if we gave up on the stars altogether?

What if, instead of sentencing ourselves to many more years of starless night skies, we constructed a new one, furnished with artificial objects launched high into space, engineered to do the twinkling instead?

This would be a depressing defeat, and quite dystopian. When I asked John Barentine, the director of public policy at the International Dark-Sky Association, a nonprofit that works to mitigate light pollution, he began to lament. “How incredibly disconnected we have become from that aspect of nature,” Barentine said.

He wouldn’t be surprised if it happened someday, though. A redesign of the night sky might sound like science fiction, but humankind has been dramatically altering environments on Earth for even longer. Outer space was just another one. When human beings finally reached it, fairly recently in our history, some transformation was inevitable.

The first generation of satellites in orbit around Earth, in the 1950s and 1960s, were a hit. Stargazers marveled as they passed overhead, visible only during twilight, when sunlight could still reach the objects. The satellites’ shiny surfaces caught and reflected the sun’s rays, appearing as tiny pinpricks gliding against the dimmed sky. Today, you can get text alerts about when to look for the brightest satellite in orbit, the International Space Station.

Thousands of satellites have been launched into orbit since humankind became a spacefaring species. The majority provided the same set of functions, such as communication, navigation, and spying.

But recently, there’s been an uptick in some unconventional uses.

Last year, the American company Rocket Lab launched a spherical satellite named Humanity Star that had no function except, as its CEO said, to unite people, “no matter where you are in the world, rich or in poverty, in conflict or at peace.” In December, a Nevada museum paid SpaceX to launch a silver, plastic-like object in the shape of a diamond, the work of an artist who wanted “all of us to look up at the night sky with a renewed sense of wonder.” A Japanese company is testing satellites that can drop tiny objects from space into the atmosphere, simulating a meteor shower, and a Chinese organization wants to launch satellites coated in mirrors to beam light down to the city of Chengdu, part of an effort to perhaps someday replace streetlights.

These projects are usually met with some grumbling, mostly from astronomers, who argue that bright, shiny objects, even if short-lived, can be tremendously disruptive to ground-based telescopes trying to peer deep into space. Satellites with less whimsical intentions receive backlash, too; many astronomers hate SpaceX’s new satellites, launched last month, the first of nearly 12,000 that would someday provide internet services from space. They worry that the brightness of the satellites, combined with their sheer numbers, would effectively ruin astronomical study from the ground.

“It will get to the point, if plans continue, that there will be so many satellites in the night sky that at any given moment, it will be impossible to remove the human component of the view from the view itself,” Barentine said.

Elon Musk, the CEO of SpaceX, has said that some satellites will appear dimmer as they settle into higher orbits, and that engineers would consider measures to further reduce their reflectiveness.

Now imagine if satellite operators went in the opposite direction and leaned into the light. If they designed the satellites to not only reflect sunlight, but beam artificial light of their own for hours or longer. And they added some propulsion systems, so that the satellites would never fall out of the sky, or so that they could orbit together, as a constellation with a mythological story preprogrammed from the ground. And when the satellites came into view in the moments before sunset and sunrise, they looked like ordinary stars.

Such an effort would be expensive and technically difficult, and likely carried out by the very rich. Unlike national space agencies like NASA, space entrepreneurs like Musk and Jeff Bezos aren’t beholden to taxpayers. They have to receive approval from federal agencies that regulate space activity, but as long as their payloads don’t contain some kind of bomb, regulators are likely to grant their launch requests. “As more private companies become involved in spaceflight, the rules and the oversight change,” says Lisa Ruth Rand, a historian who studies orbital debris. “In the 1960s, we wouldn’t have launched a cherry-red Tesla into space.”

To some, the artificial stars might represent a triumphant display of human technology. “I can see the appeal of looking at artificial stars, because it’s sort of the recognition of the ingenuity of humanity,” Barentine said. “It’s a sign of modernity, a sign, in some respect, that we have arrived, that we humans can put things into the sky that rival the stars themselves.”

Perhaps a synthetic starscape would be seen as an extension of art, says Stuart Eves, an engineer who studies the removal of space debris, such as defunct satellites. Artists emulate the natural world in paints and canvas, while engineers might use microchips and metal. “People paint pictures of landscapes presumably because they find the landscape attractive,” Eves says. These exercises share the same instinct of mimicry, but in space, the final product would eliminate the original in an unprecedented way.

Or the effort may seem an earnest attempt at recovering the wonder of an unobscured sky, to provide people in light-polluted areas with an ancient connection to the universe. Rand lived in New York City during the great blackout in the summer of 2003, and she remembers walking through Times Square, completely darkened in the power outage. “I remember how odd it was to look up and see Mars,” Rand says.

It was a delight, but it didn’t make Rand mourn Midtown Manhattan’s tragic destruction of the evening sky. No one expects Mars to be visible in the middle of Times Square. “Obviously, there is something lost in not being able to see a starscape, but that’s just become a reality that’s accepted by modern urban dwellers,” Rand says. “Those who are not astronomy nerds like us probably don’t think about it as much.”

Sara Pritchard, a historian at Cornell who studies efforts to reduce light pollution, says a manufactured sky would deprive stargazers of what can make the natural world so mesmerizing: unpredictability. “You may really want to see a shooting star, but you could sit there all night and not see one,” Pritchard says. “There’s a certain human humility to doing that, because you realize you can’t necessarily control all phenomena of the natural world out there.” Pritchard suspects city residents yearning for the stars will be just fine without a sky brimming with shiny, fake objects.

For most of human history, the stars mattered more than modern-day light polluters can imagine. “It was unthinkable to ignore the stars,” Gene Tracy, a physics professor at the College of William and Mary, wrote in an essay in Aeon in 2015. “They were critical signposts, as prominent and useful as local hills, paths or wells. The gathering-up of stars into constellations imbued with mythological meaning allowed people to remember the sky; knowledge that might save their lives one night and guide them home.”

Today, beneath a blanket of satellites telling us what time it is and where to go, we no longer navigate our lives by the stars (although other animals still do). In one way, they have become purely decorative. A futuristic escalation—giving up on the real thing altogether and assembling a simulacrum—doesn’t seem so far-fetched.



Leonard Susskind, a pioneer of string theory, the holographic principle and other big physics ideas spanning the past half century, has proposed a solution to an important puzzle about black holes. The problem is that even though these mysterious, invisible spheres appear to stay a constant size as viewed from the outside, their interiors keep growing in volume essentially forever. How is this possible?

In a series of recent papers and talks, the 78-year-old Stanford University professor and his collaborators conjecture that black holes grow in volume because they are steadily increasing in complexity—an idea that, while unproven, is fueling new thinking about the quantum nature of gravity inside black holes.

Black holes are spherical regions of such extreme gravity that not even light can escape. First discovered a century ago as shocking solutions to the equations of Albert Einstein’s general theory of relativity, they’ve since been detected throughout the universe. (They typically form from the inward gravitational collapse of dead stars.) Einstein’s theory equates the force of gravity with curves in space-time, the four-dimensional fabric of the universe, but gravity becomes so strong in black holes that the space-time fabric bends toward its breaking point—the infinitely dense “singularity” at the black hole’s center.

According to general relativity, the inward gravitational collapse never stops. Even though, from the outside, the black hole appears to stay a constant size, expanding slightly only when new things fall into it, its interior volume grows bigger and bigger all the time as space stretches toward the center point. For a simplified picture of this eternal growth, imagine a black hole as a funnel extending downward from a two-dimensional sheet representing the fabric of space-time. The funnel gets deeper and deeper, so that infalling things never quite reach the mysterious singularity at the bottom. In reality, a black hole is a funnel that stretches inward from all three spatial directions. A spherical boundary surrounds it called the “event horizon,” marking the point of no return.

Since at least the 1970s, physicists have recognized that black holes must really be quantum systems of some kind—just like everything else in the universe. What Einstein’s theory describes as warped space-time in the interior is presumably really a collective state of vast numbers of gravity particles called “gravitons,” described by the true quantum theory of gravity. In that case, all the known properties of a black hole should trace to properties of this quantum system.

Indeed, in 1972, the Israeli physicist Jacob Bekenstein figured out that the area of the spherical event horizon of a black hole corresponds to its “entropy.” This is the number of different possible microscopic arrangements of all the particles inside the black hole, or, as modern theorists would describe it, the black hole’s storage capacity for information.

Bekenstein’s insight led Stephen Hawking to realize two years later that black holes have temperatures, and that they, therefore, radiate heat. This radiation causes black holes to slowly evaporate away, giving rise to the much-discussed “black hole information paradox,” which asks what happens to information that falls into black holes. Quantum mechanics says the universe preserves all information about the past. But how does information about infalling stuff, which seems to slide forever toward the central singularity, also evaporate out?

The relationship between a black hole’s surface area and its information content has kept quantum-gravity researchers busy for decades. But one might also ask: What does the growing volume of its interior correspond to, in quantum terms? “For whatever reason, nobody, including myself for a number of years, really thought very much about what that means,” said Susskind. “What is the thing which is growing? That should have been one of the leading puzzles of black-hole physics.”

In recent years, with the rise of quantum computing, physicists have been gaining new insights about physical systems such as black holes by studying their information-processing abilities—as if they were quantum computers. This angle led Susskind and his collaborators to identify a candidate for the evolving quantum property of black holes that underlies their growing volume. What’s changing, the theorists say, is the “complexity” of the black hole—roughly a measure of the number of computations that would be needed to recover the black hole’s initial quantum state, at the moment it formed. After its formation, as particles inside the black hole interact with one another, the information about their initial state becomes ever more scrambled. Consequently, their complexity continuously grows.

Using toy models that represent black holes as holograms, Susskind and his collaborators have shown that the complexity and volume of black holes grow at the same rate, supporting the idea that the one might underlie the other. And whereas Bekenstein calculated that black holes store the maximum possible amount of information, given their surface area, Susskind’s findings suggest that they also grow in complexity at the fastest possible rate allowed by physical laws.

John Preskill, a theoretical physicist at the California Institute of Technology who also studies black holes using quantum information theory, finds Susskind’s idea very interesting. “That’s really cool that this notion of computational complexity, which is very much something that a computer scientist might think of and is not part of the usual physicist’s bag of tricks,” Preskill said, “could correspond to something which is very natural for someone who knows general relativity to think about,” namely the growth of black-hole interiors.

Researchers are still puzzling over the implications of Susskind’s thesis. Aron Wall, a theorist at Stanford (soon moving to the University of Cambridge), said, “The proposal, while exciting, is still rather speculative and may not be correct.” One challenge is defining complexity in the context of black holes, Wall said, in order to clarify how the complexity of quantum interactions might give rise to spatial volume.

A potential lesson, according to Douglas Stanford, a black-hole specialist at the Institute for Advanced Study in Princeton, New Jersey, “is that black holes have a type of internal clock that keeps time for a very long time. For an ordinary quantum system,” he said, “this is the complexity of the state. For a black hole, it is the size of the region behind the horizon.”

If complexity does underlie spatial volume in black holes, Susskind envisions consequences for our understanding of cosmology in general. “It’s not only black-hole interiors that grow with time. The space of cosmology grows with time,” he said. “I think it’s a very, very interesting question whether the cosmological growth of space is connected to the growth of some kind of complexity. And whether the cosmic clock, the evolution of the universe, is connected with the evolution of complexity. There, I don’t know the answer.”

This post appears courtesy of Quanta Magazine.



When Christine Robinson was first diagnosed with a corn allergy 17 years ago, she remembers thinking, “No more popcorn, no more tacos. I can do this.”

Then she tried to put salt on her tomatoes. (Table salt has dextrose, a sugar derived from corn.) She tried drinking bottled iced tea. (It contains citric acid, which often comes from mold grown in corn-derived sugar.) She tried bottled water. (Added minerals in some brands can be processed with a corn derivative.) She ultimately gave up on supermarket meat (sprayed with lactic acid from fermented corn sugars), bagged salads (citric acid, again), fish (dipped in cornstarch or syrup before freezing), grains (cross-contaminated in processing facilities), fruits like apples and citrus (waxed with corn-derived chemicals), tomatoes (ripened with ethylene gas from corn), milk (added vitamins processed with corn derivatives). And that’s not even getting to all the processed foods made with high-fructose corn syrup, modified food starch, xanthan gum, artificial flavorings, corn alcohol, maltodextrin—all of which are or contain derivatives of corn.

“It’s such a useful plant,” Robinson says of corn. “It can be made into so very, very many things that are, from my perspective, trying to kill me.”

[ Read: The ancient origins of dieting]

Corn allergies are relatively rare, and ones as severe as Robinson’s are rarer still. (Many people unable to eat whole corn can still tolerate more processed corn derivatives.) But to live with a corn allergy is to understand very intimately how corn is everywhere. Most of the 14.6 billion bushels of corn grown in the U.S. are not destined to be eaten on the cob. Rather, as @SwiftOnSecurity observed in a viral corn thread, the plant is a raw source of useful starches that are ubiquitous in the supply chain.

It’s not just food. Robinson told me she is currently hoarding her favorite olive-oil soap, which she had been using for 17 years but recently went out of stock everywhere. (A number of soap ingredients, such as glycerin, can come from corn.) She’s been reading up on DIY soapmaking. A year ago, the brand of dish soap she liked was reformulated to include citric acid, so she had to give that up, too. And navigating the hospital with a corn allergy can be particularly harrowing. Corn can lurk in the hand sanitizer (made from corn ethanol), pills (made with corn starch as filler), and IV solutions (made with dextrose). A couple years ago, she went to see a specialist for a migraine, and her doctor insisted she get an IV that contained dextrose.

“And while in the midst of a migraine I had to argue with a doctor about the fact [that] I really could not have a dextrose IV,” she said. In the moment, she realized how absurd it was for her to be telling a world-class specialist to change her treatment.

[ Read: The allergens in natural beauty products ]

Because corn allergies are rare, many doctors are not familiar with the potential scope. Robinson said she was the first case her original doctor had ever seen in 38 years of practice, and he didn’t know to advise her against corn derivatives. Even official sources of medical information can be confusing, telling corn-allergy patients that they do not need to avoid cornstarch and high-fructose corn syrup. Misinformation abounds in the other direction, too, because corn allergies can be easy to misdiagnose and easy to self-diagnose incorrectly. All this means that corn-allergy sufferers encounter a good deal of skepticism. But Robert Wood, president of the American Academy of Allergy, Asthma & Immunology and a pediatric allergist at Johns Hopkins, told me that derivatives such as corn syrup can indeed cause problems for certain people.

People with corn allergies have naturally been finding one another on the Internet. A Facebook group called Corn Allergy & Intolerance (Maize, Zea Mays) now has nearly 8,500 members. Becca, a tech worker in Washington State, writes a fairly prominent blog called Corn Allergy Girl. (She asked I not use her last name because she doesn't want her health status to affect her professional life.) The blog collates years of Becca’s research into corn allergies, as well as resources inherited from other, now-defunct corn-allergy blogs.

Members of the Facebook group have also forged ties with individual farms. Once a year, Robinson said, a farmer in California sends members of the group a big box of avocados that have not been exposed to corn-derived ethylene gas or waxes. “It’s a great month when you’re trying to get through all of them,” she said. For the rest of the time, she gets most of her food from a CSA with a local farm in Pennsylvania.

Becca, who writes Corn Allergy Girl, also gets a lot of her produce from local farms. The rest she grows. She goes to a specific butcher and meat processor who will custom-process whole animals for her without using lactic acid or citric acid. She has two fridges and several freezers to store food for the winter, when fresh vegetables are less abundant. “I go all Little House on the Prairie on the weekend,” she said, “pickling things and shredding them and baking them.” She counts herself lucky to live in the Pacific Northwest, where there are many organic, local farms. It’s harder to find fresh food in many other parts of the country, and it’s much harder to do so on a budget. “Your dollars just don’t go as far as if you’re getting a bunch of Chef Boyardee. It’s very cheap to eat canned, preserved food,” Becca said. She had to run GoFundMe campaigns, for example, for friends who couldn’t afford to buy chicken from a source they can tolerate.

The diet of someone with a severe corn allergy is in some ways the ideal diet for a certain type of foodie: fresh, local, free of preservatives and processed foods, the provenance of every ingredient intensely cataloged. It’s just not exactly by choice.

Knowing how to avoid foods with corn is one thing; knowing how to navigate social situations where danger lurks in every corner is another.

Robinson said that she has two rules when eating out with friends now. First, eat beforehand. Second, order a San Pellegrino and an appetizer for the table to share, which deflects the inevitable concern from the waitstaff. “They’re nice, but people really feel they can find something, and they try. You have to keep saying, ‘No, I can’t, I can’t,’ and everybody feels bad.”

Cassandra Wiselka, whose 5-year-old is allergic to corn, has written about the problem of Halloween. Virtually all mass-produced candy contains high-fructose corn syrup. Her son still goes trick-or-treating, but she switches out the candy he collects with corn-free alternatives: lollipops, gummy bears, and “fancy expensive chocolate that we don’t even buy for ourselves.” She makes and freezes big batches of corn-free cupcakes and pizza to bring to birthday parties. It’s hard, she says. “He still gets upset at birthday parties and things where he has to have his own special food.” They recently had to turn down a birthday party that was moved to a pizza place at the last minute because they didn’t have time to make safe pizza to bring.

Wiselka’s family moved from Germany to California when her son was 18 months old. He seemed to get worse after the move. It’s hard to say exactly why, but Wiselka noticed that “in Germany, things are a lot less processed, food-wise. At least not processed as much with things like corn.”

The one thing Robinson told me she really misses is being able to travel without worry. She did make a trip to Hawaii recently, after much advance planning. She picked Hawaii for the scuba diving. When she dives, she has to watch out for a few specific things—that her wetsuit has not been washed with a corn-containing detergent, that her dive partners have not been eating corn chips. But once she’s in the water, she’s calm. Sure, scuba diving can kill you if you aren’t careful (the most recent data show that 40 to 50 people die while diving in North America every year), but she can be sure there is no corn in water.

“You don’t realize you’re carrying around this extreme sense of alertness,” she said. “That level of hypervigilance that you have for things that you could touch or breathe in is gone. You’re breathing air that you know is safe and you know the actual oxygen content of. It’s just incredibly freeing.”



It’s early May of the year 4847, and Willek Muriday, a chief scientist and regional director of a far-reaching biological survey, has just submitted a report on the Cagoan District, the ruins of an ancient urban center. These ruins, southwest of Lake Mishkin, were long thought to be lifeless, but year-round tropical temperatures and high levels of background radiation have led to the rapid evolution of a number of new species. “The district of Cago is alive and thriving!” Muriday writes.

This is the premise of Beyond the Sixth Extinction, a creepily beautiful new pop-up book by Chicago paper artist Shawn Sheehy. The large-format book is ostensibly for older tweens and younger teenagers, and lavish bogeymen literally leap from its pages: Its bestiary includes a mobile, nearly life-size representation of the rex roach, a species evolved from the common cockroach; a massive snapping turtle called the Cagoan dragon; and a flightless pigeon large and fierce enough to eat small mammals. Then there’s the mudmop, a descendant of the catfish. Inconsistencies in counts of the mudmop’s mouth tentacles, Muriday soberly reports, were not clarified “until biologists realized that some of the ‘tentacles’ were not what they appeared to be.” The extra tentacles turned out to be parasitic leeches. Gross!

Though Beyond the Sixth Extinction can be enjoyed solely for its dystopian yuks, its elegant paper sculptures tell a deeper story. The book doesn’t spend much time blaming humans for the world it imagines, or spell out exactly what has befallen Homo sapiens during the nearly three millennia between 2019 and 4847. But it does hint at a world in which the human footprint has been radically reduced. Chicago transformed into the diminished district of Cago, and life to some extent has moved on without us.

All the creatures in Muriday’s imaginary field guide have evolved to take advantage of—and to some extent compensate for—human misrule. Rex roach, which like its smaller forerunners has a high tolerance for radioactivity, can neutralize the radioactive particles it digests. The clam fungus, whose ancestors lived on trees, now clusters on the surfaces of ancient landfills, where it gleans from methane gas the same elements its bracket fungus ancestors mined from wood. (The clam fungus prudently closes its brackets at sunrise, partly to protect its tender inner flesh from those hungry giant pigeons.) The mudmop sequesters heavy metals, as does the Cagoan dragon. The Peteybug’s name derives “from PT bug, for polymertrophic”—a synthetics feeder, it eats compact discs. The bloomworm, the naturalized descendant of a “genetically engineered chimera” that 21st-century researchers hoped would fight cancer, takes root in the cracks in buildings and sidewalks, absorbing calcium and aluminum from the cement and causing “concrete-based structures to deteriorate at an accelerated rate.”

Sheehy’s project was initially inspired by paleoanthropologist Richard Leakey’s 1995 book The Sixth Extinction (not to be confused with Elizabeth Kolbert’s 2014 book of the same name). “That was the first time I’d ever thought about the Earth’s five big extinction events, and that the sixth one, which might have the same sort of drama, is our fault,” Sheehy says. “That had a profound impact on me.”

Sheehy, a former elementary-school teacher, is careful not to burden his young readers with real horrors. As in his previous pop-up book Welcome to the Neighborwood, a much cuddlier tale about real-life animal builders, his primary goal is to provoke curiosity about “what else is out there that we don’t know about yet”—whether “out there” is the backyard or the distant future. The creatures of Beyond the Sixth Extinction, like the scientifically informed inventions of novelists Paolo Bacigalupi and Jeff VanderMeer, are just familiar enough, and plausible enough, to root in the imagination, and its passing place references—the “Cagoan District” includes the “Ohare Site,” infamous among 21st-century travelers—add to its eerie believability. As a contemplation of adaptability, resilience, and the many possible consequences of the present for the future, Beyond the Sixth Extinction can be an adventure for former teenagers, too.



SAN FRANCISCO—The sky has filled with eyes, and NASA is starting to notice.

Over the past several years, venture-funded start-ups have hurled hundreds of inexpensive satellites into orbit. For-profit companies have used smartphone technology to make compact satellites that look down at Earth and monitor its every oceanic gurgle, erupting volcano, or forest conflagration. Hundreds of these satellites might gaze down at the same time; they are organized in what are called (rather poetically) “constellations.”

NASA has now taken heed of these new arrangements. Earlier this year, it asked 36 scientists to figure out whether imagery and data from three satellite companies could be put to serious scientific use. On Thursday, the San Francisco–based start-up Planet announced that it is one of the three companies participating in the pilot program.

Among NASA’s goals: Decide whether data from the three satellite companies can be used to create a dashboard of what are called “essential climate variables.” These core clues to planetary health—which include figures tracking the size of leaves, the health of Arctic permafrost, and the extent of groundwater reservoirs—could function as a kind of early-warning system for environmental upheaval.

This program also reflects a potential shift for NASA. The space agency is already preparing to send a human crew to orbit in a commercial spacecraft later this year. It might soon rely on for-profit companies when collecting scientific data, too.

The announcement is something of a coup for Planet, which operates what it describes as the largest private constellation of Earth-observing satellites ever assembled. Planet’s leaders have long described their company as a boon not just for the financial and defense industries—the usual customers for this kind of data—but for scientists and humanitarians. Now they have the NASA deal to prove it.

But it could raise more difficult questions for researchers. Science is conducted largely as a public good, and researchers can vet one another’s work by checking it against publicly available data. If that basic data is no longer publicly available, it could mean that major earth-science research relies on proprietary data.

I recently visited Planet’s headquarters in San Francisco. Housed in an unassuming former warehouse in the city’s SoMa neighborhood, its office melds the feel of the National Air and Space Museum in Washington, D.C., with the unfinished, exposed-brick-and-metal aesthetic that the writer Kyle Chayka has called “AirSpace.” One floor is an open-plan office with rows of sleek monitors and small meeting rooms. The next floor up is a shining clean room where dozens of satellites are manufactured every year.

Planet is now the dominant satellite-imagery start-up in the Bay Area. In 2015, it bought RapidEye, giving it five military-grade satellites. Two years later, it acquired its rival small-satellite manufacturer Terra Bella in a deal with Alphabet. Today roughly 120 Planet satellites float in orbit—most of them are about the size of a shoebox—allowing the company to photograph every spot on Earth at least once a day.

Planet can also boast association with a large research community. More than 100 peer-reviewed papers cite Planet data. Researchers have used Planet imagery to monitor Arctic lakes, track ships, and tally the biomass of forests.

Jamon Van Den Hoek, a professor at Oregon State University and one of the 36 scientists currently adjudicating the NASA pilot project, told me that Earth imagery now functions as a crucial data source for scientists. The pixels are the data, he told me: “These aren’t just for reference. These aren’t just for a base map. These are the data you analyze.” A certain shade of pixel might say whether a forest is thriving or clear-cut, or it might suggest that a once open meadow has been swallowed by a city.

As part of the NASA pilot program, Van Den Hoek has used Planet data to help search for and study Earth’s “missing million” people—refugees and internally displaced people who live in informal camps and settlements in the least mapped parts of the planet. The project would constitute the first systematic analysis of how these settlements change over time, he said.

Not all of this is new: Scientists have been using pixels as data for the past half century. Since 1972, satellites in the U.S. government’s Landsat program have systematically photographed every speck of land on Earth, every 16 days, without fail. Landsat, now one of the largest and most powerful tranches of earth-science data, is an invaluable scientific resource. In the 1980s, it revealed the extent and severity of Amazon deforestation; now it captures the massive changes to Earth’s surface wrought by climate change. One of the most widely cited satellite data sets, a global survey of forest loss created by the University of Maryland professor Chris Hansen, is powered by Landsat data.

But the program’s future is more uncertain—and its fate is tied to Planet’s. The next Landsat satellite, dubbed Landsat 9, is due to launch late next year. But NASA and the U.S. Geological Survey have considered using a new approach with its successor, Landsat 10. They could replace it with two satellites instead, mimicking an EU program. Or they could try replacing Landsat with a swarm of satellites, creating a publicly owned version of Planet’s constellation.

Some lawmakers have even proposed that the government rely entirely on private-sector data for Landsat 10. Van Den Hoek said that seemed unlikely, at least for now. “People who hold the purse strings may want that to happen, but no one at NASA wants that to happen,” he said. Planet, too, supports the Landsat program and doesn’t want to see it change significantly, a spokesperson told me. The company’s satellites revisit the same speck of land more often than Landsat’s do, and its cameras have a higher resolution. But its craft are unable to capture as many types of light.

Planet tries to make as much of its data available to as many researchers as possible, and some universities now have blanket licenses to much of its imagery. The company remains a commercial enterprise (albeit one that has not yet turned a profit), but Joe Mascaro, an ecologist who now directs academic partnerships for Planet, told me that the replicability of research is a “core principle we would do our best to meet.” And if Planet explores “future, larger contracts with NASA,” says Trevor Hammond, Planet’s vice president of communications, it “would go in with its eyes open” about the tension between open science and closed data.

Van Den Hoek emphasized that Landsat and Planet are good at different tasks. Landsat could capture widespread shifts to the land: urbanization, deforestation, the loss of polar ice. Planet excels at more fine-grained tasks. “You can ask questions that you could never ask before,” he said. “Huge portions of sub-Saharan Africa rely on small-scale agriculture for daily subsistence. You can’t measure that with Landsat data.”

NASA is also working with Spire Global, a Bay Area start-up that collects high-quality weather data, and Maxar, a more established player that owns the WorldView spy satellites. Peter Platzer, the chief executive of Spire, told me in an email that NASA plans to spend $100 million on small-satellite projects over the next few years.



Recently, NASA released colorful, dreamy illustrations depicting an imagined future in which human beings have made it to other worlds. A curly-haired astronaut floats inside a lunar space station, with the crater-pocked moon behind her. A lunar explorer steadies a camera on a tripod to photograph Earth in the distance. And an astronaut stands on the dunes of Mars with her hands in the pockets of her spacesuit, a dog at her side.

Wait, a dog?

To be clear, NASA’s ambitious plans for missions to the moon and Mars do not include dogs. (At least, none that the public knows about. If you’re a member of a top-secret program to groom doggonauts, please contact me.) The agency does want to send humans there, sometime in the 2030s.

But dogs have been to space. In the 1950s and 1960s, the Soviet Union strapped dogs into capsules and launched them into the sky. The canines were not trusty space sidekicks, but research subjects, strays collected from city streets to test launch systems before humans themselves did. (The United States conducted similar tests, with several species of monkeys.)

Engineers “trained” the dogs; they dressed them in spacesuits, kept them in small boxes for days, and put them through rocket-launch simulators. But any pup would do, really. In the fall of 1951, days before his scheduled flight, Bolik the dog somehow managed to run away. Russian engineers, facing a strict deadline, went outside, found a stray, and strapped him in. They named him ZIB, a Russian acronym that stood for “substitute for the vanished Bolik.” He completed the mission and returned to Earth safely.

That was a sub-orbital flight, though, which stops short of looping around the Earth. The first dog to truly go to space was Laika, a three-year-old perky-eared mutt, in 1957. Her capsule successfully made it to orbit and remained there for about five months, circling the globe, before plunging back into Earth’s atmosphere. But Laika didn’t survive. A safe return was never part of the plan. The capsule was designed to run out of oxygen within a week. According to sensors embedded beneath her skin, Laika’s heartbeat was triple the normal rate during launch, and her breathing frantic. She died not long after, likely because of the extreme temperatures in the overheated capsule.

Over time, other dogs orbited the Earth and returned alive. Eventually, so did people. Dogs were left on the ground, safe from the threat of being shot into the sky.

But the NASA poster suggests that, unlike the Soviet dogs, a canine on Mars would not be a lab animal, but a valued companion on the journey to a distant land. Even still—imagine life for a dog on Mars. It probably would be miserable.

The journey would begin with a bone-chattering rocket launch. Passengers would feel as much as four times the force of Earth’s gravity pressing down on them. The experience is stressful—even some of the best-trained astronauts take off with skyrocketing heart rates. It would be far worse for a passenger who couldn’t comprehend what was going on, says Clive Wynne, a psychology professor at Arizona State University who studies canine behavior, and the author of the forthcoming book Dog Is Love: Why and How Your Dog Loves You.

Wynne considered his own dog, Xephos, an eight-year-old mutt named for Xenophon, an ancient Greek scholar who wrote about dogs. “I’m pretty certain Xephos doesn’t want to go to Mars,” he says. “If we were to try this out by putting her in a confined space and subjecting her to loud noises and sudden movements, I think she would convince us that this wasn’t something she wanted to do.”

Xephos enjoys some turbulence, like riding in a car with the windows down. “If the option existed for a dog to stick its snout out the window during the ride to Mars, then maybe,” Wynne says. But “the little I know about space travel—there are not going to be windows.”

No, there won’t. And the technology to build a palatial spaceship like the USS Enterprise is many years away. The first ships to travel to Mars will likely be small and cramped, packed with little more than the essentials, like life-support systems. There won’t be much room for astronauts to move around, much less play catch with their canine companion.

The ride would be hard on the bodies of the passengers, human and dog alike, especially if their spacecraft can’t produce artificial gravity that keeps their feet and paws on the floor. Without gravity, fluids in the body would float to their heads and congest them. Bones and muscles would thin out. Eyeballs would squish, blurring vision—a medical mystery scientists are still trying to figure out. And without the protection of Earth’s magnetic field, the passengers would be exposed to radiation, the high-energy rays that permeate the cosmos, which can increase the risk of cancer.

Human beings can volunteer for this perilous experience, but their dogs can’t. “I think it would be inhumane to take a dog on a spaceship,” Wynne says.

The challenges would continue on Mars, if humans and their dogs even make it there. The air in the thin atmosphere is unbreathable and the soil toxic. The gravity, about one-third that of Earth, would wreak still more havoc on their bodies. The dog would probably live in a small habitat along with the humans, only venturing outside in a spacesuit.

Designing a spacesuit for a dog wouldn’t be the hard part (leaving aside the debate over how a dog would wear pants back on Earth). NASA has decades’ worth of experience in manufacturing spacesuits, which are like little spacecraft of their own, equipped with the systems necessary to keep their wearers healthy and alive. Presumably, the dog would communicate with a human companion the same way two astronauts chat during spacewalks: radio. The pup would wear a fabric hat featuring a microphone at the ear, to receive commands and who’s-a-good-dog reassurances, and another microphone at the mouth, so that the human companion could hear it bark. (NASA’s name for these hats—Snoopy caps—is quite appropriate.)

The problem is the dog’s experience inside that spacesuit, which would circulate the same air over and over. Dogs have 300 million olfactory receptors in their noses, compared with just 6 million for humans. They love to sniff just about everything in sight. They can even tell when their humans feel sick. The enclosed environment of a spacesuit would be stifling.

“The dog is never going to sniff the roses,” Wynne said. “There’s not going to be any weather. The dog is never going to smell the fresh rain and splashing puddles, and never going to sniff a lamppost and realize there’s a new dog in town.”

With their sense of smell limited, dogs wouldn’t be as useful, since working dogs are trained by scent. Perhaps they could be taught to sniff out certain minerals in the soil, but the investigation would have to be done with samples brought indoors, far from the Martian breeze, where machines could probably do it anyway.

There’s also the question of the dog relieving itself. Astronauts wear adult diapers during spacewalks; Mars explorers would have to train their canine companions to become comfortable with a similar arrangement. “I don’t know how anyone’s going to scoop the poop,” Wynne says.

Future generations of Martian dogs, born and raised on the barren planet, would probably be fine. Like children born on Mars, they wouldn’t miss the roses or the rain. But if it’s going to be this bad for the first canines, why send dogs to Mars at all?

“I’d assume we’d take our dogs and chickens and all sorts of animals with us, don’t you?” says Valeri Farmer-Dougan, a psychology professor at Illinois State University, where she runs the Canine Behavior and Cognition Laboratory. “When we traveled to other places over the course of human history, we took things with us.”

For owners who consider their pets family, it would no doubt be difficult to leave a loved one behind on Earth. “I wouldn’t want to go anywhere without my dogs,” says Farmer-Dougan, who has five: a golden retriever—her service dog—a poodle, and three special-needs Australian shepherds, two of which are deaf and blind. Sending people to an entirely new planet, decision makers would have to weigh the benefits of companionship and emotional attachment against ethical concerns about animal welfare.

Some Mars evangelists suggest that the rosy future pictured in NASA’s posters would emerge right after arrival. In a recent Popular Mechanics interview, for instance, Elon Musk was asked for his ideas for producing food, water, and fuel. “Once you get there, that stuff is relatively straightforward,” he said.

That’s quite optimistic. The first Mars missions will likely be perilous and painful. It would be tremendously difficult to keep the humans alive, let alone the dogs that come along. Astronauts would be better off bringing small machines, the common companions of space travels in science fiction. Research has shown that robots can prompt feelings of empathy and bonding in humans, especially when they look like WALL-E. They can roam the Martian landscape for hours, unencumbered by memories of an earthly past.

Wynne has another suggestion.

“I wonder if maybe it would be a better plan to take a cat,” he says.



The mysterious signals come from all directions in the sky.

No one knows exactly what they are, or what causes them, but astronomers have detected dozens over the past decade. The signals, known as fast radio bursts, originate from deep within the cosmos, well beyond the Milky Way galaxy. The radio waves travel across space for billions of years, moving at the speed of light. When they reach Earth’s telescopes, they make a brief and powerful appearance. For a few milliseconds, the bursts shine with the intensity of an entire galaxy. And then they’re gone.

Of the more than 50 recorded fast radio bursts, or FRBs, astronomers have a favorite: FRB 121102, named for the date of its discovery six years ago, on November 2, 2012. Unlike other fast radio bursts, this one repeats. Telescopes have observed blindingly bright flashes coming from the same point in the sky over and over, sometimes several times in less than a minute. The signal’s quirky nature has allowed astronomers to study it in more detail, to mine each flash for different kinds of information and even pinpoint its location in a small galaxy about 3 billion light-years from Earth.

Despite the nondescript name, FRB 121102 was one of a kind. Which raised a discouraging possibility: Could it be the only one of its kind? Each new pulse produced tantalizing data. But to really make sense of it, astronomers needed to find another—if any existed.

They began to search the sky, with focused attention and more powerful tools. And, to their relief, astronomers have now found that, no, FRB 121102 is not the lone example of this intriguing phenomenon.

A Canadian-led team announced Wednesday the discovery of a second repeating FRB. A newly built radio telescope in British Columbia detected six flashes from the same spot in the sky last summer. This FRB, named 180814, appears to originate about 1.5 billion light-years away from Earth, half the distance of the other repeating burst.

The same team has also detected 12 more one-off FRBs, which brings the total number of known flashes to 65. The research, described in a pair of papers in Nature, will provide more clues to one of astronomy’s greatest mysteries.

The two repeating signals have more in common than just their flashy nature. When FRBs arrive at Earth, many appear smeared across a range of frequencies, a sign of their long and bumpy journeys through cosmic material across the universe. This includes FRBs 121102 and 180814. But even though the bursts came from two very different locations, and carved out two very different paths to Earth, their radio waves showed similar distortion patterns.

This particular finding stunned astronomers at a recent conference, where the researchers teased their discovery with a little trick. “They put up images of these bursts, and everyone was like, ‘Okay, that looks familiar,’ and then the person showing it said, ‘Actually, you’ve never seen this before, because they’re from a new repeating FRB,’” said Shami Chatterjee, an astrophysicist at Cornell who studies FRBs and was not involved in the new research. “It looks shockingly similar.”

The similarities suggest the two repeaters may have originated in the same kind of environment. It’s possible that repeating bursts are just one of many classes of FRBs, some yet to be discovered. But with so little information, researchers are far from any definitive conclusions.

“We don’t know what it means yet,” said Ingrid Stairs, an astrophysicist at the University of British Columbia and a member of the research team. “This is our second repeater. I think we need to have a much better sample.”

When the first FRB was discovered in 2007, some astronomers thought the flashes could be errant noise from telescope instruments. The bursts just didn’t seem real. “These things are billions of light-years away,” said Jason Hessels, an astronomer at the University of Amsterdam and ASTRON, the Netherlands Institute for Radio Astronomy, who studies FRBs. “It’s absolutely remarkable that they can still be bright enough to detect on Earth.”

The complicated twisting observed in FRBs suggests they come from extreme environments with strong magnetic fields and high temperatures. Astronomers know of several astrophysical objects that could provide these radio-wave-bending conditions: Supermassive black holes, which can belch streams of radiation in space when they eat matter. Neutron stars, the fast-spinning cores of stars, leftover from spectacular explosions. Magnetars, a certain kind of neutron star, which spin even faster.

Before the detection of 121102, FRBs were thought to be one-time events, the products of cosmic collisions or explosions that, given the power of the flashes, no astrophysical object could surely survive. The repeating nature of 121102 showed that the universe, always ready to surprise, is capable of producing objects that can erupt over and over without fizzling out.

The scattered waves of FRBs can be used to answer other intriguing but basic questions about the universe, including what it’s actually made of. “If you try to add up all the material in galaxies and stars and planets and rocks, it doesn’t come up to the right number at all. We’re short by a lot,” Chatterjee said. “So where is all this missing matter?”

Astronomers suspect that it may reside in the space between galaxies. The intergalactic medium is orders of magnitude emptier than the best vacuums in our terrestrial laboratories, but it still has some wisps of cosmic matter. The universe is so big, though, that these tiny traces could make up a substantial amount of space stuff. FRBs pass through this matter as they travel through space, and their interactions become encoded in the radio waves. “When [the FRB] arrives at Earth, we can basically read that information off the radio burst itself,” said Sarah Burke-Spolaor, an astronomer at West Virginia University who studies FRBs. The cosmic flashes can help illuminate the complicated composition of the universe, and the more FRBs astronomers detect, the more ground—er, space—they can cover.

More discoveries are likely on their way. The telescope responsible for these findings, the Canadian Hydrogen Intensity Mapping Experiment, or CHIME, promises to be the most effective FRB hunter in operation. CHIME scans the entire Northern Hemisphere every day, hopping from one spot to the next every 15 minutes. The observatory can examine 500 times as much sky as the next FRB superstar, the Parkes radio telescope in Australia, which revealed the first FRB in 2007 and has found the majority of known bursts.

You could say CHIME wasn’t even trying when it found a new batch of FRBs last summer. The data was collected before formal operations began, when astronomers were still tinkering with the instruments. “We were calibrating it and improving it day by day,” said Cherry Ng, an astronomer at the University of Toronto and a member of the research team. “Sometimes we had to turn off the instrument just to make changes.”

Scientists estimate that FRBs occur about 10,000 times a day across the entire sky, and CHIME, at peak capacity, is poised to detect dozens every month.

As with most cosmic mysteries, the specter of an extraterrestrial explanation looms large. Some, including astrophysicists at Harvard, have suggested that FRBs are beacons from an advanced alien civilization. Hello out there! they shout, searching the vastness of space for neighbors. FRB researchers say they can’t rule out an extraterrestrial origin for the cosmic flashes. It’s one possibility of many. But it’s the least likely, they say.

“[FRBs] come from all over the sky, and from many different distances, always from different galaxies—the chances of aliens living in different parts of the universe getting together to organize, to produce these signals in this kind of way, are infinitesimally small,” Stairs said. “There’s just too many of them out there.”

On top of that, the home environments of FRBs aren’t exactly conducive to life, intelligent or not. The emissions likely torch their surroundings as they erupt into space. “If we had one go off near Earth, we might not be around anymore,” Burke-Spolaor said.



Cape Canaveral, Fla.—The Space Coast, lined with idyllic beaches and swaying palm trees, faced a quiet future when the space shuttles stopped flying nearly eight years ago, and the famed spacecraft rolled off the launchpads and into museums. Then Elon Musk and SpaceX moved in, under a lease with NASA, and brought their own rockets.

The company tweaked the launchpads to support its own operations, and began launching new missions: commercial satellites built by manufacturers from around the world, cargo ships packed with supplies for the International Space Station, even top-secret missions for the U.S. government. In the past few years, the Falcon 9 rocket has flown so regularly, and without incident, that the launches now feel almost routine.

The next mission leaves Earth in the very early–morning hours of Saturday. This time, the rocket will carry an unprecedented payload: a spacecraft designed to carry humans.

The mission is a test, the first flight of a newly designed system. No humans will be on board—just 400 pounds of cargo and a mannequin dressed in a sensor-coated spacesuit, which SpaceX has named Ripley, for the protagonist and sci-fi feminist icon of the 1979 film Alien. But if the mission goes well, people could be riding in SpaceX spacecraft as early as July. The first passengers—two NASA astronauts, Bob Behnken and Doug Hurley—have already been selected and begun their training.

The flight is an important milestone for the American space program. The United States hasn’t launched astronauts from American soil since 2011, when the space shuttle Atlantis closed out a 30-year program that folded under the weight of cost, political will, and safety concerns. Americans continued to fly to space. They hitched rides on a Russian launch system, the Soyuz, operated in Kazakhstan, in the middle of the desert—an expensive situation, but necessary to keep the ISS staffed.

In 2014, NASA awarded two American companies, SpaceX and Boeing, billion-dollar contracts to build the next generation of astronaut transportation. SpaceX would build a passenger-safe version of its uncrewed Dragon spacecraft, which already delivers cargo to the ISS, to fly on a Falcon 9. Boeing would develop the Starliner, to launch on the Atlas V, a rocket manufactured by the United Launch Alliance, Boeing’s venture with Lockheed Martin.

After schedule delays and technical issues at both companies, SpaceX has beaten Boeing to the launchpad for the NASA program’s first significant test. The firms have always resisted describing the efforts as a race, but surely there’s something juicy about a billionaire-run start-up edging out a longtime government contractor.

Competition aside, the companies must do the same thing: prove to NASA that they can safely send astronauts to space.

“The task ahead of us is really historic,” Hans Koenigsmann, the vice president for build and flight reliability at SpaceX, told reporters on Thursday. “We’ve done an incredible amount of testing together with NASA to make sure everything is safe and ready to go.”

That sense of history is baked into the concrete here at the launch site. The mission will depart from the Kennedy Space Center’s launchpad 39A, right along the water, the site of many historic launches in American spaceflight history, including the Apollo and Space Shuttle programs.

When the final space-shuttle mission flew, in 2011, the fate of the program had already been decided years earlier. After the Columbia disaster in 2003, which killed all seven crew members upon reentry, the United States shut down the program to conduct a lengthy review. As investigators worked to determine the cause of the tragedy, the Bush administration considered the future of American spaceflight. National-security officials spent the year in meetings to discuss what the country should do next, Sean O’Keefe, the NASA administrator at the time, said.

Former President George W. Bush announced the result of these discussions in a speech in January 2004. “America has not developed a new vehicle to advance human exploration in space in nearly a quarter century,” he said. “It is time for America to take the next steps.”

The president proposed the construction of a brand-new launch system that could carry astronauts not just to low-Earth orbit, but also farther—to the moon and Mars, journeys the space shuttle was not designed to make. The government couldn’t fund both efforts at the same time, so it was decided that the space shuttles would be retired after they finished delivering the hardware necessary to construct the new ISS, which was being built in orbit, piece by piece, at the time.

“Take the next seven years to finish the ISS, because this is the machine that can build it,” O’Keefe said. “And once we’re completed with that, by that time there should be a capability developed to go back beyond low-Earth orbit to any destination you choose.” To start, Bush wanted to return Americans to the moon by 2020.

When the United States paused the Space Shuttle program in 2003, American astronauts could fly to space only with Russia’s help. I asked O’Keefe whether he thought, during those discussions more than 15 years ago, that this would someday become NASA’s only option for years. “No, no,” he said. “Through all those discussions, that was the furthest thing from anybody’s imagination.”

Bush left office five years after announcing that plan. When Barack Obama arrived in the White House, he convened an independent review of Bush’s exploration program, known as Constellation. The assessment found that billions of dollars in additional funding would be required to reach the program’s ambitious timelines. The president’s next budget requested no funding for Constellation, but included the searing description of the program as “over budget, behind schedule, and lacking in innovation.”

Obama directed NASA to focus instead on Mars, with a goal of having a crewed mission orbit the planet in the 2030s. The new administration reimagined some of Constellation’s rocket plans. Since 2011, NASA has worked on the Space Launch System and Orion crew capsule, a rocket-and-spacecraft combo that the agency hopes will someday carry astronauts to the moon and Mars. (The effort has problems of its own; a report by NASA’s Office of Inspector General recently said that the system won’t be ready for its first test flight, expected in mid-2020, unless it receives more funding.) As for low-Earth travel, NASA would get help from the commercial sector, from companies such as SpaceX.

Members of Congress, which holds the purse strings for NASA, frequently lament the country’s reliance on Russian services to reach the closest stretch of space. It’s an expensive travel package; today, one seat on the Soyuz launch system costs the U.S. government $81 million. But for American leaders, the arrangement has cost the country prestige, too. The United States, the world’s premier spacefaring nation—the one that put men on the moon—was never supposed to stay grounded for this long.

NASA will continue to pay Russia to fly astronauts until SpaceX and Boeing prove themselves capable of doing the job, starting with this crucial mission playing out over the course of the coming week.

The Falcon 9 will propel the Dragon spacecraft into orbit on Saturday. When the spacecraft approaches the ISS, it will attempt a new maneuver. In previous missions, a powerful robotic arm, operated by an astronaut on board the ISS, reached out and grabbed the capsule, pulling it toward the station. This time, the Dragon spacecraft will dock to a five-foot-wide metallic ring, controlled by only its autonomous computer systems—a procedure that carries a risk of collision. Russia’s space agency, Roscosmos, which controls half of the ISS, was even hesitant to formally approve the plan.

When the spacecraft sticks, the ISS crew—an American, a Russian, and a Canadian—will go in and unload the fresh supplies. The spacecraft will stay docked to the station for five days before it detaches and prepares for a fiery reentry through Earth’s atmosphere. The mission ends with a parachute landing in the Atlantic Ocean.

NASA says there’s still work to be done before its astronauts ride to the top of the Falcon 9 and climb aboard. Officials continue to examine the hardware involved in an explosion in 2016 while the rocket was being fueled for a routine engine test. The fiery explosion destroyed the rocket and its $200 million payload, and damaged the launchpad. Musk described it as “the most difficult and complex failure we have ever had in 14 years.”

The incident also drew attention to SpaceX’s process for preparing for launch, which involves fueling the rocket just 35 minutes before liftoff. SpaceX planned to follow the same approach for future crewed launches, which sparked some concern. Last summer, NASA decided after an “extensive” review that the process was safe for astronauts.

There’s also the matter of safety reviews at both SpaceX and Boeing, which Jim Bridenstine, the NASA administrator, announced in November would involve hundreds of interviews “to assess the culture of the workplaces.” Bridenstine said his decision was influenced in part by several spaceflight tragedies in NASA’s history. But the timing suggested additional factors; weeks earlier, Musk smoked marijuana and drank whiskey during a podcast appearance that drew millions of viewers.

“I will tell you that was not helpful, and that did not inspire confidence, and the leaders of these organizations need to take that as an example of what to do when you lead an organization that’s going to launch American astronauts,” Bridenstine said at the time.

By now, NASA and SpaceX have completed thousands of hours of tests and analyses in preparation for the Dragon flight. NASA officials say that while the SpaceX mission is ready to fly, they don’t expect a flawless test. They’re only comfortable saying this, of course, because Ripley the mannequin can handle a failed launch.

“I guarantee you everything will not work exactly right, and that’s cool,” Bill Gerstenmaier, the associate administrator for NASA’s human-exploration division, said last week. “We want to maximize our learning so we can get the stuff ready; so when we put a crew on, we’re ready to go do a real crew mission.”



Astrophysicists usually don’t get chased by reporters, but that’s what happened to Avi Loeb last November.

They bombarded Loeb’s phone lines. They showed up at his office with television crews. One of them even followed him home and confronted him at the front door, demanding Loeb answer a question.

“Do you believe that extraterrestrial intelligence exists?”

Days earlier, Loeb had published a new research paper in an astrophysics journal. Scientists publish thousands of research papers every year in journals big and small, prestigious and obscure. Usually, aside from some basic coverage by science journalists, these papers attract little public attention. But Loeb’s latest work covered a topic that is historically very attention-getting: aliens.

The subject of the paper was a mysterious space rock known as ‘Oumuamua. When it was discovered in October 2017, the rock was the talk of the astronomy community. ‘Oumuamua is the first interstellar object astronomers have seen in our solar system; it did not originate here, but likely traveled for billions and billions of years, past countless other stars, before reaching our own. Telescopes caught it just after it sped past the sun. They can’t see it anymore, but ‘Oumuamua is still going. Eventually, it will cross the edge of our solar system and into interstellar space, again.

The leading hypothesis among astronomers is that ‘Oumuamua is an odd-looking comet, a remnant of another solar system that was kicked out by natural forces and sent barreling through the cosmos.

Loeb offered a different explanation: ‘Oumuamua could be a probe that was deliberately sent to the solar system by an alien civilization.

It’s no surprise that news of Loeb’s theory took off. The detection of extraterrestrial beings, whether they’re the wrinkly ET kind or the teeny microbial type, would be among the most significant scientific discoveries in human history. The thought of finding sapient life beyond Earth, of learning that we are not alone, is exhilarating and disorienting. The suggestion that it might actually have happened is doubly so.

But there’s another reason the paper was so widely covered: Loeb is a tenured Harvard professor.

“If this was some random astronomer that you had never heard of from, say, Equatorial Guinea, you probably wouldn’t write a story on it,” says Bryan Gaensler, the director of the University of Toronto’s Dunlap Institute for Astronomy and Astrophysics, and a former colleague of Loeb’s at Harvard. “There’s a lot of astronomers that have outlandish ideas, and most of them aren’t taken seriously by the community, and most of the time the media don’t really give attention to them.”

Loeb has two decades’ worth of experience and is well regarded in the field. But that background doesn’t come up in news stories. Harvard does.

Loeb even looks the part of someone you’d believe about, well, an extraterrestrial spaceship zooming past Earth. Bespectacled, with a neat haircut, Loeb is the antithesis of the History Channel’s disheveled, wild-haired man-turned-meme, who mentioned aliens one too many times. If both men approached you on the street and told you aliens existed, which one would you believe?

Several astronomers I spoke with echoed Gaensler’s sentiments. So did Loeb himself. He recognizes that his name-brand employer likely attracted the news organizations—and probably primed their readers to trust him.

“It’s not just affiliation; it’s the fact that I’m chair of the astronomy department [at Harvard],” Loeb said. He rattled off a series of other legitimizing titles: director of the Institute for Theory and Computation; founding director of the Black Hole Initiative; chair of the Board on Physics and Astronomy of the National Academies; chair of the scientific committee for the Breakthrough Starshot Initiative.

Coming from an expert at a high-prestige institution, with credentials in the relevant field, news of an encounter with extraterrestrial life would be more believable to most people, says Michael Varnum, a psychology professor at Arizona State University. Varnum studies a very niche and very relevant topic: how the public might react to the news of an alien discovery.

The prestige effect is magnified, too, “if the evidence or arguments are technical enough that it is not easy for laypeople to understand or evaluate them,” he says. The journalists who cover Loeb make him seem even more trustworthy. “Part of what reinforces that credibility is coverage in news outlets with reputations for serious journalism,” Varnum says.

Loeb, pleasantly surprised by the media reaction, has leaned into the press interest. He has given dozens of interviews to a variety of news organizations since his paper was published in November, from The Verge to The New Yorker.

Some astronomers, however, wish he’d stop.

“‘Oumuamua was exciting, but I’m getting a little frustrated,” says Karen Meech, an astronomer at the University of Hawaii Institute for Astronomy, and one of the people who discovered the interstellar object. “Now it just won’t die.”

Meech, you might have guessed, doesn’t buy Loeb’s theory.

‘Oumuamua is unlike anything else astronomers have seen in the solar system. It doesn’t orbit the sun, like everything else around here. It has an extremely elongated shape. It’s moving very fast, and even seemed to accelerate as it sped through our part of the solar system.

But many astronomers, including those who discovered ‘Oumuamua, say that these features can be attributed to natural phenomena. That acceleration, for instance, could have been caused by icy particles of comet melting in the sun’s warmth.

Astronomers also checked ‘Oumuamua for signs that it came from a technologically advanced alien civilization. (I use “checked” loosely here, because the best way to truly determine where ‘Oumuamua came from is to chase after it with a spacecraft, which modern technology can’t do.) In December 2017, the Green Bank Telescope in West Virginia, one of the world’s most powerful radio observatories, tuned toward ‘Oumuamua and listened for faint radio transmissions. The idea to do it came from Loeb himself. The telescope didn’t detect anything.

“That doesn’t necessarily prove anything, of course,” says Seth Shostak, an astronomer at the SETI Institute. “The fact that we didn’t pick up transmissions doesn’t rule out the possibility that [‘Oumuamua] could be something directed here.”

It’s not the suggestion of alien origins that bugs Meech and other astronomers. When faced with puzzling cosmic phenomena, astronomers must explore myriad possibilities, including extraterrestrial ones. The alien option is the least likely explanation, as history has shown, but it’s always on the table.

What bothers them is how Loeb has presented this potential explanation to the press. Unlike in his paper, which hedges with many a “may” and “might,” the astrophysicist sounds certain in news stories. In The Verge: “I cannot think of another explanation for the peculiar acceleration of ‘Oumuamua.” In The New Yorker: “It is much more likely that it is being made by artificial means, by a technological civilization.” To me, in a recent interview: “In my mind, it’s not speculative at all.”

“It doesn’t look identical to things we would see in our solar system, but why should you expect that if it’s coming from elsewhere?” Meech says. “We would all love to have discoveries of aliens, but if you’re going to go down that route, you have to have ironclad evidence.”

Loeb says that the peculiarities of ‘Oumuamua are evidence. In his view, the acceleration could be a result of ‘Oumuamua, an artificial probe, taking advantage of free solar energy for an extra push.

Loeb and his colleagues at Breakthrough Starshot, a million-dollar project, are trying to develop such technology, known as lightsails, to send to the star nearest our own. He resists the suggestion that his work is unscientific speculation, and says public discussion of potential explanations—all of them—gives laypeople a real-time look at the scientific process.

“Very often scientists say, Let’s not communicate to the public; let’s talk among ourselves,” he said. “They build this ivory tower, don’t explain what they’re doing, and then they come out with a statement once they know the answer.”

Some astronomers are grateful for Loeb’s approach, even if they’re wary of his certainty. “He is using tenure and his stature the way we all imagine it’s supposed to be used: As a shield so that he can explore potentially unpopular research avenues without fear of retribution or ostracism,” Jason Wright, an astronomer at Pennsylvania State University, wrote in a recent blog post. “We all imagine that’s what we would do in his position (I hope!) but too often it ends up just being a club to get junior scientists to conform to one’s vision for what ‘proper’ science looks like and what ‘good’ problems are.”

Wright proposed a controversial theory of his own in 2015, when telescopes detected a strange clump of matter orbiting a nearby star. He and his fellow scientists suggested that the material could be megastructures built by an advanced civilization. A few years later, the same scientists concluded that the megastructures were likely just cosmic dust.

“History is on the side of skepticism when it comes to this stuff,” Shostak says. Scientists who do think we could be closer to discovering extraterrestrial life worry that breathless news coverage of weird cosmic phenomena could negatively affect the reception of the real deal—whenever that comes along.

“If and when we do find extraterrestrials—and I think there’s a real chance that we might detect some sort of life, intelligent or not, in the next decade or two—we’re going to have a ‘boy who cried wolf’ problem,” says Gaensler, the University of Toronto astronomer. “The people who find real evidence of this are probably not going to get the credit they deserve, because we’ve heard this all before.”

In popular culture, Earth’s first encounters with extraterrestrial life are unequivocal. One moment, we’re alone; the next, we can’t deny the existence of aliens. But in reality, the first evidence of alien life—like the early evidence in many scientific breakthroughs—could look much less certain. If there’s one lesson from this story, it’s that the public’s willingness to get excited about it might depend on where the people who first discover aliens work. An Ivy League affiliation wouldn’t hurt.



Identifying a killer can be difficult when it seems like every murder weapon imaginable has been used in the crime, and when the victim is the entire planet. About 252 million years ago, a rich and wonderful world was annihilated in the worst mass extinction ever: the end-Permian, a catastrophe with no close competitor in Earth’s history. Volcanoes of a truly preposterous scale erupted in Siberia over many thousands of years, loosing all manner of chaos on the world. Rounding up, everything died.

Diagnosing the particular flavor of chaos responsible for this mass death has proven elusive. The Siberian Traps, now long retired as a vast swath of basalt plateaus in the far northern reaches of Russia, might have poisoned the world with mercury. Or maybe they destroyed the ozone layer by incinerating huge underground layers of ancient evaporites. Or perhaps they acidified the planet with sulfur dioxide and carbon dioxide, stripping vegetation, killing corals worldwide, and altering the chemistry of the planet’s soil so that dirt would have tasted like vanilla. Or maybe the Siberian Traps wracked the planet with brief volcanic winters, or they poisoned the planet with carbon dioxide itself, or the oceans became stagnant and poisoned with toxic hydrogen sulfide. Maybe that’s what killed everything.

Or maybe the oceans became stratified and nutrient-starved, and phytoplankton suffered. Or perhaps it was a lack of oxygen in the ocean that suffocated everything, or maybe it got just too damn hot. Some paleontologists have thrown up their hands and yielded to this overdetermination of kill mechanisms at the end-Permian, proposing an inelegant Murder on the Orient Express hypothesis of mass extinction that implicates the entire suite of killers. A new study, though, claims to pinpoint the primary killer from this murderers’ row: Among the slew of Very Bad Things implicated in the worst calamity the Earth has ever known, it was the global-warming-driven ocean anoxia that stands out as the primary agent of Armageddon. And in this reaper of the Paleozoic, the study’s authors see a future menace.

“I think this study shows the end of the road that we’re heading down,” says the lead author, Justin Penn of the University of Washington, about our modern, warming, and increasingly suffocating oceans.

As we’ve known since the 1860s, carbon dioxide is a very important greenhouse gas, and if you increase the amount of it in the atmosphere, it makes the planet warmer. At the end of the Permian, the volcanoes of Siberia, by burning through a giant basin filled with coal and other carbon-rich rocks, emitted enough carbon dioxide to warm the planet by a sweltering 10 degrees Celsius or so. Coincidentally, this is about the same magnitude of warming predicted for humanity in a modern burn-it-all scenario.

“If we are truly the stupidest intelligent species ever, we probably could do the same thing,” says Curtis Deutsch, a co-author on the study. “As it is, we’re headed toward 3 to 4 degrees Celsius of warming by the end of the century, which is nothing to sniff at. But 10 degrees isn’t that off the charts.”

As the world warmed 10 degrees more than 250 million years ago, up to 96 percent of species in the ocean went extinct (for comparison, roughly zero percent of modern species in the ocean have gone extinct so far in what’s been called “the sixth extinction”). For all the planet knew, it was time for complex life to close up shop after a nice quarter-billion-year run. After several millennia of eruptions from the Siberian Traps, the fossil record remained startlingly impoverished for almost 10 million years, before limply convalescing in the ensuing Triassic period.

To tease out what was primarily responsible for all this death in the oceans—in this, “the Great Dying”—Penn and his colleagues developed a climate model, not dissimilar to those used to project future warming on our own modern world. Only in Penn’s model, the continents were reunited. This was Pangaea, the mythic supercontinent that reached its apotheosis in the Permian period, joining Morocco with New Jersey and India with Antarctica. Then the team lit this ancient world on fire.

By jacking up the CO2 in their model high enough, Penn and his colleagues were able to re-create the scorching temperatures of the end-Permian mass extinction, searing their ancient climate model maps in worrying shades of red. The flip side of a hot ocean is one with less oxygen, and it has long been known that the oceans of the end-Permian were gasping for the stuff. This paleoceanographic fact has been uncovered by geologists who have found the sickly presence of laminated, pyrite-rich ocean rocks in end-Permian rock outcrops around the word—from the Salt Range in Pakistan to the old whaling redoubt of Spitsbergen in the Arctic Ocean. Even subtler, uranium isotopes in rocks from the catastrophe whisper dark rumors about the asphyxiation of the entire ancient ocean.

By driving up the temperature in his model, Penn re-created this end-Permian oxygen loss as well. This is because oxygen is less soluble in hot water, so heat alone can cause oxygen to plummet in the ocean. But a hotter ocean is also a more sluggish and stratified one, so the depths become starved of oxygen’s delivery as well. Even worse, the hotter it gets, the more oxygen animals need to power their metabolism, so hot water quickly creates a crisis of supply and demand. By populating his model ancient ocean with modern creatures, such as sharks and crabs and corals—creatures with a variety of tolerances to things like deoxygenation, temperature, and pH—and then letting all climate hell break loose, Penn found that it was the heat-driven loss of oxygen in the ocean, more than any other factor, that could explain the end of the world.

While essentially nothing was spared in this mass extinction, it appears from the fossil record that life at the poles was especially marked for destruction. And this makes sense in a world losing its oxygen. There’s more oxygen in colder waters at the poles, so the creatures there have adapted to it—and are especially sensitive to its diminishment. Meanwhile, tropical creatures are adapted to warmer, more oxygen-poor waters. So if anyone is to survive on a world that’s about to become outrageously hot and lose three-quarters of its oxygen, it will be those hardy inhabitants of the low latitudes. And that’s what’s seen in the fossil record. The tropics still faced an unthinkable cataclysm, but they fared mildly better. The predicament for polar creatures was not unlike those luckless creatures that today inhabit the tops of mountains, and that will have no higher altitude to which to escape in the coming decades. “They’re shit out of luck,” Deutsch says.

When the ocean loses its oxygen, it’s something of a great leveler compared with other hypothesized mass-extinction mechanisms. Ocean acidification, for instance (what happens when too much CO2 reacts with seawater), has previously been proposed as the great killer of the end-Permian. But while acidification can have a surprisingly variable effect on the survival of different kinds of sea life, there is hardly any selectivity at all when oxygen disappears from an ecosystem. Everyone dies, matching the near-universal signal of slaughter in the ancient ocean.

“This study suggests we should be worrying much more about hypoxia than about ocean acidification,” Deutsch says. “There’s vastly more resources being put into [studying] organisms’ responses to pH in seawater than there is into understanding temperature-dependent hypoxia. I think that the field has basically allocated those resources in exactly the wrong way.”

The modern oceans have already lost 2 percent of their oxygen since 1960, a remarkable loss driven mostly by coastal nutrient pollution and global warming. It’s an environmental problem that promises to worsen in the warmer world of the coming centuries, just like it did in the end-Permian. And if Earth’s past is any indication of its future, this asphyxiation could be truly world changing. The prospect has led dozens of paleoclimatologists, geochemists, and oceanographers to sign the Kiel Declaration on Ocean Deoxygenation, developed this September to raise global awareness of a problem with increasingly worrying geological precedent.

“This study shows that we’re on that same road toward extinction, and the question is how far down it we go,” Penn says.

To head off warming and drastic deoxygenation of the oceans, humanity can either stop burning fossil fuels or artificially dim the amount of sunlight reaching Earth’s surface—a kludgy solution that goes by the name of geoengineering. One of the most hotly debated methods of geoengineering would involve shooting sulfate aerosols out of planes and into the atmosphere to reflect sunlight back into space. Unfortunately, says the City College of New York geoscientist Benjamin Black, the end-Permian mass extinction represents something of a proof of concept for the idea, and it’s not pretty.

In a paper published last week in Nature Geoscience, Black and his co-authors describe not only the extreme warming of the climate around 252 million years ago, but also the extreme climate whiplashes that throttled the planet on much shorter timescales. These environmental seesaws, the researchers show, were induced by volcanic sulfur dioxide from the Siberian Traps, which would have briefly cooled the planet and masked the warming before being rained out of the atmosphere and allowing the planet to jump back into the high-CO2 inferno. Similarly, if humans embark on a geoengineering project of shooting sulfur dioxide into the air to head off all of the problems of warming, without drastically reducing the concentration of CO2 in the atmosphere—and if they ever give up on this project after it starts, for whatever reason, at any time in the next few thousand years—Black can imagine a similar disaster unfolding.

“So if you think about the Siberian Traps and the end-Permian mass extinction as a feasibility study for global warming and sulfur geoengineering, the results of that study were … not the best,” he said, referring to, quite literally, the worst thing that’s ever happened. “It’s worth asking ourselves whether we really want to make our current predicament even more like the end-Permian mass extinction.”



For three decades, the deadly bacteria sat in cold storage. Normally, Enterococcus faecalis lives harmlessly in the human gut. One particular strain, however, caused a series of strangely persistent infections at the University of Wisconsin Hospital and Clinics in the 1980s. The E. faecalis found its way into patients’ blood and grew resistant to antibiotics. Patients started to die.

The outbreak ran its course, but its origins remained a mystery. How do bacteria that live without causing distress in the gut—that probably are living in your gut right now—turn lethal? Fortunately, Mark Huycke, then a doctor at the University of Wisconsin, thought to save E. faecalis samples from the 1980s outbreak.

“It’s great that sometimes microbiologists don’t throw things away,” says Daria Van Tyne, an infectious-disease researcher now at the University of Pittsburgh and the lead author of a new paper on the 1980s outbreak. Three decades later, Van Tyne’s colleagues were able to sequence 62 frozen samples from the outbreak. Antibiotic-resistant E. faecalis still causes trouble in hospitals here and there. This study is one of the most detailed reconstructions yet of how E. faecalis can mutate inside patients’ bodies, going from innocuous gut dweller to deadly blood infection.

First, Van Tyne established that the E. faecalis outbreak strain really was exceptional. It had acquired powers that the E. faecalis of your gut may not have: toxin production, resistance to several antibiotics, resistance to the specific disinfectant used in hospitals, and tolerance of acidic pHs. This tolerance, Van Tyne thinks, is part of how E. faecalis spreads from patient to patient—the fecal-oral route. Patients would accidentally ingest the bacteria after touching contaminated surfaces; the bacteria then had to pass through the acidic stomach before reaching its favored environment, in the intestines.

This simple observation actually has profound implications for how E. faecalis continues to evolve, over and over again in each person it manages to infect. In people who are very sick, bacteria can leak from the gut into the bloodstream. But since gut bacteria are adapted to live in the gut, that relocation poses a challenge to E. faecalis. To cause a full-blown blood infection, they had to change, in order to thrive in human blood.

Van Tyne analyzed the novel mutations in the 62 samples, and she noticed they clustered in specific genes: cydABDC, where mutations help bacteria evade the human immune system; pbp4, where mutations confer resistance to antibiotics; and gntR, another spot that helped the bacteria escape immune cells, but that also made them resistant to antibiotics.

These changes had a surprising feature: Not every patient’s E. faecalis had the same mutations. In fact, the bacteria had different mutations, but in many of the same places. What this means is that gut-optimized E. faecalis is independently evolving to infect the blood of each patient. But it’s converging on the same strategy each time, tinkering with the same set of genes but making slightly different alterations.

“It’s evolution in action in the body,” says George Weinstock, a microbial genomicist at Jackson Labs. By sequencing all these different strains, scientists are able to watch evolution play out over and over again in the bloodstream of each patient.

Other bacteria that evolve from benign to troublesome may go through the same process. Van Tyne is now wrapping up a study with doctors at the University of Pittsburgh Medical Center about Klebsiella pneumoniae, which lives harmlessly on skin and in the gut but can sometimes cause lung infections. And while patient records from the 1980s E. faecalis outbreak have unfortunately been lost to history, she is able to compare genomes from different Klebsiella pneumoniae samples to see which ones made patients ill and which ones were fatal.

From the perspective of gut bacteria, evolving into a deadly blood invader is not a great long-term proposition. It’s pretty nice to hang out in the gut for decades over a human life span. But evolving to be so deadly as to kill your host means you have to go find a new one—or die. “It’s shortsighted, because it doesn’t think of after tomorrow,” says Sylvain Brisse, a population biologist at the Institut Pasteur.

Ultimately, blood-infecting E. faecalis lineages may be evolutionary culs-de-sac. They die out when the patient is cured or when the patient dies. But these particular E. faecalis  samples happened to be saved in a freezer. That’s the beauty of this paper, says Brisse. It captures a brief evolutionary blip that is of little consequence to E. faecalis as a species, but of huge consequence to the human unlucky enough to have encountered a deadly line of bacteria.



On a very cold January morning, in an athletic field in central England, Annemieke Milks watched as six javelin-throwers hurled a pair of wooden spears. Their target was a hay bale, “meant to approximate the kill zone of a large animal, like a horse,” says Milks, an archaeologist at University College London. And their spears were replicas of the oldest complete hunting weapons ever found—a set of 300,000-year-old, six-and-a-half-foot sticks found in a mine at Schöningen, Germany.

The athletes managed to throw their replicas over distances of 65 feet. That’s a far cry from modern javelin feats—the world record for men, set in 1996, is 323.1 feet. But it’s twice what many scientists thought that primitive spears were capable of. It suggests that, contrary to popular belief, early spear-makers—Neanderthals, or perhaps other ancient species like Homo heidelbergensis—could probably have hunted their prey from afar.  

“This experiment convincingly shows that in the hands of skilled users, spears are capable of killing at greater distances than previously thought,” says Jayne Wilkins, an archaeologist at the University of Cape Town. “This matters because it challenges a long-held idea” about the evolution of human weaponry.  

It’s abundantly clear that Neanderthals and other early hominins were capable hunters who made and used spears. But many researchers have argued that such weapons were too heavy and clunky to be thrown quickly or accurately, and could only be thrust into prey from close range. “The general consensus has been that they were limited to ranges of 10 meters,” or about 32 feet, Milks says.

According to this view, long-distance kills became possible only when modern humans invented specialized tools like spear-throwers, atlatls, or bows. Those superior weapons gave their bearers—our ancestors—an advantage over other hominin species, allowing them to safely bring down dangerous game that Neanderthals were forced to engage at close quarters. Perhaps that partly explains why the latter went extinct, while modern humans thrived.

But to Milks, this narrative always had a glaring problem. “We don’t have good data on how hand-delivered spears performed, so we can’t make a valid comparison,” she says. “The 10-meter distance was repeated over and over again, but not backed up with much evidence.” It came from an influential ethnographic review that considered the spear-throwing skills of many modern populations, but didn’t include adept groups such as the Tasmanian and Tiwi peoples of Australia. And it was bolstered by studies and anecdotal reports in which spears were thrown by anthropologists—hardly a decent stand-in for a skilled Neanderthal hunter.

For example, John Shea, an archaeologist at Stony Brook University, told me that he regularly takes his students into an athletic field and asks them to throw replica Schöningen spears at him. “If they hit me, I pledge to give them $20,” he said. “I’ve been doing this ‘experiment’ for 25 years, and I’ve neither got so much as a scratch on me nor parted with any cash. The spears come sailing in so low and slow I can usually just step sideways out of the way, bat them away with a stick, or if I am feeling really cocky, catch them in midair.”

A German sport scientist and javelin-thrower named Hermann Rieder had more success: In a small study, he managed to hit targets from around 16 feet away and suggested that the spears were useful weapons at longer distances. (A Wikipedia entry that cites his study and claims that “athletes could throw replicas up to 70 meters” is almost certainly wrong.)

To get more thorough data, Milks asked Owen O’Donnell, an expert in reconstructing ancient technology, to create the best possible replicas. He made two from spruce—the same wood as in the Schöningen spears. He built them to the same weight—1.67 and 1.76 pounds, respectively. And he finished them with stone tools to give them an authentic texture.

“I’ve been asked a lot if I threw in my own experiments,” Milks says. “But that wouldn’t tell us anything, other than that I’m a bad thrower.” Instead, she gave the spears to six trained javelin-throwers, whom she filmed with high-speed cameras. The participants hurled the spears both far and fast. It’s sometimes said that heavy spears would slow mid-flight and hit their targets with dull thuds. But Milks found that the replicas slowed very little, and landed with a kinetic wallop comparable to projectiles launched by bows or spear-throwing tools.

But Steve Churchill, an anthropologist from Duke University, notes that the javelin-throwers only hit their target a quarter of the time, and less so at the farthest distances. He’s also unclear as to how many of those “hits” would have been strong enough to, say, penetrate an animal’s hide. In his own experience (and he freely admits that he’s not a trained thrower), Schöningen replicas wobble a lot and tend to strike targets at glancing angles. They might fly far, in other words, but do they fly true? “This is a very good study,” he says, but “I don’t see a lot here to convince me that the Schöningen spears were effective long-range weapons.”

Milks counters that professional javelin-throwers go for distance, and aren’t trained to hit targets. Despite that, some of them clearly got the sense that the heavy spears behave unusually, vibrating along their axis and flexing on impact. The more experienced athletes compensated for this by putting spin on the spears. “That brought home how important it is to use skilled throwers,” Milks says. “What I really want to do now is to go to hunter-forager groups and have them show us what these spears are capable of. They use spears from age 6, which is something I can’t replicate with javelin athletes.”

“There’s also a hypothesis that these spears required a lot of training, and a big robust body to use them properly,” she adds. Spear-throwers and bows may have given their users an edge not because they launched projectiles farther or faster, but because they could be picked up more easily, by more members of a group. As technology, they weren’t inherently superior, just more user-friendly. “That’s an idea that’s worth going forward with,” Milks says.  

This isn’t to say that Neanderthals would have always thrown their spears. Last year, the archaeologist Sabine Gaudzinski-Windheuser analyzed Neanderthal-inflicted wounds on the fossil remains of two deer; after a whirlwind forensic analysis, she concluded that the animals were killed by spears thrust from below, not thrown from above. Neanderthals, she told me, hunted cattle in their prime, hibernating cave bears, and entire herds of horses or reindeer. “That these very different prey species, living in very different environments, necessitated very high flexibility in hunting tactics is a given,” she said.

Indeed, the Schöningen finds attest to that flexibility. Some spears could have been thrown, but others had kinks in them and were tapered only at one end. “That wasn’t a throwing spear,” Milks says. “It looks like [Neanderthals] had a collection of different technology at that site.”

The weapons are only half the story, too. There’s also the matter of their wielders, and some researchers have argued that Neanderthals were anatomically incapable of a strong throw. Milks believes that the “evidence for that is quite weak,” although she admits that her study of human javelin-throwers says nothing about the throwing arm of Neanderthals.

Despite that, experiments like hers are very welcome, says Katerina Harvati of the University of Tubingen. “It is really essential to understanding the behavior of Neanderthals and other Pleistocene ancestors, and to accurately interpreting archaeological findings such as the extremely rare spears from Schöningen. This study goes a long way to clarifying how those spears may have been used.”

Last year, Harvati and her colleagues busted another common misperception about Neanderthals: that they were especially prone to traumatic head injuries, perhaps because of their proclivity for close-range hunts. In fact, they were no more likely to get bonked on the head than contemporaneous humans. “Studies like these,” Jayne Wilkins says, “add to a mounting body of evidence against the old-fashioned idea that Neanderthals had only subhuman capacities, employed ineffective technologies, and were continuously struggling for survival.”



The Atacama Desert in northern Chile is the driest place on Earth, a parched rockscape whose inner core supports zero animal or plant life. Only a few hearty species of lichen, algae, fungi, and bacteria can survive there—mostly by clinging to mineral and salt deposits that concentrate moisture for them. Still, it’s a precarious life, and these microbes often enter states of suspended animation during dry spells, waking up only when they have enough water to get by.

So when a few rainstorms swept through the Atacama recently, drenching some places for the first time in recorded history, it looked like a great opportunity for the microbes. Deserts often bloom at such times, and the periphery of the Atacama (which can support a little plant life) was no exception: It exploded with wildflowers. A similar blossoming seemed likely for the microbes in the core: They could drink their fill at last and multiply like mad.

Things didn’t quite work out that way. What should have been a blessing turned into a massacre, as the excess water overwhelmed the microbes and burst their membranes open—an unexpected twist that could have deep implications for life on Mars and other planets.

The Atacama has been arid for 150 million years, making it the oldest desert on Earth. Its utter lack of rain can be traced to a perfect storm of geographic factors. A cold current in the nearby Pacific Ocean creates a permanent temperature inversion offshore, which discourages rainclouds from forming. The desert also lies in a valley that’s wedged between the Andes Mountains on the east and the Chilean Coastal Range on the west. These mountains form a double “rain shadow” and block moisture from reaching the Atacama from either side. The desert’s driest point, the Yungay region, receives fewer than 0.04 inches (or 1 millimeter) of rain a year. Death Valley in California gets 50 times more rain annually, and even the driest stretch ever recorded there still averaged 0.2 inches a year.

That’s why the recent rainstorms in the Atacama—two in 2015 and one in 2017—were so startling. They left behind standing lagoons, some of which glowed a lurid yellow-green from the high concentration of dissolved mineral. Nothing like this had happened in Yungay since at least the days of Columbus, and possibly much earlier. No one quite knows what caused the freak storms, but climate change is a likely culprit, as the cold sea currents have been disrupted recently. This allowed a bank of rainclouds to form over the Pacific Ocean. The clouds then plowed over the Chilean Coastal Range and dumped water onto Yungay and surrounding areas.

Five months after the June 2017 storm, a group of scientists led by Armando Azua-Bustos, a microbiologist at the Universidad Autónoma de Chile, and Alberto Fairén, a planetary scientist at Cornell University, visited the Atacama to sample three lagoons. They wanted to study the microbes that had gotten swept into them and document how well they were handling this precious influx of water.

Not very well, it turned out. As detailed in a recent paper, the scientists found that the majority of microbes normally present in the soil had been wiped out—14 of 16 species in one lagoon (88 percent), and 12 of 16 in the others (75 percent)—leaving behind just a handful of survivors. On a local scale, the rains were every bit as devastating as the asteroid that wiped out the dinosaurs 66 million years ago, which killed off 70 to 80 percent of species globally.

The scientists traced this massacre back to the very thing that allows the microbes to survive in the Atacama: their ability to hoard water. Under normal conditions, this miserliness pays off. But when faced with a glut of water, they can’t turn off their molecular machinery and say when. They keep guzzling and guzzling, until they burst from internal pressure. Azua-Bustos and Fairén’s team found evidence of this in the lagoons, which had enzymes and other organic bits floating around in them—the exploded guts of dead microbes.

Water in the Atacama, then, plays a paradoxical role: It’s both the limiting factor for life as well as the cause of local extinctions. And while the death of some bacteria and algae might not seem like a big deal, these microbes are actually famous in some circles as analogues for life on Mars.

We don’t know whether Mars ever had life, but it seemed like a promising habitat for its first billion years, with vast liquid oceans and plenty of mineral nutrients—not much different than Earth. One billion years probably wasn’t enough time for multicellular life to arise, but Martian microbes were a real possibility.

Starting around 3.5 billion years ago, however, our planetary cousin went through a severe drying-out and began to lose its water. Some was sucked deep underground, and most of the rest got dissected into H2 and O through various chemical reactions. Eventually these processes turned most of Mars’s surface into one giant Atacama Desert, forbiddingly dry and dotted with mineral deposits. NASA, in fact, uses the Atacama landscape to test rovers and other equipment for Mars missions.

But there’s an important wrinkle here. The great drying-out didn’t happen instantly; it took eons. And during the transition, when Mars was fairly parched but still had some liquid water, it experienced floods that would have made Noah blanch. We can see evidence of them on the surface of Mars today: The dry riverbed channels and alluvial fans that those floods left behind are the largest in the solar system.

This tumultuous state—a hyper-dry climate, punctuated by massive washouts—would have been catastrophic for life on Mars. The slow drying-out would have choked off the vast majority of microbes, grinding them into dust. Any that managed to pull through, scientists have argued, probably would have resembled those in the Atacama today: water-hoarders clinging to oases of mineral deposits in a vast red desert.

But if Martian microbes did resemble their Atacama counterparts, then the washouts probably finished them off, swelling them with water and bursting them like balloons. After a certain point, in other words, Mars might have been too wet to sustain the life that evolved there.

It’s possible, of course, that a few lucky pockets on Mars escaped flooding entirely, allowing microbes there to survive until today. But if so, Azua-Bustos and Fairén point out, our current approach to finding these holdouts could be doomed to fail. NASA sent the famed Viking lander to Mars in 1976, for example, largely to search for life there. To this end, the lander scooped up several soil samples for analysis—and immediately doused them with water. Viking might have come up empty anyway, but given the Atacama results, it also might have killed off the very thing it was looking for.

What applies to Mars applies to other worlds as well. Over the next decade, several new space telescopes will expand the hunt for life beyond our solar system, to planets orbiting distant stars. Scientists are especially keen to find planets that have liquid water, since as far as we know, liquid water is essential to life.

But that statement might need qualification. Water can give life, certainly. As planets change, however, and life evolves in tandem, it can also snatch life away.



As the humans go about their affairs, living atop a thin crust floating on molten rock, the liquid iron in the Earth’s core is churning in strange, erratic ways.

This is a problem because those humans, clever in some ways, have figured out that the movement of the liquid iron creates a magnetic field. For centuries, their compasses have pointed “north.” But where that is, exactly, is changing.

After observing, if not exactly understanding, the magnetic field’s recent behavior, scientists decided to update the World Magnetic Model, which underlies navigation for ships and planes today. As Nature reported, the update was supposed to come January 15. But the model is jointly developed by the British Geological Survey and the U.S. National Oceanic and Atmospheric Administration, and the U.S. government is shut down.

The NOAA web page for the World Magnetic Model currently says, “The website you are trying to access is not available at this time due to a lapse in appropriation.”

This isn’t a big crisis: The north magnetic pole has always drifted. Since scientists began tracking its location in the 19th century, it has moved from Canada toward Siberia. (The north magnetic pole is close to but distinct from the north geographic pole, whose location is determined by the axis on which the Earth spins.) For most of the 20th century, the pole moved about nine miles a year. Then, beginning in the 1990s, it moved about 35 miles a year.

What’s making the north magnetic pole speed up? Scientist have proposed that a jet of liquid iron under Canada may be dragging it toward Siberia. Interestingly enough, notes Ciaran Beggan, a geophysicist with the British Geological Survey, the south magnetic pole has not moved much at all. 

On top of the North Pole’s movement, scientists have noticed a series of mysterious pulses in the Earth’s magnetic field. No one can say what causes them. “Our knowledge of what’s happening in the Earth’s core is very limited,” says Arnaud Chulliat, a geophysicist at NOAA and the University of Colorado Boulder. But the World Magnetic Model cannot account for those pulses, and its predictions are especially off near the North Pole.

One of these pulses came in 2016, right after a scheduled update to the model. “The error started to grow faster than usual,” says Chulliat. So the team decided to compute a new version using satellite data. They planned a release on January 15, 2019, ahead of the scheduled update that usually happens every five years. The new model has the North Pole 25 miles away from what the previous one predicted, according to Beggan. 

The updated model itself is ready, and Chulliat says they can make it downloadable for users within a few days. They’re just waiting for the government to reopen. 

Practically speaking, this delay in the World Magnetic Model update matters only to those currently engaged in navigation requiring great precision around the North Pole. The farther away you are from the pole, the smaller the error. Anyone looking at the compass in a phone in the United States will find it pointing northward with reasonable accuracy. 

But in another way, the episode underscores just how mysterious the inner workings of the Earth still are, and how attempts to understand such global phenomena require collaboration and stability that perhaps should not be taken for granted, given humanity’s own inconstant nature.



The cosmos would seem like a dull and desolate void if it weren’t for the Hubble Space Telescope. The space-based observatory has revealed a trove of colorful, cosmic wonders, from sparkling stars and galaxies, to glowing clouds of gas and dust, to the glittering shards left behind after a supernova. Hubble has found these cosmic jewels scattered across the universe and followed them back in time, reaching almost to the Big Bang.

The work behind this celestial catalog begins back on Earth, at the Space Telescope Science Institute in Maryland. Each year, the institute receives more than 1,000 proposals from scientists around the world asking for a piece of Hubble’s busy observation schedule. The process is quite competitive: Only about 200 proposals are accepted, selected by committees of astronomy experts.

Unfortunately, the process may be flawed, too. In 2014, the Space Telescope Science Institute noticed a pattern: In more than a dozen review cycles since 2001, proposals led by men consistently did better than proposals led by women. The Institute’s leadership wondered whether the way they assessed proposals had something to do with it; under the current system, reviewers know the identities of applicants—including their gender—but applicants don’t know the identities of reviewers. It’s a standard setup in the sciences, from telescope proposals to paper submissions, but perhaps it had allowed subtle biases to creep in.

This year, the institute decided to conduct a double-blind review of Hubble proposals, which hid nearly all information about applicants, including gender, from reviewers. Of the 351 male-led proposals, 28 were picked. Of the 138 female-led proposals, 12 were chosen. That translates into an 8.7 percent success rate for female researchers, and 8 percent for male researchers.

Under the new review system, the disparity that Hubble’s decision-makers had seen year after year had disappeared.

Priyamvada Natarajan, a theoretical physicist at Yale who led the effort, said she was surprised at the outcome. “I was ready to see a small change, but not complete parity,” she said.

But she wasn’t surprised that the years-long pattern had been broken. Research has found ample evidence that men and women are evaluated differently in the same settings, and the Hubble program is no different, she said.

“I firmly believe that conscious and unconscious bias both operate quite strongly in these kinds of reviews,” Natarajan said. “They’re not entirely objective.”

Last year, the Space Telescope Science Institute brought in some outside researchers to sit it on reviewer discussions and evaluate the process. They reported that nearly half of all discussions included some focus on the applicants rather than the science in their proposals. “He is very well qualified,” one reviewer said. “My group has benefited a lot from previous work from this team,” said another. To the outside consultants, this process wasn’t objective at all. They recommended that the institute implement a fully anonymous review system.

The new system presented reviewers with applications without any names or identifying details. Outside observers were brought in to listen to their discussions again. This time, the tenor of the deliberations was different. “It was really noticeable how the discussion were really focused much more on the science,” said Natarajan, who has participated in the discussions of both settings. Some of the reviewers said it was “almost liberating” to focus on the science of the proposals, and not on the people who wrote them.

If they wanted, reviewers could learn about the applicants after they made their final decisions. The institute had applicants submit separate documents detailing their backgrounds and expertise, just in case reviewers wanted to make sure that the team could, in fact, execute their proposals. Natarajan said the majority of reviewers didn’t seek out those documents. “They were like, it doesn’t matter, we are confident that we picked the best science,” she said.

Natarajan cautions that it’s too early to determine whether gender biases are the only biases that played a role in the process and, if they did, by how much. The review process wasn’t a controlled experiment. “We have to continue this, and it’ll take time to see whether these trends hold up,” she said.

The pattern that the Hubble program identified in its reviews is not new, and it affects some of the most powerful—and coveted—telescopes around the world. A 2016 survey of more than 13,000 applications to the European Southern Observatory, which operates several ground-based telescopes, found that female applicants had significantly lower chances of getting telescope time. Another 2016 analysis, of applications to the National Radio Astronomy Observatory, which also runs ground-based telescopes, found the same effect. This year, an analysis of requests for Canadian telescopes found that proposals written by women were rated significantly worse than those by men. In all these cases, reviewers were aware of the identities of the applicants.

Some institutions have implemented anonymous review process in an attempt to protect against potential perceptions of bias. The journal Biological Conservation switched from single- to double-blind reviews in 2014, not because it had seen any evidence of bias in its process, it said, but just in case. “This will ultimately be in the best interests of furthering conservation science.” Nature and its suite of journals followed suit in 2015, offering researchers the choice between the two systems, but analyses have shown that the number of study authors who actually opt for an anonymous review is low.

Space Telescope Science Institute officials say they will continue to use double-blind reviews. Natarajan hopes that over time, researchers can focus on other factors beyond gender, like country of origin, university or institution affiliation, and how well-known applicants are in their field. But this experiment is getting quite the late start. Hubble launched 28 years ago, and the observatory is aging. Engineers don’t know exactly when Hubble may stop functioning, but they are prepared for that moment to come soon.

I asked Natarajan whether she was frustrated that officials decided to overhaul the proposal system now, when requests for Hubble are bound to become even more competitive, and time is running short. What else could Hubble had seen, if the process had been different, if the pool of applicants were more diverse?

“It’s a bit upsetting that there was more struggle than needed to be because basically the system was rigged and the playing field was simply not level,” Natarajan said.

Officials are looking ahead to the next great space telescope, the James Webb, which will be 100 times more powerful than Hubble. Webb is scheduled to launch in 2021. Ken Sembach, the director of the Space Telescope Science Institute, said the organization is considering using double-blind reviews for Webb proposals from the outset, but hasn’t made a formal decision yet. “We are still reviewing the results from the recent Hubble review and wish to discuss them with our stakeholders at NASA and in the science community,” he said.

Natarajan feels like the decision has already been made. For her, the results of even one round were encouraging enough. “I think those days are gone,” she said of single-blind reviews. “The impact is so obvious that there’s just no way that we can go back now.”



In 2012, Lindsay Zanno was searching for dinosaur fossils in the hillsides of eastern Utah when she found a bone protruding from the hillside. Most of it was still wreathed in rock, but Zanno, who heads the paleontology division at the North Carolina Museum of Natural Sciences, could already tell that it was the limb of some two-legged meat eater. “That was a thrilling moment,” she says.

It took several years to fully free the bone, along with a few others, from the rock, and several more to work out that they were once the right leg of a tyrannosaur—a cousin of the famed Tyrannosaurus rex. But at just 170 pounds and six feet long from nose to tail, this new human-size dinosaur was much smaller than its more famous relative. Growth rings in the bones, much like those in a tree trunk, showed that the individual was at least seven years old and nearly mature. “It’s certainly not a very young individual of a very large species,” Zanno says. Instead, it was an adult—just a small one.

Zanno named it Moros, after the embodiment of impending doom in Greek mythology. It’s a rather dramatic name for such a diminutive dinosaur, but it’s apt considering the creature’s age. Moros lived 96 million years ago, preceding Tyrannosaurus by a good 30 million years. It was a miniature harbinger of the bone-crunching tyrants to come—impending doom, indeed. And its age and size offer important clues about one of the most dramatic plot twists in the dinosaur story.

During the late Jurassic period, at a time when Asia and North America were connected to each other, the first tyrannosaurs evolved in the former continent before crossing over into the latter. At first they were just one of many groups of small-bodied hunters, all skulking subordinately in the shadow of far bigger predators, such as the allosaurs, a family of toothy, two-legged dinosaurs with dangerous claws. But at some point during the Cretaceous period, the allosaurs died out. The tyrannosaurs quickly usurped them, evolving into apex predators that ruled unchallenged in the northern continents until an asteroid strike (perhaps in combination with volcanic activity) ended their reign.

That switch from allosaurs to tyrannosaurs “was a defining event in dinosaur evolution, but we still don’t know very much about it,” says Steve Brusatte from the University of Edinburgh. “We’re not really sure exactly when it happened, if it happened quickly or was more of a prolonged battle, or if it happened across the northern continents all at once.”

These mysteries remain because of a lack of tyrannosaur fossils, especially in North America. Paleontologists have found many small-bodied species that are about 150 million years old, but the record then goes dark until the biggest species appear about 80 million years ago. During the 70 million intervening years: nothing, except for a few teeth. “It’s like a historian trying to understand how the Ming dynasty gave way to the Qing dynasty, but with only a few scraps of parchment to go by,” Brusatte says.

Moros, however, lived squarely within that tyrannosaur-free zone. Its discovery means that 96 million years ago, North American tyrannosaurs were still pretty small. That dramatically narrows the timing of their eventual ascension to a much shorter 15-million-year span. “That’s very quick,” Zanno says, for an animal to increase in mass by more than 100 times.

“This doesn’t completely solve the mystery of why the tyrannosaurs took over from allosaurs, but like a partial fingerprint at a crime scene, it provides important context and helps rule out some theories,” Brusatte says.

A similar scenario played out in Asia. Three years ago, Brusatte and his team announced the discovery of a tyrannosaur from Uzbekistan called Timurlengia, named after the central-Asian conqueror. It lived 90 million years ago, and was the size of a horse, suggesting that Asian tyrannosaurs were also small and medium-size for most of their history. “There is still a gap of about 10 million years between Timurlengia and Moros and [the later] huge tyrannosaurs,” Brusatte says. “Filling that gap, and hopefully with more complete skeletons, will be the next big breakthrough.”

In the meantime, Zanno and her colleagues are continuing their work in eastern Utah, focusing on sites from the early and middle Cretaceous. These rocks are much older than those that harbor celebrities such as Tyrannosaurus and Triceratops, and since many of the fossils within them are badly preserved, fewer paleontologists have studied them. That the sun can bake the ground to about 130 degrees Fahrenheit doesn’t help. “It’s a very difficult place to work,” Zanno says.

But a decade of hard labor has already paid off. Aside from Moros, the team also recently announced the discovery of Siats—a 30-foot-long allosaur whose name (pronounced see-ots) comes from a man-eating monster of Ute mythology. They’re also working hard to describe three new species of dinosaur and one new turtle. “We’re working to uncover an entirely new ecosystem,” Zanno says.

By unearthing this poorly understood world, she hopes to learn more about why allosaurs such as Siats died out. At the time, global temperatures were rising, as were sea levels. Flowers appeared around the world, and several Asian animals expanded into North America. Perhaps some combination of these changes conspired to dethrone the allosaurs, creating open opportunities that the tyrannosaurs then seized.

After all, Moros’s leg suggests that these animals were fast, agile hunters, while Timurlengia and other early tyrannosaurs show that the group already had well-developed senses. “As soon as the allosaurs went extinct, these early tyrannosaurs like Moros were primed to make the jump to being top predators,” Zanno says.

If this story is right, it means that the world’s most famous dinosaur was the beneficiary of good luck. “Tyrannosaurs are such iconic predators that people think they somehow outcompeted their rivals and were destined to be the top predators of the day,” Zanno says. “But Moros helps us understand that their success was linked to the extinction of allosaurs. Had that not happened, these tiny animals wouldn’t have been able to assume the top predator roles. There was no destiny in the ascent of tyrannosaurs.”



What Anita Radini noticed under the microscope was the blue—a brilliant blue that seemed so unnatural, so out of place in the 1,000-year-old dental tartar she was gently dissolving in weak acid.

It was ultramarine, she would later learn, a pigment that a millennium ago could only have come from lapis lazuli originating in a single region of Afghanistan. This blue was once worth its weight in gold. It was used, most notably, to give the Virgin Mary’s robes their striking color in centuries of artwork. And the teeth that were embedded with this blue likely belonged to a scribe or painter of medieval manuscripts.

Who was that person? A woman, first of all. According to radiocarbon dating, she lived around 997 to 1162, and she was buried at a women’s monastery in Dalheim, Germany. And so these embedded blue particles in her teeth illuminate a forgotten history of medieval manuscripts: Not just monks made them. In the medieval ages, nuns also produced the famously laborious and beautiful books. And some of these women must have been very good, if they were using pigment as precious and rare as ultramarine.

If pigments can be preserved in tartar—the gunky yellow stuff on teeth that dental plaque hardens into—that means that fibers, metals, and other dyes could be, too. “This is genuinely a big deal,” says Mark Clarke, a technical art historian at Nova University Lisbon who was not involved in the new study. You could imagine identifying metalworkers, carpenters, and other artisans from the particles embedded in tartar, Clarke says. “It’s opening up a new avenue in archaeology.”

Radini and her co-author, Christina Warinner, did not set out to study the production of illuminated manuscripts. Radini, now at the University of York, was initially interested in starch granules in tartar as a proxy for diet, and Warinner, a microbiome researcher at the Max Planck Institute, wanted to study the DNA of ancient oral bacteria. But the blue particles were too striking to ignore.

“Can you imagine the kind of cold calls we had to make in the beginning?” says Warinner. “‘Hi, I’m working with this thing on teeth, and it’s about 1,000 years old, and it has blue stuff in it. Can you help me?’ People thought we were crazy. We tried reaching out to physicists, and they were like, ‘I don’t know what you’re talking about.’ We tried reaching out to people working in art restoration, and they were like, ‘Why are you working with plaque?’” She eventually reached physicists at the University of York who helped confirm the blue did indeed come from the mineral lazurite, derived from lapis lazuli.

But art experts were still skeptical. Some dismissed the idea that a woman could have been a painter skilled enough to work with ultramarine. One suggested to Warinner that this woman came into contact with ultramarine because she was simply the cleaning lady.

Warinner eventually reached out to Alison Beach, a historian at Ohio State University who studies female scribes in 12th-century Germany. Over the past couple of decades, Beach and other scholars have cataloged the overlooked contributions of women to medieval book production. The challenge, Beach says, is that while most manuscripts with signatures are signed by men, the vast majority of manuscripts are unsigned. But a small number of surviving manuscripts are signed by women, and scholars have found correspondence between monks and nuns about book production.

Beach even came across a letter dated to the year 1168, in which a bookkeeper of a men’s monastery commissions sister “N” to produce a deluxe manuscript using luxury materials such as parchment, leather, and silk. The monastery where sister “N” lived is only 40 miles from Dalheim, where the teeth with lapis lazuli were found. Beach also identified a book using lapis lazuli that was written by a female scribe in Germany around a.d. 1200. The pigment would have traveled nearly 4,000 miles from Afghanistan to Europe via the Silk Road. All the evidence suggests that female scribes were indeed making books that used lapis lazuli pigment in the same area and around the same time this woman was alive.

The team considered a number of alternative ways lapis lazuli could have gotten into the woman’s dental plaque. Could the particles have come from repeated kissing of an illuminated manuscript? This practice didn’t become popular until three centuries after this woman likely died. Could it have come from lapis ingested as medicine, as suggested in Greek and Islamic medical texts? There’s little evidence that prescription was followed in 12th-century Germany. The lapis lazuli particles were also especially fine, which requires a laborious grinding process. This detail in particular suggests that the stones were purposefully made into pigment.

The team concluded that two scenarios are most likely: The woman was a painter who could have ingested ultramarine paint while licking her brush to a point, or she breathed in the powder while preparing pigment for herself or someone else. You can almost begin to picture her, Beach says, sitting by herself laboring over a manuscript day after day. “For a medieval historian,” she adds, “this kind of clear material evidence of something from the life of an individual person is so extraordinary.”

Cynthia Cyrus, a professor at Vanderbilt who has also studied medieval scribes, told me that reading the paper was “the highlight of my day.” Like many monasteries, she noted, the one where this woman was buried was eventually destroyed in a medieval fire. There’s little evidence of what life was like there. But the woman’s teeth suggest that it could have been a site of highly skilled book production.

Warinner is continuing to study the particles embedded in old tartar. She and others have found everything from insect parts and the pollen of exotic ornamental flowers to opium, bits of wool, and milk proteins—all of which tell stories about what people ate and how they lived. The detritus of everyday life accumulates in the gunk that modern dentists are so vigilant about scrubbing off. “They aren’t thinking of future archaeologists,” Warinner jokes.



In the past 50 years, climate change has altered the weather of the United States, leading to milder winters, warmer nights, and sweltering summer heat waves. These changes will intensify in the decades to come; by the end of the century, for instance, Philadelphia could feel a lot like Memphis.

But a new study suggests that most Americans have not noticed these changes—and they never will.

For the past decade or so, different teams of social scientists have tried to answer the same question: Where does our sense of “normal” weather come from? Why do some days feel unusually hot, and some only normally hot? Were I to compare thee to a summer’s day, would I be thinking of a lifetime of summer days, the past few decades of summer days, or just some pictures of summer that I saw once in a book?

The new study, published this week in the Proceedings of the National Academy of Sciences, tries to answer this question by looking at Twitter data. Is the weather ever so unusual, the authors asked, that people tweet more about it? To find out, they matched a database of 2.1 billion geotagged tweets with another database of geotagged weather conditions. Then they filtered the tweets for weather-specific words, such as drizzly, scorching, and autumnal.

Americans’ sense of “normal” weather seems to reset about every five years, they found. People sent more weather tweets when it was unusually hot or cold outside, but their sense of what made for “unusual” weather was fairly shortsighted. Generally, if people had experienced an extreme temperature in the same month over the previous two to eight years, they were much less likely to tweet about it.

This is a challenging finding for many climate advocates, because it suggests that people update their sense of normal weather faster than climate change will occur. In other words, many Americans will simply never detect that anything has gone wrong with the weather, at least on a day-to-day basis. As Frances Moore, an author of the paper and an environmental science and policy professor at UC Davis, told me: “We can’t just expect people to walk outside and realize climate change is happening.”

In their data, Moore and her colleagues found that Twitter users updated their sense of cold weather just as quickly as they did hot weather. So users would sometimes complain about a seemingly frigid week in midwinter, even though outdoor temperatures were “not actually that cold in historical context,”’ she said. “It just felt cold because people’s idea of normal winter temperatures has changed.”

Earth’s Temperatures Will Rise—But We Might Not Notice

The study tells a larger story about climate change, one that I can recognize in my own experience. It suggests that global warming won’t feel as if someone is raising the atmosphere to a broil. Instead, it will feel as if we’re all ascending an endless staircase, without really knowing how high we’ve climbed. Every few years, people might remark about a dangerously hot summer or a worryingly warm winter. But after those temperatures come back a few times, we’ll stop noticing them. We’ll forget that the seasons were once different than they are now. And the cycle of extremes will start over again.

Yet the study can only really gesture at this idea, however compelling it might be. Aaron McCright, a sociology professor at Michigan State University who has studied public understanding of climate change, told me he is uncomfortable analyzing Twitter data to measure changing attitudes. Ultimately, only a computer program is up to the task of analyzing 2.1 billion tweets—and even then, computer programs make basic mistakes, get confused, and don’t recognize sarcasm. Even though humans double-checked a small sample of that program’s work, they can never clear the entire data set.

The study ignores other important questions, too. “You really want to try to account for the length of time a person has lived in an area when you are asking them to evaluate some weather as normal or abnormal,” McCright said in an email. But the study doesn’t do that.

It also doesn’t account for how much any one heat wave or cold snap was covered by the press, which could shape how often people tweeted about it. “Think about the polar-vortex wobble a few weeks ago,” he said. “Sure, most in the U.S. experienced much colder temperatures than normal. But we were heavily bombarded with major news stories before, during, and after the event telling us just how extreme the weather was.”

Finally, because only a fraction of Americans use Twitter, the study’s sample likely does not represent the U.S. population as a whole. “I’m just not sure what to make of this study,” he said.

Even the study recognizes some of these gaps. Moore stressed that the study does not examine perception of high-profile natural disasters, such as floods, wildfires, or hurricanes. Yet evidence suggests that Americans still take heed of those events. Last month, an AP poll found that “recent extreme weather events” are the main reason that Americans are coming to accept climate change.

For Alexa Spence, a psychology professor at the University of Nottingham, the study offers helpful lessons for scientists, the press, and anyone hoping to talk persuasively about climate change. “We should be making sure that … historical comparisons are selected appropriately” she said, so that we can properly appreciate today’s weather in its “full alarming enormity.”

After all, most of our weather has been unprecedented lately. We have just lived through the four hottest years ever measured. But what did winter bring back in 2014? How sweltering was that summer? A few years can be enough time to forget whatever felt different.



David Reif, now a biologist at NC State, realized his old paper had taken on a dangerous second life when he saw it cited—not in the scientific literature, but in a court case.

The paper was titled “Genetic Basis for Adverse Events after Smallpox Vaccination,” and it came up in 2016 when a vaccine-skeptical doctor tried to argue that it explained her patient’s development delays. The court was not persuaded, but Reif’s co-authors began hearing of yet other doctors using DNA tests to exempt patients from vaccines. Just this month, San Francisco’s city attorney subpoenaed a doctor accused of giving illegal medical exemptions from vaccination, based on “two 30-minute visits and a 23andMe DNA test.” On anti-vaccine blogs and websites, activists have been sharing step-by-step instructions for ordering 23andMe tests, downloading the raw data, and using a third-party app to analyze a gene called MTHFR. Certain MTHFR mutations, they believe, predispose kids to bad reactions to vaccines, possibly even leading to autism—a fear unsupported by science.

This interest in MTHFR can be traced right back to Reif’s 2008 paper, which linked a variant of the gene to “adverse events” after smallpox vaccines. It was a somewhat intriguing result then. A decade later, however, James Crowe, the senior author of the paper and the director of the Vanderbilt Vaccine Center, offers a blistering assessment of his own study: “It’s just not even a valid study by today’s methodology.” To use it for granting vaccine exemptions now, he says, is “illogical and inappropriate.”

What’s changed? The basics of genetics research. With MTHFR, opponents of vaccines have been able to exploit a lag between the advance in scientific knowledge and widespread understanding of it. In the past 15 years, mainstream genetics research has evolved—but in ways that are not always obvious to the public.

A lot of that confusion is in fact centered around MTHFR. In the early days of genetics research, scientists looking at a small number of genes in a small number of people found that certain MTHFR variants were linked to a range of maladies: blood clots, cancer, heart disease, pregnancy complications. This seemed to make sense, as MTHFR codes for an important enzyme in the body. But as scientists went from looking at hundreds to thousands to hundreds of thousands of people, they realized many of those variants were extremely common, found in up to 40 percent of the population in some cases.

More importantly, those associations with various diseases just didn’t hold up in bigger data sets and with better statistical tools. They had been flukes all along. MTHFR is not alone in this. The scientific literature is littered with “candidate genes” that turn out not to explain much at all. The American College of Medical Genetics and Genomics currently does not recommend testing for MTHFR.

But the word about MTHFR was already out. And the bold claims about the gene have lingered on alternative and naturopathic medicine sites. “It’s been hard to reverse because if you go to historical literature, you can find some literature to support your claim,” says Elizabeth Varga, a genetics counselor at Nationwide Children’s Hospital. “Without a big picture, without knowing the full story, I think that’s where people who want to exploit the information, they can exploit the information.” And now, mail-in DNA tests have made it relatively easy for anyone to get tested.

In 2017, 23andMe published a blog post noting that MTHFR was the “most asked-about gene by 23andMe customers.” Its scientists concluded that common MTHFR variants were not clinically useful to test. (That’s why anti-vaccine doctors have to download the raw 23andMe data and analyze MTHFR using a third-party tool such as Genetic Genie or Promethease.) The company told me it does not condone the use of its test to grant vaccine exemptions and pointed toward a disclaimer about using its raw data for medical or diagnostic reasons.

Interest in MTHFR and vaccines specifically seemed to have ticked up in 2016, when California outlawed personal and religious exemptions from vaccination. Doctors could still grant medical exemptions, however, and anti-vaccine websites started sharing possible reasons for doing so. MTHFR was listed as one of several, and for evidence they linked to Crowe and Reif’s paper. (Interestingly, the paper actually identified a second gene called IRF1 as well, but the focus has always been on MTHFR, perhaps because the latter gene was already familiar to the naturopathic community.)

Crowe says that understanding how genetics affect reaction to vaccines is still a legitimate area of research, but the 2008 paper was emblematic of that early, now outdated genetics research. The paper was composed of two small studies, one with just 85 participants and the other with 46. To get published today, such studies would likely need thousands of participants and to have validated the results in a second group of people. “We were just starting to figure out how to use the genome,” Reif says. The tools they used—along with so many other geneticists at the time—were simply not up to snuff.

Furthermore, the study only covered smallpox vaccines, which are no longer given to children, as the disease has been officially eradicated since 1980. It wouldn’t make sense to extrapolate to measles vaccines given today. And the “adverse events” were simply mild fevers and rashes—nothing that would bolster the discredited link between vaccines and autism.

That vaccine-autism link also infamously originated with a single journal article, now retracted. The anti-vaccine movement is decidedly outside of mainstream medicine, but it has always borrowed the language and trappings of mainstream science. By tapping into the wider interest in genetics, vaccine skeptics are attempting to tap into scientific legitimacy. The early hype about the power of genes and the early spate of now outdated research made genetics research all the more exploitable.

Plenty of solid genetics research has been published since then, but the idea that genes are powerful has spawned a world of less rigorous ideas about DNA too. At a time when companies are hawking (unproven) DNA-based diets, supplements, and exercise routines, of course people are wondering what genetics says about vaccines—even if the answer is, currently, not very much at all.

Crowe and several of his co-authors are now drafting a letter to the journal that published the 2008 paper, clarifying just how little their original paper actually says. And on Wednesday, the California Senate advanced a new vaccine bill making it harder to get medical exemptions. Public-health officials—not individual doctors—would have the power to grant them.



About 10,000 years ago, a group of hunter-gatherers settled on a floodplain in modern-day Turkey and stayed for a millennium. You can still see remnants of the houses they built. Archaeologists have mapped out alleyways and uncovered intact skeletons under ancient plaster floors. After all this time, Aşıklı Höyük is remarkably well preserved.

But Jordan Abell did not come for these sights when he last visited Aşıklı Höyük in 2017. He came to look for something invisible: ancient urine.

The people of Aşıklı Höyük all, presumably, peed. So did their sheep and goats. By estimating the quantity of ancient urine deposited at Aşıklı Höyük, Abell and his collaborators reconstructed the population of humans and animals at the site 10,000 years ago. You might call it urine archaeology.

“The method is, as far as I see, totally new and creative,” says Benjamin Arbuckle, an anthropologist at the University of North Carolina at Chapel Hill, who studies animal domestication in Turkey during the same period. Sheep and goat domestication is what got Arbell and his co-authors interested in urine in the first place. Animal bones and even dung at Aşıklı Höyük suggest that its occupants were among the first people in the world to domesticate sheep and goats. They penned the once-wild horned creatures near their homes. They learned to cull young males to maximize the size of their herds.

It was the discovery of unusual nitratine crystals that prompted the team to think about sheep and goat pee. “There’s very few places on Earth that have these nitratine crystals forming,” says Abell, who is now a paleoclimate researcher at Columbia. These places tend to be very dry, and they have high concentrations of salts. Abell, along with his collaborators at the University of Arizona and Istanbul University, wondered if urine was the source of those salts. So they went out and collected 113 samples from Aşıklı Höyük. They were especially interested in “middens,” ancient refuse heaps where human and animal waste may have piled up. And they made sure to collect samples from different layers in and around the middens, spanning the 1,000 years that people lived at Aşıklı Höyük.

Back in the lab, Abell looked for the chemical signatures of urine—sodium, nitrate, and chlorine—in each of these samples. The tricky part is that these salts can come from elsewhere, too. They are also found in various concentrations in rainwater and in the natural sediment around Aşıklı Höyük. So Abell built a model attempting to account for those sources. To make sure his assumptions weren’t totally off base, he compared the urine salt concentrations at Aşıklı Höyük with that of modern livestock feedlots, and found they were similar. The model ultimately estimated that an average of 1,790 humans and animals were peeing per day in Aşıklı Höyük during the 1,000 years of settlement.

As the team went up the dirt layers and through time, they found 10- to 1,000-fold increases in the concentration of urine salts at the latter end of the millennium-long period of occupation. This suggests that the human and/or animal population of Aşıklı Höyük was getting bigger and denser. (Unfortunately, archaeologists don’t have a way to distinguish between ancient human and animal urine using this method.) Assuming the model holds up, these urine deposits can be seen as a record of humanity’s transition from hunters to animal farmers.

Bones, Arbuckle points out, are evidence of animals being eaten by humans. “It’s really hard to tell if they’re being hunted or if they’re being herded or if some of them are being hunted and some are being herded,” he says. Vast quantities of urine, on the other hand, would suggest that animals and the people herding them were in fact staying and peeing in one place.

At this point, using urine salts to understand Aşıklı Höyük’s population relies on a lot of assumptions. Canan Çakirlar, a zooarchaeologist at the University of Groningen, calls the technique “very promising,” but she also points out that not very much is known about how urine deposits might have chemically changed over the millennia. Other factors may have changed too: People and livestock had different diets 10,000 years ago than they do now, which could produce different concentrations of salts in their urine.

Rainfall patterns over Aşıklı Höyük could have changed as well. Today, it’s a fairly dry place. The region gets about 400 millimeters (15 inches) of rain a year. It would be harder to study urine deposits in wetter places, says Abell, where rainfall and a changing water table would blur the fine layers of urine salts. He hopes to get more data from Aşıklı Höyük next year, to sample more sediment from more areas and study what little rain falls over the site. He would also like to get some urine from the local sheep that still roam the fields. Ten thousand years after humans first learned to raise their flocks here, they’re still at it.



The first 2020 presidential candidate out with a comprehensive climate-change policy is … Beto O’Rourke?

I was surprised, too. The former congressman from Texas, whose campaign has previously been somewhat skimpy on policy proposals, debuted on Monday a $1.5 trillion proposal meant to rapidly move the economy away from fossil fuels and slow the advance of climate change.

“We will ensure we are at net-zero greenhouse-gas emissions by the year 2050, and that we are halfway there by 2030,” O’Rourke said in a video posted to Twitter. His plan calls climate change “the greatest threat we face—one which will test our country, our democracy, and every single one of us.”

O’Rourke says his proposal is the “most ambitious climate plan in the history of the United States.” Certainly it is—so far—the most wide-ranging climate plan debuted by any Democratic presidential candidate in the 2020 race, though a number of contenders say their own proposals will come out shortly. And it makes for a dramatic contrast with the agenda of President Donald Trump, who has repealed major federal rules restricting carbon pollution and staffed the federal government with former fossil-fuel lobbyists.

It certainly doesn’t lack for length. The new proposal, running more than 2,500 words, has nearly doubled the policy content of O’Rourke’s campaign. Previously, his website devoted only one page to policy, detailing a 3,000-word “vision for America” that ranged across 13 different issues.

There are several different ways to address climate change through federal policy. O’Rourke’s plan tries to do all of them at once.

First, the government can try to make carbon pollution more expensive by regulating or taxing it. O’Rourke says that on his first day in office, he would reverse all of Trump’s climate-related orders, rejoin the Paris Agreement, and tell the Environmental Protection Agency to restrict air pollution from power plants and car tailpipes again.

He would also ask Congress to pass a “legally enforceable standard” that would force the United States to zero out its carbon emissions by 2050. What is this “standard”? Though the proposal’s language is cleverly vague, O’Rourke seems to be describing some kind of carbon tax—his exact language is “a clear price signal to the market”—that scales up as the mid-century deadline approaches.

Second, the government can try to make clean energy cheaper. O’Rourke says he will spend $200 billion on a new R&D program to study technologies that can reach his zero-carbon goal.

Finally, the government can buy things: solar panels, wind turbines, public transit, electric-car charging stations, and adaptations (such as seawalls) that will help people prepare for the worsened weather to come. O’Rourke says he would ask Congress to cut tax breaks for oil companies, using the resulting $1.5 trillion to fund new climate-ready infrastructure.

O’Rourke also promises to connect $500 billion in federal spending—spending that would happen anyway—to his climate goals. The federal government already tries to “buy American,” favoring U.S. companies and manufacturers; under O’Rourke’s plan, it would also “buy clean,” favoring steel, glass, and cement produced in a climate-friendly way. Some scholars associated with the Green New Deal have proposed similar new programs.

O’Rourke’s proposal goes much further than either Trump- or Obama-era policy. It will also face virtually guaranteed political opposition. But it combines a mix of approaches. Some of his proposals require new congressional legislation; some can happen through annual budget negotiations; some can be authorized by the president.

Take his proposed advanced-energy R&D program. The United States actually has an active energy R&D program, called ARPA-E, or the Advanced Research Projects Agency-Energy. Trump has proposed closing ARPA-E every year since he took office, but some Republicans and Democrats in Congress have resisted him. As such, ARPA-E now has a budget of $366 million—a record haul for the small agency.

But that all-time record is still 550 times smaller than O’Rourke’s $200 billion proposal. O’Rourke says that $200 billion is “an amount equal to what we invested in our nation’s journey to the Moon,” but I think that may actually understate the monetary scale of the proposal’s ambition: In inflation-adjusted dollars, $200 billion exceeds the cost of the 15-year Apollo program.

O’Rourke’s climate ambition is noteworthy in part because, as a candidate, he has not had the easiest relationship with the environmental left. Earlier this month, he declined to turn down money from fossil-fuel workers, saying only that he would refuse donations from oil executives, industry trade groups, and their political-action committees. In December, the environmental nonprofit Oil Change USA said that O’Rourke had violated its “no fossil-fuel money” pledge, kicking him off its approved list after he accepted too many donations over $200 from fossil-fuel employees.

The disagreement gets at a deeper problem: whether the national Democratic Party should treat the fossil-fuel industry like it once treated the tobacco industry—as an evil enterprise and political enemy—or like it now treats the pharmaceutical industry—as an important part of the economy that must be tamed and transformed. O’Rourke’s campaign suggests that he thinks the latter approach can coexist with ambitious climate policy. Senators Bernie Sanders and Elizabeth Warren, Mayor Pete Buttigieg, and Governor Jay Inslee—whose entire primary campaign is focused on climate change—have taken the opposite bet, forswearing large fossil-fuel donations.

While other candidates have climate proposals in the works, O’Rourke now has the most detailed one in the Democratic primary. Warren has released a detailed proposal for public lands that overlaps with some of O’Rourke’s climate agenda. (Both candidates would, for instance, ban all new fossil-fuel projects on federal land, as would many of their competitors in the field.) Sanders has endorsed a Green New Deal, though provided little detail about it. And Inslee is expected to debut his own climate proposals shortly.

The O’Rourke plan seemed to catch many climate groups off guard. Even Greenpeace USA, which calls for aggressive climate action, said in a statement that the plan “surprised” it and was “an important contribution.”

“I did not expect him to come out first with it, and I didn’t expect the rhetoric in it to peg so closely with the Green New Deal framing,” Greg Carlock, a policy researcher at the leftist advocacy group Data for Progress, told me. “It sets at least an expectation that other candidates have to react to.”

While Carlock said the plan could be more detailed—he called its proposed $1.5 trillion in new funding “woefully inadequate”—it reflects “a good consensus that the U.S. has to do a lot more, a lot faster.” He judged it to sit roughly between the climate policies adopted by President Barack Obama and those favored by Representative Alexandria Ocasio-Cortez of New York. One of the few groups to criticize the O’Rourke plan: the Sunrise Movement, the youth-led activism corps that helped launch the Green New Deal to national recognition last year. “He gets a lot right in this plan,” said Varshini Prakash, the group’s executive director, in a statement. But she said that O’Rourke should instead set 2030 as a carbon-free goal for the United States. (It is unclear that it is possible for the United States to meet the 2030 goal without a near-revolutionary upheaval in the national energy system.)

And Carlock said that, regardless, O’Rourke’s plan would needle other candidates into similar specificity: “If every candidate comes out with their vision, and we can debate that in the public sphere, that’s good.”



Last week, at Christie’s auction house in London, an anonymous buyer paid almost $625,000 for the skeleton of a dodo bird. More precisely, the buyer purchased a set of fossilized bones belonging to at least two different birds, dug up and assembled into a skeleton by collectors. The last such assemblage sold in 2016 for about $430,000. Before that, no dodo skeleton of any kind had been offered for public sale for nearly a century.

Even for a species that, famously, has been extinct for more than 350 years, dodo remains are scarce. The University of Oxford has a dodo head—the only specimen that includes any soft tissue—and a skeletal dodo foot. There’s a dodo skull in Copenhagen, and a dodo beak in Prague. The British Museum used to have its own dodo foot, but lost it around 1900.

“The dodo remains that were collected while the bird was still alive would fit in a shoebox,” says Leon Claessens, a paleontologist at the University of Maastricht, in the Netherlands.

The rest of what remains of the dodo, in public and private hands, is fossilized, made up of bones that were buried in caves and bogs for thousands of years. Today, the most complete dodo specimens on public display are two fossilized skeletons, one on the dodo’s native island of Mauritius and the other in Durban, South Africa. And both were excavated during a craze for dodo memorabilia that occurred centuries after the species went extinct.

In the late 16th century, when Dutch sailors returned home from Mauritius with stories about a large, ground-nesting bird, the dodo was just one of thousands of unfamiliar species that travelers were describing and displaying to European audiences. “There were all sorts of wonderful animals coming into Europe—you had the first giraffe, the first cassowary—so the dodo was just another interesting animal,” says Julian Hume, a British artist and paleontologist.

As dodo numbers plummeted, their eggs gobbled up and their habitat destroyed by the rats, cats, dogs, and pigs that disembarked from arriving ships, nobody in European scientific circles suspected that the species was in trouble. At the time, most people in Europe and elsewhere still believed that all species were divine creations, and that extinction of any kind was impossible. Not until the late 1700s did scientists realize that extinction was possible, and not until the mid-1800s did they accept that it could be caused by humans. By that time, the dodo was so long gone that it was only hazily remembered—as a kind of vulture, or albatross, or even a small ostrich. Some people suspected that it was more like a mermaid, in that it had never existed at all.

The dodo was rescued from mythical status by two Victorian researchers, Hugh Strickland and Alexander Melville, who collected surviving firsthand accounts of the species in an 1848 book called The Dodo and Its Kindred. The book brought public attention to the dodo, inspiring Lewis Carroll to include a plump fictional dodo in Alice’s Adventures in Wonderland—and prompting amateur and professional scientists to begin searching, belatedly, for real dodo remains.

Perhaps inevitably, the search got competitive, and the competition got nasty. In 1865, after years of looking, a schoolteacher named George Clark discovered a jumble of fossilized bones, including dodo bones, in a Mauritian marsh called the Mare aux Songes. Richard Owen, an anatomist at the British Museum, was so eager to get ahold of Clark’s finds that he laid claim to bones meant for his colleague Alfred Newton—knowing that Newton, whom Owen had recently recommended for an academic appointment, would be in no position to protest. Newton’s brother Edward, a colonial administrator in Mauritius, was outraged: “I must say that I feel very indignant about the conduct of Owen in the case of Clark’s Dodos,” he wrote to Alfred. “He has shown himself to be a very mean-minded illiberal sort.”

While scientists squabbled over the bones from the Mare aux Songes, Louis Etienne Thirioux, a Mauritian barber and avid amateur naturalist, was quietly looking elsewhere. Thirioux, who reportedly entertained customers with his “genius for conversation,” nonetheless spent his Sundays and holidays alone, reading scientific literature and hiking through the mountain range that bisects the island. In the late 1800s, he started excavating fossilized bones from caves and river valleys, eventually assembling the two dodo skeletons now displayed in Mauritius and Durban. (Almost all the bones in the skeleton in Mauritius are thought to be from a single individual; the skeleton in Durban, like all other dodo skeletons known today, is a composite.)

Claessens speculates that Thirioux traded or shared some of the individual dodo bones he found with Paul Carié, a Frenchman who owned the land surrounding the Mare aux Songes in the early 1900s. Using dodo bones from his marsh and some loaners from Thirioux, Carié assembled a number of piecemeal skeletons. He sold or donated all but one—which remained in his family until it was sold in London last Friday.

The dodo is better understood than it used to be. From its few remains, scientists have learned that it was neither vulture nor ostrich but a member of the pigeon family; that it was probably svelter and faster than early descriptions suggested; and that despite the dodo’s reputation as a hapless victim, its anatomy and behavior were beautifully adapted to its environment.

But the species is gone, and the dodo’s story will always be as fragmentary as its remains. “Every time you think you’re getting close, your hands almost touching it, it just seems to move away, so that you can’t quite work out what this bird was doing,” Hume says ruefully. “It’s always a little out of your grasp.”



Everything is formed by habit. The crow’s feet that come from squinting or laughter, the crease in a treasured and oft-opened letter, the ruts worn in a path frequently traveled—all are created by repeatedly performing the same action.

Even neurons are formed by habit. When continuously exposed to a fixed stimulus, neurons become steadily less sensitive to that stimulus—until they eventually stop responding to it altogether.

Anything that’s habitually encountered—the landscape of a daily commute, storefronts passed on a walk to the bus stop, photographs arranged on a mantelpiece—tends toward invisibility. The more we see a thing, the less we see it. Familiarity breeds neglect.

Once perception settles into a comfortable pattern, we fall asleep to it. Only when the pattern is broken do we notice there is a pattern at all. The chains of mental habit are too weak to be felt until they are too strong to be broken, to paraphrase Samuel Johnson.

Wit, whether visual or verbal, can make the commonplace uncommon again by breaking the habits that render perception routine. We tend to define the quality of wit as merely being deft with a clever comeback. But true wit is richer, cannier, more riddling. And the best of it is often based on a biological phenomenon called supernormal stimuli.

The story of supernormal stimuli begins with the Dutch biologist Nikolaas Tinbergen. As a boy growing up in The Hague in the 1910s, Tinbergen was fascinated by the fish and fowl inhabiting the little pond in his backyard. These early encounters with the wildlife of the Netherlands informed his later work, and as an adult, he kept an aquarium in his home.

One day he noticed that the male three-spined sticklebacks—which have “gorgeous nuptial colors,” Tinbergen observed, “red on the throat and breast, greenish-blue on the back”—went into attack mode every time a red postal van parked outside. They dropped their heads and raised their dorsal fins, a posture normally assumed only in the presence of a rival male.

Wondering whether the fish were reacting to the postal van, Tinbergen introduced variously colored objects into the tank. He discovered that the males became aggressive in response to anything red—the unmistakable sign of another male’s presence—regardless of whether it resembled a fish. The observation sparked Tinbergen’s discovery of color’s influence on animal behavior, for which he shared the Nobel Prize in Physiology or Medicine in 1973.

When he wasn’t observing three-spined sticklebacks, Tinbergen spent a lot of time with adult herring-gull hens, which have pronounced orange spots on their lower mandibles. For the first few weeks of a chick’s life, its mother’s beak is its sole food source. That orange spot is a good target for chicks to aim at when they peck at their mother to prompt her to regurgitate food.

Tinbergen noticed that the chicks in his lab, like the male sticklebacks in his aquarium, aggressively pecked not just at their mother’s beak but at anything with an orange spot on it. It occurred to him that it might be possible to one-up nature, to “make a dummy that would stimulate the chick still more than the natural object,” he wrote.

So Tinbergen started making “super-gulls”: cobbled-together constructions that amplified the orange spot to which the chicks so enthusiastically responded. He painted orange spots on everything from old pieces of wood to kitchen utensils. He made the orange spots bigger and surrounded them with white rings to enhance the contrast. The chicks pecked at absolutely everything that had an orange spot on it. The bigger the spot, the more aggressively the chicks pecked.

Tinbergen called his exaggerated orange spots “supernormal stimuli,” which, he concluded, “offer stimulus situations that are even more effective than the natural situation.” This response to supernormal stimuli is not limited to herring gulls. Chicks from all species will beg for food from a fake bill if it has more dramatic markings than its parents have, and parents will ignore their own eggs and attempt to incubate much larger objects—including volleyballs—if those objects are decorated to resemble eggs.

Tinbergen theorized that human beings are susceptible to supernormal stimuli, too. The oversized eyes of stuffed animals, dolls, and cartoon characters are supernormal, he reasoned, kick-starting our instinctive response to nurture anything with infantile facial features. Sugar-saturated soft drinks, works of art, clothing, perfume, even lipstick—anything that intensifies or exaggerates an instinctive biological, physical, or psychological response—can be considered supernormal stimuli.

Supernormal stimuli are key to certain kinds of wit, too, deliberately skewing or exaggerating our usual patterns of perception. The great silent comic Buster Keaton is a case in point.

In The High Sign (1921), as Keaton settles down on a bench to read his local daily, he unfolds the paper to standard broadsheet format. He soon notices, though, that the newspaper is bigger than he expected, so he continues unfolding it—first to roughly the surface area of an ample picnic blanket, then easily to the proportions of a king-size bedsheet, until he’s finally engulfed by a single gigantic swath of newsprint.

In Seven Chances (1925), Keaton, a stockbroker on the verge of financial ruin, learns that he will inherit handsomely from his grandfather—if he weds by 7 p.m. When his sweetheart rebuffs him (she will marry for love, not for money), he places an open offer of marriage, with details of the pecuniary benefits, in the newspaper. Hundreds of women turn up at the church for the ceremony, only to become enraged at Keaton’s tactics. The bevy of would-be brides chases him out of town and onto a nearby hill, where he dislodges a single rock, which sets in motion an avalanche of boulders, which rain down on our hapless groom’s head.

Keaton’s gags start innocuously enough, with some ordinary object, then snowball into supernormal stimuli. But stimuli can also be made supernormal by visual or verbal tricks that disrupt the ordinary ways we see and understand the world.

Marcel Mariën’s work is rife with such tricks. Mariën started out as a photographer’s apprentice while still in his teens. But in 1935, after seeing the work of René Magritte for the first time, he decided on a career as an artist, soon becoming a close friend of Magritte and one of the most prominent of the Belgian surrealists. He worked in a variety of media—photography; film; collage; and “ready-mades,” works of art assembled from discarded materials, common household items, or unused parts of other objects.

In Star Dancer (1991), Mariën attached a doll’s high-heel shoe to one of the arms of a dead starfish, transforming it into a wispy, Matisse-esque ballerina. The strange juxtaposition makes the viewer do a double take. How can such a clearly alien creature have such distinctly human expressiveness? Like the volleyball/egg that birds try to incubate, the cobbled-together starfish/doll becomes a supernormal stimulus that alters viewers’ perceptions.

The same principle is at work in verbal wit. The English film director Anthony Asquith, for example, once introduced Jean Harlow, the platinum-blond 1930s Hollywood star, to his mother, Lady Margot Asquith, the author and wife of the longtime British prime minister Herbert Henry Asquith. Harlow mispronounced Lady Margot’s first name, sounding the final t, as in forgot. “The t is silent, my dear,” Asquith snipped, “as in Harlow.” Lady Margot isolated and exaggerated the significance of the simple t, just as Tinbergen isolated and exaggerated the herring gull’s orange spot, thereby dramatically enhancing its impact.

What is a punch line but a supernormal stimulus?

We respond to witty words and images more intensely than to “normal” objects, just as Tinbergen’s theory of supernormal stimuli suggests. “Humor at its best is a kind of heightened truth—a super-truth,” E. B. White wrote. This is also true of wit, which takes routine seeing and heightens it by shearing ordinary things and meanings of their habitual context, revealing them as suddenly strange and unfamiliar.

This piece was adapted from James Geary’s new book, Wit’s End: What Wit Is, How It Works, and Why We Need It.



Lauren Divine first heard that the birds were dying on October 13, 2016, when one of her colleagues stumbled across the corpse of a tufted puffin while walking along a beach on Alaska’s St. Paul Island. The next day: another carcass. Soon, several of the island’s 450 residents started calling in with details of more stranded puffins. Some were already dead. Others were well on their way—emaciated, sick, and unable to fly.

Nestled in the middle of the Bering Sea between Alaska and Russia, St. Paul is the largest of the four Pribilof Islands, which together support more than 2 million seabirds. Dead individuals aren’t uncommon. Divine’s team, which works on environmental issues that affect St. Paul’s Aleut community, would usually expect to find one or two on its monthly beach surveys. But that October, “you couldn’t walk more than a few steps before having to pick up another bird,” she says. “It was pretty apparent that something was really wrong in the environment.”

The team stepped up its surveys, braving biting winds and crashing waves to comb the beaches on all-terrain vehicles. Over the next few months, it located more than 350 bodies, a rate that was about 70 times higher than normal. Stranger still, most of these birds were tufted puffins—a species that very rarely washes up dead. In the previous decade, the team had only ever found six puffin carcasses, and never in the winter months. It seemed that the puffins had become the latest species to experience a mass-mortality event—a large-scale die-off, of a kind that’s becoming more and more common.

To work out how many puffins had actually died, Timothy Jones of the University of Washington used the locations of the known bodies and data on local wind patterns to simulate where the dead birds were coming from. He estimated that between 3,150 and 8,800 tufted puffins perished in the final months of 2016.

What killed these birds? Most of them were intact, with no signs of either predator attacks or disease. Some of them had saxitoxin—a potent poison made by algae—in their stomach, but at levels almost 100 times lower than what would be considered safe for humans to eat. Instead, the most likely cause of death was starvation. The birds were extremely thin, with weak flight muscles and very little body fat. “They literally didn’t have enough to eat and became weak to the point of death,” says Julia Parrish of the University of Washington, who led the study.

Tufted puffins look like fancier versions of the more widely known Atlantic puffins, with elaborate yellow eyebrows that sweep backwards down their neck. On land, they have a clownish, goofy disposition. But in the sea, they become grace personified, using their streamlined body and sickle-shaped wings to fly underwater in pursuit of small fish.

But what if there are no fish to pursue?

The climate of the Bering Sea is changing rapidly. In recent years, the sea ice that would have extended southward in the winter has become unprecedentedly thin and sparse. And that has affected everything from tiny plankton to titanic walruses.

The ice sheets create a layer of super-cold water called the “cold pool,” which sits at the bottom of the Bering Sea. Pollock, cod, and other fish like to congregate in large numbers at the edges of this pool, providing excellent hunting grounds for puffins and other sea birds. When the cold pool doesn’t form, as has been in the case in recent years, the fish spread out over larger distances, and are harder to catch.

And when they are caught, they’re worth less. In the warmer waters, the plankton have shifted toward smaller and less energy-rich species, and the fish that eat those plankton have become similarly thinner in calories. Fish-eating birds, such as puffins, “are going from Clif Bars to rice cakes,” Parrish says. “They have to work much harder to get the same energy content. And this is happening over thousands of square kilometers of ocean, so it’s not like they can say, ‘Oh, there’s no Clif Bars here, so I’ll go to the next grocery store.’”

These changes hit the birds at the worst possible time—when they change their coat of feathers. Puffins use their body feathers as a wetsuit that keeps water away from their skin and helps them retain heat. To keep that suit secure, they regularly replace all their old plumes in a dramatic synchronous molt. Over the next few weeks, they need a lot of energy to grow new feathers, but they can barely fly or dive. For that reason, they typically molt from August to October, when food ought to be plentiful. If it isn’t, the birds don’t make it.

It’s no coincidence that most of the tufted puffins that washed up during St. Paul’s mass-mortality event were in the middle of molting. At a time when they were most in need of food, and least able to get it, the dwindling sea ice forced them to travel farther afield for sparse, energy-poor scraps. “In short, climate change causes seabird starvation,” says Melanie Smith, the conservation director for Audubon Alaska. “It’s not the only factor at play, but it is the common thread among similar events.”

Other species in the Bering Sea are suffering, too. Ever since 2013, when the massive marine heatwave known as “the blob” formed off Alaska, “we’ve seen a whole bunch of mass-mortality events,” says Parrish, who documented a similar die-off of Cassin’s auklets in 2015. “In every case, there are thousands to hundreds of thousands of marine birds that should normally be way offshore, but are crowding into pretty narrow strips of coastal land. They can’t keep it together, they’re starving to death, and they’re washing in.”

“Bird die-offs have happened up there before,” says Phyllis Stabeno, an oceanographer at the National Oceanic and Atmospheric Administration. “But it’s unusual for there to be so many of them, spread out over the whole [Bering Sea] system.”

“It’s an ecosystem that, in my experience, is screaming constantly at us to pay attention,” Parrish adds.

Kathy Kuletz from the U.S. Fish and Wildlife Service adds that most mass-mortality events probably go unrecorded, because they happen out at sea, and the carcasses never make it to shore. “Our office has conducted about 15,000 to 20,000 kilometers of seabird surveys annually since 2007, and before 2014, we averaged 1 to 2 dead bird encounters per year at sea,” Kuletz says. “Since then, we've had between 20 and 70 dead birds per year. Those numbers may not seem like much, but bird carcasses are difficult to see from large vessels moving at 10 to 14 knots, so this could represent a much larger problem than is documented by monitoring efforts on land.”

These changes are also affecting the people who live on St. Paul and the other Pribilof Islands. The native Aleut, or Unangan, people have long traditions of hunting puffins and collecting their eggs. The birds aren’t that important as a food source now, but they’re still culturally significant. “People enjoy having them around,” Divine says. “When the community saw the die-off, it was alarming and upsetting. They wanted to know what is happening to the species, and what management measures the federal government will take to understand and fix this situation.”

Other seabird populations are declining, too, Divine says. Several species roost on cliff faces, and without sea ice to buffer the coast from fierce winter storms, those cliffs are eroding at an alarming rate. The shorelines are wearing away, too, destroying the breeding sites where endangered Steller sea lions would normally congregate. “Their numbers here have gone to almost zero,” Divine says. “These huge biological and physical changes are very noticeable in the Pribilofs. We’re in the middle of it all.”

And yet, the exact scope of those changes is hard to assess, because the Pribilofs are so remote, and because censuses of seabirds rarely attract significant funding. Only through the efforts of Divine’s team of volunteers did the extent of the puffin die-off become clear. “Everything up here is data limited,” says Austin Ahmasuk of Kawerak, a consortium of Alaska Native tribes. “We only know about [the puffins] thanks to this citizen effort.”

“This is a sad bird story, but it’s also one about how community science and mainstream science can work together,” Parrish adds. “Listening to local expertise and incorporating that into what we do … that’s the only way science is going to save the world.”





Since the mandarin duck appeared in Central Park last fall, his unexpected presence has stirred up many questions: Where did he come from? Why is he so hot? Can such beauty survive in our garbage world? And, for the linguistics nerds out there, where do mandarin ducks get their name?

Yes, true, mandarin ducks are native to China, where Mandarin is the official language. But the word mandarin has a more roundabout origin. It does not come from Mandarin Chinese, which refers to itself as putonghua (or “common speech”) and China, the country, as zhongguo (or “Middle Kingdom”). It doesn’t come from any other variant of Chinese, either. Its origins are Portuguese.

This one word encapsulates an entire colonial history. In the 16th century, Portuguese explorers were among the first Europeans to reach China. Traders and missionaries followed, settling into Macau on land leased from China’s Ming dynasty rulers. The Portuguese called the Ming officials they met mandarim, which comes from menteri in Malay and, before that, mantrī in Sanskrit, both of which mean “minister” or “counselor.” It makes sense that Portuguese would borrow from Malay; they were simultaneously colonizing Malacca on the Malay peninsula.

For centuries, Europeans’ impressions of China filtered largely through the Portuguese. The 16th-century Jesuit priest Matteo Ricci, for instance, was Italian, but he arrived in China through Portuguese Macau. Following the twisty logic of colonialism, when he attempted to transpose Chinese characters into the Latin alphabet, he made use of both Italian and Portuguese, comparing the sounds of individual characters to the sounds of Portuguese and Italian words. Even today, “linguists go to town and try to figure [out] what Chinese would have sounded like at the time,” says David Moser, author of A Billion Voices: China’s Search for a Common Language. “They could use as a clue the way Matteo Ricci wrote the Portuguese.”

Over time, the Portuguese coinage of “mandarin” took on other meanings. The Ming dynasty officials wore yellow robes, which may be why “mandarin” came to mean a type of citrus. “Mandarin” also lent its names to colorful animals native to Asia but new to Europeans, like wasps and snakes and, of course, ducks. And the language the Chinese officials spoke became “Mandarin,” which is how the English name for the language more than 1 billion people in China speak still comes from Portuguese.

But words have a way of collecting just-so origin stories, and Chinese speakers have sometimes retroactively given a Chinese origin to “mandarin,” says Moser. It sounds similar enough to mandaren, a phrase that could mean “important Manchurian.” The rulers of China’s last dynasty, the Qing, were from Manchuria, so it make sense if you squint at it. “But it’s not true,” says Moser. “Mandarin” has a distinctly non-Mandarin origin.

“Mandarin” is what linguists call an exonym, an external name for a place, people, or language. And exonyms often tell a history of how cultures met, fought, and interacted. Many English names for continental European cities derive not from the local language but from French—probably a legacy of the Norman conquest of England. For example, English and French both use Cologne for Köln, Florence for Firenze, Prague for Praha, and Belgrade for Beograd.

In other cases, says the lexicographer Grant Barrett, exonyms arise because two places have a relationship that pre-dates current national boundaries. For example, adds the linguist Anatoly Liberman, we use “Germany” from the Latin Germania. In French, the name is Allemagne from a group of tribes called the Alemanni; in Finnish, Saksa from the Saxons. Germany (Deutschland in German) only became a unified country in 1871, long after other Europeans had adopted their own names for the place, based on different peoples who once lived there.

From the vantage point of English speakers, many of the exonyms for non-European places and languages come filtered through the languages of former colonial powers. Bombay and Ceylon, for example, also come from the Portuguese, whose empire once sprawled through Asia. The names imposed by colonial powers can be controversial, of course; Bombay and Ceylon have since officially changed their names to Mumbai and Sri Lanka. The name “Mandarin” still endures, perhaps because its origin is more obscure or because China has enjoyed warmer relations with Portugal than with other European countries. As for the mandarin ducks, they also live in Portugal now.



Marcus Drymon wasn’t expecting a baby shark to barf up a ball of feathers onto his boat.

The shark’s presence wasn’t the weird bit: Drymon and his team of fisheries ecologists regularly assess fish populations along the coasts of Mississippi and Alabama, and every year, they’ll catch, weigh, tag, and release thousands of sharks. In 2010, they were doing just that for the meter-long tiger shark when it coughed up the feathers. “Being an ecologist, I scooped them up and took them back to the lab,” Drymon says.

He passed the feathers to Kevin Feldheim, a molecular biologist at the Field Museum, who analyzed the DNA within them to work out what species they belonged to. The answer: a brown thrasher, a thrush-like songbird that lives in forests. What on Earth was it doing in the belly of an oceanic apex predator?

“I had expected a laughing gull or a brown pelican,” Drymon says. “The brown thrasher was the last bird I would have expected.”

In fairness, a brown thrasher is hardly the weirdest thing to end up in a tiger shark. This species is notorious for eating pretty much anything. Aside from the remains of dolphins, dugongs, sea turtles, and sea snakes, scientists have found tires, license plates, a drum, unexploded munitions, and an entire chicken coop inside tiger-shark stomachs. And when Drymon dug through some old papers, he found a few decades-old records of tiger sharks eating land-based birds. Thinking about his brown thrasher, he wondered, “Was this just a one-off anecdote, or is there some sort of a pattern?”

For the next eight years, during his annual surveys, Drymon checked any tiger sharks he caught for feathers. The method is simple: Put a wide tube in the shark’s mouth, thread a hose down the tube, turn the shark upside down, and catch whatever comes out. Amazingly, they found bird remains in 41 out of 105 sharks—39 percent!

In most cases, the feathers were so degraded, and swamped by DNA from the sharks and their other prey, that the team couldn’t identify them. But they managed to do so for 11 samples. Barn swallow, house wren, common yellowthroat, yellow-bellied sapsucker, American coot ... all land-based, with not a single seabird among them. In a few cases, the birds were only partially digested, “and the DNA barcoding wasn’t necessary,” Drymon says. “We could identify them from a field guide.”

“We’re seeing these interactions every single year,” he adds. “All of a sudden, it’s not just a gee-whiz thing. There’s something driving these interactions, in a predictable way.”

He was stumped until he had lunch with Auriel Fournier, a bird ecologist who works in the same building. She told him that large flocks of birds migrate over the Gulf of Mexico, and presumably some of them fall into the sea because of bad weather, exhaustion, or some other unlucky event. It wasn’t surprising that a shark should eat them. But Fournier was surprised at how often it was happening.

She consulted eBird—a database run by Cornell University, which collects sightings from bird-watchers worldwide. Pulling data from the Mississippi and Alabama coasts, Fournier showed that the dates at which Drymon pulled feathers from his tiger sharks coincided almost exactly with the peak sighting times for almost all of the 11 species.

Nature’s migrations are so epic that it is easy to forget how treacherous they are, and that many travelers simply never get to their destination. Consider the migrating birds that travel southward over the Gulf of Mexico from later summer to fall: They have to make the crossing without stopping. They don’t have the water-repelling oils that seabirds use to coat their feathers, so if they land in the sea, “they suck up all that water, and become so soaked that they can’t get up again,” says Fournier. “If a bird has to make that landing, it’s probably done for.”

No one knows how often this happens. But with an estimated 2 billion birds crossing the gulf every year, a low chance of death still translates into a lot of floating bodies—and a lot of meals for scavenging sharks.

Drymon says that the waters near Mississippi and Alabama are rich in very young tiger sharks, and he only ever found bird remains in these small individuals. “This scavenging on easily accessible prey could represent a way for these young sharks to feed themselves before they’ve learned adult hunting behavior,” he says. “It’s almost like baby food.”

This could also help to explain why tiger sharks, unlike many other species, don’t deposit their young in sheltered estuaries and mangroves, and instead give birth in more open waters. Those areas might offer less protection, but if they predictably receive feathery manna from the heavens, that would benefit the baby sharks. And so two worlds—forests and oceans, songbirds and sharks—briefly collide. The same could be said for the researchers involved in this study. “It’s a fun way of bringing together these two parts of the biology world that don’t talk to each other very often,” Fournier says.

“A fisheries ecologist, a molecular biologist, and a bird ecologist ... it’s like the start of a bad joke,” Drymon adds.



Humankind first laid eyes on the far side of the moon in 1968.

“The backside looks like a sand pile my kids have been playing in for a long time,” the astronaut Bill Anders told NASA mission control. For millennia, people had gazed up at the same view of the Earth’s companion—the same craters, cracks, and fissures. As the Apollo spacecraft floated over the unfamiliar lunar surface, Anders described the new territory, which promised to be a tough landing for anyone who tried. “It’s all beat up, no definition,” he said. “Just a lot of bumps and holes.”

Fifty years later, humankind landed in the sand pile.

China set down a spacecraft on the far side of the moon on Wednesday, Beijing time. On Thursday, the spacecraft, named Chang’e 4, after the Chinese goddess of the moon, unlocked a hatch and released a rover onto the lunar soil. The rover carries tools designed to explore the uncharted terrain, which, thanks to a lifetime of facing the cosmos, is covered in craters.

The landing, celebrated already as an achievement for humankind, is a reminder that people can accomplish some wonderfully wild things, given enough curiosity, skill, and rocket fuel. The first photos from the Chang’e 4 mission, captured inside a crater near the moon’s south pole, are chill-inducing. But the landing is also a distinctly geopolitical win for a nation that hadn’t even launched its first satellite when Bill Anders saw that sand pile 50 years ago.

The story of space exploration, the kind carried out by national governments, began as a quest for national achievement and power. In the 1950s, the Americans and the Russians shot rocket after rocket into the sky with patriotism, not discovery, at the forefront of their minds. Any science that came out of it was a bonus.

Perhaps the clearest illustration of this geopolitical drive is a Soviet spacecraft called Luna 2. The Soviet Union launched Luna 2 in 1959, two years after sending the first satellite into orbit around Earth. Luna 2 was beachball-shaped, with spiky antennas, and weighed 390 pounds. The spacecraft carried multiple instruments designed to measure the radiation environment around the moon. It transmitted this data back to Earth as it flew through space. When Luna 2 approached the lunar surface, mission control held their breath.

The signals stopped. Luna 2 had slammed into the moon, breaking apart into pieces.

Mission control erupted in cheers. For the Soviet Union, it didn’t matter that Luna 2, which became the first spacecraft to reach the moon, had been smashed into smithereens. The point was to get there first—to mark territory. The Soviets had packed the spacecraft with metal pendants bearing the hammer and sickle of the Soviet Union. The impact scattered them across the lunar regolith, where they remain today, as if on display at a museum.

For the United States and the Soviet Union, every milestone in the space race was commemorated as an achievement for all humankind, yes, but also as a gain for the nation—for its government, its policies, its ideals—that reached it first. Two days after Luna 2 completed its mission, Soviet Premier Nikita Khrushchev visited the United States. As the British historian Robert Cavendish wrote in the magazine History Today, Americans suspected that the space mission had been coordinated with the political visit: Khrushchev was “beaming with rumbustious pride” and gleefully “lectured Americans on the virtues of communism and the immorality of scantily clothed chorus girls.”

A decade later, when Neil Armstrong and Buzz Aldrin landed on the moon, the Soviets were decidedly less rumbustious. Sergei Khrushchev, the son of the premier, told Scientific American in 2009 that Soviet propaganda let the news of “one giant leap for mankind” slide by without much fanfare. “It was not secret, but it was not shown to the public,” he said.

By then, China had already been trying to insert itself into the space race for more than a decade. After the Soviet Union launched Sputnik, Mao Zedong instructed his country’s scientists and engineers to prepare a satellite of their own, to launch in 1959, in honor of the Great Leap Forward, the leader’s ultimately failed plan for rapid industrialization. The directive from the top to scientists was simple: “Get it up, follow it around, make it seen, make it heard.”

But the country didn’t have the necessary technology for such a fast turnaround, and space-exploration efforts would be repeatedly derailed by political turmoil in the coming decades. The satellite launched at last in 1970, equipped with a single purpose: playing the first few bars of “The East Is Red,” an instrumental song glorifying China’s Cultural Revolution.

In recent years, though, China’s space efforts have jumped to warp speed. When the country launched its first astronaut in 2003, it became one of only three countries to have done so. It sent an uncrewed orbiter around the moon in 2007, and a rover in 2013. In 2011, it launched a space station that astronauts visited twice before it was decommissioned and deliberately crashed into the Pacific Ocean. A second space station launched in 2016. In 2018, China launched more rockets into orbit than any other country.

China has more bold plans for the future. The country is aiming to land a rover on Mars in early 2021 and, if successful, would become the second country after the United States to accomplish the feat. It also wants to land astronauts on the moon by 2030.

These and other milestones can be celebrated on a global scale as an achievement for the human species, just like the landing was. “It is human nature to explore the unknown world,” Wu Weiren, the chief designer of the Chang’e 4 mission, said in a television interview, according to The New York Times. “And it is what our generation and the next generation are supposed to do.”

But China’s space accomplishments are as symbolic and strategic as the Apollo and Vostok programs were in the 1960s, especially now, when space agencies in Europe, Russia, India, and, most recently, the United States have put a big focus on lunar exploration. “We are building China into a space giant,” Wu said.

For spacefaring nations, impressive feats, whether it’s landing on Mars or on the far side of the moon, will always be seen through the lens of the nation that managed to pull it off. “When you are the first country to land a probe on the far side of the moon, that says something about your science and technology, that says something about your industry,” the Heritage Foundation’s Dean Cheng, one of the few Chinese-speaking analysts in the United States that focus on China’s space program, told The Atlantic in 2017.

If it still seems silly to consider geopolitical history in the exuberant moments after a moon landing, consider this reaction from the Global Times, a newspaper run by the Communist Party, China’s ruling party, reported by The Washington Post:

Unlike mankind’s mania in the past, the Chinese people ultimately harbor the dream of shared human destiny and practices open cooperation. We choose to go to the back of the moon not because of the unique glory it brings, but because this difficult step of destiny is also a forward step for human civilization!

A “forward step for human civilization,” indeed. But the “unique glory” is certainly nice, too.



There’s some disagreement about what the last people to visit the moon said just before they left. It could be Gene Cernan telling Jack Schmitt, who was fiddling with a camera, “Now let’s get off. Forget the camera.” It could be what was spoken after that, which NASA’s official transcript of the Apollo 17 mission describes only as “[garbled].” Or it could be, as astronaut lore has it, a few colorful words from Cernan: “Let’s get outta this mutha.”

The point is, the NASA astronauts left the moon in 1972, and no one has been back since.

When the Apollo program ended, NASA turned its attention toward other parts of the cosmos. It built space stations and shuttles, designed powerful floating telescopes, and sent machines to fly past some planets and moons and to land on others. Today the moon, Earth’s closest companion, seems almost distant in comparison.

But Donald Trump’s administration wants to go back, and soon.

“At the direction of the president of the United States, it is the stated policy of this administration and the United States of America to return American astronauts to the moon within the next five years,” Vice President Mike Pence said this week.

Pence made the announcement in Huntsville, Alabama, the city that built the rocket that lofted Apollo astronauts toward the moon. In the most significant space-policy speech of the Trump administration so far, the vice president said the United States would establish a permanent base on the moon that would someday help Americans mount a mission to Mars.

As other leaders have done, Pence waxed poetic about the nation’s drive to explore the unknown. He lavished praise on NASA employees. He made Buzz Aldrin, the second man to walk on the moon, stand up so the audience could applaud him. But while the speech was big on the magic of space exploration, it was low on specifics. Pence left out something rather important: how the administration plans to fund this whole effort.

NASA received far more funding in the Apollo days than it does now; at the moon program’s peak, the agency’s annual budget accounted for more than 4 percent of federal spending. It’s less than half a percent today. NASA has poured plenty into exploration efforts in the past several decades, but one president’s policies usually get yanked back by the next. Little gets done in the meantime.

The latest NASA budget, $21.5 billion, is the largest in years. But the Trump administration had requested $19.9 billion, and it was Congress, the final arbiter on funding, who added the extra cash. And in its request for next year’s allocation, the administration actually proposed scaling back funding.

Pence said that to speed up the effort, the government would consider scrapping NASA’s own work and using commercial technology instead. The space agency has spent nearly a decade working on a rocket powerful enough to deliver astronauts to the moon, but it’s behind schedule and over budget. “If commercial rockets are the only way to get American astronauts to the moon in the next five years, then commercial rockets it will be,” the vice president said.

But the government would still have to pay the commercial companies for their services, and it’s unclear whether those firms would be ready in time—or even want to participate. To make a moon return happen under the current budget, the administration would need to propose making some cuts to major programs, such as its moon rocket—which has significant support in Congress—or even the International Space Station.

These are matters for lawmakers to figure out. But as they do, they will be forced to confront the clearest argument against spending all that money: Americans have been to the moon already. Why go back at all?

According to Pence, it’s more or less the same reason they went last time, during the height of the Cold War. The vice president’s rationale seemed to center, as it did during John F. Kennedy’s presidency, on national pride, prestige, and a sense of duty to keep outer space out of the hands of nations that aren’t like this one.

“The United States must remain first in space, in this century as in the last, not just to propel our economy and secure our nation, but above all because the rules and values of space, like every great frontier, will be written by those who have the courage to get there first and the commitment to stay,” Pence said.

The passage of time has coated the Apollo missions with a sparkling sheen. Polls show that support for the moon landing has risen over the years; 77 percent of people in 1989 thought the effort was worth it, compared with just 47 percent a decade earlier. Even in the thick of the Apollo years, Americans were skeptical, as the space historian Roger Launius wrote in 2003: “Consistently throughout the 1960s a majority of Americans did not believe Apollo was worth the cost, with the one exception to this a poll taken at the time of the Apollo 11 lunar landing in July 1969.”

A Pew Research Center poll in 2018 found that while most Americans believe it’s important for the United States to be a world leader in space exploration, 63 percent think NASA’s main focus should be climate research. Only 13 percent said sending humans to the moon should be a top priority.

Even Buzz Aldrin himself thinks it’s time to look beyond Earth’s gray companion, and toward Mars. “We’ve done the moon. We understand it better than anything else,” he said in a 2011 interview with Space.com. “We’ve got to stop thinking of short-term hurrahs and start thinking of long-term investments.”

Depending on whom you ask, there are many reasons to explore the moon, including some that aren’t tangled up in geopolitics. If human beings want to go anywhere in space, the moon seems like the most logical target—it’s the closest, after all. A journey to Mars could last as many as nine months, but a trip to the moon takes just a few days.

The moon offers some hope for self-preservation. A species living on two worlds has a better chance of surviving should catastrophe, such as the worst effects of climate change or an asteroid impact, befall it. The odds are even better if the species resides on three worlds, which would require some practice first, says David Spencer, an aerospace professor at Purdue University who worked at NASA’s Jet Propulsion Laboratory for nearly two decades. “If we go to Mars directly without going to the moon and establishing a permanent presence, I think we’re skipping a step,” Spencer says.

Some argue that robots could do a better and cheaper job of exploring the lunar surface. On Mars, rovers have crisscrossed plains and valleys and made significant discoveries. But people move much faster than a rover’s slow crawl—the Opportunity rover covered just 28 miles in 15 years—and they could provide fixes a machine can’t. NASA engineers probably wish they had someone around to jostle its Mars lander, which recently got stuck while trying to drill into the planet’s surface.

The moon has water—though it’s unclear how much—frozen away in the rock, including at the south pole, where Pence said astronauts would go. This would be useful only for lunar explorers, who could theoretically funnel this ice into life-support systems.

Earthlings might find use in another resource on the moon, an isotope called helium-3, delivered to the surface through powerful winds from the sun, which Earth’s magnetic field blocks out. Scientists have suggested transporting helium-3 back to Earth, where its nonradioactive properties could produce safer nuclear energy. But “it’s a very futuristic concept,” Spencer says. “I’m not saying this first return to the moon is going to lead directly to that. I think over the long term, there could be possibilities that could be really enabling.”

A lunar outpost, whether a city or a mine, would require years of effort, but there was no mention of that in Pence’s speech. The vice president said that Trump wants NASA to meet the 2024 deadline “by any means necessary,” but he didn’t discuss what would happen after.

“If all they do is that first mission, it will wind up very similar to Apollo,” Spencer says. “It’ll be Apollo with newer technology.”

The déjà vu in Pence’s speech was palpable. “We’re in a space race today, just as we were in the 1960s, and the stakes are even higher,” he said. As proof, he brought up China’s historic landing on the far side of the moon in January, and the United States’ costly reliance on Russian launch systems to deliver American astronauts to the ISS. “The first woman and the next man on the moon will both be American astronauts, launched by American rockets, from American soil,” Pence said.

In other words, the Trump administration wants to make the moon American again. The last president to set his sights on the moon, George W. Bush, called for a similar return in 2004, but he set the deadline for 2020, long after he’d leave the White House, taking his slogans with him. The fact that the Trump administration has picked 2024, the final year of a potential second term, is telling. Trump might be trying to produce a decisive accomplishment on a timeline that can’t be undermined by his successor.

But the rush is also part of a larger attempt to produce as many showy achievements in space as possible to bolster Trump’s legacy, an effort that began soon after he took office.

“The common thread among many of the policy options, transition and industry officials said, is a focus on projects able to attract widespread voter support that realistically can be completed during Mr. Trump’s current four-year presidential term,” The Wall Street Journal reported in February 2017.

Days after the inauguration, White House officials asked NASA to consider putting people on its first test of the Space Launch System, the beleaguered moon rocket, which would occur during a Trump term. The plan had been to wait until the second flight to make sure the first one, you know, didn’t blow up. NASA staff reviewed the option, but ultimately decided against it.

A few months after that, Trump reportedly asked the acting administrator of NASA whether the agency could send people to Mars in the next few years, a feat that would require buckets of money and probably defy the laws of physics. “But is there any way we could do it by the end of my first term?” Trump asked. “But what if I gave you all the money you could ever need to do it? What if we sent NASA’s budget through the roof, but focused entirely on that instead of whatever else you’re doing now. Could it work then?”

The moon seems far more achievable in comparison.

American astronauts made it to the moon eight years after Kennedy declared that the country should send them. It’s impossible to predict whether Trump’s plan will work and, if it does, whether the next president will decide to keep going. He or she might say, as Barack Obama did in 2010, when he scrapped Bush’s moon plans, that “we’ve been there before,” and that Americans should aim for somewhere else. After a triumphant return, the United States might find itself back where Gene Cernan left it decades ago, ready to blast off “this mutha.”



When Becky Evans started studying cat-human relationships, she kept hearing, over and over again, about how cats are psychopaths.

On one hand, anyone who has looked into the curiously blank face of a catloaf knows exactly what that means. But also, exactly what does it mean to apply a human mental diagnosis to felines? We let these clawed creatures into our homes and our beds, but we still have trouble understanding them on anything but our own human terms.

Evans, a psychology graduate student at the University of Liverpool, recently devised a survey for owners who think that their cats are psychopaths. The survey asks owners to describe the allegedly psychopathic behaviors, and so far they have included bullying other pets, taking over the dog’s bed, and waiting on the kitchen counter to pounce on unsuspecting family members. In short, pretty typical cat behavior.

These answers get at the tricky semantics of calling a cat a “psychopath” when it is just … a cat. There’s always an implicit comparison when we talk about cats as aloof little jerks, says Mikel Maria Delgado, a postdoctoral researcher on cat behavior at the University of California at Davis. And that comparison is with dogs, which humans have spent thousands more years domesticating and molding in our image.

“We like things that remind us of us,” Delgado told me. “We like smiling. We like dogs doing what we tell them. We like that they attend to us very quickly. They make a lot of eye contact.”

Cats, she pointed out, simply don’t have the facial muscles to make the variety of expressions a dog (or human) can. So when we look at a cat staring at us impassively, it looks like a psychopath who cannot feel or show emotion. But that’s just its face. Cats communicate not with facial expressions but through the positions of their ears and tails. Their emotional lives can seem inscrutable—and even nonexistent—until you spend a lot of time getting to know one.

Dogs, on the other hand, have learned to mimic humans. They do that thing where they pull their mouths back into something resembling a smile. They hang their heads in a way that looks super guilty. Just as humans have shaped the physical appearance of dogs, we’ve bred them to be extremely attuned to human social cues. Dogs that repeatedly raise their brows to make cute puppy faces are more likely to be adopted out of shelters.

A common charge against cats is that they do not care about their owners as anything more than a source of wet food. In studies of pet-owner relationships, scientists have found that dogs are more “attached” to owners. These studies frequently rely on protocol called the Ainsworth Strange Situation, in which the pet explores an unfamiliar environment alone, with its owner, or with a stranger. Dogs are more at ease with their owners rather than with strangers. Cats can’t seem to care less about the human there.

Maybe this says something about pet-owner attachment, but Delgado noted that dogs are used to their owners taking them to new places. Cats are territorial, and they might only leave the house to go to the vet, so what looks like indifference to their owners might just be overwhelming anxiety about a new, strange environment. Plus, the Ainsworth Strange Situation was developed by Mary Ainsworth to study parents and infants—another example of us judging cats on human rather than cat terms.

Also, not all cats. There are terrifying cats, but there are also cats who just want to snuggle all day. Delgado was taking her cat on a walk when I called her. Evans has a lovely ginger tomcat, who definitely is not a psychopath and who definitely was not the inspiration for her latest research.

The survey, Evans hopes, is just the first step in devising a way to measure psychopathy in cats. She’d like to eventually study cats in their natural habitat—their house—so as not to rely on the word of their owners. The ultimate goal of the research is to devise a test for shelters so they can better match cats with owners. Whether it’s fair to call a cat a psychopath, we naturally do it, and it affects how well new owners and their cats will get along.

Talk to experienced cat owners, of course, and you’ll quickly find that psychopathy, or something that looks like it, is hardly a dealbreaker. When the subject came up in the office, my colleague Rachel Gutman launched into a tribute to her childhood cat K.C., who terrorized everyone but her immediate family members and, for some reason, Carmine the electrician. He’d bite anyone who dared to pet him. He’d attack her grandfather’s ankles. He’d pee in her grandmother’s bed when she came to visit. “In conclusion,” she said, “he was the best cat, and I miss him every day.”



When ecologists watch nature documentaries, sometimes they get ideas for research projects. John Grady, an ecologist from Michigan State University, kept seeing those inevitable scenes in which shoals of hapless fish are demolished by predators, and thinking about the differences between the cold-blooded killers—the tuna, the cod, and other big fish—and the warm-blooded ones. With a group of colleagues, he started tracking down their whereabouts, and soon found a surprising geographical trend.

The warm-blooded predators—the whales, the seals, the penguins of the world—bucked an almost universal pattern. Most groups of plants and animals are richer in species and more abundant in the tropics. In the ocean, that held for cold-blooded predators. But warm-blooded predators were more diverse toward the poles and conspicuously missing from several warm hot spots. For example, in the seas around Indonesia and Australia, which are among the richest in the world, marine mammals are virtually absent, as are penguins and other swimming birds.

Why? This riddle has a simple answer, Grady argues in a new study—but one with chilling implications for the future of seals, penguins, and whales.

It’s not about food. Grady and his team considered the possibility—warm-blooded animals need a lot to fuel their gas-guzzling metabolism. Perhaps colder waters are just richer in algae, plankton, and small fish? But they found that at higher, colder latitudes, there isn’t actually much more food around. It’s more that warm-blooded animals are eating a much bigger share of it than their cold-blooded rivals.

The real explanation for that pattern, the team says, is deceptively simple. An animal’s speed, agility, and mental prowess depend on its metabolism, which in turn depends on its temperature. Since birds and mammals can keep heating their bodies in frigid conditions, they remain fast and alert. By contrast, the fish they hunt become slower and dumber. At some tipping point of temperature, seals, dolphins, and penguins start outswimming their prey. They become more likely to encounter targets, more likely to catch them, and more likely to outpace cold-blooded predators of their own.

In Grady’s words, “Warm-bodied predators are favored where prey are slow, stupid, and cold.” That’s why sharks and other predatory fish dominate near the equator, but colder waters are the domain of whales and seals. By monopolizing food in the poles, these creatures can then specialize on specific types of prey, which makes them more likely to split into separate species. The killer whales of the North Pacific, for example, include mammal-eating transients and fish-eating, year-round residents, who don’t interbreed.

The team’s conclusions about “the thermal constraints of marine predators seem to fit with observations in nature, as well as theory,” says Donna Hauser from the University of Alaska Fairbanks. Consider the mammals and birds that, bucking the trend, do thrive in the warm tropics. To Grady, these exceptions simply prove the “slow, stupid, and cold” rule. The penguins of the equatorial Galápagos Islands, for example, feed in areas with cold currents. Sperm whales and their relatives forage by diving into frigid depths. Monk seals in Hawaii go after slow, bottom-dwelling prey. Giant whales, like blues and humpbacks, have evolved a style of foraging—lunge feeding—that allows them to engulf massive shoals of prey in fast surprise attacks.

And dolphins—the only group of marine mammals that have really diversified in the tropics—make up for any physical disadvantages with intellect. They can corral fish into balls using curtains of bubbles, herd them toward one another with tail slaps, and even drive them onto shorelines. When you’re as smart as a dolphin, perhaps everything seems slow and stupid, even when it isn’t cold.

But the world is changing. It’s likely that the surface of the oceans will warm by 2 to 3 degrees Celsius within this century. As that happens, marine mammals and birds should disproportionately suffer, as warmer water robs them of the advantages that they’ve historically enjoyed over cold-blooded rivals.

Signs of that shift are already apparent. In the Barents Sea, off the northern coast of Norway and Russia, stocks of capelin and other small fish have been going up in recent decades. That should be a boon for predators such as cod and harp seals, but while the cold-blooded cod are indeed flourishing, the harp seals have declined. And that may be because the local water has become considerably warmer.

Grady’s team estimates that every time the ocean’s surface warms by 1 degree Celsius, populations of marine mammals will fall by 12 percent, and populations of seals and sea lions in particular will fall by 24 percent. “The threat of warming waters is a real issue for a lot of marine mammals and birds,” Grady says.

But “predictions are hard,” Hauser notes. There’s not a lot of data on how Arctic mammals are responding to changing climate, but what we have paints a complicated picture. Polar bears are the archetypal losers of a warming world, but some populations are still doing well—as are those of bowhead whales. Some groups of belugas have shifted the timing of their migrations; others are foraging in deeper, colder waters. These changes in behavior might make marine mammals more resilient to shifting climates than simple calculations would suggest. Maybe they just need to find the parts of the world where fish remain slow, dumb, and cold.



The intense and mysterious winds of the Washington, D.C., metro system seem to come out of nowhere. They’re not particularly bad when standing on the train platform, as one might expect; in fact, it’s the level between the train platform and the street where the infuriatingly powerful gusts are the strongest. Every now and then, my fellow commuters and I will be caught holding down our clothes and gripping our reading material, while our hair slaps us in the face. Occasionally, a small child is knocked over. But it’s impossible to predict when the winds will strike. One morning I noticed I was tensing my entire body, bracing myself for a blast that—of course, this time—never came.

It’s maddening, and no one can seem to figure out where the wind is coming from, or why it’s so variable. Plenty of Washingtonians seem content to clutch their hats and ignore this puzzling phenomenon. When I first moved here, I heard the tracks would be “constantly on fire” (they aren’t), construction would make weekend travel impossible (it doesn’t), and all the metro cars have weird, vintage rugs (which, okay, some do). But what I wasn’t warned about—and wish I had been—was the wind.

After a few months of being consistently caught off guard, I needed to understand what was happening. So I called Kenny Breuer, an engineering professor at Brown University, to see whether he could help me figure out the possible factors.

Several interconnected variables could be at play here, according to Breuer, and one could be an air-pressure difference. Any large, underground environment with a lot of people—such as a metro station—needs “a powerful air-conditioning or air-handling system.” This system creates an exchange of air from the ground to the upstairs, or indoors to outdoors, where there is also likely a pressure difference. Air also naturally moves from areas of higher pressure to those of lower pressure, to equalize a pressure difference. “If you’re in the right place,” he told me, “these relatively small pressure differences can generate a substantial flow.”

Furthermore, Bernoulli’s principle states that as air pressure changes, air speed reacts in the inverse, basically trading off. So, as Breuer explained, “if you have a high air pressure, you have a low speed, and if you have a low air pressure, you have a high speed.” Anytime there is airflow, like “air moving through the station, from large spaces to small spaces,” the velocities and pressures can change substantially.

Yet another factor could be what’s commonly called the piston effect, which refers to the airflow that a vehicle creates when it moves through a tunnel. In this case, trains are running through the tunnels at high speeds, pushing air out in front of them onto the platform— which spreads outward wherever it can (such as up escalators and into other sections of the station)—and creating suction by pulling air into the tunnel behind them.

On top of all this, Breuer pointed out that “incredibly complicated geometry” is involved in metro stations: “There’s trains going in two different directions, or if it’s a big station, an interchange with multiple rails and multiple trains going.” In large cities like New York, building shape has a direct influence on wind strength. (Chicago also comes to mind here, although the Windy City did not get its name from weather, but from “the hot air bellowing from politicians.”) And because of the aforementioned pressure difference, aboveground air also affects the air belowground.

Finally, thermodynamics must be accounted for. “If the air in the metro is warmer than the air outside or vice versa,” Breuer said, “then the temperature difference could cause a flow of air.” Again, it’s simple physics: Cold air is denser than hot, which means cold air will fall and hot air will rise. In the case of so many urban, underground train stations, which are (in theory) heated in the winter and cooled in the summer, cold air could be flowing down into the station, or warm air flowing upward out of the station, “and that could be a significant factor.”

So air-handling systems, Bernoulli’s principle, the piston effect, complex building shapes, and temperature shifts all possibly have a role. I reached out to D.C.’s transit agency, the Washington Metropolitan Area Transit Authority, for further clarification and comment, but it never responded.

My bizarre fascination aside, is there anything, really, to worry about here? My research turned up one long-term concern: Underground transportation hubs are uniquely vulnerable to airborne biochemical attacks, similar to what happened in Tokyo in 1995. These stations have “high populations of people in a confined space,” with dozens of openings to the city, as David Brown, of Argonne National Laboratory, explained to me over the phone. That means “material can move throughout the system and can come up all over the place.”

He must have heard the concern in my voice, because he followed up with reassurances about “a computational model that we can use to predict these [air]flows and how materials are transported through the system.” He added, “The really key things are to know how material dilutes from station to station, and at what speed it moves through the system.” In the past decade, Brown and his team have run “extensive” simulations in Boston, New York City, and Washington, D.C., to gain information that could help inform responses to a biochemical terrorist incident.

But the short answer to my question is no—commuters can face metro winds without fear. Apart from one very unusual case in 2014, when a child in a stroller was blown onto the tracks in London, and three cases in which gusts caused by the movements of the trains themselves blew people right over, the strong winds aren’t dangerous. At most they will ruin our hair, ruffle our clothes, and discourage at least some of us from wearing skirts.





Shoestring, waffle, curly, or thick-cut: However you slice it, nearly everyone loves a deep-fried, golden-brown piece of potato. But that’s where the agreement ends and the battles begin. While Americans call their fries “french,” Belgians claim that they, not the French, invented the perfect fry. Who’s right? This episode, we take you right into the heart of the battle that continues to be waged over who owns the fry: Who invented it, who perfected it, who loves it the most?  And then we take you behind the scenes into another epic fight—the struggle for the perfect fry. Can food scientists create a fry with the ultimate crispy shell and soft inside, one that can stay that way while your delivery driver is stuck in traffic? Plus, the condiment wars: Does mayo really have the edge over ketchup? Listen in now to find out!

Potatoes were domesticated in what’s now Peru approximately 10,000 years ago, but fries—sticks of potato cooked in oil so that a crispy shell surrounds a creamy interior—are a European invention. Exactly where and when these crispy delights evolved, however, remains a matter of debate. The Spanish brought potatoes to Europe from their South American colonies in the 1500s, but even though they undoubtedly fried pieces of potato in olive oil, the results wouldn’t have been fries as we know them. It took northern Europeans, with their animal-fat-based deep-frying, to create the true fry. But which northern Europeans: the Belgians or the French?

To get to the bottom of this mystery, we travel to Belgium to visit the world’s largest and smallest fry museums—the Frietmuseum, in Bruges, and the Home Frit’ Home micro museum, in Brussels. With the help of the museums’ founders, Eddy Van Belle and Hugues Henri, we examine the evidence—books, engravings, fairground posters, missing letters, and dead journalists—and declare a victor. And then, undaunted, Gastropod wades into another battlefield: the fight for the perfect fry.

Thanks to food scientists, this is a battle that has largely been won. “About 50, 60 years ago, it would be not unusual to walk into a restaurant and eat a fry that was soggy, doughy, mealy, limp, or very hard,” Kantha Shelke, the principal at the food-science and research firm Corvus Blue, told us. “You don’t get that today. Practically every restaurant has fries that are crisp and deliciously and sensually soft inside.”

We go behind the scenes with Shelke, as well as Deborah Dihel, the vice president of innovation at Lamb Weston, one of the largest producers of frozen french fries in the United States, to learn the scientific secrets of that success. We also hear about the failures along the way—from Lamb Weston’s fry-shaped graveyard to Shelke’s undercover operation to try to make a certain fast-food restaurant’s fries match up to those of its competitor. (Shelke wouldn’t reveal the name of either restaurant, but we have an educated guess!)

Today, however, there’s a new challenge facing fry scientists: the rise of delivery. “When you make fresh french fries and you put them in a closed package, you create a little sauna in there,” explains Dihel. Her team has spent years fighting soggy delivery fries—one of her colleagues even signed up to be an Uber Eats driver to better understand the challenge facing fries. Can they deliver a fry that stays crispy all the way from the restaurant to your front door? Listen in to find out!

This post appears courtesy of Gastropod.



Since 2013, Kristina Olson, a psychologist at the University of Washington, has been running a large, long-term study to track the health and well-being of transgender children—those who identify as a different gender from the one they were assigned at birth. Since the study’s launch, Olson has also heard from the parents of gender-nonconforming kids, who consistently defy gender stereotypes but have not socially transitioned. They might include boys who like wearing dresses or girls who play with trucks, but who have not, for example, changed the pronouns they use. Those parents asked whether their children could participate in the study. Olson agreed.

After a while, she realized that she had inadvertently recruited a sizable group of 85 gender-nonconforming participants, ages 3 to 12. And as she kept in touch with the families over the years, she learned that some of those children eventually transitioned. “Enough of them were doing it that we had this unique opportunity to look back at our data to see whether the kids who went on to transition were different to those who didn’t,” Olson says.

By studying the 85 gender-nonconforming children she recruited, her team has now shown, in two separate ways, that those who go on to transition do so because they already have a strong sense of their identity.

This is a topic for which long-term data are scarce. And as transgender identities have gained more social acceptance, more parents are faced with questions about whether and how to support their young gender-nonconforming children.

“There’s a lot of public writing focused on the idea that we have no idea which of these gender-nonconforming kids will or will not eventually identify as trans,” says Olson. And if only small proportions do, as some studies have suggested, the argument goes that “they shouldn’t be transitioning.” She disputes that idea. “Our study suggests that it’s not random,” she says. “We can’t say this kid will be trans and this one won’t be, but it’s not that we have no idea!”

“This study provides further credence to guidance that practitioners and other professionals should affirm—rather than question—a child’s assertion of their gender, particularly for those who more strongly identify with their gender,” says Russell Toomey from the University of Arizona, who studies LGBTQ youth and is himself transgender.

(A brief note on terms, since there’s a lot of confusion about them: Some people think that kids who show any kind of gender nonconformity are transgender, while others equate the term with medical treatments such as hormone blockers or reassignment surgeries. Neither definition is right, and medical interventions aren’t even in the cards for young children of the age Olson studied. That’s why, in her study, she uses pronouns as the centerpiece marker of a social transition. Changing them is a significant statement of identity and is often accompanied by a change in hairstyle, clothing, and even names.)

When the 85 gender-nonconforming children first enrolled in Olson’s study, her team administered a series of five tests that asked what toys and clothes they preferred; whether they preferred hanging out with girls or boys; how similar they felt to girls or boys; and which genders they felt they currently were or would be. Together, these markers of identity gave the team a way to quantify each kid’s sense of gender.

The team, including James Rae, now at the University of Massachusetts Amherst, found that children who showed stronger gender nonconformity at this point were more likely to socially transition. So, for example, assigned boys who had the most extreme feminine identities were most likely to be living as girls two years later. This link couldn’t be explained by other factors, such as how liberal the children’s parents were. Instead, the children’s gender identity predicted their social transitions. “I think this wouldn’t surprise parents of trans kids, and my findings are often ‘duh’ findings for them,” says Olson. “It seems pretty intuitive.”

Charlotte Tate, a psychologist from San Francisco State University, says that this quantitative research supports what she and other transgender scholars have long noted through qualitative work: There really is something distinctive and different about the kids who eventually go on to transition. From interviews with trans people, “one of the most consistent themes is that at some early point, sometimes as early as age 3 to 5, there’s this feeling that the individual is part of another gender group,” Tate says. When told that they’re part of their assigned gender, “they’ll say, ‘No, that’s not right. That doesn’t fit me.’ They have self-knowledge that’s private and that they’re trying to communicate.”

Olson’s team also showed that those differences in gender identity are the cause of social transitions—and not, as some have suggested, their consequence. After assessing the group of 85 gender-nonconforming children, the team administered the same five tests of gender identity to a different group of 84 transgender children who had already transitioned, and to a third group of 85 cisgender children, who identify with the sex they were assigned to at birth. None of these three groups differed in the average strength of their identities and preferences. In other words, trans girls who are still living as boys identify as girls just as strongly as trans girls who have transitioned to living as girls, and as cis girls who have always lived as girls. Put another way: Being treated as a girl doesn’t make a trans child feel or act more like a girl, because she might have always felt like that.

“Implicit in a lot of people’s concerns about social transition is this idea that it changes the kids in some way, and that making this decision is going to necessarily put a kid on a particular path,” says Olson. “This suggests otherwise.” Children change their gender because of their identities; they don’t change their identities because they change their gender.

“The findings of this compelling study provide further evidence that decisions to socially transition are driven by a child’s understanding of their own gender,” says Toomey. “This is critically important information given that recent public debates and flawed empirical studies erroneously implicate ‘pushy’ parents, peers, or other sources, like social media, in the rising prevalence of children and adolescents who identify as transgender.”

Olson’s new findings come on the back of another controversial study, from 2013, in which Thomas Steensma from University Medical Center in Amsterdam studied 127 adolescents who had been referred to a clinic for “gender dysphoria”—a medical term describing the distress when someone’s gender identity doesn’t match the gender assigned at birth. Only four people in that cohort had socially transitioned in early childhood, and all of them ended up identifying as transgender. By contrast, most of those who had not transitioned did not have gender dysphoria later.

“People have taken from that study that a lot of these kids are not going to be trans adults so you shouldn’t be socially transitioning them, or that social transitions are changing kids’ identities,” Olson says. But “we’re suggesting that the kids who are socially transitioning seem to be different even before that transition, which shifts the interpretation of that past study.” (Steensma did not respond to requests for comment.)

Olson admits that there are weaknesses in her new study. It’s relatively small, and all the children came from wealthy, educated, and disproportionately white families. And since it began almost by accident, when parents of gender-nonconforming children approached her, she couldn’t preregister her research plans, a growing practice in psychology. (It reduces the temptation to fiddle with one’s methods until they yield positive results and instills confidence among other scientists.)

To at least partly address these shortcomings, Olson did a multiverse analysis: She reran her analyses in many different ways to see whether she still got the same result. What if, instead of using all five tests of gender identity, she just looked at combinations of four? Or three? Two? The team ran all these what-if scenarios, and in almost all of them, the results were the same. “They went above and beyond the analyses typically conducted and presented in scientific journals,” says Toomey. “Their results were robust across these additional tests, suggesting that readers can have a high level of confidence in these findings.”

Olson stresses that she has no magic test that can predict exactly which children will transition and which will not. It’s a question of probabilities. In her study, based on their answers, all the children got a gender-nonconformity score between 0 and 1. For comparison, those who scored 0.5 had a one-in-three chance of socially transitioning, while those who scored 0.75 had a one-in-two chance.

“How much gender nonconformity is ‘enough’ to allay the anxieties parents feel around transition is an open question,” says Tey Meadow, a sociologist from Columbia University who studies sexuality and gender and has written for The Atlantic. Parents are the ultimate arbiters of a child’s access to transition, and they make decisions “in a culture that encourages parents to look for every possible alternative to transness,” Meadow adds.

“It's not like you can take a blood sample or do an MRI,” says Aaron Devor, the University of Victoria’s chair of transgender studies, who is himself transgender. “One of the phrases often used is ‘consistent, persistent, and insistent.’ When you get that constellation, that kid is also a kid who might want to transition. And that’s what [Olson’s] research is corroborating. It adds some very valuable data.”

Devor and others note that Olson’s earlier studies suggest that children who are supported and affirmed in their transitions are just as mentally healthy as cisgender peers. That reminds him of seminal work by the American psychologist Evelyn Hooker. In the 1950s, when many psychologists saw homosexuality as a mental illness (largely because they had only ever worked with gay people who had records of arrest or mental-health problems), Hooker surveyed a more representative sample and found that gay and straight men don’t differ in their mental health. That was instrumental in getting homosexuality removed from a list of mental-health disorders in 1987. “We’re sitting in a similar moment today with transgenderism,” says Devor. “The mental-health issues that we see are largely the result of living a life that blocks your expression of your gender. My view is that the work coming out of Olson’s group will have an Evelyn Hooker effect.”

I am reminded of what Robyn Kanner wrote in The Atlantic last year: “Society has done nothing for trans youth for so many years. People have to trust that the youth who sway in the breeze of gender will land on their feet when they’re ready. Wherever that is, it’ll be beautiful.”



The town of Kabwe sits about 70 miles north of Zambia’s capital, Lusaka, as the crow flies. Just over 200,000 people live in this major transportation crossroads. Like most of this south-central African nation, Kabwe is perched on a high and vast plateau, a land of red soils dotted with shrubby legumes and canopies of small, spindly miombo trees.

Kabwe’s story is defined in part by a mine that opened in the early 1900s after rich deposits of lead and zinc were discovered on the edge of the town. Kabwe—then called Broken Hill—became a major mining center, producing profits for British interests and, later, important metals for the Allies in both world wars. At that time, Zambia was known as Northern Rhodesia, after British mining magnate Cecil Rhodes, whose name has come to symbolize the worst evils of his nation’s colonialism.

The mine shut down in 1994 after its deeper deposits of zinc and lead were exhausted, 30 years after Zambia achieved its independence. But it left the town with a toxic legacy of lead contamination. Recent studies have found that nearly all of Kabwe’s children have blood-lead levels so high that their health is in serious danger. Environmentalists consider Kabwe to be one of the most polluted cities on Earth. And they are concerned by reports that the Zambian government has given the international minerals company Jubilee Metals Group, based in London, permission to begin collecting lead and zinc from surface deposits this year.

Yet the Kabwe mine also left a happier legacy, one that all of humankind can celebrate: In 1921, miners working there discovered the fossilized skull of a possible human ancestor, along with some other bones thought to be associated with it. Dubbed “Rhodesian Man,” this hominin might occupy a pivotal place in the evolutionary transition from Homo erectus to Homo sapiens. Today anthropologists refer to the find as the “Kabwe skull” and recognize it as the first early-human fossil discovered in Africa, found at a time when most scientists were looking to Asia or even Europe for the origin of our species.

Soon after its discovery, mining officials sent the fossils to the British Museum for study. In subsequent years, the skull and other remains stayed in the United Kingdom, and today they reside in London’s Natural History Museum. The Zambians have been trying to get them back for decades, to no avail.

The United Kingdom has a reputation for fiercely resisting the return of antiquities acquired during colonial times, especially tourism-generating treasures such as the Parthenon sculptures (a.k.a. Elgin marbles) from Greece and the Rosetta stone from Egypt. But last May, at a meeting of the United Nations Educational, Scientific and Cultural Organization (UNESCO) heritage committee in Paris, Zambian representatives finally broke through British resistance. The United Kingdom agreed to sit down and talk about the possible repatriation of the skull and related fossils back to Zambia.

British and Zambian officials are being tight lipped about the upcoming negotiations, citing their sensitive diplomatic nature. Yet the decision to discuss repatriating the skull fits a more recent pattern wherein former colonial powers have begun returning cultural artifacts and human remains to indigenous peoples. Examples include Germany’s return to Namibia of the remains of more than 25 victims of a colonial-era genocide, including 19 skulls that had been taken out of Africa in the early 20th century for “anthropological” research; France’s return of the remains of Saartjie Baartman (also known as “Hottentot Venus”) to South Africa for proper burial; and the Smithsonian Institution’s repatriation of human remains to New Zealand and to Native American tribes in the United States.

If Britain agrees to return the remains of the Rhodesian Man, it could provide a major boost, the Zambians say, to their national identity and would represent a major victory for repatriation efforts worldwide. At stake are key issues about the rights of former colonies to control their own heritage, and the responsibilities of former colonial powers to own up to the sins of the past.

On June 17, 1921, a Swiss miner named Tom Zwigelaar and a young African miner, working at Broken Hill, uncovered the Rhodesian Man. We owe details of the discovery to Aleš Hrdlička, a famed anthropologist at the Smithsonian Institution, who traveled to Northern Rhodesia to gather more information about the exact location where the skull had been found.

Hrdlička spoke with Zwigelaar himself, who was still working at the mine, about the find. “[Zwigelaar] was found to be a serious middle-aged man, not highly educated but of good common sense,” Hrdlička wrote in a 1926 issue of the American Journal of Physical Anthropology.

Zwigelaar told Hrdlička that he was working with an African miner—whose name was never recorded—at about 10 a.m. that June morning in a pocket of the mine with a lot of lead ore. “After one of the strokes of the pick, some of the stuff fell off, and there was the skull looking at me,” Zwigelaar told him. Hrdlička’s paper included a photo, taken by the mine’s manager shortly after the discovery, of Zwigelaar leaning against the mine shaft holding the skull on the palm of his outstretched left hand.

The skull didn’t stay in Northern Rhodesia for long. A doctor at the Broken Hill Hospital examined it and immediately suspected its scientific importance. About five months later, the Rhodesia Broken Hill Mine Company shipped it off to England, donating the find to the British Museum in London. There, the museum’s keeper of geology, the renowned paleontologist Arthur Smith Woodward, named it Homo rhodesiensis. Woodward and other scholars recognized that the skull, with a brain size of about 1,300 cubic centimeters—within the range of H. sapiens—was an important human ancestor. Many anthropologists today classify the skull as belonging to the species Homo heidelbergensis, a descendant of H. erectus. Some researchers think H. heidelbergensis is, in turn, the common ancestor of modern humans and Neanderthals.

Over the years, the “Kabwe skull” has continued to attract scientific attention, especially because it is one of the best-preserved hominin fossils from its time period of roughly 300,000 years ago. That timing coincides with when human-evolution experts think that H. sapiens diverged from more archaic hominins in Africa. Thus, the Kabwe skull—which includes ancient features such as prominent brow ridges and modern features such as a globular-shaped braincase—could represent a transitional step in human evolution.

In 2016, scientists sampled it for ancient DNA, although so far attempts to sequence even part of the Rhodesian Man’s genome have been unsuccessful. In just the past two years, at least 10 papers have been published about the fossils, many based in whole or in part on CT-scanning data from the skull. These studies seem to confirm that the skull is a descendant of the earlier H. erectus, but its relationship with later humans, such as H. sapiens and the Neanderthals, is still a matter of debate. Researchers at the Natural History Museum are trying to help resolve this mystery by dating the skull more precisely using modern methods.

Zambia achieved its independence from Britain in 1964. A decade later, the young nation began trying to get the Kabwe skull and associated bones back, but the British government either rejected or ignored its requests.

In recent years, Zambian researchers and cultural officials have left a paper trail of detailed and eloquent arguments—citing moral grounds and international law on cultural artifacts and human remains—for the return of the Kabwe skull. In many ways, the case for repatriation echoes that made by Native Americans under the 1990 Native American Graves Protection and Repatriation Act, which provides for the return of artifacts and human remains under certain defined conditions.

Key to Zambia’s position is a colonial law from 1912 called the Bushman Relics Proclamation. Zambia interprets the proclamation to mean that no cultural artifacts or human remains could be removed from Northern Rhodesia without a permit from the British South Africa Company, which at that time was chartered by the British government to administer the protectorate. The Zambians insist that no such permit was ever issued to the Broken Hill mining company when it donated the skull to the British Museum.

In a 2013 paper in the African Archaeological Review, which chronicles some of this history, the Zambian historian Francis Musonda contended that the removal of the skull from Zambia occurred in a colonial context that is anachronistic today. (Greece has made similar arguments for the return of the Parthenon sculptures housed in the British Museum.)

“African people find it unacceptable for a British institution to provide a repository for an African fossil when they themselves have the capacity to do so,” Musonda wrote. “This has put the country in an embarrassing and awkward position because of the impression created that it is incapable of looking after its own hominin fossil.” And even if the conditions in Zambia were “not ideal,” Musonda argued, “why not assist the country in creating conditions deemed suitable for the object?”

It is still unclear when the actual negotiations between Zambia and the United Kingdom will begin, and Zambian officials have expressed some frustration at the delays—both in the Zambian press and to Sapiens. In the meantime, wrote Flexon Mizinga, executive secretary of the National Museums Board of Zambia, in an email, “it would be premature to make any statements on this matter before exhausting consultations in progress with the Government of Zambia.” Mizinga adds that “we wouldn’t want to jeopardize the multilateral issues involved.”

A spokesperson for the U.K.’s Department for Digital, Culture, Media & Sport was equally circumspect, only confirming the UNESCO agreement and that it was expected to lead to “discussions to find a mutually acceptable solution to the Broken Hill skull case.”

Nevertheless, the news did get considerable coverage in the Zambian press, and on June 1, 2018, the Zambian delegation in Paris put out a detailed statement hailing the diplomatic breakthrough.

In email correspondence, numerous human-evolution researchers expressed sympathy with Zambia’s position. “We should all support repatriation of cultural objects looted or taken away, for whatever reason, from any country in the world,” writes Yohannes Haile-Selassie, the curator of physical anthropology at the Cleveland Museum of Natural History.

“The pride that Africans feel about ancestry is unwavering and pronounced,” writes Wendy Black, the curator of pre-colonial archaeology at the Iziko Museums of South Africa in Cape Town. “For Africans, repatriation of these items is viewed as part of a healing process, where all parties concerned can make amends, forgive, and move on.”

Haile-Selassie, an Ethiopian who is active in paleoanthropological research in his native country, points out that the key question is who will have control—not only of the actual skull but also the CT scans and other digitalized information that have been gathered on the specimen over many years. That information, which the Natural History Museum now considers its intellectual property, should be under Zambia’s control, he contends.

Another issue is access, which human-evolution researchers are eager to maintain. “It is an aesthetically beautiful specimen,” writes Leslie Aiello, president of the American Association of Physical Anthropologists. Aiello, formerly at University College London and a past president of the Wenner-Gren Foundation, which funds Sapiens, adds that “while in London, I used to ask them to get it out occasionally just so I could admire it!”

Some researchers think that before the Kabwe skull is repatriated, certain conditions should be met to ensure that scientists will be able to access and study it in the future. Gerhard Weber, an anthropologist at the University of Vienna in Austria who has studied CT scans of the skull, writes that even if it is scanned and digitalized with “the best resolution possible” before it leaves London, “this will only help for a limited time … There will be new methods in 20, 50, or 100 years that we cannot even imagine today.” Weber suggests that agreements should be negotiated with Zambia that guarantee access to the skull so that novel techniques can be applied. He also thinks an international committee should monitor these agreements.

But Black and others don’t see any inherent barriers to access if Zambia gets the Kabwe skull back. “Researchers travel to Africa all the time,” Black maintains. “Museums in South Africa and Kenya, for example, provide access to their collections to numerous researchers from around the world each year … One could apply for access, as all researchers do at all institutions.”

Furthermore, writes Rebecca Ackermann, a biological anthropologist at the University of Cape Town in South Africa, “a move to Lusaka would certainly make it easier for African researchers to study the remains.” Indeed, the Kabwe skull, discovered when Zambia was still under colonial rule and then whisked out of the country, is an outlier; most hominin fossils discovered in Africa—such as Ethiopia’s “Lucy” and the many fossils found in Kenya, Tanzania, and South Africa—have remained in their countries of origin.

Ackermann and others contend that non-African researchers and museums must be willing to loosen their grips on the spoils of the colonial past, even ones that are vital to our understanding of human origins. “There has been a whole lot of taking and comparatively little giving back,” she contends. Keeping the skull in British—not Zambian—hands, she argues, perpetuates a colonial legacy. “Any claim that Zambians can’t take responsibility for their own heritage is frankly racist.”

This post appears courtesy of Sapiens.



Editor's Note: Fifty years ago this month, the three-man crew of Apollo 8 swung around the moon’s far side and encountered a vision never before seen by human eyes: the sunlit Earth, juxtaposed against an ashen lunar plain, and a backdrop of infinite black space.

Frank Borman, Apollo 8’s commander, has expressed frustration that he and his fellow astronauts failed to convey, with words, the cosmic import of their experience. “I don’t think we captured, in its entirety, the grandeur of what we had seen,” he once said.

By the time Apollo 8 splashed home in the Pacific, writers had already tried to bridge the gap between the astronauts’ limited literary powers and the extraordinary sight they beheld. “To see the Earth as it truly is, small and blue and beautiful in that eternal silence,” the poet Archibald MacLeish wrote in the Christmas 1968 edition of The New York Times, “is to see ourselves as riders on the Earth together, brothers on that bright loveliness in the eternal cold, brothers who now know they are truly brothers.”

Many literary interpretations of this new motif—the astronaut gazing back at Earth—would follow. But perhaps none has surpassed a two-paragraph passage in Don DeLillo’s 1983 short story, “Human Moments in World War III,” about two men aboard an orbiting military space station, one of whom becomes entranced by his view of Earth through the station’s window. The planet “fills his consciousness,” DeLillo writes, “the answer to a lifetime of questions and vague cravings.”

With special permission from Mr. DeLillo, the passage will appear here at The Atlantic through next July’s anniversary of the first moon landing.

  –Ross Andersen

Vollmer has entered a strange phase. He spends all his time at the window now, looking down at the earth. He says little or nothing. He simply wants to look, do nothing but look. The oceans, the continents, the archipelagoes. We are configured in what is called a cross-orbit series and there is no repetition from one swing around the earth to the next. He sits there looking. He takes meals at the window, does checklists at the window, barely glancing at the instruction sheets as we pass over tropical storms, over grass fires and major ranges. I keep waiting for him to return to his pre-war habit of using quaint phrases to describe the earth: it’s a beach ball, a sun-ripened fruit. But he simply looks out of the window, eating almond crunches, the wrappers floating away. The view clearly fills his consciousness. It is powerful enough to silence him, to still the voice that rolls off the roof of his mouth, to leave him turned in the seat, twisted uncomfortably for hours at a time.

The view is endlessly fulfilling. It is like the answer to a lifetime of questions and vague cravings. It satisfies every childlike curiosity, every muted desire, whatever there is in him of the scientist, the poet, the primitive seer, the watcher of fire and shooting stars, whatever obsessions eat at the night side of his mind, whatever sweet and dreamy yearning he has ever felt for nameless places far away, whatever earth sense he possesses, the neural pulse of some wilder awareness, a sympathy for beasts, whatever belief in an immanent vital force, the Lord of Creation, whatever secret harbouring of the idea of human oneness, whatever wishfulness and simple-hearted hope, whatever of too much and not enough, all at once and little by little, whatever burning urge to escape responsibility and routine, escape his own over-specialization, the circumscribed and inward-spiralling self, whatever remnants of his boyish longing to fly, his dreams of strange spaces and eerie heights, his fantasies of happy death, whatever indolent and sybaritic leanings, lotus-eater, smoker of grasses and herbs, blue-eyed gazer into space—all these are satisfied, all collected and massed in that living body, the sight he sees from the window.

Excerpt from “Human Moments in World War III” by Don DeLillo Copyright ©1983, 2011 by Don DeLillo. First published in Esquire Magazine and included in The Angel Esmeralda: Nine Stories (Scribner, a division of Simon & Schuster, Inc.) Used by permission of The Wallace Literary Agency.



