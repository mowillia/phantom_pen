President Donald Trump says he doesn’t want to cut taxes on the rich. His Treasury Secretary Steven Mnuchin said he doesn’t want to cut taxes on the rich. The Democratic Party says they don’t want to cut taxes on the rich. Americans say they don’t want to cut taxes on the rich.

The House and Senate Republican tax bills are taking a different approach: They are cutting taxes on the rich—significantly. Their plans would slash the corporate tax rate by almost half, cut taxes on pass-through income for smaller businesses, eliminate the Alternate Minimum Tax, and erode the estate tax, all of which disproportionately help rich families. This comes at a time when post-tax corporate profits as a share of GDP have hovered at a record-high level for the last seven years, and the top 1 percent's share of total income is higher than any time in the second half of the 20th century.

Nearly 50 percent of the benefits of the Senate tax cut would go to the top 5 percent of household earners in the first year of the law, according to the Tax Policy Center. By 2027, 98 percent of multimillionaires would still get a tax cut, compared to just 27 percent of households making less than $75,000. It’s no wonder then that the GOP tax bills are now among the least popular pieces of major legislation in modern history, with the public rejecting it by a two-to-one margin. Other than Republicans, all party, gender, education, age and racial groups disapprove of the bill.

In an almost eerie way, the unpopularity of the bill is an almost perfect reflection of its distributional effects. In a recent Quinnipiac poll, about 60 percent of respondents said that the wealthy would benefit the most from tax cuts compared to just 6 percent of the poor. In fact, TPC analysis finds that about 60 percent of the tax benefits of the House and Senate bills would go to the top quintile, while the poorest 20 percent would receive about 6 percent.

Share of Quinnipiac Responses vs. Estimated Distributional Effects of Tax Bills

There is no parliamentary rule requiring that major tax legislation must be a means of enriching the already affluent. Lawmakers could increase take-home pay for non-rich families immediately with a payroll tax cut. They could expand the Earned Income Tax Credit and permanently extend a larger Child Tax Credit that grows faster than inflation. They could permanently increase the "refundability" of tax credits to help lower-income families.

But they’re not doing any of that. They’re cutting taxes for the rich. And there are two reasons why.

The first is that Republican politicians, whose campaigns are often financed by wealthy conservative donors like Sheldon Adelson and the Koch family, are worried that a failure to cut taxes on corporations will have a detrimental effect on contributions from the party’s corporate-libertarian wing. “My donors are basically saying, 'Get it done or don't ever call me again,'" Representative Chris Collins, a New York Republican, told The Hill.  The “financial contributions will stop" if the GOP fails to deliver corporate tax cuts, Senator Lindsey Graham, a Republican from South Carolina, told NBC News. "The donor class … has concluded that the inaction of this administration and Congress is totally unacceptable,” Josh Holmes, the former chief of staff to Senator Mitch McConnell, told CNN. “(Donors) would be mortified if we didn’t live up to what we’ve committed to on tax reform,” Steven Law, the head of Senate Leadership Fund, a super PAC, told the New York Post.

There are so many quotes from Republican politicians foretelling donor retribution that it’s tempting to say the party’s legislative problems are simply the result of a plutocratic donor class demanding laws that are out of step with the American public. Indeed, even Republican voters don’t stand behind them. In a 2015 Pew survey, more than half of Republican voters said they were bothered by corporations not paying enough taxes.

But there is another reason why the Republican tax bills, like the party’s “repeal and replace” bills, have faced such massive national unpopularity. Spurred by a donor class that is seeking radical changes to the budget, the party has already rejected the moderate conservative solutions to healthcare and corporate tax policy. As The Atlantic’s David Frum wrote this week, “the broad outline of tax reform seems obvious: Lower corporate rates to somewhere between 25 and 30 percent, the developed-world norm [and] tighten collection so that the rate is actually paid.” But that very idea has already been proposed by President Barack Obama in 2012. Republicans immediately rejected it, just as they rebuffed the president’s inclusion of ideas hatched at the conservative Heritage Foundation in the Affordable Care Act. Since the Republican Party has already rejected the reasonable conservative frameworks for health care and corporate tax policy, all that it’s left with is the land of the unreasonable.



When Janet Yellen leaves her role as the chair of the Fed at the end of her term in February, she will have a pretty impressive record to tout. She has led the Fed during one of the longest market rallies in modern history and presided over one of the biggest declines in unemployment and most significant periods of job creation ever. Despite these successes, critics had hoped that Yellen, who inherited an economy that had stabilized since the recession, would be aggressive in rolling back recession-era policy. Instead she proceeded with a slow and cautious approach to raising interest rates in the face of a strengthening economy.

Yellen will retire from the board completely after her term is up, even though she is still eligible to serve as a governor. One of the board’s current governors, Jerome Powell, will take her place, and likely continue the general arc of her monetary strategy.

Despite the growing health of the economy under her watch, Yellen will be the first Fed chair in recent history to finish a term but not be appointed for a second. The previous three Fed chairmen, Ben Bernanke, Alan Greenspan, and Paul Volcker, were all reappointed despite elections that put a president from the rival party in power.

I asked four women economists what they think Yellen has accomplished as the head of the Fed, and if having a woman in one of the most high-profile jobs in economics changed anything for them, or the male-dominated field.

She did a lot to weigh all of the data in determining the strength of the labor market, the risk of inflation. And those decisions to keep interest low have helped the recovery continue, and especially have helped the recovery reach communities of color, which is another thing that I think she should get credit for—being a Fed chair who was willing to hear concerns about what the Fed can do to address racial disparities, and acknowledging that there are racial disparities in employment and other economic outcomes that the Fed’s policies can have some effect on.

I don’t think it really had any impact on the profession and how the profession views female economists. I don’t sense really that anything has changed much. I was excited and glad that there was finally a woman in that position. But I would say the bigger impact may be for people outside of the profession. This is the first time that people have seen a woman in that role, and I don’t know that many people ever believed that someone other than a white male should be a Fed chair. And so I think having her there has sort of opened that door.

Janet Yellen has had a successful tenure as chair of the Federal Reserve. During her time there, we have seen a dip in unemployment rates, an overall improvement in the economic picture, and an uptick in other indicators that suggest that the recovery after the Great Recession has finally taken hold.

While she prefers to not be viewed through a gender lens, what makes her stand out to me as the first female Fed chair is her speech on women’s economic opportunities, and how women are unable to fully participate in the labor force because of a lack of family-friendly policies in the workplace, such as paid family and medical leave. This is an issue that I care about deeply, and it was wonderful to hear Janet Yellen use her forum to bring this issue to the forefront of the conversation, to talk about it not as a women’s issue but as an economic issue confronting the U.S., and particularly as an issue that matters for economic growth. All too often this kind of thinking is glossed over or sidelined. But coming from her, I think it gave the issue prominence and salience. And I am grateful for that.

I’ve known Janet since 1975. She’s been special to me because of her humanity and her ability to rise above the rest.

In terms of female role models and mentors, she is clearly one: Laura Tyson was CEA Chair during the first Clinton administration, Janet followed her in the second Clinton administration, and Christina Romer was CEA Chair during the first Obama administration.

In the American Economic Association, we now have almost a full house of female officers. I was president in 2013–2014. Recent elections gave both vice president positions to women and several others on the executive committee. The major journal has had a female editor for a long time and we now have another. I can go on and on. The point is that young women do see many female economists in high positions—none as high as Janet, of course. Yet, my male colleagues are still tone deaf when it comes to putting together important panels at meetings (now called “manels” when there are no women) and they are insensitive in other ways.

Most academic female economists find themselves, early in their careers, with few women who can act as examples or role models. Growth in cohorts of women in the economics Ph.D. pipeline stalled about 15 years ago, and the share of women among full professors in the departments who train Ph.D.s just reached 14 percent this year.  (The Federal Reserve Board does better, and has been very active in recent years recruiting and promoting a more diverse set of researchers.) So of course, the first woman in a prominent and powerful position such as Fed chair has an important psychological impact on ambitious young women studying (or deciding to study) economics.  

The aspect of Yellen’s tenure that makes her a role model effect particularly powerful, I think, is the general acclaim of her performance—she has, with little drama, presided over what most commentators regard as an extremely successful term. She makes professionalism and competence seem like world-beating attributes—which, of course, they are. Hard-working young women find this extremely encouraging. It would be nice if the current publicity about Yellen’s term encouraged more undergraduate women to major in economics, but we’ll see.



Somewhat unintuitively, American corporations today enjoy many of the same rights as American citizens. Both, for instance, are entitled to the freedom of speech and the freedom of religion. How exactly did corporations come to be understood as “people” bestowed with the most fundamental constitutional rights? The answer can be found in a bizarre—even farcical—series of lawsuits over 130 years ago involving a lawyer who lied to the Supreme Court, an ethically challenged justice, and one of the most powerful corporations of the day.

That corporation was the Southern Pacific Railroad Company, owned by the robber baron Leland Stanford. In 1881, after California lawmakers imposed a special tax on railroad property, Southern Pacific pushed back, making the bold argument that the law was an act of unconstitutional discrimination under the Fourteenth Amendment. Adopted after the Civil War to protect the rights of the freed slaves, that amendment guarantees to every “person” the “equal protection of the laws.” Stanford’s railroad argued that it was a person too, reasoning that just as the Constitution prohibited discrimination on the basis of racial identity, so did it bar discrimination against Southern Pacific on the basis of its corporate identity.

The head lawyer representing Southern Pacific was a man named Roscoe Conkling. A leader of the Republican Party for more than a decade, Conkling had even been nominated to the Supreme Court twice. He begged off both times, the second time after the Senate had confirmed him. (He remains the last person to turn down a Supreme Court seat after winning confirmation). More than most lawyers, Conkling was seen by the justices as a peer.

It was a trust Conkling would betray. As he spoke before the Court on Southern Pacific’s behalf, Conkling recounted an astonishing tale. In the 1860s, when he was a young congressman, Conkling had served on the drafting committee that was responsible for writing the Fourteenth Amendment. Then the last member of the committee still living, Conkling told the justices that the drafters had changed the wording of the amendment, replacing “citizens” with “persons” in order to cover corporations too. Laws referring to “persons,” he said, have “by long and constant acceptance … been held to embrace artificial persons as well as natural persons.” Conkling buttressed his account with a surprising piece of evidence: a musty old journal he claimed was a previously unpublished record of the deliberations of the drafting committee.

Years later, historians would discover that Conkling’s journal was real but his story was a fraud. The journal was in fact a record of the congressional committee’s deliberations but, upon close examination, it offered no evidence that the drafters intended to protect corporations. It showed, in fact, that the language of the equal-protection clause was never changed from “citizen” to “person.” So far as anyone can tell, the rights of corporations were not raised in the public debates over the ratification of the Fourteenth Amendment or in any of the states’ ratifying conventions. And, prior to Conkling’s appearance on behalf of Southern Pacific, no member of the drafting committee had ever suggested that corporations were covered.

There’s reason to suspect Conkling’s deception was uncovered back in his time too. The justices held onto the case for three years without ever issuing a decision, until Southern Pacific unexpectedly settled the case. Then, shortly after, another case from Southern Pacific reached the Supreme Court, raising the exact same legal question. The company had the same team of lawyers, with the exception of Conkling. Tellingly, Southern Pacific’s lawyers omitted any mention of Conkling’s drafting history or his journal. Had those lawyers believed Conkling, it would have been malpractice to leave out his story.

When the Court issued its decision on this second case, the justices expressly declined to decide if corporations were people. The dispute could be, and was, resolved on other grounds, prompting an angry rebuke from one justice, Stephen J. Field, who castigated his colleagues for failing to address “the important constitutional questions involved.” “At the present day, nearly all great enterprises are conducted by corporations,” he wrote, and they deserved to know if they had equal rights too.

Rumored to carry a gun with him at all times, the colorful Field was the only sitting justice ever arrested—and the charge was murder. He was innocent, but nonetheless guilty of serious ethical violations in the Southern Pacific cases, at least by modern standards: A confidant of Leland Stanford, Field had advised the company on which lawyers to hire for this very series of cases and thus should have recused himself from them. He refused to—and, even worse, while the first case was pending, covertly shared internal memoranda of the justices with Southern Pacific’s legal team.

The rules of judicial ethics were not well developed in the Gilded Age, however, and the self-assured Field, who feared the forces of socialism, did not hesitate to weigh in. Taxing the property of railroads differently, he said, was like allowing deductions for property “owned by white men or by old men, and not deducted if owned by black men or young men.”

So, with Field on the Court, still more twists were yet to come. The Supreme Court’s opinions are officially published in volumes edited by an administrator called the reporter of decisions. By tradition, the reporter writes up a summary of the Court’s opinion and includes it at the beginning of the opinion. The reporter in the 1880s was J.C. Bancroft Davis, whose wildly inaccurate summary of the Southern Pacific case said that the Court had ruled that “corporations are persons within … the Fourteenth Amendment.” Whether his summary was an error or something more nefarious—Davis had once been the president of the Newburgh and New York Railway Company—will likely never be known.

Field nonetheless saw Davis’s erroneous summary as an opportunity. A few years later, in an opinion in an unrelated case, Field wrote that “corporations are persons within the meaning” of the Fourteenth Amendment. “It was so held in Santa Clara County v. Southern Pacific Railroad,” explained Field, who knew very well that the Court had done no such thing.

His gambit worked. In the following years, the case would be cited over and over by courts across the nation, including the Supreme Court, for deciding that corporations had rights under the Fourteenth Amendment.

Indeed, the faux precedent in the Southern Pacific case would go on to be used by a Supreme Court that in the early 20th century became famous for striking down numerous economic regulations, including federal child-labor laws, zoning laws, and wage-and-hour laws. Meanwhile, in cases like the notorious Plessy v. Ferguson (1896), those same justices refused to read the Constitution as protecting the rights of African Americans, the real intended beneficiaries of the Fourteenth Amendment. Between 1868, when the amendment was ratified, and 1912, the Supreme Court would rule on 28 cases involving the rights of African Americans and an astonishing 312 cases on the rights of corporations.

The day back in 1882 when the Supreme Court first heard Roscoe Conkling’s argument, the New-York Daily Tribune featured a story on the case with a headline that would turn out to be prophetic: “Civil Rights of Corporations.” Indeed, in a feat of deceitful legal alchemy, Southern Pacific and its wily legal team had, with the help of an audacious Supreme Court justice, set up the Fourteenth Amendment to be more of a bulwark for the rights of businesses than the rights of minorities.



First, there was Thanksgiving. Then, a few decades ago, Black Friday came along. Next came Cyber Monday, which debuted in the ‘00s. Then, a few years ago, came a day decidedly not about consumption: Giving Tuesday, a “global day of giving” that is celebrated (mostly on social media) the Tuesday after Thanksgiving. Allison Janney celebrates it. So do Bill Gates, Jill Biden, and a host of other other public figures.

Last year, charities big and small raised $180 million on Giving Tuesday, according to the 92nd Street Y, the organization behind the day. That’s  a significant increase from 2015’s $116 million. This year, as per projections from the nonprofit consultancy Whole Whale, that number will likely grow to more than $200 million. Charities and nonprofits in more than 100 countries will take part in the effort, and organizations that have used the day as an occasion to launch an end-of-year campaign have seen significant increases in donations on the season.

That’s not bad for a holiday that’s only been around since 2012. Giving Tuesday was initially conceived by Henry Timms, now the chief executive director of New York’s 92nd Street Y, in partnership with the United Nations Foundation. It was intended to counter the shopping frenzy that’s increasingly come to pass for the holiday spirit. “It originally followed Black Friday and Cyber Monday here in the United States, as a day to think about giving back after two days of consuming,” explains Asha Curran, the chief innovation officer and director of the Belfer Center for Innovation and Social Impact at the 92nd Street Y.

Giving Tuesday also takes advantage of a reality in the world of charitable giving: Just under 25 percent of all donations received annually will be given in the roughly five-week period between Thanksgiving and New Years, according to the Center for Philanthropy at Indiana University. For a not-unsubstantial 16 percent of organizations, giving in the final months of the year will account for half of contributions received.

There is another insight that drives the still nascent day as well: According to Curran, the most common reason people donate money to a charity is because a friend solicited them to do so. Giving Tuesday takes that idea and updates it for the age of social media: Organizations solicit bids with the hashtag #GivingTuesday and, in turn, those who donated are urged to share too. “People are taking peer-to-peer fundraising online and they are doing it in the form of saying, ‘I made this donation,’” Curran observed. “That’s a really powerful force for raising more money or attention or awareness for a cause.”

Giving Tuesday, in other words, takes the oft-derided concept of virtue signaling and puts it to good use. Of course, the Giving Tuesday campaign is hardly alone on this—a study published in Nature magazine in 2012 demonstrated that Facebook’s election-day “I Voted” feature increased voter turnout.

Nonetheless, Giving Tuesday’s importance shouldn’t be overstated. This year’s estimated $200 million charitable haul may sound significant, but it is tiny compared with the estimated $5 billion consumers spent on Black Friday, never mind the entire holiday season. And Giving Tuesday is not on its own significantly boosting overall charitable giving in the United States, which remains just a tick over two percent of the gross domestic product. It also can’t disguise the fact that many people are giving less to charity than in the past. When the Institute for Policy Studies, a left-leaning think tank, studied the issue, it discovered that while those with six-figure incomes and higher upped their charitable donations over the past decade, households with less money coming in cut their giving by about a third, something the researchers mainly attributed to “economic inequality and insecurity.”

However, in the longer run, it’s possible Giving Tuesday could help counter (but probably won’t reverse) these trends and raise overall giving. The majority of the day’s donations are made by “small-dollar” donors, as they are known in the philanthropic sector. According to the day’s backers, the mean donation made on Giving Tuesday in 2016 was for $107.69. “We are placing a particular investment in what we might call everyday givers,” Curran says.

And there is lots of room for growth. According to a Harris survey conducted shortly prior to 2016’s Giving Tuesday, three-quarters of Americans still don’t have a clue the day exists. But another poll, this one conducted by Ipsos shortly after last year’s Giving Tuesday event, found that 62 percent of those aware of the day say it inspired more giving.

That makes sense. Giving Tuesday offers people a way to feel a little less guilty about the stuff they’ve already bought and the stuff they plan to buy before year’s end. If charities can benefit from that, it’s most certainly a day worth celebrating.



At age 12, Philip Glass started working in a Baltimore record store owned by a man he called Ben. Ben was, in fact, Glass’s father, but he and his brother, Marty, both referred to him by his first name because they didn’t want anyone to know they were his children. Of course everyone still knew who they were.

Even before working in that small record store and spending countless evenings with Ben, learning to sort the good music from the bad, Glass knew he’d become a musician. He took flute lessons; his brother studied the piano. Now 81 years old, Glass is one of the most lauded composers of the 20th century. He has an honorary doctorate in music from his alma mater, the Juilliard School, and has won a National Medal of Arts, the Society of Composers and Lyricists’ Lifetime Achievement Award, and multiple Golden Globe and Academy Awards. I spoke with him about those early days in his father’s record store, the scariest moments from his time driving taxis in New York City to make ends meet, and how young people today should seek jobs that grant them independence.

This interview has been lightly edited for length and clarity.

Lolade Fadulu: You got into music because of your father, but did you ever consider becoming a librarian like your mother?

Philip Glass: My mother was a teacher and a librarian, and I definitely was not going to become a librarian. I knew these two people very well, my mother and father, and I had no interest in my mother’s friends at all. I was very interested in everything that my father did. That was just the way it turned out for me.

My mother, on the other hand, she encouraged my brother Marty, and Sheppie, my sister, so we all were given music lessons when we were young. That was considered part of our education. Isn’t that wonderful? I’m talking about the 1940s. If you were a young person, there might not be a program in the school that you went to, but my brother and sister had private music lessons, and I went to the Peabody Conservatory when I was, I think, 8 years old.

I wanted to have two instruments, but I was only allowed to have one because that was the budget that we had. So what I did is I would sit in on my brother’s lessons. He had a teacher that came to the house. The teacher would give him a lesson and would leave. And as soon as he left I went over and I played the lesson. My brother thought that I was teasing him, and he would chase me around the room. We were kids, really young. And he thought I was making fun of him. But I wasn’t. I just wanted to play the piano. He’d say, “Well, you have your own lessons. You don’t have to steal mine.” But I did have to steal his, actually.

We were very good friends. He passed away last year. But, you know, he was in his 80s. I’m into my 80s. So he had a wonderful life of his own. He wasn’t a musician.

Fadulu: You were interested in everything your father did. What did he do?

Glass: He had a small record shop in downtown Baltimore. Now, you have to remember in the 1940s we didn’t have big Virgin Megastores or Sam Goody record shops. We didn’t have a music store like that. It was like a mom-and-pop candy store. In the back of the store he fixed radios, and in the front of the store he sold records.

He himself was not a musician, but he loved music, and he would bring music home to listen to. If he didn’t sell a record he would try to find out what was wrong with the music and he would take it home and listen to it. And I was listening. I was his listening partner. The things he’d listen to were mostly modern music that people didn’t like, and we both ended up liking all of this modern music. He became an expert on modern music. I’m talking about modern music of the ’40s, so that’s people like Bartók and Hindemith and people like that.

In the record store we had all kinds of music. We had country and western music, we had jazz music, we had band music, we had marching-band music, we had classical music, we had operas. But there were only two categories, really. That was good music and bad music. That’s the only thing he recognized. He would encourage people to buy the pieces that he liked.

My brother and I spent all our weekends and the holidays at the record store starting from the age of 12. So he introduced me to a lot of music, my father did. He passed away in the 1970s. I dedicated my first violin concerto to him because I thought he would have liked if he had lived to hear it, and so I always felt that violin concerto was written for him.

Fadulu: Did you work in your dad’s record store at all?

Glass: Oh, yes. Oh yes, yes, yes, yes. From the age of 12. It wasn’t considered child labor. It was a family business. At the beginning, all my brother and I did were the inventories, and we moved the records around. But we eventually got to know the business pretty well.

To this day, among my earliest memories was someone would give my father $5 and he’d hand them a record. So the exchange of money for art, I thought that was normal. I thought that’s what everybody did. I never thought there was anything wrong about making money.

Fadulu: Did your dad expect you to take over the store at some point?

Glass: No, he never expected that. He loved the store himself.

It was just a small store but he eventually got a partner who had a radio program on the Baltimore stations. And suddenly his record store began. I remember coming and seeing him one time when I came back from school, and I said, “Ben.” (We always called our father by his first name because my brother and I didn’t want people to think that we were working for our father.) And I said, “Ben, you’re really doing well here now.” I was about 18. And he said, “Yeah.” He said, “Store’s going good.” “Well,” I said, “all of those years of hard work paid off.” And he said, “Nope. Just got lucky.” He was that kind of a guy.

Fadulu: Did you have any doubts about becoming a musician?

Glass: I always knew I was going to do music, so I had no doubts about it at all.

The only issue was how I was going to get a music education in Baltimore. Well, I was lucky, again, because the Peabody Conservatory was quite a good music school. I went away to college when I was quite young, and I went to the University of Chicago. In those days you could enter the university if you passed the entrance exam. I told my advisor I wanted to take the entrance exam for Chicago, and he thought that was a funny idea. Everyone thought it was funny. But me, I was pretty serious. I took the test and I passed it, to everyone’s surprise.

At the same time Chicago was the center for the jazz movement, especially for the bebop players and people like Charlie Parker and Charles Mingus and Bud Powell. They were regular players in Chicago, and I got to hear them, too. I was a little too young to go into the bars. They didn’t let me go in the bars, but there was a bar on 57th Street on the South Side of Chicago. And I would stand outside listening to the music, and finally the guy at the door said, “Hey, kid, come on. You can come and sit here. Sit here for listening, but you can’t drink anything. Just sit here and you can listen.” I used to go down there and listen to jazz.

Fadulu: While you were really getting started, you worked as a plumber and as a taxi driver, and also as part of a moving company. Why did you work those jobs?

Glass: I had an ensemble at the time. I would go out and play for three weeks. We would come back from the tour, and we usually had lost money so I had to make money immediately. I put an ad in the paper. My cousin and I ran the company, and I moved furniture for about three or four or five weeks. Then I went on tour again. Again, we lost money.

That went on for years. I thought it was going to go on for the rest of my life, actually. It never occurred to me that I would be able to make a living, really, from writing music. That happened kind of by accident.

I was interested in jobs that were part-time, where I had a lot of independence, where I could work when I wanted to. I wasn’t interested in working in an office where everything would be very regimented.

About that time—I’m talking about the early ’70s—the part of New York called SoHo now, it was mostly buildings that housed factories that made clothing. But about this time, artists were buying spaces in that area, and my cousin and I began to help build. We were putting in heating systems and putting in kitchens and bathrooms. We learned how to do that. We would put an ad in the paper, and we’d get to your house, and we’d do it. When it was time to go back on tour, I just closed up for about three weeks and [would] come back and go to work again for two or three months sometimes.

Also, at that time, I was a composer in residence at the La MaMa theater on East Fourth Street, so I was also writing music for plays, and I had my ensemble. I was starting to become a professional composer. I had been out of Juilliard by that time. And eventually, by the time I was 41, 42, I was actually making a living playing music.

I was surprised it happened so quickly, actually. I expected to have a day job for the rest of my life.

Fadulu: I feel like composers are viewed a lot differently than plumbers and taxi drivers.

Glass: Let me tell you something. If you’re in New York City, you might hail a cab. There’s a good chance that the driver would be an actor or a performer. A lot of day jobs around New York are picked up by people in the arts. It was very common to find that the waiter at the coffee shop you went to was having a concert later in the week and you would be invited to come to the concert. So my experience was quite different from what you’re describing. A lot of people in theater, in dance, in filmmaking and music performance, we all had day jobs. And eventually if you were lucky you spent more time doing your art than making a living.

Fadulu: Did you like driving taxis?

Glass: I loved it, actually.

I would pick up a car, usually around 5 o’clock in the afternoon, and I would drive till one or two in the morning, and I would get up early in the morning, actually to take my kids to school, because I had kids growing up in New York at the time. And sometimes I would stay up all through the night, write music, then take the kids to school. Then I would go to sleep around 8 or 9 o’clock and I would wake up around 4 o’clock and go back to the garage or wherever I was going. So I could combine a workday and a regular writing schedule at the same time.

It was very scary at times. Robberies could happen. Unpleasant things can happen when you pick up people off the street, which is what taxi drivers do all the time. It wasn’t so great in one way, but I got to know the city. I knew my way around the Bronx, my way around Brooklyn. And I could listen to music on the radio. There was always a good music station to listen to.

I liked the independence of having a car in New York and just driving around. It could get tiresome, especially on the holidays when there could be very long workdays. But I didn’t want to be in a place where there was a boss telling me what to do.

Fadulu: What were some of the scariest times?

Glass: I remember a couple of guys get in the car laughing their heads off, and they’re throwing money around. They just robbed a store, right?

Now they’re in the back of my car. I said, “Where are you going?” They said, “We’re going to Bed-Stuy.” Well, at that time it was one of the most hardcore places in New York for people out of work and looking for money and this and that. These guys had just robbed a store and looked to me like they were just about to rob me, too.

If I was lucky I could get rid of them somehow. Sometimes a police car would follow us for a while and they’d pull me over and take a look at the guys in the car and say, “What are you doing with these guys?” Well, you know, as a cab driver you’re supposed to pick up anybody. You have to. And I said, “Look, I just want to get out of here.” And the cop car would follow me until I let them off.

I could tell you a lot of very scary stories. But mostly, evenings were pretty quiet, just picking up people. Sometimes they had drunk too much and you’d have difficulties of that kind, and then they forgot where they lived or they got sick in the car. It’s not a violence-free environment, to be driving a cab in New York at night. I was glad when it was over.

I was commissioned to write Satyagraha, an opera about Gandhi, and the opera company paid me. So I didn’t go back to work for four or five months, and then after that I had another job. About a year later I realized I hadn’t driven a cab in a year. I renewed my cab license for another year or so, but I never had to drive again. By that time I was 42 years old. And that was 40 years ago, so that’s a long time ago.

Fadulu: Was there anything that you learned while you were driving that was helpful for composing?

Glass: I learned a lot. I listened to music on the radio. There were a few good music stations.

In those days you could work three days a week, maybe four sometimes, and you could live on that. It was the quickest and easiest way to make an honest living. I thought it was a pretty good deal. I didn’t have to teach any classes anywhere. I just drove the car and I got paid. I liked that. I had my independence, which was very important to me. But also, it didn’t take much time.

But, look, the thing to remember is that life was financially much easier. Actually, for the young people trying to make a living today, part-time, it’s almost impossible.

People work six days a week. No one can work three days a week. It’s just gotten to be more expensive, the rents are higher, there are more people around trying to do exactly what you’re trying to do. When people ask me how I did it, I say to the young people, “Look, I have to tell you. It was much easier when I did it.” I said, “It’s hard right now.” But people are still coming to the city, to the big cities where you have concert halls and museums and galleries. There’s a lot of part-time work. There are all kinds of things that you can do.

I went to school for a long time. I finished my studies when I was 28. Was probably much too late. But no one ever asked to see my diplomas. Never. When I got a job writing music no one said, “Can I see your diploma first?” That never happened. It makes you laugh when you think about it. There’s a lot to be learned at school, but it doesn’t give you a passport to making a living at all.

Fadulu: Do you think people should still follow those passions, especially if they’re in the arts?

Glass: When I do concerts I often give talks to students. They get them together, and I talk to them in the afternoon, and we talk about music. Not too long ago one young fellow, he said, “Tell me one thing that I can take away from this talk that I’ll remember and that’s important.” And I said, “No, I’ll give you one word.” He said, “What’s that?” I said, “Independence.”

Fadulu: Yeah, you have said that a lot. Why was having your independence when it came to work so important?

Glass: Well, it meant that I controlled how I spent my time. Being a young dancer, a young painter, a tremendous amount of dedication and work goes into developing the skills to accomplish the artistic goals that you set for yourself. I’ve had friends who’ve gone to law school, and one of them will go and complain about how hard they worked, and I just laugh at them. None of them would consider practicing six or eight hours a day, but that’s quite normal for dancers or musicians or painters. Our workdays tend to be more like eight to 10 hours a day, and we don’t take weekends off, and very few people take off holidays. It’s a very work-intensive environment. But the freedom of working that way seems to be preferable.



When Cristina Jiménez was 13 years old, her family moved to the United States from Ecuador. Three years later, her peers started getting jobs at the mall. But Jiménez was undocumented; that was not an option for her. She opted instead to babysit and work as a “helper” to a social worker in her apartment building.

I recently talked with Jiménez, who is now the cofounder and president of United We Dream—a nonprofit that organizes immigrant-youth-led activism—and, at 33, the youngest of the MacArthur Fellows named last year. Immigration has been a hot-button issue during the Trump Administration; the president decided last September to end the Deferred Action for Childhood Arrivals program, which granted legal status to undocumented immigrants brought to the United States as children, and Congress has not passed the hoped-for Dream Act legislation to reestablish legal status for so-called Dreamers. Jiménez and I spoke about her own immigration status, her parents’ career aspirations for her, and what happens when the boundaries between work and life blur. This interview has been lightly edited for length and clarity.

Lolade Fadulu: I know that part of the reason your family moved to the United States was so that you and your brother would have access to a better education. I'm curious about your parents’ educational background and what their jobs were.

Cristina Jiménez: In Ecuador, both of my parents just reached high school in terms of their education. My dad grew up homeless, and so college wasn’t really a possibility for him, just based on all of the challenges that he faced while growing up. He started working at a car-manufacturing factory in Ecuador, became a union organizer when he was there, and then he went on to work for security at one of the largest banks in the country.

And then my mother grew up in a household where—I mean, it’s just not out of the ordinary for the culture and the social norms of the time—but in her family, they didn’t believe in investments in education for the women in the family. So, all her brothers were sent to school, college, and/or the military. All the women were encouraged, after high school, to do vocational jobs. So most of my aunts including my mom became seamstresses and hairdressers. My mom worked in those two areas for a long time, but after she had me in her 30s, she stopped working outside of the house and her full-time job was being a mom and a homemaker.

In terms of their jobs (once we moved to Queens, New York), my dad, when he was younger, was predominantly in the construction industry. As men get older in the construction business, they’re actually encouraged to leave the job; they push them out, basically. And so my dad was pushed out of his job once he was in his early 50s. And since then, he’s been working in a parking garage in Manhattan, parking cars, making much lower pay than in the construction job that he held for many years.

My mother, in the United States, fluctuated between being a domestic worker for families, cleaning homes, to working at a nail salon for a while. And now she’s a babysitter. She’s fluctuated between those three different jobs throughout the over 20 years that we’ve been here.

Fadulu: Your mother’s parents had different expectations for men and women. Did those ideas travel down to how your parents viewed what you and your brother would do career-wise?

Jiménez: My mom has had these dreams of achieving, almost through her children, what she was denied—which is an education. So for us, for both my brother and I, she’s been the main supporter, always encouraging us in school and ensuring that we were good students, as well as pursuing college.

When I was growing up undocumented, my family struggled a lot to pay for school because I didn’t have financial aid or support to go to school. It was a family effort to pay for college. My mom, myself working, and my dad—all of us pitching in for my tuition. And my brother’s in college right now.

Fadulu: Was that your first job, while you were working in college to pay for tuition?

Jiménez: Well, I had two different jobs when I started working for the first time, and that was here in the United States. I was babysitting a family, the pal of family friends here in the United States. I was doing this right after I turned 16, mainly during the summer. Also, there was a social worker in my building, one of our neighbors, who used to work for the government. She needed someone that could take notes for her but also carry her computer and her bags of papers and documents and materials that she would take to families. I was kind of her assistant. I used to go with her and do all of these visits, a lot in New York City, in particular to poor communities in the Bronx and Manhattan and Queens and Brooklyn, and I would just carry her stuff, her computer bag, her bags, a lot of documents and her lunch.

Fadulu: And she worked for the government?

Jiménez: Yeah. I just know that she was a social worker, she worked for a government agency. She would give me, like, $20 for the day, or something like that.

Fadulu: I see. And so you weren’t really thinking at all about your undocumented status while you were working for this woman who worked for the government or—

Jiménez: Well, I kind of felt that it wasn’t a job in that I wasn’t clocking in and out. I was her helper, and I was getting some pay for it. Certainly, I knew I couldn’t work because of my status, which presented a huge, huge challenge.

Fadulu: How did you find out that you couldn’t officially work due to your status?

Jiménez: I just think [being undocumented] becomes more real once you become eligible to work, in terms of age, and some of your friends in high school are working or trying to land a job at the mall, and you just can’t, which is where I really felt it. And also because I wanted to figure out ways in which I could go to college. I realized that I couldn’t get any support, which was a surprise for me. I wasn’t aware fully of the implications of my undocumented status in terms of college access.

Fadulu: When you started college, did you know you were going to get involved in activism?

Jiménez: No, it wasn’t, like, a career choice. I didn’t know that that could be a career, anyway, at the time. But I really started organizing for immigrant rights and access to higher education because of survival—because many other people that I met at the time couldn’t go to college. And I felt a deep sense of injustice about that. And so I just started to get engaged. I found community groups that were working on these issues, and I plugged in.

Fadulu: How did your parents feel when they saw that you were getting involved in activism?

Jiménez: I mean, at the beginning, they didn’t understand it. But because my dad was a union organizer in Ecuador, when I took them to one of the rallies, it clicked for him. They didn’t get it until they were exposed to it. But once they did, they were really supportive about it. Their dream has also always been that I go to law school. I haven’t gone to law school, but they just seem to be really supportive of my work.

I also think that, sometimes, particularly as I have gotten more visibility, they have gotten more worried about what could happen to me. We come from countries where people that do this kind of work get killed.

Fadulu: In my school, there were some student activists who were really gung-ho about causes while they were in college but then once they graduated, they went off, for a variety of reasons, into investment banking or something. Can you talk more about why you made the decision to stay in it?

Jiménez: As I got to meet more people like me, young people and their families really gave me a larger motivation to do this work. For many years, we didn’t see a lot of progress. I remember advocating for the Dream Act in the early 2000s, and we are in 2018, and we haven’t passed the Dream Act yet. And we were able to see programs like DACA, but DACA was terminated.

Fadulu: A lot of people talk about the whole work-life-balance idea. And it sounds like this is just life for you. It doesn’t necessarily feel like work or a career for you.

Jiménez: I do feel like this is my calling in life, and even though the undocumented experience has been very difficult and it has created a lot of trauma for me and my family, like for everyone in our communities, in many ways I’m grateful for the experience of being undocumented because it really led me to find my purpose in life.

I think of myself when I was really fearful and ashamed of my status and I wouldn’t talk to anyone about it. And then I moved from this place of shame and fear to feeling empowered. And now I’m part of creating that experience for other young people and their families.

In terms of work-life balance, I think that all of us have struggled with it. Especially for folks like me, who are deeply into this work, and it’s so much about your life and your right to exist. And so for me, what’s been really helpful is to be really aware that if I want to continue to do this work and be good at it and give back good energy to people that I work with, I have to make sure that I rest and that I take care of my health.

Fadulu: What advice do you have for young people today who are now in the position that you were in when you were growing up?

Jiménez: I think my biggest advice is don’t let anyone tell you “no.” And believe in your potential and believe that you are worth it. My college advisor [in high school] told me that she was not going to help me apply for college, that I couldn’t go to college because I was undocumented. And if I had listened to her, if I had believed her, if I had not pushed back against that and sought out other people to help me, I don’t know what would have become of me. I am really thankful to my mom and her courage. She pushed me to really go back to school and find people that could help me.

And I was able to find a way. Educators and other people in power in different institutions have so much influence, often. And sometimes not in constructive ways, for young people in particular.



On Tuesday night, a visit to the website of the Ivanka Trump brand turned up a sharply cut floral dress and a pair of suede sandals on broad, three-inch heels. “Bring on the heat” unspooled in elegant italics across the site’s landing page. By then, the message had acquired an awkward dual meaning. Earlier in the day, Ivanka Trump had acknowledged that she would be closing her apparel-and-accessories business, IT Collection, and laying off its employees. Trump publicly blamed her hectic schedule as an adviser to her father, President Donald Trump: “After 17 months in Washington, I do not know when or if I will ever return to the business,” she said, “but I do know that my focus for the foreseeable future will be the work I am doing here in Washington.” But the closure also comes at the end of an undeniably bad run for the fashion line, during which Nordstrom and other retailers stopped selling it, citing poor performance. In the end, it seemed, Ivanka Trump could not handle the heat.

Every Trump needs a personal brand, and, for the longest time, Ivanka’s has been as the Platonic ideal of the modern working woman—one who, through sheer determination, will have it all. She has been known to post photos to Instagram in which she poses in elegant evening wear, clearly about to depart for a night out, while one or another of her children frolic at her feet wearing pajamas; her Twitter profile advertises that she identifies as a “wife, mother, sister, daughter” as well as an “advisor to POTUS.” Shortly after Trump introduced her fashion brand, in 2014, she launched a hashtag campaign, #WomenWhoWork, organized around “content that inspires and empowers women to create the multidimensional lives they want to live.” Her 2017 book is called Women Who Work: Rewriting the Rules for Success. In it, Trump writes that when she engaged New York ad agencies to refine her brand’s message, the admen cautioned her against overdoing the language around working, what with its associations with “professional tedium.”

One sees the admen’s point. Trump’s message—online, in person, in her books—is one of constant, indefatigable self-improvement: “We’re training for marathons and learning to code. We’re planning adventures with our kids and weekend getaways with our friends,” she writes in her book. Whatever one thinks of this approach to life—we are, are we?—Trump has been an exemplar of it. There’s nothing wrong with being good at multitasking, except when one of your tasks is to profit from a Trump-branded business, and another is to help run a Trump-branded White House. Trump made her first high-profile faux pas as the president’s daughter days after Donald Trump won the election, in November 2016, when she appeared on 60 Minutes wearing a $10,800 gold-and-diamond bangle from her own jewelry line, and, a day later, her brand’s marketing department sent an email blast publicizing the bracelet’s cameo.

Abigail Klem, the president of the Ivanka Trump brand, blamed a “well-intentioned marketing employee.” Trump’s company issued an apology, and then, soon after, got caught up in another series of ethical mishaps. A hashtag campaign called #GrabYourWallet had been urging people to boycott retailers that sold Trump family–connected goods. People particularly targeted Nordstrom for stocking the Ivanka Trump brand, and by February 2017, Nordstrom had dropped the line, a decision it described as being “based on the brand’s performance.” Soon, President Trump was tweeting that Nordstrom had treated his daughter “so unfairly,” and his adviser Kellyanne Conway was telling viewers of Fox News to “go buy Ivanka’s stuff,” adding, “I’m going to give a free commercial here: Go buy it today, everybody; you can find it online.” To avoid the appearance of a conflict of interest, Ivanka Trump had earlier handed day-to-day control of her brand to Klem and in March 2017 transferred its assets to a trust, but, according to The Wall Street Journal, she still received certain financial information and a share of the company’s profits. Now, with the closure of her company, Ivanka Trump’s working-woman brand has been further fractured.

All this comes at a moment when the line between politics and culture, if there ever was one, has utterly vanished. Corporations have demonstrated that they are susceptible to hashtag campaigns and public outcry. Ordinary people continue to leverage this fact to get attention for the causes that stir them, and the fallout is often swift. See also: ABC’s cancellation of Roseanne Barr’s  TV show due to a racist tweet she posted about a former Obama adviser, and the departures of Elon Musk, the CEO of Tesla, and Kenneth C. Frazier, the CEO of Merck, from Donald Trump’s business councils, in response, respectively, to the president’s withdrawal from the Paris climate-change agreement and his lukewarm response to the violent white-supremacist rally in Charlottesville.

Ivanka Trump, of course, could never have distanced herself from the Trump administration the way these other businesspeople did, as she’s an active participant in it. Instead, the slow fallout of #GrabYourWallet-style activism appears to have forced her hand. The Journal reported that Trump had closed her brand because she had grown “frustrated” by the restrictions she had been forced to impose to avoid the appearance of a conflict of interest. If that’s one factor, though, it’s likely not the only one. Rakuten Intelligence, a research firm that tracks online sales, estimates that sales of the Ivanka Trump brand, on the websites for Amazon, Macy’s, Bloomingdale’s and others, fell 27 percent in the year ending June 2017, compared with the previous year. In the year ending June 2018, they fell another 55 percent. A spokeswoman for Rakuten said that while the data is somewhat limited—it is based on a sample of thousands of customer receipts, and covers only online sales on certain sites—it likely tracks with overall sales trends for the brand. It would seem that the death of the fashion line represents, at least in part, Trump’s decision as a businesswoman to maximize profit and minimize losses, within the political constraints inherent in being a Trump. In this, at least, she remains as on brand as ever.



Four people in need of work went to the first meeting and gave the man money, but Racida Eslabon was the only one who made it to the United States. She had already worked in a factory in Japan, and when she got back to the Philippines, she wanted to leave again so she could send money home to her mother, who was sick. She had been trying to get a job through a placement agency but with no success, so it seemed like very good luck when she met Alfred Briones in June 2008.

Eslabon’s decision to pursue a job through Briones, made in desperation in the Philippines 10 years ago, began a chain of events that left her trapped in fear and debt. She was eventually able to escape and obtain a T visa, a type of visa reserved for trafficking victims who have cooperated with law-enforcement investigations and would face extreme hardship if removed from the U.S. An applicant must submit evidence that she meets these requirements, typically including a declaration from federal law enforcement or government officials that she has faced trafficking and been helpful to law enforcement. In Eslabon’s case, the Department of Labor’s Wage and Hour Division provided Eslabon with a certification, based on its investigation of her experience and conversations with her. The details in this account are drawn largely from this certification, as well as The Atlantic’s interviews with Eslabon.

Briones worked for a placement agency in the Philippines bringing workers to the United States though a U.S. counterpart, Coastal Ventures, in Destin, Florida. Briones told Eslabon he could get her a job working as a housekeeper in Miramar, Florida, according to Eslabon—all she had to do was pay him about $600 to $700 within a week’s time to get the visa interview at the U.S. Embassy. And she had to decide quickly; otherwise, he said, he would offer the job to someone else.

To Eslabon, the job—a cleaner at a hotel—seemed worth the risk. According to the contract she received, it promised 40 hours a week at $7.50 an hour, plus $11.25 for overtime, though she would have to pay $75 dollars a week for the home she would share with other female Filipina workers, $7 dollars for utilities, and $15 for transportation to and from work. After this initial payment, her visa would be renewed at no extra cost every six months. She hurried to get the papers and the money together to meet Briones at a mall in Quezon City in the Philippines.

Eslabon’s story is illustrative of a hole in America’s labor protections—a hole into which desperate foreign workers can fall. Originally, Racida Eslabon entered the United States in 2008 on an H-2B visa, a temporary work visa to the United States. The visa is tied to a single employer (Eslabon’s visa reads “Holiday Inn DBW Coastal Ventures”), though many of these employers aren’t employers so much as recruiters, bringing workers to the United States for temporary low-skill jobs at other companies. In today’s fragmented, contractor-heavy economy, many hotels, restaurants, and other facilities no longer directly employ their workers. This employment arrangement may seem strange, but “it is very common for hotels in the U.S. to contract with labor recruiters in the Philippines (and other countries like Jamaica) to recruit temporary seasonal workers on H-2B visas,” said Laura Berger, formerly of the City Bar Justice Center, a New York–based pro bono legal organization that represented Eslabon in her immigration case. This leads to situations like Eslabon’s, in which no one takes responsibility for the imported workers and they often face exploitative work conditions.

Eslabon is not unique in having placed her faith in a recruiter. According to a report from Polaris, an anti-trafficking organization, “Foreign nationals who have paid large recruitment and travel fees to labor recruiters often become highly indebted.” Because of this debt, traffickers can maintain control and manipulate victims by leveraging the fact that the visa is tied to the job. Nearly every single victim of labor trafficking and labor exploitation that the organization identified involved a recruitment operation like the one that brought Eslabon to the U.S. In another report, Polaris found 124 trafficking cases and 510 labor-exploitation cases in the hospitality sector between 2014 and 2015. Eighty-one percent of the trafficking cases involved foreign workers. Additionally, because victims lack knowledge about where they are, their rights, and language fluency, they are often unable to easily extricate themselves from the situations the recruiters have placed them in.

The first sign for Eslabon that something was wrong was that Briones always seemed to want more money. First, an extra $200, because she needed another document because she’d be working at a hotel, according to Eslabon and the DOL certification. When Eslabon passed the interview in August of 2008 and was approved for an H-2B visa through Coastal Ventures, he asked for another $7,500. This was an impossible sum. But she had already booked her flights and was ready to go, so she asked her uncle if she could borrow the money. She put up a property as collateral and borrowed money from someone else, according to the DOL certification. The loan had an interest rate of 25 percent, Eslabon said, and she is still paying it off.

When Eslabon arrived in Florida, nothing was as she thought it would be. Coastal Ventures Management told Eslabon that she had to pay another $250 dollars as a deposit for housing, according to Eslabon and the DOL certification. (Multiple efforts to reach Coastal Ventures representatives for comment went unanswered. And despite providing Eslabon with a certification for immigration purposes, the DOL has not pursued any enforcement action against Coastal Ventures, according to Eslabon’s attorney. Coastal Ventures has since dissolved its LLC.)

She felt she had no choice but to give him the money, even though, she told me, “this is the only money I had since I left the Philippines and I had not eaten yet.” She got to the apartment and was horrified to find that instead of other women, as she was promised, there were no Filipinos who spoke her language, and there were men, with multiple people to a room, and only one bathroom for the six residents, she told me. “I cannot do this,” she said to me. “It is not our culture and not appropriate.” And the home had no cookware, no bed, no internet, no phone. “When I read the contract,” she told me, “you dream in the U.S. you are going to live in a home.” But this was not a home, though it was expensive. At $75 per person per week, not to mention utilities and transportation fees, Coastal Ventures was likely making money off of their employees. Suzanne Tomatore, the co-director of the Immigrant Justice Projects at the City Bar Justice Center, said this is a common strategy: “A contractor will charge well above market rate, putting up six people in a two bedroom and charging everyone.” The employees are told they have to live in that particular apartment.

Life in the apartment also came with rules. The employees had a 10 p.m. curfew. At night, representatives from Coastal Ventures would come and check to make sure the tenants were at home. They told her if she broke curfew or any of the house rules, she would get a letter, and after three letters she’d be sent home, according to the DOL certification. They told her she couldn’t leave the state without permission, she said. When she did leave later on to visit a friend, without permission, the agency called her multiple times to warn her not to say anything about her work, she said. When she asked to move later, she told me they insisted she still pay them the transportation fee even though she wasn’t using the shuttle they offered to and from the house. “One thing that I thought distinguished Racida’s case was the scrutiny that her employers put her through—even checking in every night to make sure she and the other employees were in the apartment by 10 p.m.,” said Berger. “But the threats, poor living conditions, low pay, and false promises made by the original recruiter are pretty standard in these cases of Filipino clients with H-2B visas.”

In May 2008, right before Eslabon met Briones, PhilStar, a Filipino news outlet, reported that the National Bureau of Investigation (NBI), a government agency in the Philippines responsible for high-profile crimes, had arrested a colleague of Briones. The reporter called the colleague a “female large-scale swindler who has victimized more than a dozen applicants looking for jobs in the United States.” According to the article, the applicants “had paid more than P6 million [over $100,000] as fees.” The article makes reference to Briones, the human-resources manager for the company that had allegedly committed these crimes, but says that according to the NBI, Briones was not charged, investigated, or arrested. The NBI did not respond to request for comment on the case. Attempts to locate and contact Briones were unsuccessful.

The morning after Eslabon moved in September 2008, she started work at Marriott’s Courtyard Sandestin at Grand Boulevard, in Miramar Beach. There were about 50 other H-2B workers there, according to the certification. Although her contract promised 40-hour weeks, it was September, low season in Florida, and the hotel could only offer few hours, sometimes as few as 10. One week she only worked one day, according to the DOL certification. “Florida is seasonal,” Eslabon said. “So you cannot blame the hotel. They try to give us more hours but they don’t have customers, so what we are going to do?” When she asked for more work, she said the agency told her she was “talking too much,” because they were supposed to handle all communications with the hotel, she said. No matter the hours, she still had to pay the agency the same fees for rent, transportation, and utilities, which could total as much as $147 per week, according to a paycheck from the agency. The paycheck, dated September 24, 2008, shows Eslabon earning a net pay of $53.64 after these deductions, below minimum wage. The company also charged her $500 dollars for renewing her visa every six months, according to the DOL certification. Hungry, she ate food off discarded room-service plates, also according to the DOL certification. Once, she says, she remembers being in a drugstore and needing medication and crying, until someone took pity and purchased the medicine for her. Worst of all, she said, “I couldn’t send money to my mom. I didn’t know what excuses I was going to tell them.” She told her family nothing about what was happening to her here, not wanting to worry them.

When I asked Marriott specifically about this case, it replied, “We don’t have any information related to the incident you’ve referenced, so we aren’t able to verify whether it is true or accurate,” through a press representative, Barbara Delollis. There are structural reasons that hotels, for their part, turn to companies like Coastal Ventures for workers. “There are a variety of arrangements companies make these days as they outsource different functions for very legitimate business reasons,” said Michael Lotito, co-chair of the Workplace Policy Institute at the management-side labor law firm Littler Mendelson. Lotito, who cautioned he was not speaking about a specific company or situation, explained that “in the hospitality industry it is not unusual” for a company to look for temporary workers through a recruiter, especially as “occupancy swings from 50 percent to 100 percent.”

This dynamic exposes chains like Marriott to labor markets in which workers are much more likely to have been trafficked or otherwise abused. Delollis stressed that as of this year Marriott employees were required to undergo training that teaches the signs of human trafficking. “The protocol is to have employees ‘see something, say something,’ and to report information directly to management, who will assess the situation and work with relevant parties, including law enforcement as necessary.” She said that two employees reported human trafficking within three months of the training. She also said that the brand has been working to combat this issue since 2006.

I reached out to the American Hotel and Lodging Association, an industry group, to ask about combatting this problem on a larger scale. “We do not have any comment at this time,” they told me through a press representative.

Berger, Eslabon’s lawyer, says that relationships between subcontracted employees and employers are prone to abuse, and that employers often do not scrutinize how the subcontracted employees are treated. “I think that subcontracting for labor is a direct contribution to labor exploitation and trafficking because the most important thing for the contractor is the price,” she argues. Often, subcontractors offer low prices to hotels, and can do this because they pay low wages and charge fees to employees. And while Berger says that this is because many hotels fail to do “due diligence,” there is also little federal or state oversight.

The Fair Labor Standards Act, which governs minimum wage and overtime, was created in 1938. “Unless you have been living under a rock you know the workforce has changed dramatically,” Lotito said. In 2015 and 2016, in order to address these changes to the economy, David Weil, the Department of Labor wage-and-hour administrator at the time, issued new guidance for the concept of “joint employment,” which would classify contract employees as employees, making both the subcontractor and the employer responsible for the contract employee. Labor advocates saw this as a move in the right direction; industry groups and proponents of smaller government saw it as an overstep for an executive agency, and a step backwards in terms of allowing companies to set their own hiring practices without fear of lawsuits. Secretary of Labor Alexander Acosta overturned these guidelines in June, but nothing has come in their place. “Under Acosta that guidance is being revoked, but there is no substitution for the guidance,” said Lotito. In December, the Republican-controlled National Labor Relations Board (NLRB) voted to overturn a similar Obama-era ruling, which held companies responsible for illegal activities committed by their subcontractors. That reversal, however, was itself reversed in late February because of a board member’s recently uncovered conflict of interest. That leaves the issue open to possible congressional action.

In 2011, the DOL issued two denials of applications for more H-2B workers for Coastal Ventures. One was a 2010 request for applications for 70 maids and housekeepers for a Hilton in Sandestin, and the other a request in the same year for 50 workers for a Marriott in Panama City Beach. Both denials were related to a new (at the time) federal ruling that required Coastal Ventures to also submit paperwork from the employer (the hotels) as part of the applications.

Eslabon saw no way out. Every time she tried to pick up supplemental work, Eslabon says, Coastal Ventures threatened to deport her. Finally, in 2010, Coastal Ventures said that she couldn’t renew her visa, and in 2011 said she had to leave and come back in order to work, Eslabon says. But she was scared to fly without a visa. She finally escaped with the help of a friend to a job in Virginia, where she stayed for three years. She then moved to Queens, New York. The whole time, she says, she believed that Coastal Ventures was still looking for her: She felt she had to change her phone number, and she was terrified because she was here illegally, didn’t know what to do, and didn’t trust anyone. During that time, she said, “my heart [was] empty.” But in New York, she connected with an organization, Safe Horizon, which referred her to a lawyer who could help.

When Eslabon agreed to speak with me this winter, she wanted to make sure the interview wasn’t for television. Eslabon said she didn’t want her mother to see her, because she never told her she had been trafficked. She did call her mother, however, after her T visa petition was finally granted last year, allowing her to stay in the United States. “It was a blessing for me,” she said.

This project is supported by Dignity Health Foundation and Silicon Valley Community Foundation.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?



ATLANTA—It was not until a few years after he moved in that Zachary Anderson realized that he was not, in fact, the owner of the house he thought he’d purchased. Anderson had already spent tens of thousands of dollars repairing a hole in the roof, replacing a cracked sidewalk, and fixing the ceilings of the small two-bedroom home where he lives in southwest Atlanta. He was trying to get a reduction in his property taxes when his brother, who was helping him with his taxes, looked up the property in public records and found that the owner of the home was actually listed as Harbour Portfolio VII LP.

“It’s like a trick,” Anderson, a 57-year-old, told me, sitting in front of a wood-burning fireplace he’d installed in the living room of the house to lower his heating bills. “They get free work out of a lot of people.” Anderson had entered into a contract for deed, a type of transaction that was rampant in the 1950s and 1960s before African Americans had access to avenues of conventional lending. In a contract for deed, the buyer purchases an agreement for the deed rather than buying the deed itself. The tenant has to fulfill the conditions of the agreement in order to get the deed, conditions that usually include making a series of timely payments over decades, paying for home repairs and general maintenance of the home, and paying taxes and insurance on the property. If he misses one payment, thus violating the agreement, he can be evicted, losing all the equity he put into the home.

Though half a century ago, contract-for-deed arrangements were often made between an individual real-estate speculator and a tenant, today they are more commonly made between a tenant and a big private investment company, like Harbour Portfolio Advisors, which is based in Texas and has entered into thousands of contract-for-deed arrangements across the country.

My colleague Ta-Nehisi Coates detailed contract-for-deed arrangements—also called rent-to-own deals—in his 2014 cover story “The Case for Reparations,” which looked at the prevalence of such arrangements in 1950s Chicago. What is surprising today is that, according to some housing advocates, these arrangements are in some ways even more predatory than the ones of half a century ago, even after decades of laws and regulations enacted to prevent racial discrimination in the housing market. “It was bad in the mid-20th century, but it is even worse now,” said Beryl Satter, a history professor at Rutgers University–Newark who wrote Family Properties, a book on the history of predatory lending in Chicago, about contract-for-deed arrangements. “The housing is in way worse shape, the markups are grotesque, and these people have been through multiple forms of credit exploitation, which is partially why they’re in this market.”

Through its lawyer, Harbour contested the idea that these contracts are exploitative. “It is simply not true that any of these agreements were predatory in nature,” David K. Stein, a lawyer for Harbour, told me. Instead, he said, contract-for-deed arrangements, which have been legal for centuries, give families who might not otherwise have the chance the opportunity to own a home.

Contract-for-deed arrangements in today’s housing market came under scrutiny more recently in 2016, when The New York Times reported how low-income buyers in Ohio were entering into these agreements and then losing the homes. Soon afterwards, the Consumer Financial Protection Bureau said it had assigned two enforcement lawyers to look into whether contract-for-deed transactions violate federal truth-in-lending laws. But now, advocates in Atlanta are raising another issue with contract-for-deed arrangements—alleging that they are racially discriminatory and that they violate the Fair Housing Act, along with various other state and federal laws. In a lawsuit filed in a U.S. district court last year, a group of plaintiffs represented by the Atlanta Legal Aid Society alleges that Harbour Portfolio, the group that owns the home where Zachary Anderson lives, specifically targeted African American neighborhoods with its contract-for-deed products. This violates the Fair Housing Act, the lawsuit argues, because it markets a predatory loan product specifically to African Americans. “Basically, what they were counting on is that people who were not already familiar with the home-buying process would be taken in by the American dream of owning a home,” Kristen Tullos, a lawyer for Atlanta Legal Aid, told me. Harbour moved to dismiss the case, but last month, a judge ruled that most of the plaintiffs’ claims in the case, including their core Fair Housing Act claim, could go forward.

The Fair Housing Act, enacted exactly 50 years ago on April 11, 1968, makes it illegal to deny housing or loans to people in residential real-estate transactions on the basis of race. Subsequent cases have also found that targeting bad loan products at certain racial groups—a practice known as “reverse redlining”—also violates the Fair Housing Act. If contract-for-deed agreements are found by a judge to be aimed at African American neighborhoods, it will be evidence that the country has returned to the untenable position where it was half a century ago.

In the 1950s and 1960s, African Americans were prohibited from borrowing through traditional means, so they entered into contract-for-deed arrangements, which left them with little equity to pass on to their children. This had long-lasting effects—African Americans still have, on average, much lower credit scores than whites, in part because they didn’t have the means of building wealth through homeownership that whites had. In the 1980s, 1990s, and 2000s, banks started lending more to African American buyers, but these buyers were frequently targeted by subprime loans with high interest payments and terms that were difficult to fulfill. (African American borrowers were 76 percent more likely than white borrowers to have lost their homes to foreclosure during the recession, according to the Center for Responsible Lending.) Now that many African Americans in cities like Atlanta were foreclosed on during the subprime crisis, many of them have bad credit as a result—which means they can’t buy homes the traditional way, and so are being offered contract-for-deed payments once again.

This tees up another cycle of debt and lost equity in the housing market, and in the larger economy that could continue to drag down the very people that the law 50 years ago had tried to protect.

Zachary Anderson has worked all his life, but he has never owned a home. For decades, he was a mechanic for the city of East Point, a predominantly African American suburb of Atlanta, making good money, but never enough to save up for a big down payment. This is not unusual: Black households overall have less savings than white ones, in part because of historical practices that prevented them from building equity. While the typical white household could replace almost 10 months of income if they liquidated all their financial accounts, the typical black household could replace only 23 days, according to a 2015 report from the Pew Charitable Trusts.

It was in 2010, while he was still working, living in a small apartment in the College Park area of Atlanta, that Anderson started seeing the signs around East Point. “SALE,” they read, in big red letters, and then listed the amounts buyers would have to put down—often as low as $700—and the amount they’d have to pay per month—often as low as $375—for the homes along the block. Anderson, sick of his cramped apartment and of hearing his neighbors’ every move, called the number listed on the sign and asked if they had any other houses in Atlanta. They referred him to a website that listed some of the homes, so Anderson went out and bought a computer so that he could start looking.

He eventually found a house he could afford in the Capitol View neighborhood of Atlanta, and the company gave him the code to a lock on the door that would enable him to get into the house and look around. The home, a small bungalow, was a fixer-upper. There was a hole in the roof, no stove or refrigerator, and tree branches invading the property. But Anderson knew how to work with his hands. He could put his own time and money into fixing up the home, he thought, which made it a good deal. The money he had to pay monthly, at $495, was less than he was paying in rent at the time. After a $1,000 deposit, he was told, the home, worth $46,750, would be his. (Harbour’s attorney declined to comment on the experiences of Anderson or any other specific individual.)

The contract, sent to him in the mail, also required that he paid all taxes on the property and kept the property insured. If he failed to make any of the agreed-upon payments, the contract said, he would forfeit all the money he had paid to the seller. He signed and initialed the contract in front of a notary, and sent it back to the company. A little while later, he received a letter in the mail congratulating him on becoming a homeowner. He could move in once he changed the locks, it said. He never met a single person from Harbour throughout the whole process.

Of course, it could be argued that Anderson should have known better than to enter into this type of contract, that he should have read the fine print. That he should have persevered until he could buy a home the traditional way. Harbour’s lawyer told me the individuals were provided “full disclosure” of the nature of the arrangement before they even first visited the homes. “It would be impossible for any reasonable person to not understand the nature of the transaction,” Stein said. But Anderson had never bought a home before. He didn’t know that this wasn’t the traditional way homes were sold. “I thought I went and bought a house,” he told me. He thought he had just stumbled across a deal.

He also didn’t know how difficult it would be to keep up the terms of the contract, because he didn’t realize just how much work the house would need. There is no requirement that a home inspector look at the house before a contract-for-deed agreement is signed. When Harbour told him he needed to get insurance, he says, the insurance company started sending him problems with the house that he didn’t even know existed—one document he showed me, for example, informed him that his “rake board,” which is a piece of wood near his eaves, was showing deterioration.

There is nothing inherently wrong with contract-for-deed arrangements, says Satter, whose father, Mark Satter, helped organize Chicago residents against the practice in the 1950s. It’s still possible for sellers who aren’t banks to finance properties in a fair way, she said. A San Francisco start-up called Divvy, for instance, is testing a rent-to-own model in Ohio and Georgia that gives would-be buyers some equity in the home, even if they default on payments. But there are two reasons these contract-for-deed agreements seem particularly unfair, Satter said. First, the homes that many of these companies buy are in terrible condition—many had been vacant for years before being purchased, unlike the homes sold for contract for deed in the 1950s, which frequently had been left behind by white homeowners fleeing to the suburbs. Fixer-uppers make it even more difficult for would-be buyers to fulfill all the terms of their contracts, because the houses need so much work.

And second, Satter said, many of these companies are aggressively targeting neighborhoods where residents struggle with credit because of past predatory lending practices, such as those that fueled the subprime-mortgage crisis. “We’re watching private-equity firms coming in and cleaning up, finishing the job of destroying these communities,” she said.

In some ways, the concentration of contract-for-deed properties in African American neighborhoods is a logical outgrowth of what happened during the housing boom and bust. The lending market ran amuck, allowing banks to offer subprime loans and other financial products to people who otherwise might not have access to home loans. Often, these products charged exorbitantly high interest rates and targeted African Americans. One study found that between 2004 and 2007, African Americans were 105 percent more likely than white buyers to have high-cost mortgages for home purchases, even when controlling for credit score and other risk factors. When many of these people lost their homes, the banks took them over. Those that did not sell at auction—often those in predominantly African American neighborhoods where people with capital did not want to go—ended up in the portfolio of Fannie Mae, which had insured the mortgage loan. (These are so-called REO, or “real-estate owned” homes, because the lender possessed them after failing to sell them at a foreclosure auction.) Fannie Mae then offered these homes up at low prices to investors who wanted to buy them, such as Harbour.

But Legal Aid alleges that Harbour’s presence in Atlanta’s African American neighborhoods is more than happenstance. By choosing to only buy homes from Fannie Mae, the lawsuit says, Harbour ended up with homes in areas that experienced the largest amount of foreclosures, which are the same communities targeted by subprime-mortgage lenders—communities of color. Even the Fannie Mae homes Harbour purchased were in distinctly African American neighborhoods, the lawsuit alleges. The average racial composition of the census tracts in Fulton and DeKalb counties, where Harbour purchased, was more than 86 percent African American. Other buyers in the same counties that purchased Fannie Mae REO properties bought in census tracts that were 71 percent African American, the lawsuit says. Harbour also targeted its products at African Americans, the lawsuit argues. It did not market its contract-for-deed arrangements in newspapers, on the radio, or on television in Atlanta, the suit says. Instead, Harbour put up signs in African American neighborhoods and gave referral bonuses, a practice which, the lawsuit alleges, meant that it was mostly African Americans who heard about Harbour’s offer.

In its motion to dismiss the case, Harbour contests the idea that it targeted African Americans with predatory loans. Harbour’s practices of putting up “for sale” signs and encouraging people to refer friends to the company “are more accurately characterized as no marketing plan at all,” Harbour’s motion argues. What’s more, the process of buying up Fannie Mae homes and selling them on contract-for-deed arrangements does not immediately mean that Harbour was targeting a minority population, Harbour argues—in other words, Harbour is not the reason that so many of these homes were located in census tracts with large minority populations. “It’s not accurate that any one group was targeted,” Stein told me. Harbour bought homes from the government, he said, and didn’t have a choice where they were located. Additionally, he said, Harbour sold them “in a fair manner, and did so without any discriminatory or predatory practices or targeting.”

Still, Heather K. Way, a professor at the University of Texas School of Law, told me that she thought Legal Aid had a “strong” case. Though the Fair Housing Act was initially aimed at prohibiting behaviors like redlining that prevent minorities from ending up in certain neighborhoods, a series of lawsuits in recent decades have led to another type of discrimination being prohibited under the law. “Reverse redlining,” for example, consists of marketing certain products to a protected class, like African Americans. In 2000, a judge found that a mortgage company had violated the Fair Housing Act by marketing unfair loans to African Americans in Washington, D.C. “Under the Fair Housing Act, you can’t intentionally target communities of color with these predatory lending products,” Way told me.

The contract-for-deed arrangements are predatory products, Legal Aid says. Harbour charges interest rates of around 10 percent, more than double the interest rates being charged for traditional mortgages, and it sells the homes for four to five times what it paid for them, the lawsuit says, even though the company does not invest money into fixing up the homes. The contracts are designed to fail, Tullos, the Legal Aid lawyer, said, because they require tenants to do so many repairs so rapidly.

Anderson’s contract, for example, required that he make his property “habitable” within four months. This turned out to be an expensive proposition. He repaired the roof, cut the limbs hanging over the house, repaired the sidewalk, and shored up the roof in the back where it was falling in, he told me. He installed a hot-water tank and bought a stove and refrigerator, he said. Since then, he’s also lowered the ceilings to retain some of the heat—his initial electricity bills were around $500 a month—put in a new fence, painted the house, replaced the windows, installed a new fireplace, put a screen on the porch, and added solar panels. He estimates that he’s spent $35,000 on the house. “It was just a really incredibly predatory contract in the way it was structured,” Tullos told me. “They transferred incredible burdens onto someone who was not actually a homeowner.”

When Anderson looked recently, he said, his Harbour account showed that he still owed the company $43,000, just $100 or so less than he’d owed in 2011, because such a high share of his payments go to interest.

Anderson was injured at work in 2012, and retired earlier than he’d expected, he told me. He now received disability payments of about $650 a month, he said. About $500 of those payments goes to Harbour, and the rest goes to the electricity company and the water company. He’s on food stamps and often has to borrow money from relatives in order to keep making payments on the house. When he was in the hospital after being injured and he missed a payment, Harbour told him it was going to evict him, he told me. But he caught up on the payments, and he’s determined not to let Harbour have the house back. He’s put too much work and money into it to lose it.

He is still current on his payments, but many of the plaintiffs in the Legal Aid case have fallen behind and are facing eviction. This is common in contract-for-deed agreements—nearly half of borrowers tracked over a 21-year period had defaulted and their contracts were canceled, according to a study prepared for the Texas Department of Housing and Community Affairs. Fewer than 20 percent of would-be buyers had actually received the deed to the property.

The Fair Housing Act was a long time coming. The Civil Rights Act, passed four years before, had outlawed discrimination in the workplace and in public facilities, and sought to end school segregation. But it had excluded language about housing, and discrimination in housing was still a pervasive problem even after that bill’s passage. Newly introduced fair-housing legislation was stymied by filibuster in 1966 and died in committee in 1967. It was not until the assassination of Martin Luther King Jr. that President Lyndon Johnson had enough political capital to push a fair-housing bill through Congress.

In some ways, the Fair Housing Act allowed the country to make great strides in integration, implementing policies that sought to help families of color access high-opportunity neighborhoods and that helped create more affordable housing. But the long legacy of discrimination in housing means that there’s still a lot of inequality to overcome. The homeownership rate for African American households is now hovering around 42 percent, according to census data, compared to a white homeownership rate of 72 percent. “Ultimately, it’s not like we’ve taken real steps to stop predatory lending based on race,” Beryl Satter told me.

Americans are told homeownership is a pillar of the American Dream, yet it’s a dream that remains largely out of reach for certain groups of people. That’s why so many people like Zachary Anderson end up in these terrible deals. He told me that he doesn’t regret signing the contract with Harbour, even though he recognizes how unfair it is. He even says he’d sign the paperwork again, knowing that he would have to put thousands of dollars into the home and could still be evicted if he misses a single payment.

Despite the shock of learning that he isn’t actually the owner, he loves his little green house, and is still working on it, installing new flooring, painting the fence, fixing the shed. This initially surprised me—the contract for deed seemed like such a bad deal, why would anyone be willing to enter into such an arrangement knowingly? But Anderson likes having his own place to repair and fix, to style as he wants. He still dreams of the day he’ll own it outright—a friend won the lottery and paid off his contract-for-deed agreement, and Anderson hopes that will someday happen to him too. It’s the only way he could ever own a house. For Anderson, and many other people like him, even 50 years after the passage of the Fair Housing Act, a bad deal on a home is probably the only deal he’s going to get.



There are no TV screens inside the Polynesian, the giant new tiki bar that opened three stories above Times Square over Memorial Day weekend. That means no news crawls, no Fox & Friends, no jaw-gritting headlines—nothing to break the illusion of a rum-fueled tropical oasis.

The Polynesian’s splashy opening signals the arrival of more than just another themed bar serving $15 drinks in skull-head tiki mugs. It’s the manifestation of a certain mood in America: the escalating need for escapism. (The over-the-top drinks are just a bonus.)

On opening night, the Friday heading into the holiday weekend, aloha-shirted tiki enthusiasts queued in the lobby of the Pod Times Square hotel, awaiting the grand unveiling. It was an ironic moment that echoed one from almost 30 years earlier, when another sprawling tiki bar inside a Midtown Manhattan hotel closed, ushering in what would be the end of tiki in New York for decades to come. That was when Donald Trump closed Trader Vic’s, a tiki bar in the basement of the Plaza Hotel, which Trump then owned, deriding it as “tacky.” Today, the tumult surrounding the Trump administration has helped reinvigorate the tiki machine.

The original tiki movement grew out of a similar sense of unease, says Martin Cate, a tiki historian and the proprietor of the tiki bar Smuggler’s Cove, in San Francisco. Don the Beachcomber, the tropical-themed café in Hollywood that set the template for the modern-day tiki bar, opened in the 1930s, in the middle of the Great Depression, Cate notes. “It offered a sense of a escape,” he says. “It was an imagined South Pacific, a transportive journey outside of the Depression.”

America’s tiki obsession hit its golden era in the postwar years, continuing into the 1950s and ’60s. After World War II, servicemen carried home stories of faraway Pacific lands. Among those returning was the author James Michener, a former naval reservist, who won a Pulitzer Prize in 1948 for his book Tales of the South Pacific. Rewritten as a musical, South Pacific became first a Broadway hit, then a movie sensation in 1958. Hawaii became the 50th U.S. state in 1959. Two years later, Elvis Presley released Blue Hawaii, setting off a fresh wave of enthusiasm for island culture. And thanks to developments in commercial aviation, more Americans were able to visit the actual South Pacific. In particular, tourism to Hawaii thrived.

Tiki bars continued to provide a sense of escape, but during this economic-boom time, they acted as “a dramatic counterpoint to the go-go sense of progress, big money, chrome and steel and future and space age,” Cate explains. “Maybe I want to loosen my tie and forget about the rat race. Or the flip side of all that advancement—the constant threat of nuclear war that loomed over America as this existential threat throughout the 1950s.” It’s not a coincidence that Sven Kirsten, who wrote The Book of Tiki, called tiki bars “the emotional bomb shelter of the Atomic Age.”

This all sounds eerily familiar: Tensions with North Korea have put the threat of nuclear war back in the headlines. Study after study shows that Americans feel overworked and chronically stressed. Meanwhile, smartphones make tuning out work obligations and worrisome news harder; for many, “out of office” no longer equals “off duty.” Added to that, social media amplify the chatter of headlines and arguments, often churning up anxiety and discontent. The trappings have changed, but the “go-go sense” remains. “Maybe we’re not in the recession anymore,” Cate says. “But we’re back to those original feelings.”

No wonder tiki bars are booming again.

Yet tiki—a catchall term for mid-century-inspired homage to all things tropical and vaguely Polynesian—has evolved in recent years. For one thing, tiki has gone from being an appropriation of actual Polynesian culture to becoming an adaptation of that earlier appropriation. (More on that in a moment.) For another, the scrappy and kitschy are increasingly giving way to the luxe and well funded—in other words, 21st-century tiki is escapism, capitalized anew.

A growing number of deep-pocketed restaurant groups now back successful tiki enterprises. In Orlando and Anaheim, California, Walt Disney World and Disneyland each have a Trader Sam’s outpost, a relatively kid-friendly take on the tropical-bar concept. Chicago has Three Dots and a Dash, a sprawling space in the downtown business district, as well as Lost Lake, a more intimate bar in the hip Logan Square neighborhood. But Tiki bars don’t have to be high-end productions to transport patrons from daily worries. Most major cities have seen new tiki bars launched within the past few years, from Latitude 29 in New Orleans to Hidden Harbor in Pittsburgh and Hale Pele in Portland, Oregon. Even cities that don’t have tiki bars often have popular tiki nights hosted within existing establishments.

Among big-ticket tiki, the Times Square Polynesian is the latest—and arguably most expensive—example, launched under the umbrella of Major Food Group, which runs such concepts as The Grill/The Pool in the former Four Seasons space, ZZ’s Clam Bar, and Carbone. With the exception of the Trader Sam franchise, the Polynesian, launched within a hotel, also seems the most explicitly targeted to tourist traffic.

It’s a particularly lavish, theatrical experience. The 200-seat indoor/outdoor space features an intricately carved wooden bar topped with lava stone glazed an oceanic turquoise. A “pirate room” is secreted away in the back, centered around an enormous round table topped with a pirate’s map of Polynesia and illuminated by an oversize, gilded hanging lamp shaped like an inverted cocktail coupe. It’s not hard to imagine the space for corporate meetings; it’s even easier if you imagine all the corporate honchos wearing eye patches.

Adding to the drama, Brian Miller, a co-owner, bartender, and self-declared “pirate,” presides over the operation, cutting a Jack Sparrow–esque figure in his trademark sarong and tricornered hat. According to the Mariners’ Museum, pirates are associated with the Caribbean in the late 17th and 18th centuries, not Polynesia, adding to the tropical mash-up.

The revelers at the Polynesian may be more interested in rum drinks than a history lesson, yet allegations of cultural appropriation have long dogged the tiki industry. Tiki was, after all, a key export of the tourist culture built upon the stolen Kingdom of Hawaii, which was a by-product of Hawaii’s transformation from sovereign nation to U.S. territory to state. Is a respectful approach even possible? Yes, insists Shelby Allison, a co-owner of Lost Lake, in Chicago: Today’s tiki is “more conscientious and more considerate,” she says. “We’re able to leave behind the old tropes that were problematic in tiki bars of yore.”

Others, including Miller, hope to sidestep implications altogether: “I don’t want to get into arguments. I don’t want to talk about cultural appropriation. I’m not looking to fight,” Miller says. “We’re not about that ... I want to bring tiki to more and more people. We’re just trying to honor the culture and shine a light on tiki cocktails.”

For Miller, the Polynesian is the culmination of several years of hosting semisecret tiki nights at venues across Brooklyn and Manhattan. The cocktail menu features some of his original cocktails, such as the derelict, a potent, banana-spiked sipper featuring a quartet of rums; the playlist, which on opening night bounced from reggae to Run-DMC, is also his. “Hopefully down the line we are the greatest tiki bar in the world,” he told me.

Although the Polynesian-branded glassware isn’t (yet) available for sale, it’s a reminder that merchandising also is part of the tiki-bar economy. For example, Jeff “Beachbum” Berry, the proprietor of Latitude 29, has his own line of tiki merch on the website Cocktail Kingdom. Similarly, Chicago’s Lost Lake sells mugs, T-shirts, even “garnish kits” for decking out cocktails at home. The mai-tai mug is a particularly strong seller, Lost Lake’s Allison reports. “Mugs are a huge source of revenue for tiki bars,” Allison notes. It also helps offset the cost of theft, she says, a problem many tropical-themed bars face, thanks to patrons seeking souvenirs. “No one is stealing coupe glasses at Death & Co,” a speakeasy-style bar in NYC, “but at least five ceramic pieces walk out my door every Saturday night.”

Although it’s difficult to pin an exact number on how much money is spent on chasing escapism through tiki bars; conferences such as Tiki Oasis, in San Diego, and the Hukilau, in Fort Lauderdale; or exotica music and loud floral-print caftans, it’s abundantly clear that tiki is in yet another golden age. Americans are still finding refuge in spaces that bring the pageantry of flaming cocktails to the forefront, and push TV screens and the ever-frenzied news cycle deliberately out of sight.

Of course, nothing is stopping patrons from pulling up Politico or CNN on their phone. But a quick glance around the Polynesian reveals that everyone’s too busy Instagramming blue drinks in fishbowls to check the latest headlines anyway.



Imagine two families in Mobile, Alabama, trying to buy a home. The households are similar in many ways. They have roughly the same income and employment history. They are seeking to buy similar three-bedroom ranches in comparable, quiet neighborhoods. They both want a loan from the same local bank, and both want to put down a similar, standard down payment. The only difference is that one family is white and the other is black. Today—50 years after the passage of the Fair Housing Act, 40 years after the passage of the Community Reinvestment Act, and a decade after the subprime-loan crisis—that black family would be 5.6 times more likely to be denied a conventional mortgage than that white family, a damning report released last month by the Center for Investigative Reporting found.

Redlining and other forms of discriminatory lending practices remain a defining feature of the American housing market, and they have profound consequences in terms of wealth-building, equality, and equity. Yet a technical and mostly overlooked provision of a big piece of financial-regulatory legislation working its way through Congress might make such practices harder to identify, and thus harder for federal regulators to stamp out.

This week, Congress is considering a sweeping and complicated piece of law aimed at helping community and local banks. Its exact provisions are still uncertain, but the law will likely let smaller banks make certain risky investments; exempt certain institutions from a rule that restricts their lending, depending on what they hold in deposits; reduce the number of institutions labeled as systemically important; and put more responsibility on the Federal Reserve and other regulators to intervene in the event of a crisis. The Economic Growth, Regulatory Relief, and Consumer Protection Act is a rare bipartisan effort; given its support in both houses and both parties, its passage is all but certain.

Off of Capitol Hill, the bill’s reception has been mixed. Conservatives largely love it, moderates largely support it, progressives largely hate it, and many left-of-center types argue it is less of a regulatory gutting than they expected from a Republican-dominated Congress. “It’s difficult to categorize this as a pile of horrendous ideas, or as a motherhood-and-apple-pie, just-helping small-community-banks [effort],” said Aaron Klein of the Brookings Institution, who helped author the Dodd-Frank banking legislation of 2010.

Much of the criticism of the bill has focused on the way it might end up reducing the regulatory burden on big banks, not just small ones. Some of the country’s largest, most risk-hungry, and most powerful financial institutions have been on a quiet campaign to loosen regulations, such as one determining how much leverage “custodial banks,” ones that safeguard assets for rich clients and institutional investors, are allowed to have. “In general, I’m against exempting anything from the simple leverage ratio,” Klein told me. “Once you start exempting one bank, where does the logic end?” He expressed concern that exempting institutions from the rule would increase the chance banks would game the regulatory system, and increase systemic risk. Moreover, the bill largely fails to address the most prevalent consumer-protection issues of recent years, namely the widespread fraud at Wells Fargo and the data breaches at Equifax.

Then there are the provisions regarding redlining and discrimination in lending—ones largely overlooked, but potentially important. The legislation in process includes a number of technical changes that stand to put borrowers of color, mobile-home owners, and rural residents at risk. Chief among these is a change letting banks that make fewer than 500 mortgage loans a year report less data to the government on who they lend to and at what rates—data meant to help show whether financial institutions are discriminating against families of color. According to data from the Consumer Financial Protection Bureau, the legislation might exempt four out of every five banks and credit unions.

Supporters of the provision have argued that the vast majority of mortgage loans would still be covered by these reporting requirements, which stem from the 1975 Home Mortgage Disclosure Act (HMDA) and were expanded by Dodd-Frank, and also argued that the intention is to make things easier for small banks without the resources to handle the data reporting. An amendment made to the bill this week also required small banks that have gotten low scores on examinations performed by the government to provide the full scope of HMDA data.

But fair-lending groups, civil-rights organizations, and Democratic politicians have pointed out that many financial institutions would still be able to discriminate and hide their discrimination—and the government, journalists, and housing activists would have fewer tools to detect troublesome patterns. That might make it harder for regulators to identify discriminatory lending practices that might precipitate another crisis going forward, or simply make the country’s yawning racial wealth gap worse. “The only way to enforce fair-lending laws is to have an accurate picture of what the market looks like,” Scott Astrada, the director of federal advocacy for the Center for Responsible Lending, a policy-research group, told me.

A yet broader concern is that this particular provision is coming at a time when the federal government is scaling back other protections for communities of color. The Trump administration, for instance, has hollowed out the Consumer Financial Protection Bureau, and the Department of Housing and Urban Development is removing its mandates for inclusion and consumer protection from its mission statement. “One could imagine a world in which the Trump Department of Justice said, ‘Don’t report so much data. That’s a headache. We’re going to step up enforcement because we take the civil rights of people of color seriously, more seriously that we have in the past,’” said Mike Konczal of the Roosevelt Institute, a left-of-center think tank. But, instead, he pointed to clear signs that the Trump administration has pulled back on a wide range of regulatory investigations.

What is at risk? More than a decade after the housing crisis, discriminatory lending—meaning both that black families are more likely to be denied mortgages than white families, and are more likely to be offered high-cost financial products than white families—remains pervasive. This both disadvantages black families in terms of intergenerational wealth building, by pushing them out of the housing market, and raises costs on them, sapping their month-to-month income by forcing them into higher-interest-rate loans. At risk is fairness, then—but also wealth inequality, and the integrity of the mortgage market itself.



Imagine, for a moment, a marijuana producer. See his Crocs. Admire his hacky sack. Inhale his earthy musk. Whoever comes to mind—it’s not John Russo.

Stepping to the podium in the San Jose Hilton’s tasteful ballroom earlier this month, Russo, a real-life marijuana manufacturer, looked a lot like my gastroenterologist: white ring of hair around the periphery of his head, wire-rimmed glasses, stylish-but-sensible shoes. “This morning I’m going to tell you about a company that’s poised to be the largest independent producer of high-quality, low-cost concentrated cannabis in the industry,” Russo told the crowd. He was the first presenter at CNvest: Terps and Tech, a gathering in the heart of Silicon Valley where entrepreneurs pitched their pot start-ups to more than one hundred investors, executives, and journalists. At the end of the day, a panel of judges would award $10,000 for the best presentation.

In 2016, Russo said, his company, Indigo Therapeutics, won the first license for the legal manufacture of concentrated cannabis in the state of California. Operating out of a 52-acre campus that was once owned and operated by the pharmaceutical company Bayer, Indigo was primed, he said, to scale its manufacturing operation and meet rising demand when the ideal moment arrived. “Which is now,” he said.

As a growing number of states have legalized marijuana, dispensary lines curl around city blocks. New products—edibles, vape-ables, smoke-ables—come online each week. Insiders wonder whether college grads looking for jobs will migrate toward their field. And start-ups send reps to conferences like this one, to raise money for their new ideas, touting the virtues of an industry that, until recently, operated in less elegant precincts.

“Four years ago I would come to an event like this and it was the stereotypical stoner kind of vibe,” said Jeff Siegel, the managing editor of Green Chip Stocks, an investment research service focusing on the marijuana industry. “Now, since I cover the cannabis space, all the interns are like, ‘We want to go.’ I say, ‘Listen, just so you know, it’s not a party. We’re going to be hanging out with accountants and lawyers and entrepreneurs.’”

True, a shady guy with a giant hockey bag approached me furtively halfway through the pitches to ask if I’d like to sample his company’s pills. But then he left to get the stuff and never came back.

Over the course of the day, representatives from 16 cannabis start-ups delivered five-minute pitches, complete with PowerPoints. They were gunning for the $10,000 prize—but also for funding from attending VCs. Contestants plugged products that ranged from the practical (flavored cartridges, grooming products for pets) to the quirky-but-probably-lucrative: Tokey Mongo, a start-up in the “cannatainment” field (where the time is always 4:20) sounds like Pokémon GO for stoners: Users plant virtual pot fields outside City Hall, watch UFOs take off from their favorite dispensaries, and collect the platform’s proprietary currency—TokeyTokens. “You don’t have to be high to enjoy Tokey Mongo—but it does help!” the company’s CEO, Michael Hardy, a Canadian in white pants, told the audience.

Cyo Ray Nystrom pitched a product for “humans with vaginas and humans without vaginas who love vaginas.” Her company, Quim Rock, makes a cannabis-infused oil that, if it does all she says it does, will hit the list of most-effective sexual aids between Barry White and beds: The oil, she said, intensifies climax, enhances natural lubrication, increases libido, and fosters vaginal health. “Close the orgasm gap!” Nystrom said.

No fewer than 20,000 cannabis businesses operate today in the United States. Marijuana is expected to generate as much as $40 billion by 2021. Citing research by analysts at the Arcview Group, Sumit Mehta—CEO of Mazakali, which provides business-support services to cannabis companies—said marijuana is now the second-fastest-growing large industry in American history, behind only the internet. “The only thing Americans might want more than their cannabis is Wi-Fi,” he said.

But as Silicon Valley’s hyperactive investment culture moves into a business that has for decades been quarantined in the shadows, the success of this odd coupling—and the future of start-ups like the ones addressing the conference—hinges on whether pot companies can adapt to the sunlight.

When venture capitalists steeped in mainstream industries encounter cannabis entrepreneurs, they expect a level of professionalism akin to what they’d find making a tech or energy investment. They insist on accurate budgets, credible projections, follow-through. Such competence, investors say, remains rare. “This industry has been complete chaos,” said Indigo Therapeutics’ Russo.

The beginnings of any industry can be amateurish, of course. Russo recalled the PC’s early days, when manufacturers shipped software on floppy disks in Ziploc baggies. It’s no surprise then that many cannabis start-ups, just now coming in from the cold, aren’t ready for prime time. Ben Larson, a cannabis investor, recalls that, a couple of years ago, a marijuana grower showed up his office in Oakland, Calif., brandishing a Ziploc bag of his own stuffed with cash. “He’s like, ‘I transact seven of these a day,’” said Larson. “Seven gallon baggies full of $100 bills.” Larson remembers thinking, “Oh, this isn’t a normal industry.”

One by one, contestants at the Hilton took to the stage to make the case that they were the exception. All told there were 13 men and three women. They threw around terms like “vertical integration” and “curated experiences.” They pitched grow-it-yourself pot kits, self-lighting pipes, and security services for transporting cannabis and cash. They proffered pot-monitoring camera systems, infrastructure to grow pot vertically, and, according to one entry in the conference handbook, technology promoting the “recruitment of highly cooperative, plant beneficial symbionts into the plant-microbiome assemblage,” which seemed to mean something like growing more pot.

Jeff LaPenna delivered the final pitch of the day. LaPenna is the CEO of The Peak Beyond, a San Rafael, Calif.-based start-up run by three millennials who make interactive smart tables for cannabis dispensaries (think giant iPads as the table’s surface). Customers set a jar of marijuana on one of their tables and receive a digital rundown of the product’s particulars—THC levels, physiological effects. Then the table facilitates the sale. LaPenna is clean-cut but hip—earrings in both ears, trim beard. He is also extremely articulate and savvy. Before this, he developed brand strategies with companies like Google and Sony Pictures. One of his business partners comes from IBM; the other built an interior design business.

Stoner culture is giving way to something “a lot more accessible to a mainstream audience,” LaPenna told me later. “The companies who are succeeding right now are the ones who’ve gotten on board the quickest.”

Which is to say, if you’re offering bespoke cannabis pills, you had better be possessed of sufficient follow-through to deliver them.

When the pitches were done, attendees adjourned for beer and wine while judges counted their votes. There was little tension in the room. The stakes, ultimately, were low: $10,000 was not going to put any of the companies over the top, and the real prize—a cash infusion from attending VCs—would take time. More than that, it wasn’t much of a contest. The younger presenters were simply more adept than older contestants at standing in front of a crowd and delivering a compelling vision for their companies. They didn’t sweat as much. They didn’t breathe as heavily. Their pitches were on point and natural and matched up beautifully with their slides. Whether a slick presentation says anything about viability remains to be seen. But when John Sidline, one of the conference’s directors, hopped up on a chair, shushed the crowd, and announced the winner, no one seemed all that surprised.

“After tabulating the votes,” Sidline said, “the winner of the inaugural CNvest: Terps and Tech Audience Choice Award is The Peak Beyond”—LaPenna’s smart-table company. LaPenna thanked the audience, and Sidline handed him the trophy, a one-liter curing jar fashioned from dark Miron glass infused with gold. A lovely addition to any glassware collection and a great place to put your weed.



GREENFIELD, Mass.—Al Norman has been fighting to keep Walmart and other big-box retailers out of small towns like this one for 25 years. He’s been successful in Greenfield, his hometown and the site of his first battle with Walmart, and in dozens of other towns across the country—victories he documents on his website Sprawl-Busters, an “International Clearinghouse on Big Box Anti-Sprawl Information.” Partly because of Norman’s efforts to keep out such stores, Greenfield still has a Main Street with dozens of businesses, including a bookstore, a record store, and Wilson’s, one of the last independently owned department stores in the country.

But Norman and business owners in Greenfield are noticing that the Main Street stores are now struggling in the face of another force that’s become more and more powerful in recent years: e-commerce. Many customers who kept shopping in Greenfield’s downtown because Walmart was too far away are now turning to Amazon and other websites that offer free and fast shipping for basic needs, sapping business away from local stores that had survived for so long. Facing competition from a company as enormous as Amazon, some local stores are having trouble staying open.

I twice stopped by Wilson’s, the department store, to try to meet the manager, and saw no shoppers inside the store the entire time I was there. (Wilson’s did not respond to multiple interview requests for this story.) And Home Furnishing Co., a 100-year-old store in downtown Greenfield, closed last year, and then Magical Child, a toy store on the brink of closing, partnered with a local bookstore, World Eye Bookshop, to remain open, consolidating into one storefront.

“If you were going to pick a place years ago that would still support small businesses, and shop downtown first, I would have said Greenfield would be that place,” Jessica Mullins, the owner of World Eye, told me. But her store’s sales were down significantly last year. Several customers who were once reliable shoppers now come in and find out about new books and games, take a picture of them, and then buy the products online, where they’re cheaper. It’s a practice called “showrooming,” and while the executives running big legacy retailers are the ones who most publicly lament it, it can hurt smaller shops too. “People are getting on Amazon and they’re not getting off,” Mullins said.

Greenfield and other towns across New England are learning that while they might have been able to keep out big-box stores through zoning changes and old-fashioned advocacy, there’s not much they can do about consumers’ shift to e-commerce. They can’t physically keep out e-commerce stores—which don’t have a physical presence in towns that residents could push back against—and they certainly can’t restrict residents’ internet access. “It’s one thing for me to try and fight over land use in the town I live in, or in somebody else's town,” Norman told me, over lunch in a diner on Greenfield’s Main Street. “But e-shopping creates a real problem for activists, because on some level, shopping online is a choice people make, and it’s hard to intrude yourself in that.”

Shoppers are, as Norman well knows, increasingly turning to Amazon and other e-commerce sites. Online sales represented about 13 percent of American retail sales in 2017, according to Forrester, a research firm, which projects that number will grow to 17 percent by 2022. And about one-third of online purchases are made through Amazon, Forrester says—83 percent of American adults who use the internet (that is to say, nearly all of them) made a purchase from Amazon in 2016. This has translated to a decline in shopping at brick-and-mortar stores. Last year, more chain-store locations closed than in any previous year.

The dominance of e-commerce has affected Main Streets too: Around 90 percent of independent retailers said that Amazon was having a negative impact on their business, according to a 2017 survey of more than 850 such businesses. Between 2006 and 2015, the number of retail firms with fewer than 10 employees fell by 9 percent, according to census data.

Of course, there’s a reason Amazon and other e-commerce sites are so difficult for small businesses to compete with: The convenience of online shopping is unmatched. Amazon’s rise is proof that as much as some consumers may want to support nearby businesses, in a sense there’s nothing more local than shopping from their living-room couch.

And, as the company pointed out when I contacted it about this article, Amazon does create some opportunities for independent businesses as well. More than 140,000 small and medium-sized businesses each sold more than $100,000 in goods on Amazon last year, according to the company. “We are empowering so many retailers—many of them small businesses and main street businesses—to reach customers, not just in the US, but around the world,” an Amazon spokesman, Erik Farleigh, wrote to me in an email.

Roundabout Books, a small business a mile from Greenfield’s Main Street, is an example of a shop that has been able to grow because of e-commerce. Raymond Neal, a former schoolteacher, opened the store six years ago, and most of his business is used books. Online retail—including selling through Amazon—has helped him keep the doors open. (He bemoans the fees he has to pay Amazon for the privilege, however.) He estimates that half of his revenue comes from online sales; the other half is a mix of in-store transactions and pop-up sales he does in busy locations like downtown Boston. “I go where the customers are,” he told me. But his Greenfield location produces only a small part of his revenues—if he makes $50 in a day in his store, it’s a good day, he said.

The shift of retail away from brick-and-mortar stores to online ones represents a fundamental change in the American economy, one that has big repercussions for communities like Greenfield. The average American spends nearly $15,000 a year on retail shopping, according to census data. If that money is going to companies based far away, the local economy may suffer, because less money is being kept in the community. Money spent at an independent business generates four times the direct local economic benefit than money spent at a chain store—in terms of employee pay, local charitable giving, and employee spending—according to an analysis done by Civic Economics, a research firm that studies independent businesses. Local business owners will often spend the money they earn from their business nearby, at restaurants, bars, and other retail stores. Also, as I’ve written before, the decline of local retail also has major implications for cities and towns’ ability to raise revenues through sales taxes.

There are other, less tangible, changes that occur when brick-and-mortar businesses disappear. As Main Streets become sparser, there will be fewer of the spontaneous, community-building interactions that take place when residents run into each other on the sidewalk or at a store. People who live in the same town might start to meet less often in person as they shop more from their couches and work more from their dining-room tables. Relatedly, small businesses are often the linchpins of a community—they sponsor softball teams and cookouts, charity auctions and parade floats. Bob Nelson, the owner of Nelson Ace Hardware in Barre, Vermont, another town struggling to revitalize its Main Street, said he gets “at least one request a day” to sponsor a local cause, whether it be the local Rotary Club or Lion’s Club or softball team. But who will be left to sponsor softball teams or floats in parades if there is no more small-town retail?

It’s possible that as e-commerce companies continue to encroach on brick-and-mortar stores, they will support communities in the same way that other small businesses traditionally have. Amazon pointed out that it has sponsored, among other events, holiday festivals in Jeffersonville, Kentucky, a Pride parade in Kenosha, Wisconsin, and a summer reading program in San Antonio. But going to Amazon for donations is fundamentally different from walking into a store and asking the owner, based on a personal relationship, for support.

For the residents of Greenfield in particular, the decline of small businesses is hard to bear because the town has a history of resisting national companies that have tried to come in and set up shop. The first anti-Walmart battle, in the mid-1990s, was prompted after the town council rezoned a plot of land, thus allowing a developer to build a Walmart. Norman, the Sprawl Buster, led a ballot initiative to reverse that zoning decision, and his narrow win surprised just about everybody in Greenfield, including him. “We really tried to play up the idea that Greenfield had a lot to lose,” he told me. “Our slogan was, ‘You can buy cheap underwear at Walmart, but you can’t buy small-town quality of life anywhere.’”

A decade later, when a developer again tried to put a Walmart outside of town, Norman fought it because the new site was on a wetland. Eventually, the state’s Department of Environmental Protection forbade construction. Then, in 2011, when the developer reconfigured the site and won a planning board’s permission to build, Norman found plaintiffs to file a lawsuit against the developer that is still winding its way through court. He drove me by both sites when I was in town, and both are still tree-filled fields, rather than the big stores developers had envisioned.

Lisa Cocco, the owner of Opus, a Main Street boutique selling small gifts like jewelry, pottery, and wind chimes that has been around for 28 years, said that when she thought Walmart was coming to Greenfield, she opened a second store in another town because she didn’t think her original location could withstand the retailer’s presence. The Walmart didn’t come, so she stayed open in Greenfield. Now, she’s not sure if she can weather the switch to e-commerce. She told me customers come in and browse, find something they like, and compare prices online when she’s standing right there. “It’s seriously hurting business,” she said. “I’m extremely discouraged.”

In some ways, Greenfield’s lack of big-box stores might have accelerated residents’ transition to e-commerce. While there are shops downtown, those don’t offer the selection of a Walmart or Target. And since the only big stores are a 30-minute drive away, many in Greenfield have started buying off Amazon instead. “There are only a certain number of things you can get downtown,” Danielle Jenczyk, a 37-year-old Greenfield resident told me. Jencyzk told me she shops on Amazon for just about everything, since she gets free shipping through her Prime subscription and because she can look at product reviews before she buys anything.

Small businesses in other towns that successfully kept big-box stores out are also having trouble. In Randolph, for instance, a Vermont town that recently fought off a proposal to build a shopping mall and a hotel on the outskirts of town, Belmain’s, a variety store that has been in business since 1934, announced in October that it would close. The store’s owners said it was closing because of “the growth and convenience of Amazon and other mail-order companies and the lack of good steady flow of foot traffic in Randolph.” And that likely isn’t due to any decline in population—Vermont actually gained residents between 2000 and 2016.

The whole state of Vermont has long been a difficult place for big-box stores to locate—the state won’t get its first Target until later this year. That’s in large part because of Act 250, a state law that gives regional environmental commissions the power to deny building permits for big projects. But despite those successes, Paul Bruhn, the executive director of the Preservation Trust of Vermont, a nonprofit that seeks to protect the state’s architectural heritage, is concerned about the future of Vermont’s downtowns. “With most small businesses, you don't have to take away all of their business for them to fail,” Bruhn told me. “A business that loses 10 percent to 20 percent because of Amazon, that’s a big impact.”

Some communities are trying to push back against the decline of independent businesses by launching campaigns asking people to shop local, such as Local First Arizona and Portland Buy Local. (Greenfield launched its own currency—Greenfield Dollars—in hopes of getting people to spend money in the area.) City officials can zone downtowns for mixed-use retail, and create affordable commercial space in new housing developments, said Stacy Mitchell, the co-director of the Institute for Local Self-Reliance, a nonprofit that’s skeptical of big business. Some cities have helped set up community banks that are more likely to give out small-business loans, Mitchell said.

But it will be hard for cities to create a shopping environment more convenient than Amazon’s. Julie Keane, a 30-year-old who lives in Greenfield, told me that her family understands the importance of supporting local businesses, going to the Wilson’s department store when they can. But she has a 10-month-old son, and often, Amazon has baby products that the department store doesn’t. When Amazon was offering a free Prime trial two years ago, her family signed up. They now use it frequently, since it saves them time—it doesn’t make sense for Keane to pack her son into the car and drive to the Target 30 minutes away for the same products. And as long as she’s buying those sorts of products on Amazon, she’s likelier to buy other products, the kind available on Main Street, from the company too—the longer someone is a Prime member, the more money they spend on the site, studies show. “We try to shop locally,” she told me. “But sometimes, there are better options online to what we have.”

How might local businesses respond? “I think you’re seeing that local merchants are thinking seriously about what their advantage is,” said Marc Levinson, the author of The Great A&P and the Struggle for Small Business in America. Some small retailers are trying to offer services that e-retailers can’t offer to draw in customers. Seth Lustig, the owner of Greenfield Games, another Main Street store, says that his business has been able to attract customers by organizing game nights and other events for people to learn about new products they might not naturally come across online. Nelson, the hardware-store owner in Vermont, says helpful customer service helps him draw in shoppers—people who know that he’ll assemble products for free will come in rather than buying something online and having to assemble it themselves.

But the challenge posed by online shopping to local businesses is immense. Even Al Norman, who refuses to shop at Walmart, says he doesn’t have the same aversion to Amazon, in part because he thinks the internet is the future of shopping. His wife has a Prime account, and he recently ordered tea from the website when he couldn’t find it locally, he said, adding that he has no plans to organize protests or zoning meetings about Amazon. He doesn’t love the idea that some of his money is going to Jeff Bezos, “the richest human around,” as he refers to the Amazon founder, and so still shops locally whenever possible. He doesn’t know whether he’ll still be doing that in a decade. When he launched the first campaign against Walmart in Greenfield 25 years ago, he led activists with bumper stickers that said, “If you build it, we won’t come.” He knows the same can’t be said for Amazon, because shoppers, including him, are already there.



Last September, a farm near Schulenburg, Texas, a quiet, conservative town of fewer than 3,000 people, became a medical-marijuana dispensary. Knox Medical, based in Florida, owns the farm and is one of the three newly licensed cannabis outfits in Texas to start selling cannabidiol, or CBD, a substance derived from low-THC marijuana. When deliveries start going out to patients this month, Schulenburg, home to distinctively painted churches and the Texas Polka Music Museum, will become one of the first legal outposts for medical marijuana in Texas.

It’s not an identity residents of the area are rushing to embrace. Town officials are quick to point out that the site of the greenhouses and the future dispensary is technically outside of city limits. And Kristopher Emola, the cultivation manager for Knox Medical, has already learned not to volunteer that he grows pot when talking to people in Schulenburg. “It’s one of those things that has been so stigmatized for so long,” Emola says, “that it’s natural to question it initially.” But if small towns like Schulenburg can get past the stigma, they may just be the perfect entry points for a booming marijuana business in a largely conservative state. “If it helps people and it doesn’t hurt anything,” asks Fayette County Judge Ed Janecka, “why not do it?”

It is unclear whether marijuana will ever become a significant part of the state’s economy. Despite a push across the country to legalize both recreational and medical marijuana (30 states and the District of Columbia have legalized it in some form so far, and 15 others have legalized CBD for medical uses), Texas officials have been reluctant to go anywhere near state-sanctioned cannabis. Mainstream Texan culture doesn’t support it yet, and new legislation is very narrow when it comes to legal use. In fact, the only reason this plan is viable now is due to CBD. Derived from low-THC cannabis, a person would have to smoke an entire barrel of CBD to get high. With recreational use or abuse therefore unlikely, Texas lawmakers got onboard and passed the Texas Compassionate Use Act in 2015.

The law authorized the Texas Department of Public Safety (DPS) to create a registry of prescribing doctors. It also required the DPS to issue licenses by September 2017 to at least three dispensaries to sell low-THC cannabis (containing 0.5 percent or less THC) that is at least 10 percent cannabidiol. Sales must be aimed specifically at the 150,000 patients in Texas, mostly children, who suffer from intractable epilepsy. The drug drastically reduces the number of seizures many patients with this condition suffer with almost no side effects, says Andrew Lerman, a neurologist who has been prescribing the drug to his own epilepsy patients in Florida since it was legalized there four years ago.

It’s a fair bet that none of the Texas lawmakers who supported the legislation imagined the first dispensary to open would be located in Schulenburg, but Knox Medical’s CEO, Jose Hidalgo, says the location makes sense for a lot of reasons. Schulenburg is roughly an hour and a half from each Houston, Austin, and San Antonio, granting easy access to some of the largest cities in the state. Plus, Fayette County is a farming and ranching community, so there’s plenty of space available to grow marijuana without being near schools, parks, or neighborhoods. When the DPS started taking applications in early 2017, Knox representatives quickly reached out to Janecka and other community leaders. “Immediately, when we came in wearing suits and looking professional,” Hidalgo says, “they looked surprised and relieved.”

Opening the dispensary in Schulenburg could be a boon for the town, says Dietrich Vollrath, a University of Houston economics professor. Medical marijuana is generally a low-risk business, and the town did not have to put up money or offer incentives to get Knox to base its Texas operations there. So, if it works, great; if it doesn’t, there’s no big loss of investment or effort for Schulenburg. “For a small town that may not have many other opportunities for growth, this may be the right move,” Vollrath says. “Once you’re the first, the natural fit would be to expand the business from there. There’s no reason it has to be Schulenburg versus anywhere else in Texas, but if it becomes the marijuana capital of Texas, why not?”

At most, though, the economic impact will be quite modest, says Jeffrey Miron, a Harvard economics professor focused on marijuana policy. Initially, the dispensary will only employ about a dozen people, and the products will be available for delivery only, via nondescript white vans. Plus, the number of doctors prescribing the drug is limited, and the number of patients who can afford cannabis oil—which will not be covered by insurance since it is still classified as a Schedule I narcotic—may be quite low.“If you tax medical marijuana, you can always collect tax revenue, but the true employment numbers, the GDP in the county, will hardly change at all,” Miron says. “Selling low-THC marijuana is like low-alcohol drinks: Nobody wants it aside from those who need it, and the market for those who need it isn’t huge and the number who can actually afford it is even smaller.”

But with the market for marijuana expected to grow three- or fourfold in the next seven years, many believe this is really just the beginning. Despite Governor Greg Abbott and other state politicians’ insistence that the Texas Compassionate Use Act is not the first step toward broader legalization, it’s likely going to be pretty tempting for legislators to expand the laws once legal CBD revenues start coming into the state. “On the medical side, it’s just a matter of time,” says Franklin Snyder, a Texas A&M University law professor who taught one of the first marijuana law classes in the country. “The evidence is accumulating about the benefits, and the drug is so much less dangerous than the alternatives. We have a nationwide opioid epidemic right now, and the fact that this could be a way to cut back on prescribing those drugs is going to propel this further.”

Any expansion would likely be a slow process. As it is, per federal law, doctors in Texas could be risking their prescribing rights by recommending CBD to their patients, which is likely why, according to the DPS, only seven doctors have signed up for the Compassionate Use Registry of Texas so far. And marijuana’s future in Texas won’t be helped by its uncertain legal status at the federal level: Last week, the Justice Department rescinded a policy instated under President Obama that steered prosecutors away from bringing any charges in states with permissive marijuana laws.

Still, Knox Medical, when contacted after the rescission, said it was proceeding with its plans under the assumption that the policy shift wouldn’t change much in Texas. Snyder doesn’t think the company is being overly optimistic: He expects the DOJ’s new position to have a negligible bearing on a state where prosecutors have demonstrated little interest in cracking down on CBD. (He says it might be a different story for “states with recreational-use and broad medical-marijuana programs like California's, where you can buy doobies to deal with your headaches.”)

As federal policy gets hashed out, the folksy Schulenburg location, the benefits to sick children, and the suit-wearing Knox executives could all have a powerful effect on public opinion. “They made a savvy choice putting the dispensary there,” Snyder says. “There’s something about Schulenburg that sounds very ordinary and Texas-like, reassuring in a way that, say, downtown Austin does not.”



At this point, the fact that women in the United States earn about about 80 cents to each dollar earned by men is so commonly known that it’s become both a perverse, if slightly tired, punch line and a litmus test in the culture wars.

But there’s plenty of variation under that top-line statistic. The wage gap is worse, for example, for women of color and for all women in prestigious, well-paying fields like finance and law. Even less often discussed: Geography accounts for 0.3 percent of the gap between male and female wages—which doesn’t sound like a lot, but adds up to more than $2 billion a year nationwide. In Montana, women earn 73 cents to the dollar on average; in Louisiana, they earn 69 cents.

One common explanation for the geographical differences is the fact that some states set a minimum wage that is higher than the national minimum wage. Since women make up nearly two-thirds of minimum-wage workers, those states’ policies raise the pay, on average, of female workers. This would seem to suggest that if a women wants to earn more, she can simply pick up and move elsewhere. But a working paper published Monday by three economists—Kerwin Kofi Charles of the University of Chicago, Jonathan Guryan of Northwestern University, and Jessica Pan of the National University of Singapore—complicates that notion.

Charles and his colleagues wanted to find out how sexism in a person’s birth state—as measured by people’s answers to survey questions about gender roles, such as, “Would you vote a female for President?”—might affect her workforce participation and earnings relative to men, even after she moves to another state. They studied groups of men and women who were born in one state but were living in another (focusing only on white people, to isolate gender effects from racial ones), and found that, on average, a difference of one standard deviation in the home states’ level of sexism—the difference between, say, California and Mississippi, or between Minnesota and Texas—accounted for a 0.8 percent drop in women’s participation in the labor force. The women from places with more sexist attitudes tended to earn less, too. “Where you live now matters more—but where you’re from matters a lot,” Charles told me.

The economists didn’t research why this was the case, but Charles theorized that it had something to do with the persistence of the cultural values we’re exposed to when we’re young. “My taste for a particular cuisine and my accent—there’s a little bit that I carry with me,” he told me. The same could be true, he said, of attitudes about a woman’s societal role—the age at which she should marry and bear children, for example, or the acceptability of negotiating for higher wages at work.

If this is a startling finding, perhaps it shouldn’t be. In fact, as Matthew Stewart has written in this magazine, intergenerational mobility in the U.S.—in essence, a person’s likelihood of being more financially successful than his or her parents—has declined over the past several decades. By one common measure, the relationship between a person’s financial well-being and her parents’ is stronger in the U.S. than in almost any other developed country. “In America,” Stewart writes, “the game is half over once you’ve selected your parents.” Add Charles and his colleagues’ findings, then, to the rising pile of evidence countering the idea that Americans, simply by virtue of being American, can rise above their station.



The U.S economy is in the midst of a wrenching technological transformation that is fundamentally changing the way people sleep, work, eat, shop, love, read, and interact.

At least, that’s one interpretation.

A second story of this age of technological transformation says that it’s mostly a facade—that the last 30 years have been a productivity bust and little has changed in everyday life, aside from the way everyone reads and watches videos. People wanted flying cars and got Netflix binges instead.

Let’s call these the Disrupt Story and the Dud Story of technology. When a new company, app, or platform emerges, it’s common for analysts to divide into camps—Disrupt vs. Dud—with some yelping that the new thing will change everything and others yawning with the expectation that traditionalism will win out.

But both stories often fail to capture the way that new tech actually works—and the unexpected ways it can change not only its competitors but also its entire marketplace.

Consider Airbnb. Like some of the most exciting start-ups of this century, Airbnb is a new kind of “aggregation” platform. It’s a portal that connects producers and consumers in the marketplace for accommodations—like Facebook does for content, or Amazon for commerce, or Uber for driving.

Five years ago, the Disrupt Story went that Airbnb was going to challenge hoteliers and maybe even make their business obsolete, as young people ditched Marriotts and Hiltons for the empty beds of strangers. Since then, Airbnb has enjoyed one of the more magical runs of any company founded in the 21st century. With a $31 billion private valuation, it’s the second-biggest “start-up” (if that label even still applies) in the country, after Uber. Its annual revenues are doubling by the year.

So, naturally, the hotel business is in a state of wretched suffering—yes? Quite the opposite. Last year was the best year ever for hotel occupancy in the United States. The stock prices for the major hoteliers Marriott and Hilton are both up more than 40 percent in the last 12 months.

Airbnb is a transformative travel business. But most people failed to predict the thing it would transform—for good and bad.

Let’s review what the market for accommodations looked like before Airbnb came along. Most vacation rentals were in empty second homes, often in beach, resort, and ski towns; renting them meant knowing an owner personally or working through a local agency. Meanwhile, most brand-name hotels in major U.S. cities were (and still are) near business centers, where locals might work, but rarely sleep, wake, and wander around.

Airbnb’s great contribution was to allow travelers to live as locals do—in the busy downtown residential areas, near the best restaurants, bars, and other local hangouts. Business travelers might prefer the amenities of a hotel. But what Airbnb offered was a superior simulacra of the local experience for leisure travelers—for an affordable price, which happened to support some local dwellers’ income.

Airbnb’s business took off among a particular demographic—young, urban, and relatively well off. Half of Airbnb’s bookings are made by Millennials, or those under 35 years old, and most of them are for leisure rather than business, according to the research firm MoffettNathanson. Airbnb has left an impressive mark on the way people travel to big cities: The share of American travelers using “private accommodations” like Airbnb quadrupled between 2010 and 2015, according to MoffettNathanson.

Percentage of U.S. Travelers Using Private Accommodations

So how did all of this new business not hurt hotel bookings?

First, business travelers still prefer hotels; more than 90 percent of Airbnb’s business is in personal tourism. Second, if it weren’t for Airbnb, travelers might be suffering through a terrible squeeze in hotel space. The construction pipeline of new hotels plunged after the Great Recession. As the economy recovered and travel picked up, it seemed inevitable that the prices of scarce hotel rooms in major U.S. cities were set to soar. But they didn’t. Airbnb-listed rooms vastly expanded the supply of beds for travelers—tourists and business travelers alike—to lie in. With the explosion of the private accommodations market, rooms opened up and hotel prices stayed down.

So far, this sounds like a wonderful transformation: Airbnb expanded the availability of beds for visitors, gave young tourists a more authentic taste of their urban destination, and kept prices down for all travelers.

But Airbnb's success also encouraged dubious behavior on the part of “commercial” power users—property owners who listed downtown units (especially second residences) all year long, as if they were hotel rooms. Why would would that be a problem? Open apartments occupied for much of the year by Airbnb-using travelers reduce the number of available homes to people who want to move into that building. High demand, plus lower supply, leads to higher prices. Several studies—including research from Harvard, MIT, UCLA, USC, and the University of Massachusetts Boston—have come to the same conclusion: Airbnb altogether drives up the price of rent in many neighborhoods. (It’s only fair to point out that some of the most strident conclusions came from studies sponsored by the hotel industry.)

When I asked Airbnb about these claims, a spokesperson pushed back against them in several ways, arguing that the company doesn't have a wider effect on rental prices. First, he said the vast majority of Airbnb’s users are merely renting out primary residences rather than filling otherwise vacant units with tourists. Second, he said Airbnb has worked with several cities to write rules that crack down on commercial users who try to turn their secondary residences into ersatz hotel rooms.

Indeed, Airbnb doesn't account for enough downtown housing to be the major driver of rising rents in major metro areas. But the basic economics is relatively straightforward. Airbnb isn’t just competing with hotels for travelers. It is often competing with locals for space. The company has shifted the burden of rising prices in crowded downtown areas from travelers to residents—pushing down prices for hotel rooms, while raising rents for city dwellers. Was that Airbnb’s intent? Almost certainly not. But that is the outcome, anyway, and it is a meaningful—even, yes, disruptive—one.

This outcome fits neither the Disrupt Story nor the Dud Story. Airbnb lowered prices for tourists, supplemented the income of renters, and simply made travel to major cities more fun. But upon inspection, it shares some things in common with more-controversial companies—albeit with less grave implications. Facebook and Twitter design for attention, but incidentally encourage mendacious outrage and trolling. eBay and Amazon design for open marketplaces, but incidentally encourage the frenzied resale of bulk-ordered toys around Christmas. Airbnb was supposed to challenge hotels by letting tourists pay renters. But its platform is unwittingly producing a subsidy of tourists, paid for by nonparticipating urban dwellers, who bear the cost of higher rental prices. Like just about every story these days about revolutionary tech platforms, Airbnb is a story both of democratized access to commerce and the unintended consequences of those democratizing efforts, even when they succeed on their own terms.



Amazon, JPMorgan Chase, and Berkshire Hathaway announced on Tuesday that they intend to form a new company that manages health care for their hundreds of thousands of U.S. employees, the idea being that a unified, not-for-profit entity can reduce workers’ expenses.

The surprising trio of the nation’s largest online retailer, largest bank by assets, and most famous investor (Warren Buffett, the chief executive of Berkshire) riding to the rescue of the beleaguered health system already rocked insurance stocks and thrilled health-care experts who have long dreamed of a technological solution to “bend the curve” of inexorably rising medical costs.

But it’s not altogether clear what this company will be, how much money each corporation will commit to it, or whether it is meant to eventually provide services for workers at other companies. It’s also not clear how the venture will financially benefit the three corporations.

“The ballooning costs of health care act as a hungry tapeworm on the American economy,” Buffett said memorably, in a statement. “Our group does not come to this problem with answers. But we also do not accept it as inevitable.” In other words, this is not the launch of a fleshed-out business venture so much as the public announcement of a corporate collaboration fixated on providing low-cost services and slashing the Gordian knot of ever-rising health-care costs.

Here is a brief accounting of knowns and unknowns about the new venture. The new company—operating outside all three corporations—will “provide” health care. But it is not clear whether this will be a pure insurance company or whether it will pay for its own doctors and clinics. The enterprise is supposedly going to use “technology” to lower costs. It is not clear what technology would be employed, or what costs will be lowered, or by how much. The company will be “free from profit-making incentives and constraints.” What does it mean to be free of profit-making incentives, as opposed to actual profits? It’s not clear.

While JPMorgan and Berkshire Hathaway are listed as partners in the endeavor, Amazon would seem to be the galvanizing force behind the announcement. In the last year, the company has explored several health-care businesses, by selling more medical supplies, expanding its inventory of drug products, and hiring an executive to build a possible pharmacy business. These moves have already so spooked the pharmacy and insurance industries that they reportedly pushed CVS to place a $69 billion bid for the insurance giant Aetna.

Across the economy, Amazon has become a kind of deflationary Death Star, so well-known for its high-volume, low-profit model that stocks plummet in every sector it threatens to enter. Indeed, within minutes of the announcement, shares fell for pharmacy managers and drugmakers. As of 10:30 a.m. Tuesday, large insurance companies like Anthem and UnitedHealth Group were trading down about 5 percent, while the largest hospital companies, like HCA, ticked up 8 percent. This suggests that investors believe the new health-care company will compete most directly with insurance firms and pharmacies rather than with hospitals and larger clinics. Even so, if the corporate trio really wants to bring down health-care costs, they might try to open a network of low-cost clinics throughout the country that compete with large hospitals for less-complicated care.

If health care is, as Buffett describes, a hungry tapeworm, the parasite isn’t growing as fast as it used to. The rate at which medical costs increase each year has, with some exceptions, generally declined since the 2000s. Between 2010 and 2013, the average annual growth rate in health expenditures was scarcely higher than that of GDP. As the economy picked up in 2014 and 2015, medical-cost inflation turned up again.

Consumer Price Index for All Urban Consumers: Medical Care

For Amazon to take the lead in taming medical-cost inflation continues an interesting trend in tech, with visionaries like Jeff Bezos, Bill Gates, and Elon Musk taking on the traditional roles of government, whether by spending hundreds of millions of dollars on basic research, sending rockets to space, revolutionizing infrastructure, or building new health-care companies. It might seem a bit ironic that three for-profit corporations would seek to create a nonprofit institution to do what traditionally has been done by the ultimate nonprofit institution—the U.S. federal government. Then again, at a time when libertarian corporate interests have taken over Washington, the work of governance is being outsourced, fittingly, to corporations.



Candace Thille’s mother, who had an undergraduate degree in physics and a master’s degree in mathematics, always told her that all work is honorable work, as long as you set a high standard for yourself. Her father, an electrical engineer, was the one who emphasized the importance of education: “The most important thing you can learn,” he’d tell her, “is how to teach yourself new things.”

When Thille was 11, her father quit his job working in missiles and space at Lockheed. Her parents were pacifists, and her father realized he was building systems that were being used in war. “So everybody in the family started working doing all kinds of different things to help financially support the family,” she said.

Thille has worked at Stanford University and is now Amazon’s director of learning services. I recently spoke to Thille about creating macramé plant hangers, following one’s passion while paying the bills, and lifelong learning. This interview has been lightly edited and condensed for clarity.

Lola Fadulu: What sort of work did you start doing when your father quit his job?

Candace Thille: I started doing house cleaning and babysitting. And then I was 15 when I got my first real job, which was working in retail at an arts-and-crafts store. In the arts-and-crafts store, I also learned started teaching macramé classes. Macramé is essentially the art of knot-tying to create artwork. A real popular thing was to create macramé plant hangers. I actually started my own business when I was 15, creating macramé plant hangers and selling them through the local plant shops. In building these macramé plant hangers, the knotting was fine with me, but cutting hundreds of pieces of yarn for each plant hanger was really tedious. So I built a wheel whose circumference was exactly the length of the yarn piece that I needed. I could quickly put the yarn on this wheel, spin it around, and then make a single cut off one side of the wheel. So then I'd have my hundreds of pieces of yarn, at the length I needed to build my plant hangers.

Fadulu: Were you drawn to that job because you had a passion for crafts and arts?

Thille: No, that job was because it was a job.

Fadulu: Could you tell me about one or two jobs you worked in college that were the most memorable?

Thille: One of them was I worked in the library in the government documents division. What was memorable about that was that it was so boring. Figuring out how to make something that is so fundamentally tedious and boring tolerable, because I needed the job. That was one.

And then the other extreme was I also had a job as peer sex educator, which was through Cal Hospital on campus at Berkeley. My job was to go out into the dorms and other student-living situations and hold value-clarification conversations about sexuality and decision-making about sexuality. And that job was a blast because you're a teenager or in your twenties and you're out there talking with people about sex, but also helping.

Fadulu: After college what did you do?

Thille: I graduated from UC Berkeley, and I actually immediately moved to Pittsburgh, Pennsylvania, because I was following my then-boyfriend who was in medical school in Pittsburgh. I was in a position where I was in a new place, and I needed to get a job to help financially support myself.

My first job out of college was working at a bakery and retail. I wore a pink polyester dress and my hair up, and most of the other people who worked in the bakery were 60 or 70, little old ladies. I did that, though, because we needed income.

But then I also volunteered at the local rape crisis center called Pittsburgh Action Against Rape. The reason is that I was and am a feminist, and was very much into empowering women. I started volunteering there, and shortly after I started volunteering there, their education program coordinator went out on maternity leave, and so I stepped in as the education program coordinator. Then she decided not to come back, so it was my job.

Then I totally expanded the program, and I developed trainings for hospital staff on how to do evidence collection and how to support a person who's been sexually assaulted. I developed and conducted trainings for the local police, and then the county, and then the state police, on how to interview and support people who had been sexually assaulted. Then I developed and delivered education programs kindergarten through high school in schools all over Allegheny County on child sexual abuse. So I had to redirect people’s attention away from the stranger-danger stuff that they were teaching to help getting children skills around the fact that there’s a higher probability that they might be sexually abused by people that they know.

Fadulu: How did you go from those positions to Amazon?

Thille: When I was still in my early 20s, I moved back to the Bay Area and took a temp job as a bookkeeper. I taught myself bookkeeping because the temp rate for bookkeepers was better than the temp jobs for receptionist—but I would take any temp job that came up. I started as a half day temp receptionist fill-in at a small management consulting company that focused on leadership development and worked at that company for 18 years, starting as the half day receptionist and working my way up to vice-president and managing partner.  It was at that company where I first designed a blended e-learning experience on coaching. I saw the potential for using technology and the affordances of the science of human learning to accelerate human learning, which ultimately has become my field of research and practice and passion. Following that passion did not come without a cost. The first year I worked at Carnegie Mellon, where I founded and directed the Open Learning Initiative (OLI), my total annual income was less than what I had paid in federal income tax the year before as a VP and partner in a corporate consulting firm.

Fadulu: You now have experience in both higher education, having worked at Stanford, and the business side, as the director of learning sciences at Amazon. I wonder if you can talk a little bit about what's important for young people to know about the skills they'll need for the future?

Thille: I think there's a lot of pressure on young people who feel they have to be perfect immediately. Nobody is. I think the world would actually be a lot better if we were all a lot more humble and didn't feel like we have to present as perfect all the time. What's interesting is how the world of work is being changed by technology. We used to think about computers or technology only doing things that we would directly instruct the computer to do, just faster. The sort of work that we are always imagining being displaced by technology would be predictive, repetitive work. But now with machine learning, I think a challenge in our time is to continuously examine how we use machines and the large amounts of data to augment human decision-making—really exploring where the boundaries are between when a machine and when a human makes decisions.



SEATTLE—I entered Amazon Go, the company’s checkout-less convenience store in Seattle, at 10:23 a.m. Monday and spent precisely 11 minutes and 59 seconds browsing before I walked out with a sandwich and a yogurt cup. This information was available because the moment I scanned a personalized QR code at the store’s subway-style gate, myriad cameras on the ceiling started tracking me. Every time I picked up an item, it was added to my virtual cart; when I placed the item back on the shelf, it was removed. A couple minutes after I walked out, Amazon charged $6.61 to the credit card linked to my account. The receipt included the time-spent-shopping tidbit, presumably to impress customers with how little time it took to buy lunch.

Just as striking as the shopping experience was the scene outside, where there’s evidence that the company famously seeking a second home city is still gobbling up its first. South of the store was territory the company has already colonized—gleaming office towers where 40,000 employees work, expensive apartments where many of them live, glassy domes filled with rare tropical plants. Across the street, four cranes sprouted from a hole in the ground that will eventually anchor another office tower. Construction noise was ceaseless. In front of the store, two masked protesters held a banner that proclaimed, “YOUR FUTURE IS TOTAL SHIT.”

Given what’s already known about automation, labor economics, and Amazon founder Jeff Bezos’s appetite for expansion, there’s little reason to believe the company won’t scale up the innovations tucked into its new convenience store. By further easing the buying process and collecting even more consumer data, Go’s underlying technology is a logical next step in Amazon’s brick-and-mortar retail pursuits.

Go is the latest foray in the company’s relentless push to minimize friction in retail transactions. “All the selection, all the convenience, low prices. And they get it to you in three days, then two days, then one day, then same-day, then same-hour,” says Mark Mahaney, a technology analyst with the financial firm Royal Bank of Canada. “Amazon’s done a lot of things to remove friction from the online shopping experience. The question is, can they do it with the offline store?”

The first Go shoppers on Monday were notably pleased, even entertained, with their experience. “It was a lot of fun,” Melody Coleman, a freelance user-interface designer who lives in Seattle, told me. “You could just grab stuff and walk out. It’s such a foreign concept to me ... It feels like I’m shoplifting.”

Once the novelty wears off, that shoplifting sensation will in theory become an appreciation of speedy transactions. In exchange for that convenience (which could also entice greater spending), Amazon will surely reap vast amounts of data. Amazon won’t say exactly what its cameras monitor, but it says the camera system is inspired by the same technology that guides self-driving cars. If the sophistication of Amazon’s retail sensors comes close to that of automotive systems that might produce four terabytes of data per day, then Amazon will surely gather insights more detailed than just shopping duration and items removed. Should a customer, for instance, grab a six-pack of microbrew beer, only to return it a minute later and exchange it for cheaper Rainier, Amazon might learn that the customer is a price-sensitive shopper and perhaps send them coupons for higher-margin items.

It’s easy to imagine Amazon Go’s technology in Whole Foods, which Amazon bought for $13.7 billion last year (a small section of the Go store already sells some products from the grocer’s Whole 365 line), but Sucharita Kodali, an e-commerce analyst at the market-research firm Forrester, says the camera setup could be too hard to scale, at least for now. A grocery store might be 100 times larger than the 1,800-square-foot Go store, and far more customers and products would need to be monitored simultaneously.

There are also issues with pricing. “Fresh produce, meats—a lot of that is sold on a weight basis, not a unit basis,” Kodali says. “I guess if you get to selling everything on a unit basis and standardize everything, maybe it could work. But you would have to significantly reshape your packaging and supply chain ... to make your pricing really consistent.” Likelier expansions, she says, would be bringing the technology to smaller Amazon retail outlets like its book stores, or licensing the technology to, say, fast-casual restaurants or gas stations.

Kodali is more confident that elements of Amazon’s technology will change the retail labor market—particularly for cashiers. “You won’t need as many of them, and the ones left behind will be forced to wear more hats,” she says. That’s not a groundbreaking notion; workers at Trader Joe’s have several duties that extend beyond the register. Yet Amazon certainly has incentives to further streamline its labor model. Labor is the biggest cost supermarkets face besides the food they sell, and grocers are already taking steps to make cashiers obsolete via self-checkout stands. Furthermore, brick-and-mortar success might be essential to sustaining Amazon’s swift growth, as 90.9 percent of U.S. retail sales still takes place in stores.

This has some worried about the economic implications of Amazon Go’s technology becoming mainstream. Cashiers are economically vulnerable—their median pay was about $20,000 in 2016—but numerous; 3.54 million Americans hold the job, second only to the number of retail salespeople. The repetitive nature of the job leaves it particularly susceptible to automation; researchers at Oxford University have concluded there is a 97 percent chance cashier jobs will be automated, and that was back in 2013.

Those who shopped at the Go store on opening day were pondering what the technology would mean for workers who hold low-skill jobs. Joy Carter, a service-industry worker and one of the masked protesters, said Amazon’s business model was “built on exploitation of low-paid workers,” adding, “It’s not going to be anything good for the working class.” (Amazon declined to answer questions about its new store, and did not respond to a request for comment about its pay practices.)

Others were more sanguine. Every non-protester I interviewed—those waiting in the block-long line were, of course, a self-selecting population—saw the replacement of cashier jobs as an inevitability of technological progression. Coleman, the designer, said low-skill jobs will be eliminated no matter what Amazon does; Andrea Guichard, a college student who drove about an hour to attend the store’s opening, said automation and machine learning will create more jobs than they destroy. Jeremy Ickes is a flagger for GLY Construction, the contractor that has built many of Amazon’s office towers. While guiding concrete trucks past the queued shoppers, he explained that his job wouldn’t be possible without Amazon. “They provide thousands of jobs, in multiple careers. It’s not just computers,” he said. “All these buildings have to be maintained. There’s construction all the time.”

Alison, a consultant who declined to give her last name, felt the protesters, like the city they live in, would also be swept up by Amazon’s growth. “I don’t know what they’re protesting,” she said. “They’ll likely end up working at Amazon in the future, too.”



In January, the U.S. economy added 200,000 jobs while the unemployment rate held steady at 4.1 percent, according to the Bureau of Labor Statistics. The number slightly beat analysts’ expectations: Economists surveyed by The Wall Street Journal anticipated around 177,000. But the biggest story of the month was the uptick in wages, which grew 2.9 percent from the previous year—marking the biggest jump in earnings since 2009.

Slow and meager advancement in wages has been a concern in what is otherwise a mostly healthy economy. In 2018, economists hope to finally see some meaningful, long-term growth on this front. Earnings increased by about 2.5 percent in all of 2017. That performance is not especially impressive for an economy that’s been growing for the better part of a decade. January’s performance may indicate that this year will be stronger. Over the month, earnings ticked up by 9 cents, making the 12-year growth rate 2.9 percent. That’s the greatest wage growth the U.S. economy has seen since May 2009.

Still, labor-force participation remained at 62.7 percent for the fourth straight month—the lowest levels seen since the 1970s. And the share of underemployed workers—those who are working part-time when they’d rather be working full-time—also ticked up slightly, to 8.2 percent from 8.1 percent.

At the end of 2017, the president touted a milestone for black unemployment, which ticked down to its lowest level on record—6.8 percent. But that level was still significantly above that of whites, and while the gap between the two groups had narrowed, black unemployment still remained nearly two times as high. In January, the unemployment rate for black Americans went back up, landing at 7.7 percent. In the meantime, unemployment for whites ticked down further, to 3.5 percent—expanding the disparity once again.



In a recent survey, America’s mayors named housing, and housing affordability, as the number-one problem facing their cities. This concern was not only voiced by mayors of expensive coastal cities, but in diverse communities across the nation. The biggest culprit, according to a large and vocal chorus of urban theorists and economists, is outmoded and overly restrictive zoning and building codes—not to mention politically powerful “not in my backyard” (NIMBY) groups—which hold back new housing construction.

But according to a report released Thursday by the urban-housing economist Issi Romem of Buildzoom, a platform for finding contractors, many urban cores are actually developing and growing denser. And lots of housing continues to get built at the suburban periphery. Romem argues that America’s real housing problem—and a big part of the solution to it—lie in closer-in single-family-home neighborhoods that were built up during the great suburban boom of the last century, and that have seen little or no new housing construction since they were initially developed.

Overall, the picture looks something like this: There are pockets of high-density construction at the urban core and rapid building along the metropolitan periphery, but lagging growth in the dormant suburban interior. As Romem puts it:

In the past, virtually every patch of land in the metropolitan U.S. continually sprouted new housing, but this is no longer the case. In recent decades, residential construction has become increasingly confined to the periphery of American metro areas, while a growing swath of the interior has fallen dormant and produces new homes at a negligible pace. At the same time, a tiny fraction of the land area, scattered in small pockets throughout the metropolitan landscape, is responsible for a growing share of new home production, primarily in large multifamily structures.

The development of what was once the great suburban crabgrass frontier (to use the historian Kenneth Jackson’s evocative phrase), providing upward mobility and a path to a better life in the 1950s, ‘60s, and ‘70s, has essentially been choked off. The urban core is growing denser, while the inner-ring suburbs are increasingly dormant, and in many cases distressed.

The following maps show the evolution of this process across greater Los Angeles over the past half century or so. On the maps, light blue represents areas where new single-family construction predominated; orange indicates areas of medium-density developments, of two to 48 units; red shows areas of large multi-family construction, of 50 units or more; and dark blue indicates virtually no construction at all.

The first map shows L.A.’s development at the dawn of the postwar crabgrass frontier, 1940 to 1960. The great majority of the map is filled with light blue, indicating single-family-home construction, with orange areas of small to midsized multifamily construction in and around the urban core.

Development in Los Angeles, 1940–1960

There is a still a great deal of light blue on the second map, which covers the years 1960 to 1980, and shows these same crabgrass suburbs but stretching out farther into the periphery. There are small specks of red near the urban center, and somewhat larger areas of orange stretching out from the core.

Development in Los Angeles, 1960–1980

But in the 21st century, the pattern changes dramatically. Now the great bulk of the map is dark blue—vast swaths of no construction. More than half of L.A.’s built-up areas have hosted no new housing construction this decade. While most urban theorists complain about land-use restrictions in the urban core, and urban NIMBYs, there are considerable areas of red and orange in downtown L.A., Hollywood, and large parts of the Westside and the San Fernando Valley. The areas with no new housing tend to envelop large swaths of older, closer-in suburbs. From this map, restrictive land-use policies and NIMBYism appear to be more a problem of the old crabgrass suburbs than of the inner city.

Development in Los Angeles, 2000–2016

While L.A. provides a particularly useful illustration of America’s dormant suburbs, it is far from unique. Romem’s study shows how this pattern fits virtually all U.S. metropolitan areas. Over time, a larger and larger share of their land is taken up by dormant single-family neighborhoods that are failing to add any new housing.

Still, there are important differences between metro areas, according to the study. Large Sunbelt cities, such as Atlanta, Dallas, and Phoenix, have demonstrated a much greater capacity to expand outward at a low density, while their cores gradually get denser. Lagging Rust Belt cities like Cleveland and Buffalo have seen much less growth out across their suburban periphery, and modest or minimal increases in density in their urban cores as well. Many expensive coastal urban areas, with the Bay Area being the prime example, have slowed their outward expansion due to policies meant to curb sprawl. Nonetheless, all these different types of cities have large areas made up of dormant suburbs with little or no new construction.

The reality is that most of the housing stock and most of the land area of America’s metro areas is made up of relatively low-density suburban homes. And a great deal of it is essentially choked off from any future growth, locked in by outmoded and exclusionary land-use regulations. The end result is that most growth today takes place through sprawl.

While urban density can house some people—mainly affluent and educated ones—the bulk of population and housing growth is shifted farther and farther out to the exurban fringe. That leads to more traffic and longer commutes, and the social and environmental consequences that flow from them, as this old suburban-growth model is stretched beyond its limits.

But if America’s dormant suburbs are a big part of its housing and growth problem, they can also be part of the solution. Relaxing zoning rules in these neighborhoods would spread population growth more equitably and sustainably across a metro, relieving the pressure of rising housing prices and gentrification around the urban core, and unsustainable growth at the periphery.

“The dormant suburban sea is so vast that if the taboo on densification there were broken,” Romem writes, “even modest gradual redevelopment—tearing down one single-family home at a time and replacing it with a duplex or a small apartment building—could grow the housing stock immensely.” Many of these suburbs are located relatively close to job centers or along major transit lines. They are the natural place to increase density.

There are some signs cities may be moving in this direction. After being considered untouchable for decades, single-family zoning restrictions are finally beginning to be reconsidered. In California, state legislators have proposed a bill that would do away with all single-family zoning restrictions in areas that are in close proximity to high-frequency transit. Scott Wiener, one of the bill’s authors, has said this legislation would help the state produce more “missing middle” housing—modest apartments and duplexes that are far cheaper to build than steel-frame high-rises common in downtown areas. Massachusetts is also considering zoning reforms that would make housing production easier. And around the country, “accessory dwelling units”—small homes in the backyards or basements of single-family homes—are gaining in popularity.

The great cities of the 21st century not only need more density in their urban cores, but more distributed density—the kind of continuous density that allows great global cities like London, Tokyo, Paris, and New York to scale and accommodate larger and larger populations without expanding ever farther outward. For future-oriented cities, the cranes dotting downtown skylines may be only the beginning.

This post appears courtesy of CityLab.



This is the story of a small-town, publicly-owned hospital that, after thriving for decades, is struggling and now in all likelihood about to be appended to a large regional health-care system. The tale of Berger Municipal Hospital is, like that of many sectors of the American economy, one defined by industrial consolidation and the costs that come with it. The story begins in 1929. That year, the city fathers of Circleville, Ohio, in the south-central part of the state, dedicated the town’s new hospital, funded partly with money willed by a local patron named Franklin Berger.

The hospital opened at a time when other small towns had been building them, too. Turn-of-the-century medical breakthroughs such as disinfectants, sanitary surgery, and new technology like X-ray machines (invented in 1895) helped transform hospitals from last-resort warehouses for the sick poor (the rich were usually treated at home by private doctors) into places where all members of a community would go to receive care. Mothers began to deliver babies in hospitals instead of at home, and birthing (and, in more recent years, prenatal care) became big business for community hospitals. Not only would Berger help improve the health of Circleville residents, but it was expected to be a sign of modern welfare that would attract business executives and workers. As was typical, Berger was owned and operated by the city, and then, a generation later, jointly by both the city and surrounding Pickaway County.

Last November, however, Circleville’s voters chose another direction, one that, in other places, has resulted in an economic hit to the community—mostly in the form of job losses and stagnant wages—as well as a lowered quality of care. At the urging of city and county leaders, and Berger’s administrators, residents voted to allow local politicians and the hospital’s board to begin a process to turn Berger, one of the last publicly owned and operated hospitals in the state, into a nonprofit private corporation. Following that, Berger would most likely be integrated into a larger regional system, probably the Columbus-based nonprofit Ohio Health, with which Berger has an ongoing relationship. The hospital and the local leaders campaigned hard for that approval, but not because it was the ideal future they envisioned. They feared that Berger wouldn’t survive any other way.

Hospitals have been struggling—especially independent public and/or nonprofit hospitals located in smaller cities and rural towns. Last year, for example, the National Rural Health Association, a nonprofit, estimated that 673 rural facilities (with a variety of ownership structures) were at risk of closure, out of over 2,000. And with the new tax legislation, and events like the merger of the drugstore chain CVS and the insurer Aetna, the turmoil looks to get worse. In response, stand-alone nonprofit hospitals have been auctioning off their real estate to investors, selling themselves to for-profit chains or private-equity firms, or, like Berger, folding themselves into regional health systems.

The implications of those moves can be profound, as consolidation can hurt hospitals and the smaller cities and towns they’re located in. Not only are community hospitals vital to many places’ social fabric and image of themselves, but they are often the largest local employers now that manufacturing jobs have faded. “When I started here in 1999, we were coming off losing multiple thousands of jobs to globalization,” Tim Colburn, Berger’s CEO, says. Berger is now the biggest employer in Circleville, generating an estimated $50 million a year of economic activity in the area, including wages, the purchase of goods and supplies for the hospital, and follow-on spending, such as when hospital visitors eat in local cafes.

Fairfield Medical Center (an independent nonprofit hospital) in nearby Lancaster, Ohio, is the largest employer there. Bryan Hospital (also an independent nonprofit) is the largest employer in Bryan, Ohio, in the northwest corner of the state. The same is true of hospitals in many communities across the country: Health care in the U.S. accounted for $3.2 trillion in spending (about $9,900 per person) and 17.8 percent of GDP. Whereas a good local hospital was once seen as a way to attract employers, such hospitals have now become the primary employers. “And I don’t say that with any pride,” says Phil Ennen, the president and CEO of Community Hospitals and Wellness Centers, which includes Bryan.

Small nonprofit or city-owned hospitals seem like public assets, like roads or a sewer system. But they’ve always been hybrids—part social-welfare organization, part business. “It is that contradiction, that health care is both a public service and a private profit center, that our system has never resolved,” Beatrix Hoffman, a historian at Northern Illinois University and the author of Healthcare for Some: Rights and Rationing in the United States Since 1930, explains. “We’ve never had that moment every other country has had when they decided to have universal care. We haven’t, and so we have this contradiction continue.”

“Hospitals walk this fine line,” adds Nancy Tomes, a historian at Stony Brook University and the author of Remaking the American Patient: How Madison Avenue and Modern Medicine Turned Patients Into Consumers. “The nonprofits have to look like they’re a benevolent public trust, and yet, on the other hand, they have to behave like a local car dealership,” promoting their brands so they can make money. That balance is becoming  difficult to sustain as for-profit hospitals attract well-to-do (or well-insured) patients who can pay for expensive procedures, Tomes says—“Give me those cardiac bypasses!,” she jokes, is the cry of the for-profits. The nonprofits then feel pressure to keep up so they don’t lose their market.

Hospitals like Berger need to make a margin—a little profit—so they can plow cash back into facilities, increase wages, and hire new employees. Four percent is considered a healthy margin. Three percent is fine. Ennen, a former chairman of the board of the Ohio Hospital Association, the trade group for government-owned, for-profit, and nonprofit facilities in the state, estimates that only about one-third of Ohio hospitals are comfortably in the black. Another third have margins of less than 2 percent, and the remaining third are losing money. Berger makes about 1 percent. The same goes for Bryan. Last August, the credit-rating agency Moody’s downgraded the Lancaster hospital’s $92.8 million in outstanding bonds—meaning analysts thought the hospital was at greater risk of not being able to pay its debts. Moody’s cited operating losses for the first six months of the 2017 fiscal year and “expectations that performance will remain modest.”

One reason why performance may remain “modest” is that such hospitals, like many others in the U.S., live off of government payouts. The United States relies on a two-track system to pay for medical care: private and employer-subsidized health insurance, and federal and state health-insurance programs like Medicaid (the federal health-insurance program for low-income people) and Medicare (which covers Americans over 65). (Military veterans have the additional option of the Veterans Health Administration system.) As of 2015, Medicaid and Medicare accounted for 40 percent of personal health-care purchases, private insurance 35 percent. And since rural residents account for an outsized portion of Medicare expenditures, it’s no surprise that roughly two-thirds of the revenue for all three of these Ohio hospitals come from Medicaid and Medicare. “I live in a conservative community, and I tell them, ‘If you’re opposed to socialized medicine, you are way too late,’” Ennen says, referring to how much public money hospitals already receive. “That horse left the barn a long time ago.”

Ohio’s governor, John Kasich, unlike some other Republican governors, forced a reluctant legislature to adopt Medicaid expansion as provided for under the Affordable Care Act (ACA). In 2008, 36.1 percent of Ohio residents ages 19 to 64 who lived at or below 138 percent of the federal poverty line had no health insurance. After expansion, that percentage fell to 14.1 percent. No wonder Ennen calls expansion a “godsend”: As more people gained health insurance, the hospital swallowed fewer unpaid bills, and more people were able to use the facility in the first place. Small-town and rural hospitals are also supported by Medicare “extenders”—extra payments designed to help them survive. There’s a low-patient-volume extender, for instance, a rural-ambulance-service extender, a Medicare-dependent-hospitals extender. The payments that flow from the Children’s Health Insurance Program (CHIP) are another important source of revenue.

The new Republican tax legislation threatens all these. The tax cuts eliminate the ACA’s individual mandate. Healthy younger people may drop insurance, helping to drive premiums for everybody else skyward. Then, even those who want insurance may be forced out of it if they can no longer afford it. After the ACA was passed in 2010, some employees, like those who did not work enough hours to qualify for ACA-mandated employer-provided insurance, shifted onto newly expanded Medicaid. But both Medicaid and Medicare face big cuts under the new law, with possibly more to come. “I said to the Republican House delegation [from my area], ‘You think these people can get off Medicaid, find jobs, and won’t need to be on Medicaid anymore?’” Ennen recalls. “I do not disagree there are jobs out there for able-bodied people, but there’s no health care tied to those jobs anymore. You’re asking people to take jobs and lose health-care coverage.” And even if they are covered with a new job, Ennen argues, often the employee’s share of the payment can be far too expensive. So they’ll do without, and not use his hospital, or use it even if they’re unable to pay the bill.

In a last-minute deal, Congress extended the funding for CHIP through March, easing the immediate concern of a cash crisis, but doing nothing to end the uncertainty. (And there are concerns that funds might run out sooner than that.) If CHIP and the extenders were to go away, Ennen says, that could mean a $2.3 million yearly loss to Bryan Hospital. “I have spent the past 96 hours trying to make people in D.C. realize they are about to do something that will really hurt,” Ennen told me when we spoke as the final bill was being hashed out in the House and Senate.

Consolidation, naturally, is sweeping the industry partly as a defense against this turmoil and partly as a way for hospitals to gain some negotiating power. According to the economist Martin Gaynor of Carnegie Mellon University, there were 1,412 hospital mergers between 1998 and 2015, and 561 in just the five years from 2010 to 2015.

Health-care consolidation in general worries Ennen as his hospital becomes an ever smaller fish in a pond filled with whales. “The more health care moves towards consolidation and the corporate world—well, Aetna sends letters out telling us what they will do with zero input from us,” Ennen says. “CVS will continue that. It’s hard for me to figure out how to have a conversation with CVS or Aetna. I feel less empowered today than I did yesterday.” Ennen doesn’t know how exactly the CVS-Aetna merger will affect his facility, and Troyen Brennan, the chief medical officer for CVS Health, says Ennen shouldn’t worry that the merger will change Aetna’s position in the insurance marketplace vis-a-vis hospitals. Aetna, Brennan argues, won’t have any more market power than it did before. But the merger is symbolic of what Ennen fears will be a health-care oligopoly that leaves his own hospital with less control over its own fate.   

Given this landscape, it’s no wonder Circleville’s hospital chose to join a larger health group. Colburn, Berger’s CEO, believes that’s the only way to maintain a local hospital that can serve local needs. While a deal hasn’t yet been worked out, Berger will likely be leased to Ohio Health. Ohio Health’s payment of the lease will take the form of investments in facilities, new specialists, and training and education for staff. That way, at least Berger could remain somewhat autonomous and local.

Other hospitals, including some in big cities, have chosen different paths when they’ve faced some of the same pressures. Some have used sale-leasebacks to real-estate investment trusts (REITs). In a sale-leaseback, a hospital sells its facilities, and then leases back those same facilities from the REIT. Such a deal can yield a lot of cash, but, according to Eileen Applebaum, a senior economist at the left-leaning Center for Economic Policy and Research, “The rent payments reduce the operating surplus of the hospitals, many of which already faced challenging economic circumstances.”

Some hospitals have been bought in leveraged buyouts by private-equity shops. For example, in 2008, Capella Healthcare, a chain of hospitals owned by the private-equity firm GTCR LLC, leased the city-owned hospital in Muskogee, Oklahoma. It subsequently executed a deal with a second facility, Muskogee Community Hospital, in which its lease payments are put toward eventual ownership of the hospital. The hospitals changed hands again when a REIT, Medical Properties Trust, purchased Cappella for $900 million. In April of last year the hospitals were flipped a third time when RegionalCare Hospital Partners, a chain owned by the private-equity giant Apollo Group absorbed Capella in a $650 million deal.

This merging, semi-merging, and buying out is of a piece with what’s been happening to airlines (Delta-Northwest and United-Continental), silicon chips (Broadcom–Qualcomm–NXP), and telecommunications (AT&T–Time Warner). Hospitals, however, are different. Consumers don’t usually pay directly for most of the expense—insurance companies or governments do. And while the same kinds of cost-saving plays—“synergies”—used in other consolidating industries can be run with hospitals, such maneuvers can benefit investors far more than the commonweal.

Increasing industrial concentration can work to the detriment of hospital workers, patients, and communities. Workers’ wages have stagnated or fallen as more hospitals have been taken over. As Ennen points out, any acquirer of Bryan Hospital would likely outsource jobs like food service and janitorial to contractors as a way to lower expenses and boost margins. Billing would be sent to some corporate headquarters far away. Agency nurses could pick up more hours from full-time nurses.

Also, property could be “monetized.” That’s exactly what Cerberus Capital Management did when it bought a small chain of community hospitals in the Boston area called Caritas. Cerberus, founded by Stephen Feinberg, an advisor to Donald Trump, created Steward Healthcare System in 2009 to buy Caritas and then squeezed cash out of Caritas’s assets through sale-leasebacks and other financial engineering, according to a report by Eileen Applebaum.

Exactly what all these maneuvers did for Steward’s balance sheet is still a little murky, and it did not respond to a request to answer questions. (The company is currently in a feud with the state of Massachusetts for not releasing financial information as required.) But it’s clear that investors in for-profit hospitals are finding it difficult to make money, especially when the hospitals are strapped with debt from executing financial moves such as issuing high-interest junk bonds and then using that pricey debt to buy facilities. Even big operators like Tenet Healthcare and Community Health Systems have struggled.

Consolidation can drive costs up and quality of care down. Carnegie Mellon’s Gaynor says costs can rise 20, 30, sometimes 50 percent after consolidation. “If the reason for your merger is to enhance your leverage with insurers, you’re not focused on doing better,” Gaynor says. “So guess what? You don’t.”

A 1999 study by Daniel Kessler and Mark McClellan found that “treatment of [heart-attack] patients in the least-competitive areas became significantly more costly than treatment of [heart-attack patients] in competitive areas.” More competition, they found, “had the potential to improve [heart-attack] mortality by 4.4 percent.” When Gaynor and his colleagues studied hospitals in Britain’s National Health Service after a series of 2006 reforms introduced more competition, they found that the more concentrated the market, the poorer the quality of care.

But the deepest scars of consolidation can be in the communities that have long hosted independent hospitals. If one closes, for example, babies are no longer born in town, and mothers may have to drive longer distances for prenatal care. And when a hospital becomes the largest employer in a town, it takes on the civic burdens that may have once been borne by a large business. Ennen’s board, he says, feels a deep commitment to buck the trend and remain independent. He says the board tells him, “Employ as many as you reasonably can. Let’s churn the economy for the community we serve.” And so he does. He’s just not sure how long he can keep doing it.



Consider two American children, one rich and one poor, both brilliant. The rich one is much more likely to become an inventor, creating products that help improve America’s quality of life. The poor child probably will not.

That’s the conclusion of a new study by the Equality of Opportunity project, a team of researchers led by the Stanford economist Raj Chetty. Chetty and his team look at who becomes inventors in the United States, a career path that can contribute to vast improvements in Americans’ standard of living. They find that children from families in the the top 1 percent of income distribution are 10 times as likely to have filed for a patent as those from below-median-income families, and that white children are three times as likely to have filed a patent as black children. This means, they say, that there could be millions of “lost Einsteins”—individuals who might have become inventors and changed the course of American life, had they grown up in different neighborhoods. “There are very large gaps in innovation by income, race, and gender,” Chetty told me. “These gaps don’t seem to be about differences in ability to innovate—they seem directly related to environment.”

The discrepancy in who gets patents is not the result of innate abilities, Chetty and his team, Alex Bell of Harvard, Xavier Jaravel of the London School of Economics, Neviana Petkova of the U.S. Treasury Department, and John Van Reenen of MIT, conclude. Children from many different backgrounds excel in math and science tests in third grade, for instance. But it’s the wealthy children who do well in math and science that end up getting patents. Why? Because they have more exposure to innovation in their childhood, the researchers say. This exposure comes mostly from interacting with people who are themselves inventors. If young kids know people who are inventors, or hear conversations at the dinner table about research and innovation, they’re more likely to become interested in pursuing careers in that field, Chetty told me. “Opportunity broadly, and exposure to innovation in particular, are really the keys to increasing innovation,” he said. Chetty, for instance, grew up in a family of academics, and overheard conversations about science and making discoveries, which, he says, influenced his decision to pursue a career in academia.

Inventors Are More Likely to Come From High-Income Families

Aaron Hertzmann, who is now a principal scientist at Adobe Systems, has eight patents. He grew up in Palo Alto, where he had a computer before he was 10 years old. He had a lot of exposure to inventors as a child—his father was a “tinkerer,” Hertzmann told me, and his stepfather was an academic in the field of computer science. “He exposed me to approaching math as something to explore, rather than it just being a homework assignment,” Hertzmann said, about his stepfather. Hertzmann and his mother would tag along to his stepfather’s conferences in places like Greece, meeting other academics and hearing them talk about their work. From that, the idea bloomed in Hertzmann’s mind that academia, and specifically math and science, were areas where he could have an impact. When he graduated from college, his stepfather guided him along the process of applying to study for a Ph.D. Hertzmann, now 43, has a Ph.D. in computer science, and develops new ideas and algorithms at the intersection of art and computer science.

Indeed, exposure to certain specific fields makes children more likely to pursue a career, and a patent, in those fields, the researchers found. This is how they know that exposure, in addition to neighborhoods, is important to innovation: It would be unlikely that growing up in a good neighborhood would inspire many children to patent in the same small field.  People who grew up in Minneapolis, where there are many medical-device manufacturers, were especially likely to get patents in medical devices, for instance. Among people living in Boston as adults, those who grew up in Silicon Valley were especially likely to patent in computers. Children whose parents have patents in a specific field—say, antennas—are also likely to patent in exactly the same field as their parents did.

Women who grew up in an area where women held a higher share of patents in a certain field were more likely to themselves get patents in that area when they grew up. Strikingly, it was especially important for children to see people who looked like them as innovators for them to pursue the same career path—girls in an area with a lot of male innovators wouldn’t necessarily envision themselves in the same career, while boys would. If girls were as exposed to female inventors as boys are to male inventors, the gender gap between male and female inventors would fall by half, the researchers estimate. (They find that 82 percent of 40-year-old inventors today are male.)

These findings have big implications for the state of the U.S. economy, which has seen innovation decline in recent decades. Innovation is often measured by what’s known as “total factor productivity,” which essentially tracks advances that have been made in using existing resources to increase output. Prior to 1973, total factor productivity increased at an annual rate of 1.9 percent—but since then, that growth rate has fallen to 0.7 percent, according to the Brookings Institution. Innovation is central to economic growth, Chetty says. About half of U.S. annual GDP growth is attributed to innovation. Innovation, says Chetty, is what allows people to live richer, healthier, and more productive lives.

Much of the past work out of the Equality of Opportunity project has been motivated by ideas about justice, and the idea that everyone, regardless of where they are raised, should have a fair shot at the American Dream, Chetty told me. But these results indicate that equality of opportunity is important for another reason too: It makes the economy stronger. “Opportunity might be vital for economic growth even if you don’t care about inequality or fairness concerns,” Chetty said. “If you give kids from lower-income families better training and better opportunities, maybe they would end up contributing more to the economy and that would help everyone essentially.” Chetty and his team estimate that if women, minorities, and children from low- and middle-income families invented at the same rate as white men from high-income families, there would be four times as many inventors in America as there are today.

Chetty and his team came up with these results by linking patent applications in the U.S. between 1996 and 2014 to federal income tax returns to create a dataset of 1.2 million inventors. (The study uses patents as a way to measure an individual’s contribution to innovation.) They tracked inventors’ lives from birth to adulthood to determine who becomes an inventor. They then linked data on math test scores from third to eighth grade from children who attended New York City public schools to see if the differences in who got a patent could be related to innate ability (they aren’t). They then showed that children who grew up in commuting zones with higher patent rates are “significantly” more likely to become inventors than children who did not. They also showed that children from both low-income and high-income families who attend universities like MIT go on to patent at relatively similar rates, suggesting that it’s factors in a child’s earlier life that determine whether they go on to patent.

This follows on earlier research from the Equality of Opportunity project that shows that growing up in an impoverished area can hurt a child’s chances of achieving many of the pieces of the American Dream. Living in certain neighborhoods makes it less likely that a child will attend college, that they’ll earn more than their parents did, and that they’ll postpone having children until they marry.

This paper’s results suggest that policies that increase exposure to innovation childhood could go a long way in stimulating economic growth. Internships or mentorship programs could link children interested in math and science with innovators, for example, which might make them more likely to pursue careers in that field. Integration could also help—if children have exposure to more types of people, the people they think of as their peer group changes, and they might be more likely to pursue a career that is dominated by people who don’t look like them. That will help them succeed individually, and it could have a positive effect on the economy as a whole.



In November, the U.S. economy added 228,000 new jobs and the unemployment rate remained unchanged at 4.1 percent, maintaining the lowest rate since 2000.

Last month’s additions, which were largest in the industries of manufacturing, professional services (everything from doctors to architects to lawyers), and health care, beat the 195,000 added jobs that economists were expecting, according to Bloomberg. The government’s monthly report confirms that the economy has shaken off the temporary slump caused by large, destructive hurricanes in the South earlier this year. (The effect of hurricane damage on Puerto Rico’s economy is not counted in the jobs report.)

November’s report shows a strong positive trend for 2017, particularly in job growth and the unemployment rate. This year, the U.S. economy will add over 2 million jobs.

But despite the continued growth, economists are still worried about other economic measures. The labor-force participation rate remained at 62.7 percent, which is still low by historical standards. And while average hourly wages ticked up by 5 cents, to $26.55—a 2.5 percent increase over when the year started—wage growth remains relatively sluggish, especially for a time when the economy overall is getting stronger.

And then there are questions about how the GOP’s tax bill could affect the labor market. The Trump administration and Congressional Republicans have said that their tax-reform plan will boost wages, allow corporations to invest more in workers and businesses, and help bring companies back from overseas. But, as my colleague Annie Lowrey wrote recently, many experts are skeptical of the bill’s ability to deliver on those promises—particularly when it comes to the job market.

Still, the mostly strong jobs report could provide the Federal Reserve with a reason to raise interest rates when the board meets next Wednesday.



On a sunny morning in June, a middle-aged lawyer named Yoshimasa Obayashi heard his telephone ring once, and nearly ring again, before he rushed to snatch the phone’s receiver from its cradle. It was an unexpected call, from an unknown caller, who confessed that he feared he was working himself to death. In Japan, this sentiment can be expressed using a single word: Karōshi, or “death from overwork,” refers to fatalities from heart attacks, suicides, and other health issues resulting from the stress and fatigue of long hours spent on the job.

In 1988, at the height of Japan’s economic “bubble years,” a group of doctors and labor lawyers launched Japan’s first telephone hotlines dedicated to curbing karōshi. They published their office telephone numbers in pamphlets, and later online, as a means of offering free consultations to at-risk workers, who typically called the volunteer doctors, and bereaved family members, who usually reached out to lawyers like Obayashi for help with compensation claims.

During the summer of 2000, corporate bankruptcies drove hundreds of run-down salarymen to call the hotline each day. By that time, Japan’s government acknowledged just 100 to 200 karōshi cases each year, though Hiroshi Kawahito, a lawyer at the National Defense Counsel for Victims of Karōshi, told me he doesn’t believe that number. He says that given the level of secrecy on the part of employers and what he considers to have been an overly narrow government definition of karōshi at the time—which, for example, didn’t count someone as having worked to death unless they logged more than 100 hours of overtime in the month before dying—the actual number of victims might have been as high as 10,000 cases annually. (The government now uses a lower threshold of hours.)

Press reports about the karōshi epidemic helped push millions of young workers—many of them college graduates who had been offered jobs with major companies—to opt out of Japan’s deadly corporate culture, instead choosing freelance or part-time careers that allowed for a more relaxed lifestyle. It seemed like a prophylactic, of sorts, against karōshi, and indeed, until around 2008, Japan’s karōshi hotlines were used almost exclusively by full-time, salaried workers. (It was considered a shocking outlier, for example, when a young restaurant worker killed herself that year after working more than 140 hours of overtime in a single month.)

These days, though, Obayashi feels that part-time workers are increasingly at risk of karōshi. In recent years, firms have been eschewing full-time workers in favor of more flexible arrangements with recruits who work for lower wages, with less job security, which leaves them vulnerable to abuses like unpaid overtime and has forced many to take extra jobs. Since 2015, Japan’s number of workers with two or more jobs has grown by roughly 30 percent. “Today’s generation of part-time workers can’t afford to be so carefree,” Obayashi told me.

The Japanese government, which now considers people to be at risk of karōshi if they regularly work 60 hours a week or more, does not publish statistics on the working hours of part-timers with multiple jobs. In July, hoping for a clearer picture, I visited Asami Ito, a community manager at Lancers, which builds software platforms that match freelance workers with companies. According to Lancers research, some 4.5 million full-time workers in Japan have second jobs, where they work, on average, between six and 14 additional hours each week, on top of any overtime hours they clock at their primary job; a small number of them work up to 30 or 40 hours per week at their second jobs. “We’re recruiting many more ‘parallel workers,’” Ito told me, using a Lancers nickname for people with side jobs on top of full-time jobs. Ito said Lancers’s research suggests most of Japan’s workforce will be freelancers by 2027.

The fact that people are working multiple part-time jobs just to earn a living wage is surprising, given that Japan’s low birth rates have left the labor market as tight as it has been in forty years, with almost 1.6 jobs for every applicant. In the food-service industry, workers are in such short supply that McDonald’s recently resorted to an expensive advertising campaign aimed at recruiting housewives and retirees to help out with its busiest shifts. Convenience-store chains have hired more foreign workers, while small and mid-sized manufacturing companies have increasingly turned to automation. But the one recruitment strategy that hasn’t really taken hold is increasing wages.

An explanation lies partly in Prime Minister Shinzō Abe’s signature fiscal policy, known as “Abenomics,” which relies in part on using monetary policies to weaken the yen so as to make exports cheaper for foreigners—which has increased profits for Japan’s manufacturers. In theory, higher corporate profits should have led to higher wages and an increase in consumer spending. Instead, Japan’s corporations have chosen to sit on the piles of cash they’ve earned from Abe’s fiscal policy. Each spring, over the past six years of Abenomics, the leaders of Japan’s major industries have ceded remarkably little ground to unions during the annual wage negotiations known as shuntō. Workers have responded by saving what little cash they have, rather than spending it. And while a weaker yen has helped corporations increase exports, it has also made importing products and materials more expensive, which contributes to weakened buying power for Japan’s increasingly cash-strapped households. Overall, workers are spending an average of 11 percent more time to earn the same salary they were bringing home about 20 years ago, and some are working unpaid overtime on top of that. Even the most promising gains leave room for pessimism: In June, government data showed that inflation-adjusted wages rose at a pace not seen since 1997, but that was mostly due to large one-off summer bonuses.

In recent years, there have been several high-profile cases of karōshi. In 2013, a 31-year-old journalist working for Japan’s national broadcaster died of heart failure after working 159 overtime hours in a single month, prompting lawmakers to pass legislation aimed at creating greater awareness of the dangers of karōshi. In 2015, a 24-year-old rookie employee at Japan’s largest advertising firm, Dentsu, took her own life under similar circumstances.

The fact that karōshi risk has spread outside Japan’s “lifetime employment” system appears to be related, in part, to a series of legislative changes. A karōshi-prevention measure set to go into effect next year will restrict overtime to 45 hours during normal months, though it allows for up to 100 overtime hours during busier months. Many workers who have come to rely on overtime wages have simply responded by taking on second jobs, according to Lancers data. That development has been helped by a separate recent decision, meant to improve labor mobility, in which Japan’s Ministry of Labor canceled a law that had prevented workers from taking a second job without the approval of their primary employer.

Jun Kobayashi, who has three service-industry jobs that keep him on his feet for as many as 70 hours most weeks, is a reluctant sort of pioneer in the new class of Japanese workers. When I met him on a damp, humid afternoon near the end of June, he barely had time for the subway ride between the job he’d worked that morning and the one he’d work that night. As we hurtled through the spiderweb of tunnels that sprawl out beneath central Tokyo, I asked Kobayashi whether his bosses forced him to work as many hours as he did. “It’s true that they really rely on me,” he said. “But if I didn’t work so many hours I wouldn’t be able to get by.”



“Hi! I noticed you posted about your cold today. It sucks to be sick. I thought maybe you’d like to try some greens! I love them; I swear, you’ll never get sick again!”

I did not want the greens.

This was the third time my friend from college had tried to sell them to me online. She also did things like post statuses about “That Crazy Wrap Thing” that her friends were supposed to pretend were not advertisements. My aunt who homeschools her seven children sells organic cleaning supplies. A poet I know says she sells online for the community it gives her. A young college administrator likes it for the freebies and the friendships. A stay-at-home mom said she was using a lot of makeup anyway, so Younique only made sense.

Multilevel marketing goes by many names. Those being propositioned often think of multilevel marketing as a pyramid scheme or scam; those selling believe the business model is a straightforward way to earn extra income from home. Here’s how it works: “Consultants”—sellers for a direct-sales company—solicit new recruits to sell products online, and, in addition to their own sales, those consultants then earn a percentage of their recruits’ sales. Those recruits, in turn, then sign up still more online sellers and earn a percentage of their sales, and so on. It’s “Avon calling!” for the internet age. And as was the case back in Avon’s heyday of the 1950s and 1960s, the vast majority of sellers are women—many of them stay-at-home mothers.

While there isn’t any precise data on how many mothers moonlight as salespeople, websites promoting MLM work seem to be everywhere online—including one site called Stay a Stay at Home Mom. Kristen Duvall, a self-employed ghostwriter and multilevel-marketing retailer in California, sells both Jamberry and Perfectly Posh products online. She says she makes a few hundred dollars of income each month. Duvall said selling for Jamberry, which sells trendy nail wraps, is fun for her. “It’s this community of collectors and fans that swap wraps like baseball cards,” she said. It’s true: Collectors can trade a limited-edition wrap pattern for double to triple the amount they originally paid. The same goes for the clothing company LuLaRoe, another multilevel-marketing operation, where limited prints can sell for hundreds of dollars in profit.

The sellers find out about the newly released products and exchange tips to increase sales. They are all working independently, and yet the group also works together as a whole. They are each a cog in the wheel, the wheel is part of a much bigger machine, and the entire setup moves toward one goal: the bottom line. But many of the cogs—the salespeople—don’t quite see it that way. For them, being sellers is about more than money. “I compare it to a fandom,” Duvall told me. “It’s no different when someone loves a particular sports team or Harry Potter, and they talk about it nonstop.”

I saw all this firsthand. For nearly a year, I observed Duvall’s group—the Sparky Lil Spitfires— and saw women, and a few men, negotiate the ins and outs of life in direct sales.

Multilevel marketing, or MLM, is experiencing a major boom. In fact, according to the Direct Selling Association, there are more MLM companies in 2017 than there have ever been before. One in six households in the United States participate in a direct-sales company. Experts point to both economic forces and social media to explain this outsized success.

Take the clothing retailer DeAnne Stidham, for example. She launched LuLaRoe in 2013, and by 2016, multiple outlets, including Forbes and Business Insider, heralded the company as ingenious. Now, just a year later, the hit pieces—LuLaRoe is known for its colorful prints and leggings—keep coming. A LuLaRoe spokesperson told me that the company has been able to grow so fast due to its “tens of thousands of Independent Fashion Retailers” who work off the brand’s “Social Retail” experience.

“Social Retail is focused on creating exciting, personal and engaging shopping experiences for consumers—whether they take place in-person at a Pop-Up Boutique, or online via a social media group or live sale. Our innovative approach is attractive to Retailers because it gives them the freedom to decide when, where and how to sell LuLaRoe—and perfect for consumers, who want to shop in ways that are most convenient for them.” The company said it recorded more than $2.3 billion in retail sales in 2017 alone.

Unlike many MLM companies, LuLaRoe requires a hefty buy-in at $5,000. That gets the consultants their stock, and from there, they each work as an individual boutique operator, buying wholesale from the mother company and selling the clothes and leggings for twice the price. Ideally, that looks a lot like Lauren Hefner, who made six figures selling LuLaRoe last year. She walked away from a highly paid management position in health care when she started making more from her side business than she did at her 9-to-5.

“The high start-up cost makes LuLaRoe a business that requires careful consideration and prevents a saturated market,” Hefner told me. She cited the company’s profits doubling year-over-year sales each month in 2016 and said she makes $25,000 a month, 50 percent of which is profit.

Yet Hefner may be mistaken about market saturation. In just six months, sales consultants for LuLaRoe have shot up from 38,000 to 77,000, according to Business Insider, and most of those consultants are not making much money—if any at all. Partner that with consumer complaints of garments tearing and insider scoops about network moles turning on sellers who discount their merchandise, and what was once a rousing success may soon become a disaster. What’s more, most independent retailers agree, if you hope to bring in any income, then LuLaRoe isn’t a side business at all. “It is extremely time-consuming,” Hefner confirmed. “Consultants manage their own inventory, marketing, invoicing, and shipping. At my volume, it is a more than a full-time job.”

Of course, Hefner’s work-at-home windfall wouldn’t be possible without Facebook. “I sell exclusively online through my VIP Facebook page and through parties [arranged online], in which a hostess invites her family and friends to an online or in-person event that I run,” Hefner explained. The hostess then “receives rewards in free clothing dependent on how many items her party purchases.”

In an uncertain job market and an exploding gig economy, taking a spare hour or two at your convenience to earn some cash is tempting, and using the internet to sell products sure is a lot easier than lugging your wares around. “I never would have walked door-to-door to sell Tupperware or Mary Kay,” Jenie Evans of LimeLight told me. “But I have over 5,000 contacts at my fingertips on the internet, and I don’t even have to get out of my pajamas to share my products with them.”

Like Hefner, Evans is an online-retail success story. After rising to a high level as a popular makeup consultant at Younique, making 95 percent of her sales through social media, Evans switched to its competitor LimeLight during that company’s infancy. Evans predicts she’ll make anywhere from $250,000 to $500,000 this year. She shot up to the highest levels at LimeLight in mere months and has more than 50 people directly under her, each of whom has people under them. In total, Evans is responsible for recruiting nearly 400 people to LimeLight, and her earnings reflect that. LimeLight did not respond to requests for comment.

Robert Fitzpatrick, a consumer-rights advocate and the co-author of False Profits, says recruitment is an essential part of MLM. “In 18 years, I have never met one person in MLM who earned a sustainable profit without recruiting,” he says. “The reward is dependent on the recruiting. You have to move up to have access to the reward. Therefore, you can’t make money without recruiting.” In fact, joining a multilevel-marketing company when it is new, like Evans did, may be the only way to make any money at all.

At the Sparky Lil Spitfires, sales goals hover around $500 to $1,000 a month. These women may not be raking it in like Hefner and Evans, but they are committed to making their businesses viable. They’re scrappy and tenacious, upbeat and optimistic. They build each other up, help each other out, and try for that extra dollar sign every day. Most days they fall short, but they don’t let that deter them.

Fitzpatrick says that while the internet has made tiered marketing more efficient, the root of the proliferation of new MLM companies in the past decade really comes from doubts about the strength of the traditional economy. “We now have college students who are faced with a lot of debt, and they’re not sure the job market has room for them, so these outside-the-economy solutions seem like a great idea,” Fitzpatrick said. What these companies peddle to their retailers—more than goods or even an investment opportunity—is a worldview. They sell an image of self-sufficiency not dependent on the country’s economy, but dependent only on the seller’s own gumption and perseverance. They sell a dream of economic independence. “The system is completely separate from the mainstream economy,” Fitzpatrick explained. “It’s unique. It’s entirely up to you. You have complete control, so if you don’t make the money, it’s because of you. The only way you can lose is if you quit. Losers are the quitters; quitters are the losers. People quit because they didn’t have enough ambition or enough character.”

But the sellers I met all said it’s about much more than money. They value the sense of community, friendship, and purpose that comes with being a vendor. Women who join as team members under another seller become bonded like Girl Scouts in a troop. Each subsequent recruit becomes yet another member in a hierarchy within the hierarchy. These sellers then come together day after day online and through phone chats. They get to know each other on a level that goes beyond leggings and makeup. “Being a military spouse, having an MLM business can be a fantastic way to make friends,” said Melanie Greeke, a stay-at-home mother in Florida who has sold everything from Scentsy to Younique. “It’s common ground. You have a product they like, they contact you, you chat, and build a relationship. I have tons of friends I met this way.”

Those on the outside caution against this friendship formula, including William Keep, the dean at the School of Business at the College of New Jersey, who has studied multilevel marketing at length. He says these women are “not making friends; they’re buying them.”

Consultants, however, are quick to dispute this. “Did I have to spend $99 to make friends?” Greeke countered. “No. I could have done it easily on my own. Did it help me put myself out there? Yes.” Duvall agreed. “I joined because I was obsessed and spending a ton of money on the product already,” Duvall said. “I stay because the teams I’m on provide friendship I’ve not found since my sorority days in college.”

Sparky Lil Spitfires is a Facebook group like any other, but with members all belonging to teams underneath the leader Jennifer Hosey. They use the group as a gathering point to swap stories, ask questions about new products, and look for advice on how to handle difficult aspects of the business—like how to deal with unruly customers or unreasonably slow shipping. Whenever a Spitfire signs on to Facebook and checks in with the group, she sees a cascade of posts touting Perfectly Posh perks, swag, contests, and fun. Spitfires also have nearly 400 members, many of whom consider each other very close friends. “This little Facebook page has so much heart and soul and love,” Patricia Frederickson, a graduate student in Georgia, told me. “Sales is the backbone, sure, but the heart of the group is in the people.”

During my time in the group, the Sparky Lil Spitfires did share tidbits from their lives, celebrating triumphs and mourning losses. But, more than anything, they posted about the Perfectly Posh products. Still, for every 10 or 20 product posts, a personal post would appear. “I see prayer requests, photos of kids, sweet dance moves, funny stories,” Frederickson said. “If you look through this page, there are sales, but there are also a lot of laughs and a strong sense of community engagement.”

She’s not wrong. When Brandi Henderson’s house burned down while she and her family were on vacation, she lost everything. In that time of turmoil, it was the Sparky Lil Spitfires group that sent her strength, both through kind words and support, and through physical items she needed just to get by day to day. “I love these people more than I love even some of my actual family,” Henderson said.

Several of the women in the group are taking care of chronically ill children or partners, and they say the group dynamics keep them going on difficult days. Susan Sweeney has an 8-year-old son with complex medical issues, which forced her to leave her full-time job in 2014. She spends most of her days in and out of hospitals and doctors’ offices and said the Posh group saved her sanity. “My husband calls Posh my outlet from the doctors,” Sweeney said. “I touch my business daily, even in the hospital. I needed this.” But again, it’s not all business. “A lot of them are on my personal Facebook,” she told me. “They know when I’m at the hospital, they know when things are going all medically wrong with my children, and they are there for me. I can’t put a price tag on it.”

A lot of the Sparky Lil Spitfires dynamic comes from the group’s Perfectly Posh leader, Jennifer Hosey, who in the MLM world is known as the “up-line.” While she isn’t technically anyone’s boss, every member of her Spitfire group has either been recruited by her directly or been recruited by one of her recruits. Simply put, Hosey makes money off of each person selling in that group because she put in the effort to get them there. Hosey spends multiple hours a week forging connections with her group. She sends out samples with handwritten cards and motivates her team with charisma, a human touch in an online world. Hosey’s deep-seated love for her “down-lines”—her recruits, and their recruits, and their recruits—is no doubt enhanced by the profits she pulls down as a result of all their efforts. Nevertheless, her enthusiasm is infectious. “I haven’t met a lot of these girls and guys, but I would fight tooth and nail for every one of them,” Hosey told me.

The group is a real community. But it is also a classic—if virtual—salesroom. Sometimes the Facebook group page feels like a packed conference room where the top sellers make pitches to the troops to keep morale high, to keep profits up, to keep the product moving, and to keep getting more people to sign up as sellers. Sparky Lil Spitfires members are expected to dial in for all Perfectly Posh group calls and to watch PowerPoint presentations to help them become better salespeople. The sellers are also given worksheets with a dizzying array of columns and rows that intersect at the number of recruits and monetary sales. If a seller recruits a certain number of sellers underneath her, her sales and their sales combined can elevate her within the company. A seller can climb to several different levels, and each level has different escalating requirements and rewards attached. All these charts and numbers depend on both individual sales and team sales. Just looking at the paperwork is intense and confusing, but to those acquainted with the system, it’s second nature.

Perfectly Posh is similar to other MLM companies: People who want to be consultants find a friend or an acquaintance who already sells and gets in under them. They plunk down $99 for a starter kit, which contains 20 or so products. Then the new consultant is offered the opportunity to go through business training—in the first month of selling, there’s a course every day. Over the next 90 days, the courses go down to weekly. Perks—the free Posh products given out for hosting parties, buying products, and selling products—rain down on the participants at this level, which is called Protégé. Consultants earn 20 to 30 percent commission on sales at this stage, and 1 to 6 percent of their down-line sales. Once someone reaches Pink, which is the next level—meaning they sell $500 that month, their team sells a total of $20,000, and the company sells a total of $100,000—consultants start making more money. And on it goes, up—and down—the chain. Finally, if consultants wish to remain in the company, they are required to sell $300 worth of products every six months. The Atlantic tried to reach Perfectly Posh several times. They never returned our calls.

Sellers are also taught how to mine their contacts. First, sellers must go through all their Facebook friends. A live team call went into explicit detail. Split the names up into several groups: friends (best friends, people you hang out with, friends of friends); relatives (in-state, out-of-state, those on your holiday-card list); acquaintances (receptionists, bank tellers, dental hygienists, grocery clerks, coworkers); neighbors (every person on all adjoining streets in the area in which you live, past neighbors you’ve kept in touch with); kids (parents of your children’s friends, people at children’s sporting events, church). If that isn’t enough categorization for you, sellers must next break down all those categories into four different groups: people who would help you if asked; people who might help you if they saw the product and heard about the benefits; people who might not help you; and people you’re pretty sure would not help you no matter what. Keep an eye on that wording. They aren’t looking for acquaintances interested in buying from you, but in people who would help you.

There is a point to all of this. Most people immediately want to sell to their close friends and family; the group call advised against this. Those people probably know all the same people the sellers already know. This could lead to a “black hole” in the business as the same people pass the information around and the base never grows. Instead, the call leaders encouraged sellers to pick a few people in their acquaintance pool who might need to hear the sales pitch first before diving in, but who then might be interested. These acquaintances, the logic goes, would know different people than the sellers and therefore could spread the news of the business opportunity outside the seller’s original close-knit group.

Hosey is proud of what she has created. She told me that Perfectly Posh has changed her for the better. “I’ve always been a stay-at-home mom—an educated stay-at-home mom at that,” Hosey said. “I have a college degree, as a lot of women on our team do. We choose to stay home and see our kids grow up. I started paying bills after not contributing financially to the family for 13 years. This is not a hobby for me or a way to cure the boredom. My business, this company, this team—they are my passion.”

MLM can be a way for a lot of women like Hosey to join the workforce. Many sellers are mothers who want to work from home part-time with flexible hours—a combination that is often unique to the gig economy. After all, at many typical American workplaces, there is little to no accessible or affordable child care, there are shoddy family work practices, and there is rampant discrimination—all of which contribute to the hope of selling successfully online. Some even succeed—like Hosey, Hefner, and Evans. But many, many more don’t.

And though MLM can seem like a great opportunity for women to carve out a productive work life, it does nothing to change the societal structures that may have forced them in this direction in the first place. Worse, people often become condescending to women who attempt to work from home with the options they have left. Many hold a marked distaste for MLM sales encroaching on their relationships. “I cringe when I see another friend start up an MLM business because it feels so awkward to get invited to things and added to groups I don’t want to be in for things those friends should know I would never buy,” said Julie Cotton, a stay-at-home mother in Massachusetts, “except they want to make money so they conveniently forget.”

“Lots of folks ask, ‘Why not buy from your friend rather than a store?’” said Audra Williams, a writer in Toronto. “And the answer to me is that you don’t have a personal relationship with the store that will be impacted if you don’t like or repurchase the product.”

Both Cotton and Williams have been added to multiple selling parties on social media. Neither asked to be there. They aren’t the only ones.

“I’m pretty against most MLMs because I saw how my friend was taken for a ride by one,” said Elizabeth Hawksworth, a social-media coordinator in Toronto. “She had to shell out something like $1,000 to join a tech MLM a few years ago, and she never got the money back. The company was later taken to court for being shady.”

Those who study business models say it’s plain to see why people should be leery of MLM operations. “Money has to get from the bottom to the top,” said Fitzpatrick, the consumer-rights advocate. “If I recruited you, and you bought $100 of goods and became a distributor, $40 will go as recruiting rewards to the distributor’s chain above you. Of that $40, most of it goes to the top of the chain.”

For instance, Thirty-One Gifts’ brief earnings statement acknowledges that most consultants who sell its handbags and totes will make between $183 and $1,993 annually. This range, however, comes only from “typical participants”—defined as sellers who are active at least five months out of the past year. This means those numbers skew high, because all of the sellers on the top tier making six to seven figures will be included in this average, but none of the women who signed on and couldn’t make a go of it for at least five months will be counted. Thirty-One Gifts did not return phone calls for comment.

Fitzpatrick defines fraudulent MLM outfits as businesses in which “the profit of the people at the top comes from the losses of the latest recruits.” The numbers for Jamberry say the average sales consultant makes slightly more than $200 a month for an average of seven months out of the year. Still, there is little public data on how many consultants making that much sustain those numbers, or how many are new consultants who sign on, sell for a few months, and then drop out when their friends and family stop buying. Jamberry did not respond to an interview request. At Young Living, a company that sells essential oils, 94 percent of sellers are in the lowest tier. The average monthly income for that level is a mere $1. For sellers on all 10 levels, the annual average remains only $25. Requests for comment from Young Living went unanswered.

“They have bought a story,” Fitzpatrick said. “It’s a beautiful story, a self-indulgent story, a miraculous story—that in 2017, with all its job insecurity, there is, in America, an alternative, and that alternative is not run by Wall Street or the government. It’s a kind of mass hoax. It’s a psychological sale first, then an economical sale, and the two work together. The scheme tells you that the cause of the failure is not the system, but you: that you didn’t work hard enough at it.”

We want to hear from you. Please email your response to letters@theatlantic.com.



The much-discussed stream of sexual harassment allegations against famous men has left many people wondering just how common such problems are in American culture. The answer, it seems, is pretty common. The allegations and subsequent firings, coupled with new data about how women experience discrimination in the workplace, paint a pretty disturbing picture of what it’s like to be a woman at work in 2017.

According to a new survey from Pew Research, 42 percent of women say that they have experienced some sort of gender-based discrimination at work. And while more than one-third of the men and women polled said that sexual harassment was a problem at their workplace, women were three times more likely than men to say that they had personally experienced harassment.

The survey, which polled a representative sample of nearly 5,000 men and women, asked if workers had ever felt that their gender led to being passed up for a promotion or receiving less attention or support from superiors. By contrast, 22 percent of men said that they’d faced any sort of bias because of their gender. The survey was conducted during the summer of 2017, well before the major recent stories about alleged sexual harassment began to break.  

Researchers also asked if people had ever discovered that they were being paid less that someone of the opposite gender for the same work, or if they felt that they were often treated as if they were incompetent. About a quarter of the women surveyed answered yes to each of those questions. This data tracks with existing narratives about how gender discrimination manifests in the workplace.

Many of anecdotes about on-the-job gender bias hinge on women having their competency questioned, despite a demonstrated record of success. In Liza Mundy’s recent Atlantic story about gender discrimination in Silicon Valley, Tracy Chou, a software engineer, described finding a critical flaw in her company’s code. She goes on to say that her finding wasn’t taken seriously until a male colleague backed her up, and after that, her work to fix the bug was constantly scrutinized and second-guessed, even though she had saved the company from a large error.

Chou’s experience with gender discrimination fits a pattern in the labor market that can seem counterintuitive: Having more education and working in more competitive and highly paid fields make women more likely to experience certain forms of discrimination at work. In Pew’s survey, reports of discrimination increased significantly for women with postgraduate degrees: Nearly 60 percent of working women with advanced degrees reported encountering discrimination. For women with a college degree, around 40 percent reported this issue. And that figure was about the same for women with no college degree, 39 percent of whom reported issues with gender discrimination. Highly educated women are also more likely to see a bigger difference between their own incomes and that of their male colleagues.

There are other notable patterns in who reports experiencing harassment at work. More than half (53 percent) of black women surveyed by Pew said that they had experienced some form of gender-based discrimination at work, significantly more than the 40 percent of white and Hispanic women who reported issues with discrimination. More specifically, nearly one-quarter of black women said they had been passed over for important assignments because of gender. Fewer than 10 percent of white and Hispanic women reported facing the same problem.

These findings track with existing research that shows that despite educational gains, black women are rarely found in the upper echelons of company management, and still struggle to overcome stereotypes that paint them as aggressive or difficult to work with. And there’s still more evidence that black women struggle to get the economic and labor-force boost that many other groups get from increasing their education. Instead, their pay remains significantly lower than most other groups, they remain overrepresented in low-pay industries, and they are more likely to be fired than their peers.

Given the recent wave of horrifying allegations of harassment and assault in the workplace, issues of pay and promotion can seem less critical or urgent. But workplace cultures that devalue women economically and professionally send a message that suggests that women are expendable. Bias in determining compensation and position also plays a critical role in creating the power structures that empower men while disempowering women—breeding inequalities that can foster discriminatory and dangerous behavior. And while examples of sexual harassment and assault are making headlines and getting men fired—more subtle gender discrimination also severely harms women, and undermines the prospect of greater equality.



What is bitcoin? An investment? A technology? A bubble? What is even happening?

All of these questions seem like reasonable ones to ask, as its price has surged and plummeted. Bitcoin is many things: a proxy for more stable units like the dollar and the euro, a speculative investment, a payments mechanism, a means of hiding transactions from various governments and tax collectors, and a monetary innovation that might legitimately transform the world.

Yet cryptocurrencies, such as bitcoin, are also a bubbly, frothy, and overhyped phenomenon—a latter-day version of a penny stock, boosted by drug dealers, digital evangelists, Wall Street types, and a large twinset of Harvard rowers. Sure, sophisticated investors are pouring money in. But neophyte investors are charging bitcoins to their credit cards. A company called Long Island Iced Tea, purveyor of virgin lemonades and steeped drinks, added “blockchain” to its name and saw its stock price jump as much as 500 percent. Companies are raising vast sums on the public markets via initial coin offerings. The prices of various currencies are spiraling around like a loose tab of acid lost in a dust storm at Burning Man. It is getting weird out there.

Regulators are taking notice, concerned that beside the explosion of legitimate investment in digital currencies lurks a whole lot of old-fashioned consumer fraud, self-dealing, market manipulation, and false advertising. Among them is Joseph Borg, the director of the state of Alabama’s securities commission, who recently voiced his concern that people were mortgaging their homes to get in on the hype. I spoke with him as the price of bitcoin was in the midst of plummeting 30 percent in a day, to a point at which it still would have grown tenfold in a year. The interview that follows has been lightly edited for clarity.  

Annie Lowrey: What’s your 50,000-foot view on what’s been happening with bitcoin?

Joseph Borg: From our office’s point of view, we have money transmitters and securities. If bitcoin is being used as a transmission vehicle for money, those businesses have to be licensed. We’re concerned about encryption, how they’re transmitting money, the security of wallets, that kind of thing. It’s just like Western Union. If you’re sending money via Western Union from New York to California, they have to be licensed to transmit the money. But they’re not creating the money. That’s one aspect.

The whole cryptocurrency area is getting looked at closely by regulators, for that money-transmitter aspect. There’s a group that’s come up with a cryptocurrency-transmission law to be used as a model. We’re studying that, and New York has been pushing out some regulations on cryptocurrency as well. But it’s such a new phenomenon. And any time you have regulators looking at something new, we’re behind the curve. The folks who developed it understand it and we have to learn it.

Lowrey: Got it, so that’s one side—the money-moving side.

Borg: Right, then there’s the securities side. We’re concerned about the companies doing initial coin offerings. We’re also concerned about the companies using bitcoin as a basis for people to speculate, or creating technology off of the blockchain. They’re raising money to develop other companies, raising money to get into business. That’s an investment, not a money-transmission business.

Right now, my message is: This is just like the dot-com bubble, tulips in the 1600s, and oil and gas speculation. Things get to be a mania. The retail market gets hits with advertisements and media pitches: You’re going to miss out on the next Microsoft! You’ve got to get in now, because it’s going up and up and up! It’s the same sort of thing that you see in any type of mania. When oil was $4 a gallon, everyone was pitching this new technology to drill old oil wells, that kind of stuff.

The difference with the cryptocurrencies, the bitcoin mania, is that the technology ramps up quicker and so the mania goes faster. The mania on oil and gas took two years—this is taking two months. It’s tech-driven and instant.

Lowrey: But the mania is the same?

Borg: You just go do a Google search for “make money on bitcoin.” It’s page after page of it, hyping it to the whole retail market. Bitcoin’s making new millionaires! Get in before it’s too late!

The thing is that the market has done well, but the average Main Street–type person hasn’t participated in it. They got burned by the micro-cap stocks in the 2000s, then burned by foreclosures and the real-estate collapse. They’re concerned about Washington deregulating everything, and Social Security going broke, and health-care costs going up. And they haven’t had a salary increase in years.

You’ve got a family making $60,000, $100,000 a year. They don’t have a lot of money for retirement. Then, someone comes along and says, “Make $13,000 in 24 hours, guaranteed!”—got to get the “guaranteed” part in there. It’s like you’ve got a fuel pump at a pump station, where the pump is stuck and the fuel is spilling out all over the street. And there’s people lighting matches. And someone says, well, let’s pour more fuel on it!

At some point, there’s going to be a huge correction, when the bubble breaks. I can’t tell you when that would be. It could go on for a while. There’s a lag time between when people invest and when they realized they got duped. We’re in the middle of the frenzy. It’s going to be 24 months, maybe longer, before we know. Sometimes it’s 8 or 10 years.

Lowrey: Are there people you’re especially worried about, in terms of getting ripped off?

Borg: Well, if these folks are seniors, often we don’t even hear about it because they’re embarrassed. They figure if they let people know, the family will figure that they cannot handle their affairs anymore. Seniors will tell us, “I lost the money. I got taken. But my kids would say I cannot manage things anymore if I told them that.” They don’t want to lose their way of life.  However, I don’t think there are a whole lot of seniors invested in this.

Lowrey: Who is, then? Because that matters a lot for who would get hurt by a collapse.

Borg: The way I hear about it is that we do 80 to 90 public events a year. We talk a lot about protecting people from fraud, and I’ll ask people if they’ve heard of bitcoin or invested in bitcoin. If I ask, “Do you know what a bitcoin is?,” four or five hands out of 60 go up. And maybe two or four are invested. I’ll follow up during a break, when we’re serving lunch or breakfast. I’ll say, “This is risky stuff!” That’s a good way to hear about the exposure.

Most folks are doing it out of savings, maybe by selling off part of a mutual fund. They aren’t betting everything on it. A few said they took $10,000 out on credit cards to buy bitcoin. Some took out $10,000 in a home equity line of credit. That’s like a credit card on steroids, a second mortgage.

Lowrey: Right, your home is at risk if you can’t pay it back. I guess the question is whether these people can be said to know what they’re doing, and if they’re being exposed to fraud.  

Borg: Remember back in the dot-com era, that ad with that orange-haired kid telling the CEO to buy Kmart stock? Or there would be ladies at the social club playing canasta, talking about how they bought this or that mutual fund and made $300 in four hours? The water-cooler conversation at the office went from football and baseball to what so-and-so bought today—that kind of hype.

Now, with cryptocurrency, the numbers are higher, the technology is quicker, and instead of television commercials, it’s all done on your phone. It’s a frenzy. But it’s not as big as it was back then.

Lowrey: Part of what matters is who’s distributing what money to whom. If it’s all fairly rich people, maybe you’d worry less about that as a regulator.

Borg: The bigger it gets, the more the pool widens out. People say everybody loses in a Ponzi scheme, but that’s not true! The bigger it gets, you have more winners and more losers. At some point, we’re going to run out of folks willing to pay $19,000 for a bitcoin. Then, we’ll see.

We’re not saying bitcoin is illegal or bad, or that cryptocurrency is bad. We’re saying, don’t misunderstand what it is. Don’t, because of the hype, talk yourself into putting yourself at risk of losing your house. I always say, if you want to invest in this, ask yourself if you would take $10,000 and put it on black in Las Vegas. If you would, maybe invest in bitcoin.



A bar of gold. A disk of iron. A chain of beads. A card of plastic. A slip of cotton-linen paper. These things are worthless. One cannot eat them, or drink them, or use them as a blanket. But they are valuable, too. Their value comes from the simplest thing. People believe they are money, and so they are.

If every currency is a consensual delusion, then bitcoin, a digital cryptocurrency that changes hands over the internet, feels more like a consensual hallucination on psychedelic drugs. The concept of bitcoin was born in a detailed white paper published in late 2008 by a pseudonymous “Satoshi Nakamoto.” By 2013, one bitcoin was worth $12. As of this writing, it’s worth more than $10,000. Its value has doubled in the last two months alone. For any currency’s value to increase by 100 percent in eight weeks is, to use a technical term, bonkers. If the Japanese yen or American dollar did the same, their economies would plunge into an infernal deflationary spiral.

Throughout history, currency has taken one of two forms: physical assets, like gold or beads, and fiat currency, like government-backed paper and coins. Bitcoin and its brethren introduce a third category: digital currencies that run on a combination of game theory, economics, and cryptography—thus, cryptocurrencies. If all money is the sharing of an illusion, bitcoin wants to build a better way to share it.

Like many people, I’ve long regarded bitcoin’s rise with both wonder and confusion.  To help me make sense of it, I started calling cryptocurrency experts and academics to ask, is bitcoin just a dumb bubble, like 17th-century tulip bulbs? An investment hedge, like gold? A currency, like dollars? The answers I got weren’t satisfyingly unanimous. I heard “all of the above” and “none of the above” and “nobody knows for sure, yet.”

Toward a More Perfect Money

What’s wrong with dollars, anyway? If you ask me, very little. I like my credit card. I don’t even mind cash.

But to others, the dollar’s dangers are glaringly obvious: a single omnipotent entity, the federal government, strictly controlling money supply and the rules that govern it. Some worry that the creation of too many dollars will lead to out-of-control inflation. “Cypherpunks have dreamed of fully decentralized electronic payment systems for decades” that would allay these concerns, writes Timothy Lee, a senior tech-policy reporter at Ars Technica who has long been on the bitcoin beat. Most digital-currency ideas, however, had the same tragic flaw—replicability. Just about everything that exists online (think text, photos, or files) can be copied. Fear of rampant counterfeiting would spell death for a digital currency.

Bitcoin solved this problem with the blockchain, an online ledger that records and validates all peer-to-peer payments to eliminate double-spending. For those inclined to less-than-legal behavior, it helps that the blockchain encrypts transactions to provide anonymity. The payment network is maintained by bitcoin “miners,” a decentralized group of individuals with powerful computers that approve transactions and are rewarded with new bitcoins for their work. The total possible supply of bitcoin in the world is capped. Thus, bitcoin solves both of the cryptopunk money problems—the blockchain thwarts centralization, and the planned scarcity of bitcoins checks inflation.

The blockchain is an ingenious and potentially transformative technology. People like Marc Andreessen, the well-known venture capitalist, have predicted that it could become the scaffolding of the entire economy, like the internet. Here’s a taste of the transformative vision from an interview Andreessen held with The Washington Post:

Digital stocks. Digital equities. Digital fundraising for companies. Digital bonds. Digital contracts, digital keys, digital title, who owns what—digital title to your house, to your car … You’ve got digital voting, digital contracts, digital signatures … And then every aspect of financial services: insurance contracts, insurance derivatives, currency exchange, remittance—on and on and on.

Nobody knows for sure whether the blockchain will transform the economy of the future, as Andreessen foresees. What’s clearer, however, is that it has not transformed the economy of today. While the number of bitcoin transactions is growing every year, it’s nothing close to a mass-market consumer technology, like Google, or Netflix, or even PayPal. Bitcoin remains cumbersome to use (the typical transaction can take up to 10 minutes) and the price is extremely volatile. It is, for now, a frankly terrible currency built on top of a potential transformative technology.

Which leads to perhaps the most obvious question: If bitcoin appears to have flopped as a mass-market currency, why has it so suddenly succeeded as an investment vehicle?

Up, Up, and Away

There are countless theories about why bitcoin’s valuation has gone berserk. But for the purpose of time and sanity, let’s reduce them to four mega-arguments.

1. Venture capital (and a green light from the feds) got the ball rolling.

For the first five years of bitcoin’s existence, venture capital’s interest in bitcoin-related products and companies was minimal. After all, the very idea of cryptocurrency was infamous for its association with online black markets like Silk Road, where criminals used digital tokens to anonymously sell drugs and other illegal stuff. (In fact, one could argue that bitcoin’s rising valuation is just a bet that its most dubious uses—say, avoiding taxes or laundering money—will keep rising.) It seemed for a while that the U.S. government might try to crush the ostensible competitor of the almighty dollar.

But in November 2013, shortly after the FBI shut down Silk Road, several senators praised bitcoin and other virtual currencies at an official hearing as “legitimate financial services.” Senatorial droning on C-SPAN doesn’t always move markets. But when it does, it really does. The value of bitcoin tripled within the month to $900, and venture capital got its green light. VC investments in bitcoin rose from nearly nothing in 2012 to $400 million in 2014 and $600 million in 2016. Bitcoin didn’t yet have an obvious mainstream purpose. But it had something even more valuable: legitimacy from Washington, with curiosity and cash from Silicon Valley.

2. It’s digital gold.

People have long described bitcoin as digital gold. In early November, Bloomberg reported that “buy bitcoin” had overtaken “buy gold” as an online search phrase, suggesting that bitcoin’s rising valuation could be partly due to investors seeing it as the precious metal’s trendy equivalent. Like gold or silver, bitcoin is scarce (by design) and a popular hedge for inflation hawks, worrywarts, conspiracy theorists, and other antiestablishment investors who believe the global economy is always a month away from implosion or hyperinflation.

There is another important way that bitcoin is like gold: Its reputation is much bigger than its market. In any given week, $34 billion in bitcoin is traded, according to The Wall Street Journal, less than 1 percent of the global foreign-exchange market.

As New York University professor and so-called “dean of valuation” Aswath Damodaran quipped, bitcoin could become the world’s reserve cryptocurrency or the biggest bust of the century. “Right now it’s not a very good currency, because it’s not a good medium of exchange and it’s not a good store of value, because it’s too volatile,” he told CNBC. He offered a more probable outcome for bitcoin: “gold for Millennials.”

3. It’s the reserve currency of the ICO market.

What’s an ICO? An “initial coin offering” is essentially a way for a company to crowdsource funds without selling shares. Instead of accepting public money in exchange for equity, as in an initial public offering, or IPO, an ICO offers digital tokens denominated in a new cryptocurrency.

The conventional wisdom on ICOs is somewhat split. Some see it as an ingenious way for founders to quickly raise money without relying on the gatekeepers of venture capital. Others point out that it’s easy way to con poor dolts looking to buy into the crypto frenzy. And what a frenzy it is: In 2017, the ICO market exploded, raising more than $2 billion for new companies.

There are several ways that the ICO craze feeds, and is fed by, the bitcoin boom. First, some analysts believe that the most lucrative ICOs are driven, not only by gullible rubes, but also by bitcoin millionaires who want to diversify their investments without paying tax by cashing out of cryptocurrencies, which would trigger a capital-gains tax. ICOs fulfill that need.

Second, many ICO investors first convert their cash into bitcoin before buying tokens in a new cryptocurrency. As Tim Lee argues, this makes bitcoin the “reserve currency” of the crypto economy. Just as the U.S. dollar benefits from its status as the world’s reserve currency, accepted worldwide in lieu of or in exchange for the local currency, the same is often true of bitcoin in cryptocurrency markets. It’s possible that these factors work together in a feedback loop, where bitcoin millionaires seeking diversification raise the profile of ICOs, which increase the value of bitcoin.

This much is clear: Bitcoin’s valuation has gone nuts in tandem with the (perhaps equally nuts) boomlet in ICOs.

4. Maybe it’s just this simple: Bitcoin is an unprecedentedly dumb bubble built on ludicrous speculation.

It seems strange to call a currency a bubble. But lacking more specific terminology, bubble seems like the only word that would apply.

Even if one buys the argument that blockchain is brilliant, cryptocurrency is the new gold, and bitcoin is the reserve currency of the ICO market, it is still beyond strange to see any product’s value double in six weeks without any material change in its underlying success or application. Instead, there has been a great and widening divergence between bitcoin’s transaction volume (which has grown 32 times since 2012) and its market price (which had grown more than 1,000 times). 

Surveys show that the vast majority of bitcoin owners are buying and holding bitcoin to exchange them for dollars. Let’s be clear: If the predominant use case for any asset is to buy it, wait for it to appreciate, and then to exchange it for dollars, it is a terrible currency. That is how people treat baseball cards or stamps, not money. For most of its owners, bitcoin is not a currency. It is a collectible—a digital baseball card, without the faces or stats.

* * *

The explosion of bitcoin’s value has been pretty silly. But great things can be born of such silliness.

As Dan Gross wrote in his book Pop!, the soapsuds of burst bubbles often fertilize the next generation’s breakthrough technologies. Before the national telegraph, train system, and tech giants, there was a telegraph bubble, a train bubble, and (who could forget?) a dot-com and online-retail bubble. The blockchain, like each of those technologies, has the potential to become a critical piece of infrastructure for the digital economy, even if the price of bitcoin is crashing as you read this paragraph.

In my most illuminating conversation about bitcoin, I spoke with Christian Catalini, a professor of technology at MIT Sloan School of Management. He began by reciting the three classic purposes of money: unit of account (you can measure income in dollars), store of value (you can hold dollars in your wallet and they won’t “go bad”), and medium of exchange (give somebody dollars and they’ll trust the value). Would bitcoin meet all three criteria? Maybe, he said. But maybe it won’t—and it won’t matter.

“You could imagine that in the future there might be a cryptocurrency that is mostly a store of value, like gold,” he said. “It would be decentralized, and robust, but with high transaction fees. I might use it to buy a house, but not a coffee. On the other hand, others might be more useful for smaller payments. With digital tech, maybe we can have many different kinds of currencies, which altogether unbundle store of value from medium of exchange.”

What seems most certain is that the future of money will test our conventional definitions—of currencies, of bubbles, and of initial offerings. What’s happening this month with bitcoin feels like an unsustainable paroxysm. But it’s foolish to try to develop rational models for when such a market will correct itself. Prices, like currencies, are collective illusions. And the history of American bubbles suggests that national hallucinations, like the over-construction of the rail system in the 19th century, can undergird the very real transformations of the next generation, even after they go pop.



Of all of bitcoin’s uses—as a currency, a payment system, an investment, a commodity, a technology, a remittance network, a market hedge—perhaps its most notorious is as a facilitator of online drug transactions. For years now, the cryptocurrency has allowed anonymous purchasers to pay anonymous vendors on eBay-like markets, avoiding the use of the formal financial system and thus the easy intervention of the federal authorities.

“Making small talk with your pot dealer sucks. Buying cocaine can get you shot. What if you could buy and sell drugs online like books or light bulbs? Now you can: Welcome to Silk Road,” the journalist Adrian Chen wrote in an exposé for Gawker on the now-defunct market, back in 2011. At the time, Chen called it “the most complete implementation of the bitcoin vision” of freewheeling, anarcho-libertarian anonymity.

Seven years later, though, problems with using bitcoin on the dark web—a kind of mirror internet that uses encryption to ensure its participants’ privacy and features websites that are not accessible from standard browsers—have piled up. Purchasers and vendors are cancelling orders, losing money, and fleeing to other forms of cryptocurrency. Bitcoin remains in wide use for drugs and other illegal goods, but the shadowy markets that made it famous, and infamous, are turning on it.

The first issue lies in the extreme volatility of the price of bitcoin. The cryptocurrency has, since its very earliest days, been a highly unstable one, its price surging and collapsing much like that of a penny stock. Even so, the past year has proven unusually volatile, with dramatic day-to-day and even minute-to-minute swings and plunges. Investors crowding into the cryptocurrency—including those putting bitcoin on their credit cards, or taking out equity loans on their houses to buy it—and regulatory interest from governments around the world have helped to drive those fluctuations. And the currency’s short-term volatility has been matched by some longer-term volatility too: The currency’s value surged 1,300 percent last year, and it has fallen by more than half of late.

For Wall Street–type investors seeking to buy and hold bitcoin or risk-happy prospectors looking to make a quick buck, such price swings are generally a feature, not a bug. Nor are they problematic for many the many Silicon Valley entrepreneurs interested in the blockchain technology underpinning the currency. But this kind of volatility is a headache for participants in marketplaces with transactions denominated in bitcoin. That means the darknet markets, which have continued to crop up and collapse since the federal authorities seized Silk Road in 2013.

On those markets, the price of drugs and other illicit and licit goods are fundamentally pegged to dollars or euros, not bitcoin. Buyers think in terms of traditional currencies, in other words: An eighth of an ounce of marijuana is worth $25, not a minuscule fraction of a bitcoin. And vendors think in the same terms, often purchasing wholesale goods with dollars or other government-issued currencies, or seeking to sell their wares for cash in person. As such, “the price of a bitcoin does not matter,” Nicolas Christin, a computer scientist at Carnegie Mellon University and an expert on the darknet markets, told me. “But that it is stable matters.”

To understand why, it helps to know a bit more about the mechanics of buying drugs on the dark web. A purchaser buys bitcoin, reviews vendors’ offers on a marketplace, and then pays for his goods. His money generally goes into escrow before it is released to his vendor. This introduces a number of financial choke points and transaction delays: between when the purchaser procures bitcoin and makes a purchase, when the vendor receives the order and receives payment from escrow, and when the vendor cashes out from the marketplace. Those are all moments when bitcoin’s volatility becomes problematic. For vendors, price drops while payments are in escrow might wipe out all the profits from a sale, for instance.

Complaints about these kinds of scenarios are rife in popular forums where buyers and vendors chat online, including on Reddit. “Seems I hear Vendors are sitting on the sidelines. If payment is in [bitcoin and] then [the] price falls all their work is for nigh,” one user recently posted, worrying that fewer vendors were selling given the market dynamics at work. Another complained, “Seriously?! I purchased coins this morning at like $675 and within 1.5 hours it dropped down to $625.”

Of course, licit markets have the exact same vulnerability to swings in the price of bitcoin. But those markets—with their deep-pocketed investors and ties to the formal financial system—have come up with ways to avoid them. “Merchants who want to avoid volatility will still accept bitcoin or cryptocurrency, and can use a service provider that automatically converts it,” Jerry Brito, the executive director of Coin Center, a nonprofit research and advocacy organization for cryptocurrencies, told me. “That service provider accepts bitcoin on their behalf, automatically converts it, and deposits dollars into the merchant’s account. That way they never face the volatility.”

But such businesses want nothing to do with illegal markets, meaning that marketplaces, vendors, and buyers have few if any ways to hedge. Some drug dealers urge their customers to “finalize early,” letting their payments out of escrow before they receive their goods. And some marketplaces have built in their own mechanisms to help manage volatility. Indeed, the original Silk Road provided a kind of insurance system against volatile cryptocurrency prices. “Ross Ulbricht was a very smart young man who got into a line of work he should not have been involved in,” said Christin, referring to the creator of Silk Road, who was arrested in 2013 and is now serving a life sentence. “He had very clever ideas, like this hedging system that exists in banks.” But other markets do not have the technological wherewithal to do so, or the willingness to absorb any volatility risk from their customers and vendors. As a result, many vendors cancel orders, or requests that their buyers cancel orders, to manage the swings.

It is worth noting that volatility has proven less of a problem when the price of bitcoin was shooting up, as buyers and vendors holding bitcoin found their currency worth more and more. (Indeed, in forum posts, some vendors note that they have made more money holding bitcoin than selling drugs.) But a crash in the price of bitcoin gives vendors far less of an incentive to do business on the darknet markets. “Volatility upwards is, of course, largely a good thing for [the darknet markets], as they produce a wealth effect,” wrote Gwern Branwen, a cryptocurrency researcher who goes by a pseudonym, in an email. Branwen added, “The really bad thing is when prices crash. This sets up an ugly dynamic for sellers: typically you still have to pay your expenses and your supplier in a fiat, so do you continue shipping out orders pre-paid with bitcoins which are now worth a lot less and may well incur a loss?”  

The second reason bitcoin is falling out of favor on the dark web has to do with the sudden increase in the cost of transacting in bitcoin. Here, again, it helps to get into the technical details for a moment. All bitcoin transactions are kept in a decentralized and public ledger. When someone makes a transaction with bitcoin, miners in the network solve cryptographic puzzles to verify and log it—and get paid a small fee in bitcoin to do so. That has given the cryptocurrency a scaling problem: As demand for transactions has gone up, the price to transact has gone up. Indeed, the price of a bitcoin transaction recently spiked as high as $55.

That might not be a problem for an investor. But for someone who’s just looking for some weed? “If you look at the average transaction on cryptomarkets, half of transactions are something like $30 or $50,” said David Décary-Hétu, a professor of criminology at the Université de Montréal. “It makes no sense to pay a commission of $35 for $50 of drugs.” Such transaction fees become especially problematic for anyone trying to make many smaller bitcoin transactions in order to avoid the attention of the authorities—such as drug dealers.  

Bitcoin’s fees and transaction delays have also pushed darknet market participants away from the cryptocurrency. “Which markets would YOU recommend, now that the bitcoin literally became unusable in low amounts?” one Reddit forum poster asked. “How should one adapt to this? The fees got enormous, the sites I use to buy [bitcoin] set their minimum amount you can buy up to 500€.” Another commenter stepped in to advise the user, recommending a rival cryptocurrency: “Monero appears to be the way forward, at least for now: as you said, bitcoin is currently unusable for smaller transactions.”

Another posting reads: “I think [it is] officially time to step away from [bitcoin], at least for the time being. Went to do a direct deal today with a vendor, realized my $250 purchase would end up costing me $315 or so with fees and would still take probably 24 hours to get to him,” a Reddit user wrote. “As of this morning the lowest electrum fee was approx $32 to send coin.... and people reporting at the highest level still not having coin move 12-16 hours later.”

A third issue has to do with anonymity—or really, a lack of it—as law-enforcement and regulatory agencies have become more interested in and sophisticated about monitoring cryptocurrencies. Though bitcoin initially promised completely anonymous transactions, the public nature of the blockchain system in fact has always meant that savvy observers could amass huge amounts of information on bitcoin users, identifying the addresses of popular darknet markets and making money-laundering more onerous. “It’s pretty well established at this point that bitcoin is not anonymous, and it is traceable,” said Sarah Meiklejohn, a cryptography expert at University College London. “If you are buying drugs, using bitcoin is not the best bet.”

Other coins offer more privacy, and people who use darknet markets are moving to options like Ether and Monero. “Alex Cazes is dead because he believed bitcoin mixers obfuscated his money trail,” one forum poster said, referring to the founder of the now-defunct market AlphaBay and “mixers” that would supposedly hide his illicit bitcoin transactions. “My advice. Convert your bitcoins into Monero.” Another argued: “While many of us have benefited from the surge in BTC price, it’s time we left it in the past and move on to something safer and more efficient. The wave starts with getting vendors and markets on board. While making an order I urge you to ask your vendor if they have considered switching to Monero (or alternative). If more customers want to pay with Monero, vendors and markets will want to switch to where customers have money.”

Even with these three factors, bitcoin still remains the common currency of the dark web. Given the difficulty of purchasing drugs and the lucrative nature of selling them, people are willing to put up with high transaction costs. Moreover, market participants have many other prevalent risks to worry about, and transaction difficulties to deal with: the threat of law enforcement running a market as a honeypot to catch dealers and purchasers; the threat of vendors stealing their customers’ bitcoin and suddenly disappearing; whole marketplaces scamming their vendors and customers; the question of how to launder huge amounts of money converted from bitcoin. “If you want heroin, you might be willing to pay a fee, or take these risks,” said Décary-Hétu.

Plus, they have few alternatives—unlike participants in licit markets, whose advantages bitcoin-denominated markets throw into sharp relief. The dollar and euro are stable, with prices shifting just a few percent per year. Online payment systems are cheap and reliable, with credit cards charging just a few percentage points to process a near-instantaneous transaction. Contemporary financial markets are rich marvels, offering hedges, insurance, security guarantees, and a seemingly infinite variety of other products to make buying goods and doing business easy.

Not so with bitcoin. Its original promise—to be more efficient, easy to use, low-cost, immediate, and anonymous than traditional banking—has turned out to be false. One can still use it to buy drugs, of course. But not so easily.



Back in the 1970s and ‘80s, Lower Manhattan was known for two things: its nightlife, and being a haven for artists, musicians, writers, and intellectuals. Bars, pubs, and clubs that were popular 30 years ago such as Studio 54, Max’s Kansas City, Area, Danceteria, and Palladium have since become the stuff of legend. People smoked, drank, did drugs, and stayed out late. Working out and healthy living seemed like the last thing on their minds.

Today, the very same streets are teeming with fitness-obsessed urbanites lining up at a myriad of “boutique fitness studios,” such as SoulCycle, Flywheel, Barry’s Bootcamp, CrossFit, CorePower, and Orangetheory, to name just a few. “Athleisure” shops and purveyors of green juice and acai bowls stipple the streets between them.

Indeed, the fitness industry has experienced an incredible boom in recent years. Health-club revenue topped $81 billion worldwide in 2015, according to the International Health, Racquet and Sports Club Association (IHRSA). That same year, more than 150 million members visited some 187,000 health clubs. Boutique fitness studios in particular have been attracting millions of dollars in investment capital. For example, in 2011, Equinox (the upscale gym with scads of urban locations across the country) and SoulCycle (which hosts sessions with stationary bikes) were purchased by the real-estate development firm Related, in part to enhance real-estate development projects across Manhattan.

These boutique studios are most prevalent in major cities. SoulCycle, one of the pioneers of the boutique fitness industry, has 17 locations in Manhattan and 3 more in Brooklyn. Those make up majority of the state’s 29 total studios. Outside of New York City, too, SoulCycle studios tend to crop in top-tier neighborhoods. In Los Angeles, for example, there are a number of studios in desirable areas, such as downtown, Hollywood, and Santa Monica. Chicago has a studio downtown in the Loop; Boston has one in the picturesque Beacon Hill area; and in San Francisco, there are studios in the bustling SoMa and Marina districts.

Pure Barre—a strength-training studio where classes are focused around a ballet bar—has clusters of studios in urban areas such as New York City, San Francisco and Los Angeles; Houston, Dallas, and Austin; Orlando and Miami; Boulder and Denver. A glance at the location maps of these and a few other leading fitness studios shows their disproportionate concentration in major metro areas.

The Locations of Pure Barre Studios in the U.S.

Charting the location of fitness trainers and aerobics instructors provides another lens into the geography of the fitness revolution. More than 250,000 people were employed in these fields as of May 2016, according to the Bureau of Labor Statistics. And employment in these occupations is projected to grow by another 10 percent between 2016 and 2026.

California leads the nation in the sheer number of fitness instructors, with more than 30,000 in all. That’s almost double the number of instructors than in each of the next five leading states: New York has about 18,000, followed by Texas (14,800), Florida (13,870), and Illinois (13,350). But these figures are a function of these states’ large populations. A metric called a “location quotient,” or “LQ,” provides a better gauge of how states actually measure up, by comparing the percentage of a metro area's workers who are fitness instructors to the percentage nationwide, and then expressing those two figures as a ratio. The leading states on this measure are Virginia and Massachusetts, which both have LQs of 1.58—meaning that the proportion of workers there who are trainers or instructors is a little more than one-and-a-half times the national average. Colorado (1.56), New Jersey (1.51), and New Hampshire (1.50) are not far behind.

As the map below shows, there appear to be two broad fitness belts, according to this metric—one across parts of New England and the Mid-Atlantic, and the others along parts of the Plains, the Rockies, and the Northwest. The Deep South and the Midwest have the lowest ratios for fitness trainers and aerobics instructors. These places are among those with the highest levels of obesity as well. In this way, the urban fitness revolution reflects the large and growing divide in Americans’ health and well-being, no less because the classes themselves are expensive—at many boutique studios, the cost of entry is anywhere between $30 and $40 a class, if exercisers don’t buy them in bulk.

Fitness trainers and aerobics instructors are even more concentrated at the level of the city. It’s no surprise that large metros like New York City, Chicago, Washington, D.C., and Los Angeles contain the greatest number of them. But looking at LQs to control for population, smaller places, including a number of fitness-oriented college towns, come to the fore. San Rafael, California—just across the bay from San Francisco in upscale Marin County—tops the list with a high LQ of 3.4. Also among the top 10 are Eugene, Oregon (2.6), which is home to the University of Oregon and is often referred to as “the running capital of the world”; Lynn-Saugus-Marblehead (2.5), a coastal boating, sailing, kayaking and fishing mecca outside of Boston; and Boulder, Colorado, home to the University of Colorado and a gathering place for runners, cyclists and skiers.

There are many things to like about the urban fitness revolution. Working out is surely a better way to live than smoking, drinking, and staying out all night. It’s also a way to forge community and escape the potential loneliness of everyday urban life. As one Toronto-based trainer, who owns a CrossFit gym in the city’s Liberty Village area, says, “It’s about having a few hundred members who get to belong somewhere… It’s the rise of the community gym.”

The urban fitness boom also helps to upgrade routine jobs by introducing more-personalized service-oriented jobs to the market. The median yearly salary for fitness trainers and aerobics instructors across the U.S. is $42,780. It is as high as $50,000 in Seattle, Boston, and Los Angeles, and more than $67,000 in New York City. While these instructors make considerably less than the knowledge and professional workers many of them coach, they take home a much larger salary than tens of millions of the nation’s service workers, the majority of whom make about $32,000 a year.

But there are some more-insidious elements to the urban fitness revolution. For one, the obsessive focus on staying fit reflects the growing pressure that many urban professionals face to look young and in shape. Exercise can also be a means of generating the physical stamina and mental focus required for long hours of knowledge work. As such, it is bound up with the relentless trends of the knowledge economy, which creates a lifestyle of continuous improvement. Indeed, this is built into the very mantra of many urban fitness studios: Many of them pledge not just to change your body, but to “change your life” and help you “find your soul.”

This post appears courtesy of CityLab.



When PepsiCo decided to create a new premium water brand last year, it came up with LIFEWTR—a clear plastic bottle with a black cap and a colorful, eclectic series of labels designed by emerging artists. Art is a central part of the LIFEWTR brand. Through it, PepsiCo also donates art supplies to public schools and has endowed a $100,000 annual fund for the Brooklyn Museum to purchase new works.

PepsiCo is only the latest example of a brand making substantial, and sometimes surprising, new investments in art and artists. BMW has been producing Art Cars since 1975, Absolut has had artists design its vodka bottles since 1986, and Louis Vuitton has commissioned collections of handbags by artists such as Takashi Murakami, Yayoi Kusama, and Jeff Koons since 2003. But the phenomenon of brands positioning themselves as patrons of creative culture has accelerated in recent years, driven, it seems, by the rise of visual-centric social media and the merging of contemporary art with mainstream pop culture. Facebook, Kickstarter, and Adobe host artists-in-residence in their offices, and most WeWork locations commission a mural from local street artists. Dolby invites artists to constantly reconceive its logo. Nike regularly unveils sneakers designed by artists, and sponsors new media installations in cities like Hong Kong. Calvin Klein recently engaged the artist Sterling Ruby to redesign its flagship boutiques in Manhattan and Paris. Uniqlo not only puts art on T-shirts, but sponsors a grant for public artworks in New York City’s parks. Earlier this year, OkCupid tapped the Italian conceptual artists Maurizio Cattelan and Pierpaolo Ferrari to design a marketing campaign.

The relationship between art and commerce has always been filled with anxiety. The speculative art model, in which the lone genius creates a painting in her studio and later seeks a buyer, has existed for scarcely more than a hundred years. For centuries before that, artists created bespoke works following the explicit instructions of a client, be that the church, a king, or a wealthy merchant. Even in the modern art market, the tastes of collectors and institutions have influenced what artists make. Though artists aspire to create “art for art’s sake” instead of for the vulgar marketplace, even the most radical avant-garde creators have been tethered to the bourgeoisie, as the art critic Clement Greenberg put it in 1939, by “an umbilical cord of gold.”

The question “What if Nike is the new Medicis?” began as an art-world in-joke about a decade ago, but has grown less absurd over time. With the diminishing impact of traditional advertising, companies are seeking new ways to capture the attention and goodwill of the public. In exchange, brands provide financial opportunities to emerging artists. “In some ways, the goals are a little amorphous,” Natasha Degen, a historian of the art market at New York’s Fashion Institute of Technology, told me. “The lines are becoming very blurred between corporate social responsibility, philanthropy, and marketing.” In a vacuum of meaningful public-arts funding, and in contrast to the stratified commercial art market, brands have the potential to be an alternative pillar of support for artists. Can this new gray area be called patronage, and if so, what would that mean for art?

Over my career as an art critic, curator, and strategist, I’ve observed this shifting landscape up close. In 2009, I was working in Beijing as the studio manager for the artist Cao Fei when she was approached by Hermés to make a film for the brand’s traveling exhibition “HBOX.” I knew Cao to be uncompromising in all aspects of her vision, so I was initially surprised that she’d consider the project. Then she explained that the brand was giving her carte blanche—she just had to put its logo in the end credits. As she saw it, Hermés was essentially paying her to make a video she would have made anyway—and, in paying her a significant fee, would also fund another more experimental project she wanted to do.  

Cao genuinely enjoys tinkering with brands, mass culture, and, by extension, the infrastructure of capitalism itself. She had previously created a project called Whose Utopia, as part of a residency sponsored by Siemens in its light-bulb factory in Guangzhou, in which she collaborated with workers to make a film about their personal dreams and lives outside of the assembly line. More recently, Cao has collaborated with BMW (which commissioned her to make a highly experimental Art Car in 2017) and JD.com, the Chinese online retail giant (which she approached directly for logistical, not financial, support in making Asia One, a new film currently on view at the Guggenheim that considers the future of automation and human-robot interactions).

She has joked that, in designing her art car, she was the most “demanding” artist BMW ever worked with, continually pushing back on the collaboration to make it more interesting to her. She insisted on visiting BMW’s Chinese factories and meeting their workers, to understand more about how they run their business in China.

“For me, it’s a kind of art education for the company,” Cao told me recently. “These companies are so big and influence our whole society. If an artist can influence one of them, change them even a little bit, then even if they’re still just selling a product it might be more human.” She sees the entire process as a form of social research, and finds meaning, and perhaps a kind of Robin Hood–esque satisfaction, in the interplay. “That is the interesting point,” she said. “How the brand and artist are fighting.”

In the years since I worked for Cao Fei, I’ve worked on projects for brands such as Converse, Ford, Absolut, Airbnb, and Gucci. (I even helped co-found a publication that analyzes such collaborations through interviews with the brands and artists involved.) In my experience, working with a brand has most of the same trade-offs as with any other source of funding. There’s the need to diplomatically shape expectations, negotiate careful contracts, manage different communication styles, and ultimately protect artists—who are often the most vulnerable party in the equation—and their vision. I’ve found that while it’s easy to be cynical about a project funded by a brand that sells handbags or energy drinks, it’s useful to investigate one’s visceral reactions and to see these initiatives in a broader historical and economic context.

In a precarious economy, a growing number of young artists similar to Cao Fei see value in projects with ties to brands. “The notion that somebody is selling out to do that kind of collaboration”—a typical reaction in years past—“has completely fallen away,” Martha Buskirk, an art historian at Montserrat College of Art, told me. She observed that the “professionalization” of being an artist has made art school more essential, which means more artists are starting their careers with MFAs—and the hefty debt that entails. Also, as studio rents in urban areas have risen, “there’s not a lot of room for idealism that ignores how to make a living.”

Still others are attracted by the possibility to share their art with a wider audience, and to blur the distinctions between “pop” and “high” art. Shantell Martin, an artist who recently designed her third collection of shoes and apparel with Puma and has worked with other brands including Autodesk and Warby Parker, finds that in comparison to traditional exhibitions at galleries or museums, brand collaborations are often “more accessible and visible for much longer” to a broad public. Also, she said, “you’re able to make something you would not be able to make as an individual,” such as large-scale manufacturing of shoes or sunglasses.

However, artists are struggling to navigate the asymmetrical power relationship with large corporations, and to weave these one-off projects into a sustainable career. With no standardized fees, contracts, or best practices, artists are typically left to negotiate and advocate for themselves with little leverage. “They expect you to be super-professional on your side, but then they’re unprofessional on their side,” Amalia Ulman, a new-media artist based in Los Angeles who has collaborated with brands in the past (including two collaborations that I worked on, for Gucci and Airbnb), told me. In some cases, she said, companies have canceled large commissions at the last minute without any payment. “They can decline the project with almost no notice, or compensation, or anything.”

What’s more, some artists and critics are concerned that this influx of branded capital may prioritize certain kinds of art production over others —i.e., works that are shiny, colorful, and Instagrammable, instead of conceptual, political, and challenging. It’s true that most branded projects don’t allow artists to approach sensitive topics such as sex, violence, or political critique—or meta-critique of the brand itself (though a memorable exception was a video by the Swiss artist Sylvie Fleury depicting the destruction of Chanel handbags, included in the 2008 Chanel Mobile Art Pavilion). Ulman has often been frustrated by these restrictions. “For a brand to be able to work with an artist,” she said, “they can’t expect the artist to do something that is not art.” The brand has to allow the artist breathing room. “If you’re already telling them what font to use,” she said, “then what’s the point?”

Of course, art history reminds us that patrons of every era have shaped aesthetic trends and set the bounds of political expression. In countries like China, unbridled creative speech has never been guaranteed, so it’s perhaps unsurprising that artists there were among the first to be less sentimental and more pragmatic about both the benefits and limitations of this type of partnership—a sensibility that then filtered into other places. In addition, there’s a potential benefit in having these stakeholders and transactions so transparently mapped out. Sean Raspet, who is interested in blurring the distinction between the art economy and rest of the economy, told me, “The content of a work of art might be a very radical politics, but then the economics of the work is still selling to the .001%, as an object for a collector to speculate on.” If an artist is working with a consumer brand, then “at least the cards are on the table, and there isn’t this much of a disconnect between where the money’s coming from and how the artist is functioning.”

Raspet is going especially far in muddling these categories. As an artist and self-taught flavor chemist, in 2015 he went to work in the R&D department at Rosa Labs, the company that manufactures the beverage Soylent, to develop new flavors. (Rosa Labs introduced one of them, Nectar, to its product line, but it is now discontinued.) His contract stipulated that the artificial flavors he designed there were technically his own artworks, and could be displayed (and sold) as such in the future, though Raspet has not done so yet.

In the 1961 essay “The Plight of Culture,” Clement Greenberg wrote that in premodern societies with no clear boundary between “work” and “leisure,” “work and culture tend to be fused in a single functional complex”—uniting art, religion, craft, and the techniques of production. In the postindustrial age, as labor and leisure collapse once more, Greenberg speculated that work and culture will likely merge again. The new wave of brand patronage may be less a cause than a reflection of this change.

Perhaps in coming years, artists will complete the shift,  from making functionless objects for rich people to shaping daily life for the masses. In that process, some artists might circumvent the need for the brand-patron altogether. Raspet eventually left Rosa Labs to found his own experimental sustainable-food company called Nonfood, which makes things like an algae-based snack bar—a conceptual artwork, a political gesture and, at the same time, a product. How does it taste? Like nothing else on the market.



Andrew Cherng started working in the United States at 18, while he pursued an undergraduate degree in mathematics at Baker University, in Kansas. Starting in 1967, he began spending his summers in New York City, working in a restaurant where his father had connections. It was his first real job. The work was fast-paced, his English wasn’t perfect, and New Yorkers were ruthless, he says.

After Cherng had been working in the restaurant for six summers, his cousin, who also lived in New York, decided to open a restaurant in Washington, D.C. The new business needed a manager, and Cherng seemed an obvious choice. In 1972, his cousin moved the restaurant to Hollywood, and Cherng followed. Several months later, Cherng’s parents moved to the United States.

In 1973, Cherng and his father found a place to start their own restaurant: Pasadena, California. After six months of remodeling, Panda Inn, which would inspire Panda Express, was created. Cherng ran the dining room while his father ran the back. Cherng’s father died in 1981, before he could see the restaurant chain take off.

Panda Express now has 2,000 restaurants globally and more than 35,000 workers. I recently spoke with Cherng about his first jobs in the United States, how they differed from his father’s experience working in restaurants in China, and how he created Panda Express’s company culture.

Lola Fadulu: What was your first job?

Andrew Cherng: I grew up in Asia. Just before coming to the United States, we actually moved to Japan from China. I was a high-school student for the most part. My father got me a job in the kitchen in a restaurant somewhere in Chinatown in Yokohama, Japan.

Then I came here, to the U.S. One of my first jobs was working in a school cafeteria as a dish washer. We had this industrial bacterial dish-washing machine. So there would be people working, and the plates, the silverware, would go onto this moving assembly-line-like thing. They’d go through a very hot wash. I had the job of picking up the hot plates at the end of it. And it was really, really hot. By the end of it, my hands got pretty tough.

Fadulu: How was working in a school cafeteria for you?

Cherng: It was okay. I mean, you know, it was a job. You’d have to be pretty quick because if the plate does not get picked up, the line stops. When I was in college, I also worked in the library. I did some filing and organized some shelves in the library and stuff like that. One of the more relevant jobs that I’ve done is that from the first summer, which is 1967. I actually went to New York and, for the first time, learned how to work in a restaurant. That was really an eye-opener, because that’s when I found out how difficult it is to adjust to working in a restaurant.

Working as a waiter—that wasn’t easy. I remember I took a job in Clifton somewhere. The restaurant was pretty big, and there were a couple people working, a couple waiters working. One minute, the restaurant was pretty slow, and within 15, 20 minutes, my section was totally full, and that’s probably 10 tables. I was like, “Are you kidding me? I don’t know how to do this.” And I don’t even know how I got through it. I worked in New York all through my college years, including graduate school. Just about every vacation, I would either fly up, or I would drive up from the Midwest—from Kansas when I was in college, and Missouri when I was in graduate school. So I worked five or six summers, plus Thanksgiving, Christmas holidays, New Year’s, and those times.

Fadulu: Why New York, specifically?

Cherng: My father knew some friends working in New York, and that’s where I knew some people who could help me. He got me in touch with the people who helped me, so that’s where I went. My father was a chef.

My dad actually started to work in restaurants at a very young age, in China. My dad grew up in the countryside, and he never went to school.

Fadulu: How did working in restaurants in New York inform how you went about creating Panda Express?

Cherng: We always think about getting our people to adopt to this idea of I can do more than just working, I can learn to take responsibilities, I can thrive, and I can also help other people to do the same. We like people who work hard and didn’t think they could be a manager; when we suggest it to them, we have to push them a little bit. We like that because taking responsibility is something they can learn. Restaurant people, by nature, don’t mind working hard, because it is a seven-day week. You work harder on holidays—that’s expected. If you’re looking for an easy job, you wouldn’t work in the restaurant. We need to figure out how they should grow personally.

One of our values is continuous learning, whether you go back and get a degree or whatever learning they think will help them advance themselves.



“Welfare makes people lazy.” The notion is buried so deep within mainstream political thought that it can often be stated without evidence. It was explicit during the Great Depression, when Franklin D. Roosevelt’s WPA (Works Progress Administration) was nicknamed “We Piddle Around” by his detractors. It was implicit in Bill Clinton’s pledge to “end welfare as we know it.” Even today, it is an intellectual pillar of conservative economic theory, which recommends slashing programs like Medicaid and cash assistance, partly out of a fear that self-reliance atrophies in the face of government assistance.

Many economists have for decades argued that this orthodoxy is simply wrong—that wisely designed anti-poverty programs, like the Earned Income Tax Credit, actually increase labor participation. And now, across the world, a fleet of studies are converging on the consensus that even radical welfare programs—including basic-income programs and what are called conditional cash transfers—don’t make people any less productive.

Most notably, a 2015 meta-study of cash programs in poor countries found “no systematic evidence that cash transfer programs discourage work” in seven different countries: Mexico, Nicaragua, Honduras, the Philippines, Indonesia, or Morocco. Other studies of cash-grant experiments in Uganda and Nigeria have found that such programs can increase working hours and earnings, particularly when the beneficiaries are required to attend classes that teach specific trades or general business skills.

Welfare isn’t just a moral imperative to raise the living standards of the poor. It’s also a critical investment in the health and future careers of low-income kids.

Take, for example, the striking finding from a new paper from researchers at Georgetown University and the University of Chicago. They analyzed a Mexican program called Prospera, the world’s first conditional cash-transfer system, which provides money to poor families on the condition that they send their children to school and stay up to date on vaccinations and doctors’ visits. In 2016, Prospera offered cash assistance to nearly 7 million Mexican households.

In the paper, researchers matched up data from Prospera with data about households’ incomes to analyze for the first time the program’s effect on children several decades after they started receiving benefits. The researchers found that the typical young person exposed to the program for seven years ultimately completed three more years of education and was 37 percent more likely to be employed. That’s not all: Young Prospera beneficiaries grew up to become adults who worked, on average, nine more hours each week than similarly poor children who weren’t enrolled in the program. They also earned higher hourly wages.

This finding has direct implications for the United States, where a core mission of the Republican Party is to reduce government aid to the poor, on the assumption that it makes them lazy. This attitude is supported by many conservative economists, who argue that government benefits implicitly reward poverty and thus encourage families to remain poor—the idea being that some adults might reject certain jobs or longer work hours because doing so would eliminate their eligibility for programs like Medicaid.

But this concern has little basis in reality. One of the latest studies on the subject found that Medicaid has “little if any” impact on employment or work hours. In research based in Canada and the U.S., the economist Ioana Marinescu at the University of Pennsylvania has found that even when basic-income programs do reduce working hours, adults don’t typically stay home to, say, play video games; instead, they often use the extra cash to go back to school or hold out for a more desirable job.

But the standard conservative critique of Medicaid and other welfare programs is wrong on another plane entirely. It fails to account for the conclusion of the Prospera research: Anti-poverty programs can work wonders for their youngest beneficiaries. It’s true north of the border, as well. American adults whose families had access to prenatal coverage under Medicaid have lower rates of obesity, higher rates of high-school graduation, and higher incomes as adults than those from similar households in states without Medicaid, according to a 2015 paper from the economists Sarah Miller and Laura R. Wherry. Another paper found that children covered by Medicaid expansions went on to earn higher wages and require less welfare assistance as adults.

“Welfare helps people work” may sound like a strange and counterintuitive claim to some. But it is perfectly obvious when the word people in that sentence refers to low-income children in poor households. Poverty and lack of access to health care is a physical, psychological, and vocational burden for children. Poverty is a slow-motion trauma, and impoverished children are more likely than their middle-class peers to suffer from chronic physiological stress and exhibit antisocial behavior. It’s axiomatic that relieving children of an ambient trauma improves their lives and, indeed, relieved of these burdens, children from poorer households are more likely to follow the path from high-school graduation to college and then full-time employment.

Republicans have a complicated relationship with the American Dream. Conservative politicians such as Paul Ryan extol the virtues of hard work and opportunity. But when they use these virtues to inveigh against welfare programs, they ignore the overwhelming evidence that government aid relieves low-income children of the psychological and physiological stresses that get in the way of embracing those very ideals. Welfare is so much more than a substitute for a paycheck. It is a remedy for the myriad burdens of childhood poverty, which give children the opportunity to become exactly the sort of healthy and striving adults celebrated by both political parties.



CHICAGO—Americans hear a lot these days about the country’s urban-rural divide. Rural counties are poorer; urban ones richer. Rural areas are losing jobs; urban ones are gaining them. People with a college education are leaving rural areas. They’re moving to urban places.

Behind this divergence lies a straightforward story: The twin forces of globalization and technological change are enriching a handful of big urban areas, while resources are drained from the heartland, leaving it often devoid of opportunity and prosperity. But this neat division, rural versus urban, erases another part of the story of America’s changing economy: the pressure that those twin forces are exerting within cities, pulling some people up to the very top while pushing others to an unforgiving bottom. In some prosperous cities, such as Chicago, where the number of wealthy census tracts has grown fourfold since 1970, people at the bottom are struggling as much as they always have, if not more—illustrating that it’s not just the white rural poor who are being left behind in today’s economy. The disconnect is why Andrew Diamond, the author of Chicago on the Make, has called Chicago “a combination of Manhattan smashed against Detroit.”

Like many of America’s biggest cities, Chicago has thrived in the globalized world—at least on a superficial level. The evidence is everywhere, from the gleaming office towers and condos going up alongside the river to the prosperous international companies like Motorola Solutions, the whiskey giant Beam Suntory, and GE Healthcare that have relocated their headquarters to downtown. In May, the unemployment rate for the Chicago metropolitan area sank to 4.1 percent, the lowest since the government started tracking it in 1976. (It has since ticked back up to 5.3 percent.) Almost one-quarter of households in the city of Chicago earned more than $100,000 a year in 2016, according to census data. These factors are part of why Chicago was one of just four U.S. cities to be named one of PricewaterhouseCoopers’s “Cities of Opportunity,” in its periodic report on places that foster economic innovation and “common wellbeing.”

But this prosperity isn’t filtering down to people like Brastell Travis, a 21-year-old who lives in the city’s Englewood neighborhood. Many mainstream economists believe that it should: In theory, people who live in booming cities with a highly educated population will have more opportunities than those in rural areas because the successful workers in cities will spend money, creating jobs for less-educated people. For each new job for an educated worker in a city, five additional jobs are created for people like construction workers, waiters, and hairdressers, according to research by Enrico Moretti, an economist at the University of California, Berkeley. Someone like Travis, who has lived in Chicago his whole life, just miles from this growth, should be surrounded by good job opportunities.

Travis couldn’t afford college, but he wanted a good, steady job with a solid paycheck, so he decided to become a welder like his grandmother before him. But after taking a 13-week course to get a welding certificate, Travis hasn’t been able to find a full-time job in Chicago. He’s currently piecing together two part-time jobs that both pay minimum wage. Part of the problem, he told me, is that kids that grow up in neighborhoods like his often don’t know how to apply to jobs or where to seek out help. “I think there’s not as many resources as there are in other neighborhoods,” he told me. Meanwhile, because of where he went to high school, he can’t apply for jobs in certain neighborhoods, because he could become a target of violence if he goes to the wrong areas of town, he said.

Why are large swaths of Chicago’s population unable to get ahead? There are two main reasons. The first and most obvious is the legacy of segregation that has made it difficult for poor black families to gain access to the economic activity in other parts of the city. This segregation has meant that African Americans live near worse educational opportunities and fewer jobs than other people in Chicago. City leaders in Chicago have exacerbated this segregation over the years, according to Diamond, channeling money downtown and away from the poor neighborhoods. “Public policies played a huge role in reinforcing the walls around the ghetto,” he told me.  

The second factor is the disappearance of industrial jobs in factories, steel plants, and logistics companies. Half a century ago, people with little education could find good jobs in the behemoths that dotted Chicago’s south and west sides. Now, most of those factories have moved overseas or to the suburbs, and there are fewer employment opportunities here for people without much education. Chicago underscores that it’s not just white, rural Americans who have been hard hit by the disappearance of manufacturing jobs.

These two factors have compounded each other, with people stuck in segregated neighborhoods, unable to access the education or job opportunities that could help get them out. Meanwhile, the middle-class black families that once sustained neighborhoods in Chicago continue to leave for even better opportunities—Chicago lost 181,000 black residents between 2000 and 2010, most of them middle-class people who could afford to pick up and move elsewhere—which further widens the gulf between the rich and poor.

The repercussions of missing out on this economic boom are huge for people like Brastell Travis. There are jobs in the suburbs, but he can’t get to them to even apply—he doesn’t have a car. He can’t travel to many neighborhoods in Chicago, he told me, because of gang turf wars that often end up harming innocent people from one neighborhood who end up in another. When he applies to jobs, he’s told he needs a college education. “In school, they tell you to go to college, but I don’t have the grades,” he told me. “They don’t tell you how to find a job.”

For a long time, Chicago represented a step up for many African Americans. Some 6 million of them left the oppression and violence of the Jim Crow South for industrial cities like Chicago during the Great Migration, which began in 1916. African Americans who settled in northern cities like Chicago, New York, and Detroit earned at least twice as much as those who stayed in the South in 1930, according to work by Leah Boustan, an economics professor at Princeton.

Many jobs were located along rail routes outside of Chicago’s central Loop area. By the mid-1950s in North Lawndale, for instance, a predominantly black neighborhood on Chicago’s west side, a Western Electric plant employed over 43,000 workers, an International Harvester plant had employed 14,000 workers, and the headquarters of Sears, Roebuck and Company employed 10,000 people, as the Harvard sociologist William Julius Wilson documented in his 1996 book, When Work Disappears. People employed in manufacturing spent money on goods and services, creating jobs in the neighborhoods where they lived. For every black man who worked at a factory, others found jobs at restaurants and grocery stores and shopping centers where manufacturing workers spent their money, most of which were located near where workers lived, in the city’s south and west sides.

Of course, not everything was rosy for black Chicago residents, even during manufacturing’s heyday. As my colleague Ta-Nehisi Coates documents in his seminal June 2014 cover story, “The Case for Reparations,” African Americans with the money to buy homes in Chicago were prevented from doing so by policies like redlining, which made it impossible to get a federally backed loan for homes in majority-black neighborhoods. African Americans were also kept out of certain neighborhoods through racially restrictive covenants—Coates writes that half of Chicago’s neighborhoods were effectively off-limits to blacks by the 1940s. At the same time, the Chicago Housing Authority was building public housing in predominantly black neighborhoods, further amplifying segregation. And when black residents did finally begin moving into majority white neighborhoods, real-estate agents encouraged white homeowners to list their homes for sale and decamp for the suburbs, telling them their home values would soon drop.

Segregation is problematic in many ways, but this isolation proved especially devastating when big employers in these neighborhoods began to move out in the 1960s. The huge Western Electric plant closed in the 1960s, Sears moved its headquarters downtown, and the Hawthorne plant began to cut back operations and finally closed in 1984, according to Wilson. When the big plants left, so, too, did smaller businesses like banks and gas stations that relied on the business of the people who had worked at the big companies. Wilson estimates that North Lawndale lost 75 percent of its businesses from 1960 to 1970 alone. Businesses weren’t only leaving North Lawndale. In the South Side of Chicago, for instance, steel plants like Acme Steel and factories like the General Mills cereal plant began to close. There were 11,646 retail jobs in the Back of the Yards neighborhood on Chicago’s near South Side in 1970, according to a report by the Great Cities Institute at the University of Illinois at Chicago. By 2015, there were just 1,849 such jobs. Some businesses moved to the suburbs—Wilson writes that over a 20-year period ending in the 1990s, the majority of the jobs created in the Chicago area were in the northwest suburbs, where black residents made up less than 2 percent of the population. Others moved operations overseas.  

Meanwhile, as jobs disappeared, there was little effort put into replacing them. While today, government agencies are spending money retraining white working-class workers who lost their jobs because of outsourcing and automation, little such effort went into helping the newly unemployed black residents of Chicago. “When the decline started, there was no replacement of those industries, no forethought given to, ‘How do we replace what went away?’,” Shari Runner, the CEO of the Chicago Urban League, told me. In 1960, 33 percent of black workers in Chicago were employed in manufacturing, according to a report by the Great Cities Institute. By 2015, just 5 percent of black workers were employed in manufacturing. Low-skilled workers were left to compete with each other for the few jobs left.

The disappearance of industrial jobs and the businesses that supported them jump-started a downward spiral in many neighborhoods. As joblessness began to rise, the neighborhoods changed from ones where most people were employed to ones where some people were employed. As Wilson documents, 70 percent of black men nationwide worked full-time, year-round in the 1970s—but by the 1980s, only half did. As more men stopped working, neighborhoods became places where the majority of people no longer worked or did much that was otherwise productive during the day. “There’s a qualitative shift in the neighborhood, and it becomes a cycle, where people begin to feel like it’s dangerous, like they want to move out,” Chad Broughton, a sociologist at the University of Chicago, told me. Once neighborhoods began to feel unsafe and unstable, black middle-class families who could afford to live elsewhere moved out.

This emptying-out was detrimental for the people who remained for many reasons. Kids growing up in neighborhoods that once had a good mix of middle-class and low-income families were now surrounded predominantly by people who weren’t working, or who were struggling. They had fewer role models who had good jobs, who graduated from high school, who went to college. The social networks and connections available to people make a big difference in how they see the future.

That’s been the experience of Kenneth Graves, who was born in 1977 and raised on the South Side of Chicago. He’s been cycling in and out of full-time work for more than a decade. Being surrounded by violence and drugs made it hard to think about doing well in school, or going to college, or even getting a good job, he told me. “If you’re in an environment where you see nothing but nice roses and nice people with good vibes, people living the way you’re supposed to live as a citizen, then it’s like a role model, you can do the same thing,” he said. “But if you’re in an environment where it’s crackheads and fights and arguments and gangs and poverty, it motivates you to do that as well.”

The people who remained also had less access to stable, good-paying employment. Today, the bulk of jobs in Chicago are located in the Loop area or North Side neighborhoods, according to the Great Cities Institute. Up to 700,000 jobs are located within a 30-minute train or bus ride from the Loop and North Side, according to the organization, while just 50,000 jobs are located within a 30-minute commute on public transit from the South Side. “The investment in those places where there is a lot of growth, and where the city is booming—the Loop, for example—are not the places where most African Americans live,” Runner, of the Chicago Urban Institute, said.

This lack of good jobs means that African Americans who are stuck in segregated neighborhoods but who want to work usually have to travel far to find good opportunities. I talked to Cyrus Walton, a 20-year-old who lives in Chicago’s Englewood neighborhood. Walton graduated high school in 2015 and found a job working at UPS. But he eventually had to quit because his start time was 3 a.m., and it was difficult to get to the facility, which was 45 minutes away, from his house in the middle of the night without a car. He said it was nearly impossible to get a job closer to home—he’d apply but be told the companies weren’t hiring. Meanwhile, he’s stuck in the neighborhood where, he told me, “you have to look over your shoulder every five minutes.”

Chicago has one of the worst unemployment rates in the country for people in their early 20s. People in that age group are worse off than they were in 1960, according to a separate report by the Great Cities Institute. Around 40 percent of black 20-to-24-year-olds in Chicago are out of work and out of school today, compared with 7 percent of white 20-to-24 year-olds in Chicago.

Some researchers say that the lack of economic opportunities for youth has given rise to a cycle of violence that ravages neighborhoods on the South Side. Murders in Chicago increased by 58 percent between 2015 and 2016, and the number of nonfatal shootings grew by 43 percent, according to the University of Chicago Crime Lab. “If you’re in a low-opportunity area, the hypothesis is that having fewer economic opportunities available makes it hard to make a living outside of a black-market economy,” said Katie Buitrago, one of the authors of a report about the intersection of poverty and violence for the Heartland Alliance. As violence racks neighborhoods, the cycle of disinvestment continues, as more businesses and families leave.

In Chicago, unlike many global cities, the neighborhoods that struggled 30 years ago are still the neighborhoods that struggle today. While New York’s East Village has changed completely in the past three decades, Chicago’s Englewood has been slower to change.

Chicago residents have what Robert J. Sampson, a Harvard sociologist, calls “mental maps” of the city—deeply held perceptions about different neighborhoods. Many people, black and white, see large swaths of Chicago as places they would never live, no matter how affordable the rents or good the amenities. So while wealth is creeping into some poor neighborhoods in cities like New York or Los Angeles as upper-class people move back to cities, less gentrification has taken place in poor, black neighborhoods in Chicago. “In racially segregated cities, people look at the city in different ways—they won’t even consider moving to entire quadrants of the city,” Sampson told me. In a study of Chicago published in the American Sociological Review, Sampson found that Chicago neighborhoods that were more than 40 percent black didn’t gentrify.  As middle-class residents stay out of such neighborhoods, so too do the businesses that they would patronize. The decades-old legacies of segregation, far from being reversed, are instead being reinforced.  

As the divide between rural and urban Americans becomes more pronounced, commentators from all over the political spectrum have advice for the white low-income people living in economically depressed rural areas: Move. Move to big cities, or to booming states like Texas, or to anywhere that is not a low-opportunity town that has seen economic opportunity pass it by. The idea is that global cities like Chicago, Los Angeles, and Seattle will improve the fortunes of anybody who moves there, through higher wages and more work opportunities. But global cities don’t mean economic fortune for everyone. African Americans living in segregated neighborhoods in Chicago actually have worse economic outcomes than African Americans in less-prosperous cities. Between 2000 and 2015, median wages for black workers in the Chicago area fell 17 percent, to $26,494. Meanwhile, in comparable cities like Los Angeles and Washington, D.C., they rose—by 1 percent in Los Angeles, to $33,909, and by 2 percent, in Washington, to $39,782. About 34 percent of African Americans in Chicago live in relative poverty, meaning they earn less than half of the local minimum wage. That’s compared to 25 percent of those in Los Angeles and 30 percent of those in Washington, according to Brookings. “Being a global city doesn’t also mean that you can’t be exclusionary and leave a lot of your population behind,” Alan Berube, a senior fellow at Brookings’ Metropolitan Policy Program, told me. The unemployment rate for blacks in the Chicago metropolitan area in the beginning of this year was 16.2 percent, compared to 4.7 percent for whites, according to the National Urban League. (In San Antonio, by contrast, the unemployment rate for blacks was 6.4 percent, compared to 4.5 percent for whites.) Chicago, the most segregated city in America, shows what happens when groups are separated by race and income for decades.

Aaron Dawson, a 35-year-old, grew up on the city’s west side. Dawson faced many of the same challenges of other people who grew up in rough neighborhoods in Chicago—he was raised by a single mother, he struggled with alcoholism, and his cousin, who was like a brother to him, was murdered in Englewood. But, Dawson told me, “My mother was a big advocate of me getting out of the neighborhood.” Rather than going to his struggling neighborhood school, Dawson attended high school in the wealthy Lincoln Park neighborhood of Chicago. He always tried to leave his neighborhood as much as he could, he told me, taking the train downtown to walk around the Loop, and just people-watch. Leaving his neighborhood illuminated to him just how depressed it was. “On the west side, the culture is that it’s cool to stand on the corner and sell drugs,” he told me. Dawson now works for a downtown nonprofit, Cara Chicago, which helps homeless and at-risk individuals find jobs. He attributes his success to leaving the neighborhood where he lived. “I was able to get out of that neighborhood, know there were things other than those four corners,” he told me.

But many African Americans living in Chicago don’t have that option. Housing in high-opportunity neighborhoods is expensive. And many times, people don’t have the resources needed to help them move. After Chicago began in the 2000s to dismantle its public-housing complexes, for example, families received vouchers that they could use to move elsewhere. But many of the families still ended up in impoverished neighborhoods, for many reasons. They didn’t know how to find housing in better neighborhoods, they couldn’t afford better neighborhoods with their vouchers, and they felt more comfortable with what they knew. A federal program that would have allowed voucher holders to use the vouchers in more upscale neighborhoods in selected cities, including Chicago, was suspended by the Trump administration in August.

Of course, it might not be logical to try to uproot every black Chicago resident who lives in concentrated poverty to a better neighborhood. People leaving the neighborhood is part of what led to this decimation in the first place. What many residents of Chicago’s poorest neighborhoods want to see is a return of businesses, of middle-class residents, of opportunity. This has happened only to a small degree so far. More than a year ago, for example, developers opened a new shopping complex with a Whole Foods, Chipotle, and Starbucks in a struggling area of Englewood. The city subsidized the development, and the stores coming in promised to hire local residents and provide shelf space for local businesses to sell their goods. Developers hoped that other projects would soon follow. “It’s like dropping a rock in the water. You get a ripple effect to go out from there,” Leon Walker, a managing partner of DL3 Reality, which developed the shopping complex, told me. A microbrewery plans to open up across the street from the Whole Foods in the fall.

It could take a long time for those ripples to reach out across other areas of the city, where low-income black residents are still looking for the good jobs that are supposed to come with a city’s improving prosperity. A few store openings in Englewood, after all, can’t make up for decades of industries closing their doors and moving away. New jobs may just be slow to come, and may spread out year after year, block by block. Or, Chicago could be the example that proves economists wrong. In the American economy today, there’s no guarantee that improved conditions benefit everyone. Cities are doing better and better in today’s economy. But at the same time, some of their residents are doing worse.



They’d cut back on traffic, ease air pollution, and complement public transit. Or so they said.

But the effects of Uber, Lyft, and other transportation-network companies (“TNCs,” in wonk-speak) are proving more complicated on city streets. In New York City, rapid growth in on-demand vehicles roving the roads—with and without passengers—is contributing to markedly slower traffic, as numerous analyses of Taxi and Limousine Commission data by Bruce Schaller, a transportation consultant and former NYC Department of Transportation official, have shown.

It’s an old saying that you can’t manage what you can’t measure, and because Uber and Lyft carefully guard raw trip data, the kind of analyses Schaller produces is hard to produce in many cities. At the 97th annual meeting of the Transportation Research Board this week, Schaller moderated a panel of experts from San Francisco, Chicago, New York City, and Boston on the importance of capturing on-demand mobility data—and how researchers are getting creative about gathering it.

San Francisco is by some measures the third-most congested city in the nation, but public officials found that ride-hailing companies weren’t all that helpful in figuring out exactly why. “There is lots of happy talk about collaboration,” said Joseph Castiglione, a panelist at the conference and the deputy director for technology, data, and analysis at the San Francisco County Transportation Authority (SFCTA). “But the type of information they claimed to be willing to share was not entirely useful.”

So researchers got savvy. After their requests for citywide trip data were apparently rebuffed by Uber and Lyft, researchers at Northeastern University built a software script that scraped reams of TNC vehicle-location information by sending automated data requests to Uber and Lyft’s platforms. San Francisco County Transportation Authority staff then cleaned, modeled, and mapped that information to estimate where, when, and how many daily trips occur.*

Their analysis found that more than 170,000 vehicle trips are made by TNCs within city limits on a typical weekday, which is about 15 percent of all car trips, and 9 percent of all trips, across different modes. “That’s a floor estimate,” Castiglione said—that is, it’s conservative. They also found that the vast majority of TNC trips are heavily concentrated in San Francisco’s northeast quadrant, which is already the densest, most congested part of the city, as well as the area best served by public transit, bike lanes, and walkable streets. Future studies will examine the extent to which TNCs might be adding to traffic and/or contributing to declines in Bay Area transit ridership.

In traffic-clogged Boston, Alison Felix, a transportation planner at the Metropolitan Area Planning Council (MAPC), a government-created agency, said that her city has also struggled with a scarcity of meaningful data from Uber, Lyft, and other ride-hailing companies. “The impacts of these services are not fully understood,” she said. “But they are most likely impactful.”

So the MAPC conducted a rider-intercept survey to study the issue. Of the nearly 1,000 TNC passengers surveyed in fall 2017 around the Boston metro area, more than 40 percent said they would have taken public transit if Uber or Lyft had not been available, and 12 percent said they would have walked or biked. Most cited speed and convenience as the main reasons for choosing an on-demand ride over buses or trains. “The responses to those questions provide strong evidence that TNCs are pulling from, not complementing, public transit,” said Felix.

To be sure, the battle for riders that Uber, Lyft, and other TNCs are winning isn’t particularly hard-fought. Service cuts and performance declines on many transit systems—especially bus networks—offer passengers little reason to stay loyal. In some cities, the rise of ride-hailing may be as much a statement on the quality of public transit as anything else. Schaller estimates that, in 2018, the number of annual for-hire vehicle passengers (which includes ride-hailing and the ever-shrinking pool of taxi trips) will outstrip the number of bus riders nationwide. “[This] shows the acute need for public transit to provide the same level of prompt, reliable and comfortable service that’s attracting people to TNCs,” he said via email.

That’s part of the story in Chicago. There, rail-transit performance and ridership are strong, but buses are another story. Joseph Schwieterman, the director of DePaul University’s Chaddick Institute for Metropolitan Development, told an audience at the TRB conference that in some cases, TNCs may be “filling a void” where bus service has fallen short of neighborhood needs. Without much TNC data to draw on, Schwieterman and his research colleagues studied the trade-offs between time and cost that riders make when choosing between transit and UberPool in the Chicago area—by actually making 50 real-life trips themselves.

The results are about what you’d expect: UberPool tends to win on time, while the Chicago Transit Authority tends to win on cost. The most time-saving UberPool trips were between residential neighborhoods where rail stations don’t generally extend, and where bus-service gaps are the widest.

It’s a good thing that TNCs are mobilizing passengers in transit-scarce neighborhoods. And Chicago isn’t the only place that’s happening—similar patterns have emerged in New York and San Francisco, where Uber and Lyft rides are also serving lower-income neighborhoods and neighborhoods of color more than yellow cabs used to. On-demand mobility is also proving to be transformative for many underserved population groups, including the elderly, the disabled, and people in need of medical care.

Ride-hailing doesn’t have to end up leaving cities worse off. Asked for comment, Chelsea Harrison, a Lyft spokesperson, emphasized the potential benefits of its Lyft Line carpool service. “[A]s more people choose to share the ride we’ll be able to even further reduce congestion and carbon emissions while making transportation more affordable for everyone,” she said. (Uber did not respond to a request for comment.)

But public officials are responsible for ensuring that future. After initially battling (with mixed success) to regulate Uber and Lyft like taxi companies, many cities have since embraced ride-hailing services as an antidote to car dependence. Now a growing body of research is proving that, overall, this isn’t the case. “It’s the job of city and transit officials to chart the path to incorporate TNCs into city transport networks in ways that work for everyone, including other motorists, delivery companies and bus riders,” Schaller said via email.

What might that path look like? Based on these studies and others, it seems the best defense is a good offense: High-quality public transit may be the only way to keep more-affluent riders onboard. Second, putting a tax on TNC trips, as Chicago has done, may also discourage unnecessary solo trips and raise funds to keep transit top-notch. Policies like congestion pricing—for which Uber has expressed vocal support—may do the same. And third, as creative as they are, studies like these make a clear case for the need for more data from on-demand companies themselves.

This post appears courtesy of CityLab.

*This article originally stated that the San Francisco Municipal Transit Agency was involved in collecting trip data, and omitted the involvement of researchers at Northeastern University. We regret the error. 



After Phil Knight first launched the Nike brand in 1971, he claimed that he could persuade the whole world to buy his shoes if he could first get them on the feet of “five cool guys.” In truth, it took only two cool guys to transform Nike into what Knight would later call a “total brand”: the Oregon distance runner Steve Prefontaine, whose spectacular rise and early death rooted his legend, and his unrealized potential, firmly in the soil of Nike’s origin story; and Michael Jordan, who reintroduced the brand to millions of Americans a decade after Pre’s death, saving the shoe company from irrelevance at the tail end of the jogging boom.

“What Phil and Nike have done,” Jordan said, “is turn me into a dream.”

The dream business was immensely profitable for Nike: Just a few years after Jordan’s first Nike commercial aired in 1985, the company surpassed a billion dollars in annual sales; a short while later, in 1988, Dan Wieden, of the Portland advertising firm Wieden + Kennedy, gave Nike its most enduring slogan: “Just Do It.” On Monday afternoon, in anticipation of that slogan’s 30th anniversary, Nike announced the former NFL quarterback Colin Kaepernick as the new face of the “Just Do It” campaign.

It’s significant that an institution as powerful as Nike has thrown its weight behind Kaepernick and his crusade against racial injustice, which began when he started kneeling during the national anthem—a move that has put him at odds with the NFL, and which has almost certainly kept football teams from employing him. But Nike has often been on the wrong side of social-justice movements, and in the past used its considerable power and influence to crush any protest movement that undermined the company’s bottom line.

Throughout the 1980s and ’90s, underage workers toiled in Indonesian factories producing Nike shoes; at factories in China, workers claimed they were coerced into putting in excessive overtime in order to meet Nike’s demanding production schedule; and in Vietnamese factories, workers faced dangerous conditions later documented by independent auditors from Ernst & Young. In the summer of 1997, when Nguyen Thi Thu Phuong died while making a pair of Nike shoes at a factory in Vietnam, the company’s response was to boldly claim: “We don’t make shoes.” This was a shockingly disingenuous statement from a company whose founder would later call his memoir Shoe Dog.

While reporting a book about Nike, I learned that during the spring of 2000, Knight sought to crush a growing campus-protest movement against sweatshop labor by quashing lucrative equipment and apparel deals with the University of Oregon and the University of Michigan. Behind closed doors, the billionaire resorted to more personal means of retribution, including withholding donations from a nonprofit organization run by the University of Oregon president, Dave Frohnmayer. When Nike did at last make concessions to labor unions at some of the factories making its shoes, it was only because of sustained efforts from labor and human-rights organizations, such as the Worker Rights Consortium. In the wake of this defeat, after years of ignoring or denying accusations that it had relied on sweatshop labor, Nike learned how to market itself as a good corporation with noble intentions, which were stymied only by its naïveté. It was a company trapped by its own humble beginnings, unaware of the immense power it had accrued, according to a May 2001 statement issued by Nike’s corporate and social responsibility manager, Harsh Saini.

“We were a bunch of shoe geeks who expanded so much without thinking of being socially responsible that we went from being a very sexy brand name to suddenly becoming the poster boy for everything bad in manufacturing,” Saini said.

Kaepernick’s “Just Do It” ad, which bears the slogan “Believe in Something. Even if it means sacrificing everything,” seems, on its face, to be more politically divisive than any campaign in Nike’s history—praised from the left for giving Kaepernick a platform to continue speaking out against police brutality and racial injustice, and vilified from the right by the likes of Sean Hannity, who remains determined to cast Kaepernick as unpatriotic and disrespectful. In reality, however, Nike’s standing with Kaepernick has nothing to do with politics and everything to do with the fact that he has transformed himself into an icon. For Nike, Kaepernick’s cause is simply good business—if it were anything other than a cynical branding exercise, the company would surely not be simultaneously doing business with the NFL, which has done its best to stifle Kaepernick’s protest movement.

One of capitalism’s most enduring myths is the idea that there are good corporations and bad corporations. The truth is far more simple: Colin Kaepernick has a dream, and selling dreams is Nike’s business.



The monopolies are coming. In almost every economic sector, including television, books, music, groceries, pharmacies, and advertising, a handful of companies control a prodigious share of the market.

The beer industry has been one of the worst offenders. The refreshing simplicity of Blue Moon, the vanilla smoothness of Boddingtons, the classic brightness of a Pilsner Urquell, and the bourbon-barrel stouts of Goose Island—all are owned by two companies: Anheuser-Busch InBev and MillerCoors. As recently as 2012, this duopoly controlled nearly 90 percent of beer production.

This sort of industry consolidation troubles economists. Research has found that the existence of corporate behemoths stamps out innovation and hurts workers. Indeed, between 2002 and 2007, employment at breweries actually declined in the midst of an economic expansion.

But in the last decade, something strange and extraordinary has happened. Between 2008 and 2016, the number of brewery establishments expanded by a factor of six, and the number of brewery workers grew by 120 percent. Yes, a 200-year-old industry has sextupled its establishments and more than doubled its workforce in less than a decade. Even more incredibly, this has happened during a time when U.S. beer consumption declined.

Net New Jobs at American Breweries, 2001-2016

Total Employment at U.S. Breweries, 2001-2017

Preliminary mid-2017 numbers from government data are even better. They count nearly 70,000 brewery employees, nearly three times the figure just 10 years ago. Average beer prices have grown nearly 50 percent. So while Americans are drinking less beer than they did in the 2000s (probably a good thing) they’re often paying more for a superior product (another good thing). Meanwhile, the best-selling beers in the country are all in steep decline, as are their producers. Between 2007 and 2016, shipments from five major brewers—Anheuser-Busch, MillerCoors, Heineken, Pabst, and Diageo, which owns Guinness—fell by 14 percent. Goliaths are tumbling, Davids are ascendant, and beer is one of the unambiguously happy stories in the U.S. economy. The same effect is happening at liquor distilleries and wineries. Employment within both groups grew by 70 percent between 2006 and 2016, thanks, in part, to the falling real costs of booze-producing equipment and the ease of advertising local businesses on social media.

When I first came across these statistics, I couldn’t quite believe them. Technology and globalization are supposed to make modern industries more efficient, but today’s breweries require more people to produce fewer barrels of beer. Moreover, consolidation is supposed to crush innovation and destroy entrepreneurs, but breweries are multiplying, even as sales shrink for each of the four most popular beers: Bud Light, Coors Light, Miller Lite, and Budweiser.

The source of these new jobs and new establishments is no mystery to beer fans. It’s the craft-beer revolution, that Cambrian explosion of small-scale breweries that have sprouted across the country. The West is leading the way—cities with the most craft breweries include Portland, Denver, San Diego, Seattle, and Los Angeles—but the trend is nationwide. In Illinois and Idaho, brewing jobs grew by a factor of 10 between 2006 and 2016, according to the Bureau of Labor Statistics. According a BLS economist that I spoke with, 2016 was likely the best year for job creation at breweries in American history.

But what explains the nature of the craft-beer boom? From several interviews with economists and beer-industry experts, I’ve gathered that there appear to be two big reasons—a straightforward cause and a more complex and interesting history.

The first cause is something simple yet capricious—consumer tastes. “At the end of the day, the craft-beer movement was driven by consumer demand,” said Bart Watson, the chief economist at the Brewers Association, a trade group. “We’ve seen three main markers in the rise of craft beer—fuller flavor, greater variety, and more intense support for local businesses.” These factors are hardly unique to the beer industry. One could use the same descriptors to explain the concurrent rise of fast-casual restaurants, like Sweetgreen and Dig Inn, or the growth in expensive coffee from $5 lattes at Starbucks to a $55 cup of Esmerelda Geisha. There is, perhaps, a new trendiness to rare beer and expensive coffee that is luring new entrepreneurs into the space.

Craft breweries have focused on tastes that were underrepresented in the hyper-consolidated beer market. Large breweries ignored burgeoning niches, Watson said, particularly hoppy India Pale Ales, or IPAs, which constitute a large share of the craft-beer market. It’s also significant that the craft beer movement took off during the Great Recession, as joblessness created a generation of “necessity entrepreneurs” who, lacking formal offers, opened small-time breweries.

But the triumph of craft beer is not just about a preference for hops and sours. It’s also a story about America’s regulatory history, and how a certain combination of rules can make innovation bloom or wilt.

* * *

In the early 20th century, alcohol producers owned or subsidized many bars and saloons. These establishments were known as “tied houses,” since the bars were “tied” to the brewers and distillers. Tied houses were mortal enemies of the temperance movement. They were vertical monopolies that pushed down prices, got patrons drunk on cheap booze, and upsold them on gambling, prostitution, and other vices.

At the end of Prohibition, lawmakers felt that smashing these vertical monopolies was critical to promoting safe drinking. After the passage of the 21st Amendment, citizens in all states voted to abolish tied houses by separating the producers, like brewers, from the retailers, like bars. This led to a “three-tier system” in which producers (tier one) sold to independent middlemen that were wholesalers or distributors (tier two), who then sold to retailers (tier three).

By dividing the liquor business into three distinct groups, these state-by-state rules made the alcohol industry deliberately inefficient and hard to monopolize. “The great effervescence in America’s beer industry is largely the product of a market structure designed to ensure moral balances, one that relies on independent middlemen to limit the reach and power of the giants,” wrote Barry Lynn, the executive director at the Open Markets Institute, a nonprofit that researches antitrust issues.

The modern alcohol sector is specially designed to promote variety, in other ways. So-called “thing of value” laws make it illegal for beer producers to offer gifts to retailers in an attempt to purchase favorable shelf space. Other rules make it illegal for producers to buy shelf space, which saves room for smaller brewers to thrive at supermarkets and liquor stores. Altogether, these rules are designed to check the political and economic power of the largest alcohol companies while creating ample space for upstarts.

If the U.S. had long ago allowed a couple of corporations to take over both the distribution and retailing of wine before the Napa Valley renaissance, Lynn told The Atlantic in an interview, Americans would be exclusively sipping three varieties of Gallo table wine. “The reason that didn't happen 50 years ago is because you had this system that was designed to promote deconcentration, to incentivize [retailers] to go out and find the new, the different, the alternatives,” he said. “It was effective in achieving that aim.”

It was effective. Until it wasn’t. After Ronald Reagan’s election, the Justice Department relaxed its enforcement of antitrust laws. This kicked off a period of consolidation in various sectors across the economy, including the beer industry. Through a cavalcade of mergers in the last 30 years, 48 major brewers joined to form two super-brewer behemoths—Anheuser-Busch InBev and MillerCoors. Thus, an old system set up to avoid concentration became characterized by extreme consolidation.

But even as federal antitrust enforcement in the last 30 years has shifted to favor conglomerates, a groundswell has created the perfect conditions for the craft-beer revolution—or, more accurately, several distinct craft-beer revolutions. In the early 1980s, a smaller beer boomlet, featuring then-new breweries like Sierra Nevada and Samuel Adams, foreshadowed today’s larger craft craze. The timing was no coincidence. In 1978, Congress approved a resolution that legalized home-brewing, unleashing a generation of beer makers who experimented with flavors far more complex than the simplicity of Schlitz, Budweiser, and other basic brews that reigned for decades.

More recently, many states have made exceptions for small craft breweries to sell beer directly to consumers in taprooms. These self-distribution laws are controversial. Technically, they create an exception to the cherished three-tier system in a way that advantages smaller breweries. But economists and beer fans alike often defend these rules, since they can help small firms establish a fanbase and then phase out when a brewer makes it big.

* * *

So, what are the lessons of craft beer’s triumph for the rest of the economy? First, just as research shows that gargantuan companies are bad for innovation and job creation, the craft-beer boom shows that the burgeoning of small firms stimulates both product variety and employment. Second, sometimes consumers have their own reasons to turn against monopolies—particularly in taste-driven industries—just as they are moving away from Budweiser and popular light beers toward more flavorful IPAs and stouts produced by smaller breweries.

Third, even in an economy obsessed with efficiency, sometimes it is just as wise to design for inefficiency. Alcohol regulations have long discouraged vertical consolidation, encouraged retailers to leave room for new brands, and more recently made it easier for individuals to introduce their own batch of beer to the market. Those are the aims the country should adopt at the national level, both to make it easier for small firms to grow and to make it harder for large firms to relax.

A phalanx of small businesses doesn’t automatically constitute a perfect economy. There are benefits to size. Larger companies can support greater production, and as a result they often pay the highest wages and attract the best talent. But what the U.S. economy seems to suffer from now isn't a fetish for smallness, but a complacency with enormity. The craft-beer movement is an exception to that rule. It ought to be a model for the country.  

Joe Pinsker contributed reporting to this article.



With sales of Diet Coke in a prolonged rut, Coca-Cola announced last Wednesday that it is tweaking the design of its most famous zero-calorie soft-drink can to be more slender and colorful. It is also launching several new flavors of Diet Coke, including “Feisty Cherry,” “Twisted Mango,” and “Zesty Blood Orange.”

"You don’t mess with a good thing," Coca-Cola said in its statement. But, quite to the contrary, Coca-Cola is in a near-permanent state of messing with its things. The first version of Diet Coke debuted in 1982. The very next year, the company released a caffeine-free Diet Coke, and a cherry-flavored variety followed in 1986. This century, several more flavors have joined the family, including lemon, vanilla, lime, black cherry, and raspberry.

These changes—in addition, of course, to the old standards—amounted to a winning formula. At the peak of soft-drink consumption in the mid-2000s, America consumed 53 gallons of soda per person each year—more than half a liter, per person, per day.

But soda’s prospects have since fizzled. Diet Coke may still be the second-most popular soda in the country, but soft-drink consumption has declined every year this decade, according to an analysis shared with The Atlantic by the research group IBISWorld. In its last annual report, Coca-Cola said that the volume of Diet Coke sold in North America declined by 5 percent—more than any other Coca-Cola beverage brand identified in the report.

Per Capita Soft-Drink Consumption

It’s not hard to understand Diet Coke’s imploding popularity: The diet beverage is suffering both as a diet product and as a beverage.

A growing consumer focus on health has clearly dented soda’s dominion. Beyond widespread concerns of the dangers of artificial sweeteners, government research has found that daily drinkers of diet soda are at higher risk for strokes and other “vascular events.” While Diet Coke’s new can designs are tall and slender—a possible reference to the body type a diet-beverage drinker seeks—more of them simply don’t trust any kind of soda to be a part of a healthy diet. Between 2000 and 2015, switching from sodas to other beverages saved the country an estimated 64 trillion calories in total—that works out to 71 fewer calories per day, per drinker.

At the same time that academics have questioned the health effects of soda, the U.S. has undergone a profound change in its taste for liquids, in three major ways.

First, bottled water has transformed from an ecologically dubious ordinary consumer product to an ecologically dubious economic juggernaut. Since 2000, bottled-water consumption has tripled. In 2016, the volume of it consumed surpassed that of soda in the United States for the first time ever, according to data from the Beverage Marketing Corporation (BMC). Meanwhile, related categories such as flavored water and flavored seltzer water have grown even faster, albeit from a much smaller base. Sales of so-called “value-added” water, like Coca-Cola’s vitaminwater, have grown by nearly 3,000 percent since the turn of the century, according to BMC. The flavored-seltzer market is growing by more than 10 percent annually, with the top five brands—Sparkling Ice, LaCroix, Perrier, San Pellegrino, and Polar—now accounting for $1.2 billion in yearly sales.

Second, whereas many Americans once turned to Diet Coke to power their afternoons, these days the market for energy-giving beverages is crowded. At the peak of Diet Coke craze, in the early 2000s, soft drinks outsold coffee by a three-to-one margin in the U.S. But thanks to rising coffee consumption (and coffee’s high price, relative to soda), the U.S. coffee industry is on track to surpass domestic soda sales sometime in the early 2020s. Meanwhile, sales of energy drinks in the U.S. have grown by more than 5,000 percent this century, according to analysis from the BMC.

Finally, while Diet Coke is still one of the most popular sodas in the country, it’s losing market share to more-flavorful beverages. Many drinkers prefer the richer taste of classic Coca-Cola, which is still growing worldwide. Sales of Sprite and Fanta are also rising in the U.S., according to Coca-Cola’s financial reports. Research has shown that black cans and avoiding the word diet in beverage titles lures male consumers; indeed, the black-bottled Coca-Cola Zero Sugar is growing at Diet Coke’s expense.

But slender bottles with streaks of color probably won’t arrest Diet Coke’s demise. As the Harvard business professor and author Clayton Christensen has written, products and customers have certain “jobs” that need to be done. One could argue that, in the last decade, all of the jobs of Diet Coke are being outsourced to superior beverages. The role of hydration has been outsourced to bottled water and sports drinks, like Gatorade. Getting a jolt of energy has been outsourced to coffee and energy drinks, like 5-Hour Energy. And the satisfaction of a cold liquid fizzing on one’s tongue? That’s been outsourced to the trendy crop of flavored seltzers, like LaCroix. In the end, it probably doesn’t matter what the Diet Coke can looks like. Young people know what’s inside the can. Perhaps that’s precisely why they’re drinking so much less of it.



Edith Mendoza was working at Damayan, a migrant workers’ organization, when she met a young woman, Sherile Pahagas, whose story was eerily like her own. Both Mendoza and Pahagas were from the Philippines. Both had searched for work on a website called greataupair.com. Both had found work at the home of a German diplomat and his wife, Pit and Mareike Koehler. And both ended up working day and night for less than minimum wage.

Mendoza’s ordeal began in the summer of 2014, when the Koehlers responded to her posting on greataupair.com, according to a 2017 civil lawsuit filed by Mendoza and Pahagas. (The lawsuit was dismissed in November 2017, on the grounds of diplomatic immunity.) The family was looking for a domestic worker to take care of their four children and home in West Harrison, New York. During Mendoza’s phone interview with them, and reading the contract they sent, the job seemed very appealing, according to a complaint filed as part of the lawsuit.

The Koehlers and their lawyer declined to comment, and directed me to the spokesperson at the German mission. “Please be aware that we are unable to provide further details on this matter out of respect for the privacy of those involved,” wrote a spokesperson from the German mission in a statement sent over email. “We provided all information about this legal employment to the appropriate U.S. authority, the United States Mission to the United Nations, Office of Host Country Affairs.”

According to the complaint, Mendoza was attracted to the job because of an advertised 35 to 40 hour weeks, at $10.02 an hour, between 7 a.m. and 9 p.m. on weekdays and a Saturday weekend shift, with time-and-a-half pay for overtime. Sundays off, vacation, and transportation. A good job with a diplomat. At the time Koehler was an official with the Delegation of the European Union to the United Nations. Since 2016 he has been a counselor to the Permanent Mission of Germany to the United Nations. Koehler’s job at the UN, according to Emily Brease, the communications coordinator at Damayan, was specializing in human rights and child welfare.

Because of Koehler’s employment, the family would be sponsoring her for a G-5 visa, designated for personal domestic workers of an employee working for an international organization, such as the United Nations or the World Bank. His status in the United States offered him another right: diplomatic immunity—the legal privilege that means that diplomats and their immediate family members are exempt from criminal prosecution and most civil actions in the country to which they are posted. Originally established because of the need for diplomats to be able to conduct their business freely without fear of retribution by a foreign government, it can in practice mean diplomats enjoy enormous legal freedom unrelated to their immediate work—including, even, freedom from laws that regulate how people must treat those they employ in their own homes.

Mendoza signed the contract in the fall of 2014, according to the complaint. In January of the next year, she told me, she found herself sitting at the Koehlers’ dining table for her first dinner in the United States, marveling at the size of their kitchen. Mendoza said that Koehler’s wife, Mareike, told her to wake at 6 a.m. the next day: There were five different lunches to prepare, one for each of the kids plus Mr. Koehler. When he had gone off to work and the kids to school, Mrs. Koehler took her on a tour, detailing the tasks Mendoza would be expected to complete, as she alleged in the complaint: a daily thorough cleaning of the six-bedroom home and two-car garage, including vacuuming, laundry, dusting, ironing, food preparation for the family and guests, and occasional shopping, shoveling snow, cleaning the fence, and caring for the pet birds, in addition to her work as an au pair, a live in caretaker for the Koehlers’ four children, one of whom was one-and-a-half. This seemed like way too much to do, especially with one of them being so young. “There is also the baby,” she told me. “I said baby because he is still young, a one-and-a-half-year-old playful boy, and I need to be aware for his safety.”

Mendoza said she cleaned without gloves or protection. And the worst part of the job was looking after the Koehlers’ pet birds. Mendoza said she used a ladder to reach the high points of the house to sanitize them from bird poop multiple times a day. She was completely overwhelmed by the volume of work. “Mareike wants everything be organized, so it’s really hard you know,” she told me. “And I’m only one person, only one domestic worker has to do this every day for a long day without eating or having rest. I almost never felt my bed.”

According to the complaint she filed, in violation of her contract, Mendoza was working from 6:30 a.m. to 10:30 p.m., Monday through Thursday, and Fridays until past midnight, as well as Saturdays from approximately 7:30 a.m. to 4 p.m., without any breaks during working hours. She was working around 90 hours per week, more than double what she was supposed to, and she wasn’t getting overtime pay. Her health started to deteriorate, and she began to get headaches where it felt like her head would go numb, she told me.

Mendoza’s experience places her in a small group of victims of labor abuse who arrive on visas for employees of international officials. Research by Polaris, a national anti-trafficking organization that runs the National Human Trafficking Resource Center Hotline and the BeFree Textline, identified 16 potential victims in a one-year period between 2014 and 2015 on the G-5 visa or the similar A-3 visa (which is for the staff of diplomats on an A-1 or A-2). All 16 victims were females doing domestic work, most of whom were located in the Northeast, and 25 percent were Filipina. (Twenty percent of all A-3 and G-5 visas issued over the past five years were to Filipinos, according to Polaris.) All of the victims were domestic workers. When Polaris takes calls, it distinguishes between victims of labor exploitation who are reporting contract disputes, wage and hour issues and other workplace violations, and victims of human trafficking, who experience economic, psychological and physical abuse or coercion under the Trafficking Victims Protection Act (TVPA). Most notably, although there are very few visa holders in this category, all but three of these women were found to be victims of human trafficking, the highest percentage of all visa categories Polaris tracked.

“Trafficking by diplomats has been an issue for decades, although it might not have been called that,” said Martina Vandenberg, the founder and the president of the Human Trafficking Pro Bono Legal Center. “Unfortunately the abuse continues and diplomats feel no shame in using their immunity as a shield.”

The issue drew attention in 2014 after an incident involving an Indian consular official who allegedly made false statements to obtain a visa for her domestic worker and then did not pay the worker minimum wage. A diplomatic crisis ensued: India claimed that the official had full immunity as a consular officer, though she did not, and then requested to change her assignment so she did. Meanwhile, enormous public pressure mounted in the United States to deny the change in assignment. The official, Devyani Khobragade, was indicted on charges of visa fraud and making false statements. In a 2016 study of the topic, Vandenberg wrote, “the inadequacy of the government’s criminal enforcement efforts may be traceable to a troubling conundrum that lurks at the heart of diplomatic relations … Prosecuting diplomats stationed in the United States for their crimes would certainly enhance the rule of law. But it presents a danger of severely disrupting the orderly implementation of the President’s foreign policy.”

Vandenberg said the State Department has recently gotten better on this problem, especially since the signing of the William Wilberforce Trafficking Victims Protection Reauthorization Act in 2008, an enhancement of the original Trafficking Victims Protection Act in 2000. Under the reauthorization, a consular official’s interview for an “alien for an employment based nonimmigrant visa” should educate them about their rights, their right to seek legal redress, and access to victims services.

But there’s still a ways to go, she says. Her article analyzed federal cases and found that many diplomatic trafficking cases are never criminally prosecuted. Criminal prosecution for diplomats with full immunity would require a waiver of that immunity, which the U.S. has only requested in two of the cases Vandenberg analyzed. She also thinks that possibly fewer civil cases are filed than reflect the problem—only 28 since 2003, as victims of trafficking are unlikely to come forward. “It is likely that the actual number of domestic workers trafficked by diplomats and international officials is much higher,” she wrote.

When asked what is being done to combat the problem, a Department of State official wrote in an email: “The Department of State is committed to protecting the welfare of foreign domestic workers holding A-3 and G-5 visas who are employed by foreign mission personnel in the United States, both in hopes of preventing abuse of these workers and addressing allegations when they arise.”

The experience of these workers is in many ways an extreme version of a much larger problem: the vulnerability of domestic workers—women (almost entirely) who work intimately as cleaners and child care providers in a family’s home—to trafficking and other labor abuses such as harassment and wage theft. Domestic workers often have little legal recourse—the industry is almost entirely unregulated. They work in isolation from other workers, and in close quarters with their employers. “The women who perform domestic work today, are, in substantial measure, immigrant workers, many of whom are undocumented, and women of racial and ethnic minorities,” the National Domestic Workers Alliance wrote in a 2016 report. “These workers enter the labor force bearing multiple disadvantages.” The report, which studied the experience of over 2,000 domestic workers, found that two-thirds of live-in workers report making below state minimum wage.

In cases of abuse of domestic workers on diplomat-sponsored and other work visas, the situation is made worse by the fact that the visa is tied to the employer: the employee has nowhere to go. When I asked Vandenberg why diplomats would abuse their workers, she cited an interesting pattern. “We have had multiple cases where domestic workers worked for diplomatic employers in the country of origin and the employer treats that domestic worker reasonably well and has no fear of deportation.” But when they come the United States, “they suddenly discover they have unfettered power and can threaten the victim with deportation. … The shackles introduced by this visa provide the diplomatic employer with incredible power.”

Over time, Mendoza’s headaches become unbearable, she said. She asked Mrs. Koehler to let her go to the doctor, but according to the complaint and what she told me, Mrs. Koehler told her she could not go to the doctor until the family went on vacation. She had no time off to go, only Sundays when many doctors are closed. Against the family’s wishes, Mendoza took time off to go to the doctor, she told me. When the doctor told her she had to return for tests, the family warned her if she attended the appointment she would be fired. “I called [my] church,” she told me. She says she begged for a way out of the situation. “I told the church to pray for me for some way to rescue from the horrors of that work place.” Her prayers were answered, in a way, when her church referred her to Damayan. Damayan provided her with a job, and educated her about her legal rights. “Working there,” she said, “I found out my rights.”

She had always thought her situation was worse than most, so she was shocked to meet Sherile Pahagas, who also had worked for the family, beginning in 2012. According to the complaint they filed together, Pahagas said she worked 100 hours a week for the family with no breaks and less money than she was promised and no overtime. Like Mendoza, she was overwhelmed by the quantity of work, which included taking care of the home, cooking for the family and for guests, driving Pit Koehler to the train station and picking him up in the evening, she told me, and taking care of the four children, all of whom were under 10 at the time. When she complained she said they told her they couldn’t afford to pay her more. “I just stayed quiet you know,” she said, “and continued working and working.” She felt devastated, she told me, but like she had no choice. “I felt isolated because it was my first time stepping in the United States.” After she quit, she found Damayan, and Mendoza.

In a case filed by the Urban Justice Center on behalf of the two women, they alleged failure to pay minimum wage, which is required under the Fair Labor Standards Act (FLSA) and New York Law; failure to pay overtime wages and spread-of-hours compensation for work days longer than 10 hours; failure to pay a promised wage; failure to provide pay stubs; and breach of contract. The lawsuit garnered attention in the news, from outlets such ABC News and CBS New York.

According to Pahagas, Mendoza, and representatives from Damayan, the Koehlers returned the lawsuit unopened. Later, in a September 2017 filing on the Koehlers’ behalf, the Permanent Mission of Germany to the United Nations asserted that the defendants were entitled to diplomatic immunity and that the attempts of service were inadmissible as a result. The mission, and the Koehlers’ attorneys, urged the court to stop proceedings because they lacked jurisdiction, and the case was dismissed in November 2017.

In a letter dismissing the case, the judge explained that the dismissal was on the narrow grounds of diplomatic immunity. “Notably,” he wrote, “nothing in defendants' motion to dismiss based on diplomatic immunity challenges the factual allegations of the complaint. … If the allegations of the complaint are true, defendants’ conduct was abhorrent and intolerable.”

The Department of State is taking further measures to prevent similar problems, such as the launch of an in-person registration program for the support staff of diplomats. Vandenberg also mentioned new reliance by the State Department on the evidence of bank deposits as part of the interview process, which has already been taken advantage of, with employers asking for money back from the employee after they make the payment.  “Where you create a system of accountability, very clever people will find a way through.”

Although most civil cases end with a dismissal, like Pahagas and Mendoza’s, the filing provides a basis for staying in the United States, because those suing their employers have temporary immigration relief in order to participate in legal proceedings connected with their case. It also provides recourse for when the diplomat goes back to their home country and their status shrinks back to residual immunity, and, as Vandenberg said, “they only have the defenses of a mere mortal.” This results in some cases being resolved out of court, because of the threat of future action. For the cases that don’t resolve, there is nothing to do but wait. And in terms of large-scale measures, there are provisions for the Department of State to stop issuing these visas to a country or a diplomatic organization. “The truly shameful thing is that no country has ever been suspended for in what some cases are egregious violations,” Vandenberg said.

“Edith is a mother along with most of our members, and has been away from home for years to support her family—it is an awful juxtaposition there,” Brease, from Damayan, said. Damayan continues to ask Koehler to pay the allegedly stolen wages and attorneys’ fees, for a total of over $360,000. “We also want diplomatic immunity to be dismissed as well as a public apology because he did this twice that we know of.”

For Mendoza, the result was extremely disappointing. “You know diplomats are covered by their immunity. If they committed crimes it is okay for them—they are protected,” she said to me. “But the workers like me are never protected. And, you know, I am also human.”

This article is part of a project called “The Unfree,” which is supported by Dignity Health Foundation and Silicon Valley Community Foundation.



“We’re like the piggy bank that everybody’s robbing,” President Donald Trump said at a Saturday news conference at the G7 summit in Canada. “And that ends.”

The president, who perceives that the U.S. is being treated unfairly by its trading partners, had imposed tariffs on steel and aluminum imports from Canada, Mexico, and the European Union, along with a threat of further penalties. After a press conference in which Canadian Prime Minister Justin Trudeau reiterated that his country plans to retaliate against the new tariffs, Trump said that when it comes to a potential trade battle, “We win that war a thousand times out of a thousand.”

Trump’s tariffs puzzle many economists; they are unlikely to effectively address China’s oversupply of steel or to lower U.S. trade deficits. But the decision is consistent with his rhetoric on the campaign trail, when he invoked Ronald Reagan’s example. “President Reagan deployed similar trade measures when motorcycle and semiconductor imports threatened U.S. industry,” Trump said in a June 2016 campaign speech in Pennsylvania. “I remember. His tariff on Japanese motorcycles was 45 percent, and his tariff to shield America’s semiconductor industry was 100 percent, and that had a big impact, folks. A big impact.”

Reagan did impose tariffs on Japanese motorcycles, electronics, and other products. But while these penalties could be seen by some as a precursor to Trump’s recent decisions, there are some critical differences. Reagan’s actions were more targeted, and he also promoted some free-trade policies alongside them, including proposing a North American common market. Perhaps more important is the fact that, according to a recent study, it wasn’t really the tariffs, but another policy altogether, that helped U.S. businesses compete in a global economy: Reagan’s change to the tax code in 1981, establishing the federal Research and Experimentation Tax Credit to subsidize innovation.

Businesses can claim the tax credit if they are working to develop new, improved, or technologically advanced products or trade processes. Created as a temporary incentive for two years, the credit was extended repeatedly by Congress until it became permanent in 2015. (The credit was briefly in jeopardy during the tax-bill negotiations last year, but the final version preserved its benefits.) Most U.S. states, too, now offer tax incentives for research and development.

In the 1980s, this stimulus induced companies to innovate and catch up to their foreign competitors, according to the economists who co-authored the recent study: Ufuk Akcigit of the University of Chicago, Sina T. Ates of the Federal Reserve Board of Governors, and Giammario Impullitti of the University of Nottingham. They describe how, in the second half of the 1970s, U.S. manufacturing productivity was lagging behind that of other advanced economies, and technological competition from Japan, Germany, and France was increasing. While U.S. residents filed 70 percent of patent applications in the United States in 1975, that share had fallen to closer to 60 percent by 1981.

Then, as now, “there was concern that the U.S. was losing leadership,” Akcigit told me. It could have just isolated itself from the world economy. “But instead, the U.S. decided to subsidize its industries quite strongly.” International competition, according to Akcigit and his colleagues, has two playing fields: a company’s home market and its foreign markets. In open economies, companies first have to push hard to improve their productivity and quality of goods, or they will be vulnerable to foreign competitors encroaching on their turf. Second, large businesses can gain share in foreign markets.

In the absence of tariffs, research and development subsidies will encourage companies to make long-term investments to improve their competitive position at home and abroad, the researchers find. After the creation of the federal and state R&D tax credits, U.S. businesses began to catch up to their foreign counterparts; the intensity of their research spending increased, and, after continuing to fall for a few more years, their share of patent applications rebounded by the mid-1990s to above 60 percent.

Akcigit and his co-authors find that economies benefit more in the long run by subsidizing innovation than by stifling trade. Having recently visited Germany, Akcigit cited the rivalry between BMW and Tesla as an example of international competition pressuring companies to develop new products. BMW felt the pressure on the market when Tesla came along, he said. “Now they are pushing hard for electric cars. The consumers are benefiting from it: The price of electric cars will come down.”

Why, though, do businesses need subsidies? The research-and-development tax credit has been controversial at times, with some economists arguing that businesses would have made the investments anyway. But R&D spending has an uncertain payoff, Akcigit argues, and new products and business processes benefit all of society, not just the company that creates them. His research shows that subsidies induce businesses to invest more in long-term innovation than they would have otherwise.

In this analysis, Reagan’s tax credit looks like a smart move. Then, there’s the separate issue of his tariffs, including the 49.4 percent import duty on Japanese motorcycles, imposed in 1983 to benefit Harley-Davidson, which was struggling at the time. Harley revived its business and returned to profitability by 1986, but it’s not clear that the tariffs were responsible. A study conducted for Japan’s Research Institute of Economy, Trade and Industry, by Taiju Kitano and Hiroshi Ohashi of the University of Tokyo, credited Harley’s internal improvements, including reducing the share of motorcycles it produced with defective parts from around 50 percent to 2 percent.

“For years we tried to figure out why the Japanese were beating us so badly,” Vaughn L. Beals, Harley’s former CEO, told The New York Times. “First we thought it was their culture. Then we thought it was automation. Then we thought it was dumping. Finally we realized the problem was us, not them.” (Among the EU’s current targets for duties on U.S. imports are Harley motorcycles. Harley said the retaliation would have a “significant impact” on its sales.)

Akcigit, Ates, and Impullitti find that protectionism can lead to short-run gains for an economy—say, over 10 to 15 years—as businesses temporarily reap higher profits. This only works, though, if a country can impose tariffs without retaliation. That’s an unlikely scenario, as evidenced by the fierce response to Trump’s import duties. If countries retaliate, the researchers find, global competition diminishes, and everyone suffers because of slower technological progress.

Over a longer period, whether countries retaliate or not, consumers in the country that imposes the tariffs become much worse off. If countries do not retaliate, companies have less fear of foreign competitors entering their home market. If countries do retaliate, companies have fewer opportunities to expand overseas. Either way, businesses in the home market have less motivation to come up with new ideas. “You are shielding them from international competition,” Akcigit said, “so they become lazier.”

This is the opposite of the argument from the White House. “We may have a little bit of short-term pain, but we’re certainly going to have long-term success,” White House press secretary Sarah Huckabee Sanders told reporters in April.

Akcigit said policymakers face one important question: How much do you care about the future? If an administration could impose tariffs unilaterally, at least during a single election cycle, “they will just see the benefits of it as a politician,” he said. “But as a citizen of the country, in the long run, the society will be hurt by this.”



In 2013, Uber was in the midst of an aggressive global expansion when it launched in South Africa. The app requires a critical mass of drivers to function properly, otherwise riders must wait prohibitively long for trips. In Cape Town, a Zimbabwean driver who I will call Mike (he asked that his name not be used because he fears deactivation for criticizing the platform) attended several meetings held by Uber managers seeking to win over potential drivers. He enjoyed the free sandwiches and coffee they offered him. “In the first six months those guys were beautiful to us,” he recalled.

After arriving in Cape Town, Mike had initially worked in hotels and restaurants, later becoming a meter-taxi driver. When he heard about Uber from some former colleagues—they spoke of higher earnings, no shift managers—he immediately signed up. Uber’s pitch to drivers was the same as it is everywhere else: “Make good money. Drive when you want. No office, no boss.” Mike’s first impression of Uber, he said, was, “Here comes a company that’s liberating me.”

But in South Africa, Uber’s model doesn’t work the way it can in some other countries. The country’s severe income disparity means that few professional drivers actually own the cars they drive; instead, they rent them from owners and split the earnings, very often struggling to make ends meet. Though Uber does not release its figures, drivers and their representatives estimate that since 2013, the service has grown to around 4,000 Uber cars in Cape Town, mostly driven by foreign African migrants. A substantial majority do not own their cars—a model that Mike soon came to believe was “broken.” Here, more than anywhere, the gig economy’s promise of independence was illusory.

From the start Uber had faced a problem in South Africa, as well as in other developing countries such as Pakistan and Mexico: While there was no shortage of willing drivers, few could afford vehicles suitable for the app’s high-end market—sedan cars no older than five years, which in South Africa cost at least $10,500. The national unemployment rate, including people who have given up looking for work, exceeds 35 percent, and more than half the population lives below the poverty line.

Were South Africa simply a poor country, there would have been no demand for Uber in the first place, but it also holds the distinction of being among the least equal societies on earth. Though unemployment and poverty are rampant among people of color, cities like Cape Town and Johannesburg have robust middle classes, with many thousands of people wealthy enough to use on-demand car services. To tap into this new market, Uber devised a solution to the car-ownership problem: Find people with the means to finance new vehicles, and encourage drivers to work for them. Today some of these owners, who like drivers are termed “partners” by Uber, operate entire fleets. One Cape Town partner (who asked not to be identified) currently has 50 vehicles on the road. There are even companies offering end-to-end fleet-management services. Since launching in San Francisco in 2010, Uber has spread to more than 814 cities (and counting). But in countries like South Africa, rather than disrupting entrenched patterns of capital, Uber’s version of the gig economy has largely conformed to them.

Samantha Allenberg, a spokeswoman for Uber South Africa, declined to comment on the proportion of drivers engaged in third-party agreements. “We are aware that some drivers work for vehicle owners and would like to be their own bosses,” she said. “Driving for someone else is the first entry point for drivers to join the Uber app.” Allenberg added that the company had partnered with local banks and car dealerships to offer financing for drivers with low credit ratings.

Yet ownership by drivers remains exceedingly rare. Faiza Haupt, an Uber partner who is helping to create a new national e-hailing association for drivers, estimates that just 10 percent of Cape Town’s Uber drivers work for themselves. (Haupt, a former driver, currently has four vehicles on the platform.) Mike, who has only ever driven for partner-owners, including one fleet that rotated drivers on consecutive 12-hour shifts, believes the figure is even lower.

“Uber in Cape Town is not functioning in the way Uber portrays it,” Ine Geitung, an Oslo city employee who wrote a Master’s thesis on the ride-hailing app in South Africa, told me. “Uber should put stricter and better guidelines between car owners and drivers to ensure that their platform does not contribute to exploitation, as it does today.” Critics such as Geitung, along with many Uber drivers, believe that Uber unfairly profits at the expense of the workers who make its service possible in South Africa.

Allenberg, of Uber, contested that characterization. “The lion’s share of the revenue generated goes to the driver,” she said, noting that Uber applies a standard service fee for 25 percent in all cities. The cost of running and improving the Uber app comes out of Uber’s service fee, she added.

Like their counterparts elsewhere, drivers in South Africa have attempted to force Uber to recognize them as employees, not contractors. In 2016, seven drivers—some working under partner-owners, some for themselves—took the company to court and won, but Uber successfully appealed. The drivers, who had founded a group called the Independent Drivers Guild, had already been deactivated from the platform. “The contract states that Uber can terminate you for any reason,” one of the drivers, Joseph Munzvenga, told me. Regarding the prevalence of partner-owners, he added: “As African people, with our histories of colonialism and apartheid, who can afford such a premium vehicle? The idea has become empowering people who were already rich.”

Typically, owners set drivers’ weekly “targets,” ranging from $190 to $230, which drivers must pay them before they can start earning money themselves. Some owners are registered with Uber and pay out earnings to their drivers, minus these deductions; in other cases, the drivers are registered themselves and must deduct rental fees from what they earn. Either way, drivers must pay for their gas and cellphone data. This leaves little over for drivers, many of whom work 60-hour weeks or longer. (With rising insurance premiums and competition for riders, many owners say that the model is no longer working for them either.)

Records from Mike’s app shows that he pockets less than $760 most months, though he works, on average, 65 hours per week; his wife, who works a nine-to-five job, makes more. Uber traffic is busiest on weekends, so while his wife and children are home, Mike is generally on the road. “If I was earning well it might be worth it for a few years,” Mike said. “But I’m not, and I’m not spending any time with my children. This way, what’s the point?”

Until this May, when Uber South Africa imposed a 12-hour shift limit on its app (excluding waiting time between rides), Mike often drove for 20 hours or longer in pursuit of better earnings. Like many other drivers I met, he began keeping a blanket in his trunk for naps. Late one night, after he dropped a customer at home, the man refused to open his driveway gates to let Mike leave. “He could see how tired I was,” Mike told me. “He was a gentleman—he made me sleep in the car until morning.” Another time Mike ordered an Uber for himself after going drinking. The driver was red-eyed and slurring with exhaustion. “I canceled the trip and told him to go home, but I don’t think he did,” Mike said.

Uber South Africa sent drivers a short video this July, announcing the findings of a national costs survey. Both rentals and vehicle finance had grown more expensive with inflation, while car-insurance premiums had more than doubled since 2015. A recent petrol price hike had squeezed drivers even further. “On top of these increases in your operating costs, inflation has caused the cost of everything else in your life to go up as well,” a narrator explained, over piano music. “All of this means that your earnings are not enough.”

On August 1, the company announced that it was increasing its minimum fare charge for UberX trips by 25 percent and piloting “tiered” discounts on its fees for drivers with good track records. “It’s a big F-you to drivers,” Mike wrote me by WhatsApp when he saw the news. Boosting the minimum charge makes a difference only to extremely short trips, and he found the commitment to discounts vague. Allenberg, the Uber spokeswoman, said: “Uber suceeds when our partners suceed, and our teams are working hard every day to ensure drivers using our app continue to thrive.”

After more than 10,000 trips, Mike said, he was tired of waiting. He recently completed a part-time course to become a tour guide. (“Due to financial constraints,” he said, it took him a year instead of the typical six months.) He meets other men all the time, Zimbabwean immigrants like him, who want to drive for Uber. He has given up arguing that they are wasting their time. Driving a nice car feels like a good job—a status symbol—even if the weekly payments are too steep for it to be at all lucrative, he said. Compared to what they earned back home, the money isn’t bad. People learn not to touch fire, Mike has learned, when you let them burn their fingers. No matter what happens, Uber will get its cut.



On August 19th, a video appeared on the Macy’s website. It opens with a light-flooded room, in which a young woman sits in front of a mirror. “Macy’s” is spelled out on the wall in gold, glittering cardboard letters attached to a string with clothespins, like decorations at a child’s birthday party. The woman—Isabel Campbell, a digital assistant in the petites department at Macy’s—introduces herself. “I am a very relaxed type of girl—I love to just shop around, have brunch with my friends,” she says. “And this”—gesturing to her clothes—“is my go-to outfit: an oversized sweater from Free People and a Free People jean skirt.” If you like what you see, you can click the links that appear nearby to buy similar products from Macy’s.

Most people have never heard of Campbell, and that’s the point. Weary of celebrities who demand high salaries and unreliable Instagram “influencers,” Macy’s is making it possible for its own employees to serve as its brand ambassadors, through a project it calls Macy’s Style Crew. The strategy shift comes as brands are raising concerns about how many of their customers are truly being reached by digital advertising. Last year, for the first time, advertisers spent more on digital ads than on TV spots. Yet this is a season of disillusionment with social media—beyond its well-documented problems with hate speech, election malfeasance, and emotional manipulation. Instagram influencers with large followings are raising their rates to feature a company’s product in a sponsored post. Many of the influencers rarely follow federal disclosure requirements about advertising. Some wind up embarrassing brands with inappropriate comments or bad behavior. And occasionally it turns out that influencers aren’t that influential at all, and have audiences that can include fake and paid-for followers.

Consumer-products companies, which have been huge advertisers online, are becoming more careful about their spending in response. Unilever has said it will no longer work with influencers who buy followers. Procter & Gamble, one of the world’s largest advertiser, cut its digital ad spending by $200 million last year, saying much of it was a waste.

Influencers, and those who represent them, are working to rebuild trust. In the meantime, it’s cheaper and safer, Macy’s hopes, to rely on one’s own employees. Because the retailer directly employs these workers, it is better able to control their behavior; if an employee discredits the company, Macy’s can fire him or her. “It’s easier to leverage assets that exist than creating something from nothing,” Marc Mastronardi, the executive vice president of business development at Macy’s, said at a retail conference in June.

Following a pilot with 20 employees, Macy’s has expanded its Style Crew to more than 300 people across the United States. Employees hope to benefit; the retailer has promised them incentives (that amount has not been publicly specified) if they help increase sales. But given the economics of platforms such as Instagram, it’s hard to imagine many are making much money. On social media, as in much of the economy, only a small number of top performers earn a lot. A highly visible Instagram influencer can charge roughly $1,000 per 100,000 followers, for each post. But the average payment for a sponsored Instagram post is only $300.

Some members of the Style Crew have more than 10,000 followers, but having fewer than 1,000 is more typical. (Campbell has 1,416 as of this writing.) This puts them in the category of “micro-influencers,” people with smaller, but presumably more loyal, audiences. Brands have been courting micro-influencers to see if they can get similar engagement (customers who like a post, make a purchase, or take other actions) without spending a lot. Their average rate, according to IZEA, a company that makes influencer-marketing software, is $62 for a sponsored photo. (Perhaps the true appeal of micro-influencers is that they get micropayments.)

“Macy’s Style Crew comprises colleagues who are passionate about servicing the customer, participants who want to create unique, authentic content, and who want to build their social media presence and get rewarded for their impact,” Mastronardi said in an email.

Macy’s isn’t the only company asking its staff to do more. Brands such as ModCloth and Sephora have recruited employees for ad campaigns. Others call on their customers. Maker’s Mark buyers who proselytize for the company can have their names added to a bourbon barrel and later get a chance to purchase a bottle from that batch. This summer, Tommy Hilfiger sold clothes embedded with Bluetooth trackers to what it calls a “micro-community of brand ambassadors.” The company will study how much people wear the items, and where, in exchange for gift cards and other merchandise.

There are more than 6,000 Instagram posts, so far, with the #macysstylecrew hashtag. Macy’s also has a Style Crew section on its website, with each video bearing links to clothes, accessories, or makeup available for sale. A few posts have sophisticated videography and editing, and appear to have been created with more input from the company. Most are what you might expect from people trying to squeeze extra work into already-full lives. One woman shoots her short Outfit of the Day videos with her cell phone pointed into a mirror, the way people used to before society perfected the selfie. “All the girls in my office are wearing denim skirts again. They’re back. Go get one. Bye!” she says. A young man enthusiastically explains Macy’s makeup specials from the corner of a borrowed room while traveling. “Why are we here today?” he asks. “A wedding,” someone patiently answers off camera. Some of the posts are just photos of perfume ads. One is a series of images of bras dangling from hangers, presumably in a Macy’s lingerie department.

Then there’s Candace Bryant, an administrative manager at Macy’s corporate office in Cincinnati, and perhaps the best example of why the Style Crew program exists. Warm and charismatic on camera, Bryant gives her co-workers makeovers and tells them they deserve to spend time on themselves. In one self-filmed video, she invites a colleague to share a poignant anecdote about overcoming negative self-scrutiny and developing confidence. Their backdrop is a window covered with horizontal blinds that overlooks a parking lot. The merchandise is present, but Bryant—whose personal Instagram feed is otherwise populated with inspirational quotes and images of herself singing at church—is the star.

Glimpses of regular people hoping to make a few extra bucks: It’s not glamorous, but it’s certainly relatable. The most credible form of marketing is recommendations from friends and family, according to Nielsen. Macy’s Style Crew collapses the façade of traditional advertising, with its agency fees, professional stylists, skilled photography, studio lighting, and hours of editing and retouching. (It also threatens the jobs of all the people who have built careers around filling those roles; see the upheaval at major advertising agencies for details.)

Instead, Macy’s is bringing the exposure economy in-house. Dissolve the haze of marketing lingo, though, and the company is inviting a group of mostly low-paid employees, who normally are compensated for selling merchandise, to spend more of their time—possibly uncompensated—selling that same merchandise to their families and friends. It’s a high-tech Tupperware party. As corporate profits rise and wages for regular people represent a shrinking portion of the U.S. economy, the Style Crew is hustling ever harder—just like most American workers. Want to buy a purse?



What is Uber? The company’s standard answer is that it is a technology company—an app that matches people who want to get somewhere to people who will take them there for money. This is not wrong.

But, as the European Union’s highest court told the company on Wednesday, that answer is incomplete. Whether Uber likes it or not, it is, officially speaking, a transportation company.

The consequence of this designation is that, within the borders of the EU, the company will be regulated just like any other transportation company. That’s a big deal. It’s a big deal for Uber (which will now have to play by any rule a European city sets for transportation companies) and it’s a big deal for the platforms that, like Uber, depend on the labor of people who aren’t full-time employees.

First, the implications for Uber: The ruling “places a significantly larger regulatory burden on Uber, if they want to operate in any European city, and it also can severely restrict their growth, depending on the city,” says Arun Sundararajan, a professor at NYU’s Stern School of Business and the author of The Sharing Economy: The End of Employment and the Rise of Crowd-Based Capitalism. How might it prevent Uber from growing at the rate it has in the past? If, for example, a city has or imposes a cap on the number of professional drivers permitted within its limits, that cap would apply to Uber. The same goes for any city’s law requiring that drivers must be considered employees and not contractors, which would force Uber to either get out of town or make sure its drivers are classified properly.

In an emailed statement, Uber insisted the decision will not do much to change the way it’s already operating in Europe. And its CEO, Dara Khosrowshahi, tweeted that the ruling was “Not a setback, since we’ve already changed our approach in the EU to follow transportation laws and work with professional drivers.” What he’s referring to is the fact that the specific service that was at issue in court—it’s called UberPop, and it was open to drivers who didn’t have taxi licenses—has been discontinued in most major European cities, and has been replaced by a service with licensing requirements.

It makes sense, from a PR perspective, that Uber might want to mitigate any impression that this is bad news for it. But, in a way, from the company’s position, the ruling might not even seem like a big deal, relatively speaking. “This is a significant ruling for Uber, but given everything that's going on in Uber’s life, maybe it’s not the most significant blow that they’ve received this year,” Sundararajan says. 2017 has no doubt been a busy year for the company’s publicists, who have had to make the best of a very public battle over who would run the company, a sexual-harassment scandal, a lawsuit over racial and gender discrimination, and a secret tool it used to trick the authorities. It also got banned from London. That’s not a promising series of events for a company that reportedly wants to go public in 2019, and Sundararajan says running Uber is “certainly the hardest CEO job in tech at this point.”

One of the many challenges of that job is to change the image of the company shaped by Travis Kalanick, Khosrowshahi’s predecessor, who was pressured to step down this summer by board members after presiding over a string of controversies. “Travis Kalanick’s style of engagement was more pugilistic—everything was a battle to be won,” Sundararajan says. “But Dara Khosrowshahi is trying to create a ‘kinder, gentler’ Uber that is seen as an entity that is more worthy of the public trust.” Establishing that reputation is important, Sundararajan says, if Uber is to earn the trust of regulators moving forward.

Wednesday’s ruling also carries implications that reach beyond any one company. By deciding to treat Uber as a transportation company, the EU’s high court might be suggesting that other similar platforms, such as Airbnb, could be regulated similarly in Europe. This means that companies that depend on independent contractors (who generally get fewer benefits and legal protections, in both the EU and the U.S.) for their labor might be required to hire people as full-time employees.

Sundararajan says that while this development may be welcomed by a group of dedicated drivers who go from not having benefits to having benefits, it will disappoint a larger group of people who will now have a tougher time driving occasionally for money on the side. “I think the right path there isn’t to say, ‘Well, everybody needs to fit into the full-time employee bucket,’” Sundararajan says. “Rather, we want to decouple some of the nice things that are available exclusively to full-time employees and spread them out broadly across a workforce that’s participating in these non-employment work arrangements.” Such “portable” benefits are frequently suggested as one remedy to the increasingly precarious and shaky nature of work for many millions of people.

U.S. courts are still sorting out these questions, too. I talked to Shannon Liss-Riordan, a lawyer who has been representing Uber drivers in California and Massachusetts who say they should be classified as employees rather than contractors. While the EU’s decision doesn’t have any bearing on U.S. courts, Liss-Riordan says, “I think it is important because it is another tribunal that has found that Uber is a transportation service, rather than just a technology company, as it has claimed.” Like in the EU, that designation matters greatly in the U.S. for how the company—however courts decide to classify it—treats the people who drive the cars that show up when its users tap the screens of their phones.



Disney announced on Thursday that it would acquire most of the entertainment assets of 21st Century Fox for about $60 billion in stock and debt, in what would be the largest-ever merger of two showbiz companies. Already the most storied entertainment empire in the U.S., Disney would become a global colossus through this deal, gaining large stakes in the biggest entertainment companies in both Europe and India. The deal will almost certainly receive regulatory scrutiny, as the Justice Department has been lately dubious of mega media mergers.

The yuletide haul includes some of the most famous properties in television and film. In the transfer of power, Disney would receive the 20th Century Fox film studio, including the independent film maestros at Fox Searchlight (Best Picture Oscar–winners include: Slumdog Millionaire, 12 Years a Slave, and Birdman), the X-Men franchise, Fox’s television production company (worldwide hits include: The Simpsons, Modern Family, and Homeland), the FX and National Geographic cable channels, and regional sports networks, including the YES Network that broadcasts New York Yankees games. Disney also acquires a majority stake in the TV product Hulu, which it may use to kickstart its entry into the streaming wars.

These additions would enrich an overflowing treasury at Disney, whose assets includes Star Wars, Marvel, Pixar, ABC, ESPN, the world’s most popular amusement parks, and, of course, its classic animated-film division. When Mufasa tells Simba in The Lion King that “everything the light touches is our kingdom,” it isn’t just memorable screenwriting. It is corporate guidance.

The deal allows Rupert Murdoch, the billionaire patriarch behind 21st Century Fox, to consolidate his own kingdom—and his legacy—around the very place where he got his start: news. Murdoch, who built his $100 billion business starting with a single newspaper in Australia, would retain ownership of the Fox broadcast network, the Fox News Channel, and several national sports networks. Like an aging King Lear dividing the spoils in his twilight years, one of the world’s most famous media moguls is selling off his accumulated fortunes.

At the deepest level, this corporate marriage isn’t about Mickey versus Murdoch, or Avengers versus X-Men. It’s all about Netflix—and, to a subtler extent, Google and Facebook, whose dark shadows extend over the entire media landscape.

Streaming video has conquered pay TV and created a generation of cord-cutters; the youngest Millennials (those in their late teens and early 20s) watch 50 percent less traditional television (“cable TV,” as it’s commonly called) than people that age did in 2010. That means every content company now has to be a streaming technology company. As eyeballs shift away from the cable bundle, advertising is following them to mobile devices, where Google and Facebook have built an impregnable duopoly. That means every ad-supported television business has to become a direct-to-consumer business.

For media and entertainment companies, there is one big existential question: Get big and stream, or give up and sell? That is a choice that motivates both this deal and AT&T’s troubled bid for Time Warner. By making huge acquisition offers, AT&T and Disney have chosen Door No. 1. Disney’s future hinges on whether it can build a streaming powerhouse, or “Disneyflix”—a direct-to-consumer television product that, like Netflix, distributes a library of video over the internet to phones, tablets, and TVs. The company plans to launch an internet sports product in 2018 and—most importantly—a filmed entertainment product in 2019. To truly compete with Netflix, Disney’s 2019 service will need both a deep library for viewers ages 1 and higher (some viewers just want old shows and movies) and an excellent television production company (some viewers prefer new stuff). With this deal, it would have arguably the world’s best in both categories.

By agreeing to acquisition offers, Time Warner and 21st Century Fox have chosen Door No. 2. The latter group has seen a vision of their future—permanently falling live-TV ratings, more cinematic flops, quarterly job-cut announcements—and rather than wake up every morning in a hot sweat for the next 10 years, they’d prefer to sell high as fast as possible. Time Warner wants out of the movie business. 21st Century Fox wants out of the regional-sports-network business. It makes sense to sell to skittish behemoths that are both desperate and flush.

If one graph could possibly explain this entire deal, this one does. It shows change in traditional-television viewing time in the last eight years.

Change in Time Spent Watching Traditional TV by Age Group

The upshot is pretty simple: Traditional television is a pure gerontocracy. The only age demo watching more TV than in 2010 are eligible for Medicare. By clutching Fox News (average viewer age: nearly 70) and other traditional TV channels, Murdoch is holding fast to the appropriately gray line. Disney is paying $60 billion to build a business that reaches everybody else—every youthful, colorful, nose-diving line segment in the chart. You could say Disney is spending $60 billion for a risky makeover to appeal to a younger demographic, while Murdoch is using the money to install a golden stair lift.

The Justice Department faces its own existential question: Namely, should this merger exist in the first place? The government has sued to block the AT&T deal on the basis that the combination of large distribution and content companies could be anticompetitive. But Disney’s long-term strategy is, like Netflix, to own the means of distributing its content. What’s more, this deal is a “horizontal” merger—i.e., between competitors in the same industry—which has historically attracted more negative attention from government regulators. If the Justice Department permits the Disney merger without a peep, it will feed speculation about why the government is blocking the acquisition of the president’s most-hated television channel.

With this deal, Disney would control as much as 40 percent of the the U.S. movie business (Disney and Fox films earned that share of U.S. box office revenue in 2016) and 40 percent of the U.S. television business (the new Disney would earn 44 percent of U.S. affiliate fees among major networks), according to data from MoffettNathanson, a media-research company. Its control of the sports-television landscape, between the regional sports networks and ESPN, might be even more concentrated, giving Disney’s more leverage to demand higher fees from cable and telco companies in exchange for distributing its content.

If that sounds a little scary for television distributors, or television viewers, then good. Everybody should fear the Disney Death Star. Hollywood studios should be afraid to compete with a corporate Goliath that could earn half of all domestic box-office revenue in a good year. Every tech company should be afraid to get into a content war with a company that combines the top blockbuster movie studio, with a top prestige-film company, with a world-class television production company, with the most valuable franchises—Star Wars, Marvel, Pixar, and X-Men—in the world. And consumers should fear too; not just those who are afraid that Disney will water down artsy filmmaking (like Fox Searchlight’s Grand Budapest Hotel) and R-rated superhero films (like X-Men’s Deadpool), but also those who are afraid that too much control of any industry confers monopoly power that restricts choices, raises prices, and hurts workers.

But here’s the truly weird part: Disney should also be afraid of its own Death Star. (After all, the thing keeps getting blown up.) In the last fiscal year ending in October, Disney’s made $55 billion in revenue, with about 60 percent coming from television and film (the rest came from parks, resorts, and merchandise). That 60 percent is endangered: Box-office ticket sales have been flat or declining for years, and television is in obvious structural decline. In many ways, the entire company’s future hinges on its ability to funnel its expansive universe of entertainment into a single direct-to-consumer stream that takes on Netflix, which already has more than 100 million subscribers worldwide. These sort of corporate transformations are treacherous, even when they are necessary.

The future of media is going to a very long, very expensive great-powers war. There’s no question that, as of 2017, the streaming rebels are winning. With this deal, the empire just struck back.



Editor's Note: This article is part of an oral-history series where Aaron Reiss interviewed the young-adult sons and daughters of Chinatown shopkeepers about how they are helping to keep their families’ businesses alive.

Cynthia Koo, a 30-year-old designer, uses her marketing and art expertise to help manage an Instagram presence and an English-language website for her family’s Cantonese restaurant, Oriental Garden: “I speak Cantonese and took Mandarin in school, but I don't read enough to understand the register. But I’ve helped in other ways.”

I spoke with Koo in the spring of 2018. Below is our conversation, lightly edited for clarity.

When I was a kid, all of our family celebrations would be here at the restaurant. I spent a lot of time after school here and at the garment factory where my mother worked. It probably wasn’t up to code, but the children of the other seamstresses would all be there. We would run around, play in the fabric.

When I was born, my father was just a waiter at Oriental Garden. Actually, he’s worked his way all the way up from busboy to part owner. And now my mother helps out here, too. She’s always managed the books, but now she helps behind the register as well.

I’ve never been able to do that—I speak Cantonese and took Mandarin in school, but I don’t read enough to understand the register. But I’ve helped in other ways. We’ll have family dinner once a week, and things just come up in conversation. My dad will run through the difficulties they are dealing with, and I’ll find ways to help.

Like, over the years we’ve gotten press inquiries in English, but he doesn’t know exactly how to handle them. Maybe he isn’t sure what they are asking or how to respond. Language is hard in general. He’s also having me take the food-safety certificate classes so that I can liaise with the health-inspector authorities. The rules are really hard to decipher, and every time they get a point off, my dad is really anxious.

I also helped them with anything digital. I helped them claim their business on Yelp and make their profile nice. He might ask me, “Should I advertise on Groupon?” because he doesn’t know exactly what the service is. So I will sit down and explain how that might work. That is kind of how I saw my role, as explainer. And then he decides what’s best for his business.

We used to have an all-text menu, but for someone who doesn’t know this food, it can be really hard to order. I showed my dad how to take pictures of our dishes and how to cut out the photos using Photoshop. My mom was more familiar with computers, so they did it together. Now we have a picture menu that he did himself.

A year ago, I quit my job. I had been working at a financial start-up for three years.

When I left my job and started helping out more at the restaurant, I didn’t want to touch anything they were currently doing—I wouldn’t feel comfortable. The waiters, kitchen procedure, ingredient sourcing—I don’t know that stuff. But I’ve always helped out with design and marketing, because that is something my parents struggle with, and something I really enjoy. And given what I know about social media, I’ve always seen that as a serious hole in their operation. I offered to take up the effort of getting them on social media and managing their presence online.

At that time, they reacted like, “Why? You have a great job. Restaurants make no money; you’re on your feet all day. This job is hard. You don’t want it!” But they were receptive to my offer to help. They always have been, even if I don’t think they fully understood what I was talking about.

So I brought in a 23-year-old intern, and she does our Instagram. My dad actually pays her out of his salary, which is amazing. I had already designed them a website, something I had been wanting to do for a long time. After that, they started getting inbound English inquiries and reservations, and English press reaching out. I wanted to be an interface between the younger, English-speaking market and what they’ve always known.

Part of the reason I started doing this is because my father works so hard, and the food is so good, and there is so much to his story. It makes me sad that they are not more successful.



Too many Americans are overweight and eat unhealthy food, a problem that falls disproportionately on poor and low-income people. Many have blamed the existence of “food deserts”—disadvantaged neighborhoods that are underserved by quality grocery stores, and where people’s nutritional options are limited to cheaper, high-calorie, and less-nutritious food.

But a new study by economists at New York University, Stanford University, and the University of Chicago adds more evidence to the argument that food deserts alone are not to blame for the eating habits of people in low-income neighborhoods. The biggest difference in what people eat comes not from where they live per se, but from deeper, more fundamental differences in income and, especially, in education and nutritional knowledge, which shape people’s eating habits and in turn impact their health.

To gauge the quality of food and nutrition by income groups and across different geographies, the study uses data from the Nielsen Homescan panel on purchases of groceries and packaged food-and-drink items between 2004 and 2015, which it then evaluates in terms of the U.S. Department of Agriculture’s Healthy Eating Index. It examines the gap between high- and low-income households: that is, those with annual incomes of $70,000 or more, and with incomes of less than $25,000 per year.

The study reinforces the notion that food deserts are disproportionately found in disadvantaged neighborhoods. It finds that more than half (55 percent) of all ZIP codes with a median income below $25,000 fit the definition of food deserts—that’s more than double the share of food-desert ZIP codes across the country as a whole (24 percent).

Furthermore, the study documents the disturbing extent of nutritional inequality in America. Across the board, high-income households benefit from better, more nutritious food. They buy and consume more of four very healthy types of foods: fiber, protein, fruit, and vegetables. They also consume less of two of four unhealthy ones: saturated fat and sugar. (Their consumption of sodium and cholesterol is basically the same as that of lower-income households.)

Indeed, the groceries of higher-income households are considerably healthier—in statistical terms, almost 0.3 standard deviations healthier—than those of low-income households, a gap that expanded substantially between 2004 and 2015. Overall, high-income households purchase one additional gram of fiber per 1,000 calories than low-income ones, which is associated with a 9.4 percent decrease in Type 2 diabetes. They also buy 3.5 fewer grams of sugar, which correlates with a 10 percent decrease in death rates from heart disease.

That said, there are some striking similarities in food consumption between high- and low-income households. They both mainly shop at grocery stores, no matter where they live. High-income households spend 91 percent of their grocery dollars at supermarkets. Low-income households spend just slightly less, at 87 percent.

Supermarket Expenditure Shares by Household Income

Shopping Trip Distances by Household Income

So what is the role of neighborhood location in American diets, and why do food deserts matter far less than the conventional wisdom says they do?

To get at this, the study cleverly tracks two things. First, it looks at what happens when new supermarkets open in less-advantaged neighborhoods, including food deserts. It turns out that the entry of new supermarkets has little impact on the eating habits of low-income households. Even when people in these low-income neighborhoods do buy groceries from the new supermarkets, they tend to buy products of the same low nutritional value.

Basically, new, closer-by supermarkets simply divert sales from older, farther-away supermarkets. As the authors of the study succinctly put it, “supermarket entry does not significantly change choice sets, and thus doesn’t affect healthy eating.” Overall, improving neighborhood access to better grocery stores is responsible for just 5 percent of the difference in the nutritional choices of both high- and low-income people.

Second, the study looks at what happens when low-income people move from neighborhoods served by lower-quality stores to ones with healthier offerings. Again, it finds little effect. Moving to a neighborhood where people have healthier eating habits has virtually no impact in the short term and a very small impact in the medium term, leading to just about a 3 percent improvement in the Healthy Eating Index scores of their grocery purchases.

Ultimately, the study finds little evidence to support the notion that food deserts are solely to blame for unhealthy eating. It concludes that the “evidence does not support the notion that eliminating food deserts would have material effects on nutritional inequality.”

Instead of within cities, the biggest geographic differences in the way Americans eat occur across regions. The map below plots the geography of healthy versus unhealthy eating across America’s 3,500-plus counties. Dark red indicates a lower health index based on grocery purchases, while light yellow represents a higher health index. While there is some variation within cities and metro areas, by far the biggest and most obvious differences are across broad regions of the country. There is a large “unhealthy eating belt” across the Midwest and South, surrounded by healthier eating belts along the East Coast, West Coast, and Pacific Northwest.

Average Health Index of Store Purchases by County

Ultimately, the fundamental difference in America’s food and nutrition has more to do with class than location. More than 90 percent of the difference in Americans’ nutritional inequality is the product of socioeconomic class, according to the study. And it’s not just that higher-income Americans have more money to spend on food. In fact, the cost of healthy food is not as prohibitively high as people tend to think. While healthy food costs a little bit more than unhealthy food, most of that is driven by the cost of fresh produce. There is only a marginal price difference between other healthy versus unhealthy eating options. Furthermore, the price gap between healthy and unhealthy food is actually a little bit lower than average in many low-income neighborhoods, according to the study.

When it comes to food and nutrition, it’s not just that higher-income Americans have more money. They benefit even more from higher levels of education and better information about the benefits of healthier eating. Indeed, education accounts for roughly 20 percent of the association between income and healthy eating, according to the study, with an additional 7 percent coming from differences in information about nutrition.

The authors of the study suggest that equipping Americans with more knowledge and better information about healthy eating may be the better and more efficient path for policy. This seems a bit hopeful, though: Information on healthy eating is widely available, and calorie counts and ingredients are already listed on many, if not most, food items.

There are deeper reasons, again tied to class, that enable affluent and educated households to put this nutritional information to use. For one, they simply have more time and resources to devote to their health and well-being. Conversely, lower-income people may simply discount the health advantages of higher-quality food or see some of those foods, like kale or avocado toast, as smacking of urban elitism.

Whatever the case, America’s great nutritional divide reflects the fundamental class divisions of the country, mirroring the very same class divides seen in fitness, obesity, and overall health and well-being. It’s not food deserts per se, but this deeper fault line that is to blame for nutritional inequality.

This post appears courtesy of CityLab.



KUALA LUMPUR, Malaysia—Malaysia bills itself as “heaven for foreign companies.” Since the 1970s, the Southeast Asian nation has drawn 5,000 foreign firms from more than 40 countries to set up facilities in parts of the country specially set aside for business development. The electronics industry—the country’s largest manufacturing sector, which makes everything from semiconductors to TVs to computer keyboards—accounts for over 36 percent of the country’s exports and a quarter of its employment, according to the country’s manufacturing-development agency. United States electronics companies have invested billions in their Malaysian operations to date.

The results are plain. In Kuala Lumpur cranes stretch outward among the gleaming towers in a perpetual construction boom powered by foreign investment. The streets are spotless and well policed, the water is clean, and the politics are relatively stable. Consumers around the world benefit from products like mobile devices, circuit boards, and LED screens.

At the heart of this economic success are migrant workers. From Bangladesh, Nepal, the Philippines, Indonesia, and India, they arrive at Kuala Lumpur International Airport by the scoreful, papers in hand, hoping for a better life. Estimates of the number of foreign workers in Malaysia vary widely, from the government’s count of almost 1.8 million to perhaps twice as many, which would amount to a quarter of the country’s workforce. Migrant-worker advocates estimate one-third of those workers are undocumented.

Many foreign workers believe “Malaysia is the land of milk and honey,” said Joseph Paul Maliamauv, of Tenaganita, a workers’-rights organization, when I met him at the group’s office in Petaling Jaya, a suburb on the outskirts of Kuala Lumpur. “They come out there, and think the streets are paved with gold.”

But upon arrival, migrants find this paradise doesn’t extend to them. Malaysia is “a booming economy and one of the most developed economies, multicultural and multinational, with a huge amount of foreign investment,” said David Welsh of the Solidarity Center, an affiliate of the labor group AFL-CIO, when I met him in Kuala Lumpur. “But in a region plagued with human-rights abuses and labor abuses, Malaysia is in many ways transparently the regional leader.”

Malaysia provides a window into a troubling part of the global economy that makes the whole system work, one that touches and connects practically every part of the world and billions of people: a flow of humans that shapes lives, creates the world’s things, and is built on the availability of a massive, inexpensive, and flexible labor supply. In Malaysia, it’s possible to see what maintains that flow: the recruitment strategies that bring workers to factories, the government policies that are so ineffective at protecting workers, the struggle to improve working conditions up and down supply chains, and the global political and economic realities that sustain the demand for cheap, unremitting work.

In 2014, the watchdog organization Verité released a study on migrant workers in the electronics sector in Malaysia. Among a sample of more than 400 foreign electronics workers, at least 32 percent were, by Verité’s definition, forced to work against their will. According to the report, “these results suggest that forced labor is present in the Malaysian electronics industry in more than isolated incidents, and can indeed be characterized as widespread.”

That same year, the U.S. State Department ranked Malaysia “Tier 3” in its annual Trafficking in Persons (TIP) report, the worst rating possible, alongside countries such as Iran and North Korea. This rating is reserved for countries that commit egregious human-rights abuses. The next year the country was upgraded to a “Tier 2 Watch List” country, and then a full-fledged Tier 2 country in 2017—upgrades that many felt were unwarranted, especially because in 2015 graves of upwards of 130 suspected human-trafficking victims were found at the country’s border with Thailand. “It made a mockery,” Shawn MacDonald, the CEO of Verité, said of the State Department's revision. Malaysia had “literally done nothing—if anything a slide backwards.”

Welsh and others said that the upgrade was widely assumed to be because of a side agreement, part of the Trans-Pacific Partnership (TPP), between the United States and Malaysia that would give workers more rights. MacDonald alleges that the U.S. improved Malaysia’s ranking because of the country’s “very, very adamant” support for the TPP. The TPP fell apart (bringing the side agreement down with it), but nevertheless the State Department upgraded the ranking, one of the best ways to encourage improvement on the human-rights front.

American State Department workers in Malaysia who contributed to the trafficking report “were very upset” at the upgrade, Charles Santiago, a member of parliament for Klang, an area near Kuala Lumpur, told me over lunch. “Really upset.”

“I went to the State Department and simply said, ‘You guys should be embarrassed. You have done a disservice to your own government.’” (The State Department told me that a new TIP report was imminent, and that it would withhold comment until the next report was released.)

Still, Malaysia has made some improvements, at least on paper. According to Jodie Mitra, from the International Labour Organization, the UN’s labor-standards agency, the government’s efforts to address human-trafficking issues have “improved, as we note increasing trafficking investigations, prosecutions, and convictions.” But, Mitra told me via email, “enforcement and implementation efforts … need to be strengthened as abusive labour practices of migrant workers that may amount to forced labour continue to exist.”

When I visited Malaysia in April, the country’s election was looming; party flags, especially the blue and white scales of the Barisan Nasional, the ruling coalition, hung in rows off the front of practically every building, it seemed. Everyone said it would be business as usual, that despite the scandals that plagued then-Prime Minister Najib Razak, whose party had been in power for 60 years, gerrymandering would ensure that he continued to hold power. But in May, at age 92, Najib’s mentor and the country’s former leader, Mahathir Mohamad, became prime minister.

The new regime is made up of a center-left coalition that includes the Democratic Action Party (DAP), Santiago’s party. “I can tell you there’s been direct reach-out at the highest levels to members of parliament asking what priorities should be to provide road maps of priority issues,” Welsh said. The Labor Consistency Plan—the workers’-rights reforms that had been discussed during the TPP negotiations—is back on the table. And yet, advocates aren’t wholly pleased with the new regime. Against the wishes of the DAP, the government announced the end of a rehiring program for foreign workers at the end of May, which will remove legal protections from hundreds of thousands of undocumented workers. (The country has tried to address the problem in the past by either granting large numbers of illegal workers amnesty or trying to deport undocumented workers.) “The government has not yet established its strategies on labor migration,” said Catherine Laws, a technical officer at the ILO.

Still, the election results might be the impetus to move forward, to build a system of worker protections where there had before been none. The absence of strong labor laws presents an enormous opportunity, said Welsh.

There are many ways for a migrant worker to become trapped in a forced-labor situation, in which a worker has no recourse if work conditions are poor or he or she is not being paid. But the problem typically begins at recruitment, the kickoff to a cycle of debt and bondage that can trap people for years and decades. The Verité study found that 92 percent of foreign workers paid recruitment fees to get their jobs, often exceeding what’s standard in the industry (one month’s wages). The money often goes to both a recruiter in Malaysia and in the worker’s home country. These fees are due well before the worker leaves his or her home country, and often plunge an entire family into debt.

This was the case for Novita Marbun, a worker from Medan, Indonesia, whom I spoke with. When Marbun originally came to Malaysia at the age of 19, she paid 1,500 ringgit—the equivalent of about $375 —to get her job, much more than she makes in a month. Her parents took out a 15-year loan on their house to help pay the fee and other costs of her trip. The money she makes now only covers daily expenses and feeding her son, who is still in Indonesia, but she cannot get enough hours to make enough to help her parents. “I can’t save more money,” she said. As MacDonald puts it, “The system is designed to make the most poor pay the costs of recruitment.”

Workers coming from rural regions around Asia can amass large amounts of debt just in an effort to get to a big city where they can get recruited. Anne Beatrice, of the North South Initiative (NSI), an organization based in Kuala Lumpur that supports workers both in their home countries and when they come to Malaysia, told me that by the time a Nepali worker reaches the capital city of Kathmandu, she typically has already procured a sub-agent in her home village, sometimes at great expense to her family. When she reaches the city, she has already invested so much it can feel like it doesn’t matter if she doesn’t like the look of the recruiter or the contract, or the recruiter substitutes the contract before she gets on the plane. “Recruiters have sub-sub-sub-recruiters and sub-sub-sub-agents,” said Sumitha Shaanthinni, a lawyer who works with migrants. “The recruiter doesn’t go to the village; the sub-agent goes to the village.”

Once she arrives in Malaysia the charges continue to accrue. Workers can find themselves paying for a levy for a work permit (a cost which now the law has shifted to the employer, at least in theory), as well as fees for housing and their visa. Although it is against the law, many employers also confiscate and hold workers’ passports in order to keep them from leaving an untenable situation. (Recruiters have their own costs to cover—often some that are less above-board than others. Maliamauv, of Tenaganita, describes a situation in which government officials provide recruiters with more work permits than there are jobs available. How a recruiter “got that bid, those jobs on paper, you need to guess. Paid a bribe.”)

Migrants in Malaysia do not usually enter illegally, labor advocates told me. It’s not “people climbing over fences. Most of them come documented,” said Maliamauv. Instead, workers find themselves undocumented when they flee a job, or their employment contract is not renewed, since their visas are tied to their employers. And being undocumented means a worker is at risk of being deported during a raid, and that they have no protections against exorbitant fees when their recruiter gets them another job.

“After you pay the levy deduction, the passport deduction, and the shelter deduction, your salary is so low,” said Beatrice. The contract doesn’t mention these other charges, and what workers are left with is often not enough. When the workers complain, an agent will encourage them to do the job, or, said Beatrice, the agent says, “‘Leave the job, I will find you another place.’ [The workers] don’t realize they can’t do it, and will become undocumented.”

Once settled in, undocumented or not, workers face very difficult living conditions. When I spoke with Manjoj Chapagain, a translator and migrant worker, he had just come from taking Malay doctors around a migrant-worker camp near the city of Petaling Jaya, a suburb of Kuala Lumpur. Five or six thousand workers live in the camp, by his estimation. He said the doctors were “very surprised” by the living conditions, in which 20 people can sometimes share a 1,000-square-foot house, with 10 sleeping there at night and 10 in the morning, as they rotate in and out for different work shifts. There’s no clean drinking water and no plumbing. “The doctors had never seen this kind of mess and kind of smell,” he told me. These living conditions can further place workers in a precarious situation, as they are not allowed to stay in Malaysia if they contract certain diseases, such as hepatitis, according to Maliamauv.

Often workers fall ill “because the living conditions are so bad,” Maliamauv said. Female workers are also frequently sent home if they get pregnant. According to the Nepali embassy, 386 Nepali workers died in Malaysia in 2016. By the embassy’s count, about 300 on average have died per year since 2005. The cause of death isn’t always determined, and unexpected deaths can be extremely hard financially on their families, who are left with the debt to recruiters but no earnings, to say nothing of the emotional toll.

The treatment of workers is not uniformly bad across companies and sectors. Well-known multinational companies, many of which are monitored by watchdog groups here and abroad, tend to have better track records. The problems come further down in the supply chains. “The big corporations, the multinational companies, I don’t think have a problem much,” Shaanthinni said. “They mostly comply with the code of conduct that they have and don’t deduct wages or keep the passports, things like that. But their supply chains do that. How much they are monitoring [that] is another question altogether.”

Many companies emphasize that they push their supply chains to function at the same standard that they do. And many major electronics brands say on their websites that they expect companies in their supply chains to comply with both legal standards and human-rights standards. However, supply chains are complicated, with factories of varying sizes, employers who are often recruiters, and, in Malaysia, worker protections that are both weak and inadequately enforced.

Since 2004, many companies have looked to a watchdog organization, the Responsible Business Alliance (formerly the Electronic Industry Citizenship Coalition, or EICC) to help them monitor their supply chains. Bob Mitchell, from the RBA, told me that the organization relies on “diversity in approaches to addressing endemic issues in supply chains,” because the problems are so complex.

“The further you get down, the less leverage you have as a company or an individual company,” Mitchell said. RBA works to harness the power of the brand names to pressure the downstream suppliers. But some lawyers and workers’-rights advocates say this approach has not improved the situation, in part because of the lack of transparency from companies about which suppliers are in their supply chains. Even the companies that have prioritized treating their workers well, such as Patagonia, still struggle with the further reaches of their supply chains.

And of course, many workers do not know where the fruits of their labor end up either. “If you are going to produce a small component, sometimes you don’t even know what the component is,” Shaanthinni said. “If it is a screw, how are they going to know? … Lower down, they provide the metal. You say, ‘What’s your job?,’” and the worker answers, “‘Oh, I cut metal.’ How am I going to know what company it is going to?”

This article is part of a project called “The Unfree,” which is supported by Dignity Health Foundation and Silicon Valley Community Foundation.



It’s getting harder and harder to avoid paying for one of the most basic and necessary banking services: a checking account. And that could make it even harder for low-income customers to access the services of mainstream banks.

Just this week, Bank of America finished converting an unspecified number of customers still using its eBanking checking account to a different kind of checking account that will charge a monthly fee of $12. While the original eBanking account wasn’t technically free, its monthly $8.95 fee could be circumvented if account holders didn’t go to a teller (which fewer and fewer Americans do) and agreed to get their statements online instead of in the mail. The fees for the new account won’t be as easy to get around. In order to have the $12 monthly fee waived, customers will need to keep their balance above $1,500, or have direct deposits of $250 or more per month.

In comparison to most other major banks, those terms aren’t out of the ordinary, and those fees are comparatively low, Betty Riess, a spokeswoman for Bank of America, said in an email. That’s true. In recent years, plenty of other major banks including Wells Fargo and U.S. Bank have moved away from no-fee or effectively free checking accounts in recent years. “Checking accounts oftentimes are free if certain conditions are met—of course, those conditions can be tough for people to meet,” says Thaddeus King, who works on consumer-finance issues at the Pew Charitable Trusts.

Still the change could be a blow to some some of the low-income clients who relied on the ability to forgo a few services in exchange for access to free checking at a major financial institution. Many Americans, especially those who don’t earn much, have a tenuous relationship with the traditional banking system. Around 7 percent of Americans don’t have very basic banking access, such as checking accounts, and around one-quarter of Americans don’t have access to all the banking tools that they need, such as affordable accounts, debit cards, and credit.

So why are banks making it harder for Americans to keep an account? Over the past few years, overdraft practices—when banks charge customers for overdrawing their checking accounts instead of denying the transaction—have come under scrutiny. The fees on such policies can start at $35 at major banks, and many banks have relied on transaction reordering, which sorts checking account withdrawals from highest to lowest in order to increase the likelihood of one or more overdrafts on a low balance account. This so-called “overdraft protection” costs Americans around $14 billion a year, according to the Center for Responsible Lending.

These policies have disproportionately hurt low-income Americans who are more likely to overdraft (and wind up closing accounts because of constant overdrafts); they have also brought in a lot of revenue. The shift away from harsh overdraft penalties will undoubtedly help some consumers avoid onerous charges, but the fees generated by those overdraft policies were a big part of the free checking-account model. Thus, as banks lose that revenue stream, it’s become more likely that customers have to pay for their accounts.

There are still options for those who are unwilling or unable to pay a monthly fee: some smaller regional banks, credit unions, and banks without brick-and-mortar locations still offer free checking accounts. And many banks offer low-fee checking accounts for customers who are willing to forgo basic banking options, such as paper checks or bank branches. But at big banks, the move away from free checking is likely here to stay.



Gary Cohn, President Trump’s top economic adviser and the director of the National Economic Council, will resign from the White House, according to multiple sources.  

Neither the White House nor Cohn has offered an official reason for the resignation—the latest in a string of noteworthy departures from an administration that appears to be descending into chaos.  But it’s hard to ignore the fact that Cohn’s departure comes in the disorderly aftermath of Trump’s announcement that he will enact stiff tariffs on steel and aluminum imports. The president’s tariffs decision was reportedly made over Cohn’s strenuous objections and without input from most of the president’s economic advisers. According to NBC News, Trump made his announcement in a fog of frustration, following the resignation of Hope Hicks, his longtime aide.

Cohn had reportedly threatened to step down before, most notably last August after the Charlottesville protests. After President Trump said there were “very fine people on both sides” of the violence that ended in the death of a woman protesting neo-Nazis, Cohn said he felt “enormous pressure” to resign. Then, just the threat of his departure was enough to send financial markets plunging. As of Tuesday evening, stock futures point to a large loss when markets open on Wednesday.

As the former president of Goldman Sachs, Cohn was widely seen as a White House surrogate for Wall Street interests, charged with reining in the president’s nativist instincts. As a candidate, Trump spent months railing against the effects of globalization and trade, promising to protect steelworkers and miners. But in his first year, the president’s economic policies seemed effectively interchangeable with those of any typical Republican leader, like Mitt Romney or Paul Ryan. He oversaw massive deregulation of businesses and signed a corporate tax cut whose benefits have accrued overwhelmingly to the largest corporations and their shareholders.

Indeed, the White House is already framing Cohn’s resignation as the inevitable departure of a man who has accomplished all he came to do—cut taxes on big companies. “Gary has been my chief economic adviser and did a superb job in driving our agenda, helping to deliver historic tax cuts and reforms and unleashing the American economy once again,” the president said in a statement to The New York Times.

Cohn’s departure marks a new chapter in the turf war between the White House’s free-market globalists and its nationalist flank. After Steve Bannon was fired and the president signed the corporate tax cut, it seemed that Cohn and other free-market advocates had persuaded Trump of the virtues of conservative economic theory. But Trump’s new tariffs—and the way they were conjured without any formal decision-making process—may signal Trump’s new willingness to defy his advisers and the Republican Party to pursue a radical agenda that few economists can explain, much less defend.

Trump has spent much of the last year pointing to the stock market as a report card for his presidency. By threatening a trade war and allowing the resignation of Wall Street’s de facto ambassador to Washington, he has chosen another path that could threaten that pro-business narrative.



George Soros is an exceptionally busy man, at least according to right-wing conspiracy theorists. Just within the last year, he has been credited with single-handedly funding the Black Lives Matter and Antifa movements, as well as with bankrolling (as a false-flag operation) the white-nationalist rally in Charlottesville against which both of those groups mobilized. Soros has been accused of masterminding Colin Kaepernick’s NFL protest and the Women’s March, and with pulling the strings that led H.R. McMaster, President Donald Trump’s national security adviser, to fire alt-right–aligned staffers. And last week, the supporters of the Alabama Senate candidate Roy Moore alleged that Soros paid women to falsely accuse him of sexual assault.

Soros, of course, has been the subject of intense scrutiny for decades. Ever since he made $1 billion by shorting the British pound in 1992, the power Soros wields over financial markets has loomed large in the public imagination. By the early 2000s, when Soros had become one of the top funders of the Democratic Party—he once declared that he’d willingly trade his entire fortune to prevent President George W. Bush’s reelection, though in the end he only spent $27 million, an unprecedented sum at the time—he also became a partisan target for conservatives.

But it hasn’t been Soros’s financial buccaneering or even his political giving that have featured most prominently in the conspiracies about him. It’s been his philanthropy. Soros has long been one of the leading donors to progressive causes in the United States and is the most generous financial supporter of pro-democracy organizations around the world. And his giving will likely only increase in the years to come. In October, Soros disclosed that over the last few years, he has turned over around $18 billion to the institutions through which he has channeled his philanthropy, the Open Society Foundations (OSF). The enormous gift was met as a confirmation of all the darkest fears stoked by his antagonists. Pointing out that Soros’s foundation would now rank as the second largest behind the Gates Foundation, the right-wing website Breitbart announced the news by referring to OSF as the “Death Star.”

Stories of Soros as philanthropic bogeyman are clearly symptomatic of the current political moment. The vastness and the viciousness of the partisan divide, coupled with the general suspicion of financial “elites,” can make it tempting to focus ideological frustrations on a few munificent individuals who belong to the opposing political team. If conservatives do so with Soros, progressives have their own set of donors whom they demonize—such as the Koch brothers, and more recently, Robert Mercer—though, in general, progressive conspiracies involving conservative benefactors tend to be more closely tethered to reality.

What’s less well understood is how narratives that pit scheming benefactors against “the people” can work against the values of a democracy. Not only are conspiracy theories often deliberately employed by authoritarians to undermine grassroots activism, but they also muddle discussions about the immense power philanthropists actually do wield, crowding out valid concerns about the role mega-donors now play in shaping society.

The philanthropist has always been a figure fit for abuse—the term was coined by an ancient Greek dramatist to describe Prometheus, whom the gods tortured for the crime of bringing fire to mankind. Early-modern uses of the word philanthropy referred not to large-scale giving but rather to promoting a set of egalitarian, universal values. As the term became used more widely during the Enlightenment, it became associated with ambitious reformist causes such as abolition. It also absorbed many of the critiques directed at such movements: These philanthropists, critics claimed, spoke in grand terms about the rights of Man but ignored the poor and oppressed in their own communities. The grandiose universal values they promoted threatened to loosen religious and geographical bonds. After the French and Haitian revolutions, whose champions claimed to be marching under philanthropy’s banner and pursued violent means to achieve emancipatory ends, the concept began to carry the whiff of menacing radicalism.

Then, in the late 19th century, the meaning of philanthropy began to change. With the rise of industrial fortunes and the large-scale monetary contributions derived from them, the word came to signify large-scale giving. (That idea may seem unrelated to the word’s roots, but the conceptual link is that both bold  social reforms and modern philanthropic foundations are premised on the inadequacy of modest, intimate, small-scale charitable donations to address the world’s most pressing problems.) Industrial titans—John D. Rockefeller, to name one—funneled their wealth into ambitious programs of institution-building, research, and reform, and in the process attracted to philanthropy the antagonism provoked by the rise of global capitalism.

The United States (and its economy) has been highly hospitable to philanthropists, but it has also provided a political system that nurtures conspiracy theories directed against them. Historically, both the right and left have crafted their own narratives, each fueled by a deep suspicion of concentrated power. Early-20th-century progressives worried that robber-baron benefactors were creating a shadow state that would overwhelm the federal government; conservatives and populists warned of the dense networks of charities, academic institutions, and private foundations that controlled public opinion. By mid-century, right-wing anti-Communist conspiracies targeted major philanthropies as seedbeds of pernicious internationalism. In the 1950s, congressional investigation of philanthropy sought to determine whether foundations subsidized “un-American and subversive activities” and supported efforts “to undermine our American way of life.” In the following decades, anti-imperial and anti-globalization movements lodged both legitimate grievances about philanthropies and more decadent tales of their power.

George Soros might as well have been focus-grouped to attract the various antipathies that have long swirled around philanthropy. He’s a champion of globalism, capitalism, and progressivism. He’s also Jewish, and anti-Semitism has long grown up alongside the major critiques of those forces. As anti-Semitic lore has it, the humanitarianism of the “International Jew” is merely a cover for an interest in global domination. Soros’s Jewish identity is rarely explicitly invoked by his antagonists, but it doesn’t need to be: Every invocation of his “cosmopolitanism” and his essential foreignness serves as a dog whistle for those who savor the lineage of those slurs.

Soros’s Open Society Foundations have together given away some $14 billion over the last three decades—mostly to social-justice, pro-democracy, and human-rights causes—and now operate in more than 100 countries around the world. His first major gift, made in 1979, funded scholarships for black South Africans. In 1984, he established a foundation in Hungary to cultivate the shoots of liberalism growing beneath Communist frost; his philanthropy provided copying machines, for instance, that allowed anti-Communist activists to print samizdat literature. After Communism’s collapse, Soros-funded foundations nurtured nascent pro-democracy institutions in nations throughout Central and Eastern Europe, paying for travel grants for students, supporting watchdog organizations that promoted good governance and human rights, and seeking to protect vulnerable and marginalized populations such as the Roma. In 1991, he founded the Central European University in Budapest to promote open academic inquiry. Most recently, Soros has supported a liberal immigration policy in Europe as a response to the refugee crisis.

Soros has never shied away from controversial issues, and his philanthropy has long generated controversy. But his transformation into a figure of almost demonic power is a more recent phenomenon. It’s the product of two trends, one domestic and the other international.

In the United States, conspiracies about Soros were first spun by leftists opposed to globalization. But those narratives soon found a home on the other end of the political spectrum. Right-wing media provocateurs seized on Soros’s globalism as exemplifying the beliefs of a small group of “radical infiltrators” who were “quietly transforming America’s social, cultural, and political institutions,” in the words of one popular 2006 polemic called The Shadow Party. On Fox News, Glenn Beck devoted entire episodes of his show to sketching out the twisted “One World Government” ambitions of the man he refers to as the “Puppet Master.”

Internationally, the demonization of Soros has coincided with what two decades ago Fareed Zakaria marked as the rise of illiberal democracy—regimes that are democratically elected but that ignore the “constitutional limits of their power and depriv[e] their citizens of basic rights and freedom.” After the “color revolutions” in Ukraine and Georgia in 2003 and 2004, in which several Soros-funded NGOs were involved, Vladimir Putin exploited these discontents to suggest that the uprisings had been orchestrated by Soros. The global financial crisis created a climate especially ripe for sowing suspicions about the machinations of a global financial elite. Other authoritarian leaders around the world took up the charge, suggesting that political agitation and grassroots mobilization against their rule was not in fact an expression of popular will but manufactured by shadowy outside forces, over which Soros presided.

This dynamic has recently been on display in the country of Soros’s birth, Hungary, where the ruling party of Prime Minister Viktor Orbán (who, in his youth, benefited from a Soros-funded fellowship to study at Oxford), recently spent $21 million on billboard ads against liberalizing immigration policies, some featuring a menacing photo of the philanthropist and the caption “Don’t Let George Soros Have the Last Laugh.” (Unsurprisingly, the posters soon attracted anti-Semitic graffiti.) Orbán’s party has also passed legislation clearly meant to shut down Central European University, which Soros founded (thousands protested in response). And in October, Orbán announced a “national consultation” in which a government-funded questionnaire was circulated to citizens to survey their views on an imagined master-plan hashed by Soros and European Commission leaders to abolish refugee quotas. Orbán has also directed the nation’s spy agencies to investigate a “Soros empire” of organizations that he claims seek to undermine Hungary’s Christian culture.

Right-wing leaders in nearby countries have also hyped Soros conspiracies to rally their base. In Macedonia, the former prime minister has called for the “de-Sorosization” of society. In Romania, the head of the governing party blamed anti-corruption protests on Soros and claimed that he “financed evil.” These campaigns—along with similar ones in Serbia, Slovakia, and Bulgaria—aim not just to tar the progressive policies with which Soros is now closely identified (specifically, more open immigration), but to undermine pro-democracy organizations that could challenge their political power.

With Trump’s election and the ascendance of American right-wing nationalism, these domestic and international strands have converged. In March, a group of GOP senators asked Secretary of State Rex Tillerson to investigate the extent to which U.S. funds were being given to OSF, allowing it to “impress left-leaning policies on sovereign nations, regardless of their desire for self-determination.” (The State Department declined to look into it). And last week, on Twitter, Trump’s close congressional ally, Representative Steve King, linked to an anti-immigrant tweet from Orbán and added that “Western Civilization is the target of George Soros and the Left.”

There is a particular irony to all these attacks. That’s because Soros, perhaps more than any other major philanthropist, has rejected the top-down model on which the caricatures of his philanthropy depend. In the Open Society Foundations, he created a sprawling, decentralized network of local boards in some 20 nations that were granted exceptional levels of autonomy. “The guiding ethos of the foundations is different from most [philanthropic] entities in which funding decisions are made in the center,” notes Leonard Benardo, the vice president of the OSF, and formerly its regional director for Eurasia. “That’s just how we function.” As Benardo explains, Soros’s governing philosophy insists on the primacy of local knowledge: “That’s why we have a surfeit of boards.” If Soros is a puppet master, then he’s given his marionettes some pretty long strings.

Still, it’s important to acknowledge that the strings do exist, and that there is a limit to the control Soros is willing to cede. He remains the chair of a global board that monitors the national boards and that has final authority on their grants. According to Benardo, he has rarely exercised that authority, but it exists nonetheless. Soros made this clear in a telling paragraph in an autobiographical essay in which he highlighted Open Society’s reliance on local knowledge and his willingness to defer to the judgments of local boards. He then added a significant caveat: “If I seriously disagreed with their judgment, I changed the board.” It’s also important to note that no matter how bottom-up the OSF is, Soros’s money has by definition empowered some parts of civil society over others, propping up certain organizations, public figures, and issues.

Which is all to say that the power that Soros has wielded and continues to wield as a philanthropist is undeniable. He took a new, aggressively political approach to philanthropy, one that is now embraced by a rising corps of billionaire donors, from Tom Steyer on the left to the Koch Brothers on the right, to Bill Gates somewhere in the middle. In the U.S., Soros was one of the first philanthropists to put significant money toward promoting gay marriage, opposing the death penalty, and reforming immigration law and the criminal-justice system.

Whatever one thinks of the merits of those causes, the ability of Soros and other philanthropists to use their vast wealth to exercise power over the realms of democratic deliberation is worthy of serious reflection. It’s up for debate how much sway individuals should have over public policy, but it’s almost impossible to weigh that question soberly when operating in a conspiratorial register. This suggests the second danger such narratives pose to civil society: Feverish theories about shady influence from “outsiders” obscure the real threats philanthropic power can pose to democratic institutions and norms. Even if philanthropic bogeymen are not real, there still might be good reasons to fear the dangers they actually pose.



This moment was inevitable. It just wasn’t supposed to happen so soon.

Due to the inexorable aging of the country—and equally unstoppable growth in medical spending—it was long obvious that health-care jobs would slowly take up more and more of the economy. But in the last quarter, for the first time in history, health care has surpassed manufacturing and retail, the most significant job engines of the 20th century, to become the largest source of jobs in the U.S.

In 2000, there were 7 million more workers in manufacturing than in health care. At the beginning of the Great Recession, there were 2.4 million more workers in retail than health care. In 2017, health care surpassed both.





There are several drivers of the health-care jobs boom. The first is something so obvious that it might actually be underrated, since it is rarely a proper news story in its own right: Americans, as a group, are getting older.

By 2025, one-quarter of the workforce will be older than 55. That share will have doubled in just 30 years. The graying of the nation will have widespread economic and political implications, like declining productivity and electoral showdowns between a young, diverse workforce and an older, whiter retirement bloc. But the most obvious effect of an aging country is that it needs more care—and that means more workers.

Second, health care is publicly subsidized, in several ways. Most directly, the U.S. spends hundreds of billions of dollars each year on Medicare, Medicaid, and health-care benefits for government employees and veterans. More subtly, the U.S. subsidizes private insurance in several ways, including through a tax break for employers that sponsor health care. This public support makes health-care employment practically invincible, even during the worst downturns. Incredibly, health-care employment increased every month during the Great Recession.

Third, the two most destabilizing forces for labor in the last generation have been globalization and automation. Together, they have hurt manufacturing and retail by offshoring factories, replacing human arms with robotic limbs, and dooming fusty department stores. But health care is substantially resistant to both. While globalization has revolutionized supply chains and created a global market for manufacturing labor, most health care is local. A Connecticut dentist isn’t selling her services to Portugal, and a physician’s receptionist in Lisbon isn’t directing her patient to Stamford. Health-care work has, so far, been generally resistant to automation, too. While artificial intelligence may one day take over radiology, while programmable robots replace brain surgeons, that future isn’t quite here yet.

Recently, the growth in health-care employment is stemming more from administrative jobs than physician jobs. The number of non-doctor workers in the health industry has exploded in the last two decades. The majority of these jobs aren’t clinical roles, like registered nurses. They are mostly administrative and management jobs, including receptionists and office clerks. It’s not always clear that these workers improve health outcomes for patients. “Despite all this additional labor, the most meaningful difference in quality over the past 10 years is the recent reduction in 30-day hospital readmissions from an average of 19 percent to 17.8 percent,” wrote Robert Kocher, a senior fellow at the Schaeffer Center for Health Policy and Economics at the University of Southern California.

This isn’t the end of health care’s run. It’s just the beginning. Of the 10 jobs that the Bureau of Labor Statistics projects will see the fastest percent growth in the next decade, five are in health care and elderly assistance. The two fastest-growing occupations—personal-care aides (who perform non-medical duties for older Americans, such as bathing) and home-health aides, (who help the elderly with medical care)—are projected to account for one in every 10 new jobs in that time. The entire health-care sector is projected to account for a third of all new employment.

While this is an important moment to take stock of the rise of the care economy, labor categories like “retail” and “health care” are imperfect approximations. For example, as online shopping grows, fulfillment centers and delivery truck drivers become integral parts of the retail industry. But the government does not categorize many of these jobs as retail. But while some categories are too restrictive, perhaps others are too broad. For example, there are technically more jobs in “leisure and hospitality” than in health care. A supersector that includes restaurants, hotels, and amusement parks, leisure and hospitality has grown faster than the overall labor market every year since the turn of the century, mostly thanks to the growth in restaurant workers. But it doesn’t really make sense to think of a Michelin star chef, a hotel manager, and a ticket counter at Disney World working in the same industry.

The work that seemed to define the 20th century in the American imagination included union jobs held by white men who made things. But manufacturing employment peaked in the late 1970s. Forty years later, the fastest-growing occupations—like personal care and home-health aides—are quite the opposite: poorly paid, lacking a strong union, often female, and disproportionately filled by immigrants (who account for one-third of the in-home health care workforce). The fastest growing job with higher-than-average pay in the U.S. is registered nurse. But male nurses are stigmatized. Even married women say they’d prefer their husbands find another profession. But an increase in male nurses is just the sort of development that is demographically inevitable in any health-care nation. Services are the new steel.



Editor's Note: This article is part of an oral-history series where Aaron Reiss interviewed the young-adult sons and daughters of Chinatown shopkeepers about how they are helping to keep their families’ businesses alive.

Olympia Moy, a 35-year-old with a background in nonprofit work and advocacy who helps manage her parents’ music school, shares the struggle of reconciling her legacy with that of her parents. “My parents would have rather I had come back for a cushy job and a steady income,” she says. “I came back thinking of their business as fertile ground for civic change.”

I spoke with Moy in the spring of 2018. Below is our conversation, lightly edited for clarity.

While my mom was studying piano at the Mannes School of Music, she was also teaching English and tutoring piano on the side. She also helped open a little candy shop with her mother on Bayard Street. At that time everyone was hustling. A lot of people here had just been uprooted after the Cultural Revolution in China. Coming here, they had to build something from scratch.

By the time I was born, she had turned her piano tutoring into a small business, which she ran out of a residential apartment in Chinatown. My parents had bought that building and the ground-level medical practice, which my dad took over. In the apartment above, we had an upright piano in the living room, another in the kitchen, and in another room there was a Steinway. My mom gave piano lessons, and we held recitals where 15 or 20 people would pile into the apartment and listen to students play.

When my parents bought an apartment building on Henry Street, my mom started running the Florentine School of Music, Art and Academics out of the storefront space. She was selling upright pianos, and people would come to Chinatown, buy a piano, and take it back to Long Island, or Brooklyn, or wherever. In the back, there were two rooms for piano lessons. Then that grew pretty quickly to the point where there were a couple of hundred students, with three to five classes going on at a single time—classes, not even private lessons. There were so many parents, and kids, and class after class coming and going. That’s how I grew up.

This was before cellphones, so if I was around home or the music school, I would be sent to run messages between the office and the violin studio, letting teachers know when students had canceled.

My main instrument is the viola, but I started on the violin at a Florentine class when I was almost 3 years old. My mom had a friend who was teaching a class that had a no-show, so she said, “Okay, just try this out.” I ended up staying in the lesson for 30 minutes. My dad heard about it and said, “You’re such a pushy mother!”

From then on, I was taking lessons and also participating with my siblings and my dad in the Yamaha music-curriculum courses. Eventually, our teacher at Florentine let us go out beyond the school because we didn’t have a symphony or an orchestra at Florentine. We ended up at the Manhattan School of Music. That was the end of my time as a music student at Florentine, but after that, I would help out as an assistant for concerts. In college I would fill in if they needed a substitute, teach a violin class here and there. I would help the teachers coach in larger ensemble classes. As I got older, my responsibilities got bigger. I would fix up our student database or maintain our billing systems, make brochures and printouts.

I think children in family businesses naturally become management consultants for their parents, when they hear and see the different issues that the business is going through. Like, you see these black-and-white Xeroxed brochures, and at some point, you’re like, This can be better. And you throw in your two cents, and then it gets better, and then you get more involved, and that’s how it goes.

In 2001, I went away to college, and then to grad school, and then after that to a public-interest fellowship in Chicago. Obama was just elected; I was looking at all my options in the nonprofit world. I was looking around at my peers and the different ways that they were getting involved with civic society. I remember a friend who took an entry-level job at a nonprofit telling me about how her organization was so underfunded and under-resourced that she was using a filing cabinet as a desk. I started thinking about my family’s business, and about how that basic work had already been done. I thought, rather than trying to figure out budget-line items for furniture, I could start this work more quickly from home.

So I saw coming back to Chinatown like fertile ground for the work that I wanted to do—there is so much civic potential, and so much work to be done here. And here is my family business, with a real base in the community and all these resources waiting to be marshaled. I decided I would come back, that I would wear this small-business-owner hat and see where that takes me in terms of understanding how this neighborhood works and how community change happens.

Meanwhile, I think my parents would rather I had come back for a cushy job and a steady income instead of transforming or redefining their legacy, or making them more visible than they want to be. You know, I came back thinking of their business as fertile ground for civic change—and they would rather I not use the family name and not use the family resources. I think my mom feels like she already had a legacy, you know? Quiet, sustained work over time.

Now I’ve been working here for eight years, doing this work on community building, which has taken on different forms over time. I helped organize the first-ever LGBT contingent to march in Chinatown’s Lunar New Year Parade in 2010. I did a lot of that work in the closet, actually. It’s common for a lot of queer Asians to be out in the mainstream community—and proud to be queer and Asian. But when they come back to the Chinese community, they go back into the closet. And I was kind of like that. But when this queer group was facing resistance for marching in the Chinatown parade, I kind of took on a more active role to make it happen. I was also working with Q-Wave—an LGBT group for women and trans folk of Asian descent. During that time, I was organizing educational programming, general meetings, and social events. I also worked a lot with the Princeton AlumniCorps, which helps put recent grads in community-based nonprofits. More recently, I’ve gotten involved with trying to strengthen the resources and organizations that are here in Chinatown—make them more resilient and more connected to the past.

But the reality is that I’m also running these businesses: the school and managing the real estate we own and rent to tenants. My role is elusive. I’ve never printed business cards—I don’t know what I would put on them—but my computer is littered with attempts and drafts.

We deal with the same issues as a lot of family businesses. When people like me come back, having grown up privileged, exposed to other ways of thinking and doing business—thinking strategically and with vision—it isn’t always well received, because that’s just not how things are done. For the generation that came when my parents did, I think they are inherently in survival and maintenance mode.

But my personality is very idealistic; I have these big visionary ideas. I had envisioned when I came back that Florentine would organically transform into this community center, this beacon in Chinatown and the Asian community at large. A place where all groups could have a small stage to show and see what Chinatown has to offer.

How that plays out in the day-to-day is that I want to knock down a wall to put in a movable partition so that we could have our traditional tutoring classes on the weekends and black-box theater performances on weeknights. And the measured response I get is, “Why don’t you start programming in one room, and once you’re running that successfully, then we can talk about knocking down a wall.”

When you’re talking about a vision for the future, there’s this tension, like, “Whose business is this? Whose resources are these?” If you’ve put three, five, 10 years of your adult life into a business, is it yours now? Is it your legacy? Is it what you’ve built as well? And that’s a tension that we really deal with.



Editor's Note: This article is part of an oral-history series where Aaron Reiss interviewed the young-adult sons and daughters of Chinatown shopkeepers about how they are helping to keep their families’ businesses alive.

Kevin Huang, a 22-year-old college student, recounts how short staffing at his family’s bakery found him unexpectedly spending his evenings after school helping to make buns and pastries with his father. “I’d have to think of ways to keep him in conversation, you know, to keep him up. So I would ask him about growing up in China, about serving in the Army. Little things like that. It’s not that our relationship was bad in the past; we just didn’t have time.”

I spoke with Huang in the spring of 2018. Below is our conversation, lightly edited for clarity.

It can be hard to communicate with my father, because my Cantonese is limited and he doesn’t really speak English. My mother is definitely the translator in the family, because she is fluent in Mandarin, Cantonese, and English. With my dad, sometimes when we are talking, I won’t get a point, and he’ll dumb it down until I’m like, “Oh, I know exactly what you mean.”

In China, I think my dad did something with engineering. But he couldn’t really do that here because getting a license is hard without the language. When my dad came to the States, he started working at Fei Da Bakery, back when Fei Da was just one shop. He took a class and got certified in baking, and he worked there for several years.

By the time I was born, he had started his own bakery. My mother had me and my little brother. Back then, my mom had a full-time office job in Midtown, was raising three kids, and also helping out at the bakery with administrative stuff. And I wouldn’t really see my dad that much because he was up at 4:30 a.m. to start the bakery every day, and by the time he got home, my light was already off.

Me and my brothers, we were never really truly involved with the bakery growing up. My dad never wanted us to be. Because my dad knows how strenuous it is, he didn’t want us to have to bust our ass in the bakery. He didn’t want us to bake, to be working here and try to juggle that and school—he wanted us to focus fully on school and our social life and all that.

So for him, it was about money and about sustaining a family of three boys, not about a family business. And we were comfortable; we had enough money. They said, “Don’t worry about anything,” and we truly didn’t. Not that we were rich, but we were comfortable.

The way I saw the business really changed when I did study abroad last year. I went to Europe for one month, and it was really the first time I was away from home for that long. We all live together in the same apartment, so when I got back, I would be staying up, you know, waiting for my parents to come home from the bakery every day, thinking: I lived the time of my life on this trip, and I can’t wait to tell my parents and show them pictures, but they never come back. It’s, like, midnight, and I’m thinking, Where the fuck are they?

I start asking them, and they are telling me everything is good. They kind of lied. You know, they smile, but there are, like, bags under their eyes. And I’m like, “Y’all look different.” I start to hear them arguing about how they were losing workers all the time. The bakery workers were dropping like flies.

I start asking my younger brother, Alex, “Who’s manning the jyu cheung fan station? Who’s doing the cake station? And he’s like, “Dad. Dad. Dad.” He’s like LeBron James: He’s doing everything for his damn team. He’s, like, all five positions and also the coach. But one guy making a whole bakery worth of baos, everyday—that’s insane. He can’t eat when he comes home because he has to be back up at 4:30 a.m. to make more cakes at dawn.

I have to give the credit to Alex; he started going to help out at the bakery at night, helping Dad. At first, I thought he was just helping out a little bit, but I start to realize it’s, like, every day. I go down to the bakery, and it turns out there are only five people working here, and they’re all family. I’m like, “Auntie, what are you doing here? And my other auntie! What are you doing here?” And they’re like, “Oh, we’re just helping out.” It was just a realization for me: They were carrying this whole load, especially my dad, because he knows how to make all the baos. So I was like, “Okay, I gotta step in.” I started coming in every day after school, at like 5 or 6 p.m., and working with my dad in the back until closing, at midnight or 1 a.m.

I made it work with school; I would be making dan ta while listening to lectures for my courses. At the same time, I’m spending more time with my dad than I ever had. And we end up talking a lot more than we ever have. Sometimes I see him rolling out dough and falling asleep. So I’d be like, “Yo, wake up!” and I’d have to think of ways to keep him in conversation, you know, to keep him up. So I would ask him about growing up in China, about serving in the Army. Little things like that. It’s not that our relationship was bad in the past; we just didn’t have time. We are really talking for the first time.

We just never saw each other before. You know, like only for holidays, when he would come home a few hours earlier. Other than that, I hardly saw his face. Now, the more I get to know him, I’m, like, Shit, I didn’t know you were that woke—you know, about things in the news and about minor family issues. He goes on WeChat, and he listens to Chinese radio—so he knows about international news and American news. Like, if I bring up news of a school shooting, he has his own ideas of why these things are happening, and the issues in America. I’m like, Oh, you know about this stuff?

I’ll also be sharing what I’m doing in my life. I like to go to the gym, so I might tell him, “Today I deadlifted so-and-so pounds.” He’s funny—he’ll tell me about how, when he was a kid, he could, like, pick up a car engine. We just never really talked before, so it’s just all these random things that come to mind. It’s 20 years of catching up, all at once.



The worsening traffic in New York City is a personal inconvenience, an environmental blight, and an economic drag—possibly to the tune of $20 billion. That’s the latest projection by the Partnership for New York City, a group that represents businesses, of the annual loss for the metro area over the next five years if nothing is done to unjam cars.

Congestion pricing—essentially, tolling cars to enter crowded streets during rush hours—is widely viewed by transportation advocates and researchers as an essential intervention into the city’s growing transportation crisis. It’s an idea that’s succeeded elsewhere—since London cordoned off a fee zone in 2003, the number of cars entering its city center has declined 44 percent. Congestion pricing was last seriously attempted under Mayor Michael Bloomberg in New York City in 2008, but there’s still no precedent in the U.S. for such a system.

That could soon change, if a report by Fix NYC, a traffic advisory panel appointed by New York Governor Andrew Cuomo in October 2017, turns into law. Released last week for review by the New York state legislature, the report recommends a plan, with three phases, for smoother streets and more transit revenues. It suggests a charge for driving into Manhattan’s core. One possible number: $11.52 for personal vehicles. Here are the three phases.

Phase One: Fix What’s Broken

Between cheaper gas prices, population growth, unreliable transit, and the rise of ride-hailing apps, average speeds in the central business district of Manhattan slowed by more than 17 percent in 2016, to 6.8 mph.

Phase one, which the report recommends starting immediately, involves identifying improvements for transit connections between New York’s central business district and the outer boroughs. That means restoring the subway to a state of good repair, for which no one should hold their breath. (That Herculean task could take billions of dollars and decades of work.) But there are faster and more affordable fixes, too, such as improving bus service and introducing new express bus routes to poorly connected neighborhoods. The Bloomberg administration called for this when it pushed for congestion pricing. Local advocacy groups have continued to demand the same. (And—why not?—the city could throw in some streetcars, too.)

Phase one also suggests reforming the city’s much-criticized parking-placard program, reviewing parking laws for Manhattan tour buses, and stepping up enforcement by the NYPD of moving traffic violations—a potentially rich source of revenue for the city and state.

New York City’s Parking-Ticket and Moving-Violation Revenues

Phase Two: Tax Uber and Lyft

On-demand vehicles are having an undeniable impact on urban mobility: Uber and Lyft are drawing riders off trains and buses, and packing more vehicle-miles traveled on city streets. Especially troubling is how many of these cars are roving free of passengers: Research by the transportation consultant Bruce Schaller, cited in the report, found that the number of hours for-hire vehicles spent without riders “rose from virtually zero in 2013 to 36,500 by 2017,” resulting in a proliferation of waiting drivers and empty seats.

To discourage idle driving and unnecessary trips, Fix NYC calls for a surcharge on all for-hire vehicles in Manhattan’s central business district, starting in 2018. (Chicago has already implemented a similar charge.) After a 10-month period allowing companies to install the appropriate GPS technology, all taxis, Ubers, Lyfts, and other on-demand vehicles could be subject to a fee ranging from $2 to $5, depending on location, time, and day of the week.

The report’s emphasis of this phase of the plan is noteworthy. Taxing ride-hailing firms could be a big moneymaker for the needy buses and trains of the MTA. With the number of these vehicles on the road, the annual surcharge revenues could range from $155 million to $605 million. “This is the growth industry which we can get revenue from,” said Mitchell Moss, a professor of urban policy and planning at NYU who served on the Fix NYC panel.

That’s a big difference from 2008, the last time the city pushed a fee-based traffic-taming plan. A decade ago, the iPhone had only been out for a year and Uber was merely a pitch deck. It would be three more years before Uber launched in San Francisco and revolutionized urban mobility, for good and ill. Indeed, in 2008, the number of cars crossing into Manhattan from outer boroughs was peaking; it has since declined. Now, the intense growth is found in the number of vehicles within the core of Manhattan.

Taxing those for-hire vehicles may not reduce congestion by much, according to Schaller. Wealthier riders who are opting for the ease and comfort of Uber and Lyft over the hassle and uncertainty of New York City transit might not be sensitive enough to price. Rather, the surcharge “should be aimed at raising as much revenue as possible,” said Schaller.

Phase Three: Price the Roads

At peak travel times, the number of cars on urban roads and highways will always rise to meet maximum capacity—that’s the law of congestion. Building public transit can only mitigate, not reduce, the crushing demand for road space. Half a century of transportation research, as well as case studies in Stockholm, London, Singapore, and beyond show that there’s only one way to reduce congestion: charging people to drive.

Per the recommendations of the Fix NYC panel, driving into the heart of Manhattan at the busiest times of day should cost something. One idea that the report throws out is a daily charge that’s roughly double a one-way Port Authority bridge toll, which would be $11.52 for cars and $25.34 for trucks. The revenue, which would go to the MTA, would be considerable, as would the traffic benefits. The report estimates that such charges would raise something on the order of $800 million each year, reduce the number of cars entering the city center between 6 a.m. and 8 p.m. by 13 percent, and increase average traffic speeds by 9 percent.

The panel recommends that this final phase of “zone pricing” start in 2020. The question is, can it pass political muster? Previous attempts by Mayor Bloomberg to charge drivers for entering the busiest parts of the city failed in the state legislature—members from the outer boroughs and suburbs were not onboard with taxing car commuters. The Fix NYC plan is sure to face similar concerns from state representatives in some of the same areas. “It’s an uphill climb every time,” said Schaller.

Congestion-pricing advocates also have a big problem that Bloomberg-era boosters didn’t: The current mayor isn’t on their side. Bill de Blasio opposes the idea, on the grounds that it would be burdensome to lower-income drivers. The response from the pro-charge crowd is that the current costs of congestion are disproportionately borne by poorer New Yorkers, who also depend on the mass transit that a congestion fee would help fix.

With the MTA desperate for revenue and the effects of Uber and Lyft vehicles being felt on the road, a surcharge on for-hire vehicles would likely be an easier sell in the statehouse than zone pricing. But as the city’s traffic crisis came to a head this past year, congestion pricing’s status has risen from wonkish footnote to actual public discourse. (Below, a graffitied cri de coeur sighted by a friend in a New York City bathroom.)

Apparently even NYC’s bar toilets want in on congestion pricing. (📸: @AsherFreeman718) pic.twitter.com/9GCAzLX9Z4

The Fix NYC plan is only the start of a political process; the state legislature must debate and approve the details before any of its contents become law. There is no precedent for a true congestion-pricing scheme in the U.S., and the idea has failed in New York City before. But this time, the political calculus is different, and the pressure is overwhelming.

This post appears courtesy of CityLab.



Medicaid, housing subsidies, the Supplemental Nutrition Assistance Program—these are some of the things that make up the backbone of the U.S.’s social safety net. And the federal government, guided by President Trump’s proposed budget for 2019, is seeking to make deep cuts to all three of them.

Yet while this threatens the government’s social safety net, one of a different kind continues to expand. Americans are flooding into the country’s blood-plasma donation centers in greater numbers than ever before, seeking to make up for low wages or small benefits checks, or even as their only source of cash income during a spell of extreme poverty. Their blood plasma—which historically has been collected disproportionately in the country’s poorest communities—is fueling a multibillion-dollar worldwide industry.

Blood plasma, being a vital component of certain medical treatments, is extremely valuable, and there’s not much standing in the way of American adults who want to make some money off of what’s in their veins—so long as they weigh more than 110 pounds and are in good health. A standard visit lasts 90 minutes and usually pays between $30 and $50. Unlike other countries that ban giving plasma more than once a week or limit the number of sales in a year out of concerns for donors’ health, the U.S. permits up to two plasma donations a week, every week.

This can translate into a few hundred dollars a month—a significant sum to people who have few or no other sources of income. In 2015, one of us wrote an article for The Atlantic about people who sell their plasma to make ends meet, and other journalists have focused on them as well. But what’s gotten much less attention is the global, multibillion-dollar industry these donors are sustaining. It’s an industry that helps heal patients worldwide, but it’s also one that, to keep the blood flowing, depends on the existence of a large group of people desperate for cash.

There is a thriving industry built on plasma because the substance has no substitute in medical treatments for certain rare conditions, such as antibody deficiencies and hemophilia. As one company explained in an annual report, plasma comes from “the perfect bioreactor developed over millions of years of evolution: the human body.” In addition, many treatments are so plasma-intensive that they collectively require millions of liters of it each year; a year’s worth of therapy for someone with hemophilia might require the yield of as many as 1,200 donations. So, not only is there no substitute for plasma, but enormous volumes of it are needed. On top of that, global demand for it has steadily risen as many countries’ populations age and need more treatments that require plasma.

This all has been a boon for the industry. Over a decade, the number of donations—really, “sales” is a more accurate noun—in America tripled, from 12 million per year in 2006 to 38 million per year in 2016, according to the Plasma Protein Therapeutics Association, a trade group. The number of donation centers in the U.S. has more than doubled to meet demand, from fewer than 300 sites in 2005 to over 600 today. Global sales jumped from $5 billion in 2000 to $20 billion in 2015, and are expected to keep growing at a rapid clip well into the next decade.

The Number of Annual Plasma Donations in the U.S., from 1999 to 2016

Because plasma can be a medical necessity, companies that collect it tend to wield significant pricing power. These days, a liter of plasma that costs a company about $150 to collect and process could sell for in the neighborhood of $500—a substantial markup in any industry.

Because there are high barriers to entering the industry—it’s not easy for an entrepreneur to just up and start a medically sensitive operation—a few international companies command a large chunk of the market share and keep profits high. The industry thrives in the U.S. in particular because the country allows compensation of donors (many countries do not) and has some of the least restrictive plasma regulations in the world. In the United States, a person can donate up to 104 times a year, while in much of Europe, donors are limited to 45 times in a year. Little is known about the long-term health consequences of chronic donation, although a few years ago, Darryl Wellington wrote in The Atlantic about some of the effects he and some other “plassers” experienced, including extreme fatigue and blacking out.

The big firms in the industry include Grifols, CSL, and Octapharma, all three for which plasma makes up a substantial portion of revenues, and Shire, a bigger, more diversified biomedical company. America is very important to these companies’ continued success and growth: As the world’s largest plasma producer, the U.S. supplies 70 percent of the world’s plasma, but accounts for only 40 percent of global demand.

And production is ramping up. Grifols, for instance, plans to expand to 225 donation centers in the coming years, up from 171 in 2016 and just 80 in 2010. The company’s revenues increased sixfold between 2006 and 2016, a period during which other companies saw similar growth; as of 2015, Grifols said it was collecting 26,000 donations a day worldwide, with a majority of its centers in the U.S. The company controlled about one-fifth of the market for plasma therapies in 2016. (More recent figures aren’t publicly available, as Grifols has been less forthcoming in later annual reports.)

Octapharma, another leader in the industry, announced its intention in 2015 to double its plasma output over four years. At the time, the company said it was putting 400 million euros (nearly $500 million U.S. dollars) toward this goal. (Octapharma didn’t respond to a request asking whether its expansion is on track.) And in 2013, Bain Capital got into the business, taking over a company called Plasma Resources UK, the plasma supplier for the U.K.’s National Health Service. Then a few years later, Bain sold the service to a Chinese investment group, making a considerable profit.

When contacted for this article, Shire noted the medical importance of plasma treatments but declined to go into much detail about the workings of the industry. Neither Grifols nor CSL responded to a request for comment, and Octapharma referred us to the Plasma Protein Therapeutics Association, a trade group, which in turn said it could not comment on the business prospects or donor-compensation practices of its member companies.

These companies’ expansion plans are not just a bet on the ongoing necessity of plasma, but also that there will continue to be plenty of potential donors who could really use the extra money. While there are altruistic reasons for donating blood—CSL Plasma’s website frames the act as something that will “help people around the world live healthier, happier lives”—the industry’s success is undergirded by the consistently high number of people who simply need cash, particularly in the United States.

This makes the ethics of plasma donations tricky. While it’s disturbing that cash-strapped Americans feel forced to monetize their bodily fluids, donations represent an income source that many couldn’t stand to lose. Selling plasma is probably preferable to other survival strategies that may be riskier (or less legal), though it’s worth noting how little long-term evidence there is about the health risks of frequent donation. At the very least, considering the strength and prospects of the industry, donors could stand to receive a bigger share of the revenue generated by plasma sales—few, if any, donors could ever dream of affording the treatment that they make possible for others. (No major plasma-collecting company mentioned in this article would discuss this moral dimension of plasma donations.)

It does seem there is a place for compensated plasma donation in the U.S., in some form—it is not inherently morally objectionable. But what’s concerning is the extent to which many “voluntary” donations are anything but, with people depending on them in the absence of an adequate social safety net. And as that social safety net gets weaker, the plasma industry is only getting stronger.



“The spring of investment has come,” declares a banner hanging over Zhongguancun Inno Way, a pedestrian walkway tucked behind the high-rise superstores of Beijing’s high-tech electronics zone in the city’s northwest. Twenty-somethings bustle by clutching coffee and take-out KFC, only the tops of their heads visible as they bury their attention in Chinese-made smartphones. Now the alley—whose Chinese name translates roughly as “Entrepreneurship Street”—is saturated with co-working spaces, cafés, and start-up accelerators.

Inside Garage Café, a dark space on Inno Way filled with bleary-eyed entrepreneurs hunched over laptops, I meet 27-year-old Tian Yang. Tian studied at Sydney University, then worked for two years at the Chinese computer company Lenovo. But he found the job “dry and dull, all the same, everyone on the same track, very boring.” Now he is building a social-networking app that uses facial recognition to connect people who look alike. (I asked what people were meant to talk about once they’re connected, but he hasn’t figured that part out yet.) “I’m not married, there’s no big pressure yet,” he said, “so I can try this for a year.” Other start-ups in incubation at Garage Café include an online-video education site—a growing field—and a consulting service for Chinese people looking to settle abroad, called “Ten Thousand Countries.” At lunchtime there’s a show-and-tell session for new arrivals, and the café organizes meet-ups with investors. A floor-to-ceiling bulletin board is covered with advertisements for coders.

China’s booming start-up scene has become as much a feature of its top-tier cities as traffic and smog. It used to be that college graduates applied for jobs at banks or state-owned enterprises, the proverbial “iron rice bowl” that their parents sought for them after the chaos of the Cultural Revolution. But many of those jobs were unsatisfying: In a 2012 Gallup survey, 94 percent of Chinese respondents said they were unengaged with their jobs. Now, with public and private funding flowing into Chinese start-ups, entrepreneurship has become an appealing alternative for a generation disillusioned with the conveyor-belt career paths of their forebears.

There are plenty of homegrown success stories to inspire them. Where Chinese youth once worshipped at the altar of Steve Jobs, now they look to emulate Jack Ma, Robin Li, and Lei Jun, the founders of e-commerce firm Alibaba, the search engine Baidu, and the phone manufacturer Xiaomi. Alibaba’s IPO in the United States in 2014 was the biggest in history, raising $25 billion, and Xiaomi just filed its own IPO in Hong Kong, which is expected to raise $10 billion.

The tech revolution in China is ubiquitous in urban life. I use the messaging app WeChat for work calls and vacation bookings. I pay for a cup of coffee or a ride in a car with a scanned QR code on my phone. I go to work at a rented desk in an “experimental life space” called 5Lmeet, built in an old soy-sauce factory, which offers pop-up cuisine, a cashless, staffless convenience store, and an office space, the entrance gate to which uses face-recognition software to let me in. Every time I come out of a subway stop in Beijing, I have to fight through a mass of the cheap, rentable bicycles that have transformed transportation in the city. Dai Wei, the CEO of the leading bike-rental firm, Ofo—reportedly valued at $2 billion—is 27 years old.

In years past, Chinese companies have faced accusations that, rather than coming up with new inventions, they’re simply copycatting U.S.-made technologies for Chinese consumers—a trope that has made it onto the current season of Silicon Valley. As the progenitor of the so-called “four great inventions” (the compass, gunpowder, papermaking, and printing), China has now claimed “four great new inventions”—shared bikes, e-commerce, mobile payment, and high-speed rail. The simplest of fact-checks reveals that none of those originated in China, though they were certainly popularized here.

But China has begun fostering a more creative entrepreneurial culture. In 2015, Premier Li Keqiang unveiled a plan, known as “Made in China 2025,” to update the country’s economy by investing in advanced industries, through subsidies, low-interest loans and other aid for Chinese companies. Within the next decade, China wants to be the world leader in robotics, artificial intelligence, and clean-energy cars, among other fields. President Xi Jinping’s consolidation of power—most recently with the abolishing of presidential term limits—means that policy can reshape economy through a level of top-down control that democracies cannot emulate.

Chinese leaders are looking to young entrepreneurs to spearhead the transformation. It helps that much the world’s hardware, such as smartphones and computers, is already made domestically, with many key parts produced in the southern factory metropolis of Shenzhen. Also supporting China’s strength is an influx of venture capital into Chinese start-ups, from both home and abroad, and from private investments by rich Chinese individuals who lack safer options given China’s volatile stock market and restrictions on investments in housing. Last year, Chinese-led funding accounted for nearly a quarter of worldwide venture capital, a 15-fold increase from 2013, with most of the investment going to Chinese companies, according to a recent Wall Street Journal analysis. During that period, U.S.-led funding doubled.

It’s now becoming clear that, in many respects, China has distinct advantages over Silicon Valley as it hopes to become the next nexus for innovation. Ma, of Alibaba, has praised China’s stable government and long-term support of innovative industries as good for business. When Mark Zuckerberg testified to Congress last month, one of his notes captured on camera by the Associated Press revealed his argument that Chinese tech companies pose a threat to American competitiveness: “Break Up FB? U.S. tech companies key asset for America; break up strengthens Chinese companies,” the document read.

It’s not inevitable that the kids of Garage Café are about to eclipse their peers in the WeWorks of San Francisco and Seattle. Bureaucratic red tape and poor intellectual-property law still make it difficult for Chinese businesses to get off the ground and protect their product from copycats. The Chinese government’s power over companies is a double-edged sword, allowing it to censor or shut down any start-up that gets too close to sensitive topics, as happened in April when the state agency responsible for media censorship temporarily banned the news app Jinri Toutiao for “broadcasting programs opposed to social morality.” And while the government has nurtured tech companies by handpicking individual ones as the stars of given industries (Baidu for self-driving cars, Alibaba for high-tech city infrastructure, Ofo for dockless shared bikes), that level of granular control could prevent more organic ideas from coming to fruition within competitive markets. Meanwhile, a burgeoning trade war with the United States could stymie Made in China 2025 by imposing tariffs on the high-tech manufacturing industries that China seeks to bolster.

None of this seems to have dampened the optimism of the Garage Café crowd. Kaiser Kuo, the host of the Sinica Podcast and the former director of international communications at Baidu, says, “There’s no question that China is now very much in the same league as the United States” when it comes to innovation, hardware, and capital flow. Tian Yang, the facial-recognition whiz-kid, described the flood of investment more bluntly: “All you need is an idea, and they will give you money.”



Welcome to what is poised to be—by most counts—the longest bull market on record in the United States.

For roughly 3,453 days the S&P 500 has been on a mostly steady upward trajectory. To many, these prolonged gains are unambiguously good news, particularly when combined with an economy that is strong and stable—which this one is. The market rally has resulted in gains of more than 300 percent and trillions of dollars for investors since the nadir of the Great Recession nine and a half years ago.

How did we get here? There are some who will undoubtedly thank the president. And it’s true that in the wake of the election, the markets enjoyed what was then dubbed the “Trump Bump” as many investors presumed that a corporation-friendly administration would help profits. But this rally started long before Donald Trump’s name was even seriously mentioned in the political arena.

The market started climbing in 2009, right after the country felt the worst losses of the recession. Part of the reason this market run has lasted so long is because the initial recovery from the recession was so slow and the losses were so significant. Those long, plodding years trying to recoup the losses of the Great Recession count toward this bull market, too. The current bull cycle was borne of prolonged quantitative easing, suppressed interest rates, and escalated stock buybacks, among other techniques used by the government and corporations to help markets recover.

This rally has weathered political uncertainty, a surprising presidential election, a pseudo–trade war, a barrage of potentially market-moving tweets, and several sizable drops. Skeptics who have tried to pronounce the death knell of this rally have been proven wrong again and again as the stock market continues to shake off bad news and climb to new highs.

But that won’t always be the case. Those celebrating this historic rally should remember that the sheer duration of a bull market doesn’t guarantee economic health. In fact, some experts worry that the longevity of the market rally is actually cause for concern: If this is the peak, a crash could be on the way. It’s also worth noting that while historic streaks can provide clues to what’s happening in the market more broadly, actual bull and bear markets, and recessions, are determined retroactively, not in the moment. And across the financial sector, analysts can often measure highs, lows, and other market highlights in myriad ways. All of that means that putting this particular moment in context is especially hard while it’s still happening.

For now, most of Wall Street is celebrating: Given the low unemployment rate, some moderate wage growth, and the fact that the economy is expanding, it’s not likely that the country will be plunged into a recession tomorrow. That means that by most accounting, this rally is the most significant since the one that preceded it, when the market rose steadily for most of the 1990s— during the dot-com boom. It’s nearly impossible to say when, but eventually this bull market will end the way most have in the past—with a downturn.



On Wednesday, the U.S. government ordered the grounding of Boeing’s 737 Max airplanes, following similar mandates in the preceding days by dozens of countries after a crash of one such plane in Ethiopia. The hundreds of 737 Max planes previously in service worldwide are all currently grounded.

In many other industries, when a product has a flaw, companies can rely on a range of workarounds, such as other suppliers who can rise to fill the need, or other products that can be subbed in quickly. But because of the airline industry’s peculiarities—from the importance of airlines’ in-advance flight-traffic projections to the extraordinary cost of a single plane—this temporary ban could have far-reaching, hard-to-contain effects.

The grounding will likely hurt Boeing, whose shares are down after the Ethiopian Airlines crash and whose sales might take a hit. It will likely hurt airlines, which now have fewer seats with which to shuttle customers around the country and the world. And it will likely hurt passengers, who might have to adjust their schedule and, in some cases, their spending. But most notable is the scale of it all: Depending on the duration of the grounding, it could cost all involved parties billions of dollars.

Start with Boeing. The price of the company’s stock fell more than 10 percent, which represented nearly $30 billion of the company’s market value, in the days after the crash. One of investors’ worries is that the reputation of the 737 Max—which was also involved in a crash last fall in Indonesia—is now tarnished to the point that it will hurt demand for the plane. This is no small concern: The 737 Max, a jet that costs more than $100 million, is Boeing’s all-time best-selling aircraft, and the company is lined up to sell several thousand more. If airlines cancel their orders, Boeing would stand to lose billions of dollars. (The company did not respond to an interview request.)

Volodymyr Bilotkach, an economist at Newcastle University and the author of The Economics of Airlines, says that if cancellations do materialize, Boeing likely doesn’t have a great Plan B, but neither does anyone else. The airplane-building industry, he says, is an “effective duopoly,” meaning it’s dominated by two suppliers: “There is no way Airbus”—the other half of the duopoly—“will be able to come to the rescue, as that manufacturer’s order book is also not empty.” Indeed, one analyst who follows Boeing closely told Bloomberg earlier this week that his firm didn’t see “meaningful long-term risk” for the company. (Bilotkach says it’s possible that instead of taking their business elsewhere, some airlines might opt for older Boeing-made models with safer records.)

Airlines—Boeing’s customers—are not in a great position either. The primary challenge in the industry, says Clifford Winston, an economist at the nonpartisan Brookings Institution, is how far in advance airlines have to decide how large their fleet should be at any given time. “A plane takes a long time to make,” he says—sometimes a year or longer, and even buying used planes can take a while. Airlines’ task, in essence, is to guess how many people want to go from, say, Nashville to Denver on this day next year, and then buy a bunch of elaborate, $100 million metal contraptions accordingly.

Because airlines’ fleets are assembled according to long-term projections, they might have trouble adapting quickly to events that hurt demand, such as recessions or terrorist attacks.“That’s when they lose a ton of money,” Winston says.

Grounding a certain model of plane, while it affects the supply of (not the demand for) seats, can have a similar effect. Planes are such a big investment that once an airline buys one, it wants to put it to use as much as possible, which means, Winston says, “it’s not like they have a bunch lying around” for situations like this. Basically, airlines are now stuck making the most of what they already have.

Southwest Airlines, for example, is grounding its 34 Max 8 planes, which it says accounts for fewer than 5 percent of its daily flights, and relying on “every available aircraft in our fleet” to carry out its operations. Fewer than 5 percent might seem small, but it can interfere with the delicate capacity-demand calculus that airlines perform months or years in advance. Because the duration of the grounding is unknown, it’s hard to say exactly what damage it will do, but Winston estimates that if the 737 Max planes stay out of service for months, the losses to the industry and passengers “could run in the billions of dollars.” If the grounding ends much sooner, the losses will probably be much smaller. (Southwest told me that it doesn’t comment on financial estimates outside its official earnings updates.)

Southwest isn’t the only U.S. airline with 737 Max planes. American Airlines has pulled its 24 Max 8 planes out of service, which affects about 85 flights out of the airline’s roughly 6,700 daily trips, and United has grounded 14 Max 9 planes (a similar model), which together account for some 40 flights a day.

Winston says that this shortage of capacity draws attention to another quirk of airline economics: Only American carriers are allowed to fly trips starting and ending in the U.S. He’s in favor of extending what are called “cabotage rights” to overseas airlines, one benefit of which would be that they could provide more seats in situations like this, after a surprise reduction in capacity.

Where does all this leave passengers? Winston expects to see airlines cancel some flights and perhaps raise the prices of others to compensate for the lost revenue. That means some passengers might end up spending more to get where they need to go on their preferred timeline; others might just have to be flexible on their departure time, consider another mode of transit, or not go at all.

At this point, it’s not clear how long the grounding will last, and while it is terrible publicity for Boeing, some plane manufacturers have managed to fare all right after their new aircraft has come under scrutiny. George Hoffer, a transportation economist, pointed out to me that the Douglas DC-6 and the Boeing 727 both went on to have “stellar” careers after early incidents. So the 737 Max could yet recover—it just might get rebranded. “My guess is that they will eventually … drop the Max” from its name, Hoffer said. Though the true mark of success would be for the plane’s name to go back to where it was: out of the headlines and mostly unknown to passengers.



When there’s a charitable or political cause, there’s often a celebrity who has taken it up. Elizabeth Taylor was a tireless campaigner to fight AIDS. More recently, Mark Ruffalo has used his fame to try to stop fracking, and Angelina Jolie has advocated on behalf of refugees. Appearance matters: When well-known people attempt use their prominence for good, it can elevate a cause in a way that money or grassroots activism can’t always muster.

How did it come to be natural for celebrities to lend such support? And when was it proven that a famous face could help make a movement successful? According to Johanna Neuman, a former reporter for the Los Angeles Times, it goes back to the women’s suffrage movement. In researching her recent book, Gilded Suffragists: The New York Socialites Who Fought for Women’s Right to Vote, Neuman dug through archives and discovered that the decades-long battle to pass the 19th Amendment wasn’t all Susan B. Anthony and Elizabeth Cady Stanton and Carrie Chapman Catt: There was also a vital assist from a generation of New York socialites who both funded the movement and lent their celebrity to the cause at a time when it needed the attention.

These women were celebrities—the Kim Kardashians of their day—but are now remembered by few. I spoke with Neuman recently, and asked her how the story of these all-but-forgotten women can illuminate the relationship between traditional activists and the donors they need to accomplish their work. The conversation that follows has been edited for length and clarity.

Helaine Olen: When did you realize these women were worthy of a book?

Johanna Neuman: I knew immediately. They were the media celebrities of their day. They’re the wives and daughters of the Gilded Age, and what was so striking to me is that these uber-wealthy women didn’t have to do anything: Their social standing was firm, they were all listed in the Social Register. They chose to get involved in politics. They chose to leverage their social standing for political gains. And to me this made them so compelling.

Olen: So if they were originally socialites, how did they get their start in the suffragist movement?

Neuman: The first generation of the gilded suffragists comes around 1894, when the state of New York is considering a constitutional amendment to include women’s rights. And Susan B. Anthony comes to five women of substance and money and she asks them for a donation, so that she can fund the canvassing that’s required to produce a huge petition. And they say no. It’s not that they don’t want to give their money to the cause—it’s that they also want to give their time. It’s the moment when they come into their own. They have something to say.

Olen: Why did they think they should take over the cause of longtime activists?

Neuman: These women were executives. They ran staffs. They were in charge of huge mansions. They directed architects and builders and decorators. They were accustomed to running things, and when they got into suffrage, they really for the most part were not interested in joining the other organizations. They had the money and they had the experience to run their own organizations. And also they were accustomed to seeing their names in the paper and they wanted that too.

The understanding that suffrage could be sold to the public had been missing from the movement. The understanding that it had to be branded and packaged like a consumer good is something they brought. It’s an understanding that appearance matters.

These women were expanding the circle of people who paid attention—they were reaching out to people who were indifferent to the topic, who hadn’t considered it before. If you think about Angelina Jolie becoming a special envoy for the United Nations, for refugees, it gives that cause a spring in its step. People notice it, people take notice of it, and people get involved in it. So the book is also a meditation on celebrity endorsement.

Olen: When these women, with their money and celebrity, established their presence, how much tension did this lead to in the existing movement to get women the right to vote?

Neuman: “Considerable” is the only real answer, right? The movement had been peopled by middle-class, civically minded women for a long, long time. And they resented all the attention these women were getting in the press.

Olen: This brings us to Alva Vanderbilt Belmont. If she’s remembered today at all, it’s for forcing her daughter Consuelo to marry into the British aristocracy, something few of us today would view as acceptable gender politics. But your book reveals that she was very deliberately recruited into the suffragist movement.

Neuman: The head of the National Woman Suffrage Association, Anna Howard Shaw, thinks Alva could be a source of money. And so she recruits her to be a delegate to an international conference on women’s suffrage. It electrifies Alva. She has some ideas, and she uses her money, her standing, and her position.

The first thing Alva does is open the gates of her summer home, Marble House, in Newport, to the public for the first time, with all proceeds benefiting the organization, and it just commands enormous attention. She gives speeches and she launches herself as a figure in the movement. She comes in at the top. And I suppose this should not surprise us. Right? Because that’s where these women were accustomed to being.

But some people were very angry when Alva Belmont forced the National American Woman Suffrage Association to move its headquarters to New York from Ohio. She had the money to say, “I will pay your rent for a year. I will pay the salary of a press agent for a year.” For an organization that’s strong in numbers but often poor, this is a no-brainer. But a lot of people resented it.

Olen: But she ultimately leaves the organization, right?

Neuman: Yes, after a couple of years, she is frustrated by it. She is willing to give buckets of money, but she wants action and she’s tired of the plodding and the cautiousness and the infighting that's hobbling this organization. So Alva is recruited by Alice Paul, the head of the Congressional Union for Woman Suffrage. Alice Paul is young and more radical than the more traditional suffragists. Alva is interested in funding her, provided she gets a leadership role.

Olen: You mentioned Angelina Jolie earlier. How are women like Belmont similar to today’s celebrities?

Neuman: Well, I mentioned her because I thought it would help people understand that celebrity endorsement is not just a stamp, or a name, but these women, I suppose I would say, were the first to stand with the cause as political actors.

What was fascinating about these women is that they were the first to not just put their money behind a political cause. Traditional philanthropy for wealthy women was to help a hospital or school. The gilded suffragists, they used their money for politics but they also stood with politics. They wanted to organize. They wanted to rally. They wanted to march in the streets.

Before these women entered the political landscape, the campaign to win women the right to vote was in the doldrums. Events were not well attended. Tired conventions that attracted the same crowd every year featured familiar refrains to a chorus of the already converted.

Then imagine the impact these fashionable, feminine, prominent socialites had on the debate. With their social standing, they gave cover to activists—both male and female—who wanted to join but had been reluctant to face ridicule from colleagues or neighbors. With the enormous publicity they received, they brought excitement to a campaign that had been withering.

How often have celebrities today given cover to the reluctant to join a cause, or forced the press to at least give a modicum of respect to an issue? In giving their blessings to a cause that was controversial, these women ensured that suffrage would be treated seriously.

Olen: So, after all this work, the 19th Amendment passes, and these women are soon forgotten, despite the fact that their money and efforts helped make it possible. Why?

Neuman: I think there are two possible explanations. One is that there is a lot of score-settling by suffrage leaders who resented them and left them out of their memoirs. Carrie Chapman Catt did not mention Alva anywhere in her memoirs and Alva supported her organization for a number of years.

Second, when it comes to philanthropy and philanthropists, I think it’s easy to dismiss the wealthy. Many commentators certainly did dismiss these women. They said of them that they were just indulging in suffrage as they would the latest fashion—that they didn’t take seriously. I think that is the risk of money, the risk of philanthropy. You can contribute financially to a cause and nobody really wants you to get involved. These women sort of insisted on it.



Despite Donald Trump’s “America first” rhetoric, many suspected that the tax plan he would support would actually increase the incentives for U.S. multinationals to move both profits and operations overseas. I wrote about this inevitability a few weeks ago, before the details of the Trump-GOP tax plan emerged.

Now that the bill is advancing, it’s clear that things aren’t as bad as many feared. They’re worse.

As discussed in the previous piece, Trump administration economic officials argue that by lowering the corporate tax rate from 35 percent to 20 percent and moving to what is called a territorial system—mainly, companies pay taxes on foreign earnings only to the foreign nation where those profits are booked and never owe anything to the U.S. no matter how low the foreign nation’s tax rate is—would lead to more jobs and profits staying in or coming back to the United States.

Yet, it is clear that a territorial system could have just the opposite impact: It could give a permanent preference to foreign income and lead companies to shift more profits to tax havens knowing that they could permanently avoid virtually all taxation on such profits. One crucial safeguard against that perverse impact is to apply a strong minimum tax on the profits of U.S. multinationals in each country (a “country-by-country” minimum tax). If a U.S. company had to pay a minimum tax of, let’s say, 19 percent (as President Obama had proposed), even if they engaged in complex tax planning to book $100 million in profits in zero-tax Bermuda, they would have to pay $19 million in U.S. taxes to ensure the 19 percent minimum tax was enforced. Under such a country-by-country minimum tax, you can run, you can shift profits to tax havens, but you cannot hide from paying a 19 percent minimum no matter where you are. Under this type of true minimum tax on foreign earnings, U.S. multinationals would have little incentive to engage in the ongoing race to the bottom.

As discussed in my previous Atlantic piece, the GOP plan was rumored to use only a 10 percent minimum tax, and to make it worse, would make the minimum tax determination based on the average of a company’s total global profits. What was problematic about this design was that it not only encouraged companies to move profits to tax havens, but it actually encouraged them to simultaneously move jobs and operations such as manufacturing to industrialized countries that had typical tax rates and to shift more profits to tax havens. Why? Because if you had $100 million of profits in Bermuda facing no tax, you might have still had to pay $10 million in U.S. taxes to meet the new global minimum tax. But if you moved a factory to Germany that made $100 million and paid 20 percent in taxes there, you could still pay zero on your profits in Bermuda because the average taxes paid on your global profits (from both Bermuda and Germany) would be the global minimum rate of 10 percent. This perverse design means the more a U.S. multinational shifts jobs and operations to industrialized nations with similar tax rates to the U.S., the more it can get away with shifting more and more profits to tax havens.

So how did it look in the fine print? As several tax experts including the Tax Policy Center’s Steve Rosenthal, Brooklyn Law School’s Rebecca Kysar, and Reed College’s Kimberly Clausing have written, it is even worse than anticipated on at least two additional grounds. First, it turns out that the Republican idea of a minimum tax is that it only taxes what you make over what they think is a “routine” profit, deemed to be 10 percent in the Senate bill, on “tangible” investments (think factories and equipment, including for manufacturing). As Rosenthal notes, “because ‘routine’ returns are not subject to U.S. tax, this definition of ‘routine’ returns could give U.S. firms a perverse incentive to shift more tangible assets to lower-taxed overseas locations.” That means, under the GOP bills, if you shift less profitable operations to a tax haven you would pay zero taxes on those operations as long as you are only making 10 percent a year—whether that is $10 million or $100 million—while you would pay 20 percent if the operations were located in the United States. So, the “minimum” tax is really a much lower rate than 10 percent, and would essentially be an invisible, non-existent tax except on highly profitable operations and income from intangibles.  

Second, this limitation to only excess profits encourages even more shifting of operations and jobs overseas through complex efforts to blend different income streams. How? Profits from “intangibles” like patents do not receive the 10 percent exemption for “routine” returns, so the minimum tax is seemingly designed to at least capture those well-known cases where major technology companies shift intangibles to low-tax nations and book their profits there. If a company does that and earns extraordinary profits, a global minimum tax would capture some piece of that. But again, here is where the GOP bill’s global “averaging” actually creates the incentives to move jobs and operations overseas.

Let’s say a U.S. multinational has highly profitable intangibles located in a tax haven that earn $50 million in income without any tangible investment. If the company has no other foreign profits or operations, then that income would face a mere $5 million in U.S. taxes from the 10 percent minimum tax under the GOP plan.  But if the company decides to build a new $1 billion factory overseas that earns profits of only 5 percent ($50 million) from the factory, the company will not pay a penny in U.S. taxes on its income from the factory or the intangibles. Why? Because when you add the income together, the $50 million from the intangibles plus the $50 million from the new factory,  it equals the “routine” profit of 10 percent on the $1 billion of new tangible investment, which will allow it to completely avoid paying taxes on any of the above mentioned profits.

This shows how deeply the tax plan fails when it comes to incentives to shift profits and operations overseas and to curtail the obsession of major multinational companies with international tax arbitrage that has nothing to do with innovation, productivity or job creation. Indeed, the ability to blend income from intangibles and routine profits, and from investment in higher tax nations with tax havens with zero taxes, leads to a worst of all worlds scenario: an even greater corporate focus on international tax minimization through a careful mixture of shifting profits and operations overseas.

If there was one thing the GOP international tax bill was advertised to accomplish, it was that it would favor locating jobs and profits in the United States. It does just the opposite—expanding the degree our tax system tilts the playing field against American taxpayers and American workers.



Seattle is among the fastest-growing cities in the U.S., thanks largely to Amazon’s addition of 35,000 employees since 2010. For all the economic benefits that come with growth, it has also created a variety of civic headaches, traffic chief among them.

But thanks in part to efforts by the region’s largest employers, the share of commuters driving solo into downtown Seattle is on a dramatic decline. Just 25 percent of workers traveling into the city’s center drove themselves, according to the results of the latest annual commuter survey by the Seattle Department of Transportation (SDOT) and its nonprofit partner, Commute Seattle. This is the lowest share since the city started keeping track in 2010.

The number of cars is also trending downwards, according to responses collected from 1,784 downtown workers. While Seattle has gained about 60,000 jobs since 2010, there are approximately 4,500 fewer single-occupancy vehicles.

Share of Seattle’s Morning Commuters by Type of Transportation, 2010–2017

Overwhelmingly, new workers are choosing transit. The share of commuters headed downtown by bus or train shot up from 42 to 48 percent from 2010 to 2017, with about 127,000 such trips during the average morning rush hour.* Bus trips (as anyone who’s waited at a packed King County Metro stop on a weekday morning can attest) make up the vast majority of them.

Walking, biking, and carpooling also picked up by thousands of trips per day, according to the survey. Note, though, that ride-hailing services such as Uber and Lyft weren’t explicitly identified as options in the survey, which comes from a state document that hasn’t changed much since 1991. Respondents might have registered those trips as “drive alone,” “other,” or as “rideshare” (meaning carpool), but there is currently no way of telling. That could be a potentially significant caveat, considering that other transportation surveys in U.S. cities, including Seattle, find ride-hailing services to have a cannibalizing effect on transit. But Jonathan Hopkins, the executive director of Commute Seattle, said the scale of their impact seems to be pretty small in downtown Seattle specifically.

Seattle has been trying to cut back on car commuting in several ways. “We have to for the city to grow,” Hopkins said. As CityLab’s Andrew Small recently reported, the region has consistently invested in expanding transit service, with new light-rail stations, a revamped bus network, and a voter-approved transportation-benefit district sprinkling transit stops within a 10-minute walk to more city residents. Sound Transit 3, the $54 billion ballot measure that passed in 2016, promises to spread more light-rail much further.

In some ways, Seattle transit is a victim of its own success—bus-stop waits can drag on as packed bus after packed bus sails by; one rider recently likened boarding the C line to “being in Lord of the Flies.” But few other cities are confronting their transit problems with significant tax dollars as Seattle is.

Next are employers. SDOT and Commute Seattle work with 270 large companies around the region, including Microsoft, Expedia, and Amazon, to promote commuter-incentive programs and strategic relocations. And not out of the goodness of their corporate hearts: In Washington State, big employers have been mandated by law since 1991 to reduce solo commutes.

The Gates Foundation, for example, has gone from a “drive-alone” rate of 88 percent to 34 percent by distributing a suite of transit benefits to employees, including free Monorail punch cards and free monthly Zipcar hours. It also disincentivizes parking: The company lot charges a daily rate instead of a monthly rate. Weyerhauser, a real-estate investment trust and timber company, decreased its employee drive-alone rates from 82 percent to 9 percent largely by relocating from the suburbs to downtown, according to Hopkins. The construction of new downtown housing options has helped, too.

Amazon has also made strides to reduce its traffic footprint, chiefly through its downtown location. It offers subsidized transit passes, and like Microsoft, it runs a private shuttle option to ferry workers from their suburban homes to its downtown campus. Both companies (alongside Expedia, Costco, and Vulcan) also donated hundreds of thousands of dollars to the Sound Transit 3 campaign. And, arguably, Amazon’s impending expansion into a second home city may be the greatest traffic gift the company could deliver.

This post appears courtesy of CityLab.

* This article originally stated that commuters took 41,500 trips during the average morning rush hour. We regret the error.



In late October of this year, the office-sharing start-up WeWork announced that it was buying Lord & Taylor’s flagship store in New York City. Coming as this did in the wake of the bankruptcies of such long-established retailers as The Limited and Toys “R” Us, it was widely viewed as the latest harbinger of the “retail apocalypse.”

It isn’t just chain stores in economically distressed suburbs that are going belly up, but high-end luxury-goods purveyors along the retail corridors of America’s leading cities, such as New York’s Madison Avenue, Rodeo Drive in Beverly Hills, and Chicago’s Miracle Mile. All told, roughly 100,000 retail jobs were lost between October 2016 and April 2017. In the next five years, one out of every four malls is projected to close, according to an analysis by Credit Suisse. The square footage of America’s already dead malls covers more land than the city of Boston.

But painful as this retail retrenchment may be, it creates real opportunities that cities and suburbs can take advantage of.

First things first: Brick-and-mortar retail is not going away. Even as it sheds workers, the sector is still growing at a rate of 3 percent per year. The IHL Group, a research- and advisory-services firm, estimates that retail sales are up by more than $100 billion this year, and 4,000 more chain stores will have opened than closed in the U.S.

Much of the retail apocalypse is in fact a long-overdue correction. The United States devotes four times more of its real-estate square footage to retail, per capita, than Japan and France; six times more than England; nine times more than Italy; and 11 times more than Germany.

The way Americans shop is also undergoing a fundamental reset. As more and more people shop online, the stores that are drawing in customers are those that emphasize experiences. Customers want to sit on that new sofa, feel the weight of a stainless-steel skillet in their hands, and try out new gadgets.

In fact, the line between e-commerce and physical retail is not as traceable as most people think. The most successful virtual stores are currently increasing their physical presences. Amazon is opening up bookstores, and with its acquisition of Whole Foods, it has gained a footprint in hundreds of affluent cities and suburbs. As the physical embodiment of Apple’s brand proposition, Apple stores showcase cutting-edge designs, provide service and advice, build community, and are a big part of what differentiates the company from its competition.

While there can be no doubt that the lost jobs and diminished tax bases that accompany the retail retrenchment hurt, the shift has an upside as well.

WeWork’s takeover of Lord & Taylor could be a good portent for urban economies. Work, not shopping, is the key to urban productivity and growth. When asked why rents are so high in cities like New York and Chicago, the Nobel Prize–winning economist Robert Lucas famously answered that it had nothing to do with the availability of high-end shopping; higher urban rents, he said, are a function of higher urban productivity.

As talented people and high-paying jobs move back to cities, there is demand for more office space. Big companies like Google or Amazon can afford to build their own new facilities. But smaller companies and gig-economy workers need flexible coworking spaces that companies such as WeWork provide, and they need affordable living spaces as well. Both of these can be built in the shell of former retail spaces. In downtown Providence, Rhode Island, for instance, the Greek Revival Westminster Arcade, built in 1828 as the nation’s first indoor shopping mall, has been redeveloped to include dozens of micro-apartments.

The back-to-the-city movement is driven by the preferences of talented people for urban amenities, including places like mom-and-pop shops and small hardware stores that are increasingly threatened by skyrocketing rents that only big retail chains and luxury brands can afford to pay. However, as those companies scale back their retail, real-estate developers have an opportunity to refill their storefronts with independent, artisanal, and local shops. While property owners will take a hit on commercial rents, the overall value and desirability of their buildings will likely rise.

The problems confronting distressed suburbs and rural communities run much deeper than the retail blight that stands as a physical symbol of the economic crisis they face. Yet a striking number of such communities are developing innovative strategies to transform their empty malls and big-box stores, and the acres upon acres of asphalt parking lots around them, into more-productive assets for future growth.

Ellen Dunham-Jones of Georgia Tech is perhaps the world’s leading expert on the redevelopment of old suburban malls, and is the co-author, with June Williamson of the City University of New York, of the book Retrofitting Suburbia and a recent piece on re-inhabited malls. They have put together a database of more than 1,500 retrofits or redevelopments of abandoned malls, strip centers, big-box stores, and other similar developments across the United States. (Dunham-Jones and I recently described a few of the distinctive use cases that have emerged as these anachronistic retail spaces begin their second lives.)

Educational and health-care facilities are a logical fit for these large, boxy spaces, and are growing as retail shrinks. The former Hickory Hollow Mall in Antioch, Tennessee, was redeveloped as a satellite campus of Nashville State Community College as well as a practice rink for Nashville’s pro hockey team. The campus’s downsized mall now centers around a food market featuring immigrant businesses, one of a few ways these repurposed spaces better reflect local demographics.

The old Highland Mall in East Austin, Texas, is now occupied by Austin Community College, which built a high-tech math lab on the second floor of a former J.C. Penney and is building student housing in the parking lots. With a new light-rail stop, the area is becoming a hub for local employers.

Mall retrofits can also help with resilience and sustainability efforts. Dunham-Jones and Williamson estimate that 10 such projects have been transformed into green infrastructure or parks. The old 1960s-vintage mall in Meriden, Connecticut, which paved over a creek and contributed to chronic flooding, was demolished and transformed into a park that also serves as a catchment basin for stormwater runoff. The Northgate Mall outside Seattle saw a paved-over salmon stream restored, along with new subsidized housing for seniors.

Some of the most ambitious mall redevelopments are becoming mixed-use neighborhoods. The Villa Italia Mall in Lakewood, Colorado, outside Denver, was almost completely demolished to make way for a new street grid lined with offices, arts facilities, parks, and residences, as well as new stores. The project is already generating four times the tax revenues that the old mall did. In the Denver metro area, eight of 13 malls are currently in some stage of rehabilitation to more-productive uses.

These examples are just the beginning. Dunham-Jones and Williamson estimate that there as many as 650 mall retrofits in some phase of development across the country. From megachurches to indoor paintball parks, former malls and retail spaces are being converted to all manner of uses that better reflect the way locals live. Instead of bemoaning the (admittedly exaggerated) death of retail, it’s worth applauding efforts to turn old shopping centers and chain storefronts into more viable and productive community assets.

This post appears courtesy of CityLab.



Updated on November 30

Agony is the natural state of the news industry. Newspaper sales per capita peaked before color television was a thing, and magazines have been in decline since the Clinton administration. When it comes to the finances of the Fourth Estate, bad news is, generally speaking, the news.

But 2017 has been a uniquely miserable year in the media business, in which venerable publications and fledging sites, divided by audience age and editorial style, have been united in misery. At Vanity Fair, the editorial budget faces a 30 percent cut. At The New York Times, advertising revenue is down $20 million annually after nine months. Oath, the offspring of Yahoo and AOL’s union, is shedding more than 500 positions as it strains to fit inside of its Verizon conglomerate. Meanwhile, almost every digital publisher seems to be struggling, selling, or soliciting, whether it’s the media company IAC exploring offers to offload The Daily Beast, Fusion Media Group offering a minority stake in The Onion and former Gawker Media sites, or Mashable selling for a fifth of its former valuation. So many media companies in 2017 have reoriented their budgets around the production of videos that the so-called “pivot to video” has became an industry joke. Today, the pivot seems less like a business strategy and more like end-of-life estate planning.

Even the crown princes of digital upstarts, Vice and BuzzFeed, are projected to miss their revenue targets by 20 percent each, which amounts to a combined shortfall of hundreds of millions of dollars. Finally, this week, Time Inc., the storied publisher of magazines and websites, including People, Sports Illustrated, and Time, announced it had reached an agreement to be sold to the Meredith Corporation, whose focus on lifestyle is inspiring rumors that it may yet offload or even shut down Time, Fortune, and Money.

What on Earth is going on? There are at least three major trends contributing to this dismal media moment. They all point to the same solution, and it’s something everyone in journalism should know by now: News publishers have to get better at making money outside of advertising.

1. There are too many publishers and not enough ad money.

Here is the briefest possible history of attention and advertising in the 21st century—they have both flowed from desktops to mobile devices and from publishers to platforms. In 2016, 90 percent of websites reported that unique visitors on mobile devices had eclipsed desktop; and 90 percent of the growth in digital advertising came from just two companies, Google and Facebook.

Facebook and Google’s dominance stems from one of the great arbitrages in media history. Publishers still bear the cost of reporting, analyzing, and, well, publishing the news. Facebook and Google cinch the bloated web into the straitjacket of vertical content known as results pages and feeds. In the process, they collect unparalleled information about the interests and aspirations of their users and profit from their roles as digital gatekeepers. While some have compared Facebook and Google to cable companies distributing television shows, one difference is critical: TV distributors pay networks an “affiliate fee” for their entertainment, while Facebook and Google owe no such gratuity for the vast majority of its content. In 2017, Google and Facebook are projected to account for about 61 percent combined of the U.S. digital ad market. No other company comes even close.

This reality would be troubling even if online publishing were a static business. But employment in “internet publishing and broadcast,” the government’s best approximation for online media, has grown by more than 100,000 people in the last decade. As a result, there are too many writers and publications saying the exact same thing—oops, Josh Marshall at TPM already said that—competing for a limited supply of advertising. As a result, digital media’s appetite for ads has grown faster than the digital-ad pie.

This is not the same as saying that publishers should just give up on advertising. Without it, The Atlantic might not exist. Neither would most newspapers.* Advertising has been a critical feature of a healthy news business for at least 150 years, since Benjamin Day invented the penny press, and its centrality to the news business isn’t disappearing, just dissipating.

2. Media companies accepted VC money. Now they’re accepting VC reality.

In many ways, the 2017 correction in digital media is a perfectly normal and predictable outcome of digital media becoming an investment category for venture capitalists. As a rule, the vast majority of VC investments fail. So the failure of several VC-backed digital-media companies isn’t an existential shock so much as a mathematical inevitability.

In the last decade, venture-capital firms plowed money into new media companies like BuzzFeed, Vice, Vox, Axios, Mashable, Vocativ, Mic, Uproxx, and so many others, all of which essentially made versions of the same promise: “Trust us. We get Millennials.” And, in a way, many of them did “get” Millennials in the loosest sense of the word. While some of them used venture capital to build the foundation of a distinctive editorial voice or entertainment platform, others used it to produce the equivalent of content confetti—fast, flimsy, and forgettable morsels, blasted from the CMS cannon, which upon inspection were less journalism than Millennial Mad Libs: “[Number] Ways That [Google-Trend-Generated Subject] Totally Made Us [Past-Tense Verb].”

It’s easy to say that this is all Facebook and Google’s fault. But the truth is that many digital publishers ruined themselves. To impress venture capitalists with a story of scale, they chased viral trends and search-engine optimization to grow monthly visitor figures, optimizing for clicks (shallow traffic meant to generate ever-more ad revenue) at the expense of reporting, insight, or niche editorial identities. In any healthy market—for clothes, food, or furniture—competitors try to differentiate, by quality, convenience, or price, to compete directly for consumers’ income. But in the free-for-all of VC-subsidized ad-supported publishing, too many sites chased scale for the sake of scale alone, which led to the growth of insouciant meme merchants that, in feeding from the same trough of trending content, were inherently duplicatory. A massive correction was inevitable.

And now it’s here. Venture-capital funding for digital media has shrunk for two consecutive years, according to CB Insights, a VC database. Realizing that sites like Vocativ will never reliably reach audiences even one-tenth the size of platforms like Snapchat, investors will simply cut off funding and force sites to sell at a huge discount, like Mashable, or simply close. It won’t necessarily be “a full-blown crash,” as Marshall gloomily predicted. It will be a far more awkward landing, as several companies redefine themselves as video producers, then tech companies, then data-driven storytellers, before they run out of money.

3. Donald Trump is the Ghost of Christmas Future.

It’s advisable to resist the impulse to tie every observable trend on Earth to President Donald Trump. In this case, however, the effect is too obvious to ignore.

As the news cycle has concentrated around the polarizing president, many ad buyers have said they don’t want their name near any news story that involves him. (This is a difficult proposition when Trump inserts himself into previously nonpartisan topics, like the NFL). Some companies are simply refusing to spend money with publishers that specialize in hard news. Others participating in automated, or “programmatic,” advertising markets have stipulated that their ads cannot appear near any political content. As some premium advertisers abandon political news, ad rates fall and political news becomes a tough venture for media companies, even as traffic is soaring.

The president is the media equivalent of a toxic herbicide, whose very presence makes the ecosystem uninhabitable for advertisers. It’s created one of the paradoxes of the 2017 news cycle: Readership has increased within one of the least profitable categories of news.

But the Trump effect isn’t all negative for digital-media companies. Fear of and fascination with the president has supercharged an old-fashioned revenue source for news publishers—readers. Subscription revenue has been record growth at The New Yorker and The Washington Post. At The New York Times, revenue from digital-only subscriptions jumped 44 percent—or $75 million—in the first nine months of 2017, compared with the same period from last year. That’s three times larger than the $20 million of lost advertising revenue over the same period.

In short, President Trump has pulled forward the future of news by accelerating both the decline in digital advertising and the rise of reader subscriptions.

* * *

Whatever one wishes to call this media moment—a correction, a crash, an apocalypse— it is unevenly distributed. Doom is coming for companies that relied on an unlimited supply of VC money floating them until they cracked a nonexistent code to advertising. Something far less than doom is coming for companies that balanced cost and revenue while experimenting with various forms of direct advertising, events, subscriptions, and memberships. And something almost like success has come for companies that have used the instability of the 2017 news cycle to establish themselves as vital and irreplaceable.

Advertising has been critical to the affordable distribution of news for a century and a half in the U.S. Today’s media companies don’t have to reach all the way back to the early 1800s for a business plan, to when newspapers were an elite product, selling at the prohibitive price of six pennies per bundle. But they are going back in time, in a way, and excavating a dusty business model that relies more on readers, and less on advertisers, than the typical online publisher. The New York Times is leading the trend. In 2000, circulation revenue accounted for 26 percent of its business. Last quarter, print circulation and online subscriptions accounted for 64 percent of the company’s revenue.

The near future of digital news may be as tumultuous as the near past. But it’s tough to imagine that readers and viewers will be ill-served by news organizations exchanging a fixation with breadth of scale with a renewed devotion to making a product worth more than $0.00 to its audience.

In its inexhaustible capacity for experimentation, digital media has pivoted to programmatic advertising, pivoted to native advertising, pivoted to venture capital, pivoted to Facebook, pivoted to distributed, and pivoted to video. Here is a better experiment: Pivot to readers.

* This article originally stated that New York Times ad revenue is 40 percent greater than its total wages and benefits. In fact, the company's total spending on wages and benefits is larger. We regret the error.



President Trump took many opportunities in 2017 to rail against the state of U.S. infrastructure, most recently using the fatal Amtrak crash in Washington state to point out the country’s crumbling bridges, roads, and railways. “[O]ur soon to be submitted infrastructure plan must be approved quickly,” he tweeted, harkening back to his oft-repeated promise to invest $1 trillion rebuilding the country.

Little came of that plan in 2017. But come January, the White House will begin a push, in earnest, for a national infrastructure package that gets to $1 trillion in overall investment, using $200 billion in federal “seed” money, a senior official told Fox News last weekend.

Trump advisers had previously described an infrastructure package that would rely on the private sector to make up the $800 billion difference. In this version, most of the $200 billion would be rewarded on a competitive basis to states and localities that promise to raise new, infrastructure-dedicated revenue on their own, for a total of $1 trillion, according to The Washington Post. Some portion of the $200 billion would directly fund projects in rural areas.

Such a plan could have its merits—many communities have long needed to find their own means to build roads, pipes, and transit, rather than turn to the federal government. But governors and mayors may not want to take on even more responsibility for infrastructure payments, especially on the heels of a GOP tax bill that promises to dramatically trim tax revenue coming in to certain states and cities. Trump’s new plan may heat up the debate over the role of the federal government in shaping local planning and policy.

America’s decaying transportation and communication networks was a leitmotif of Trump’s run for president. A campaign proposal even sketched the philosophical outlines of a Trumpian infrastructure bill: $200 billion in federal dollars would be leveraged to attract $800 billion in private investments through public-private partnerships.

But the president’s public-works-related pronouncements were frequently overshadowed by other events post-inauguration, and no concrete infrastructure funding proposal ever emerged. Indeed, the White House actually called to “obliterate the primary source of funding for surface transit,” said Kevin DeGood, the director of infrastructure policy at the left-leaning Center for American Progress, when it released its draft budget for 2018. That document called to cut the Department of Transportation’s discretionary budget by $2.4 billion, and to reduce the government’s regular infusions to the dying Highway Trust Fund by $95 billion by 2027.

Meanwhile, GOP leaders in Congress made clear that infrastructure was not high on their agenda. Infrastructure fell somewhere far behind repealing the Affordable Care Act and reforming the tax code in the legislative queue. Then, in September, something shifted: Trump began to emphatically state that private investment would not be the focus of his eventual infrastructure plan. In a White House meeting September, The Washington Post reported that the president pointed to well-known examples in Vice President Mike Pence’s home state of Indiana of how private-public partnerships can leave the government saddled with debt if contracts aren’t carefully negotiated at the start. The new funding focus: states and cities.

At an event in early December, DJ Gribbin, an infrastructure-policy adviser to President Trump, described the new plan as an “incentive program.” “Part of what we want to do ... is say, ‘Listen, if you as a state or local elected official are willing to create a new revenue stream for infrastructure, we as the federal government want to partner with you in doing that,’” Gribbin said.

Adie Tomer, a fellow at the Brookings Institution’s Metropolitan Policy Program, has seen details of the draft plan. He said that it emphasizes transportation projects, and that it basically resembles a discretionary grant program similar to New Starts and TIGER, two DOT programs popular across bipartisan lines for helping projects led by states and local transportation authorities meet their funding needs. (Trump’s 2018 budget blueprint called to eliminate TIGER entirely, and cut New Starts in half.)

White House officials have described themselves as neutral about how local players would come up with their spending share. “We will be agnostic as to the type of revenue, as long as it is new and dedicated to infrastructure,” one White House official told the Post. At the state level, that could mean raising gas taxes, as states as politically diverse as New Jersey, California, Tennessee, Montana, and Indiana have done in the past year. For cities, the answer might be in sales-tax-boosting measures, such as the ones that L.A. and Seattle passed last year. Others might prefer to implement tolls, congestion pricing, or other kinds of user fees. They might also seek financing methods that rely on private investors.

Gribbin has said the White House plan will lay out “clear, measurable, objective criteria” for how localities and states would win money. But Tomer said the details he’s seen place less stress on the nature of the projects it would fund, and more on who would be paying for them. “The more you come up with new revenue, the more likely you are to get help from the feds. This is going to be the key to the details,” he said. Compared to what TIGER and New Starts have provided, states and cities would foot larger shares of the final bills of their infrastructure projects.

On one hand, an infrastructure plan that calls on states and cities to rethink how they raise infrastructure funds could be welcome. With the Highway Trust Fund practically bust, states and cities have been receiving smaller and smaller outlays for highways and transit for years. “Doing things the old way and allocating [money] based on population, or trust-fund contributions, or lane-miles—that could use some revamping,” said Tracy Gordon, a senior fellow at the nonpartisan Tax Policy Center, a joint project of the Brookings Institution and the Urban Institute. “It’s not a bad idea to force some creativity in the sector.”

On the other hand, Trump’s push to rebuild infrastructure would come on the heels of the most dramatic rewrite of the U.S. tax code since the Reagan years, with major implications for every tier of governance. The new law, signed by President Trump on the Friday before Christmas, will add nearly $1.5 trillion to the federal budget deficit over the next decade, according to the Congressional Budget Office. That in turn is likely to trigger cuts to discretionary programs that help communities build roads, fly planes, drink clean water, and connect to the internet.

“That’s where we are starting from,” said Scott Goldstein, the policy director at the lobbying group Transportation for America. “With that as a foundation, it’s hard to see how you’ll find that trillion to invest.”

On top of that, nearly half of all states already faced budget shortfalls in 2017. A 2016 survey of municipal leaders by the National League of Cities found that ever-larger infrastructure needs were a top source of fiscal strain. With Americans no longer being able to deduct more than $10,000 in state and local taxes on federal returns, state and local governments will likely find a plethora of basic services—everything from public schools to first responders to pothole and streetlight repairs—even harder to pay for.

By effectively dangling infrastructure grants to the highest bidder, the White House’s proposal could pressure those same layers of government to corral what few resources they have into paying their share of an infrastructure plan. Cities that never financially recovered from the recession, like Detroit, Cleveland, Stockton, and Memphis, may feel especially limited in their spending options if federal grants are only available for big spenders.

“It’s an interesting time to be asking this sector to be more creative with revenue sources,” Gordon said. “Trying to get them to share more of the funding burden is probably not going to go over that well.”

Tomer put it a little more more strongly. For cities, he said, “it’s going to be like, ‘You’re messing with my money.’” Prodding cash-strapped states and localities to contribute more resources may cast a harsh light on the poor fiscal health that many of those places are suffering. The debate on how much the federal government should be involved in helping local economic recoveries—and how—may get more heated.

To be clear: These implications remain notional. Whatever the White House presents next month—likely before the State of the Union address on January 30th, Politico reported—will be widely discussed. Such a push might prove useful for turning around Trump’s dismal public polling. Some Democrats in Congress are already criticizing the package’s small federal contribution, while others have said they’d be willing to negotiate to shepherd such a package through. It’s mayors and governors who will be dealing with the aftermath, however; soon, their voices may be getting louder.

This post appears courtesy of CityLab.



This is one of three first-person accounts written by survivors of human trafficking. The others, as well as background about the project, can be found here.

I arrived in New York on September 15, 2005, at age 38, clutching a personal statement I had written for myself. It read, “I am going to America for the future of my kids. I am going to give them a good future. This is my purpose.”

I never thought I would get to live in the United States. But, my opportunity came when my sister moved to another country as a domestic worker and met a diplomat family that was moving to New York City. She told them about me, and they sent a contract to the Philippines for me to sign. I became one of the tens of thousands of Filipina women who go overseas each year as domestic workers. I would meet my employers for the first time in the U.S.

The contract said I would work eight-hour days, five days per week, and make $1,800 per month, caring for a teenager with special needs and doing some cooking and cleaning around the house. I would even get paid holidays and time off. But my sister, who had already worked for the same family, warned me that the contract was only for show—my real income would be $500 per month. However, that was still triple what my husband and I made combined. He was working as a driver for Johnson & Johnson, making 8,000 pesos (about $150) per month, while I made even less selling street snacks. We were feeling the strain of supporting four children, especially the hospital bills for my youngest, who suffers from seizures and often ends up in the hospital.

So I asked my husband to quit his job to stay home with the kids, and I traveled to the U.S. on a G-5 diplomatic visa. I brought with me a clean cloth diaper for each of my kids, to remind me of them. My new employers picked me up at the airport and drove me to their home, in a building with a doorman on the Upper West Side of Manhattan. I later told the rest of my story in an affidavit to the Department of Homeland Security—after learning I had become a victim of human trafficking.

In the beginning, things were okay. I had my own small room, though it was unfurnished aside from a bed. My employers would even take me out to dinner with them. But after three months, the wife started yelling at me all the time, for things like folding the laundry wrong. I couldn’t fully understand English, and said, “Sorry madam, I can’t understand.” That only made her angrier.

I was soon working 14-to-18-hour days, seven days per week. I cleaned and vacuumed their three-bedroom, three-bathroom apartment, washed and ironed their clothes, cooked breakfast and dinner, and cared for their daughter. I had to do the laundry in the bathtub, because they said the washing machine would ruin their clothes. When the daughter had an accident in her bed, I had to wash the comforter in the middle of the night. When family friends stayed the night, I had to serve them and wash their clothes too.

The food was very limited, as I wrote in the affidavit. The family would portion out how much food I should cook. I was only allowed to eat the leftovers—if there were any—after dinner. If I took more food than was allowed, the wife would say, “That’s too much.” I felt jittery all the time, knowing they were watching how much I ate. My typical meal consisted of a tall glass of water, a slice of bread, and half of a banana or plain rice late at night.

Once, I was so hungry in the middle of the night and remembered that there was still some rice in the rice cooker. I snuck into the kitchen, scooped a big spoonful of rice into a paper towel, and took it back to my room. The rice stuck to the paper towel, but I peeled off every grain. I was so hungry, I almost ate the paper towel.

Their daughter required special care and education. Caregivers for people with her condition need to have extra training, because some of them can feel easily threatened or frustrated, and they act out. I didn’t know any of this. The daughter would punch me in my back and in my ear. I would panic; I had no idea how to handle this. I would ask her to stop, and she would lie down crying on the floor. Then the wife would yell at me, or just stand there and watch the situation unravel.

I was so isolated. My employers told me not to have friends, especially other Filipinos. They warned me not to tell anyone how much I was being paid. They would say that my sister could get in trouble, or that I could get deported. They would watch me if I talked to anyone else. It scared me. For two years, I hardly ever left home unaccompanied, except on very brief errands to the grocery store across the street.

I cried all the time. I would take my rosary beads out from underneath my pillow, or take out my kids’ little cloth diapers and smell them to remember a familiar scent. That kept me going. Other times, I would re-read my statement of purpose, and remind myself that this was for the future of my kids. I had to be strong.

My employers were holding my passport, as I later reported to the DHS. But after 17 months, they let me go home for my daughter’s graduation. They deducted the cost of the plane ticket from my pay. I desperately wanted to stay in the Philippines, but I came back because my family needed the money and I didn’t know what else to do. Thinking about it now, I know that my husband would have told me to stay, that the money wasn’t worth it. But I couldn’t tell my family how bad it was. I came back.

When I returned, my employers took my passport again, and promised to renew my visa. One day when I was cleaning, I had a feeling, a premonition. I decided to open the last metal drawer of the family’s private dresser. Carefully, with an apron over my fingers, I pulled it open. And there it was: my passport. Right next to several hundred dollars. I started shaking when I saw it, because my boss had told me it was still in the office getting processed. They lied to me. I felt my heart racing from anger and disbelief. I put my passport back and started to plan my escape.

Even though the family watched my interactions, I still managed to make some friends, like the doorman and a Filipina house cleaner next door. Those small interactions were so important to me, because they helped relieve my isolation and loneliness. They also showed me that things inside the apartment were not normal. One friend was a Filipina woman I met at the grocery store across the street. After a while, I told her about my situation. She started leaving food for me with the doorman, and gave me her old cellphone. She pushed me to leave. She said that I needed to earn more, that my family needed more. I knew she was right. She introduced me to a Filipino lawyer in Queens, who wrote down my entire story and pointed out all the labor and human-rights violations. Together, the three of us devised a plan for my escape, and how to alert the authorities about what was happening.

The next morning, I told my employers I was going to visit Niagara Falls for the weekend with my friend who I had met at the store. It was summertime, and the daughter was out of school, so they gave me my passport back and let me go. I even gave my boss my friend’s phone number, as cover. That evening, I went to my friend’s house and picked up a package of documents from the lawyer: several copies of my contract, my story to send to officials, and a letter to my employers. At night, I prayed for a long time. I asked God for strength, and read my handwritten statement one last time.

I escaped the next day: July 26, 2007. I woke up early because I was anxious, and could feel my stomach churning. I knew I had a short window of time, because the wife and daughter would return home at 4 p.m. I cleaned everything in the house by 1 p.m., then walked out and left my key in the door. I immediately called my friend on the cellphone and yelled, “I’m free!” I couldn’t believe it. We ate at a Chinese restaurant that afternoon—my first full meal in months. Another friend picked me up that night.

For five years afterward, I kept silent about what happened, and avoided going out in public. My visa was expired, so I was undocumented, or what we call in Tagalog, tago nang tago, or TNT—“in hiding.” I lived in Queens and worked as a nanny and house cleaner. I was always scared around police, and constantly felt ashamed. In the Philippines, I was independent and knew everyone in my neighborhood. In the U.S., I had become isolated—a shadow of myself.

Eventually, through Damayan, a grassroots organization advocating for and led by Filipina domestic workers, I was able to get a T visa, which is a humanitarian visa for survivors of human trafficking. After I became a leader with Damayan and a board member, I was able to help other trafficking survivors and refer them to Damayan for free legal services. Four of my friends have already received their T visas through Damayan and their partner agency. Then, two years later, in 2015, my four children reunited with me in the U.S. Despite this, every day, I still feel the distance that had developed between us, as a result of nearly a decade of separation. As for the employers, because of diplomatic immunity, they left the country and were never prosecuted. I never got the money or the justice that was owed to me.

There is trafficking happening all around. Many workers from overseas have little information about the situations they are getting into. They might receive a pamphlet but not understand it. Or, the employer will hide it. They need to know contact information, and where they can get help if their employer takes their passport, withholds their pay, or if something else happens. I didn’t understand that my situation could be considered trafficking. I thought I had to follow what the employers said, no matter what, because they were my bosses. If I had understood my rights, and the law, maybe things would have been different.

This story was produced with assistance from the National Domestic Workers Alliance and its Beyond Survival campaign.

This article is part of a project called “The Unfree,” which is supported by Dignity Health Foundation and Silicon Valley Community Foundation.



This is one of three first-person accounts written by survivors of human trafficking. The others, as well as background about the project, can be found here.

My mother used to tell me, “I want you to go to school for me.” She herself had never had the chance. She came from a family of 10 children, and became a domestic worker, caring for another family’s children, by age 8. She stayed with them for eight more years, until she met and married my father.

I grew up in a small town in southeastern Brazil. My goal was always to finish high school, then go onto some kind of professional training. But it was difficult. In my district there were not enough schools for the number of children, so the school day was divided into three sessions. I went to the early session, from 7 a.m. to 11:30 a.m. Then from noon until bedtime, plus weekends, I worked for a neighbor who had asked me at age 8 to care for her 2-year-old daughter, and later, her second daughter.

When I was 14, I moved in with my older sister across the country to help take care of her newborn and pursue my dream of getting an education. To support myself, I began to work nearby as a nanny for a family of two doctors who had recently had a baby. About two years later they invited me to travel with them to Boston to care for their toddler. Being a frustrated teenager in Brazil, I saw it as an opportunity for myself. Everyone around me encouraged me to go. I didn’t know it then, but I would become a survivor of labor trafficking, as I later testified to the Connecticut state senate.

We agreed verbally that I would work for the family for two years. I would be part of the family, they said. They planned on doing a lot of traveling, visiting museums, and so on. They only had one child, and my job was to take care of him. I got a domestic-worker visa, and I didn’t even have to go to the U.S. embassy to pick it up. I never had to do an interview. I was never asked any questions. Only later I found out that I would get paid $100 per month, or $25 per week, with room and board included.

Because I was underage, I needed my parents’ permission to travel abroad. I traveled home from my sister’s house and read them a letter from the family that would employ me. They were happy for me and signed the forms. I was granted a two-year domestic-worker visa. A few weeks later, in 1990, I boarded a plane to Boston carrying a Portuguese–English dictionary, some (warm-weather) clothes, and some cassette tapes of Caetano Veloso, Tina Turner, and New Kids on the Block.

I remember feeling nervous on the plane. I’d be in a new country, learning a new language. But the family told me I had nothing to worry about. They said this would be new for them too, and we would all learn together. Those conversations made me feel safe.

But things started going wrong from the beginning. For example, the family was told by the building management that to receive mail, their names had to be on the mailbox. So they put their names on, but not mine. I couldn’t receive mail. I tried to put it on there several times, but every time, they took it off.

There were more, little things. They asked me to do more than just childcare. They asked me to do the dishes, because running the dishwasher was too expensive. They said I couldn’t use the phone to call home, because it was also too expensive.

One day, they said they wanted to turn my bedroom into a guest room, and told me to stay on the porch. It was a “three-season porch,” one that had storm windows, a concrete floor, and a big red door with thick rubber around it to keep the cold—the cold of my new room—from coming into the rest of the house. I had to sleep on a futon on the floor. Beneath that, I put cardboard boxes, to insulate me from the concrete. Remember, this is Boston. I did have a space heater, but for many months each year, the floor was frigid.

Every day, I woke up at 6 a.m., dressed, and worked nonstop, from morning until night. I made breakfast and served the family. I cleaned the house until it was spotless. I took care of their child. I did all the laundry. One thing I never understood was that they wanted everything ironed: bathroom towels, sheets, even underwear. At 11 p.m. at night, after I’d made dinner, tidied up, washed the dishes, and the children were sleeping, I would have to do the ironing.

Sometimes they had family visit from Brazil, or people over for dinner, and I had to cook and clean for them too. None of the guests ever said a word to me. Neither, mostly, did the parents themselves. There was very little conversation between us. I was a fixture in the house; a robot there to do things for them. I felt invisible, dispensable, and alone. Many days I worked 15 hours straight.

At some point, they began to ration how much food I should prepare. Often, they would eat everything I cooked and leave nothing for me. On those nights, I would go out late at night and get something from a nearby store. That money came out of my already small earnings. After a while, they had a second baby, which I was expected to care for as well, and my pay was increased to $150 per month.

For three months, I got asthma from inhaling ammonia and Clorox, and couldn’t sleep at night. Even though they were medical doctors, they never took me to the doctor or checked me out themselves. The wife told me to take some of the kids’ medicine before going to bed. I felt I was not treated as a person. Life went on like this for two years.

One thing I know is hard to understand for people who grew up with a lot of autonomy is why I didn’t speak up or walk out. Often, for those of us who grow up poor, we don’t have the tools to challenge the people who hold power over us. In situations like these, there are all sorts of power dynamics at play. For one thing, my visa was tied to my work with the family. Where would I go if I walked out? I didn’t speak English and had no one. I was not getting the education I was promised. Who could I turn to? Many people in these situations are afraid to trust government agencies or the police. I did question things from time to time. But I would get yelled at quickly. Once, the wife told me I shouldn’t disrespect her, and that I should kiss the ground she walked on.

It was hard emotionally—and confusing. I had worked for the family in Brazil, and there, I never felt mistreated. I would go with them to their vacation homes in Brazil. But something changed in the U.S. And I did feel a very real connection with the children. The oldest boy would make drawings for me and comfort me when I cried. People don’t understand that you can’t just walk out. Even if you are not in physical chains, there are constraints—economic, emotional, social—that keep women like me in place. There’s a lot of coercion—and denial. We think, “Oh, my boss is just having a bad day, I need to be understanding.”

They told me up-front that if I didn’t like it, they could get me a ticket to go home. But for me that wasn’t so easy: Coming from a simple family, it was instilled in me that all I have is my values, my word, and my commitment. I wasn’t supposed to ever break it. And I worried that if I spoke up, I would get thrown out. The porch was bad, but being out on the street with no English would have been much worse.

I blamed myself for what was happening. I would write to my family and say that everything was fine, that the city was beautiful. I never told my family about the situation, because I felt it was my fault. I thought if I went back to Brazil, I would be blamed for not being tough enough.

Toward the end, I was able to bargain in exchange for time to go to English classes. I said that if they helped me go to school, I would leave dinner in the oven and clean everything afterward and finish things up in the middle of the night. In addition, every other weekend, they would go out, and I would care for the children from dinnertime until 2 a.m. At first, my English classes cost $30 a month, which I paid. Later I was able to find a free class.

The family returned to Brazil. But I had nothing to show for my time in the U.S. I decided not to go home. I found work with another couple who bought me my first winter jacket, asked what I wanted when they went to the grocery store, and encouraged my studies. I stayed with them for 14 years.

Since then, I’ve built a life and career. I cleaned homes, and did eldercare for 15 years. By working two to three jobs at a time, I was able to finish school. Eventually, I got a Ph.D. in sociology from Boston University. I volunteered at the Brazilian Worker Center, a community-based organization in Boston that works for the empowerment of Brazilian immigrants. In 2010, I became its executive director, and helped shepherd, in coalition with other groups, the first law to protect the rights of domestic workers across Massachusetts. And now, every day, I work so that women who are in situations like the one I was in can get out and build lives of their own.

This story was produced with assistance from the National Domestic Workers Alliance and its Beyond Survival campaign.

This article is part of a project called “The Unfree,” which is supported by Dignity Health Foundation and Silicon Valley Community Foundation.



This is one of three first-person accounts written by survivors of human trafficking. The others, as well as background about the project, can be found here.

I come from a family of teachers: father, husband, sisters, and daughter. I taught for 32 years at an elementary school in the Philippines. Somehow, that added to the shame I felt for being a survivor of trafficking. I not only worried about what my family would think, but my hundreds of students as well. I thought that everyone would lose respect for us.

When I retired from teaching at 55, I went into business with a neighbor, and they disappeared with my savings. I was devastated, but a cousin through a marriage came to my rescue—or so I thought—when she told me her boss was looking for someone to accompany her elderly mother to the United States and take care of her there.

I met with the woman, and she offered me $400 per month, nearly three times what I could make as a teacher. She added that she would petition for a specific kind of visa so my family could come to the U.S. too. I was overwhelmed with happiness and gratitude. I thought this was the answer to my prayers.

The first sign that something was wrong was at the airport. The Philippines Airlines personnel withheld my ticket because the woman I was supposed to be caring for was not with me. I wondered why the mother had traveled to the U.S. ahead of me, so I called my boss to let her know I couldn’t pick up my ticket alone. She sent her mother back to Manila, and we flew to the U.S. together. In all of my excitement, I didn’t ask any questions about the strangeness of the situation. I trusted my new boss.

In San Francisco, my boss’s younger sister met us at the airport, and we happily ate dinner at her house. Before going to bed, the sister told me, “My mom stays with me. My sister used my mom so that she could get you to come here to be her domestic helper. Tomorrow, I will arrange your flight to Culver City.”

I was so shocked that I couldn’t say a thing. My head was spinning from the confusion.

I arrived in Los Angeles, and my boss took me to her condo in a gated community. She was a very prominent, influential Filipina woman, and her American husband was the vice president of legal affairs of Sony Pictures in Los Angeles. Before we went inside, she asked for my passport. She said she was going to extend my visa and petition for my family to come to America to be with me. Again, my happiness overwhelmed me, and I believed her.

Within a week, I had a “daily work schedule,” taped to the wall in the kitchen. It ran from 5 a.m. to 10:30 p.m., which was incorrect, since I also had to bring the dogs outside in the middle of the night. I had to take care of the dogs in addition to cooking, cleaning, washing, vacuuming, ironing, dusting, hemming clothes, and maintaining the plants. Every month, I cooked a large pot of a special Filipino dish of ground beef, rice, tomato, carrots, and broccoli for the dogs, but was fed leftover food that had been in the refrigerator for days. I had to brush the dogs’ teeth, clean their ears, and give them vitamins each day, but I had to sleep on a dog bed in the living room, even though the house was large, with a guest room and music room. I kept my belongings in the laundry room.

I felt that my boss disliked everything I did, no matter how hard I tried. She told me I was ignorant and brainless, and, as I later alleged in civil court, she hit me and pulled my hair, and left me with bruises and cuts.

I was scared of her, but also ashamed that this was happening to me, an elderly woman who deserved respect. I wanted to escape, but had no idea where to turn. And all kinds of fears kept me paralyzed. My visa expired, and after that, I was afraid of being arrested. My boss also told me I was responsible for paying back my airfare and that of her mother, since I couldn’t have come to America without her. She also deducted my everyday items from my salary, like shampoo and lotion. As I claimed in my lawsuit, I was paid a total of about $300 for my entire time with the family. Even if I made it back to the Philippines, I didn’t know how I could pay back my loans there.

I tried to tell people about my situation. I wrote notes to my boss’s husband. He seemed concerned about the physical abuse. But when the wife found out we were speaking about it, things only seemed to get worse. When the boss’s mother and brother came to visit, I told them too, but they gave me a prayer book and told me to pray. I think they were afraid of her too. I called a friend in Chicago, but she herself was undocumented and afraid to get involved.

In the end, the neighbors were the ones to help. From when I took the dogs out, I made friends with the 13-year-old girl next door. I couldn’t keep from crying when we were together, and eventually told her what was wrong. She told her mother. Plus, her parents sometimes sat at the swimming pool close to our condo, and heard the yelling and hitting through the walls. Her mother asked my boss if I could come help when their cleaning person didn’t show up, and my boss, trying to be a respectable neighbor, let me go. We were able to talk, and the mother encouraged me to escape. But I wasn’t ready. I was still too scared.

This went on for a year. I rarely spoke with my family on the phone, and I didn’t tell them how bad it was, because it felt useless. What could they do from so far away, given all of the debts we had? Because I didn’t have an outlet for expression, I would write things down on paper. At the end of each day, I would write the exact date and list the things my boss said and did to me. I also kept good track of the deductions made from my paycheck. This meticulous recordkeeping was a way to relieve my emotions for the day. But it was also the thing that built my case against the family.

Finally one day, we got a knock on the door. It was the police. One of the neighbors had called and said I was being hit. He asked if I wanted to talk with him alone outside, but I was silent and only looked at my boss. Even though my boss treated me cruelly, she was still my boss, and because of my culture, I felt I should obey her. Also, I had no papers, and didn’t want to be put in immigrant detention. Finally I said, “Sir, maybe some other time. Please give me your business card.”

He left, and I was in trouble after that. I remember the husband and wife berating me. It felt like an interrogation. The next day, my boss took the business card away, and told me they had arranged my flight back to the Philippines. I felt pressured to sign a piece of paper saying I wouldn’t say anything about what had happened. I refused. I went to the neighbors for help, and they called the police. The officers accompanied me back to my boss’s so I could get my things. It seemed like my boss wanted to keep my passport, but they told her to give it to me. I slept at the neighbors’ house that night. The whole experience was a blur.

The next day, the Federal Bureau of Investigation and the Immigration and Naturalization Service, which now falls under the Department of Homeland Security, showed up. My boss had called immigration enforcement, trying to get me deported before I revealed the truth. I was scared when I opened the door. They took me to a government building for several hours. I waited and waited, as exhaustion swept over me. Finally, a woman from SIPA, Search to Involve Pilipino Americans, took me to the Pilipino Workers Center (PWC), a local Filipino organizing group. My life then changed.

PWC helped me with housing, and securing food stamps and access to a doctor. They gave me a bus pass so I could learn how to navigate the city. Another organization called CAST (Coalition to Abolish Slavery and Trafficking) helped me find a lawyer, access to education, and transition to independent living. I became a certified nursing assistant.

My civil case was filed one year after I left my employers, and went to trial another year later. The trial experience was scary and stressful, and difficult to juggle with my job. My employers denied all the charges, but in the end, I won and was awarded monetary compensation. I remember one of the jurors hugged me outside the courtroom afterwards and said, “I believed you 100 percent.” I realized I had been given justice.

One year later, there was also a criminal case. My boss pleaded guilty to a charge of forced labor and had to serve three years in prison. Her husband pleaded guilty to alien harboring, and had to do community service and pay a fine. At last, I could work without fear.

Fighting my trafficking case made me a stronger person. Even when my rights were violated, on the job I had the tools and the community to fight for them—and for those of the countless undocumented domestic workers who can’t speak out.

At 74 years old, I am back in the Philippines, and finally retired. I have remained active with PWC, to help raise awareness of workers’ rights in California and issues of human trafficking. With the compensation money, I have been able to help my community here at home, especially in supporting several family members. Many of them, and my former students, know my story as a survivor of trafficking. Sharing it makes me feel proud. Many of my former students have encouraged me to keep speaking out.

All of this gives me joy and fulfillment. But, it still doesn’t compare to the happiest moment of my life. In 2013, years after I left the Philippines, I was finally reunited with my husband, my children, and my grandchildren.

This story was produced with assistance from the National Domestic Workers Alliance and its Beyond Survival campaign.

This article is part of a project called “The Unfree,” which is supported by Dignity Health Foundation and Silicon Valley Community Foundation.



At this year’s Consumer Electronics Show, there are more vendors listed as selling “smart cities” technologies than gaming products or drones.

That’s a break from the past. The annual mega-gathering of the tech world—which started in Las Vegas on Tuesday—was once a parade of TV screens, smartphones, and other personal electronics. But CES’s dazzling displays have increasingly focused on cities themselves, and the profit potential they present to technology companies. The question, as always, is where that leaves the people who live in them.

From that perspective, perhaps no other project in the world has drawn as much curiosity as “Quayside,” a 12-acre slice of Toronto waterfront in line to be developed by Sidewalk Labs, the urban-tech-focused subsidiary of Google’s parent company Alphabet. Launched in 2015 by its CEO, Dan Doctoroff, and a number of other Michael Bloomberg affiliates, Sidewalk Labs makes much of its urbanist bona fides. The company is now primarily focused on turning the patch of Toronto-owned land into what it calls the “world’s first neighborhood built from the internet up.”

That could mean nearly anything, based on the 196-page vision document Sidewalk Labs prepared that responded to (and won, last fall) a public request for proposals. In working with Waterfront Toronto, the public entity that owns the land, to develop Quayside, Sidewalk Labs would reimagine five dimensions of urban life—housing, energy, mobility, social services, and shared public spaces—with an aim to “serve as a model for sustainable neighborhoods” around the world.

A self-contained thermal grid would recirculate energy from non–fossil-fuel sources to heat and cool buildings, while a food-disposal system would keep food waste out of landfills. For cars and trucks, Quayside would be less hospitable than other areas in the city: Part of the neighborhood would prohibit non-emergency vehicles entirely, while bike-share stations, transit stops, and cycling and walking paths—kept useable through the Canadian winter with sidewalk snow melters and automated awnings—would offer “efficient alternatives to driving, all at lower cost than owning a car.” An autonomous transit shuttle would rove some streets. (Waymo, a leading developer of self-driving-vehicle software, is also an Alphabet subsidiary.)

Buildings would be largely prefabricated using eco-friendly materials, to cut back on waste. With a “strong shell and minimalistic interior,” they could be adapted to multiple uses, morphing from residential to retail to industrial, and back again. To support such a futuristic vision, Quayside would test a novel “outcome-based” zoning code focused on limiting things like pollution and noise rather than specific land uses. If it doesn’t bother the neighbors, one might operate a whiskey distillery in the middle of an apartment complex.

With its generous tree canopy, bike lanes, and bustling storefronts, the Quayside pictured in the vision document looks like “quality urbanism as we might know it,” Wellington Reiter, an architect and executive director of Arizona State University’s University City Exchange—an initiative focused on integrating campus developments into Phoenix’s larger urban plan—told me. In many ways, it’s not an especially futuristic vision: In the 1960s, out-there architects explored the idea of implementing modular housing at scale. Microgrid technology and snow-melting sidewalks are not new. And planners have long dreamed up dense and walkable developments that mixed retail, housing, and light industry. Save for the driverless cars, perhaps, these outward-facing innovations are familiar New Urbanist fare.

This might be a way for Sidewalk Labs to emphasize how different Quayside will look from, say, Masdar or Songdo, two “smart cities” planned from the top down in Abu Dhabi and South Korea that have fallen far short of their tech-utopian promises.

Rohit Aggarwala, who leads urban policy implementation at Sidewalk Labs, is addressing the CES crowds in a panel this week—one of many ways Alphabet is raising its profile at the convention this year. Aggarwala resists the term “smart city” when describing his work. “It reflects this early–21st century arrogance, that all that’s gone before is obsolete,” he told me in October at CityLab Paris, a conference run by CityLab, a sister site of The Atlantic. He feels the term is also too closely associated with software products focused on wringing maximum efficiency out of cash-strapped city services. Smart tech or not, citizens still must decide how to use the tools that are available to them, Aggarwala said: “We are not the people of Toronto. We need them to help us figure out how to apply this.”

Yet what has drawn the most concern and curiosity with regards to Quayside is a uniquely 21st-century feature: a data-harvesting, wifi-beaming “digital layer” that would underpin each proposed facet of Quayside life. According to Sidewalk Labs, this would provide “a single unified source of information about what is going on” to an astonishing level of detail, as well as a centralized platform for efficiently managing it all.

Kitchen appliances switched on too long, overflowing trash bins, and high-traffic park benches could be monitored and addressed by this digital layer. So could changes in air quality and spikes in noise levels. Each passing footstep and bicycle tire could be accounted for and managed. This ocean of data could inform urban planning, research, and new software development, including a special platform by which Quayside residents could access public services.

It’s the kind of all-seeing urban omniscience that would stir the heart of any utopia builder. But to whom, and how, would this data be made available? And what would such an arrangement mean for any Quaysider who doesn’t wish to be monitored? In Toronto and beyond, the depth and details of the data collection have sparked public debate. At the first public forum on the project, and in a list of questions related to the project compiled by the journalist Bianca Wylie at Torontoist, privacy questions and fears have come up again and again.

So have issues like inclusion and access. Toronto’s affordable-housing shortage rivals that of many pricey American cities. Aggarwala asserted that, to be successful, Quayside must be home to a representative sample of Toronto’s economically and ethnically diverse population. It’s not hard to imagine affluent and digitally savvy Torontonians lining up to move into this futuristic, data-driven community. But the city could face thorny ethical issues if it wants to provide, say, subsidized housing to low-income residents. Those residents might not have a choice in how much privacy they give up to call Quayside home, even if they don’t like the terms of use. The same could be said for anyone who uses its public spaces.

It is not yet certain that Quayside will ever be built, at least not in the state currently imagined. Sidewalk Labs has committed $50 million and one year’s worth of engagement to develop a plan for execution. Either the company or Waterfront Toronto could still decide to back out, though the two partners have also formed a third entity, called “Sidewalk Toronto,” devoted to bringing the lakeside property to life.

Pamela Robinson, a professor of urban planning at Ryerson University in Toronto, wonders if that blended entity could risk blurring public and private interests during the planning process. “Both sides must perceive some value in this arrangement,” she said—she’s just not sure what that value is. (When contacted for this article, Sidewalk Toronto did not provide any comment.)

For many of the attendees poring over the makings of “smart cities”—sensors, cameras, and cars—at CES this week, the role of technology in urban life is obvious: It is a moneymaker. For Sidewalk Labs, layering technology beneath a neighborhood may also prove a savvy way of extracting new value from land—which is, to say, a new way of “developing” it.

What about everyone else? Quayside might offer a blueprint for more-sustainable cities. It may also be a real-estate play for an immensely powerful and influential tech giant. Until more planning takes place, judgment may need to be reserved. A calendar of future meetings and forums, devoted to hammering out public priorities and private interests, is expected in the coming weeks.

Robinson sees the Quayside project as a natural evolution in the ways technology has inserted itself into urban planning, from the automobiles of the 1950s to the “smart” technologies of the early 2000s. The difference is that now—with a growing housing-affordability crisis, increasingly traffic-clogged streets, and a changing climate to contend with—all the easy solutions have been exhausted. “We need to find new ways of working,” she said. “The challenging parts are ahead.”

This post appears courtesy of CityLab.



Natasha Rothwell was born in Wichita, Kansas, but doesn’t remember much about it. Her father was in the Air Force, so she grew up moving around—to New Mexico, Florida, Illinois, New Jersey, Maryland, and even Turkey. “I definitely have wanderlust because of how I grew up,” she says. As an adult, she moved to Tokyo, where she performed at the Tokyo Comedy Store and taught English. She’s had a variety of jobs, including working at McDonald’s, where, on her father’s advice and to her manager’s surprise, she gave two weeks’ notice when she decided to leave.

Rothwell is a producer of HBO’s Insecure, in which she also stars as Kelli. In addition, she’s developing a new show for HBO for which she will be an executive producer and a writer; she’ll also star in that. Before all this, she wrote for Saturday Night Live and performed improv at the Upright Citizens Brigade.

I recently spoke with Rothwell about changing one’s mind about career paths, transferring between colleges, and her career mantras. This interview has been lightly edited and condensed for clarity.

Lola Fadulu: I saw in an interview with The Baltimore Sun that you considered journalism for a little bit, but then ultimately changed your mind. Why did you change your mind?

Natasha Rothwell: It was just misguided. I always loved to write, and I still do as a part of my job. Creative writing was where my passion lay. I thought that because my parents had pretty by-the-book jobs, I should have one too.

I concocted this whole after-school special in my head where I thought my parents would be really upset if I told them I wanted to major in theater, so I thought the next best thing would be to go to school for journalism. My initial school that I went to was Ithaca College, which has an outstanding theater.

I thought proximity to what I wanted to do would be good enough. I remember seeing a production of The House of Blue Leaves. The program had the poem by Langston Hughes that starts, “What happens to a dream deferred?” I remember just crying reading that poem because I was like, Oh, that’s what I’m doing right now. I’m sitting in the audience, and I’m looking at my friends onstage, and I want to be onstage, so I have to change that perspective by literally finding a way to get to the stage.

I had this big coming-out moment with my parents where I was like, “I want to be an actor.” They were so nonplussed. They were like, “Yeah, we know. We were really confused. We thought that that’s what you wanted to do, so we were surprised by the journalism thing, but we wanted to be supportive.”

I ended up transferring to the University of Maryland, where I got a full scholarship for acting. That’s where I completed that program.

Fadulu: Why did you decide to transfer to UMD? Could you have changed your major at Ithaca, or were you locked into journalism there?

Rothwell: No. I could’ve changed my major. I auditioned for the B.F.A. program and got rejected. I was offered a place in the B.A. program. At the time, I thought that the only way to make it to Broadway—because at the time that was my understanding of what I wanted to do—I had to be a B.F.A.

My goal was to transfer to the University of Maryland and take my core credits. At the time, my dad was stationed at the Pentagon and my mom was working at a hospital near there. I was like, I’ll stay at home, and I’ll go get my core credits first semester and spend the spring auditioning for all of these fancy B.F.A. schools.

While I was at the University of Maryland, one of the advisers there said, “Well, we have a full scholarship. You have to audition for it. It’s called a creative-and-performing-arts scholarship.” I decided to do that just in case, as a backup, and I got it. I didn’t expect to get it.

To me, at the time it just made the most frugal sense in the world to go there, even if it was a B.A. program. At that point, I had been there a semester. I’d connected with the professors and felt like I could get what I needed from the program. I didn’t intend to stay, but I’m so glad that I did.

Fadulu: Would you say that you developed an interest in acting and writing at the same time, or did one come before the other?

Rothwell: They happened sort of at the same time, and then performing is what I decided to nurture the most. I have two sisters and a brother, and being in the Air Force, when you move to a new place, your siblings are your first friends. We would often entertain each other. I loved doing that. I loved making them laugh and playing around. We put on talent shows.

I definitely sensed my love of performing and making people laugh through that, but I also remember writing a poem about Martin Luther King and reading it at Thanksgiving. I was maybe 10. It’s so sweet now, but very mortifying to think that I stopped Thanksgiving and was like, “Guys, dear older black people who lived through segregation, let me tell you about this guy, Martin Luther King. It’s going to blow your mind.”

As I got older, when there were opportunities in school for plays and performances, I definitely gravitated toward them, but I would say it wasn’t until high school and college that I started writing one-act plays or monologues.

Fadulu: What was your first-ever job?

Rothwell: Babysitting. I definitely remember reading the Baby-Sitters Club books and thinking, I’ll start a business babysitting some of the neighborhood kids. When I was younger, at the church that we attended, they had the infants’ and toddlers’ room where they needed teenagers to come in and watch kids, so I definitely worked in there.

Fadulu: You liked kids?

Rothwell: Well, it wasn’t necessarily an affinity for kids in that I wanted to be around them, but I think that when you’re young and you’re trying to figure out how to supplement your allowance it’s like, What can I do if I want two candies at the store, and I can only afford one? What are some things that I can do to make money? It was definitely more an economic decision than a passion decision.

Fadulu: Were you considering other ways to make money besides babysitting?

Rothwell: I remember having a Kool-Aid stand. You have to sit in the sun and try to get people to buy warm Kool-Aid. That was probably the only other way I thought of to make money. I think I have a vague memory of bringing candy canes to middle school and selling them around the holidays, but I had to be sneaky because it was candy. Nothing that was a legitimate business.

Fadulu: What was your first job when you were of legal age?

Rothwell: I worked at Blockbuster Video. Rest in peace, except the one that's left. I worked at McDonald's. During the summers, I worked multiple jobs. I worked at Target.

My first [real] job was at a bookstore. It was not Borders. What was the one before Borders? There was a bookstore that was pre-Borders. I remember spending maybe three hours curling my hair for this interview. It was so important to me. I was 15.

I was a photographer at JCPenney. Essentially you sat people down, you pushed a series of buttons, and then you were a professional photographer. I bounced between that department and the men’s department. I helped a lot of older men who didn’t understand how colors worked, if something matched. It’s like, “Excuse me, Miss. Do these go together?” I’m like, “No, sir.” I was so unfashionable. I had no business telling anyone what to wear, but that’s what I did.

Fadulu: Do any other memories pop up from working at Blockbuster or McDonald’s?

Rothwell: I remember quitting McDonald’s with a written two-week notice.

Fadulu: Oh, wow. That’s very nice of you.

Rothwell: I’m sort of a nerd and a goody-goody to a fault. I just remember asking my dad, “If I no longer want to be employed by an establishment, how might one leave an establishment?” He’s like, “Well, typically you write. You put in your two weeks’ notice.” So I typed it up. I remember giving it to my manager at McDonald’s. He said, “You could leave today.” I was like, “No. I want to put in my two weeks.” I worked there for two weeks. I think every day I showed up in that two weeks he was surprised. He was like, “Oh, you’re still here. I thought you quit.”

Fadulu: Were you still curling your hair for McDonald’s?

Rothwell: No. I got to wear a visor at McDonald’s. It was a rock-and-roll McDonald’s. I don’t even know if it’s still there. It had a jukebox, and it had black-and-white tile.

Fadulu: Can you talk a little bit about how UMD and UCB prepared you for starting off as a writer for Insecure?

Rothwell: At the University of Maryland, I was very heavily involved in the improv group.

I found my way to New York and started performing at UCB. Because of that, I was seen by SNL and was able to write on SNL. Writing for Saturday Night Live opened a lot of doors for me. I took meetings with Amy Gravitt [the executive vice president of programming] over at HBO. We really connected in our meeting. She served in the Navy, and I’m an Air Force brat. At the end of our meeting she’s like, “Well, we have this show in development I think you’d be really good for. Do you know Awkward Black Girl?” I said, “Oh, yes. Of course I know that show.” She’s just like, “Yeah, it’s going to be a show from the same writer, Issa Rae.” Three months, later I interviewed for the writer’s room via FaceTime with Issa and Prentice, our show runner, and got the job. Basically, that’s how the University of Maryland led me to Insecure.

Fadulu: Do you have a piece of advice you’ve received that has really helped you in your career?

Rothwell: I have a quote framed on my bedroom wall. It says, “Be so good they can’t ignore you.” It’s a Steve Martin quote. Being a person of color at any job always means you’re going to work twice as hard for half as much.

When I read that quote, I remember thinking, Oh, it’s not just about working twice as hard for half as much—it’s about being excellent about what you’re doing, so that way people will pay attention and you’ll stand out. I always strove to just be the best.



To call Bitcoin the biggest and most obvious bubble in modern history may be a disservice to its surreality.

The price of bitcoin has doubled four times this year. In early January, one bitcoin was worth about $1,000. By May, it hit $2,000. In June, it breached $4,000. By Thanksgiving, it was $8,000. Two weeks later, it was $16,000.

This astronomical trajectory might make sense for a new public company with accelerating profits. Bitcoin, however, has no profits. It’s not even a company. It is a digital encrypted currency running on a decentralized network of computers around the world. Ordinary currencies, like the U.S. dollar, don’t double in value by the month, unless there’s a historic deflationary crisis, like the Panic of 1837. Instead, bitcoin’s behavior more resembles that of a collectible frenzy, like Beanie Babies in the late 1990s.

But defining and identifying bubbles is harder than it seems (kind of like defining bitcoin). The term technically refers to an asset whose price dramatically exceeds its intrinsic value. But who determines price and value, anyway? Those aren’t scientific concepts with formulas, like gravity or the length of a hypotenuse. They are the co-creation of buyers and sellers whose needs and attitudes are constantly changing.

Sometimes, spotting a bubble is very easy. Imagine three public companies that make shoe leather—Derek Leather, Inc., Joe Leather, Inc., and Becca Leather, Inc.—with the exact same revenue, expenses, talent pool, and customer demographic. Let’s say the market caps for all three companies start the year at $1 billion and Derek Leather and Joe Leather don’t appreciate; meanwhile, the public valuation of Becca Leather climbs to $2 billion, then doubles to $4 billion in a month, and then doubles again to $8 billion in the following week. It would be pretty clear that Becca Lather’s valuation makes no sense with an apples-to-apples comparison to Derek and Joe.

But what happens when an entire industry is a bubble? It becomes harder to make an apples-to-apples comparison, since the entire sector is an incomparable fruit. A good example would be early Internet companies whose valuations soared in the late 1990s and crashed in the dot-com bubble. For years, Internet bulls defended the stock prices of companies like Pets.com by arguing that, due to the rising digitization of the economy and the global nature of the Internet, user growth was a more significant proof of value than old-fangled metrics like profit or revenue. Eventually, a combination of factors—the failure of some large Internet companies, changes to the tax code, rising interest rates, and venture capital exhaustion—contributed to the big pop.

In a way, the emergence of cryptocurrencies is akin the dot-com era, because there is no perfect comparison to illuminate the “real” value of something like bitcoin. It’s a currency (like the dollar), whose owners consider it a long-term store of value (like silver), which is appreciating as if it were a faddish collectible (like a Beanie Baby), and is running on a blockchain platform, which some insist could change the future of everything from legal titles to daily payments (like Internet). How can one be so sure bitcoin is a bubble if we don’t even know what the proper comparison is—dollars, silver, Beanie Babies, or the Internet?

In their great 1982 paper "Bubbles, Rational Expectations, and Financial Markets," the economists Olivier Blanchard and Mark Watson explain why gold is susceptible to bubbles. It’s an explanation that sheds light on the bitcoin frenzy, too. Gold, like bitcoin, is not a company. There are no financial reports, and its investors will never receive dividends. Instead, there are at least two big reasons to invest in gold. First, goldbugs want a hedge against an economic catastrophe or inflation. Second, some people invest in gold simply because they see the price of gold going up. Such an investor “bases his choice of whether or not to hold the asset on the basis of past actual returns rather than on the basis of market fundamentals,” Blanchard and Watson write. In other words, the investor’s story is: The price will go up, because … well, it just went up!

These investors buy gold, not because of any fundamental economic insight or any analysis of value, but rather because they want to catch the train. They see the price rising and they assume they can buy gold, hold onto it as it appreciates, and then offload it to some greater fool before its value declines. In fact, the economic term for this sort of irrational belief is called “greater fool theory.”

Bitcoin is turning into a gaggle of greater fools. Retail investors are jumping into the market to buy bitcoin, in the expectation that they will be able to sell their investments for cash to some other sucker later on. In November, Bloomberg reported that “buy bitcoin” had overtaken “buy gold” as an online search phrase. In December, bitcoin platforms soared up the app charts. Coinbase, an online broker where people can buy cryptocurrencies, is now the top trending app in the Apple App Store. Two similar platforms to oversee cryptocurrency accounts, Gdax and Bitcoin Wallet, are now fifth and eighth on the trending charts.

For the people downloading these apps, bitcoin probably isn’t a philosophical bet on the future of money and society’s relationship to the government, says Christian Catalini, a professor of technology at MIT Sloan School of Management, whom I have spoken to often about bitcoin. “There is a speculative frenzy among retail investors who just want to make a quick buck and the App Store is pretty clear evidence of that,” he said.

There is another important feature of the bitcoin market that could both explain its high valuation and suggest an imminent correction. The crypto market is insanely concentrated. Approximately 1,000 people own 40 percent of all bitcoin in circulation, according to Bloomberg. Just 100 accounts control 17 percent of the market. Many of these accounts have held bitcoin for years because they believe fervently in its value. But if a handful of them sell even a small portion of their shares, it could dramatically move bitcoin’s price, potentially triggering a massive correction, as retail investors (who only bought in because the price was going up) try to sell en masse to avoid losing all of their money. There is an upside to this concentration, however, which is minimal contagion effects. If the bitcoin bubble crashes, it likely won’t spill out into the general economy, like the subprime mortgage crisis did one decade ago.

Smaller bitcoin bubbles have inflated and deflated before, without any macroeconomic effect. In 2011, the price rose from $1 to $30 and then crashed back to $2 all within the same year. “I wouldn’t be surprised with another crash, followed by another growth in line with transactions,” Catalini said. Indeed, the dot-com bubble was an unambiguous frenzy of speculation and financial malpractice. But 15 years later, many of the business propositions that flamed out spectacularly were reincarnated as successful companies. Chewy.com, essentially a modern incarnation of Pets.com, sold for $3 billion earlier this year.

Fifteen years from now, the blockchain, too, might be an integral infrastructure for the digital world. In this hypothetical world of 2033, bitcoin at $16,000 might be an absolute steal. But we don’t live in “hypothetical-world 2033.” This is still real-world 2017. And bitcoin’s last few weeks are the real-world definition of a speculative bubble.



What is the right way to age? It’s a question that isn’t explored enough in American society, where, seemingly, people are expected to be forever young, until, suddenly, they are not. Reflecting this binary, any writing about a long life’s final decades tends toward extremes. On one hand, there are the accounts of heroic men and women who still put in more than 40 hours a week on the job in their late 60s and early 70s (a genre I like to call “retirement porn”). On the other, there are the articles warning about the dangers of not adapting a home for aging bodies, or the plague of financial scammers targeting lonely or cognitively challenged seniors.

That leaves out a vast middle, the space where many older people actually, you know, live their lives. Luckily, Martha Nussbaum, the renowned philosopher and ethicist at the University of Chicago, and Saul Levmore, the former dean of and a current professor at the university’s law school, decided to explore that middle. The result? The recently published Aging Thoughtfully: Conversations About Retirement, Romance, Wrinkles, & Regret.

The book’s final chapter, “Giving It Away,” discusses what people should do with their money before they die, and how they could arrange for it to be dispersed when they are no longer alive. For The Atlantic’s series on philanthropy, “Who Gives?,” I spoke to Nussbaum and Levmore about these questions, and our conversation touched on why people give money to charity in the first place as well as the benefits of giving those funds to, among other places, the opera. (Spoiler: They disagree.) The conversation that follows has been edited for length and clarity.

Helaine Olen: Why do people give money away both before they die and in their final wills? Are there different motivations in each case?

Saul Levmore: Well, that’s a really good question. Some people give money away, I think, as a way to live forever.

Martha Nussbaum: I think it’s a surrogate immortality, in a lot of cases. People realize that their life is ending, but they want some imprint on the world that is identified with them. Of course, that can take many forms, not just giving money away. It can take the form of building a building, or whatever. But I think the reason that givers to institutions so often want to name a building is they really want their imprint to be on the world in some kind of durable, etched-in-stone way. They don’t want to be forgotten.

Olen: And what are the attractions of giving money away while alive?

Levmore: It’s unsurprising when you see the Bill Gateses of the world give away a lot of money while they’re still alive, because you can watch what people do with it—you can see who’s doing and a good job and a bad job, and then give more to some places than to others, and so forth.

I think most people would prefer to give it away while they are alive and to see the progress that's made. It's just that they’re unsure about their longevity and about their future economic needs. But I think it’s natural to earmark money and have it go for some new building when you die, if you really felt like you have lots and lots of wealth.

Nussbaum: It’s also that people want to give it away before they die in order to avoid the estate tax—which may disappear, shortly. Therefore universities hate the idea that the estate tax would go away. But this is also influenced by social norms. I find that in Europe, it’s much harder to get rich people to give money away, because their peer community of rich people doesn’t honor that, as much.

Olen: So there’s something very American about it?

Levmore: It’s also tax-related. They’re taxed a little bit more heavily than we are during their lives and the taxation system has a very, very strong redistribution element.

Olen: Saul, one of things you talked specifically about in the book is how we discount the pleasure we get from giving money away while we're alive.

Levmore: There are many systems of discounting. First of all, I think it’s thought to be impolite to say how you’ve improved the world by giving money away. So, people are shy to say that. And then, also, I’ve been a donor, but I’ve also been a fundraiser when I was president of the law school for a while, and I think that there’s a sense in which you don’t want to know if people flopped with your money. You give money away, and it goes to some college—maybe your college was better when you were there, but maybe it’s worse than when you were there. You would like to imagine that you’re making the world a better place, and in a funny way, it’s easier to do that when you’re dead. I think, for example, one reason people don’t give more money to their children while they’re both still alive is it would be a shame to give a lot of money to your kid and then watch your kid not go to work every day, or watch your kid misuse the money.

Nussbaum: Suppose you endow a charity, or university. You could put your name on it, but you could also endow it in honor of some teacher you had. People differ. There are people who prefer to be anonymous in their giving, or to put somebody else's name on it. It also poisons your relationship with other people.

Olen: What do you mean by “poisons your relationships with other people”?

Nussbaum: Well, it’s if you seem to be posing as a big shot and you want to be just one among equals—you don’t want your name to be trumpeted.

Olen: In the book, you discuss the distinction between altruism and philanthropy. Can you elaborate on that?

Nussbaum: Oh, sure, because altruism is the desire to benefit others, for their own sake, and not for yours. Now, some philanthropy is very self-interested. I know one opera donor who insists that the money would be used only for works from prior to the 20th century, because she doesn’t like 20th-century music. So, you want to hear what you like—that’s pretty selfish, actually. Philanthropy can have a very strong selfish component.

The other side of it is that disinterested altruism takes many forms. It could just take the form of raising children and grandchildren, or of teaching students—there are all kinds of things you can do to benefit others that really are not giving your money.

Levmore: I saw two views of this. There’s a classic, old-world, religious one: If you’re giving money to an individual, the highest form of charity is that the recipient not know who gave the money, so that they not be embarrassed around you and not feel like you’re exercising control.

On the other hand, in the case of institutions, I know that when I was involved in fundraising, people would sometimes gives gifts anonymously—sometimes to hide it from their spouses, by the way, but sometimes so everybody wouldn’t know they’re so rich. We as fundraisers usually wanted people to attach their names to gifts, because there’s a form of healthy competition among donors and if you get one donor to offer the university a few million dollars, other people in the class might feel motivated to try to do the same if they can afford it. People might be a little more altruistic because the donee encourages it. It’s complicated.

Olen: Do you think philanthropy or altruism is better, or do you think they’re both good or both bad?

Nussbaum: Look, institutions need money and people need money, so it’s fine for them to have incentives for even the most selfish kind of giving. I think it’s just fine that this donor I mentioned wants only one century’s music to be played—you know, somebody’s got to support that and so then the symphony just has to go out and find somebody else to support the other kind of music.

I guess ethically, we would like to think that people will also have a more disinterested and unselfish kind of giving. There’s a very interesting book by Kristen Monroe called The Heart of Altruism, where she comes to the conclusion that there are few very altruists who are totally unselfish, but maybe the quintessential example is the people who rescued Jews during the Holocaust. They not only had nothing to gain, but they were taking great risks of losing their life and also losing their reputation in their very fascist peer community.

Olen: Is it selfish to leave money to your children instead of giving it away?

Levmore: One of the nicest things I remember happening when I was dean is there was a young person, a person of means, and he wanted to endow something but he didn’t want to do it while his children were young. And then it occurs to him to give the money away in order to be an example to his kids—like they could come visit our university and see, you know, how this helped poor people in our clinics, they could see this clinic that was named after their grandfather that their father had given. And they can think, “Wow, this is a good reason to work hard and make money. You can give it away and make the world a better place.” And they can be proud of him.

So I think teaching your children to be proud of being helpful is probably a really good thing for a lot of rich people, even though it tells the kid that you have a lot of money, and even though there might be moments when they think, “Why’d you give away that money? You could have given it to me!” But I think he was proud of it, and it’s nice to see your parents do good deeds. Maybe you’ll react accordingly.

Nussbaum: With inheritances, it’s really important not to give the impression that you’re extorting your children, and one way you can not do that is to make it clear to them that you're not leaving the whole of your estate to them at all, but to various charitable organizations. I think we need to remember that not all children have rich parents and we need to do things to bring about overall social welfare. Hopefully the tax system will do a good deal of that, but perhaps not. So we have to be aware of what might be neglected. In my case, I give a lot to animal welfare because I think that's pretty neglected in America.

Olen: Saul, can I ask who you give money to?

Levmore: I give less money to animals because I know Martha is giving more. I mean, I’m half-joking, but that’s the danger. Because people know you’re giving money to a cause, then that might cause the government itself to give less money to it.

My wife, especially, gives money to organizations that support things she wishes the political system could better address. So, if she doesn’t like their family planning then we give lot of money to organizations that do that. Public schools aren’t getting a lot of money, so she might give a lot of money to public schools if we think they’ll do a good job with the money. Or she might give more money to private schools if we think the competition with the public schools is healthy. So a lot of it is second-guessing what the government does and doesn’t do.

Nussbaum: I think that’s similar, except that I guess I also would give to organizations to which I have particular love and gratitude, like our own university, for example, and the Lyric Opera, in Chicago. So, although I do give some to the St. Louis Opera and to the Seattle Opera, why do I give to the Lyric Opera and not so much to other opera companies? It’s mostly gratitude for the involvement and the performances that I’ve enjoyed over the years.

Levmore: I do the same, but I don’t like it. I wish they’d just raise prices. I would much prefer that they just charge the price to keep it alive and if they couldn’t afford it, then things would close down or there’d be fewer of them. But I’m sure Martha and I disagree about this.

Nussbaum: Well, I disagree because I think the art form is really wonderful and very important and right now prices are already so high that young people are discouraged. So I want, really, to lower the prices.

Levmore: Nothing stops the opera from subsidizing young people if it’s a good investment. I don’t really see why taxpayers as a whole should be supporting the opera.

Nussbaum: They do have programs, not only to include new audiences but to train young singers. But that’s one of the things the philanthropy supports. And maybe that’s not ideal, but …

Levmore: No, I don’t think it's ideal. You know lot of these young singers are children of wealthy people.

Nussbaum: Many trained there are not the children of wealthy people. They win a nationwide audition in which five people win out of about 10,000 that initially complete.

Levmore: You should look at the numbers of where these people come from. Most poor people are immigrant families who wouldn’t want their kids training to become opera singers. It’s not a reliable source of income.

Nussbaum: Most people don’t want their kids to do lots of things. But they do it.

Levmore: They do? Not in my family!

Nussbaum: Ha! Well, I mean, look at my daughter: She’s working for animal rights, making a very, very low income.

Levmore: Yeah, she comes from a comfortable family.

Nussbaum: But what I’m saying is that artists and singers are drawn from all walks of life. Typically, they get their start when they’re in some undergraduate program and they learn that they have this wonderful talent. And then they might come from any kind of income class.

Levmore: Well, they’re wealthy enough to go to college.

Nussbaum: But I mean the state universities.

Olen: I want to jump in—you’re never going to agree on this, right? Let’s talk about why people often give more to charity as they get older.

Levmore: Well, I think there’s less uncertainty—you don’t know how long you’ll live, but you can see that you've saved a certain amount of money, and that you can have a certain amount of income per year, and you know you won’t starve. So you don’t feel this tremendous need to set aside money for yourself for the uncertainty of what’s ahead.

Nussbaum: Absolutely. I agree with that, totally.

Levmore: See, we can agree if we want to!

Olen: On the other hand, they don’t know how long they're going to live, so they still don’t completely know if they are going to need money.

Nussbaum: What most people would want is to stay in their own homes, and have home-based nursing care. They don’t really want to put all that on their children. In Finland, the government provides home-based nursing care, and tries to make it possible for people not to have to move out of their homes. But the U.S. doesn't really make that possible, so people would be right to be scared and hold onto their money. Because if they need nursing care, and they don't want to go to some faceless institution, then they need money for that.

Olen: I want to touch on something else: volunteering as a form of philanthropy.

Levmore: We both love working. So I think that putting a lot of time into volunteering is not particularly in our future. But we admire people who do. There are a lot of people who either didn’t like their careers, or their careers ended, or they worked in careers, who put an enormous amount of effort into working on behalf of other people. And I think it’s super valuable. In a way, it’s more valuable than giving money, because giving money, you must have some information about who you are giving it to, and whether they are doing a good job. But somebody that goes somewhere to build homes, or goes somewhere to care for people who need help, I think it’s really great. I mean, they learn a lot about what they are doing. They learn a lot about themselves.

Nussbaum: I think we have to bear in mind that in previous generations, a large source of volunteering was women who just assumed that they wouldn’t be able to enter the workforce. There were all these wives who never had a career, and they spent all their time doing good works. And that was great. But now women are quite rightly thinking, “Well it’s my life. I can go out and have a career.” But then their time is really at a premium. Especially if they have to do a lot of the child care and maybe elder care too. So we do have a problem of service. These posts are vacated.

I myself favor compulsory national service for young people. And in my next book, I’m going to talk about that. Because I think, among other things, that it gets work done that needs to be done—child care, elder care. But also, young people who have grown up in one social class may get to know other people. They get to know people of different regions, different ethnicities. And it’s something that military service, of course, has always done. But we don’t need to have that. We just need to have some way of taking people out of their comfort zones, and putting them to work helping others in a completely different surrounding.

Levmore: In principle it’s a terrific idea. But in practice, I’m not sure that the government will be good at knowing which areas to push people into, or force them into. There is a danger that we’ll put them to work at senior-citizen homes. And that will provide the people who work in those homes with no jobs and unemployment. It’s very hard to get right. We’d have to do it carefully.

Olen: Are there ways to encourage people, then, to be more philanthropic as they age?

Nussbaum: One thing that people actually already do as they age is take a lot of adult-education courses, particularly in literature and philosophy. So to get them talking and thinking about this kind of issue is, I think, the first step. And then if they’re thinking, “What is the meaning of life?,” then they might take the next step and think, “Well, part of the meaning is to change the world for other people.”

Levmore: I don’t know. In the very, very old days, when income taxes were new, everything about tax was public. People in New York would walk into public places, and everybody would clap, because they would know these people paid a lot in tax. And for a variety of reasons, we’ve since made this information very private. We don’t even know the president’s tax payments. And it’s probably because we are afraid of financial crime, and so forth. But in principle, if you knew how much money everybody gave—in money and time—to good causes, that might really be a good influence on people.



Most people think of charitable donations as happening in one of two ways. In one scenario, people decide how much they want to donate, then select a charity that will be the recipient of the funds. In the other scenario—one only available to the wealthy—a donor can take their money and set up their own foundation, transfer money over to it, have it grow, and then give away money over time, perhaps in perpetuity.

There’s also a third way that combines the first two approaches: It’s called a donor-advised fund, and it lets even small-scale givers put money into an account, let it mature, and then disburse it gradually. Donor-advised funds are becoming such a popular option that in 2015, the Fidelity Charitable Gift Fund, the donor-advised fund set up by the financial firm Fidelity Investments, overtook the United Way to become the largest recipient of charitable funds in the United States.

This development, though, is worrying to some. One leading critic is Ray Madoff, the director of the Boston College Law School Forum on Philanthropy. Last year, she called donor-advised funds “a bad deal for American society” in an essay she co-authored with the New York–based philanthropist Lewis Cullman in The New York Review of Books. The funds are, Madoff and Cullman went on to argue, not just inserting a middleman into the charitable-giving process, but they are also potentially slowing the regular streams of money going from givers to nonprofits.

To understand why a way of giving money to charity could be so controversial, it helps to understand how exactly it works. Donor-advised funds could best be described as a waiting room for charitable donations. People who wish to give money to charity deposit the money in an account with a donor-advised fund, where they can elect a way to invest it, or, if they place enough money in the account (at Schwab Charitable, for instance, it’s $250,000), they can choose instead to have an investment advisor manage their portfolio. In return, they receive an immediate deduction on their taxes for the amount they have “donated” by depositing into the fund, and when they are ready to make their donation (which could be years in the future), they alert the fund, and their money is disbursed to the cause of their choosing. Once the money’s in the account, it can’t be returned to the donor—it then technically belongs to the donor-advised fund.

So why use donor-advised funds instead of giving to a charity directly? For one thing, they allow ordinary people to grow their money over time, and give it to charity as a philanthropist would, like a DIY Bill Gates. Another reason: Perhaps the account holder just wants the tax deduction, and doesn’t feel like selecting a charity at the moment. These funds allow people who earn more money in one year than another to time their deduction, depositing money in the donor-advised fund in years when their earnings permit them to receive a greater tax benefit, and then donating the money to charities over a period of years. Those who are in favor of donor-advised funds suggest this incentivizes people to donate more than they otherwise would; detractors say it’s just another tax advantage for the wealthy.

While donor-advised funds date back to the Great Depression, they weren’t widely promoted by brokerage houses until the early 1990s, when Fidelity sought and obtained a ruling from the Internal Revenue Service that gave it permission to set up Fidelity Charitable. Soon, other financial services firms established similar funds.

According to the nonprofit National Philanthropic Trust, givers put $23.27 billion in donor-advised funds in 2016, a 7 percent increase from 2015 and an 18 percent increase from 2014. That money is spread out among a variety of funds: The Chronicle of Philanthropy’s 2016 survey listed six donor-advised funds in the top 10 charities ranked by donations, including Schwab Charitable, the Vanguard Charitable Endowment Program, and the Goldman Sachs Philanthropy Fund. (Such funds are more popular in the United States than in some other wealthy countries, perhaps because Americans give a greater percentage of their income to charity.)

Another appeal of these funds is that they allow aspiring philanthropists to get started with relatively small amounts of money. Schwab Charitable, for example, requires an initial donation of only $5,000; after that, future deposits (if there are any) can be as low as $500. This allows champions of donor-advised funds to argue that they result in a quasi-democratization of nonprofit foundations. Foundations are expensive to set up and administer, and experts generally say that unless donors are starting with at least $250,000, most would be better off putting money into a donor-advised fund. Since people can deposit more into those funds over time, they offer people who aren’t extremely wealthy a way to build up money in a tax-advantaged way, allowing them to give larger sums when they do finally sign the money over to charity.

But—and this is a big but—someone with a donor-advised account doesn’t actually need to order that the money get disbursed. It can remain invested with the donor-advised fund in perpetuity. This makes accounts with donor-advised funds distinct from foundations, which are required by law to give out 5 percent of their net investment assets on an annual basis. Compounding the issue: Tax laws incentivize donations to donor-advised funds, but don’t do the same thing for actually getting the money into the hands of an on-the-ground charitable organization; the giver gets the tax break in the year the money goes into the fund, not when it’s distributed to charity.

This makes donor-advised funds less than popular among many in the philanthropic community, who have come to believe that their deposits would otherwise be put to immediate use by a charity. “They’re becoming holding tanks for charitable dollars,” complains Alan Cantor, a philanthropic consultant based in New Hampshire. “The money goes out at a very leisurely pace.”

Defenders of the funds dispute that, pointing out that approximately 20 percent of money in the funds is disbursed annually—higher than the 5 percent that foundations are legally required to give out. If people want some flexibility in choosing where their money goes, what’s the harm? “They provide a way for people who want to give away money but don’t know precisely who they want to give it to a chance to make their decisions about how to get the tax benefits in the year they which they get the money, and then specify where the money is going in a later year,” says Joel Fleishman, the director of the Center for Strategic Philanthropy and Civil Society at Duke University.

But there’s another problem with this model, at least from the perspective of charities: When money arrives from a donor-advised fund, a charity often doesn’t know who actually made the donation. This makes philanthropic organizations’ jobs harder, because they can’t cultivate repeat donations. On the other hand, this can be a lure to the giver: For smaller-scale donors, it means fewer solicitations (via both email and physical letters), and for big-money donors, it’s one fewer organization hounding them for money.

The anonymity that donor-advised funds provide is problematic on another level too. It allows givers to obscure their identities. For example, according to The Daily Beast, Project Veritas, the right-wing organization whose mission is to reveal alleged left-wing media bias, received $381,505 from Donors Trust, the right-wing donor-advised fund notoriously supported by the Koch family, and $52,050 between 2011 and 2013 from the Fidelity Charitable Gift Fund. The white nationalist Richard Spencer’s nonprofit, the National Policy Institute, also received donor-advised–fund money prior to the IRS’s revocation of its tax-exempt status. “There’s no direct line between a controversial donor and a controversial cause,” Cantor says.

Yet some of these issues seem like they would not be hard to address. One way to prevent people from putting money into the account, taking advantage of the tax deduction, and then not getting around to distributing it would be to impose a deadline before which all deposits must be disbursed. But when former Michigan Representative Dave Camp introduced tax-overhaul legislation in 2014 that would have required that funds be distributed within a five-year period, the bill went nowhere because, at the time, tax reform did not have sufficient traction.

The problem of anonymity is tougher to solve. That’s because the way the tax code governs donor-advised funds, the money actually belongs to the fund once the donor turns it over, with an agreement that the fund will honor the donor’s wishes as long as the ultimate beneficiary is an officially recognized charity. But as a result, the gifted money is reported as coming from the fund, and if donors don’t want to identify themselves, they don’t have to.

It’d be nice if the government could at least step in to ensure that charities know where they’re getting their money from. Donor-advised funds are not likely to go away anytime soon—a study released by Fidelity Charitable last year found that donors under the age of 50 are much more likely than those over 50 to use donor-advised funds—so tending to problems like these will only become more important as this way of giving gains popularity.



Bitcoin is a bubble.

That much was clear to economists, investors, and analysts for quite some time. But one of the shortcomings of such analysis is that certainty of an economic bubble offers little insight on how, when, or why that bubble will pop. “I can say almost with certainty that they will come to a bad ending,” Warren Buffett said last week, to the great consternation of crypto fans. “When it happens or how or anything else, I don't know.”

Maybe—maybe—it’s finally happening.

The price of bitcoin plummeted by as much as 20 percent on Tuesday to $12,000, or about 40 percent below its all-time high in December. Other popular cryptocurrencies, like ethereum and Ripple, also posted double-digit losses.

What’s the reason? With stock-market analysis, there is sometimes an instinct to invent causality (“stocks fall on X,” “stocks slide amid Y”) when markets are driven by a matrix of inextricable factors. But in this case, the cause of bitcoin’s collapse seems pretty clear. Just as the currency’s hysterical price rise was driven in large part by demand out of China, Japan, and South Korea, its latest fall seems similarly tied to developments in Asia.

South Korean Finance Minister Kim Dong-yeon said the government is considering shutting down cryptocurrency exchanges, or at least introducing new regulations to the nascent crypto market. The Chinese government is also cracking down on bitcoin and other tokens, not only because citizens can use them for laundering money and evading capital controls, but also because the computer power required to process transactions and create new tokens—which is often called “mining”—is extraordinary intensive. The global bitcoin market uses more energy than the nation of Denmark, according to one analysis.

Bitcoin’s price rises and falls like a plastic bag in a hurricane, so it’s silly to attach too much significance to one day’s fluctuation. But today’s news still reveals a subtle crack in the bull case for bitcoin. The digital currency was designed to be stateless and leaderless—“rules without rulers”—to evade single points of failure, and to remain impervious to government control. But the great irony is that bitcoin is plunging today in part because it’s failing on all three accounts.

First, bitcoin is designed so that digital transactions are approved by a network of computers rather than sanctioned by a single government. But its price is so volatile in part because its ownership is quite consolidated. Approximately 40 percent of bitcoin is held by about 1,000 users, and the top 100 bitcoin addresses—some of which may belong to the same person—control about one-sixth of all the issued currency, according to Bloomberg. One reason why bitcoin can fall by 20 percent in a day—which is practically unheard of for most equities, and certainly of most currencies—is that if any one of these huge investors sells, it can move the market. Bitcoin’s extraordinary price fluctuation is possible because ownership of nominally decentralized technology is, in fact, quite concentrated.

Second, bitcoin exchanges—online marketplaces where bitcoins are held and traded—are all potential points of failure. And they fail, all the time. In 2014 thousands of bitcoins were stolen from Mt. Gox, an exchange based in Tokyo. In 2016, bitcoin plunged after an exchange in Hong Kong said it had been hacked. Today, bitcoin plummeted again when several governments threatened to regulate or shut down exchanges based in Asia.

Third, while the cryptocurrency was designed to be stateless and leaderless, state leaders are largely responsible for its latest plunge. The currency requires no central bank, as new tokens are issued by computers running bitcoin software. But bitcoin’s fortunes are still tied to the decision-making of central banks and other government regulators. In late 2013, after several senators praised bitcoin and other virtual currencies at an official hearing as “legitimate financial services,” the value of bitcoin tripled within the month to $900. But government rulemaking giveth and taketh away. On Tuesday, bitcoin’s value fell after a Chinese central bank official reportedly said that the government should ban the trading of digital currencies. Perhaps that’s the most ironic thing about bitcoin: A system designed to distribute value away from individual authorities is exquisitely sensitive to mere rumors about individual regulators.

An asset becomes a bubble when fundamentals yield to FOMO—a “a fear of missing out” on the action. But bitcoin’s FOMO bubble is popping, even as economic fundamentals charge forward. Look at the countries most responsible for bitcoin’s collapse. Both commodity demand and state-enterprise profit in China have reached record highs. Korean stocks have grown by more than 20 percent in the last 12 months, while Japan’s Nikkei Index has popped, growing from about 23,000 to about 24,000 in the last four weeks. Meanwhile, in the U.S., the stock market just screamed past 26,000 for the first time in history. Blockchain might be the technology of the future. But it has practically nothing at all to do with the economy of the present.



In October, the Colorado biotech company Bioptix changed its name to Riot Blockchain. The company’s valuation doubled within a few days.

This might strike you as an extraordinarily bizarre story. But even more bizarrely, it’s becoming ordinary. Weeks later, the British company Online PLC changed its name to Online Blockchain. The company’s shares jumped 400 percent. In December, the Long Island Iced Tea Corporation—which, as you might expect, sold iced tea—rebranded itself Long Blockchain. The company’s shares promptly rose nearly 300 percent. On Tuesday this week, the legacy photography company Kodak announced the launch of KODAKCoin, a “photo-centric cryptocurrency to empower photographers and agencies to take greater control in image rights management.” The stock rose 80 percent in a matter of hours.

It is officially silly season in the land of cryptocurrency. To borrow a reference from the show Portlandia, this is the “put a bird on it” stage of crypto, where seemingly every multinational company, small business, and fledgling entrepreneur is desperately slapping blockchain onto press releases and venture-capital pitches. Some of these companies might conjure an actual consumer business from this exercise in magical word choice. So far, most of them are doing no such thing.

Before we continue, many readers—and, perhaps, many stunned employees at the aforementioned companies—might be wondering: What the heck is a blockchain, anyway?

At the most basic level, it is a record of information stored on a network of computers. When people use a cryptocurrency like bitcoin to buy a pizza, a kilogram of illegal drugs, or a yacht, these digital transactions are approved by a network of computers around the world running bitcoin software. Each batch of these transactions—a “block”—gets a cryptographic code, a copy of which is posted to every computer in the network. These blocks are permanently linked to each other in a “chain” of publicly approved transactions that cannot be edited. Thus, blockchain.

You could say that blockchain is the ultimate “anti-trust” technology. That’s not only because it facilitates transactions between parties that don’t have to trust each other, but also because it doesn’t rely on a single source of power with total control of a market, like old-fashioned “trusts.” That means you could have a currency without a Federal Reserve (as with bitcoin) or run a software program without buying space on an Amazon server (as with Ethereum).

For the last six months, the biggest blockchain story in the world has been bitcoin, whose vertiginous price increase has captured global attention. Some analysts, myself included, have compared the bitcoin boom and the crypto frenzy to the dot-com bubble. In this analogy, bitcoin is akin to a single, fragile dot-com darling, while blockchain is akin to the internet, a potentially revolutionary technology that can survive the obliteration of any one cryptocurrency.

But while this analogy is popular, it has one critical weakness that doesn’t bode as well for crypto. When the dot-com bubble burst, starting in 2000, the internet was very much a mainstream phenomenon. About 50 percent of American households were online, and the number continued to grow even as the NASDAQ imploded. The internet was a technology with relatively obvious implications. At the time, Google was already ranking webpages in search results, Amazon was already a digital store that shipped boxes to front porches, and AOL had already figured out how to bundle news with personal communication, a decade before Facebook improved the recipe. The internet in 2000 had captured our attention; tens of millions of Americans were actually using it. Blockchain has merely captured our curiosity; tens of millions of Americans are merely reading about it.

Bitcoin might be where Pets.com was in 2000—a technological curiosity in search of an enduring business need. But blockchain is not where the internet was in 2000. Even blockchain’s biggest defenders can’t say what the technology’s most obvious consumer use-cases are going to be, because they plainly don’t exist yet. It is possible they never will.

Bitcoin is the most famous blockchain product, but it has little potential to scale. Visa can handle 60,000 transactions per second. Bitcoin can barely handle 10. Another popular use-case, called “smart contracts,” can automatically execute agreements like stock investments without relying on the inefficiencies of brokers, lawyers, and paper contracts—slow-witted humans. But one such smart investment vehicle called the Distributed Autonomous Organization was felled by a software bug that accidentally made a damaging investment worth tens of millions of dollars. The members had to reconvene and vote to amend the contract to take their money back. It turns out humans can be useful, slow wits notwithstanding. Several people have emailed or approached me in the last few months about blockchain’s application for local reporting. I have taken great pains to understand the promise of this idea. But the term “blockchain journalism” still reminds me of a romantic couple where you are technically fond of both people but have no idea what they’re doing together. Is it altogether possible that a distributed, anonymous ledger is simply an elegant mathematical solution in permanent search of a human problem.

To be fair to blockchain and its advocates, some inventions are coy about their utility. Four decades passed between the first prototype of the internet at the U.S. government’s Advanced Projects Research Agency and the first web browser. Seven years elapsed between the invention of the transistor and its first major commercial application in the transistor radio. Perhaps in a decade, blockchain will find its purpose.

One of the crypto start-ups that makes the most sense to me is Filecoin. Like an Airbnb for data storage, the company proposes to use latent storage on computers around the world to replace or supplement data servers, which are more vulnerable to hacking and other disruptions. The company has created its own cryptocurrency, called filecoin, to pay users to join the community. (Users could theoretically hold these tokens as an investment, exchange them within the network, or sell them for dollars.) By decentralizing data storage in this way, the company says it can improve the resilience of the internet and make it harder for governments to shut down access to certain sites and apps. In September the company raised more than $200 million in an initial coin offering, or ICO, the largest in history.

Will Filecoin revolutionize data storage? Who knows. The investor appetite in all things blockchain will encourage an orgy of trial and error. It is inevitable that many of these ideas will shortly prove themselves to be pointless. But that’s the nature of this phase of experimentation. There will be more blockchain startups for payments, banking, escrow contracts, legal documents, intellectual property, investment strategies, voting systems, and more. The crypto industry may get smarter. But on the way there, things will probably get dumber.  



In November 2016, shortly after the presidential election, students from six U.S. universities appeared in a promotional video titled “You Are Welcome Here.” Their message intended to reassure the one million international students already in the country—and the ones who might be rethinking their plans—that they were still valued.

Today, more than 300 schools participate in the #YouAreWelcomeHere campaign. But as students return to campus for the fall semester, shifting immigration policies have put that message in doubt.

Some of those policy changes have affected the F-1 visa, which allows international students to stay after graduation to pursue additional training. Students who participate in a federally designated university program in  STEM can remain for up to three years, for what’s officially known as “optional practical training.” In order to qualify, they have to line up jobs before graduating, then submit training plans for approval by their schools.

Later, those scientists and software developers may either apply for an H-1B visa or return to their home countries with substantial work experience. For those who hope to secure an H-1B visa, which allows foreign-born people with specialized skills to work in the United States, the odds are low. There are only 85,000 of the visas available each year. Big outsourcing companies have learned to game the system, and the 20,000 slots set aside for international students who earn a master’s degree in the U.S. fill up quickly. Because people can reapply each year, those with an F-1 visa who remain for their STEM training essentially get more chances to win the H-1B lottery.

The training program, which was created in 1992 and extended the amount of time STEM graduates can participate in 2016, is popular with both international students and the U.S. universities that compete to enroll them. Though the H-1B visa is better known, there are many more F-1 visa recipients—nearly 400,000 last year. (Unlike the H-1B, the F-1 does not have a strict cap.) Under the Trump administration, though, the program increasingly appears under threat.

Recent administrations have described an ongoing shortage of STEM graduates as an urgent problem; the Bureau of Labor Statistics estimates that there will be 1 million job openings in computer occupations—the field expected to dominate STEM growth—from 2014 to 2024. But even though a growing number of students in the U.S. are earning bachelor’s degrees in computer science, they can’t keep pace with the number of available jobs.

The F-1 program has provided one avenue to do so. In the past, graduates participating in optional practical training could work in the U.S. for only one year. In 2008, though, the George W. Bush administration extended the amount of time international students in STEM optional practical training could stay, from 12 months to 29 months. In 2016, the Obama administration extended the window further, to 36 months. As a result, the number of international students in STEM fields approved to work in the U.S. after graduation jumped from about 34,000 in 2008 to 172,000 in 2016, according to the Pew Research Center, in an analysis of 1.5 million college graduates who participated in the optional practical training program between 2004 and 2016. Despite concerns about fake universities and visa fraud, the Pew research shows that the vast majority of graduates in the optional practical training program attend public universities or private, nonprofit colleges, not for-profit schools.

Last year, President Donald Trump directed Betsy DeVos, the secretary of education, to make promoting high-quality STEM and computer-science education a top priority. But when it comes to developing a STEM workforce, Trump has been most intent on training Americans, in particular. In July, he signed an executive order establishing a National Council for the American Worker, focused on “the skills crisis and the importance of STEM education.” The order quotes Trump as saying, quite explicitly, “We want to make sure that we have the workforce development programs we need to ensure these jobs are being filled by American workers.”

Partly because of stricter immigration policies but perhaps also because of Trump’s rhetoric, the number of F-1 visas is down 17 percent from 2016, and well below the recent peak of nearly 645,000 visas in 2015. The U.S. government does not disclose how many applications it receives or how many it rejects. In August, chief executives of companies such as Apple, JPMorgan Chase & Co., and Pepsico sent a letter to D.H.S., saying that making it harder for high-skilled workers to stay in the U.S. will hurt the economy.

The consequences of violating the program’s terms are also becoming more severe. The U.S. Citizen and Immigration Services agency recently issued a policy memo that changed how it calculates the length of time that students on F-1 visas would be considered unlawfully residing in the United States, allowing for more punitive penalties. The longer a person stays unlawfully, the greater the penalty, which can range from being barred from the U.S. for three years to up to 10 years. About 6 percent of all F visa holders—who include F-1 recipients, their spouses and children, and students who commute from Canada or Mexico to attend U.S. colleges—stay longer than legally permitted.

The Trump administration narrowed the employment options for F-1 visa holders, through a quiet edit, in January, to the Department of Homeland Security website. According to the new program description, students could no longer qualify for the F-1 visa if they work for a staffing or temporary agency that will send them to a client’s job site. They had to receive their training at the office of the company that hired them. The D.H.S. said the change provided more oversight and helps to ensure students fulfill their training plan. Students, employers, and schools could be penalized for failing to comply. It’s not clear what percentage of people with F-1 visas work for staffing agencies. Following a lawsuit by ITServe Alliance, a trade association representing those agencies, the D.H.S. again modified its website in August, removing most of the new language but leaving unclear how the rules will be enforced.

Some American tech workers have objected to the optional practical training program, saying that it unfairly increases competition. The Washington Alliance of Technology Workers, a union local representing Microsoft contract employees, sued the D.H.S. over the 2016 rule that allowed STEM graduates to stay in the U.S. longer, arguing that it discriminated against American tech employees. (The case is pending in U.S. District Court in Washington, D.C.) In 2014, the four largest employers of those enrolled in the optional practical training program were Amazon, Intel, Qualcomm, and Microsoft.

Any broad argument that skilled foreign workers hurt U.S.-born ones, though, is probably overstated. Some research indicates that holders of H-1B visas, which many STEM graduates hope to eventually secure, depress the earnings of American workers. It’s hard to argue, though, that U.S.-born workers in STEM fields are hurting for jobs. In August, the unemployment rate for workers in computer and mathematical occupations was 2.5 percent. For workers in the life, physical, and social sciences, the unemployment rate was also 2.5 percent; for architects and engineers, 1.3 percent.

Meanwhile, the downsides of diminishing the program are clear. Since 2016, universities have increased their efforts to have programs listed as STEM-designated by the D.H.S., to better compete for international students—even in areas that haven’t traditionally been thought of as belonging to that category. Yale, Princeton, and Brown have reclassified their economics majors as STEM programs. The University of Illinois at Urbana-Champaign did the same for its graduate accounting programs. (To earn the designation, programs often have to redesign their curriculum, and they generally need approval from state boards of higher education.)

The University of Wisconsin-Madison advertises that two of its specialized MBA programs, in operations and technology management and supply-chain management, were the first U.S. MBA programs to earn STEM designations. Greg DeCroix, the director of the MBA in supply-chain management, told me in an email, “We are seeing very high-caliber international applicants these past few years—excellent academic credentials and great work experience—and we believe the STEM designation has contributed to that.”

The fate of the optional training program could be critical for universities. International students make up about 80 percent of full-time graduate students in the United States in electrical engineering and computer science, and faculty rely on them for research assistance. For many U.S. universities, cautions the National Foundation for American Policy, a nonprofit research and public-policy group, the loss of many international students from STEM fields, due to the shrinking of the F-1 program or other policies, “would cause science and engineering programs to shrink or disappear.”

That would leave the U.S. less prepared to compete globally and to develop its own workforce. China and the U.S. are vying for dominance in artificial intelligence, which requires computer-science training. The U.S. lags countries such as South Korea and Germany, according to an Economist Intelligence Unit study, in preparing students to work with computational thinking, AI, and robotics.

The unpredictable changes to the STEM training program fit the Trump administration’s pattern of making it more difficult for noncitizens to visit or live in the U.S: the travel ban, the decision to end the Deferred Action for Childhood Arrivals program, the separation of migrant families at the border; the D.H.S.’s plans to rescind the International Entrepreneur Rule, which allowed foreign-born entrepreneurs to stay in the United States legally for up to five years.

In October, the National Foundation for American Policy raised concerns that the White House could try to eliminate the STEM optional practical training program entirely. It cited the administration’s “Buy American and Hire American” executive order, implemented last year, which gave the D.H.S. a broad mandate to “protect the interests of United States workers in the administration of our immigration system.” That position paints immigrants as an economic threat; in fact, historically, they have been an economic engine. Other countries recognize this: Even as the U.S. makes it harder for universities to attract foreign-born students, Germany is working to enroll more of them. It’s an issue the U.S. will have to figure out, and soon—before high-value jobs go unfilled.



Last month, Bloomberg reported that Jeff Bezos, the founder of Amazon and owner of the Washington Post, has accumulated a fortune worth $150 billion. That is the biggest nominal amount in modern history, and extraordinary any way you slice it. Bezos is the world’s lone hectobillionaire. He is worth what the average American family is, nearly two million times over. He has about 50 percent more money than Bill Gates, twice as much as Mark Zuckerberg, 50 times as much as Oprah, and perhaps 100 times as much as President Trump. (Who knows!) He has gotten $50 billion richer in less than a year. He needs to spend roughly $28 million a day just to keep from accumulating more wealth.

This is a credit to Bezos’s ingenuity and his business acumen. Amazon is a marvel that has changed everything from how we read, to how we shop, to how we structure our neighborhoods, to how our postal system works. But his fortune is also a policy failure, an indictment of a tax and transfer system and a business and regulatory environment designed to supercharging the earnings of and encouraging wealth accumulation among the few. Bezos did not just make his $150 billion. In some ways, we gave it to him, perhaps to the detriment of all of us.

Bezos and Amazon are in many ways ideal exemplars of the triumph of capital over labor, like the Waltons and Walmart and Rockefeller and Standard Oil before them. That the gap between executives at top companies and employees around the country is so large is in and of itself shocking. Bezos has argued that there is not enough philanthropic need on earth for him to spend his billions on. (The Amazon founder, unlike Gates or Zuckerberg, has given away only a tiny fraction of his fortune.) “The only way that I can see to deploy this much financial resource is by converting my Amazon winnings into space travel,” he said this spring. “I am going to use my financial lottery winnings from Amazon to fund that.”

In contrast, half of Amazon’s employees make less than $28,446 a year, per the company’s legal filings.* Some workers have complained of getting timed six-minute bathroom breaks. (Amazon said it does not track or limit employee bathroom use.) Warehouse workers need to pick goods and pack boxes at closely monitored speeds, handling up to 1,000 items and walking as many as 15 miles per shift. Contractors have repeatedly complained of wage-and-hour violations and argued that the company retaliates against whistleblowers. An Amazon temp died on the floor just a few years ago.

The impoverishment of the latter and the wealth of the former are linked by policy. Take taxes. The idea of America’s progressive income-tax system is that rich workers should pay higher tax rates than poor workers, with the top rate of 37 percent hitting earnings over $500,000. (The top marginal tax rate was 92 percent as recently as 1953.) But Bezos takes a paltry salary, in relative terms, given the number of shares he owns. That means his gains are subject to capital-gains taxes, which top out at just 20 percent; like Warren Buffett, it is possible he pays effective tax rates lower than his secretary does.

Moreover, Amazon itself paid no federal corporate income taxes last year, despite making billions of dollars in profits. It has fought tooth-and-nail against state and local taxes, and has successfully cajoled cities into promising it billions and billions and billions in write-offs and investment incentives in exchange for placing jobs there. (Given that Bezos is a major Amazon shareholder, such tax-dodging redounds directly to his benefit.)

Or consider the country’s low minimum wage, a policy that again benefits corporations at the expense of workers. Amazon’s starting wage is about $5-an-hour below the country’s national living wage, and its median full-time wage is a full dollar below it as well: The company is profitable and has money to invest in operations and expansions because its labor force is so cheap. Of course, it is not cheap for the taxpayer, which ameliorates the effects of poverty wages with policies like the Earned Income Tax Credit, Medicaid, and the Supplemental Nutrition Assistance Program. One in three Amazon employees in the state of Arizona is reportedly on food stamps.

Noncompete agreements are another tool Amazon and other big companies use to suppress the costs of labor and to bolster their bottom lines, to the benefit of major shareholders. Amazon’s contracts have required employees to promise that they will not work for any company that “directly or indirectly” competes with Amazon for 18 months after leaving the firm. Given the breadth of the Amazon’s business, that means taking a job with Bezos might have meant turning down a future job not just at Walmart, but also at postal companies, logistics businesses, warehouses, and retailers. “Amazon appears to be requiring temp workers to forswear a sizable portion of the global economy in exchange for a several-months-long hourly warehouse gig,” The Verge, which reported on the contracts, argued. (Amazon said it does not currently have warehouse employees sign noncompetes.)

Such non-compete and no-poaching clauses used to be common only among executives and other high-income workers, but now roughly one in five workers are covered by them; more than half of major franchise businesses, like McDonald’s, include no-poaching agreements in their contracts. This suppresses wages by reducing competition for workers—and is now seen as one of several reasons wage growth has been so sluggish during the recovery.

Stripping workers of the right to move among employers is just one way that Amazon and other big businesses are flexing their monopoly and monopsony power—again with Uncle Sam helping companies at the expense of workers. Amazon’s dominance in e-commerce, particularly in markets like book-selling, has given it pricing power to squeeze both the companies it purchases goods from and its own employees. A recent study by The Economist found that Amazon opening a fulfillment center in a given community actually depresses warehouse wages: In counties without an Amazon center, warehouse workers earn an average of $45,000 a year, versus $41,000 a year in counties with an Amazon center. The data also show that in the two-and-a-half years after Amazon opens a new fulfillment center, local warehouse wages fall by 3 percent.

“In local labor markets that are highly concentrated, concentration contributes to lower wages,” said Sandeep Vaheesan, policy counsel at the Open Markets Institute, a Washington think tank that studies market competition. “Amazon wields a great deal of power over both its workers and its suppliers. Where Amazon distribution centers are located, especially in rural and more exurban areas, they are one of the powerful local employers and likely have a great deal of wage-setting power—and so they can depress wages below what would exist in sort of more competitive and less concentrated market.”

Finally, there is the decline of unions. Since its founding nearly three decades ago, Amazon has again and again sought to prevent the unionization of its workforce, a development that would likely bolster wages and improve working conditions. Amazon has reportedly shut down operations where workers were seeking to organize, fired employees advocating for unionization, hired law firms to counter organizing drives at warehouses around the country, and given managers instructions on how to union-bust. (It has denied retaliating against workplaces seeking collective bargaining.) At the same time, the government, in its regulatory bodies and the courts, has again and again sided against unions and in favor of business owners.

All of these trends have have shifted income upward, suppressing worker power and helping people higher up on the income ladder turn simple earnings into self-perpetuating, ever-growing wealth. “The period since 1973 has been characterized by falling purchasing power of the minimum wage,” said Mark Price, a labor economist at the Keystone Research Center. “It’s been characterized by a rapid decline in union density and by the falling top tax rate. It’s been characterized by no-poaching agreements among low-wage service employees.” As such, he said, it has been characterized by spiraling wealth and income inequality.

In recent months, the Trump administration has tilted policy to enhance these decade-long trends, rather than to counter them. President Trump himself has hammered Amazon for not paying high enough postage rates, and taken Bezos to task for the Washington Post’s Pulitzer-winning coverage of his administration. Yet his White House has slashed taxes for corporations and the rich, rather than for middle-income workers, all while preserving loopholes and deductions for investment income. It is now reportedly seeking to give away another $100 billion to investors via a capital-gains tax cut. It has reduced companies’ regulatory burdens and appointed the most pro-business Supreme Court in history. It has declined to push for higher minimum wages, or stronger workplace protections.

The result of these decades of trends and policy choices is that Jeff Bezos has accumulated a $150 billion fortune while the average American family is poorer than it was when the Great Recession hit. Concerns about such astonishing levels of inequality are not just about fairness, nor are they just sour-grapesing about runaway success. The point is not that Jeff Bezos himself has done wrong by accumulating such wealth, or creating such profitable and world-changing businesses. But wealth concentration is bad for the economy and the country itself, and the government has failed to counter it. Rising inequality fuels political polarization and partisan gridlock. It slows economic growth, and implies a lack of competition that fuels economic sclerosis. It makes the government less responsive to the demands of normal people, potentially putting our very democracy at risk. Bezos’s extraordinary fortune shows that the game is rigged. He just happened to play it better than anyone else.

* This story originally identified $28,446 as the median pay for domestic workers. In fact, that figure is not limited to employees in the United States. We regret the error. 



When Leigh Radford was young, her father worked in logistics at Procter & Gamble, formulating new products and technologies for Pringles. Radford’s mother worked as an educator at the University of Cincinnati, specializing in early-childhood education. Later, Radford worked for Eastern Air Lines, which would become Continental Airlines, before going on to get her master’s in business administration and rising through the Procter & Gamble ranks to become the vice president of P&G Ventures. I spoke to Radford about her career choices and finding a job that combines the left and right brain. This interview has been edited for length and clarity.

Lola Fadulu: What was your first job out of college?

Leigh Radford: I went to the University of Florida for my undergrad degree. I went down there specifically because I wanted a big university with a lot of options. I went for advertising. After graduating, I went into the airline business. I started at Eastern Air Lines, which was right after deregulation, so it was a big opportunity—a little risky at that time, but I had a passion for it. After Eastern Air Lines, it turned into Continental Airlines. Then I decided to go back to business school and went to Northwestern. Then I was recruited into Procter & Gamble.

Fadulu: Were you on the marketing and business side when you were working for Eastern Air Lines?

Radford: I started in sales. Eastern Air Lines, at that time, when in my early 20s, had gone through multiple strikes, and later bankruptcy.

I gave the example to a friend recently about my Eastern Air Lines experience when we went through the bankruptcy. The airlines stopped. I was 22, and I was pulled onto the tarmac to bring in a 757, because everyone had walked off. All the gate agents, all the machinists, all the tarmac workers. You just get the job done, and we went out there and did it. And you learn a lot—I mean everything. We went from 150,000 employees to 1,500 overnight, and all of a sudden it’s about cleaning the bathrooms since you don’t have janitorial service, it’s about writing personal paychecks to try to keep the airline afloat. And when you learn that at that young of an age, it was a fantastic opportunity, but I also realize and I never take for granted what it’s like to also be beside individuals who have worked for the company 30 years with an underfunded pension. Really, the quality of the companies you work for and the obligation of leaders to take care of employees became very evident very early in my career.

Fadulu: Did you have any jobs before working for Eastern Air Lines?

Radford: I’ve been working since I was 13. Everything from babysitting to being hired for the athletic association for my school to being a lifeguard. And I think one summer I worked three jobs. I did that because I believe in a strong work ethic. I just love that sense of independence and figuring things out and being self-driven. So that’s where it all started.

Fadulu: Were there any specific professions you wanted to have when you were growing up?

Radford: I always knew I wanted to combine the left brain and right brain—the creative with the business. I always wanted to explore the world around me.

Fadulu: How much time passed between graduating from UF and starting at Northwestern for business school?

Radford: I was three years in the airline industry before I went to Northwestern.

Fadulu: Why did you decide to go back to school?

Radford: I always knew I wanted to go for an MBA. I took my test when I was an undergrad, so I think I always knew that was going to be part of my plan. Three years seemed about right. Also, living through Eastern Air Lines and then the consolidation with Continental, I realized that this was a good time. I took a leave of absence. I graduated in ’91 from Northwestern, and at that time it was right during the Gulf War, and the airline industry was volatile. P&G came knocking, and I felt like I needed to take the opportunity to really solidify myself in a good company. This goes back to my father, where there wasn’t a day he did not get up and have a respect for Procter & Gamble and his job and his career. Given the fact that the airline was different than that, I wanted to experience that. I wanted to be part of a really well-operating, well-respected company after leaving school. That’s when I decided to come to P&G.

Fadulu: You grew up seeing your dad work for P&G. When you started working there, how much of it was how you expected and which parts of it surprised you?

Radford: I always felt that I wanted to go faster, further, and I sometimes felt that not everyone was running at the same pace. I think there was a learning curve on that, but that happened very early on. And then what I realized is if I was really clear with what I was trying to do for a certain business or brand, and got the right level of data, support, and passion, nothing was impossible.

I tend to innovate, no matter what business it is, and find new ways of making things happen. If you have an idea, you still have to sell your idea. I really pushed for things that never existed before, and that was my mainstay.



At the age of 17, LeVar Burton was on a path to the priesthood, having entered seminary three years earlier. But Burton began questioning the Catholic point of view, and he did not receive satisfying answers from his elders. He decided to change his trajectory, and landed on acting.

Two years later, as an undergraduate at the University of Southern California, Burton got a role acting alongside Cicely Tyson and Maya Angelou in Roots, the TV miniseries. “They schooled me,” he said. He’d go on to act in Star Trek: The Next Generation and to host PBS’s Reading Rainbow.

I spoke to Burton recently about serving the greater community, his calling to the priesthood, and his advice for young people dealing with the challenges that can come with extraordinary success. This interview has been lightly edited and condensed for length and clarity.

Lola Fadulu: You were born in Germany. How long did you live there?

LeVar Burton: We came back to the States when I was a year old, and then went again when I was in the third and fourth grade for another two years. So it is [my father’s] second tour of duty that I actually remember.

Fadulu: What do you remember about it?

Burton: Oh my gosh, I remember so many things. I remember our first apartment, which was what they called “on the economy,” which simply meant that it was in town. It wasn’t on the military base itself. This was the 1960s and the Allies had been in Germany since the end of World War II, so there was a constant influx of GIs and their families going there. I remember the beer man who came and delivered beer, just like they delivered milk.

Fadulu: Did your parents talk to you about their jobs often?

Burton: My mom talked a lot about not necessarily her job, but her belief that one’s life should be a service to the greater community. That was certainly something I picked up and absorbed. Most of the people in my family are in the field of education in one way or another. It’s kind of the family business. We are also a family that really values education, puts a very high premium on education and its value in society and for individuals. I personally believe that education is the key to freedom.

Actually, literacy is the key to freedom because you can educate yourself. But my mom didn’t talk a lot about her job, because she worked in a [federal program] that at that time was called AFDC. AFDC stood for Aid to Families With Dependent Children, so she worked with a lot of women who were then, as today, escaping situations that involved abuse, and she was really trying to help these women and their families get back on their feet after some catastrophic event that had obviously caused them to lose their balance. She didn’t talk about those cases specifically, because, No. 1, it was inappropriate because that’s confidential information and, No. 2, it wasn’t age-appropriate conversation either.

Fadulu: As a child, you were hearing about the importance of serving the greater community and of education. Did you ever push back on those life philosophies?

Burton: You did not push back where Irma Jean Christian was concerned. I’m sorry, that was just not an option. I don’t know how you were raised, but in my family, we did not push back on our mother. My first career choice was the Catholic priesthood.

Fadulu: Can you tell me a little bit about entering the seminary to become a priest?

Burton: It was all initiated by me. I had a calling. I felt like that’s how I was destined to spend my life, and so I took steps as early as I could in that direction, and my mom was very supportive. I entered the Catholic seminary at the age of 13 in Northern California. I began my formal training as an initiate into the order of the Society of the Divine Savior. I was there for four years. During my time there it actually shifted its focus from being solely a seminary to also being a college-preparatory program.

Fadulu: What is the most important thing you learned from your four years in seminary?

Burton: That I didn’t want to be a priest. I had a lay teacher who was neither a priest nor a brother who taught my favorite subjects, a man named Lee Bartlett. He was the English teacher, he was the drama coach, he also taught philosophy, and he opened up my mind to ways of looking at the world that were separate from the Catholic point of view, and a lot of it made sense to me. I had a lot of questions that the Catholic saints and the dogma of the Church could not answer. So I decided that I needed to find some other focus for my life at the ripe old age of 17.

Fadulu: How did you go about finding that other focus?

Burton: I sort of took inventory: What did I feel like I was good at? Where did I find some passion, some juice, in my life? And the answer was theater arts. It was the not-being-afraid-to-be-onstage part that I found I was good at. I had a natural affinity for acting and public speaking.

Fadulu: Were you nervous at all about finding a job in acting postgraduation or during your summers?

Burton: I wasn’t, no. I’m sure my mom was. But I had gone from wanting to be a priest to being an actor. I’m sure she had some concerns about both of those choices, but she never let on. She always showed a face of loving support.

Fadulu: Did you have any jobs in college?

Burton: No. My first day as a Bachelor of Fine Arts major in drama at the University of Southern California in Los Angeles, they made an announcement: “If you want to be a B.F.A., if you want a Bachelor of Fine Arts major”—and there were only two places that really offered a B.F.A. in drama at the time, USC and Carnegie Mellon—“If you want to do this, then you’ve got to commit to it. You will not have time to hold down a part-time job. You will not have time to go out for a sport. You will not have time to join a fraternity or sorority. You will be spending every waking moment in these environments, and you will be busy.” And they were right. But before I went to USC, the two summers before, I worked at Mr. B’s Formal Wear in Sacramento, renting tuxedos to wedding parties and proms. I had to wear a tuxedo every day.

Fadulu: What was it like getting Roots in college?

Burton: Are you kidding me? My life was changed forever. My first day as an actor, Cicely Tyson played my mother, Maya Angelou played my grandmother. I was 19, and they embraced me as a peer. They schooled me. They certainly taught me what it meant to be a professional, but they assumed that because I was there I belonged there, and they treated me as such. It was an extraordinary experience for a young person.

Fadulu: What did they teach you about what it meant to be a professional?

Burton: So many things that it’s impossible to list. For instance, the importance of being on time; the importance of knowing your dialogue, knowing your lines; the importance of treating everybody with respect. Just things that they don’t teach you in college.

Fadulu: Do you have any advice or tips for young people who are dealing with the stresses of extraordinary success?

Burton: Extraordinary success at a young age is incredibly challenging. My advice would be to make knowing yourself, discovering yourself, and engaging in a rigorous process of introspection and personal growth your primary focus because it’s only through a foundation of knowing who you are that you’ll be able to maintain your balance in a very unstable and destabilizing career.



In the United States Barista Championship, baristas have 15 minutes to make and serve espressos, cappuccinos, and a unique coffee drink for judges. Lemuel Butler, 48, has won more coffee championships than nearly any other barista.

While he’s now a co-owner of Black and White Coffee Roasters, and has worked at Counter Culture Coffee for more than a decade, he entered the world of coffee relatively late in life—after working at a gas station and Hardee’s, among other places. I recently spoke to Butler about what he’s learned about people from working in the service economy, his decision to drop out of college at the University of North Carolina where he’d been studying politics and government, and that time his hip-hop band opened for The Roots and Busta Rhymes. This interview has been lightly edited for length and clarity.

Lolade Fadulu: What kinds of jobs did you have before your first job as a barista?

Lemuel Butler: I had tons of jobs. It was a whole other life before coffee. I started in music as a kid. Then when I got to college, I just kind of dropped the formal training, like classical music and jazz, and picked up guitar and piano and DJ-ing. In college I had opened a music and video store. And that kind of morphed into an old-school hip-hop band. We passed our CDs to all these college radio stations, and got invited out to do all these shows. We ended up opening for The Roots, Outkast, Busta Rhymes...

Fadulu: What was the name of your group?

Butler: Sankofa. The night kind of lifestyle wasn’t for me. So I wanted to change gears, and the first job I saw in the newspaper was for a coffee shop.

Fadulu: Let’s go through the tons of jobs you had. What was the first one?

Butler: I had a paper route. I worked for The News and Observer. Imagine this 10-year-old kid biking around the neighborhood, doing his papers, and then at the end of the month, knocking on doors, collecting everyone’s money that they owed me. That was the tough part, because a lot of folks thought they can get one over on a 10-year-old kid, and be like, “Yeah, I don’t have it today; come back next week.”

Fadulu: What next?

Butler: My dad got me a job working at a gas station. The gas station was near the fairgrounds and it was owned by this family. You actually paid at the window, and the window was a part of a trailer, and the family lived in this trailer. My job was to clean up the parking lot.

And that guy was also a carpenter and he needed an assistant. He would fix floors. He would replace carpet. He would fix whatever a mobile home needs. Like the fake wood panels inside of the trailer, he would replace those, if someone kicked a hole in one or something. So I would go around with him, fixing up trailers.

That was my introduction to country music, because that’s all he listened to. I got into country a little bit, the whole summer. I was 13 at that point.

Fadulu: I’m just thinking about 13-year-old you walking around, listening to country music with this guy in a trailer park.

Butler: I had a pretty afro, too. It’s like, this big white dude, he weighed probably 300 pounds, and this little 13-year-old kid with an afro from the hood, listening to country music, going to fix up mobile homes.

There was this older white guy who lived in this stone house across the street. He would always sit out on his porch, and whenever I’d finish, he’d call me over. He had these apple trees, and he would give me a basket of apples if I just sat there and listened to him. He liked to tell me the history of Raleigh and how it’s changed.

Fadulu: Then what?

Butler: The banquet hall was at 14. That was when I “got the big bucks rolling in.” I was making $3.18? I remember putting food out, burning my hands, and standing along the wall with the other folks, waiting for everyone to finish eating. And then we would go collect their plates for them and send them to the dishwasher.

Fadulu: I’ve been to a couple of events where there’s food, and I’ve definitely been at tables where people were very sloppy eaters. Did you encounter any of that, where it was sort of, “Really? Come on,” when you were collecting the plates?

Butler: I think it was more of, like, “Wow, you didn’t eat all that steak? That’s messed up.” I would’ve crushed that. Things were really hard to come by with my family growing up. So I would always notice how wasteful people were.

Fadulu: What’s another job you had?

Butler: I was at Hardee’s. I was a cashier. And they did this outsourcing to the women’s prison, so you’d have these women prisoners making biscuits every Saturday and Sunday morning. And I’d be hanging out with them. I don’t think I stayed there longer than two months because someone had pooped in the women’s bathroom on the floor, and they told me to clean it up. And I quit that day. I think I was 17 at this point.

Fadulu: Are there any conversations with the women prisoners that you remember, or some lessons that you learned?

Butler: Don’t go to prison. They always told me to stay in school.

Fadulu: Why did you decide to study politics and government at UNC?

Butler: In addition to the women prisoners who told me to stay in school, my parents were always saying, “You’re going to college, you’re going to college.” I was the first one to go to college. But once I got there, my parents were like, “Okay, see you later. Let us know if you need anything.” I’d finally arrived, I’d made it, I achieved this goal—but there was nothing after that. What do you do when you get to college?

You’ve got to declare a major. So it’s like, “Well, my uncle, he’s a lawyer, and he’s really cool. I’ll go to law school.” But what I found when I got to UNC was you had to take all these general college requirements. It just felt like high school all over again, except you’re on your own. And I just hated it. Halfway through, it’s like, “Yeah, college isn’t for me. I probably won’t go to law school. So I need to figure out what I want to be before I waste any more time.” So I left.

Fadulu: So you took a job as a barista, and then you started really getting into the coffee industry. Was there a point where you felt you went from being a normal barista to one of the world’s best baristas?

Butler: (laughs) I mean, 15 years seems like a long time, but literally it seems like just yesterday I was in the middle of a really tough shift at the Daily Grind, sweating it out, wondering if there was ever going to be any end to the morning rush.

I feel like things come a little more natural now as far as understanding coffee. I have way more knowledge now than I did starting out at the Daily Grind, just knowing where coffee comes from, different coffee varieties, the different nuances. Pulling a certain coffee variety from one country and planting it in another country, that alone is going to affect how that coffee tastes in the end, in addition to processing, shipping, sitting around in a warehouse, and then roasting, and then what a barista does with it.

Fadulu: How did you get to owning your own store, along with your co-founder Kyle Ramage?

Butler: Kyle and I were very fortunate in our situation. He was my coach in 2016 for the U.S. Barista Championship, and I won, and we both went to Ireland to compete in Worlds, him as my coach.

We walked into cafes in Ireland and we went, “Oh, these are really cool shops.” I like this shop because the equipment’s all white, and he’s like, “I like this shop because the equipment’s all black.” And then we came up with this idea of having a café called Black and White Café.

One of his old professors had a café and roastery. He asked Kyle if he wanted to purchase it. Kyle said, ‘This is our chance.’

So we formed Black and White Coffee Roasters and bought Back Alley Coffee Roasters, which had a café and a roasting production facility. We just rebranded everything and brought to the table what we’ve learned over the past 10 to 15 years about coffee.

We felt like there was a bit of pretension that comes with specialty coffee where there’s this kind of elitist circle of people that enjoy the flavor notes of Geishas and Bourbons, and the average coffee drinker is like, ‘Uh, what? I just want some cream and sugar in my coffee.’ Anything black and white is pretty simple and straightforward, and we wanted to do that with coffee.

Fadulu: Was there anything from these different jobs in the service industry that was helpful for you working in the coffee industry, specifically?

Butler: Coffee is all about bringing people together. People come together in the coffee shop; people come together in these competitions. Even on the farming side of it. I study Central American politics, and my first place that I went to see coffee grow was in Nicaragua. I saw how former Sandinistas and former Contras were working together in a co-op in order to get their coffee out of the country. They fought each other in the civil war, and now they’re working together over this thing called coffee.

All these jobs that I’ve had, I’ve seen people in all kinds of incredible, different lives. Whether it’s on one side of the counter or the other, you get to know people the more and more you work with them.

Fadulu: What have you gotten to know about people?

Butler: We’re not loners. We need to be with each other. You can’t go into any relationship with anyone with preconceived notions about that person. It’s tough. There’s nothing easy about relationships. If it was easy then we’d probably have a better world that we live in.



For a few days earlier this month, a stretch of downtown Los Angeles’s arts district was transformed into a circus of emerging transportation technology, with companies from around the world showcasing their newest and shiniest wares. Cordoned off from the rest of the “Street of the Future” by old-fashioned orange traffic barricades, a box-shaped autonomous shuttle ferried test riders from one end of the makeshift lane to the other, sans driver or steering wheel. A self-rolling tribe of cylindrical little robots intended to act as “mechanical mules” followed close behind the legs of their designated humans. The city’s mayor posed in a sleek, 3-D–printed race car. There were at least three different electric scooter brands on hand.

“My goal—and the goal of this city—[is] to be the transportation-technology capital of the world,” Los Angeles Mayor Eric Garcetti said in his opening keynote at LA CoMotion, a five-day conference and expo devoted to the future of urban mobility. (CityLab, the sister site of The Atlantic, was among the event’s media partners.)

Much was made of the decision to hold the inaugural LA CoMotion in famously traffic-snarled Los Angeles. Clichéd conventional wisdom has long dictated that nobody in the city walks—and only nobodies rely on public transit. And yet: I was born and raised in L.A., don’t own a car, and arrived at the “Street of the Future” via a humble Metro bus.

But—like me—America’s most car-centric metropolis is trying to prepare for life after cars. This will be hard: L.A. County is larger in size than Rhode Island and Delaware combined, and more populous than 41 U.S. states. The city’s urban configuration has long existed to serve the personal automobile, as have almost a century of L.A. social mores. LA CoMotion may have been about showing off the dazzling array of new technology that might help the city get there, but it was also an opportunity to measure the stubborn gap between L.A.’s current needs and its future shape.

Life after cars, if and when it arrives, might mean something a little different for Los Angeles. Unlike its older, denser Eastern counterparts, this was never really a compact, walking city to begin with. By the time the city reached any real size, it already had an impressive streetcar system. At the dawn of the 1880s, the same decade that saw L.A.’s first electric streetcars, there were a mere 11,093 souls living in the fledgling pueblo. The Pacific Electric and the Los Angeles Railway streetcar systems entered service in 1901 and soon offered extensive coverage of the nascent metropolis.

It was this early mass-transit system (for a time, the most extensive in the nation) that helped power L.A.’s sprawl and single-family character. Paid for by real-estate companies, the streetcars were intended not just to connect outlying suburbs, but also sell them to prospective homeowners. The city’s growth, as the transit historian Ethan Elkind put it in his book Railtown, “occurred haphazardly, driven by real-estate interests rather than by good urban planning.”

The narrative of the Big Bad Auto Companies dismantling L.A.’s beautiful electric-railway system to boost car sales (immortalized in the 1988 film Who Framed Roger Rabbit?) is not entirely true. Yes, the advent of the automobile hastened the system’s demise, but that story was all but written decades before the rails themselves were pulled up. One out of every eight Los Angeles residents had their own car in 1915—that’s when the national mean was one car per every 48 residents, according to Scott L. Bottles’s classic Los Angeles and the Automobile. By 1925, every other Angeleno had a car. The automobile really conquered Los Angeles in the 1920s. And car culture has arguably been the most powerful driving force of L.A. life in the near-century since—in large part because of the city’s early-adopter embrace of a then-emerging technology.

The rhetoric of the future is nothing new in Los Angeles, a city as much sold into being as it was shaped. But the new ideal life now being advertised is far more city-driven than suburban, with urban mobility suddenly edging out grassy yards and space as the answer to L.A.’s social ills.

The goals of L.A.’s self-proclaimed “tech mayor” aren’t as pie-in-the-sky as they might seem. Taken together, L.A.’s aerospace and manufacturing past, growing Silicon Beach tech community, and coming influx of investment in transit infrastructure make the city uniquely primed for a leadership role in a new transit future. Seventy percent of Los Angeles commuters still drive to work, but the civic zeitgeist is shifting—and the city is positioning itself as a laboratory of sorts for transportation innovators and startups. The car-less Angeleno remains an occasional punchline, but it’s become a decidedly lazier one.

Last November, L.A. voters overwhelmingly approved Measure M, a half-cent sales tax that will fund an unprecedented $120 billion in transit projects over the next 40 years. The scope of investment may be novel for the city, but the ballot-box show of faith in Metro, the nation’s second-largest transit agency, was not. In fact, Measure M was the fourth such sales tax to support transit investment voted into place by Angelenos since the 1980s.

The much-heralded 2016 opening of the second phase of Metro’s Expo Line re-connected downtown to Santa Monica via rail for the first time since 1953. Although the Expo Line may not have dramatically improved travel times (the full trip takes roughly 50 minutes, slower than the freeway in all but the very worst of traffic jams), it represented a symbolic shift in a city where public transit had long been seen as a last resort.

By 2019, the currently-under-construction Crenshaw Line is slated to bring light rail through parts of historically underserved South L.A. and link the airport to the Metro Rail system. And by 2027, Metro’s Purple Line Extension should be complete, providing—at long last—uninterrupted subway service under the Wilshire Corridor, all the way from downtown to Westwood. The 2028 Olympics also loom on the horizon: That’s driving Garcetti’s “28 by 28” initiative, which aims to complete 28 Metro projects, from bus rapid-transit lines to a proposed on-demand microtransit program, by the time the Games begin.

Perhaps even further in the future: Tesla/SpaceX founder Elon Musk just officially filed plans to dig below the city for his alternate transportation system—an elaborate system of private tunnels equipped with “electric skates” that boost vehicles (and capsules of pedestrians and cyclists) up to 130 miles per hour, so those with means can avoid more-conventional modes entirely.

In other words, Southern California does not lack for big plans, transportation-wise.

“There are very few places in our country where the vision is big enough for the challenges we face,” then-U.S. Transportation Secretary Anthony Foxx said last year while announcing more than a billion dollars in federal funding for that Wilshire subway extension. Where Los Angeles points the way, he said, according to the L.A. Times, “the rest of the country is going to follow.”

“We want your products, your ideas, your vehicles, your visions to come to this fertile ground,” Garcetti told the crowd of transit professionals during his keynote at LA CoMotion. “We’re not the kind of city that says, ‘Go test it somewhere else first and come back to us when it works,’” he added.

Autonomous vehicles (AVs) are going to be a part of that process. Garcetti has long championed AVs—at the 2014 CityLab conference, he proclaimed that L.A. could be the first urban center to really do them right. Last year, his office authored an extensive report addressing future plans for AVs and on-demand sharing services, making L.A. the first major U.S. city to specifically address policies around self-driving cars. L.A. also recently implemented an electric-vehicle car-sharing system targeted at low-income communities, and Metro has committed that all its buses will run on electric battery power by 2030.

But L.A. has a long way to go, and many basic elements to hammer out, before it can transform into a showpiece for AVs, EVs, or underground tubes full of Teslas. “Focusing on the deployment of new technologies is good, but let’s not forget the basics,” as Denny Zane, the founder of the transit nonprofit Move LA, put it during a Saturday LA CoMotion panel on Los Angeles’s “Mobility Revolution.”

The importance of the basics—and the depth of the gulf between the city’s varied, glittering futures and the daily reality of being a transit-dependent Angeleno—was particularly apparent once I exited the mobility revolution and made my way to the bus stop. I narrowly dodged one of the candy-colored rolling mules as I exited the temporary festival grounds, and then walked a supremely pedestrian-unfriendly half-mile to catch an express bus that spent 20 minutes circumnavigating downtown traffic before even beginning its westward crawl.

Without dedicated lanes, buses (which account for the vast majority of Metro trips) have to sit in traffic just like the rest of the cars on the road. That same gridlock makes for a notoriously not-entirely-reliable bus system, where riders like me would rather walk a mile than have to transfer bus lines—and risk being stranded mid-trip for an indeterminate amount of time.

Land-use decisions are also pivotal to the success of a transit system: If density and affordable housing aren’t prioritized in the areas around future rail lines, that rail investment will have little real effect on mobility or equity in the city. Sexier first- and last-mile solutions, like those foldable electric scooters and stuff-carrying robots on display, are likely to be comically out of reach for most riders: As of 2014, 71 percent of transit commuters in the city of L.A. made less than $25,000 a year.

Thought leadership won’t increase the frequency of nighttime service on Metro’s existing rail lines. The promise of someday paying fares with wearables doesn’t change the fact that there isn’t yet a single, easy-to-use app that offers both accurate next-trip data and routing for Metro riders. The mobility revolution may be coming—and it looks great—but the future is far from here.

This post appears courtesy of CityLab.



The man who Sandra Pezqueda says sexually harassed her and ultimately got her fired has never been disciplined for his actions. That’s even though the man, who was her boss when she worked as a dishwasher and chef’s assistant at the luxurious Terrenea Resort in Rancho Palos Verdes, California, beginning in 2015, persistently switched her schedule so she’d be working alone near him, repeatedly offered to give her more hours if she’d go out with him, and twice tried to kiss her in a storeroom at work, according to Pezqueda. That’s even though, when she complained about his behavior to the staffing agency that employed them both, Pezqueda says supervisors began seeking reasons to fire her, eventually letting her go in February 2016. “I knew if I spoke up there would be retaliation,” Pezqueda, now 37, told me. “That’s why other women never speak up about what happened to them.”

For all the Harvey Weinsteins, Al Frankens, and Russell Simmonses who have lost their jobs after allegations surfaced of sexual harassment, there is a sobering truth often lost in the #MeToo movement—the push for accountability has class dimensions. Many other less famous men, who have harassed women in less high-profile fields, have not been held accountable. Virtually all of the men who have been publicly excoriated for their conduct have worked in industries like Hollywood, or politics, or law, that the public tends to study with laser-like focus. “If an employer isn’t worried that there’s going to be some huge public-relations issue stemming from harassment, then that is one less reason for the employer to take it seriously,” Emily Martin, the general counsel and vice president for workplace justice at the National Women’s Law Center, told me.

Sexual harassment happens just as frequently—if not more frequently—in industries dominated by low-wage workers, according to analysis of Equal Employment Opportunity Commission data by the left-leaning Center for American Progress. Half of women working in the restaurant industry experienced “scary” or “unwanted” sexual behavior, according to a 2014 report from the Restaurant Opportunities Center, a nonprofit that advocates for workers in the food-services industry. Around 40 percent of women in the fast-food industry have experienced unwanted sexual behaviors on the job, according to a 2016 study by Hart Research Associates, and 42 percent of those women felt that they needed to accept it because they couldn’t afford to lose their jobs. Harassment is frequent in these industries because of the wage and power differences between the women and the men who supervise them, according to ‎Sarah Fleisch Fink, the senior counsel for the National Partnership for Women & Families, a Washington, D.C., nonprofit. “An imbalance of power in people in two different positions is a big part of sexual harassment occurring, and I think that there’s probably nowhere that occurs more than in lower-wage jobs,” she said. According to the Center for American Progress, the most sexual-harassment charges filed by workers from any one industry between 2005 and 2015 were in one sector: accommodation and food services.   

Men in these industries tend not to be held accountable because the housekeepers and food servers they harass fear being retaliated against and losing their much-needed paychecks if they bring complaints. Some women are worried that they’ll be reported to immigration authorities if they complain. Alleging sexual harassment “is scary for anybody, but it’s especially threatening if you don’t have a financial cushion and your paycheck is the only thing standing between your family and homelessness,” Martin said. Roughly three out of four women who experience sexual harassment never talked to a supervisor, manager, or union representative about the harassing conduct, according to a report from the Equal Employment Opportunity Commission (EEOC). And a report from the Center for American Progress suggests that nearly three-quarters of sexual-harassment victims say they’re retaliated against once they file a complaint.

Proving that harassment occurred can also be challenging when it is an employee’s word against a supervisor’s. In order to show the EEOC that an employer has violated Title VII of the Civil Rights Act, women have to prove that the harassment was “severe and pervasive,” Martin says, which can be difficult unless women know to keep a diary or notes of what is happening. What’s more, Martin says, low-wage and poor women are often not believed when they report instances of sexual harassment. “Our willingness to believe victims of harassment and violence is not extended to all victims equally,” she said. “If you’re poor, you may be found less credible when you tell your story.”

Indeed, Sandra Pezqueda was initially hesitant to report what was happening to her to the staffing agency, Excellent Maintenance Service, which employed her at Terrenea. Soon after she started working at Terrenea, she says, a supervisor at the staffing agency would tell her that her uniform looked good on her, and that she was the prettiest girl working at the resort, according to a complaint she filed in California Superior Court last year. In her third week of employment, he offered to walk with her so she could move her car, and told her he was going through a divorce and that he would soon be single, she says. When she said she was worried about not getting back to work quickly enough because he was talking to her, she says, he told her that he was the supervisor, so it didn’t matter. It was around that time that he started asking her out on dates, telling her that he would give her more work if she went out with him, and at one point, calling her at her house after she’d gone home for the day and telling her to come have coffee with him. He also told her that she was “special” and would be given 40 hours of work a week, but that the extra hours would be taken away if she did not respond to his texts. “He was the main supervisor, so everyone did what he said,” she told me.

In September 2015, he sent Pezqueda to an area of the resort where there were no cameras, followed her there, blocked the doorway, and tried to kiss her, she said. This happened twice, she said. By the end of September, he told her that he wanted Pezqueda to be her lover, she says, and when she said no, he took her off the schedule for two weeks. She complained to another supervisor in October, and was told there was nothing to be done, since it was her word against his, she says. Soon after, supervisors began “nitpicking” her work, she says, in order to create a reason to fire her, she believes. She was fired in February 2016.

In a statement provided to The Atlantic, Terrenea Resort said that both Pezqueda and the supervisor were employed by an outside staffing agency. Terrenea itself has “a zero-tolerance policy toward discrimination and harassment and are committed to ensuring all guests, and associates, are treated with dignity, fairness and respect. Our hearts go out to all of the individuals who have bravely shared their stories,” the statement said. Frank Marchetti, an attorney representing Excellent Maintenance Service, said that the company has no comment at this time.

In some industries, such as domestic work, employees have a number of different bosses, and don’t have anywhere to report abuse. I spoke with another woman, Isabel Escobar, who used to clean houses for clients. One afternoon, when she was alone in the house with the homeowners’ son, he called her to come upstairs, where she found he was standing in the doorway naked. She was going to have to pass him to clean the upstairs bathroom. Terrified that he was going to rape her, she ran out of the house. He called her and told her to come back, but she refused. She didn’t report him, and never got paid for the job. “I felt that I couldn’t talk to anyone—I was scared, isolated, and alone,” she told me. “This happens not just to famous or well-known people,” she said.

Escobar was working as an independent contractor at the time, which highlights another reason it can be hard for low-wage women to feel that they’ve been heard. Title VII of the Civil Rights Act, which prohibits employment discrimination based on race, color, religion, sex, and national origin, and can be a tool for women who experience sexual harassment at work, does not cover women who are independent contractors. Filing a Title VII complaint with the Equal Employment Opportunity Commission is the first step in bringing a sexual-harassment case under federal law, but for many women, it’s off the table. Though filing such a charge does not require a lawyer, many women find that having legal advice is helpful in figuring out their options—but women who work low-wage jobs can rarely afford lawyers, and finding a pro-bono lawyer can be challenging: Many lawyers work on contingency basis, getting paid if their client wins, but because low-wage workers make so little money, the potential judgment, even if they win, may not be enough to make it worth lawyers’ time.

There are ways that businesses could do more to fight sexual harassment among low-wage workers, Martin says. Tipped workers are often subject to a higher level of sexual harassment because they have to put up with poor conditions in order to earn tips—raising the tipped minimum wage might be effective at empowering them to push back against harassment. A 2013 Supreme Court case, Vance v. Ball State, made it more difficult for low-level supervisors to be held accountable under Title VII of the Civil Rights Act because the victim has to prove that supervisors who have hiring and firing responsibilities, not just supervisors who direct day-to-day activities of employees, knew about the harassment. Reversing that decision could also help women in low-wage industries, Martin said. But most of all, giving workers more job security and higher wages might change the conditions that prevent them from speaking out and filing charges. If women feel that complaining about even the most egregious situations can get them fired, and they don’t have savings or a safety net, they’re unlikely to complain.

Sandra Pezqueda went through a dark period after she lost her job. She went into a deep depression, frustrated that speaking out had gotten her fired. Other women at the staffing agency stayed quiet about harassment because they were afraid of losing their jobs, she said. She spoke out because she didn’t like to imagine her daughters going through a similar situation. But speaking out cost her, as it does many women in her position.



The labor market is near full employment. The jobless rate is low. The economy is adding tens of thousands of jobs each month, and—at last—wages and earnings are increasing for workers at or just above the minimum wage. Indeed, Walmart on Thursday announced that it would provide a wage hike to and expand benefits for employees across the country, with 85,000 workers with two decades of seniority at the big-box retailer getting a $1,000 bonus and a million workers in total benefitting. In addition, 18 states bumped up their minimum wages for the new year, providing an estimated $5 billion more a year to 4.5 million workers, the left-of-center Economic Policy Institute has calculated.

“It has changed my life, and I have noticed the changes,” said Darryl Johnson, a home health worker based near Seattle, whose hourly rate has gone from $13.50 to nearly $15 over the past 18 months. “I have more food at the end of the month, and I’m not trying to stretch those groceries for a week and a half. I’m feeding myself better, and you need to work to eat and get out there.”

Still, the recent improvements in the low-wage labor market underscore how slow the recovery has been for millions of families—how fragile they remain, and how much longer the expansion would have to continue to make up for lost decades of growth. Many rich Americans found that their fortunes bounced back fast after the Great Recession. Millions of poor Americans, by some measures, have still not seen their financial situations recover, let alone improve.

But now that’s changing. Over the past few years, the unemployment rate has fallen precipitously for less-skilled and less-educated workers. The jobless rate for workers without a high-school diploma has dropped from 8 percent as of December 2016 to 6.8 percent last month, while it dropped from 2.3 percent to 2 percent for workers with a college degree over the same time period. Low-wage workers are also seeing big increases in their earnings, compared with middle-income workers, and the poverty rate is declining too. The long-term jobless, people with criminal records, individuals with a disability—they are getting hired, despite some economists’ fears that they would remain structurally unemployed even in a hot labor market.

A number of trends have coalesced to boost the fortunes of the working classes. In announcing that it would move its wage floor up to $11 an hour and expand its paid maternity and paternity leave policies, Walmart pointed to Trump’s massive corporate tax cut. “We are early in the stages of assessing the opportunities tax reform creates for us to invest in our customers and associates and to further strengthen our business, all of which should benefit our shareholders,” Doug McMillon, Walmart’s chief executive, said in a statement. “However, some guiding themes are clear and consistent with how we’ve been investing—lower prices for customers, better wages and training for associates and investments in the future of our company, including in technology. Tax reform gives us the opportunity to be more competitive globally and to accelerate plans for the U.S.”

But labor experts and economists are skeptical, characterizing this framing as more a marketing ploy than anything else. “With the labor market tight, most employers have been raising pay, especially now that states covering one-fifth of the U.S. workforce are phasing in $15 minimum wages,” said Christine Owens, the executive director of the National Employment Law Project, in a statement. “This low-ball announcement by Walmart after the corporate tax give away looks more like a ploy to promote the myth that corporate tax cuts are what raise wages.”

One key piece of evidence that it’s the economy, not the tax cut, pushing up Walmart’s wages: Other retail companies that Walmart competes with have already done so. Target, for example, boosted its starting wage to $11 an hour in October and has vowed to move it up to $15 by 2020.

Much the same is happening economy-wide. Businesses are struggling to fill vacancies, with nascent signs of labor shortages in a number of industries, among them healthcare and construction. “As the labor market has tightened, employers need to shift their strategies for hiring workers,” wrote Jed Kolko, the chief economist at the job-search firm Indeed.com, in a research note. “Some firms will offer higher wages; some will loosen their hiring requirements or invest more in training. This helps less qualified workers, who might now be considered for jobs that would have been out of their reach earlier in the recovery. That’s one reason why the biggest gains in employment in 2017 have gone to workers with less education.”

Additionally, there are the states and cities increasing their minimum wages, often under pressure from the labor-backed Fight for $15 movement or through popular ballot initiatives. California, for instance, passed legislation setting its state minimum wage at $11 an hour, directly benefiting 13 percent of its workforce and pushing $2.7 billion more a year into workers’ pockets, EPI has estimated. Maine added a dollar to its wage floor this year, and Hawaii 85 cents.

Though the bottom of the labor market has been doing better of late, the recovery remains uneven. Income growth—a broader measure than wage growth—remains anemic compared with 30 or 40 years ago, and has proven strongest for the very richest Americans. The bottom 50 percent of earners are making 12.6 percent of national income, down from 13.7 percent when the recession hit. The top 1 percent are making 20 percent, up more than a percentage point.

Johnson, for his part, said that his nearly $1.50 boost in hourly wages had helped keep his family afloat and reduced some of the pressure for him to work long hours. But he said that he would need $18 or $20 an hour to be comfortable—particularly given how expensive the Seattle area has gotten. “It’s okay, but it’s just not enough” he told me. “It’s just still not enough. I’m a little better now, but it’s not where I am comfortable. And I do want to be comfortable. Back a couple years ago, I was struggling just to make it, to pay all the bills. I’m at the point now where I’m not struggling but it’s still hard. Put it this way: I can’t put no money away.”

He still works 12 hour days, five days a week, he added.  



Updated on November 28 at 5:34 p.m. ET

There are currently two people claiming to be in charge of the Consumer Financial Protection Bureau. It’s up to a judge to decide who’s correct—Leandra English, who was promoted by the agency’s outgoing director, or Mick Mulvaney, the Trump administration’s pick. On Tuesday afternoon U.S. District Judge Timothy Kelly, who was appointed by Trump in September 2017, denied English’s request for an emergency temporary restraining order. Though English is likely to continue to pursue her lawsuit, the judge’s ruling means that for now, Mulvaney can continue to lead the agency.

And he’s ready to change some things. “Rumors that I’m going to set the place on fire, or blow it up, or lock the doors, are completely false,” Mulvaney, who is currently the director of the Office of Management and Budget, said in a press conference on Monday afternoon. “That being said,” he added, “anybody who thinks that a Trump administration CFPB would be the same as an Obama administration CFPB is simply naive. Elections have consequences.”

Those consequences took the form of some changes that are predictable from someone favored by an administration that doesn’t like regulations. On Monday, Mulvaney instituted a 30-day freeze on hiring, rulemaking, regulations, guidance, and payments from the civil penalties fund (which is used to compensate Americans who have been harmed by financial institutions). “Anything that’s in the pipeline stops,” he said, and it’s a move that isn’t unusual during a leadership change at a government agency.

Mulvaney went out of his way to stress just how normal such a changeover is. During that press conference, he called the leadership transition an “ordinary course of business.” He showed up for his new job early, with communications staff from the Office of Management and Budget snapping pictures of him in the director’s office. And he pulled a typical new-boss move by bringing doughnuts with him and holding meetings to introduce himself to staff. By Tuesday, Mulvaney had even taken over the CFPB director Twitter account, and tweeted out a photo of him in the office with the caption “Busy day at the CFPB.”

But the appearance of a typical day at the office was overshadowed by the fact that meanwhile, Leandra English was launching a legal battle to get a job she says is rightfully hers. As Mulvaney was giving his first press conference as acting director of the CFPB, lawyers representing Trump and English were making their cases during a hearing at a nearby D.C. District Court. Lawyers defending English have asked for a speedy resolution to determine whether or not the Dodd-Frank Act, which says the deputy director would be the agency’s new acting director, supersedes the Federal Vacancies Act, which allows the president to name an interim director to an agency in many cases.

The question over who will lead the CFPB, at least in the short term, arose weeks ago when Richard Cordray, the Bureau’s inaugural director, announced that he would step down by the end of November. The situation escalated last Friday, when Cordray elevated English to the position of deputy director in hopes of thwarting Trump’s naming of a successor. After Trump went ahead with naming Mulvaney, English filed a lawsuit, and things have been getting more and more confusing ever since.

Lawyers representing the Trump administration don’t feel a ruling in the lawsuit is as urgent as English insists; in fact, they argue, the two-boss dilemma doesn’t constitute an emergency at all. That stance makes sense given that Trump’s pick is the one currently winning the battle for control of the CFPB.



Mick Mulvaney intends to make all the drama surrounding his appointment as interim director of the Consumer Financial Protection Bureau worth it.

One of Mulvaney’s first orders as interim director was to freeze hiring, rulemaking, and regulatory actions for 30 days. That’s fairly standard practice for leadership changes in federal agencies amid a party transition. But in the past few weeks, Mulvaney’s orders have started to extend beyond the ordinary due diligence.

In addition to plans for scrutinizing the agency’s budget, the temporary hiring freeze has become indefinite, though in December the acting director mentioned plans to bring on several political staffers in order to give “professional staff here ... a better feel for where the administration wants to take the bureau.” Senator Elizabeth Warren has criticized those hires as a move to politicize an independent agency. The changes that Mulvaney is instituting also include slowing down the implementation of new rules, a moratorium on collecting identifying information that could tie individuals to the financial data gathered by the agency, and tweaks to the agency’s mission statement add up to a reorientation that could fundamentally have a big impact on the bureau and the work it does. (The bureau didn’t respond to a request for comment.)

At the end of 2017, Mulvaney ordered a delay to the implementations of the bureau’s prepaid-card rules, which was set to go into effect in April, and would have forced financial institutions to limit customer’s losses in the event of a lost or stolen card, to provide easily accessible account information, and to look into and resolve transaction and account errors. The rule would have put significantly more pressure on the operators of such cards to provide accountability and risk management. In a statement that gave few specifics about what changes would be made, or when final implementation might occur, the bureau wrote, “The Bureau expects, based on its review of the comments received, to further extend the effective date of the 2016 rule.” Though the prepaid rule was finalized in 2016, implementation had been slowed as the agency sought comment for ways to improve it, and address concerns from the financial industry. In June, the agency asked for some specific feedback regarding tweaking the rules in order to prevent fraudulent claims, and to provide more clarity on how prepaid debit cards could be used in digital wallets.

On the same day that it announced a slowdown of prepaid implementation, the agency also announced that it was paring back requirements for the Home Mortgage Disclosure Act, which was put in place in 1975, and the authority to make rules related to the act was transferred to the CFPB via the Dodd-Frank Act. In 2015, the bureau set out to update what is known as Regulation C, the provision that governs how information on mortgages is collected, reported, and disclosed. And soon after, the bureau began toying with the idea of changing and clarifying some of Regulation C’s requirements. As of the first of the year, the agency will no longer ask financial institutions to resubmit erroneous data unless the errors were of material importance, and it won’t assess financial penalties for incorrect data. Going forward, the bureau is considering more significant revisions to the rule to reduce the reporting burden on financial institutions. That helps all types of financial companies that had complained about the difficulty of keeping up with the paperwork, reporting requirements, and fines associated with the rule.

Mulvaney has also instituted a freeze on any personal-data collection until the agency further shores up its cybersecurity defense. The use of personal-data collection in the agency’s robust complaint database, as well as the materials provided by financial institutions under the agency’s purview, has long been a sticking point for critics, who say that the practice could be dangerous. But the agency’s advocates note that the ability to pair personal data with financial information has allowed them to spot dangerous patterns, such as discrimination, and to create more tailored and effective rules.

Another telling change that’s come to pass since Mulvaney took over: changing the bureau’s mission statement, which appears on many public-facing documents such as press releases and emails. When Cordray, an Obama-era appointee, ran the agency, its mission statement read, “The Consumer Financial Protection Bureau is a 21st century agency that helps consumer finance markets work by making rules more effective, by consistently and fairly enforcing those rules, and by empowering consumers to take more control over their economic lives.” In recent weeks, that statement was changed to include language that supports Trump’s broader push for deregulation, a somewhat odd addition for a regulatory body.

In full, the statement now reads: “The Consumer Financial Protection Bureau is a 21st century agency that helps consumer finance markets work by regularly identifying and addressing outdated, unnecessary, or unduly burdensome regulations, by making rules more effective, by consistently enforcing federal consumer financial law, and by empowering consumers to take more control over their economic lives.”

Even though Mulvaney will only hold the title of interim director for a limited time, the changes that Mulvaney makes now will lay the groundwork whomever Trump chooses next (pending Senate confirmation). Mulvaney has long been a harsh critic of the agency, and the changes he’s implemented thus far do little to rebut the idea that Republican control of the CFPB means undermining existing work and making the agency more friendly to Wall Street.

When he first took over as head of the bureau, Mulvaney said, “Rumors that I’m going to set the place on fire, or blow it up, or lock the doors, are completely false.” And it’s true that during his short time at the CFPB, Mulvaney has done nothing that could be fairly characterized as destroying the agency. But the alterations he has made send a clear message. Under the Trump administration the CFPB will be focused on the same core principles that all other agencies are adhering to: deregulation and unwinding the vestiges of Obama-era policy. For the CFPB, a regulatory agency founded during Obama’s tenure, that means a new bureau entirely.



On Tuesday night, as it became clear that voters in Missouri had—by a two-to-one margin—rejected a state law meant to reduce unions’ power, the president of the AFL-CIO, Richard Trumka, declared, “The defeat of this poisonous anti-worker legislation is a victory for all workers across the country.” He added, “Tonight is the latest act of working people changing a rigged system that for decades has been favoring corporations, the mega-wealthy, and the privileged few.”

The legislation in question was a law passed by the Republican-controlled state legislature last year and signed by the governor at the time, Eric Greitens, a Republican, which would have allowed employees in unionized private workplaces to opt out of belonging to a union and paying dues. Currently, unions in Missouri, as part of collective-bargaining agreements with employers, can require that an entire workplace be unionized. In those workplaces, even if someone isn’t keen to join the union, taking the job requires him to do so.

Missouri Republicans had hoped to bar that requirement, as 27 states have. Unions fiercely oppose such laws, partly on principle and partly because the laws represent an existential threat: Research has shown that when states have imposed such laws, known among supporters as right-to-work laws, union membership declines. So in Missouri, labor organizers collected enough signatures to put a measure on the state ballot, Proposition A, in order to put the issue to a vote. Then, according to The Wall Street Journal, they outraised their opponents five to one.

In positioning the vote as a milestone, Trumka is surely being self-serving, but he is hardly alone. The defeat of Proposition A is a defensive move—meant to maintain the status quo rather than actually make it any easier for workers to unionize. Still, it carried symbolic weight. Pointing to last spring’s walkouts by teachers in West Virginia, Oklahoma, and elsewhere, many commentators and politicians described Missouri’s vote as the most recent positive sign for the U.S. labor movement’s future. On Wednesday, The New York Times editorial board wrote, “Tuesday’s vote and the popular support for teacher strikes in red states show that unions have the wind at their backs for the first time in a long while.” On Rolling Stone’s website, Bob Moser said, “Workers across the country now have a model for going on the offensive against the rising plutocracy, rather than watching helplessly while wages continue to stagnate and inequality continues to widen.”

Those who are optimistic about unions’ future have some evidence supporting their views besides Tuesday’s vote. For one thing, political support for unions is rising in the United States. Gallup found last summer that 60 percent of people approved of labor unions, the highest level of support in 10 years. (Gallup hasn’t published figures for this summer.) In a poll conducted amid all the teacher strikes last spring, 52 percent of respondents said they approved of teachers leaving the classroom to strike for higher wages.

And yet, it’s not clear that popular support for unions, and for policies that help them retain members, is the right measure of their strength. Gallup’s poll last summer made headlines, but, with a couple of exceptions, public support of unions has been more or less constant: For several decades, as far back as the early 1970s, about 60 percent of people have said they approve of unions. And yet union membership has consistently declined in the United States: Last year, membership stood at the historic low of 11 percent, cut nearly in half from where it was in 1983, when the Bureau of Labor Statistics began tracking it. In the 1950s, according to separate data, more than one-third of workers were unionized. So while popular support for labor might seem to be a proxy for unions’ strength, it’s actually a bit beside the point.

The most consistent factor in determining union support seems to be the strength of the economy. Perhaps counterintuitively, support for unions and corporations follow similar trends, rising when times are good, and falling when they’re bad. When people have a job, they feel good about those that helped them get it—their unions, but also their companies. When they’re unemployed, their loyalty flags.

To understand what, besides public opinion, could really lead to a revival in union membership, it’s instructive to look at what was behind the decline. The Taft-Hartley Act of 1947, which severely restricted unions’ activities and allowed for the passage of state right-to-work laws, played an important role. Perhaps more significant though, especially recently, has been the rise of a globalized and automated economy. Those forces have decimated middle-class jobs in manufacturing and other traditionally unionized industries. They have also contributed to lower prices for U.S. consumers, which, in turn, has created jobs in industries that are built around selling stuff. The retail sector is now one of the biggest employers in the United States; it pays very little, and its jobs tend to be part-time and temporary—which discourages unionization, since employees would rather not pay dues for a job they don’t expect to hold for long.

All of this didn’t just happen. It has been helped along by decades of economic and business policies implemented by governments led by both Democrats and Republicans. Donald Trump’s trade protectionism and disdain for some Silicon Valley companies notwithstanding, it’s hard to imagine a reversal in the trends toward globalization and automation. If Trumka and his colleagues would like to position their recent success against the right-to-work movement as a proxy for union strength, and in turn for people’s ability to repair a rigged system, he may have underestimated the extent of the rigging.



Monday morning got off to a weird start at the normally staid Consumer Financial Protection Bureau, when two potential leaders for the government agency showed up to work the same job. Leandra English started the day with an email to staff, sharing her excitement about working with them in her new role as acting director. But that didn’t stop Mick Mulvaney, Trump’s controversial pick for the job, from showing up with doughnuts in hand and taking a seat in the director’s office.

The battle over who will run the Consumer Finance Protection Bureau may be headed to court. But until a judge rules on who has the right to choose a temporary director, or one party decides to give up their claim, things at the Bureau will get more and more confusing.

While both sides say that law is abundantly clear about who has the power to determine the Bureau’s interim leader, no one can seem to agree on what that means. All of this is not only awkward, it also highlights the fact that, despite claims to the contrary, determining who has control of this government agency right now is pretty complicated.

On Sunday, English, the agency’s deputy director filed a lawsuit that attempts to block the president from installing his own pick as acting director instead of her. In that suit, English’s lawyer, Deepak Gupta (who formerly worked for the Bureau) asserts that, “The law is clear: Leandra English is Acting Director of the Consumer Financial Protection Bureau until the Senate confirms a new Director.”

The lawsuit filed by English cites provisions in the Dodd-Frank Act that state that in the event that the director leaves, the deputy director will “serve as acting Director in the absence or unavailability of the Director.” That language is why Richard Cordray, the Bureau’s former director, promoted English to the post of deputy director as his final act on Friday in an attempt to thwart President Trump from putting his own candidate into the position. But Trump was undeterred.

When Cordray first announced his impending resignation, Trump looked to the Federal Vacancies Act, which gives the president the authority to fill vacancies on an interim basis unless some other method of filling them is expressly authorized. But many argue that the language of Dodd-Frank does exactly that.

Trump has not been swayed by either the provision in Dodd-Frank that outlines succession, or by the Cordray’s bold move to install the acting director before leaving. Instead, the president doubled down on his choice, naming Mulvaney, who is the director of the Office of Management and Budget, as acting director of the CFPB on Friday. The president then tweeted about the Bureau, calling it a “total disaster” during Cordray’s tenure and pledging to “bring it back to life!” Supporters of the agency pushed back against that characterization, noting that the CFPB has returned $12 billion to consumers over its six-year history.

Things only got more complicated from there. An important detail about the lawsuit that English has filed in an attempt to gain control of the directorship is that she filed the suit on behalf of herself, not the Bureau. That’s because the CFPB’s lead counsel, Mary McLeod, is backing Trump’s claim. In a memo to senior leadership on Friday, McLeod says that the president has the authority to name Cordray’s successor. “I advise all Bureau personnel to act consistently with the understanding that Director Mulvaney is the Acting Director of the CFPB,” she writes. A letter from the assistant attorney general, Steven Engel, comes to a similar conclusion. (It’s worth noting that as recently as 2016, Engel was involved in defending payday lenders in lawsuits brought by the CFPB.)

Academic scholars aren’t as convinced about Trump’s ability to name both an acting director immediately and an official director in the future. Marty Lederman, a professor at Georgetown Law writes that the claim that the Vacancies Act supersedes Dodd-Frank, making Mulvaney the acting director is “is at the very least contestable.” And after reviewing the pertinent laws, including the Federal Vacancies Act, Nina Mendelson, a law professor at the University of Michigan, argues that while Trump can at any time appoint a new director, who will then undergo Senate confirmation, he doesn’t have the authority to install an acting director.

The fact that the succession plan for the agency has turned into a battle under the Trump administration shouldn’t be surprising. Trump spent much of his campaign haranguing the agency as ineffectual, and many Republicans opposed the creation of the Bureau in the first place, and have criticized it since the get-go.

In her lawsuit, English asked for a speedy legal resolution to this dispute. But until that happens, the work of the Bureau, which includes regulating financial institutions, educating consumers, and punishing bad financial actors, remains at risk.



Sugar is having a tobacco moment, not just here, but around the world.

Urbanization, falling poverty rates, and growing global trade have changed the diets and expanded the waistlines of the world’s poor, with processed food and sweetened drinks becoming household staples. Even very low-income communities are seeing rising rates of obesity, diabetes, cancer, and heart disease as a result. But many countries lack the tax revenue and medical infrastructure to treat such conditions, leading to a burgeoning global-health crisis. To tackle it, a new task force of well-known academics and advocates is encouraging developing nations to treat candy and soft drinks as many of them treat alcohol and cigarettes—and to tax them.

The idea might seem counterproductive, or even cruel. Cheap calories have contributed to falling rates of undernourishment and a reduced incidence of famine. Taxes increase costs, with a burden that falls most heavily on the most poor. And the relationship between added sugar and worse health is not a clear-as-day causal one. But promoting empty calories might be crueler, experts argue. “People say these taxes are regressive,” Lawrence Summers, a leader of the task force and a former Treasury secretary, told me. “But I say premature death is regressive.”

Summers is co-chairing the new coalition along with Michael Bloomberg, the former mayor of New York City and the current World Health Organization ambassador for noncommunicable diseases, an honorary position. Joining Summers and Bloomberg are, among others, Tabaré Vázquez, the president of Uruguay, Margaret Chan, the former director-general of the World Health Organization (WHO), and Nicola Sturgeon, the first minister of Scotland. The group of politicians, health experts, and economists plans to study fiscal measures that can improve public health and to urge lower-income countries to adopt them.

Its creation comes as international organizations and individual governments are increasingly worried about the prevalence and cost of lifestyle diseases. The rate of obesity has tripled in lower-income countries that have adopted Western diets and lifestyles, with doctors warning that the threat of diabetes has become pandemic. There are immense costs in terms of human suffering. And there are immense costs in terms of lost productivity, lost wages, increased health expenditures, and a smaller labor force. Five main noncommunicable medical conditions—cardiovascular disease, cancer, chronic respiratory disease, diabetes, and mental-health conditions—are estimated to cost China $27.8 trillion between 2012 and 2030, and India $6.2 trillion. The price tags will be in the millions and billions for many poorer countries as well.

“There’s a set of lower-income countries, like Bangladesh and Ethiopia and Myanmar, that will go in the span of 40 years from basically having no burden of noncommunicable diseases to having a similar burden as the United States or the United Kingdom. That’s three or four times as fast as high-income countries had to make that epidemiological transition,” said Thomas Bollyky, a global health expert at the Council on Foreign Relations, the New York–based think tank. “If you can’t slow this down and give countries time to adapt, they’re dealing with a problem coming four times as fast with a quarter of the resources.”

Some noncommunicable conditions might best be targeted with low-cost medical interventions: vaccines for HPV and hepatitis, inexpensive medicines for people with hypertension. For others, taxes might be part of the answer. “For the first time in the history of the world, more people are having their health affected by eating too much, rather that too little. That’s a sea change for humanity,” Summers said, adding, “It’s going to be a while before the developing world is able to afford open-heart surgery on a massive scale. Fiscal measures are super-efficacious, both because prices matter particularly for younger and poorer people and because taxes are educative.”

Taxes do have a clear record of curbing the consumption of, and thus the public-health impact of, tobacco and alcohol. The WHO estimates that raising excise taxes on cigarettes by $1 per pack would push up the cost of cigarettes by an average of 63 percent in low-income countries. After such an increase, projections indicate, the prevalence of daily cigarette smoking among adults would fall from 14.1 percent to 12.9 percent, leading to 15 million fewer smoking-attributable deaths. The group argues that “tobacco-tax increases are the single most effective policy to reduce tobacco use.”

Studies are similarly clear about the effect of alcohol taxes, if fewer countries have them as an explicit public-health policy. “Nearly all studies, including those with different study designs, found that there was an inverse relationship between the tax or price of alcohol and indices of excessive drinking or alcohol-related health outcomes,” one survey published in the American Journal of Preventive Medicine found. Making alcohol more expensive does not just cut down on rates of cirrhosis and cancer, researchers have learned, but also reduces the incidence  of car crashes, suicides, domestic violence, workplace accidents, house fires, and so on. At the same time as these kinds of vice taxes reduce the consumption of dangerous products, they boost government coffers—providing a potential revenue stream for health spending.

Then there is sugar. “Sugar is where tobacco was in 1972,” Summers told me. “The equivalent of the surgeon general’s report has been written, but there has not been much that has happened yet to reduce demand.” He was gesturing to a growing body of studies showing that taxing sugar leads to reduced consumption—with a potential knock-on effect on obesity rates and health expenditures. Perhaps the best evidence comes from Mexico, which instituted a one-peso tax on every liter of sugar-sweetened beverages back in 2014, leading to a 5.5 percent drop in consumption in the first year and 9.7 percent in the second year.  

“These taxes help, and the people who consume the most are most affected,” said Barry Popkin, an economist and nutrition expert at the University of North Carolina, who studied the effect of the sugar tax in Mexico. He said that while the burden of the tax might have hit lower-income people the hardest, the benefits might help them the most, too. “The poor do pay more, but they’re the ones who can’t afford health care. They’re not being treated much at all in terms of chronic disease—diabetes is not something you can treat cheaply.” He added that the study did not show that Mexicans facing higher prices for soda and sports drinks seemed to shift their calories into other kinds of junk food.

Still, not all research shows such promising results—nor is it clear that sugar taxes will lead to less consumption, and thus to lower rates of obesity, and thus to a lower incidence of noncommunicable disease, and thus to reduced long-term public-health spending, in part because such tax initiatives have not been around long enough to know. “Studies looking at the effect of actual soda taxes implemented at the state level find that, while the taxes do lead to a moderate decrease in soda consumption, the net effect on obesity is next to zero,” reads one review of the literature in the United States.

Moreover, critics have questioned whether such policies are fair—pumping up prices for the poor with a questionable benefit for public health. Others oppose them on the grounds that they are paternalistic and interfere with free markets. “Individuals’ decisions about what risks they are willing to take and how much they are willing to trade pleasure for diminished health are incredibly personal and should not be overly politicized,” argues Peter Van Dorn of the Cato Institute, the libertarian think tank. Plus, junk-food and soda taxes are often unpopular, raising the ire of grocery stores and food producers, along with citizens themselves.

In spite of all that, many countries have moved in recent years to use taxes to try to improve their citizens’ diets and cut down on health costs. Thailand recently instituted a tax on sugary beverages, with Hungary putting one on junk food and Vanuatu putting in place significant import restrictions. That should provide more data on the efficacy of such measures, and the best way to design them.

If they work, the impact on public health could be considerable, in terms of lower costs and higher revenue. “You’re also seeing massive demographic changes in these countries,” Bollyky said. “It isn’t that people in developing countries have grown fat and lazy and intemperate in their habits, and now they have these health conditions. It’s because of fairly dramatic shifts in their populations as well as in lifestyles, and their health systems need time to accommodate them. They’re having to do it faster than we did and with fewer resources.”

The United States might stand to implement more vice taxes too, Summers added. “This is some of the lowest-hanging fruit for potential policy improvement.”



The Trump administration’s latest budget, which was released in mid-February, projects 3 percent annual GDP growth for much of the next decade. Most economists consider that forecast to be somewhere between wildly optimistic and historically absurd.

Why? Because consistent 3 percent growth, while the norm for countries like China and India, is exquisitely rare among developed economies. The average annual growth of America’s GDP since the Great Recession has been about 2 percent. Achieving Trump’s dream of growth would require some heroic supercharging of the economy.

There are several ways that economic growth can take off in a country like the U.S. First, the federal government has a wide arsenal of policies to combat recessions. When the economy slips into a funk, the feds can cut taxes and increase spending, thus running a large short-term deficit to combat slow growth. The Federal Reserve can slash interest rates to encourage corporations to borrow and spend more money than they otherwise would.

The most obvious problem with deploying any recession-busting policies now is, well, the U.S. isn’t in a recession. Quite the opposite: The economy is nearly at full employment. Interest rates are already low and most economists expect them to do nothing but rise in the next few years, which should discourage investment and growth. The Republican tax cut, combined with increased spending, will increase the deficit for the next few years—a rarity this deep into a recovery. It’s conceivable that those deficits might provide a bit of a boost. But sustained 3 percent growth isn’t likely.

So, how can a growing economy accelerate? Imagine a factory owner who wants to expand his shoe-manufacturing capacity. The owner can invest in shoelace machines and employee training to increase the per-worker productivity of the factory. He could also simply hire more workers. Just like that hypothetical factory owner, the economy’s growth fundamentally comes from just two things—productivity growth and labor-force growth.

The trouble with rapid productivity growth is that it’s a bit like permanent happiness—much easier to obsess over than to achieve. Indeed, economists obsess over productivity quite a bit, but they often disagree about what increases it, and, as some of them sheepishly admit, they’re not even all that great at measuring it. So far this century, productivity growth in the U.S. has been consistently low—even negative—since the end of the dot-com bubble. Several studies suggest that as rich countries like the U.S. get older, their productivity-growth rates naturally decline. (Since there’s a lot about productivity that puzzles economists, they aren’t entirely sure why this happens, either.) Designing a budget projection around a sudden surge in productivity is a bit like betting one’s life savings on the discovery of alien life on the moon. Not utterly hopeless. But certainly not advisable.

So, what’s the trick to raising GDP if productivity levels are subdued? More workers.

In the second half of the 20th century, economic growth in the U.S. rode a labor-force boom, after the Greatest Generation gave birth to the Boomers, then the largest generation in history. But in the last decade, that demographic wind has turned against the U.S.—and most advanced economies. As the Obama White House said in its 2013 economic report, “real GDP in the United States is likely to be permanently slower than it was in earlier eras because of a slowdown in labor force growth.” It’s not just that population growth is slowing down. What’s more, the share of Americans between 25 and 54 who are working—a statistic known as the “prime age labor participation rate”—has been generally declining since the late 1990s.

There are two simple ways to add more people to the U.S. population: more babies and more immigrants. The trouble with increasing fertility is that no advanced economy seems to have figured out how to do it. The U.S. is in the middle of a protracted lull in baby-making—but so is Scandinavia, and Western Europe, and Japan, and Russia. Low birth rates may simply be a consequence of gender equality and overall prosperity: As a nation’s share of educated women grows, its fertility rate tends to decline, perhaps because working women don’t have the time, money, or interest in raising the sort of large families that were so common (and necessary) in agrarian economies.

Productivity growth is unpredictable, and fertility growth is elusive. What’s left? Well, there’s immigration. Achieving higher growth without another baby boom or accelerating productivity isn’t difficult—if the country simply let in more immigrants each year, GDP growth would almost surely accelerate. More able-bodied workers means more work; more work means more production; and product is, after all, the final noun in GDP.

But Republicans are, quite publicly, pursuing the opposite strategy. The immigration legislation from Senators Tom Cotton of Arkansas and David Perdue of Georgia proposes a 50 percent cut to the nation’s immigration levels. The Trump administration, which has endorsed the plan, said it wants to reduce legal immigration to the United States by half within the decade.

This puts the Trump administration’s economic policies in conflict with its economic projections. Other countries looking to jump-start economic growth in a period of low fertility are liberalizing their immigration policies. Japan, which is further along the aging curve than the U.S., has revamped its immigration laws this century, doubling its share of foreign-born workers (from an admittedly measly 1 percent in the late 1990s to about 2 percent today). Along with strong monetary stimulus, that doubling of the foreign-born population has contributed to stronger growth than Japan would have had otherwise. As I’ve written, the economic case for maintaining and even increasing immigration levels in the U.S. is extremely strong.

The White House is discouraging talented people from immigrating during a period of low productivity and falling fertility while predicting a growth miracle. All budgets are fantasies. But there is a greater sin here than fantastical forecasting. And that is using magical growth projections to cover up for a small-minded immigration policy.



Lately it seems that, every week, a new group of media employees votes to join a union. On Tuesday, a majority of employees at Slate voted to join the Writers Guild of America, East. This came a few days after newsroom employees of the Los Angeles Times voted to join the NewsGuild–Communications Workers of America. Two weeks before that Vox Media recognized the Writers Guild of America, East, as the union representative of their editorial and video staff.

These efforts are the latest in a slew of successful campaigns to unionize educated workers, not the traditional targets for labor organizers. In the past three years, employees of Vice Media, ThinkProgress, HuffPost, The Intercept, Salon, Thrillist, and the now-defunct Gawker have all joined unions. Graduate students at Columbia, Yale, Tufts, and Brandeis have also voted to join unions. Adjunct professors at Seattle University formed a union in 2016, and employees at the legal group Lambda Legal voted to form a union in December.

Labor advocates are declaring the wins for white-collar workers a new front for organizing, and indeed, labor has been making some progress in expanding its reach among educated workers. The number of people employed in professional and technical occupations who are members of unions grew by almost 90,000 last year, according to numbers released last week by the Bureau of Labor Statistics. The fields of law, arts, design, entertainment, sports, and media all saw substantial gains in the share of workers who are in unions, ticking up from around 4 percent in 2010 to around 7 in 2017.

But these gains for unions are in stark contrast to the many high-profile failed efforts to organize less-educated workers in other parts of the country, usually outside cities. In 2017, after years of organizing, the United Auto Workers lost a bid to form a union at a Nissan plant in Mississippi. They failed to organize a Chinese-owned auto-glass plant in Ohio in November. The UAW similarly lost a bid to organize a Volkswagen plant in Tennessee in 2014. On January 19, for example, the NLRB announced that media employees at the Los Angeles Times and professional employees at a Pennsylvania charter school each voted to join a union. That same day the NLRB announced that drivers at a bakery in New Jersey, drivers at a freight company in New York, and drivers for the Hy-Vee grocery chain in Iowa all voted against joining a union, according to NLRB data.

And while labor groups trying to organize low-wage workers in industries like fast food and the on-demand economy have made some gains in recent years, they have not created formal unions, but rather established informal arrangements that help workers. The share of workers who were members of unions in production, transportation, and material-moving occupations fell to 13.6 percent, from 16.2 percent in 2010, according to Bureau of Labor Statistics data. In service occupations, that share fell to 9.9 percent from 11 percent in 2010.

The contrast, between the growing numbers of educated workers joining unions and the shrinking pool of blue-collar workers doing so, is yet another dynamic of an increasingly bifurcated American economy. As jobs for educated workers continue to proliferate in this economy, educated workers feel secure, sure that they’ll be able to find more work if they lose their jobs. In some cases, that security may mean they feel they can advocate for a union, or stand up to employer threats to shut the workplace down if a union forms. Blue-collar workers, by contrast, are competing for a smaller and smaller share of jobs in the economy, and thus may feel less willing to commit to labor drives. Of the nearly 12 million jobs created after the recession, more than 8 million went to those with a bachelor’s degree, according to the Georgetown Center on Education and the Workforce. “Blue-collar workers may want a union, but fear defines union election to a troubling degree,” Harley Shaiken, a labor expert at the University of California, Berkeley, told me. “You have the same fear among white-collar workers, but they know they have other options. If they lose their job, they’ll have something two days later. That could give them more confidence about turning towards a union.”

This difference in who is joining unions could create further bifurcation in the economy, as workers who are already relatively stable become even more protected by unions, while workers who feel themselves in a tenuous position have fewer places to turn for problems like wage and hour violations, sexual-harassment claims, or unfair termination. Union employees are also better positioned to negotiate wage increases than non-union employees—non-union employees make 80 percent of what union employees do, according to the Bureau of Labor Statistics.

Lowell Peterson, the executive director of the Writers Guild, East, who has organized both blue-collar and white-collar workers in his career, said that organizing skilled workers might be easier in today’s economic climate. “If you’re a semiskilled or unskilled worker, your leverage is a little different,” he told me. Skilled employees are hard for employers to replace, and they know it, he said. While employers think they’ll be able to hire another worker off the street to stock shelves for Amazon or work on a car assembly line, they worry about being able to find enough skilled and educated workers to do the white-collar jobs they’re trying to fill. “[Managers in media] can’t just say, I don’t care who does this job, as long as someone does it,” Peterson said.

White-collar workers may also have an easier time doing the work to organize a union. Many Gothamist workers were young and didn’t have children, so were able to go to meetings after work, Scott Heins, 29, who worked full-time as a photographer and reporter for Gothamist for two years and was on the Gothamist organizing committee, told me. Blue-collar workers are often older, and have families to support. And, since white-collar employees don’t work on the factory floor all day, they are less physically exhausted at the end of the day. Additionally, the access to information technology that white-collar workers have can make it easier to communicate with other employees throughout the company.

Of course, white-collar workers still risk losing their jobs if a union forms—that’s what seems to have happened to 115 employees of DNAinfo and Gothamist, two websites owned by Joe Ricketts, a billionaire who founded TD Ameritrade, after 25 New York staff members voted to join the Writers Guild of America, East. But many of those employees have since found other jobs, and Peterson told me that the people who lost their jobs didn’t regret organizing. Heins told me that’s how he feels. “If forced into the same situation, I would do the same thing again,” he said. Heins said he and others knew the risks when they organized, especially when Ricketts, who is vocally anti-union, purchased Gothamist.

But Heins also landed on his feet. He is now working as a freelance photographer in New York, and said that it was going pretty well, in part because of support from groups like the Economic Hardship Reporting Project, which established a $5,000 fund to help laid-off reporters from Gothamist and DNAinfo. “I am very fortunate in that photography lends itself well to freelancing,” he told me.

In contrast to Heins’ ability to find work after losing his job, many blue-collar workers can’t afford to risk such a change. They are more likely to be living paycheck to paycheck, and tend to have less savings because their salaries are lower in the first place. “People were really terrified that they were going to lose their job,” Robert Hathorn, a pro-union worker at Nissan in Mississippi, told the website Labor Notes in the aftermath of the UAW’s organizing loss in August.  

Part of the divergence between white- and blue-collar workers may also have to do with where union drives are taking place. Many white-collar workers live in big cities like New York and Los Angeles, where workers are likely to be more liberal and supportive of unions than in other places, and where owners (with obvious exceptions) may be less likely to embark on anti-union campaigns because of public pressure. But increasingly, manufacturing and production jobs are located in the South, where anti-union attitudes are most persistent. Boeing located its Dreamliner aircraft assembly line in South Carolina rather than Washington State to reduce the leverage of the machinists’ union, analysts told The New York Times. And the failure of the United Auto Workers to organize plants in Mississippi and Tennessee was closely related to anti-union attitudes there, as I found in previous reporting, attitudes that are less prevalent in automakers’ home turf of Michigan and Ohio.  

Educated workers weren’t always as open to organizing campaigns. In the past, educated workers eschewed unions for two main reasons: They had negative opinions about unions, and they felt that they had enough of a voice in their jobs that they didn’t need union representation. Both of those factors have changed in the millennial generation, according to Ruth Milkman, a professor of sociology at the City University of New York Graduate Center. Today, 45 percent of Millennials think labor unions have a positive impact on the country, up from 32 percent in 2010, according to the Pew Research Center. That’s partly because Millennials are much more progressive than previous generations.

The current climate for media jobs may also be motivating some of the media-unionization drives, she said. While college-educated Millennials know that they can get all sorts of jobs in today’s booming economy, they are disappointed with the quality of the jobs in the media sector. “These are people who were led to expect that if they did their part, the world would be handed to them on a silver platter,” she told me. “And then they find that these are crummy jobs.”

Of course, thousands of blue-collar workers are also finding that the jobs available to them in today’s economy are crummy as well. But for them, the alternative to a crummy job—nothing—is even more terrifying.







On Monday, President Donald Trump greatly reduced the size of two national monuments in Utah, shrinking Bears Ears by more than a million acres and cutting the size of Grand Staircase–Escalante almost in half.

Later in the day, some private companies shared their feelings about public lands.

Patagonia, the outdoor-clothing retailer, responded by showing visitors to its website a black page with large white text that read, “The President Stole Your Land.” Under that heading, the company called Trump’s move “illegal.” Those who just came for a fleece sweater could click through to the usual website; the more politically inclined could navigate to a brief on the company’s reasoning (footnoted, no less) and suggestions of nonprofits to donate to.

REI, another outdoor brand, took a less combative stance, putting a graphic on its website that read “We ❤️ Public Lands.” Clicking through on that image directed visitors to a corporate statement on Trump’s decision expressing earnest concern and—perhaps unusually for a company that sells rain slickers and metal sporks—detailing its policy analysis. The company called the Trump administration’s four-month review of national-monument land “hasty” and asserted that the president’s action “undermines the integrity of the Antiquities Act.” (Neither Patagonia nor REI responded to interview requests.)

This is the year 2017, when clothing brands issue analyses of 1906 regulations governing public lands and accuse the president of breaking the law. Patagonia and REI’s digital strategies are reflective of two broader truths about what advertisers must consider in a hyper-partisan environment: First, choosing a side on a controversial political issue can be a great (but risky) way to get good PR. And second, not choosing a side is a still a choice, and one that consumers may judge brands harshly for.

REI seems to be aware that taking a political stand risks alienating shoppers who support Trump and his public-lands policy—hence its hard-to-disagree-with profession of love for public lands and its carefully worded statement affirming its “nonpartisan commitment” to preserving them. Budweiser, seeing itself in a similar position earlier this year after releasing a pro-immigration Super Bowl ad, insisted it too was apolitical: “There’s really no correlation with anything else that’s happening in the country,” an executive told AdWeek.

Aimee Drolet Rossi, a professor of marketing at UCLA’s School of Management, was not surprised that Patagonia and REI—as well as North Face and Arc’teryx, two brands that are donating money in support of preserving public lands—decided to take a side in this particular political debate. She says that both brands are well defined—as selling clothing to outdoorsy (i.e., liberal) types—and this made their calculation easy. “I don’t even know that it’s politics so much as, ‘Of course that brand should be supportive of efforts to preserve the environment,’” she says. In other words, it would seem strange for companies whose catalogs regularly feature rock climbers not to take a position on national monuments. (It was similarly on-brand when websites such as Google and Wikipedia used their own online real-estate to protest the Stop Online Piracy Act and the Protect Intellectual Property Act in 2012.)

One other thing that made both companies’ decisions unsurprising is their corporate make-up. Patagonia is formally registered as what’s called a B Corp (short for “benefit corporation”), meaning it is committed to not just profits, but also the wider well-being of society and the world. REI, meanwhile, is a privately owned cooperative that does not report to traditional shareholders but instead to the employees and shoppers who own a stake in it. Both organizational arrangements provide room for more mission-driven corporate strategies.

Where companies tend to run into trouble these days, Drolet Rossi says, is when they make a political play but have a more vaguely defined brand. She points to an ad that Pepsi put out earlier this year (and that I wrote about at the time) for which it was widely lambasted. It depicts the model Kendall Jenner making peace between protestors (their cause left a mystery) and police by presenting an officer with a can of Pepsi. “It’s a little riskier for them to take on an issue that’s only tangential to what the product does,” Drolet Rossi says.

Are these calculations unique to the present moment? In some sense, yes, Drolet Rossi says. She notes that Jimmy Fallon’s poor ratings have correctly been attributed to his unwillingness to address politics on his nightly show. “It seems weird that Jimmy Fallon gets up there and doesn’t comment on some of the absolute craziness that’s happening politically,” she says. A choice not to talk politics, these days, is more conspicuous than a choice to address it head-on.

But Drolet Rossi thinks that other things have led to this particular moment in take-a-side advertising. “It isn’t just that the political situation has changed,” she says. “I actually think it’s more that the ability to target and segment has so improved, dramatically, that you can weigh in to certain political issues with less concern about backlash.” Basically, with more data gathered from social media and online behavior, companies know their customers better than they used to—though, as the Pepsi backlash illustrates, they’re still figuring people out.



Paul Volcker’s 6-foot-7-inch frame was draped over a chaise longue when I spoke with him recently in his Upper East Side apartment, in Manhattan. He is in his 91st year and very ill, and he tires easily. But his voice is still gruff, and his brain is still sharp.

We talked about his forthcoming memoir, Keeping at It: The Quest for Sound Money and Good Government—about why he wrote the book and the lessons he hopes to impart. Volcker is not a vain man, but he knows that his public life was consequential, and he wants posterity to get it right. He also does not mince words. In our conversation, he assailed the “greed and grasping” of the banks and corporate leadership, and the gross skewing of income distribution in America.

Keeping at It, written with Christine Harper, an editor at Bloomberg, is primarily the chronicle of Paul Volcker’s public life, which was spent in the thin air of global finance. After graduating from Princeton in 1949, he studied economics at Harvard and then in London, where he focused on the operations of the Bank of England. For the next 20 years, his career cycled between the U.S. Treasury and the Chase Manhattan Bank, with a particular focus on monetary affairs.

Few Americans had heard of Volcker until he was nominated, in 1979, to be chairman of the Federal Reserve Board by President Jimmy Carter, a post he held for the next eight years. During that time, he almost single-handedly pulled the nation back from a near-Weimar-scale financial collapse. If there were a Nobel Prize for government service, Paul Volcker’s name would surely be on the short list.

Volcker’s career spanned nearly the entire postwar era. World War II had ended with the United States effectively controlling the major part of the world’s wealth. In a supreme act of statesmanship, Washington offered to provide trade credits and other aid to allies and former enemies alike, so long as they adopted reasonably democratic values. The American dollar effectively became the world’s currency at its 1934 peg—$35 per ounce of gold. That worked splendidly while America’s allies were in recovery mode, but by the 1960s most industrialized countries were competitive with the United States. Swiss currency traders, the nefarious “gnomes of Zurich,” realized that America’s gold reserves could no longer support its dollar issuance. So they started testing the dollar with sudden spasms of dollar sales in the hope of forcing a devaluation.

The classic method of meeting an attack on a currency is to raise interest rates to increase the attractiveness of holding it. But this was the early 1960s, and John F. Kennedy had promised to “get this country moving again.” Higher interest rates would have scuttled that ambition. The Treasury Department hit on a temporizing solution: a tax on foreign security purchases to curb the foreign traders’ enthusiasm for holding dollars. Volcker, then a deputy undersecretary at Treasury, drafted the enabling legislation. It did not take long, however, for traders to engineer an end run around the new tax by simply keeping their dollars overseas. Thus was born the “Eurodollar,” which would proliferate wildly, quite out of the control of the Federal Reserve.

Volcker returned to Chase for several years before rejoining Treasury as undersecretary for monetary affairs in the Nixon administration. The war in Vietnam—paid for by deficit spending rather than new taxes—had triggered serious inflation. Oil imports were surging, and currency traders smelled blood. But Richard Nixon had a genius for the bold stroke. Along with John Connally, his outsize Treasury secretary, Nixon in August 1971 brought virtually his entire economics team to Camp David, where he announced that he would cut taxes, impose wage and price controls, levy a tax surcharge on all imports, and rescind the commitment to redeem dollars in gold. In his 1975 book, Before the Fall, Nixon’s über-speechwriter, William Safire, recalled, “Volcker was undergoing an especially searing experience; he was schooled in the international monetary system, almost bred to defend it.” Everyone he had worked with “trusted each other in crisis to respect the rules and cling to the few constants like the convertibility of gold.” Volcker was charged with drafting the announcement of Nixon’s new economic policies, but his moroseness showed through. Safire did the final draft, proclaiming “a triumph and a fresh start.” About Volcker himself, Safire wrote, “It was not a happy weekend for him.”

As the ’70s wound down, the dollar became a debased currency—but one that, for want of an alternative, still served as the world’s most important reserve currency. Nations might make other provisions, but that could take years. To make matters worse, an ideological cleavage between Milton Friedman’s “freshwater” Chicago monetarists and East and West Coast “saltwater” economists added an unusual testiness to the board’s discussions. Monetarists looked to the supply of money, which is the multiple of physical money—M1 in the jargon—times its velocity, or turnover rate. Friedman’s rigid version of monetarism assumed that the velocity of money was fairly stable over time, so policy makers could ignore it and steer solely by M1. (Indeed, Friedman also believed that you could eliminate the Federal Reserve Board.) Traditionalists, such as Volcker and most other saltwater economists, looked first to interest rates as a policy tool.

By the time Volcker was sworn in at the Fed, in 1979, inflation in the U.S. was running about 1 percent a month, and rising. In 1973, the OPEC countries had forsaken the hallowed $3 peg for a barrel of oil—tripling their prices and tripling them again six years later. By then, spot prices for gold were bouncing around from $235 to $578 per ounce. When the U.S. Treasury, in the early 1980s, needed to raise money, it would be forced to float bond issues in marks and yen, so far had the almighty dollar fallen.

Two months into his new job, Volcker attended a conference of central bankers in Belgrade and was shocked to find himself harangued by his peers. As he explains in his memoir, German Chancellor Helmut Schmidt, who was a friend, lectured Volcker for almost an hour “about waffling American policymakers who had let inflation run amok and undermined confidence in the dollar.” A shaken Volcker cut his trip short, got his fellow Fed members on board, and called an unusual evening press conference. Most dramatically, he stressed that he was shifting his key policy tool to monetarism. As a hedge, he also raised the Fed’s discount rate by a full point. The New York Times editorialized about the rate hike under the headline “Mr. Volcker’s Verdun,” noting that when it came to holding the line on inflation, the Fed chairman’s message echoed that of Marshal Pétain: “They shall not pass.”

At first, the experiment seemed to work. The objective was to reduce the money supply and thereby bring down prices. By January 1980, however, the numbers were going haywire. Perversely, inflation took off—it reached an annual rate of almost 15 percent. The Fed’s technical staff ruefully admitted that Friedman’s money-supply theory was not precise enough to form a basis for effective policy. The Fed board maintained its monetarist rhetoric, but Volcker shifted back to raising interest rates in order to wring inflation from the economy. This was language that all businesspeople understood. The bank prime rate eventually jumped to 21.5 percent, T-bills hit 17 percent, and prime mortgages were at 18 percent. Those rates were the highest the country had ever seen. Volcker went on a grueling speaking tour to bolster the case for what he was doing.

By the time Ronald Reagan was inaugurated, in 1981, the U.S. economy had slipped into a deep recession, one for which the Volcker Shock was largely blamed. Unemployment neared 11 percent. Volcker became a target of popular anger. One welcome ray of sunshine came from the White House, with Reagan giving full support to the continuation of Volcker’s program. (Volcker later said, “I don’t kiss men, but I was tempted.”) Another came from the American Home Builders Association, in early 1982. Its industry had been badly hit by the recession, but Volcker gave a tough speech to the association about staying the course against inflation, and was amazed to get a standing ovation.

Inflation—blessedly—broke in mid-1982. The second half of the year saw a flat consumer price index. Real GDP for 1983 was a very respectable 4.6 percent and  a blistering 7.2  in 1984. By 1986 annual inflation had come down to only 2 percent. The crisis was effectively over. After 1982, Americans enjoyed the lowest interest rates (with a blip here and there) among the major industrial countries, and interest rates are low to this day. The second half of the 1990s was one of the most prosperous periods in history—there was a twin boom in high technology and in housing. Volcker attributes the crash that came in both industries to the same “greed and grasping” he cited when we spoke.

Volcker served two terms as the chairman of the Fed, giving way to Alan Greenspan in 1987. By that time, the challenges confronting the Fed had moved to new arenas—like the reckless “oil lending” by the big American banks to Mexico, Brazil, Argentina, and a string of smaller countries. In Keeping at It, Volcker writes, “Looking back, I see Latin America today as a sad culmination of hard-fought, constructive efforts to deal with a debt crisis that, aided and abetted by reckless bank lending practices, grew out of a chronic absence of suitably disciplined economic policies.” Volcker will never escape a Fed-inflected prose style, but his assessment is spot-on.

Retirement has treated Volcker well. He did some teaching and loved it. He spent 10 contented years as the chief executive of Wolfensohn & Company, an old-fashioned investment bank, which mostly gave advice on mergers and acquisitions. When he retired, he had plenty of time for nonprofit activities and was much in demand. He chaired inquiries into the ownership of Jewish art sequestered in Swiss bank vaults; the massive theft from food and medical programs after the Iraq War; and corruption in the World Bank.

Volcker also played an important role in the cleanup after the 2008–2009 crash. His advice was widely solicited, if not always followed. In his memoir, he describes sitting at a conference and listening to bankers warn that new regulations must not inhibit trading and “innovation.” He finally exploded: “Wake up, gentlemen. I can only say that your response is inadequate. I wish that somebody would give me some shred of neutral evidence about the relationship between financial innovation recently and the growth of the economy, just one shred of information.” His lasting contribution from this period is the so-called Volcker Rule, which bars traders from taking risky positions with depositors’ funds, and which he summarizes as “Thou shall not gamble with the public’s money.”

Keeping at It is not a tell-all book. Volcker’s subject matter is economic policy, and his praise or criticism is almost entirely directed at specific ideas and actions. His first wife, Barbara Bahnson, died in 1998. In 2010, he married his longtime assistant, Anke Dening. There is not much of a personal nature in the book, and yet, unwittingly, it paints an accurate personal portrait. The picture that emerges is of a man of granitic integrity, committed to what he perceives as wise policies—committed, that is, to what he calls The Verities: stable prices, sound finance, and good government.

The secret of Paul Volcker was his father. Paul Adolph Volcker Sr. was almost as tall as his son. He was an engineer, with a degree from Rensselaer Polytechnic Institute, and he went on to become a city manager. The city he was most identified with was Teaneck, New Jersey, a municipality that had fallen prey to a corrupt political machine. It was the kind of challenge that Paul Sr. leaped at. In his son’s memoir, Paul Sr. is always working; even after a long day, he drove around his modest empire and made note of broken traffic lights, spilled garbage, and other petty violations. They were not petty to him. The city fathers once tried to can him for hiring a professional police chief. They couldn’t fire him, but they could stop paying him. Paul Sr. went to court and got his pay—and got his police chief. Exactly what his son would have done.

There are few people like Paul Volcker in the U.S. government today, or in business, for that matter—respected and trusted by everyone, whatever the disagreements, and motivated by public service. Volcker reveled in his middle-class status. He notes in his memoir that, in the 1960s and 1970s, Washington was “mostly populated by middle-class professionals, including families of civil servants and members of Congress,” and that “there wasn’t great wealth.” Now, he writes, Washington is “dominated by wealth” and by “lobbyists who are joined at the hip” with people in government, whether on the Hill or in the executive branch.

As a result, he says simply, “I stay away.”



MERCED, California—Nita Vue’s parents, refugees from Laos, wanted all nine of their children go to college. But Nita, now 20, is the only one of her brothers and sisters who is going to get a degree. A few of her sisters began college, and one nearly completed nursing school, she told me. Her brothers were less interested. “The way I grew up, the girls were more into schooling,” she said. “Women tended to have higher expectations than men did.”

This is not unusual. Across socioeconomic classes, women are increasingly enrolling and completing postsecondary education, while, even as opportunities for people without a college education shrink, men’s rates of graduation remain relatively stagnant. In 2015, the most recent year for which data is available, 72.5 percent of females who had recently graduated high school were enrolled in a two-year or four-year college, compared to 65.8 percent of men. That’s a big difference from 1967, when 57 percent of recent male high-school grads were in college, compared to 47.2 percent of women.

Women from low-income and minority families especially have made great strides in recent decades. Just 12.4 percent of men from low-income families who were high-school sophomores in 2002 had received a bachelor’s degree by 2013, compared to 17.6 percent of women. And in 2016, 22 percent of Hispanic women ages 25 to 29 had a bachelor’s degree, compared to 16 percent of Hispanic men.

(While poor women are outpacing poor men, it is important to note that in the big picture, poor women are nevertheless far behind their richer counterparts. About 70 percent of women from a high socioeconomic status who were high school sophomores in 2002 had gotten bachelor’s degrees by 2013, compared to 17.6 percent of women from low socioeconomic status.)

This gender gap in college completion has been a long time in the making. In the early 1900s, when some elite colleges started opening up to women, women quickly got better grades than men, according to Claudia Buchmann, a professor of sociology at Ohio State and the co-author of The Rise of Women: The Growing Gender Gap in Education and What it Means for American Schools. In the 1970s, as more women started attending college, they started graduating at higher and higher rates, while men’s enrollment and graduation rates remained relatively flat. But until recently, the women attending college were mostly from elite families. Now, women from lower-income families are increasingly attending college.

Percentage of American 25-to-29-Year-Olds With a Bachelor’s Degree or Higher

This is a positive development for women, because a college education is increasingly important in today’s economy. Out of the 11.6 million jobs created after the recession, 8.4 million of those went to those with at least a bachelor’s degree, according to the Center on Education and the Workforce at Georgetown. But while women across socioeconomic classes are embracing the idea that education is important and are pursuing postsecondary degrees, many men from lower-income households are not. “The puzzle is—why don't boys get it? There’s all this talk that we hear constantly, about the benefits of a college degree,” said Buchmann.  

Some of the problem is that boys from low-income families appear to struggle more in school than girls do. They lag behind as early as kindergarten even though health tests show that, at the time of birth, they are just as healthy and cognitively able to learn as their sisters, a recent paper found. This is partly because they appear to be more affected by poverty and stress than girls are. “Boys are differentially sensitive to negative environments in general,” one of the paper’s authors, Northwestern professor David Figlio, told me. These findings dovetail with much-cited research out of the Equality of Opportunity Project that finds that childhood disadvantage is especially harmful for boys.

School quality is also more important for boys than for girls, Figlio said, and since many low-income families attend poor-quality schools, their sons, who are already lagging behind their daughters, fall even further behind. The paper found that lower-income boys often do worse in elementary and middle school than their sisters, and have more behavioral problems, which can lead them to disengage with school entirely or get kicked out.

Nita Vue told me she was always set on college, even when she was in grade school. Neither of her parents has a college education, and neither has worked recently, but they encouraged all of their children to focus on school. Nita, who is now a junior at the University of California-Merced, would come home from school and read while her siblings were listening to music. She always had good grades, and graduated from high school with a 4.0 grade point average. In general, her sisters did better academically than her brothers did, her mother, Mai Kao Vue, told me. “The girls were more into schooling, and the boys were more outgoing,” she said.

What is it about girls? The differences start young: Girls enter kindergarten more prepared than boys, and derive more satisfaction from pleasing parents and teachers than boys do, according to Buchmann. In one study, 62 percent of eighth-grade girls said that good grades were “very important,” compared to 50 percent of boys, according to Buchmann and her co-author Thomas DiPrete. Girls also have more of the social and behavioral skills that are important for succeeding in school from an early age, Buchmann said.

Boys often feel pressured to act “masculine,” which can lead them to eschew school —one study showed that boys put a lot of effort into school are often labeled as “gay” or “pussies.” Yet boys who don’t buy into those stereotypes and participate in music, dance, or art, do better than other boys academically in eighth grade, according to Buchmann and DiPrete. Those different levels of engagement can make a difference for college attendance: students who reported getting mostly As in middle school have a 70 percent chance of completing college by age 25, while those who get mostly Cs have only a 10 percent chance.

How parents raise children can exacerbate these dynamics. Pressures to be “masculine” are often stronger in lower-income or working-class families, Buchmann says. “The notion of what it means to be a boy and a man, especially among lower working-class boys, makes it such that they see doing well in school as something that girls and women do, and they don’t want any part of it,” Buchmann told me. This is especially true if boys see male role models like fathers or older family members working physical, blue-collar jobs that don’t require an education. They may assume that they’ll be able to work those jobs too, even if they’re disappearing, and think that doing anything else is too “girly.” By contrast, if boys have role models that are educated, they do better in school. Better-educated parents often teach their children a different concept of masculinity in which academic achievement is important. Moreover, they are more likely to know men in careers that require an education, and to have those men as their role models.

Percentage of Black and Hispanic American 25-to-29-Year-Olds With a Bachelor’s Degree or Higher, by Gender

Nita’s brother, Por Vue, who is now 28, told me he thought he was deeply affected by his family’s lack of knowledge about the educational system. He actually applied to and was accepted into Cal State Monterey Bay, but his parents advised him to instead go to a junior college closer to home, he told me. But the junior college was overcrowded and he couldn’t get into many of the classes he wanted, so had to change his major. Then, while he was in college, he started a family, and later dropped out so he could support his wife and kids. He’s now a manager at PetSmart, where he makes around $13 an hour. “I think if I’d had a better family background, I would have had knowledge that other people had, and I would have been able to go further,” he told me.

Boys may also be more susceptible to short-term instant gratification than girls are, Buchmann told me. Boys may have a harder time slogging away at a college degree and paying for it when they know there are jobs available where they could get paid a decent wage, even if that job might not be a long-term proposition. I talked to a 31-year-old in Merced named Edward Vasquez who was one-and-a-half years into a two-year nursing program when he dropped out to take a job as a certified nursing assistant that paid $17.50 an hour. He’s since lost his job and is looking for work.

This is not to say that men can’t succeed if they don’t have a college education. I talked to a woman named Olga Jimenez who was raised by a single mother, and who went to college when her brothers didn’t. But her brother has still made a good career as a real-estate agent, and has a license and his own office, she told me. Meanwhile, Olga had to work three jobs at once while she attended Whittier College and is still paying off her college debt.

Yet Jimenez’s brother is the exception, not the rule. People with just a high-school diploma make, on average, $692 a week, compared to $1,156 for those with a bachelor’s degree. And the returns of a college education have grown over time. People with a bachelor’s degree or higher earn 14 percent more than they did in 1979, on average, according to the Bureau of Labor Statistics; people with a high school degree earn 12 percent less.

As the gender gap grows, there are wider implications for society. People are more likely to pair with others who have a similar educational background; as more women get postsecondary degrees than men, women will increasingly find their marriage prospects dimming. This is already happening in some areas of the country—I wrote in May about a town in Ohio where the women complained that all the men were on drugs or unemployed, while the women held down steady jobs. Their daughters will face a similar future, unless they can get their sons to succeed at—and care about—school.



German Benitez has started two small businesses, both of them restaurants in the city of Gaithersburg, Maryland. His main restaurant, Jazmin Cuisine, employs nine people. He seems like one of the last people any politician interested in job creation would want to kick out of the country.

And yet, on Monday, he learned that the U.S. government is planning to do just that. Benitez, who is 54, is from El Salvador, and like nearly 200,000 other Salvadorans, he has received Temporary Protected Status, or TPS, which allows people from disaster-ravaged countries to live and work legally in the United States—even if they entered the country illegally. The Trump administration said on Monday that it was ending TPS for Salvadorans effective September 9, 2019, though it remains a possibility that the protections will be restored by Congress.

Salvadorans first received the status in 2001, after huge earthquakes in their home country; though El Salvador has since rebuilt, gang violence and poverty remain widespread. (The Trump administration in November announced it was ending TPS for 5,300 Nicaraguans and 59,000 Haitians, effective in January 2019 and July 2019, respectively. A decision on Hondurans will be announced in July of 2018.)

Though the administration didn’t offer an economic rationale for the decision, Trump has often argued that cracking down on immigration will help American workers. During his campaign, Trump pledged to cut down on immigration in order to “boost wages and ensure open jobs are offered to American workers first.” Yet, just days after the decision, The Washington Post reported that the president disparaged immigrants from certain countries, calling several countries “shithole(s).”

The latest developments beg this question: What is the reasoning for the decision to end Temporary Protected Status? Is it really the economy? 

Halting TPS could make the labor market worse for American citizens, not better. Research suggests that taking away legal status from immigrants may draw more people into under-the-table work, which could create even more pressure on wages at the bottom of the labor market, in industries where people employ a lot of undocumented labor. That’s because many TPS recipients likely won’t leave the lives they’ve built in the U.S. and return to countries they fear. Instead, they’ll use borrowed IDs or get paid under the table to continue to work, according to David Bier, an immigration policy analyst at the Cato Institute, a libertarian think tank. That means they’ll have fewer labor protections and less leverage to negotiate for good wages, and as they get paid less, they’ll compete with higher-paid legal workers, bringing wages down.

The end of TPS for Salvadorans creates a nightmare situation for people like Benitez. And it could also have an impact on regional economies with large Salvadoran populations, such as California (with 55,000 TPS recipients), Texas (45,000), and Florida (45,000). About 94 percent of male and 82 percent of female TPS holders are currently working (a rate much higher than the country’s 63 percent labor-force participation rate) and contributing to Social Security and Medicare.

Tom Wong, a professor of political science at the University of California, San Diego, has found that there are 128,790 Salvadorans who earn wages or income in the United States, making $24,429 a year, on average. Deporting them would thus cost the country about $3 billion in annual contributions to the GDP. The removal of nearly 300,000 TPS recipients overall will also affect contributions to Medicare and Social Security, Wong says. On average, employed Salvadoran holders put in hundreds of millions of dollars to Social Security annually.

“The United States benefits immensely when immigrants can work,” Wong and his co-authors wrote in a report about the economic contributions of TPS holders.

The wholesale layoff of the entire employed TPS population of Haitians, Salvadorans, and Hondurans could result in $967 million of turnover costs, which are the costs that employers incur when employees leave a position, according to an analysis from the Immigration Legal Resource Center, a San Francisco nonprofit that advocates on behalf of immigrants. The layoffs will also force workers like Yesenia Reyes, 43, to stop paying the taxes and Medicare contributions she had been paying from the two eight-hour-a-day jobs she works cleaning hotel rooms at Los Angeles International Airport. She now makes more than $14 an hour, because she’s a member of a union, but worries that the end of TPS will make her go back to the life she was working before she got papers—limited hours in a garment factory where the owners paid her below minimum wage, and where she could barely make ends meet. “I’ll have to start all over again,” she told me.

Of course, TPS was not meant to last forever—the T stands for “temporary”—and TPS has ended for other groups before. In September 2016, the Department of Homeland Security ended TPS for around 2,000 Liberian beneficiaries, for example. Some of those in favor of ending it for Salvadorans argue that many of them entered the country illegally and should not be rewarded for doing so. The Trump administration’s decision to end TPS “underscores the temporary nature of TPS, and reminds us that it was never intended to be used as a tool to sidestep the legal immigration process,” reads a statement from Dan Stein, the president of the Federation for American Immigration Reform, a group that advocates for restricted immigration. “‘Temporary’ clearly does not mean ‘forever.’”

But comments by the president about certain immigrant groups have raised questions about the intentions of cutting programs like TPS. If these legal immigrants have helped the economy, what is the point of ending the program that keeps them here? Is it really just about the economy?







Subscribe to Radio Atlantic: Apple Podcasts | Spotify | Stitcher | Google Play

The 'retail apocalypse' is upon us, they say. In the United States, 2017 saw emptied malls, shuttered department stores, and once-iconic brands falling into bankruptcy. Yet retail spending continues to grow, in strange new directions that could have significant effects. What will shopping look like in the future? How will these changes reverberate throughout the country? Atlantic editor Gillian White joins our hosts to discuss.
If you listen to Radio Atlantic, we value your feedback. Please help us out by answering a quick survey. It should only take a few minutes. Just to go theatlantic.com/podcastsurvey.Links







Subscribe to Radio Atlantic: Apple Podcasts | Spotify | Stitcher | Google Play

“Politicians from both parties publicly worship the solemn dignity of entrepreneurship and small businesses. But by the numbers, America has become the land of the big and the home of the consolidated,” writes The Atlantic’s Derek Thompson.
In a time when Americans have lost faith in their institutions, the nation seems to now look to corporations for positive action. Can big business be a force for good or only a force for profit? Does their very size pose a threat? If corporations can be people, can they be good citizens?Links







Subscribe to Radio Atlantic: Apple Podcasts | Spotify | Stitcher | Google Play

In December 2007, the U.S. marked the beginning of its longest recession since World War II. Now the Consumer Financial Protection Bureau, an agency born in the ashes of the nation's economic downturn, is under new leadership that promises big changes. Meanwhile, a tax plan speeding through Congress could have far-reaching effects on the economy, well beyond taxes. On paper, the U.S. economy looks robust. But for whom, and for how long?

This week, Annie Lowrey and Alana Semuels join our hosts to look at what's happened in the decade since the Great Recession, and what's happening now. What lessons have we learned from the crisis? And which are we doomed to repeat?

Links:



Seven years ago, Donald Trump bought a vineyard and winery in Albemarle County, Virginia, a few miles south of Monticello. The property had belonged to the ex-wife of John Kluge, the late founder of Metromedia (which later transformed into Fox News) and once the richest man in America. Kluge’s 1,300-acre property went to his former wife, Patricia, in a divorce settlement, and it was she who had the vineyard planted and a small winery built.

According to Trump’s son, Eric, his father doesn’t drink and bought the property because “wine’s sexy.” In so doing, Trump joined the ranks of a relatively new class in America, the “lifestyle vintner,” a type of hobbyist investor who makes money in another field and then buys into wine, mostly for the social and financial cachet. Trump is but the most famous of them; the owners of thousands of smaller enterprises across the country—wine’s now made in every state in the union—qualify as well.

Vintner is a word that implies a knowledge of vines, husbandry, and winemaking, and a significant amount of physical labor. Not so the lifestyle vintner. It is a somewhat deprecating honorarium for mostly wealthy individuals with none of the above. Their surnames hover artfully on bottles of cabernet sauvignon and chardonnay, all deeply punted and impressively expensive.

These bottles are social entrées of a sort, often representing a quick, handy makeover. Former labels—oil man, developer, sports mogul, tech entrepreneur, financier—are jettisoned for a new title redolent of European nobility. Those defined by their accumulation of money turn their backs on that past, benefiting from a kind of lay transubstantiation in which wine washes any previous grubby associations away.

Lifestyle vintners’ websites sag with paeans to nature, viticulture, and terroir (as well as, of course, themselves). But few truly embody the back-to-the-land credo of the ‘60s and ‘70s that made world-famous places like Napa Valley, now first choice for American lifestyle vintnerhood. I have been writing about Napa since the mid-‘80s and have watched this increasingly glamorized culture change the nature of the valley for the worse. The wines have become—with notable exceptions—standardized, and the gap between real agriculture and the glamorized version has grown.

This has proved to be a very lucrative distinction. Napa wine accounts for only 4 percent of California’s total, but in conjunction with tourism and related industries generates about $13 billion a year, according to trade-group estimates. Though it’s impossible to say precisely how much revenue is earned by lifestyle vintners, it is considerable—and made possible in large part by capable immigrant labor.

Thanks to the rise of the lifestyle vintner, the market is now glutted with new wines in a numbingly similar style. Critics generally favor them, most costing well over $100 a bottle, and as a result many of the richest American palates have developed a taste for alcoholic, overripe cabernet. Napa still has its small, inspired producers, but also mega-companies—Constellation, Treasury Wine Estates, Kendall-Jackson, Gallo—that churn out bottles for nationwide distribution.

Lifestyle vintners have also left their mark on Napa’s landscape. Most refer to themselves with straight faces as “farmers,” even as “environmentalists,” while more trees are cut on surrounding mountainsides for yet more vineyards. They loudly praise the valley’s exemplary past and glorious future while exploiting its present. For instance, a prominent computer-boom beneficiary named Mike Davis has spent more millions on his sprawling new winery than will likely ever be recovered through wine sales. Since the Napa Valley floor is all planted, only the hillsides are available for new vineyards. And Davis is bent on scraping out a vineyard high on Howell Mountain that would adversely affect a precious wildlife preserve, one of the state’s most biologically rich remnants. (Davis did not respond to an interview request.)

There’s been a clamor over similar plots of land as a changing climate has prompted vintners to get the most out of Napa before possibly having to move on to the Pacific Northwest or the Rockies. Many lifestyle vintners are developers who resent objections to their plans by members of the community. Such names are common on labels. One—Craig Hall of HALL Wines—has been in a decade-long struggle with a local community that’s trying to prevent his cutting of some 14,000 trees on more than 2,000 acres in a remote part of the county.* A Dallas developer and former co-owner of the Dallas Cowboys, Hall, like Trump, has bounced back from bankruptcy and moves among high-risk investments.

Hall’s new project in Napa would partially deforest a 2,300-acre untrammeled swath of land.* This destruction wouldn’t be for something useful like growing food, but rather for yet more derivative wine beyond the financial reach of most people. Locals fear that mansions will follow, as they so often do in California. (Hall declined to be interviewed for this story, and a representative of his referred me to the county’s public records about the new project.)

After several disputes like this, social discord has grown steadily in the valley. Thousands of Napans signed a petition to put an initiative on the 2016 ballot to increase regulation of timber cutting in the hills. But a phalanx of trade groups—the Napa Valley Vintners (the host of an exclusive annual wine auction), the Napa Valley Grapegrowers, and the Winegrowers of Napa County (a coalition of corporations and wealthy individuals)—opposed it. The industry’s sway was clear when the county disqualified the initiative on a technicality.

A similar initiative is back on the ballot this year, but as lifestyle vintners leave their mark on the landscape, the influence of a different type of vintner is receding. Salvestrin Vineyards lies at the end of a dirt driveway just up Highway 29 from its antithesis, HALL. Its white-frame farmhouse was built in 1879, adjacent to a vineyard that was planted in 1859. The owner today, Rich Salvestrin, is blue-eyed, burly, and burnished by the California sun. His grandfather came to the area from Northern Italy, via Ellis Island. “He helped neighbors with their vines, and bartered his labor for the use of a horse,” Salvestrin said. “My father took over, and in 1950 bought a tractor. I’ve been tied to this land for as long as I can remember.”

Salvestrin worked in the vineyard growing up and is a useful case study in the opportunities and difficulties of small winemakers in Napa Valley. Salvestrin Vineyards is 18 acres—less than it used to be, as he sold some acreage to the local school—adding value to the crop by turning it into wine that is sold at a much higher price. But there construction stopped. The operation supports his family, including three daughters, and his parents who still live in the house. As for current tensions between development and agriculture, Salvestrin says, “We’re at the tipping point. This place should be about the wine.” More and more people are thinking just that.

* An earlier version of this article stated that Hall seeks to cut down 28,000 trees. That was the original number of proposed trees; after public debate, Hall reduced the number to 14,000 trees. We regret the error.* An earlier version of this article mischaracterized the extent of deforestation, and said the property had never been damaged by forest fires. The property was damaged in a wildfire last year. We regret the error.



Traffic is getting worse in New York City—much worse. Average speeds during business hours in Manhattan’s core dropped to a crawl in 2017—about six miles per hour, 15 percent slower than in 2010.

That time is everyone’s money: According to INRIX, a transportation analytics firm, lost hours and excess fuel costs sucked nearly $17 billion out of the New York City economy in 2016. That’s not far off from the GDP of Iceland.

North America’s second-largest city is growing: Population has climbed at least 4 percent since 2010, thanks to steady immigration from around the world. But it’s another group of recent arrivals that bears the brunt of responsibility for the new traffic: Uber, Lyft, Via, and the rest of the ride-hailing bunch.

Bruce Schaller, a former NYC Department of Transportation official and expert on New York City street traffic and the for-hire car industry, has a new report out on just how severely the rise of “transportation network companies” (or TNCs) has affected congestion. Using data from the New York City Taxi and Limousine Commission, Schaller studied passenger trips, vehicle speeds, and mileage per hour of taxis and TNCs in Manhattan’s core business district from 2013 to 2017.

The key takeaways: During that time period, total passenger trips increased 15 percent, even as taxi trips declined. That means TNCs have created new demand for backseat rides in Manhattan. And they increased the amount of miles traveled by for-hire vehicles around downtown by a whopping 36 percent, over the same time period. That adds up to more than 600 million miles of motor-vehicle traffic in the past 3 years alone—reflecting not only the staggering growth in rides, but also a trend toward lengthier trips and more “deadheading,” or cars traveling without passengers.

With a 59 percent increase in the number of for-hire vehicles, the data makes a pretty clear statement: On-demand mobility is transforming New York City streets, and it does not appear to be for the better.

“For years, as the city grew, more and more people took the subway and bus,” Schaller says in a short documentary on the subject called “Unsustainable.” “Now, as the city grows, more and more people are taking Uber, Lyft, and Via. This is not a sustainable way for the city to grow.”

Meanwhile, the quality of New York City’s mass transit is in free fall. Not only has MTA bus ridership rapidly dropped in recent years, but the subways are now losing passengers, too. This can be attributed in part to declines in service, as abysmal delays and mechanical failures have become a near-daily feature of underground commutes. (Also: The schedules need reworking.) But Schaller’s and others’ research offers evidence that TNCs are drawing more-affluent passengers off trains and into cars. “People don’t feel as likely to be able to use [transit] to get where they need to be going,” Brad Lander, a city-council member representing parts of Brooklyn, says in the same film.

That’s a lose-lose situation: Fewer transit riders means less revenue and demand for improved transit—disproportionately affecting low-income New Yorkers who have no choice but to remain aboard increasingly lousy trains and buses. “These are the effects of an inequitable, underfunded transit system,” Jessica Quiason, a researcher at ALIGN, a labor-organizing nonprofit, says in “Unsustainable.”

And more ride-hailers means more traffic—which hurts those who don’t own or travel in private cars. Clogged streets are also slowing down city buses, packages, and freight. It slows down first responders, repairmen, teachers, and nursing aides. What this all amounts to, according to Jon Orcutt, the director of communications and advocacy at the New York pro-transit group TransitCenter, is “our worst transportation crisis in decades.”

This is hardly an “only in New York” problem. A recent study from UC Davis took a comprehensive look at Uber and Lyft’s effects on transportation systems in eight U.S. cities (including New York) and found TNCs having similar adverse effects in Boston, Chicago, Los Angeles, the Bay Area, Seattle, and Washington, D.C. The reason Schaller’s traffic critique is so detailed and data-rich is because New York is one of only a few cities in the world that requires Uber, Lyft, and other such companies to share trip data for analyses like this one.

Untangling the MTA from its many financial and political challenges has been a topic of intense debate and media scrutiny in New York in 2017. But Schaller’s report argues that what’s happening aboveground can’t be separated from public transit’s woes, and a chorus of transit advocates in “Unsustainable” take up that theme.

If the city wants to keep moving, Schaller suggests three key public-policy moves: First, prioritize lanes and parking space for the highest efficiency vehicles, like buses and vans, to reward and incentivize the use of shared transportation.  Second, move more freight traffic during off-peak hours. And third, treat roads like a precious commodity, and charge drivers to use the ones in highest demand, perhaps with a special fee for TNC trips. Such an approach is known as congestion pricing, and it’s long been proposed for the city. The revenue could go into the MTA. (New York Governor Andrew Cuomo has said he’d support this; Mayor Bill de Blasio says he would not.)

These problems easily stand to get worse, not better, with the rollout of self-driving vehicles. If local leaders don’t take the wheel on regulating TNCs, city drivers might be idling for a long time.

This post appears courtesy of CityLab.



Shohei Ohtani was the most sought-after free agent in all of baseball this off-season. Based on his career so far in his native Japan, the 23-year-old star, who signed on Friday with the Los Angeles Angels of Anaheim, may turn out to be the first player since Babe Ruth who can both pitch and hit at a major-league level—a possibility that led Robert O’Connell to write in The Atlantic that Ohtani might be revolutionary not for his new team, but for baseball as a sport.

Ohtani is so promising that scouts estimate he would be worth more than $200 million, cumulatively, between now and the time he’s 30. The Angels, though, signed Ohtani at a bargain rate—the league-minimum salary of $545,000 per year, plus a one-time signing bonus of $2.3 million. If he’s such a valuable player, why is he making the lowest the league is allowed to pay?

Under Major League Baseball’s collective-bargaining agreement, or CBA, an incoming international player under the age of 25 like Ohtani can only sign for the league minimum salary; he’s now committed to the Angels for six years at that rate (unless they trade him, a decision in which he will have no say). Until this year, the CBA permitted teams to offer large signing bonuses that would make up at least part of the difference between a player’s salary and his actual value. Unfortunately for Ohtani, though, a provision in the new CBA ratified earlier this year severely limited those signing bonuses for international players; the $2.3 million the Angels offered was among the largest put forward by any team. (For added irony, the Angels will be paying Ohtani’s former team in Japan, the Nippon Ham Fighters, $20 million just for allowing him play in the U.S.)

Even Ohtani’s current contract is an impressive amount of money to make playing baseball, and there’s been no indication that he is unhappy with his lot. Still, that Ohtani will be making so little while potentially redefining baseball reveals one of the biggest paradoxes in American pro sports: Though they may look meritocratic, leagues dramatically underpay their talent, to the great benefit of league front offices and teams’ owners, who do far less than the players to influence the on-the-field outcomes fans pay to see.

Ohtani’s massively deflated contract is an especially extreme example of this trend. Under the CBA, any international player who enters the majors or minors under age 25 gets the same basic deal, as do American players who enter through the draft. Ironically, says David Berri, a sports economist at Southern Utah University, the initial goal of that standardized contract was to spark bidding wars and increase the salaries of star players. In 1974, an arbitration ruling struck down the “reserve clause,” which allowed teams to hold onto their players indefinitely and prevent the players from negotiating with other teams. “What basically was facing baseball [at that time] was, every player was going to become a free agent, so the market was going to be flooded with free-agent talent,” Berri says, which would have driven down players’ salaries. Berri went on, “But Marvin Miller, the head of the union in baseball, suggested, ‘Why don’t we have it be that you can only become a free agent after six years?’ That way, in any given year you’d only have a few free agents, and their price would be elevated.” By staggering when players became free agents, Berri says, the union ensured that “baseball salaries went up dramatically, and star players got paid a ton of money.”

But in the last 20 years, Berri says, owners have found a way to exploit this arrangement. As statistical analyses have started to show, hitters tend to peak in those first six years under team control, then steadily decline beginning at age 26 or 27. The aging curve is even harder on pitchers, who typically see their velocity start to decline the moment they make the majors. Increasing recognition of these trends, coupled with the prevalence of young superstars like Mike Trout, Bryce Harper, and Francisco Lindor, means that the demand for older players—and in baseball, “older” means “30 and up”—has begun to shrink.

That leaves a player like Ohtani in a bind. Were he to wait two years and enter the league at 25, he could plausibly get the $200 million contract his talents dictate—or more, given that average salaries increase just about every year—while gaining the ability to negotiate the length of his contract. But he would be banking on teams either being willing to pay him into his likely decline based on just his track record in the less competitive Japanese league or to sign him for a shorter length of time, not to mention gambling on the prospect of injury or physical deterioration while still in his home country. Suddenly, that $2.3 million and a guaranteed six years at the league’s minimum pay sounds a lot more appealing, even if it does mean giving a team a $200 million discount.

The cumulative effect of this system—which, as Berri noted, was initially implemented to benefit players—is to doubly advantage owners and the league. Teams are able to not only load up on young players at a steep discount but also to hold onto those players for longer than most free agents would choose to sign. This shift helps explain why, as the Indiana University professor of business economics and sports law Nathaniel Grow noted in a post on the baseball website FanGraphs, the share of the league’s overall revenue going to players has dropped precipitously, from 56 percent in 2002 to 38 percent in 2015, with the difference going to owners and the league’s front office.

The question, then, is not how Ohtani ended up so dramatically underpaid; it’s how a system that so dramatically underpays its most visible and valuable employees perpetuates itself.

The most obvious culprits are the system’s biggest beneficiaries: owners and the league’s front office, who push for many of the measures that allow them to take home more and more of baseball’s revenues. From their perspective, says Grow, “they would say they need to limit the amount of money teams are able to spend because it’s a competitive-balance issue. If you had a totally free market, high-revenue teams could spend massive amounts of money to always sign the best amateur talent, and over time that would cement their dominance on the playing field. There’s probably some hint of truth to that.” Backing up Grow’s description, international signing-bonus allocations are tied to a league provision called “Competitive Balance Picks.”

Berri is less charitable toward the league’s and owners’ claims about competitive balance. “There’s no evidence that it works that way,” he says, adding, “These [rules] are all designed to throw money at the owners. It has nothing to do with anything else.”

But it’s also important to recognize the players union’s role in perpetuating the skewed system. “The Major League Players Association only represents players who are currently in the major leagues,” Grow notes. “They do not represent players who are incoming professional talent, nor those players who are in the minor leagues.” As players’ share of revenues have declined, “the Major League Players Association realizes that it's getting pinched financially,” Grow says, “so that motivates them even more to give up on the rights of amateur players, to try to preserve as much as they can for their current membership.”

These trends help explain not only why valuable young major-league talent is so underpaid but also why thousands of minor-league players still make poverty-level wages. “As long as the players union signs off on it,” says Berri, “there’s no motivation for Major League Baseball to give more money than they have to. From Major League Baseball’s perspective, that’s a good thing, because then it impacts the bottom line: They see more money, and they see less of it flowing out to labor costs.”

However one allocates the blame, the vast discrepancy between what teams actually pay and what they’d be theoretically willing to offer is in practice a giant loophole for creative front offices. As an example, Grow points to Yoan Moncada, a Cuban prospect who signed with the Boston Red Sox in 2015 and now plays second base for the Chicago White Sox. Under the rules in 2015, the Red Sox had roughly $1.9 million to spend on signing bonuses for international amateur free agents; every additional dollar incurred a 100-percent penalty from the league. So when the team gave Moncada a record-shattering signing bonus of $31.5 million, it also agreed to a fine of more than $29 million, effectively acknowledging that the team would have been willing to pay Moncada at least $60 million if not for the CBA’s deflationary provisions. (Similarly, by paying the Nippon Ham Fighters $20 million to sign Ohtani, the Angels signaled that he is worth at least that much more than his contract.)

Egregious though it looks, the Red Sox’s deal with Moncada was governed by the CBA as any other agreement would be (and, according to Grow, was actually part of the league’s decision to push for the stricter provisions at play in Ohtani’s contract). The Atlanta Braves were less scrupulous. In November, the league penalized the Braves for several contract violations, including routing money to players through friends and associates, all designed to offer young international prospects more than the team could through official channels. In doing so, the Braves demonstrated not only that the players’ values exceed the dollar amounts on their contracts but also that the team was willing to risk harsh penalties to sign the players, suggesting their true value was even more than the sum of the aboveboard and off-the-table payments. (The new CBA aims to further crack down on such activity, although the MLB will launch an investigation into Ohtani’s contract negotiations with the Angels, just to be safe.)

Though the rules differ from league to league, the wage-suppressing dynamics in Major League Baseball pervade American professional sports. The National Basketball Association, the National Football League, and the National Hockey League all have maximum salaries for teams, players, or both; in the NBA, these have also inadvertently contributed the rise of “superteams,” undercutting claims that the provisions create competitive balance.

The most extreme example, though, is the National Collegiate Athletics Association, or NCAA, whose rules explicitly bar players from receiving compensation for their play. Though ostensibly in place to make sure athletes prioritize academics, the rules have been enforced to punish everything from schools inflating players’ grades to ensure eligibility to coaches buying meals for students. And even with such seemingly strict enforcement, schools are still so routinely busted for recruiting violations (the University of Louisville in particular has been a repeat offender in recent years) that the illicit flow of money in college recruiting has long been a talking point in favor of allowing schools to pay their student-athletes. After all, what is a recruiting violation other than a tacit admission that the players are worth enough to the school to risk the ensuing punishment?

To Berri, this kind of bad behavior is the inevitable result of deflating athletes’ pay, whether the resulting salary is enormous or nonexistent: “The fact is, if you’re going to restrict how much somebody can bid for a player, and it’s below their market value, then you’re definitely going to be encouraging cheating.”

The inevitable rebuttal to all of this is that professional athletes are still paid handsomely for their abilities to hit and throw small white balls with wooden sticks. And when it comes to student-athletes in particular, some argue that scholarships, plus the chance to become a rich professional, should be reward enough.

In Berri’s opinion, this attitude fundamentally misses the point. “People imagine that these people's lives are glamorous, and they’re getting something they couldn’t get, and the fact that they’re not adequately compensated is fine,” he says. “They never think of the flip side: That really, what this means is that an owner who’s never done anything gets all of the money. You have this small number of people, typically older white males who’ve never done anything, are being handed over money that other people are making. Shouldn’t that bother people to some extent?” Perhaps. But Ohtani, for one, doesn’t seem to mind—or at least, not enough to hold out long enough to be paid what he’s really worth.



Officials from Cincinnati, Detroit, Nashville, and Sacramento appeared in New York on Wednesday to place their bids with Major League Soccer (MLS) for an expansion team. Slots for two teams are now up for grabs in the league’s plans to expand, so cities are lining up to lob promises of tax incentives for stadium construction at the MLS.

Cincinnati, for example, has secured $200 million in private funds to build a stadium for FC Cincinnati, and the city has pledged up to $75 million in public money to pay for the infrastructure associated with a stadium. Nashville promises $25 million in tax dollars toward build-out costs for a $275 million Nashville Soccer Club stadium, which would be paid for through a public-private financing deal. Representatives for Sacramento Republic FC argued for a plan that would cost the city $46 million to realize a privately financed $226 million stadium.

Meanwhile, the Detroit Express would play on Ford Field, the home of the NFL’s Detroit Lions, meaning that the proposed soccer team’s owners—who also own the Lions, the Detroit Pistons, and the Cleveland Cavaliers—would merely have to put up the $150 million franchise fee plus some smaller costs in adjusting the existing stadium.

Various metro-area would-be soccer hooligans won’t have to wait long for an answer. Major League Soccer intends to announce its decision before December 19.

If this all sounds familiar—convoluted stadium-financing deals, half-hearted pledges to stay on budget, dispiriting expansion-team logos—that’s because the stadium boondoggle is America’s favorite pastime. Professional soccer may have a mixed record as far as capturing the imaginations of American sports fans in recent decades, but it’s now eclipsing football in the rush for public giveaways.

Maybe that’s because no one seems to like the NFL anymore: not President Donald Trump, not Jerry Jones, and not TV audiences, which have been walking away over the last couple seasons (although not as fast as they’ve fled network television in general). Revelations about the sport’s grievous toll on the brains of players are mounting, and the take-a-knee protests have alienated many a conservative fan. No football team has had it harder than the Los Angeles Chargers, a winning team that has struggled early this season to fill even half its seats at the 27,000-seat StubHub Center—a soccer arena.

How the Chargers will find takers for its planned $2.6 billion, 70,000-seat stadium in Inglewood when it can’t top out a soccer park is anyone’s guess. It’s not like the other L.A. team is faring any better: As FiveThirtyEight notes, the Los Angeles Rams are closing in on the largest season-to-season drop in game attendance in NFL history. Yet city leaders around the country, seeing what might be cause for alarm in a major market like L.A., appear to have decided that the only problem here is American-style football.

Enter Austin, a city with no pro-soccer presence and no plain stakes in Wednesday’s friendly for an MLS team. Austin wasn’t even one of the 12 cities that made the semis in the MLS expansion tournament—all of which are still eligible for the other two expansion team opportunities (to be determined later). Nevertheless, a would-be ownership group in Austin stepped forward on Tuesday with a fancy rendering of what looks a lot like a dedicated soccer arena, perhaps in the hopes of tipping the scales in MLS’s decision-making process.

The group, Austin Sports & Entertainment, pitched a plan to build a 15,000-seat arena with a 40,000-seat outdoor bowl under a series of rust-colored roofs, in a checkerboard design scheme tendered by the world-renowned design firm Bjarke Ingels Group. The so-called East Austin District would replace the Travis County Expo Center as the new home for Rodeo Austin, marrying the best in Central Texas bull-riding with the brightest in contemporary Danish architecture.

It’s almost certain that Austin Sports & Entertainment is aiming to attract the Columbus Crew SC, whose owner has spoken publicly about moving his team to Austin. One of the principals of Austin Sports & Entertainment is Andrew Nestor, an owner or executive for the Tampa Bay Rowdies (soccer), Bologna F.C. 1909 (soccer), and Americas Champions League (soccer).

Major League Soccer officials might view this quiet offer from Austin as reassurance that an expansion team in Cincinnati would not overcrowd the Ohio market, given the potential departure of the Columbus team. Or it could light a fire in Columbus to build the stadium that the Crew’s owner demands to keep the team in town. For what it’s worth, Austin Mayor Steve Adler’s office told me that the city won’t pay for a stadium—but that the city thinks there’s enough private capital to build one.

In the next few years, as many as four cities may build dedicated soccer arenas. That’s not counting the Banc of California Stadium in L.A. or Audi Field in Washington, D.C., both of which are under construction. Most of these cities are making the sensible decision to demand that private owners put up the capital to build any stadium, but it’s not all of them, by any means.

And no city appears to be weighing the hidden costs of a soccer arena—which is the same as that of a baseball park or a football stadium. In a decade or so, the owner will threaten to sell the team to a new sucker unless the city builds a new stadium, just like Columbus’s owner is doing now. Then, even when a city has only put up the costs of infrastructure, the investment will come up far short. Football may not be able to pull off this scheme anymore, but soccer is only getting started.

This post appears courtesy of CityLab.



At happy hours and class breaks, at the part-time MBA program I attend through the University of Texas at Austin, the conversation often drifts toward new business ideas. A mobile app to schedule text messages in the future. (Use case: Compose your best friend’s happy birthday text the day before.) A social network that doesn’t sell your personal information or display any ads. (Business model innovation: monthly subscription fee.) A winery in a surprisingly temperate, beautiful, and affordable region of central Oklahoma. A friend of mine was once so inspired by his own start-up concept that he pulled out his phone, checked the availability of his preferred URL, and registered the domain name on the spot.

Similar scenes play out at lots of business schools. The majority of MBA students range in age from the mid-20s to the 30s; with all the discussion of start-ups and new businesses, it would seem that they’re living the Millennial dream of entrepreneurship. But it seems more often than not these days, the start-up ideas fail to take off. When I check on my peers’ start-up proposals after a few weeks, I often find that their ideas have been abandoned, and that my classmates are focused on their steady corporate jobs.

Research suggests entrepreneurial activity has declined among Millennials. The share of people under 30 who own a business has fallen to almost a quarter-century low, according to a 2015 Wall Street Journal analysis of Federal Reserve data. A survey of 1,200 Millennials conducted in 2016 by the Economic Innovation Group found that more Millennials believed they could have a successful career by staying at one company and attempting to climb the ladder than by founding a new one. Two years ago, EIG’s president and co-founder, John Lettieri, testified before the U.S. Senate, “Millennials are on track to be the least entrepreneurial generation in recent history.”

Some of the reasons have been well-documented. The romantic view of entrepreneurship involves angel investors and venture capital funds, but in fact, the ordinary entrepreneur is more likely to fund a start-up using personal savings—something underemployed Millennials simply could not build as they entered the workforce during or in the immediate wake of the Great Recession. Funding from friends and family is the next most common source, but this personal network could not help much during the most recent economic downturn, when so much home equity was underwater. Student debt worsened the underlying economic problems. According to a report by the Federal Reserve Bank of New York, between 2004 and 2014, the number of student borrowers rose by 89 percent.

Lately, though, it seems that even those who might typically have access to other forms of funding, like venture capital, are having a hard time getting investors’ attention. As Matt Krisiloff, a former director at the Y Combinator start-up accelerator in Silicon Valley, tweeted, “Start-ups are a lot less cool than they used to be.” Michael Sadler, an economist at the University of Texas at Austin, is concerned about the rising concentration of start-up investment in just a few super-performing regions such as Austin, New York, and Silicon Valley. As with American politics, it appears the geography of U.S. venture capital and economic growth has become increasingly polarized.

There’s more competition from abroad, too. Chinese venture capital and private-equity firms—and the entrepreneurs they invest in—are challenging America’s historic tech dominance. In the past, this kind of investing tended to involve American funders and American companies. But last year, Asian investors put nearly the same amount into tech start-ups as their U.S. counterparts, according to the Wall Street Journal, with most Chinese-led investments going into the country’s own firms. Of the top five global VC deals in 2017, three were Chinese companies: Didi (a ride-sharing app), Meituan-Dianping (an e-commerce platform), and Toutiao (a news feed reader).

Meanwhile, in the United States, products and services are increasingly being created on top of existing platforms like Apple’s iOS or Google’s Android platform. While a mobile app can make for a decent side hustle to a regular corporate job, it won’t turn into the next Apple or Google, and American investors know that. The more attractive investments are in industries like health care, where there is still opportunity to build a profitable platform. One of the biggest tech deals in the U.S. last year was Outcome Health, which installs video screens in doctors’ offices and charges pharmaceutical companies to display ads to patients. In a thread attached to his tweet about start-ups, Krisiloff, the former Y Combinator executive, added that the opportunities “to start compelling start-ups,” for college students without industry-specific knowledge, “has vastly shrunk.”

While the Austrian American economist Joseph Schumpeter is best known for his 1942 paper describing his theory of “creative destruction,” the process of disrupting existing industries through business innovation or technological change, few people know about another prediction he made: He believed that innovation would gradually become an embedded process within large corporations. In many ways, Schumpeter predicted the internal innovation hubs of corporate giants like Amazon and SAP. With incumbents making innovation part of their established routines, he theorized, they would gradually squeeze out the traditional entrepreneur.

Some of the people who are innovating from within companies like Apple—which in August became the first publicly traded company to surpass a market value of a trillion dollars—might be glad about this development, Sadler said. “They think, ‘I don’t have to start up my own company in the garage, or worry about whether I’m ever going to survive. It’s all there for me now.’” But there is plenty of cause for concern. An economy dominated by older incumbent firms may be less likely to achieve consistently strong rates of growth, according to a 2014 paper from the Brookings Institution. Lettieri also questions whether big companies—in a world with less pressure from start-ups—“have any reason to innovate due to competition.”

When my classmates tell me about their start-up ideas, we sometimes also talk about what’s holding them back. Whether it’s student-loan payments, or the feeling of playing an impossible game of catch-up since the Great Recession, we often understand each other’s problems. Some entrepreneurs might argue that these shared generational experiences and the accompanying sense of solidarity will inspire Millennials to support one another’s business ventures. It’s a nice idea, but it’s not necessarily certain. Research into the personality traits of entrepreneurs shows that, as a lot, they trend toward optimism bias.



On a bright, hot afternoon in early July, Chicago Mayor Rahm Emanuel stood in the backyard of Le Penseur, a youth-and-family-services center on the South Side, and dipped a brush into sky-blue paint. He filled in a stripe of the Chicago flag sketched on a wooden box resembling an oversized birdhouse. More unfinished boxes sat on tables surrounding the yard. He was surrounded by a group of teenagers who will paint the boxes, fill them with donated books, and install them around the city as free lending libraries, as part of One Summer Chicago, a city-sponsored summer-jobs program. “We need something to bring people together,” Emanuel said.

Over the past few years, U.S. mayors such as Emanuel have been pushing to revive city summer-jobs programs, despite little federal support. The city programs place young people—typically ages 14 to 24, usually chosen by lottery—into subsidized jobs for six to eight weeks at government agencies, nonprofits, and businesses. The mayors are concerned about persistent youth unemployment, especially among young people of color. The hope is that if young people start working while they are students, they will build networks with mentors and employers who will keep them engaged with school and careers. And so, in some of the biggest cities in the United States, mayors are expanding the programs rapidly: Chicago went from 14,000 participants in 2011 to 32,000 this year, New York from over 47,000 in 2014 to nearly 70,000 last year.

But recent research on the programs’ effectiveness shows that, while mayors tend to emphasize the benefits of early work experience, simply enrolling tens of thousands more kids doesn’t solve long-term employment problems.

Summer-jobs programs have gone in and out of favor over the past several decades. They became popular in the 1960s, when elected officials raised concerns that poor communities had been cut off from economic opportunity. In 1964, Lyndon Johnson pushed for the creation of a Neighborhood Youth Corps, which reserved federal funding to hire teens for summer jobs and other work experience, as part of his War on Poverty. He characterized anti-poverty efforts as “a struggle to give people a chance ... to allow them to develop and use their capacities, as we have been allowed to develop and use ours, so that they can share, as others share, in the promise of the nation.”

Under Bill Clinton—who participated in federal summer-jobs programs as a young adult—funding for stand-alone summer programs dried up, replaced by an emphasis on year-round youth services. Without federal support, enrollment in summer-jobs programs dropped an estimated 50 to 90 percent from nearly 600,000 people per year in the 1990s. Then, in 2009, under Obama, the federal stimulus package provided $1.2 billion to states for youth employment and training, with an emphasis on summer-jobs programs to address high teen unemployment during the recession. About 300,000 students, including 8,000 in Chicago, took part that summer.

More recently, though, only small amounts of federal funding have been available for summer jobs, so mayors are cobbling together money from their budgets, philanthropists, and corporations, to place young people into subsidized jobs at government agencies, nonprofits, and small and large businesses.

One Summer Chicago began in 2011, shortly after Emanuel was first elected. Chicago’s Department of Family and Support Services, which runs the program, will spend $17 million on it this year, supplemented by funding from other city agencies and corporate partnerships; the investments subsidize wages and help cover operating expenses. Across Chicago, high-school students and other young people will paint murals, plant gardens, and answer phones in offices, among many other tasks. Emanuel, who is running for a third term next year, said he wants to make Chicago’s program the largest in the nation, though he said his office is reaching its limits. Mayors have pressed the federal government to earmark more funding for summer jobs, but they’ve had little success. “Without federal or state assistance, I cannot grow it,” Emanuel told me. “I need the federal government and the state to become a partner.”

Most recruitment for the summer-jobs program happens through the public high schools, and Emanuel said students who participate in One Summer Chicago sign a pledge committing to apply to college. While there are many teens and young adults who are neither in school nor working, city officials said those young people need more support than a short-term summer job can provide. Lisa Morrison Butler, the commissioner of the Department of Family and Support Services, told me, “This is not designed as a program for acutely disconnected youth.”

The push for summer jobs is happening at a time when a far smaller proportion of teens are working overall than in previous decades. The employment-to-population ratio for 16-to-19-year-olds was 43 percent in July 2016, well below the peak, for the month of July, of nearly 72 percent in 1978. That’s partly because many more teenagers are in summer school now than in previous decades: 42 percent were enrolled in classes in July 2016, compared with only 10 percent in July 1985 (the first year for which such data is available). But, especially for non-white youth in areas that have seen steady job losses over recent decades, it could also have to do with a dearth of opportunities. In Chicago, in particular, the decline of the manufacturing industry since 1960 has made it harder for young people in much of the city to find work, according to a study by the Great Cities Institute at the University of Illinois at Chicago. In 2015, the study said, 20- to 24-year-olds were worse off in Chicago than they were in 1960.

Even now, as unemployment has reached historic lows nationwide, young people in Chicago are not catching up. As factories disappeared, jobs concentrated in the city’s downtown instead of being distributed throughout the neighborhoods. Many jobs available today are either in professional services or are relatively poorly paid retail positions. Hiring bias based on race persists. In some areas, public transportation is lacking, making commutes difficult. (The city plans to extend its El train system to the far South Side by around 2026, better connecting people to downtown, but it is still working out funding details.)

At Emanuel’s Chicago event, Mychael Thompson, an 18-year-old with thin braids and a slight build, watched as the mayor circulated among the students, who wore gray T-shirts bearing the One Summer Chicago logo. Thompson is helping build the small lending libraries. “A lot of things happen on the streets now, so if you give kids something to do, their mind set won’t be on other things,” he told me.

Thompson lives in Roseland, a South Side neighborhood where community activists have tried to counter a lack of resources with a number of efforts including nonprofit organizations that develop affordable housing and counsel first-time home buyers. Its stretch of Michigan Avenue used to be a thriving commercial district, but blockbusting by real-estate agents and large factory closures damaged its economy. In the 1980s, Barack Obama briefly worked in Roseland as a community organizer. More recently, Chicago State University, where the poet Gwendolyn Brooks once taught, nearly shut down because of delayed state funding. The murder rate in Roseland is among the highest in the city. (Homicides throughout Chicago declined 15 percent last year, following a 58 percent increase in 2016 to more than 750 deaths.)

Asked what people get wrong about teenagers, Thompson said they “put bad things on kids, like they say they’re not going to be something, especially in the Roseland neighborhood,” he told me. “I just want them to know we’ve got kids who are really smart, really intelligent, doing really good things.”

Summer jobs make teens’ lives better in one important way: There is evidence that they reduce violence. In 2017, the University of Chicago Urban Labs released a study of One Summer Chicago Plus, a subset of the summer jobs program. In addition to job placements, participants in the 2013 Plus program worked with mentors and received cognitive-behavioral training to improve their goal-setting and conflict-management skills. The researchers found the 2013 program, which recruited students from high-violence neighborhoods and accepted referrals from criminal-justice agencies, reduced violent-crime arrests of participants by 33 percent for the following year. After two to three years, they still had 20 percent fewer arrests for violent crime. Because the decreased violence persisted beyond the short-term summer program, there seemed to be more of a benefit than simply keeping young people busy. (Arrests for property crime went up, which, according to the researchers, may be because participants travel to wealthier neighborhoods with more opportunities for theft.)

The researchers suggest that the young people in the program may have had fewer opportunities to fight, and that their job experiences and social training could have helped them learn to reduce conflicts outside of work. Studies of the summer jobs programs in Boston and New York City found similar reductions in crime.

It’s less clear that summer-jobs programs, as currently designed, make teens significantly more employable. The University of Chicago researchers found no overall improvement in school attendance or employment for the One Summer Chicago Plus participants. However, one subgroup of young people—who were younger, more engaged in school, more likely to be Hispanic, and less likely to have been arrested—had a 14-percentage-point increase in employment.

Other research shows similar findings. Studies of the New York City program found a small increase in the share of participants passing statewide high school exams and an increase in school attendance. Another study of the New York program, though, reported no improvement in long-term employment.

Martha Ross, a Brookings fellow who has conducted and analyzed research on summer-jobs programs, suggests that while the benefits of reduced crime are important, the programs may be too short to meaningfully help teens prepare for careers. Also, she notes, it is difficult to ensure that thousands of young people scattered across job sites are all having a productive experience. She has called for more research on measures such as having teens leave their summer jobs with references or letters of recommendation, and providing more intensive mentorship and training.

Some cities are experimenting with these ideas, evaluating smaller projects that aim to better prepare young people for careers. New York City has Ladders for Leaders, a more-competitive summer internship program that serves roughly 2,000 students, and that trains them on skills such as resumé-writing. Nearly a third of the Ladders for Leaders participants last year got offers to continue working with companies after the six-week summer program ended. In Chicago, Morrison Butler, the city commissioner, has pushed to offer more professional work experience. “If we’re really going to accommodate the tens of thousands of kids that apply that we can’t accept, we’re going to have to be purposeful, and try to build stronger links into the private sector,” she says.

This year, 1,000 students in One Summer Chicago are are involved in a pilot program that is meant to graduate them into private-industry jobs. In this first summer, in addition to working, they will complete basic online training about choosing a career path and preparing to succeed at their jobs. Next year, they will return for more-advanced training in the same field, meant to show potential employers that they are ready for entry-level, private-sector work in the third year. For example, a student interested in health care might work a city job in that industry for two summers, then use that preparation to transition to a job in a privately operated hospital the following summer. That will introduce new challenges: Adding skills training and mentorship requires more resources per student than simply connecting someone with a short-term job. To be successful, it also requires deeper involvement from companies. Many businesses have been happy to donate money but more reluctant to hire students directly from summer-jobs programs.

Morrison Butler hopes the students’ added training will translate into lasting employment gains, but her expectations are measured. “We’re talking about a six- to seven-week youth summer employment program,” she said. “It’s not intended to cure world hunger.”



Last June, The Atlantic published “My Family’s Slave,” a harrowing reflection by the journalist Alex Tizon on his experience of being raised by Eudocia Tomas Pulido, or, as she was known to Tizon, “Lola.” Pulido wasn’t in chains, Tizon wrote, yet “no other word but slave encompassed the life she lived.” The story moved millions of readers.

Today, as part of our special report about forced work, “The Unfree,” and with assistance from the nonprofit National Domestic Workers Alliance (NDWA), The Atlantic is presenting three essays written by women who have survived human trafficking. Here are their stories:

These stories offer glimpses of the cruelty faced by the desperate and powerless. But they are also tales of an astonishing sort of human resilience, which, as NDWA’s director Ai-jen Poo writes, “brings us face to face with the most painful aspects of humanity, so that we may collectively become more humane.”

This article is part of a project called “The Unfree,” which is supported by Dignity Health Foundation and Silicon Valley Community Foundation.



New York’s Chinatown is one of the few neighborhoods in Manhattan where parks are still packed with multigenerational, four-season activity, where diverse cultures, cuisines, and traditions are found spilling out of storefronts and community centers, and where immigrants and non-English speakers can find a familiar foothold in a new and different country. Still, over the past few decades, gentrification has brought about significant changes. That has accelerated in recent years, along with redevelopment and rent increases. Small shops like Fong Inn Too, a tofu-product store, and the New 25 Cents Store, one of the neighborhood’s last reliable sources of sewing supplies, have closed; new art galleries and upscale restaurants have proliferated; and the Pathmark supermarket has been torn down and replaced with an 80-story luxury residential tower.

As the neighborhood changes, foreign-born shop owners in New York’s Chinatown, as in other immigrant communities in the United States, have struggled to stay afloat. The traditional narrative for the children of immigrants—at least the one that often plays out in the media—involves a strong familial focus on education, and high hopes of college and high-status careers. However, in New York’s Chinatown, many business owners’ children are making a different choice: staying put at the family shop, where they’ve become unofficial, and sometimes unpaid, translators between the cash-based, word-of-mouth traditions of the past and the Square payments, social media, and Instagrammable products of today.

I recently volunteered and worked with a community-arts organization called Think!Chinatown, interviewing business owners in Chinatown for a project investigating how technology could help small local businesses, and started to notice how important a role their children played. This spring, I spoke with the sons and daughters of local entrepreneurs about what it’s like to work alongside their parents. Here are links to their stories in their own words:   



On a humid morning in June, classrooms along a third-floor corridor in a New York University building hummed with high-pitched chatter. The space serves as the hub for summer programs in computer science run by the California-based company iD Tech Camps. In one room, a group of children, ages seven to nine, knelt on the carpet next to small white robots, which they were learning to program with handheld tablets. Nearby, other kids worked on laptops, recording YouTube videos or designing video games. Down the hall, a group of teenagers jotted notes as an instructor diagrammed a linear-regression algorithm on a whiteboard. While some planned to return the following week, several told me they were squeezing in a few days of programming instruction before heading off to sleepaway camp or on family vacations.

Kids don’t learn much coding in school, which can leave them unprepared to tackle computer science in college or in a career. There are more than 540,000 open computing jobs, yet fewer than 50,000 computer-science majors graduated into the workforce last year, according to Code.org, a nonprofit that seeks to expand computer-science instruction in schools. Summer camps like iD Tech are stepping in to fill the gap, positioning themselves as a potential entry point to a career in tech down the road. iD Tech, which operates on more than a hundred campuses in the United States and abroad, has established itself—along with competitors like Digital Media Academy—as a dominant player in the niche market of summer tech programs for children and adolescents. More than 50,000 students plan to attend its camps this summer. At roughly $1,000 a week, though, these programs remain out of reach for many families, raising questions about how for-profit enrichment programs might shape access to tech education for a generation of young people—and whether they perpetuate patterns that exclude underrepresented candidates.

While many classmates at her New York City private school spend the summer at sleepaway camp, Brie Friedman, 15 years old, told me that she would rather learn to encrypt a file or dismantle a computer’s hardware to peek inside. So for the past six summers, she’s attended iD Tech’s NYU program to build on her interests in math, science, and tech. Friedman, who wore a charcoal-colored hoodie that morning, told me that last summer, she modeled a white miniature computer and used the camp’s 3D printer to create a physical version that now lives on her desk at home. This summer, she’s enrolled in the full seven weeks of iD Tech programs on offer.

Friedman’s mother, Wendi Friedman Tush, who runs a New York branding consultancy, acknowledged that the camp is expensive, but says she found it comparable to some other summer options like sleepaway camp. She credits iD Tech with helping her daughter, who is dyslexic, channel what had been an early interest in playing video games into an aptitude and passion for computer science. “It’s given her a whole new set of skills,” she says.

Pete Ingram-Cauchi, iD Tech’s CEO, says that the summer programs help ignite early interest in children who might one day go on to consider a career in STEM. “We’re trying to create the next generation in the pipeline of these tech-savvy kids,” he says.

That pipeline, though, has traditionally been leaky for low-income students. In general, the weeks of summer break between school years tend to exacerbate achievement gaps between students from affluent and poor families. While students across the board lose about a month’s worth of the previous year’s lessons, students from lower-income families tend to slip further than their wealthier classmates, who are more likely to attend enrichment programs or benefit from more frequent adult supervision. While there are plenty of free online coding classes, in-person programs aren’t as accessible: Free and low-cost coding camps run by nonprofits like Girls Who Code and Kode With Klossy tend to be reserved for girls, and are often oversubscribed.

In the absence of widespread coding instruction in schools, some educators and activists are expressing concerns about a system where expensive summer programs, available to the privileged few, serve as on-ramps to early computer-science proficiency, and ultimately, technology jobs. That prospect is particularly worrisome in a sector where women and some minorities have been underrepresented. Women make up 24 percent of people in computing occupations, according to an analysis of 2017 data from Code.org. About 8 percent of computing employees are black, and 7 percent are Hispanic.

“At a time when Americans worry about opportunity and the ‘American Dream,’ there is no better equalizer than computer science,” Hadi Partovi, the CEO of Code.org, says. “The idea that it would be limited to elite summer camps is just un-American.”

Of course, paid summer camps are part of an American tradition stretching back more than a century. Ingram-Cauchi says factors like employing one staffer for every eight campers, offering intensive employee training, and letting students use top-of-the-line laptops drive up iD Tech’s operating costs. “It’s tricky, because we would love to be able to say, ‘Every single kid can come to one of our camps,’’’ he says. “We want to be able to provide the absolute best STEM experience on the planet for our kids, but that means it’s not inexpensive.”

He says the company is working to significantly expand access to its summer programs to families who can’t afford the price. Since its founding in 1999 through last year, the company provided about $3 million in tuition help. This year, Ingram-Cauchi says, it plans to provide nearly $1 million in need-based scholarships and tuition assistance, including tuition aid of about $740,000 already granted to around 880 campers. iD Tech also runs some free weeklong camps called “outreach weeks” in partnership with nonprofits for students from low-income families. This year, they will operate at five of its roughly 150 locations.

iD Tech doesn’t track campers by socioeconomic status or race. Ingram-Cauchi believes the STEM-pipeline issue iD Tech is best positioned to address is that of gender imbalance. In 2014, the company launched a specialized girls-only program called “Alexa Café” to recruit more female campers, with the goal of achieving gender parity across its camp programs. Since then, the share of girl campers has risen from 12 percent to 28 percent, he says.

Yet steps towards gender parity in tech too often leave behind girls of color and girls from low-income families, says Tarika Barrett, the chief operating officer at Girls Who Code. The organization offers free after-school and summer coding programs and recruits girls primarily from underserved communities. About half of the girls in its free seven-week summer-immersion program are black, Latina, or eligible for free or reduced-price lunches, she says. Since its launch in 2012, almost 90,000 girls have participated in its programs. Most of them, Barrett says, had no—or very little—prior experience with computer science. “The exposure they gain is often the moment where they think to themselves for the first time, ‘Oh, I could see myself as a computer scientist,’” she says.

Extracurricular enrichment is only part of the picture. Code.org’s Partovi is among those calling for more computer-science instruction in schools, arguing that basic computer-science literacy has become fundamental to a well-rounded education and preparedness for the workforce. Thirteen states mandate that high schools offer computer-science courses, according to Code.org. Just five states require courses starting in elementary school. Among principals at K-12 schools, 40 percent reported that their school offered at least one computer science class where students could learn programming or coding, according to a 2016 survey commissioned by Google and conducted by Gallup.

That’s still a long way from incorporating computer science as a basic element of the educational experience. Code.org, Girls Who Code, and other organizations are working to train more teachers in computer science so that they can bring tech instruction into the classroom. Code.org, which is funded in part by tech firms including Microsoft, Amazon, and Facebook, runs teacher-training programs. After attending, elementary-school teachers typically incorporate about an hour of computer science classes into their weekly curriculum for 10 to 15 weeks; middle- and high-school teachers finish the training equipped to teach year-long courses. Since the programs’ launch in 2014, roughly 75,000 teachers have attended. Code.org has also made policy proposals at the federal and state levels suggesting, for example, that schools be required to eventually offer computer science, and allow computer science to satisfy a core graduation requirement. Since January, 25 states have passed new laws or initiatives that support the expansion of computer science in schools.

“Everybody learns in school how a light bulb works, how the digestive system works, how photosynthesis works,” Partovi says. As computing reshapes virtually every industry, all students should also be learning how technology works. “These aren’t things that we want only the elites to know.”



testing



In the weeks since Roy Price resigned as the head of Amazon Studios amid sexual-harassment allegations, Amazon’s CEO Jeff Bezos has made no public comments on the matter.* Bezos’ silence continues a pattern of inaction by the company.

Allegations were first made against Price in July of 2015. After an investigation, the only punishment meted out, according to a New York Times account attributed to an Amazon employee briefed on the matter, was that Price was told to watch his drinking at work functions. Despite an investigation and despite The Hollywood Reporter’s inquiry about the incident last spring, nothing more was done until recent news articles created a PR problem for the company. (Amazon declined to speak on the record.) Amazon then, finally, did make a change: In the end, Price was put on leave last month and resigned a few days later. The delay in meaningful discipline for Price led some current and former employees to wonder if that leniency was in some way connected to the company’s lack of women in senior leadership positions—according to the tech-news site Recode, Amazon has just one woman among its 18 top executives.

They weren’t wrong. Amazon seems to be typical of the sort of organization that researchers have found to be particularly prone to sexual harassment and abuse: male dominated, super hierarchical, and forgiving when it comes to bad behavior.

To start with, having more women employees, particularly in leadership roles, can reduce the incidence of harassment. Why? It’s not that women are somehow themselves preventing the behavior—in fact women too can be perpetrators—but that male-dominated organizations are more likely to have cultures characterized by aggressive and competitive behaviors and so-called locker-room culture. In addition, compared with women, men tend to have more trouble recognizing when women are being treated in an unfair or sexist way. This sets the stage for harassment: In such contexts, norms of professionalism can give way to boorish interactions in which women are treated as sexualized pawns rather than as valued and competent work colleagues. And if men are less likely to label what their male colleagues are doing as inappropriate, it can make matters worse.

What’s more is that in these hypermasculine settings, when women rise up the ranks, men can feel that their dominance is being threatened. In fact, the most common form of harassment is not the solicitation of sex, but rather what’s called gender harassment—sexist comments, obscene gestures, publicly displayed pornography—which serve as tools for putting women “in their place.” Women who violate feminine ideals by having a “man’s job” or behaving in “masculine” ways such as expressing strong opinions, being assertive, and having supervisory roles are more likely to experience such harassment.

Another general principle is that hierarchy seems to increase the odds of harassment occurring. Of course, most organizations are hierarchical to some extent, but what matters is the degree of the power imbalances among different people in the system. Studies have found that having power enables people to do as they please, often at the expense of taking other people’s perspectives into consideration. Research has also shown that in the minds of men with a high proclivity to harass, power and sex are closely linked. Moreover, their power shields them from scrutiny, criticism, and punishment. As a result, having power over others is often corruptive, in that it can lead people to behave badly, lack empathy, and even to engage in socially inappropriate or sexualized behavior. In contrast, powerlessness is associated with fear and embarrassment and a heightened sensitivity to threat. In contexts with greater hierarchy, higher-ups may be more inclined to behave badly, while at the same time subordinates are less able to push back.

A type of hierarchical situation that is rife for sexual harassment is one in which powerful individuals have a lot of discretion and a singular capacity to make or break an underling’s career. The Hollywood producer Harvey Weinstein, who has been accused of sexual assault and harassment, was for decades able to launch an unknown actress into stardom. (Holly Baird, a spokesperson for Weinstein, told The Atlantic that Weinstein “unequivocally denie[s]” any allegations of nonconsensual sex.) The venture capitalist Justin Caldbeck, who has been accused of unwanted and inappropriate advances, was in a position to provide badly needed funding to women entrepreneurs. (Caldbeck has denied the allegations and threatened to sue his accusers. He has also apologized and is now seeking to educate young men about “bro” culture. He declined to speak on the record for this article.) The U.C. Berkeley astronomy professor Geoff Marcy, who has been accused of behaving in an inappropriate and sexualized manner with students, had the power to write letters of recommendation to help women undergraduates get into graduate school. (Marcy disputes these accusations. A lawyer representing him referred The Atlantic to Marcy’s earlier public statements about the matter.) The story often follows similar lines: A harasser’s high status provides cover for their actions because victims and bystanders are leery of what will happen to them if they speak up. If the perpetrator holds the keys to your future, it can be hard to come forward or fight back. Time and again, harassers get away with it because there is a low probability of both discovery and punishment.

At its core, sexual harassment is about unequal power relations between men and women at work, at school, and in society at large. Vulnerability is a hallmark of both who gets targeted and why victims keep silent. The waitress earning minimum wage who is expected to put up with sexist comments from customers; the woman farmworker who is sexually assaulted in the field and then threatened into silence by her employer; the intern who must fend off repeated advances from a senior leader to keep her position. It is the most vulnerable women among us, those with less education, who hold low-paid service jobs or lower-level administrative jobs, who are racial and ethnic minorities, or who have been victimized before, who are harassed more frequently. And few victims ever come forward because of legitimate concerns that retribution could put them out of a job.

If power imbalances leave those at the bottom of the hierarchy vulnerable, more needs to be done to even out the scales. Strong HR departments that are empowered to protect employees and rewarded when they do, hotlines that are staffed (not recordings), and anonymous reporting mechanisms can do a lot to give voice to people who often have none.   

The third factor, and the single biggest predictor of sexual harassment on the job, is how permissive an organization is of this conduct. Permissive organizations are ones in which employees feel it is risky to report sexual harassment, think that their complaints won’t be taken seriously, and believe that perpetrators will face few to no consequences. This may seem circular, and in a way it is—harassment begets more harassment—but it also implies an important lesson: Cracking down on harassers, severely and transparently, discourages the behavior across an organization.

Quintessential examples of these kinds of permissive environments are companies like Uber and Fox News. At Uber, Susan Fowler said her repeated complaints to HR about harassment and exclusion went nowhere. Instead she was told that no actions would be taken against the perpetrator because he was a top performer. At Fox News, Bill O’Reilly was given another four-year, $25 million-a-year contract even after he settled a harassment case for $32 million and despite 21st Century Fox knowing about these allegations against him (though not about the amount of the settlement). At each company, these weren’t isolated incidents of unprofessional behavior. Rather, they reflected a larger problem. Uber ended up firing 20 people for harassment, bullying, and discrimination after an investigation of its workplace culture was conducted in the wake of Fowler’s blog post. And, in addition to O’Reilly, former Fox News CEO Roger Ailes and the Fox News host Eric Bolling have both left Fox News amid allegations of sexual harassment. (A spokesperson for 21st Century Fox said the company has taken “concerted action to transform Fox News,” including “increasing the channels through which employees can report harassment or discrimination.”)

What determines whether or not a company is tolerant of sexual harassment? In a word, leadership. Do managers work to prevent harassment by talking about company policies and modeling appropriate ways of treating and interacting with coworkers?  Do they ensure that claims of harassment are promptly investigated and that punishments are handed out—even when the perpetrator is a top performer or a higher-up? When leaders take sexual harassment seriously, it’s less likely to occur. The odds of it happening go up when company leaders condone misconduct by ignoring it, discouraging people from coming forward, failing to act, or engaging in harassing behaviors themselves.

Sexual harassment leads to many negative outcomes. Targets of harassment can have reduced mental and physical health, lower job satisfaction, and greater workplace withdrawal. They suffer real costs to their careers. When women have to quit to get away from threatening situations, they often wind up in lower-paying jobs with worse long-term professional prospects. There are organizational consequences as well, all of which hit the bottom line. Not only are the costs of litigation high, but in environments that are more hostile to women there can be more team conflict and reduced workgroup productivity.

As bad as all of this is, there is also the implication that companies can do a lot to address and prevent sexual harassment. Strong policies—with real teeth—and training are essential. In both, harassment should be clearly defined, protocols established for what employees should do when they see it happening, disciplinary consequences should be clear, confidentiality for the victim should be maintained, and retribution against him or her prohibited.

Gender equity efforts are also central. If male-dominated structures uphold a system of sexual harassment, such structures need to be changed, and women need to be promoted to upper levels. Even so, more women in management won’t alone eliminate sexual harassment, and plenty of organization with women in top leadership positions still have problems. But greater numbers of women can create more equity in the power men and women hold inside companies. More women can also do a lot to tamp down hypermasculine cultures that degrade and demean women. It appears Amazon Studios is cleaning house and moving in this direction, putting women executives into key leadership positions. This leadership shake-up came just weeks after Roy Price and a few of his male colleagues suddenly departed from the company and as Amazon Studios began an investigation into allegations that the Transparent star Jeffrey Tambor harassed a former assistant. (In a statement provided to Deadline, Tambor described the allegation as “baseless.” He also denied a separate allegation of harassment, and indicated he plans to leave the show.)

Men play an important role in counteracting sexism as well. Research shows that people take men’s complaints about sexism more seriously than they take women’s, perhaps because men are not seen as directly benefiting from doing so (and, perhaps, because people implicitly trust men more on these matters than they trust women, even though the vast majority of perpetrators are men and the vast majority of victims are women).                 

Ultimately, all of this comes down to whether senior leadership takes this issue seriously or not. A study from the military found that when women felt that their leaders were working to combat sexual harassment and modeled respectful behavior they reported experiencing less harassment and, if they filed a complaint, were more satisfied with what happened. Thus, when leaders take visible, consistent, and firm stands that sexual harassment won’t be tolerated, it creates safer and more inclusive environments. When leaders remain mum, as Jeff Bezos has, it can do the opposite.

*This article originally reported that Jeff Bezos did not talk about the Price resignation on Amazon's recent earnings call. While other Amazon executives who participated did not discuss the matter, Bezos himself was not on the call. We regret the error.



Republicans are making some heady claims about their hastily constructed, historically unpopular tax legislation. “If we do this, then America will win again like never, ever before,” President Trump said in a speech touting the legislation this week. “A vote to cut taxes is a vote to put America first again. We want to do that. We want to put America first again. It’s time to take care of our workers, to protect our communities, and to rebuild our great country.”

But a bipartisan group of leading economists have expressed some deep skepticism about many of the central claims the White House and congressional Republicans are making about the potential effects of the legislation. Below are the top seven myths they have put forward—and the evidence that disproves them.

1. The tax bill will pay for itself.

The Tax Cuts and Jobs Act remains a moving target, with congressional Republicans horse-trading different provisions into and out of the bill and work not yet done to reconcile differences between the House and the Senate versions. Still, the basic parameters are clear. On the household side, the bill would lower the rates charged in each tax bracket, expand the child tax credit, eliminate personal exemptions, and expand the standard deduction. On the business side, it would lower the corporate income tax rate dramatically, and create a big deduction or a special rate for “pass-through” businesses that pay individual income tax rates. It would also let businesses bring back foreign profits at a very low rate, and likely move the country to a territorial tax system, wherein companies pay taxes on profits generated in the United States, not worldwide.

All those rate reductions would mean that the Treasury would be taking in far less money from individuals and businesses. But Republican officials have insisted that the tax cuts would improve growth so much that they would pay for themselves, offsetting the revenue losses. “Not only will this tax plan pay for itself, but it will pay down debt,” Treasury Secretary Steven Mnuchin promised recently.

Not so, one of the country’s most respected, nonpolitical economic scorekeepers has said. The Joint Committee on Taxation (JCT) this week found that the Senate proposal would increase output by 0.8 percent over ten years. Because that extra output would get taxed like anything else, it would indeed mean additional money going to government coffers—but not nearly enough to cover the losses from the tax cuts. The JCT estimated that the bill would add $1.4 trillion dollars to federal deficits over a decade, ignoring any dynamic effects on the economy. Taking into account improved growth, it would add $1 trillion to federal deficits—more than President Obama’s stimulus bill, passed to save the economy during the Great Recession. A University of Chicago poll of some of the country’s top economists came to the same conclusion. Not a single one of the experts surveyed said that the kind of legislation under consideration would lead to a falling debt-to-GDP ratio.

2. It will supercharge growth.

Still, Republicans have insisted that the legislation would supercharge American growth. “These massive tax cuts will be rocket fuel—Little Rocket Man—rocket fuel for the American economy,” Trump said this week, referencing Kim Jong Un of North Korea. “Remember I used to say, we can hit 4 [percent growth] and we can hit 3? And they were all saying, forget it, forget it. It was 1.2. It was doing terribly. We were flat. We were even. In all fairness, the stock market was going this way. And now, we’re hitting numbers that nobody thought possible.”

But the JCT shows that the tax bill would add less than 0.1 percentage points to the country’s annual rate of growth, totaling just 0.8 percentage points of additional growth over ten years. The experts quoted in that Chicago poll said much the same. “Tax policy appears to have little effect at the margin on GDP growth in OECD countries,” argued David Autor, a Harvard economist.  

Why doesn’t the bill do more for the economy’s growth rate? In part because the government is passing tax cuts when the economy is already doing well—raising the prospect that the Federal Reserve would move to counteract the stimulative effect of all that deficit spending and would raise interest rates to cool the economy off. And in part because giving tax cuts to rich families and corporations is simply not that stimulative of a thing to do, since they do not tend to put the money toward buying new goods and services.

3. Cutting the corporate tax rate will lead businesses to give raises to regular workers.

The Republican legislation would slash the corporate tax rate from 35 percent to 20 percent, along with eliminating a number of deductions for businesses and tinkering with what gets taxed and when. “It is great for companies, because companies are going to bring back jobs. And we’re lowering the rates, very substantially. But right now, we’re bringing the rates down from 35 percent—which is totally noncompetitive. The highest industrialized nation in the world, by far, and we’re bringing it all the way down to 20 percent,” Trump said this week. “But that’s good for everybody in the room, whether you have company or whether you want a job.”

The idea is that the lower tax rates would encourage businesses to stop using tax shelters overseas and would provide companies with more money to shunt to their workers. Trump’s Council of Economic Advisers has suggested that the corporate tax reform would boost the average family’s income by $4,000 a year, “conservatively.” But that number does not hold up to scrutiny, with most nonpartisan budget scorekeepers and many economists contending that businesses would provide a far smaller bump to average workers. That White House analysis assumes that workers would get 70 percent of the benefit of the rate cut, with shareholders getting the remainder. The Tax Policy Center, a Washington-based think tank, for instance, estimates that workers would get about 20 percent of the value of corporate rate cuts, with the JCT, the Congressional Budget Office, and the Treasury all estimating that workers would get around a quarter of the benefit too. The rest would go to shareholders. Plus, of the money going to workers, much of it would flow to managers and executives, not minimum-wage or average employees.

The Center on Budget and Policy Priorities, a respected left-of-center think tank, has said that researchers view the White House’s analysis “with considerable skepticism due to its methodological weaknesses,” and describes its assumptions as “unrealistic.”

4. Corporations will invest more.

A second argument the White House and prominent Republicans have made is that businesses will use their bolstered earnings to invest here in the United States, helping the economy as a whole. “Last year, American multinational companies left more than 70 percent of their foreign profits overseas,” Trump said this week. “They actually get penalized. Our plan switches to a territorial tax system that encourages companies to return their profits to America—right here to the United States.”

One thing is certain: Companies will bring hundreds of billions of dollars home, to take advantage of the tax holiday. But it seems unlikely that most, or even much, of the money would flow to workers and investment, rather than to shareholders. To wit, a Bank of America/Merrill Lynch survey found that companies were eagerly anticipating what they would do with their cash. They were most likely to respond that they would pay down debt and buy up their own shares—neither of which would help workers much. Other executives have indicated that they would use the money for dividends.

Recent history also suggests that companies would do more to improve shareholder returns than to invest in their businesses or expand and enrich their workforces. Back in 2004, Congress let companies repatriate their earnings, much as Congress is planning to do now. “While empirical evidence is clear that this provision resulted in a significant increase in repatriated earnings, empirical evidence is unable to show a corresponding increase in domestic investment or employment,” a Congressional Research Service report found.

Economists think the same thing would happen this time around. Companies are already highly profitable and borrowing costs are already low, after all: Businesses do not really need the government to induce them to invest. Moreover, though the United States has high statutory corporate tax rates, few companies pay high effective tax rates. The Institute on Taxation and Economic Policy has found that 258 big corporations paid an average effective tax rate of 21.2 percent in recent years, with 18 companies—among them General Electric and Priceline.com—never paying federal income taxes during the time period studied.

5. The rich are not going to benefit from the bill.  

Trump has repeatedly promised that rich families like his do not stand to benefit from the Republican legislation. “We’re also going to eliminate tax breaks and complex loopholes taken advantage of by the wealthy. Who are they? I don’t know,” he said this week. “I think my accountants are going crazy right now. It’s all right. Hey, look, I’m president. I don’t care. I don’t care anymore. I don’t care. Some of my wealthy friends care. Me? I don’t care. This is a higher calling. Do we agree?”

This is false: As a general point, the richer the family, the more they benefit from the legislation, particularly over time. The Tax Policy Center has found that the biggest benefits would go to families in the top 5 percent as of 2019, with the smallest benefits going to those in the lowest income quartile. By 2027, families in the lowest two income quartiles would be receiving, on average, no benefit at all, with the biggest gains accruing to families in the top 0.1 percent of the income distribution. Moreover, the richest-of-the-rich families would exclusively benefit from initiatives like the reduction in or an elimination of the estate tax, which would let individuals like Trump pass millions and millions of dollars more to their heirs.

5, cont. Trump himself would not benefit.

“This is going to cost me a fortune, this thing—believe me,” Trump said this week. “Believe me, this is not good for me. Me, it’s not—so‚ I have some very wealthy friends, not so happy with me, but that’s okay.”

This is not true. In fact, Trump stands to benefit to the tune of hundreds of millions, if not billions, of dollars, according to tax analysts, though it is hard to know with much specificity, given that he refuses to release his tax returns and House and Senate Republicans keep tinkering with the legislation. The elimination of the alternative minimum tax. The changes to the estate tax. Abbreviated depreciation schedules. Deductions or special rates for pass-through businesses. All these provisions stand to benefit Trump directly. Indeed, tax experts have said that as a real-estate developer he seems uniquely positioned to benefit from tax reform.

6. The plan is designed for the middle class.

“The beating heart of our plan is a tax cut for working families,” Trump said this week. “That’s what it is. We’re going to make sure that you keep more of your hard-earned money. We’re going to make sure, also, that you have a job that you want.”

This is not true. Indeed, families in the middle of the income distribution would on average see no benefit from the plan as of 2027, whereas families at the top would be paying far less in taxes and many families at the bottom would actually be paying more. One reason is that the legislation changes the way that the tax brackets get adjusted year after year to account for the effect of inflation. More families would get pushed into higher tax brackets sooner under the Republican plan, so they would end up paying more in taxes, even though the marginal rates would be lower. In addition, Republicans have gone after a number of provisions in the current code—the state and local tax deduction and the medical expense deduction, for instance—that help many middle-class and upper-middle-class families.

Republicans have countered some of these claims by saying that it is impossible to cut income tax rates without primarily benefiting the rich: The rich make more money, so inevitably they get big reductions when you cut taxes, the theory goes. But this argument is silly. It is mathematically simple to design tax cuts whose benefits go exclusively to lower-income and middle-income families. It just requires making the code more progressive—something that Republicans do not want and have chosen not to do.

7. It will help small businesses.

“We’ll also cut taxes for the millions of small businesses that file as individuals, and that’s going to come out of the hopper,” Trump said this week. “It’s getting there and it’s going to be better and better. We’re reducing the tax burden on businesses of all sizes and of every, single kind.”

Here, the Republican rhetoric is more a distortion than an outright falsehood. The plan, as it stands in the Senate, allows “pass-through” businesses—accounting for hundreds of thousands of businesses that pay under the individual rather than the corporate code—to deduct 22 percent of their income before paying taxes, up to a certain limit. In the House, it allows those pass-throughs to pay taxes at a special low rate. The pool of pass-through businesses includes any number of cookie shops and bodegas and corner stores, but also law firms, hedge funds, consulting firms, real-estate development companies, investment partnerships, and lobbying businesses. An estimated 70 percent of the benefits for such pass-through firms go to the top 1 percent of income earners—meaning this benefit is more about helping rich families than it is about helping small local businesses.

Moreover, such changes to the way pass-through businesses are taxed complicate the code and create a preferential category for rich individuals to try to work their income into—something contrary to the very spirit of tax reform. The new provisions have “the potential to become the single greatest inducement to tax arbitrage ever enacted by a single Congress,” the tax expert Daniel Shaviro of New York University Law School has written, also saying that they “might end up being the single worst structural change in the history of the U.S. federal income tax.”

Of course, the Trump administration has promised that what it says is true, and that it would produce evidence of how much good its tax plan would do for the American people. Then again, The New York Times reports that a Treasury document purportedly showing that the Trump tax cuts would pay for themselves has not been forthcoming because it does not—and presumably cannot—exist.



Amazon announced on Thursday that certain members of its Prime subscription program can order Whole Foods items to be delivered within two hours. The program debuts this week in several neighborhoods in Austin, Dallas, Virginia Beach, and Cincinnati. Delivery is free for orders over $35—not exactly a challenge at a store nicknamed “Whole Paycheck”—with a $4.99 charge for cheaper purchases. Desperate dinner-party hosts can expedite one-hour delivery of fresh produce for $7.99, in many cases less than the cost of an Uber to the grocery store and back.

When Amazon spent $14 billion on Whole Foods last year in its largest-ever acquisition, many analysts saw three obvious advantages for the retail giant. First, its CEO, Jeff Bezos, would Amazon-ify Whole Foods, cutting the prices of popular items to increase foot traffic and overall revenue. Second, Amazon would use Whole Foods’ 400-plus upper-middle-class locations as distribution nodes for a range of products. Third, the company would try to turn Whole Foods into an online-retail company, by allowing households to order food on smartphones (or via a smart speaker like the Amazon Echo) and have fresh produce dropped off at their doorstep, just like they would a book or a toothbrush.

The analysts were right. Amazon is doing all of the above—cutting prices and leveraging Whole Foods’ locations to build an on-demand food-delivery service. And that on-demand food-and-meal delivery service may be set to take off. A study commissioned by the market-research firm Euromonitor projected that the market for such services will grow 15 times faster than the restaurant business through the end of this decade. And this might just be the beginning. Greg Greeley, Amazon’s head of Prime, is transitioning to a new position overseeing Whole Foods’ integration into the company, CNBC has reported.

It would be a mistake to treat every Amazon announcement as an Amazon accomplishment. On-demand Whole Foods delivery could turn out to be a giant mess. Indeed, Amazon has struggled with grocery-delivery services before, shutting down its Amazon Fresh program in several cities last year. Six months from now, the dominant news story about “Whole Foods Prime” could be a wave of anecdotes about overwhelmed Whole Foods workers in Virginia Beach or Cincinnati, or tales of zucchini that arrived so lukewarm and smushed as to resemble ratatouille. Execution matters, and excellent execution isn’t an inevitability, even for a logistics master like Amazon.

But it would be a bigger mistake to analyze Thursday’s news in a vacuum, because this announcement is bigger than heirloom tomatoes and two-hour delivery windows. In the broader context of Amazon’s ambitions—to build an operating system for the home, to expand into pharmacies and health care, to become a hit-making television production studio—this is the logical next step in turning Prime into the ultimate “life bundle,” a single membership program to bind consumers to every possible commercial need. As Amazon extends into more product areas, it can own both the search platform and the product, so that when a dad says to the smart speaker on his counter, “Alexa, I need brown rice and pork,” the product that arrives is an Amazon-branded box containing Amazon–Whole Foods–branded rice and pork.

This sort of vertical integration is invaluable for Amazon. For one thing, the creation of an on-demand Whole Foods product makes the company’s Prime subscription more valuable. Enriching Prime is arguably Amazon’s most important goal, given the lifetime value of a Prime subscriber. What’s more, as Amazon becomes the top-of-mind destination for not only books but also toiletries, medicine, and chicken breasts, it becomes the first-stop destination for all of its customers’ searches.

And what comes with search volume? Advertising. Indeed, Amazon’s ad business—which includes sponsored ads on Alexa, suggested items on Amazon search pages, and even ad boxes around the internet on other sites—grew 60 percent last quarter, faster than Google’s or Facebook’s, albeit from a lower base. The business is on track to make as much as $10 billion in revenue by the end of this year, or about one-quarter of Facebook’s total revenue in 2017. As Amazon draws more consumers into its orbit, it will also pull competitors into a deflationary cycle: Each time the company enters a new industry, like those for grocery stores or pharmacies, the stock valuations of the sector’s largest companies decline, as investors anticipate that Amazon will pull down the industry’s profits to zero in order to draw in consumers and maximize cash flow.

Amazon was a fascinating buyer for Whole Foods for just this reason. It is the anti–Whole Foods, forever evincing a no-frills obsession with low prices and absolute convenience over artisanal touches. And yet, the two companies are perfect partners. Whole Foods became a kind of cult for its most devoted customers, who sacrificed their weekly food budget on the altar of artisanal produce. Jeff Bezos’s ultimate ambition is similarly cultish: to build a pan-commercial enterprise, where every consumer question is best answered by first asking Amazon. The company is a leveraged bet on absolute customer convenience. And nothing says “absolute customer convenience” like yelling the word kale! at a box in one’s living room and finding fresh greens on one’s doorstep within 120 minutes.



During the night of October 8th, Santa Rosa, California, found itself pinned between two wildfires. To the southeast, the Nuns fire burned west of Highway 12. To the northeast, the Tubbs fire charred the hills outside Calistoga and worked its way southwest. In Santa Rosa, the latter would prove the more devastating. The Tubbs fire tore through the wealthy community of Fountaingrove before jumping Highway 101 and claiming about 1,500 homes in dense, working-class Coffey Park.

By the time they were contained at the end of October, a spate of fires around the North Bay had claimed more than 40 lives and 5,700 buildings.

Even before the fires, low-wage laborers and an estimated 28,000 undocumented workers struggled to eke out a living in an area with an exceptionally high cost of living. Now, the question facing them is not how they will rebuild their lives, but whether they can at all.

The morning after the fire devastated Coffey Park, a line formed outside the Graton Day Labor Center west of Santa Rosa. Disasters “always make new day laborers,” said the center’s director, Jesus Guzman. The Graton center is part of a national network that includes offices in New York City and New Orleans, and Guzman said his sister locations reported similar lines during the days following Hurricanes Sandy and Katrina.

Some of those looking for work were farmworkers whose fields had burned—Sonoma County is the nation’s largest producer of wine—but even more had been employed in some corner of the region’s fast-growing tourism and services industries. The flames claimed a nursing home, a Kmart, Best Western and Hilton hotels, and many other businesses on which low-wage workers had depended.

Guzman’s mother was among them. A house cleaner for decades, she worked for clients in affluent neighborhoods like Fountaingrove. At least two of her clients lost their houses there, Guzman said. One has decided to move away, but the other will rebuild and has promised to get his mother back to work when the new home is finished—which could take years.

Unemployment is only one part of the problem. “There’s work in Sonoma County, but even $15 an hour in agriculture isn’t going to cut it to pay rent here, and it’s only going to get worse,” Guzman said.

That’s partly because the housing market is dismal for working-class residents, he added. Forbes recently named Sonoma County the country’s 10th-least affordable place to live. A person earning an average wage in the county would have to spend about 82 percent of it to live in a median-priced house. To make ends meet, many low-income families share housing, with sometimes as many as 20 people to a home, Guzman said. According to the real-estate site Zillow, the median monthly rent in September was $2,366, a figure that has been steadily increasing for years.

Only about 2 percent of Sonoma’s housing stock was available before the fires destroyed thousands of homes, said Raissa de la Rosa, the economic development manager for the City of Santa Rosa. Much of the housing stock is taken up by vacation homes, and the homes that were available were out of reach for many prospective residents.

“Housing was a priority before; now, it’s a super-priority,” de la Rosa said. The fire claimed about 5 percent of the city’s remaining housing stock, leaving thousands displaced. According to Guzman, many people “don’t have a lot of hope they’ll find anything. It was hard enough to find something in the first place.”

Even before the fire came over the ridge, Santa Rosa was working toward incentivizing denser, more-diverse housing downtown, de la Rosa said. The city’s housing action plan, already in place, focuses on affordable development. But then it lost more housing than it built last year. In the weeks since the blaze, median monthly rent in Sonoma County has jumped 35 percent to $3,224, in response to new demand from displaced residents. This prompted Santa Rosa to install a cap on rent increases to combat price gouging.

In mid-October, Santa Rosa and Sonoma County issued a series of emergency ordinances designed to speed the process of rebuilding and protect those who were displaced. The new policies waived processing fees for burned structures, suspended new vacation rentals, allowed people to live in temporary housing like RVs and trailers, opened up restrictions on secondary units, and extended occupancy rules to allow seasonal farmworkers to stay year-round.

De la Rosa said the city had more than 3,100 units in the pipeline in some way before the fire; her office is now looking at which of those can be pushed through the fastest. Among those leading the charge is Rebuild North Bay, a public-private partnership established by the influential Sacramento lobbyist and real-estate magnate Darius Anderson. Acting as executive director is James Lee Witt, a former FEMA director whose otherwise respected disaster-relief company was the subject of an eight-month NBC News investigation into profiteering in the wake of Hurricane Katrina. In a recent press conference, Witt said he intends to work closely with local representatives to identify needs and act quickly.

Already, the disaster is spurring debate on how—and even if—some areas should be rebuilt. Recovery presents opportunities to start over in some areas and address housing inadequacies with equity and sustainability in mind, but some worry a hastened rebuilding effort could favor high-end developers and wineries.

“We’re acutely aware of disaster capitalism and how this community can be exploited in a way that can make a few people money,” said Annie Dobbs-Kramer of the North Bay Organizing Project. Her organization is pushing to include working-class people in the restoration plans, with affordable housing and tenant protection at the top of its list.

In Sonoma, where rents significantly outpace wages, rent control has been a divisive topic. In 2016, Santa Rosa City Council passed a rent-control ordinance that immediately earned the ire of landlords. In June 2017, a signature-collection effort plagued by accusations of fraud forced a referendum. Rent control opponents, led by the National Association of Realtors, a trade group, outspent housing-rights proponents five to one—and broke city campaign-spending records in the process, the Press Democrat reported. The rent-control measure was defeated by 781 votes.

It’s too early to tell how recovery efforts will shake out or how many of Sonoma’s low-income families will stick around. Meanwhile, the region has been flooded with relief funds. A coalition of immigrant rights groups including the North Bay Organizing Project has launched Undocufund to raise money for undocumented immigrant workers who do not qualify for FEMA assistance and face procedural and language barriers to accessing aid.

Guzman recalled that as the fires approached, public officials were slow to relay quality information in Spanish. With no idea of what to do, many Spanish-speaking families instinctively fled to the coast. Guzman said he met with many who were sleeping in their cars on the side of Highway 1. The nearby town of Bodega Bay had opened up two shelters, Guzman added, “but folks just didn’t know they were there.”

This post appears courtesy of CityLab.



On Monday morning, President Trump tweeted that the unemployment rate for black Americans had reached the lowest on record, and that the rate for Hispanic Americans will soon reach a similar milestone. He effectively claimed credit for these improvements, writing, “Dems did nothing for you but get your vote!”

The truth is, Trump has so far done little to contribute to the declines in unemployment among blacks and Hispanics—those declines are more a reflection of the sound economic policy of the past decade. And even though the black and Hispanic unemployment rates have improved over the past year, they are still much higher than the rate for white Americans—and that’s a crucial piece of context missing from Trump’s tweet.

For almost as long as unemployment statistics have been recorded (since around the time of the Great Depression), a gulf has existed between white Americans and black and Hispanic Americans. A good yet unfortunate rule of thumb is that the unemployment rate for blacks is generally about twice as high as the one for whites.

The latest jobs report indeed shows that these gaps had closed just a bit. In December 2017, the unemployment rate of the American populace as a whole was 4.1 percent. The racial breakdown, as usual, shows some sharp discrepancies: Only 3.7 percent of white Americans were unemployed at the close of the year. The unemployment rate for Hispanics was more than a percentage point higher, at 4.9 percent. And for black Americans, unemployment was just under twice the rate for white Americans, at 6.8 percent.

It’s true that 6.8 percent is historically a fairly low unemployment rate for black Americans, but it’s not a good or healthy unemployment rate by just about any measure. “If we had an overall unemployment rate of 6.8 percent, nobody would be cheering about that,” says Valerie Wilson, an economist at the left-leaning Economic Policy Institute. The last time the unemployment rate for the nation as a whole was that high was about five years ago, during a period when the economic recovery had yet to take off. And while it’s true that the most recent jobs report shows that the gap has narrowed a little, its existence still points to troubling discrepancies in the labor market that can’t all be explained away by differences in education and skills.

In truth, neither Trump nor Republicans can take much credit for the small amount of improvement that has occurred. According to research from the Federal Reserve, a slight narrowing of this gap, and an improvement in the unemployment rate for blacks and Hispanics, is precisely what is expected after a period of prolonged economic growth. The United States is in the midst of one of the longest stretches of job creation in modern history. And most of that economic growth has been presided over by President Obama, and his appointee for Fed chair, Janet Yellen (whom Trump declined to reappoint).

This is something that economists from across the political spectrum tend to agree about. When I talked to Wilson, she said, “The data and the evidence clearly show that the recovery of employment was well underway before President Trump took office.” And Michael Strain, an economist at the right-leaning American Enterprise Institute, told me last year that continuing existing economic policy could theoretically help groups with historically high rates of joblessness.

Specifically, economists have attributed the dropping unemployment rate to Yellen’s decisions to continue suppressing interest rates—despite objections from the GOP and criticism from Trump during the campaign. It was sober economic policymaking over the course of a decade—not any single thing that’s happened over the past year—that brought the black and Hispanic unemployment rates to where they are now.



I grew up on the high-elevation plains of northwest Montana, on the Blackfeet Indian Reservation, in a culture in which English did not become the dominant language until the middle part of the 20th century. Leaving to attend the University of Montana in the mid-1990s, after receiving a tuition waiver the summer following my senior year of high school, marked my first time living away from our reservation. My graduating class was one of the first in which many of us left to seek degrees, a development that mirrored a shift taking place nationwide; by 1996, 30 percent of Native American 18- to 24-year-olds were enrolled in college, up from about 16 percent in 1989.

Some of us went to college to escape our treaty-established, semi-sovereign homeland and the social and political problems common in Indian country. Others left because there wasn’t anything else to do. Many of us, though, were driven by an idea about higher education that had recently begun to take hold on reservations—that the purpose of college was to prepare us to help our communities. Not until well into adulthood did I realize that this well-meaning notion reflected not only our communities’ need for help, but also their failure to understand that higher education, in the absence of structural change and economic opportunity on the reservation, was likelier to draw young people away from home than to help them make it better.

The relationship between education and economy is more complicated in Indian country than elsewhere in the United States. While access to higher education is a means to a better life as much for American Indians as for anyone else, connotations specific to reservation people exist that trouble the situation. Going to school means leaving a cultural context—which includes many relatives, sometimes too many—that doesn’t occur anywhere else in the country. Departing for college also means engaging with an educational system that does little to break the myth of how this country came to be, one that elides historical facts about broken treaties, Indian law, and Congress’s plenary power over tribal nations.

At the University of Montana, I found myself having to address American ignorance in an exhausting manner, explaining again and again that no, we do not go to school for free, and yes, we do pay taxes; that “blood quantum”—a measurement of a person’s “Indian blood” that determines membership for most tribes—is a colonial invention.

Prior to colonization—for millennia, in fact—the economy of the Blackfoot people revolved around the iinii, or buffalo, which provided not just food, but tepee covers, clothing, tools, and weapons. The animal’s sudden, severe decline in the mid-to-late 1800s, the result of slaughter on the part of Americans hunting for hides and so-called sport, caused enormous cultural chaos for all plains tribes. Within several years, many indigenous people in the vast region were without sustenance. In 1883, as many as 600 Blackfeet starved to death, an event that came to be known as the Starvation Winter. That time still hangs in the air, one of the few historical events discussed on my reservation.

While the recent return of the buffalo to the Blackfeet Reservation has resulted in positive PR, employment statistics in our homeland make clear that their reappearance is largely symbolic. In 2015, the poverty rate among Blackfeet was higher than 38 percent (compared with a national average of 13.5 percent), unemployment was at almost 19 percent (compared with 5.3 percent nationally), and labor-force participation was at 53 percent (compared with 62.7 percent nationally). Many reservations are in rural areas geographically isolated from stronger urban job markets. Although people sometimes perceive casinos as having brought riches to reservations, that’s true in very few cases. Meanwhile, outsiders who might consider investing on reservations have difficulty assessing the risks because tribes are separate sovereign entities, with distinct and unfamiliar laws and legal structures, so they often avoid investing altogether.

And, for various reasons, the kind of economic opportunities that might produce homegrown entrepreneurship are rare. For one thing, many reservation Indians live on land that is held in “trust” by the federal government and managed by the Bureau of Indian Affairs—meaning individual tribal members don’t own the property on which they live. As a result, they lack the collateral needed to acquire business loans, a problem compounded by a lack of financial literacy endemic to Indian country.

What no one ever told me at college, I assume because it seemed self-evident to them, is that higher education is associated with a white-collar economy. When you come from a reservation, where any such economy is unlikely to exist, understanding what a degree is supposed to do is difficult. In my case, I happened upon Jack Kerouac’s work when I was 19, and became a writer. I dropped out of school, not sure how higher education related to writing fiction, unsure if I’d ever reenroll. Thus began a pattern—drop out, reenroll, drop out, reenroll.

Each move home brought an overwhelming sense of relief after the stultifying atmosphere of attending class with non-Indian students I found bafflingly humorless. (In even the darkest of times, Blackfoot prefer to laugh at life and one another.) But returning home also showed me what awaited if I stayed there: substitute-teaching gigs, working at the diner, or managing my family’s convenience store, where I often stood in the parking lot listening to the vast, predawn silence of the northern plains, drinking coffee and waiting for the first customer. Much later in life, I recognized these experiences as my first encounters with the economic hardship that dominates Indian country.

Though the general message for people like me is that the purpose of higher education is to return home to help our community, the reality is that the economy on most reservations cannot support the work that’s needed. The kinds of jobs most Americans might associate with a healthy, middle- or upper-middle-class economy—software development, sales, marketing—are nonexistent. Other occupations so common to healthy economies that we often take them for granted, such as counselorships, managerial positions, and careers with nonprofits and the state and federal government, are rare.

Perhaps it is telling that the most lucrative job available to me, during my stints back home, involved doing controversial work in the oil-and-gas industry, acquiring lease signatures from Blackfeet landowners who lived on our reservation and around the western United States. To outsiders, Indians participating in the extraction of resources from their land by American corporations uninterested in tribal nations’ well-being might appear contradictory. The reality is that, in our devastated economies, many people have little other choice.

None of these were jobs I wanted. I craved to be around writers, and the writers I knew were on campuses and in urban areas. I felt a need to be in a culture where the fine arts were appreciated, where that type of intellectual discussion was commonplace. Each time I left school, these things brought me back. After nine years, at my mom’s urging, I finally graduated. Much later, I learned my long undergrad arc, with its staccato enrollment, is common for a reservation Native.

I often ask myself what our reservation would look like if there had been a healthy economy and a more diverse culture to welcome those from my graduating class who received college degrees. The majority of my high-school classmates who left for school did not come back, opting for stable jobs elsewhere, perhaps returning to the reservation for Christmas or the summer powwow. As for me, I kept drifting. When I was 36, a new job opened up at Blackfeet Community College, one of the few white-collar positions available to someone like me on our reservation. I applied and got the job. Directing the writing center, I hoped, would give me what I needed most: a steady income, time to write, and the opportunity to give back to people in my community. I also intensified my relationship to Blackfoot-language work, helping to start a nonprofit dedicated to the revival of our mother tongue. I went to traditional ceremonies again. I ran into cousins during late-night visits to the convenience store. For the first time since high school, I became a full-time participant in contemporary Blackfeet culture.

At Blackfeet Community College, I found that many of our young people now assume they will go to college. This is the case on reservations across the country, whether that means attending one of the 38 tribal colleges and universities in the United States or another school. In an American sense, reservation people are becoming more educated. But I soon realized that college degrees haven’t translated to Indian graduates regularly securing white-collar jobs in their homelands; years after I graduated college, reservation economies still aren’t substantial enough to provide those careers. When asked what they wanted to do with their future associate’s degrees, my students responded largely with blank looks.

In my students, I saw my 18-year-old self. Many wanted to help our community, and I was at a loss to help them understand how that might happen in a place with such limited opportunities. I didn’t know how to tell them that their basic, human desire for stability and a decent income would contribute to a brain drain that has profoundly affected our economy and politics; that the purported objective of education—that we are to become educated so we can help our communities—is difficult, if not impossible, to accomplish. Without improved economies, higher education simply contributes further to reservation students’ confusion about where they belong in this world.

Though I was one of the few who found the kind of job an educated reservation Indian is supposed to find, I remained conflicted. Due to my professional duties, along with the stress that comes with teaching students from a community broken by colonial force, I found myself writing less. So I applied for a Stegner Fellowship in creative writing at Stanford University, and was accepted.

This fall, I left the reservation again, departing with some sense of failure—of not having done enough. The Stegner Fellowship will potentially provide opportunities unavailable to me otherwise: time to write and professional advancement. Pursuing those experiences, though, will necessitate being away from my reservation for most of the rest of my life. All too often, success for reservation Indians means leaving your heart in your homeland.



The Golden Globe Awards on Sunday provided a useful snapshot of the limitations of the #MeToo movement. Viewers gazed into a monochromatic protest against the scourge of harassment, with uniformly black dresses and suits, “Time’s Up” pins, and often inspiring speeches about standing up to abusive power.

But while host Seth Meyers filleted Hollywood’s most infamous offenders and Oprah Winfrey brought the audience to its feet with a rousing address, the brutal math of inequality lurked beyond the telecast. Lady Bird won the award for Best Motion Picture Musical or Comedy, but its writer and director Greta Gerwig was curiously not nominated for Best Director. That category’s five nominees were all male. In fact, only one woman has ever won a Golden Globe for directing: Barbra Streisand, in 1984, for Yentl. At the time, Gerwig was six months old, and her film’s lead actress had not yet been born. Hollywood remains an industry where women are more likely to be celebrated for speaking out in front of a camera than for holding one.

The numbers are staggering: Of the top 250 films of 2017, 88 percent had no female directors, according to the most recent “Celluloid Ceiling” report from San Diego State University. What’s more, 83 percent of the films had no female writers, and 96 percent had no female cinematographers. According to earlier versions of the survey, more than 90 percent of major studio films have no female assistants on set, including gaffers, key grips, or supervising sound editors.

The report has tracked women’s employment in top-grossing films for 20 years. “In 2017, women comprised 18 percent of all directors, writers, producers, executive producers, editors, and cinematographers working on the top 250 domestic grossing films,” wrote Martha Lauzen, the author of the report and a professor of film and television at San Diego State University. In the last two decades, the gender wage gap in America has narrowed and women have eclipsed men in the ranks of new college graduates. But behind the camera in Hollywood, nothing has changed since the late 1990s.

The emphasis on accused celebrities like Harvey Weinstein and Kevin Spacey is appropriate, but brutish behavior against women emerges naturally from a industry that deprives most of them from the power to produce, direct, write, or film. Sociological studies on sexual harassment have shown that the worst industries for harassment combine several factors: male domination in positions of power; work arrangements that are relatively transient; and young, single women in more-vulnerable and low-paying occupations.

All three descriptors apply to the movie business. First, men clearly outnumber women four-to-one among producers, directors, cinematographers, writers, and key assistants. Second, every movie or miniseries is essentially a miniature start-up, where predators and jerks can abuse or harass actors and assistants knowing they might never have to work them again after a three-month shoot.

Finally, actresses are vulnerable, not only because men dominate powerful occupations, but also because women are cast to portray the very quality of vulnerability. In my book, I reported on a study by the Geena Davis Foundation that analyzed speaking roles in 120 popular films released between 2010 and 2013 for demographics, sexualization, occupation, and career. Just 23 percent of these films had a girl or woman as a main character. The ratio of men to women portrayed at the highest levels of local or national government authority was 115-to-12 (and three of the 12 female roles were portrayals of one person: Margaret Thatcher). Meanwhile, girls and women were twice as likely as boys and men to be shown in sexually revealing clothing, and five times more likely to be called out for being attractive. If these movies collectively formed a single nation, women in this world would account for less than one-third of the workforce and two-thirds of its sex workers.

Altogether, these surveys and studies suggest something quite simple: The ratio of women in an industry (like film) or in an occupation within that industry (like directing) shapes how women are treated. While more than 80 percent of women say they have been harassed at work, they are 50 percent more likely to say so in male-dominated industries.

In Hollywood, as in media or any industry dominated by powerful men, it is important yet insufficient to name, shame, and expel the worst offenders. More fundamentally, it is critical to address the sheer number of women who work in the industry in positions of authority. Black dresses and pins get people talking. But in the end, it’ll be the math that matters.



Editor's Note: This article is part of an oral-history series where Aaron Reiss interviewed the young-adult sons and daughters of Chinatown shopkeepers about how they are helping to keep their families’ businesses alive.

Jason Luo, a 24-year-old entrepreneur who graduated from helping resolve problems with English-speaking customers in his parents’ JieLi Laundromat to running his own gadget store, Niu Shop, nearby, explains the shift from rejecting his family’s business to embracing it: “It’s like multiple personality disorder. You’ll become thankful and grateful to them sometimes. And sometimes you hate them, and you hate the business, right?”

I spoke with Luo in the spring of 2018. Below is our conversation, lightly edited for clarity.

My dad started his first business selling watermelons. He sold in the market—one cloth on the floor, stacked with watermelons. After my parents met, they built a successful business running arcades. But then the market in arcades started to get saturated, and business was slowing down.

In China, you hear stuff about America. So my dad saved up and came here. He started his own construction company. And my mother opened a laundromat. Back then, I couldn’t speak any English—not even the ABCs—and it was hard. I was a top student in China—you know, honors, always getting praise. So I came here, and all of a sudden I don’t know nothing, don’t know the language. My fourth-grade teacher thought I needed special ed—that’s how bad it was. I didn’t talk at all because I was afraid to make a mistake.

Language was a big, big barrier in my parents’ life, too. They can’t speak English, or write, or communicate. They never moved away from Chinatown, so they don’t need to learn English to survive. Their clients are mostly Chinese, they mostly use Chinese. And as I grew up, they would have me read important letters from the government. Like, they see the official logo and want to know, “What letter is this? What does it mean?”

In the laundromat, when there is a problem with an English-speaking customer’s order, they call me. They say, “Come over, solve this problem.” I remember this one customer, she can’t find her $70 underwear—it was all lace. I’m serious! I had to look up the brand online, and she wasn’t lying! It was $70. I guess you can find a luxury kind of anything, even underwear. I went there, and we actually found it in another basket. I waived her fee, and she was happy. Afterward, my parents are like, “Okay, go home.” It’s your duty! It’s my family duty. My parents don’t want the customer to feel like they aren’t getting help because of the language barrier.

After I graduated from high school, I studied computer engineering at New York University for two semesters. But then I didn’t think that class was really my thing, and I dropped out. My mom was crying. They let the whole family know. Because that generation didn’t graduate from college—just two cousins—they just want me to get a degree. Anyway, at that time I was just drifting around, doing my thing and enjoying life.

I started building an app, a small game. I worked for a year and a half at an IT firm in K-Town. And at the same time, my parents call me up when they need help with anything, like errands. Or if a worker isn’t there that day, they ask me to cover for them. It’s kind of like you’re on standby, you’re on call.

But I didn’t like it. I felt like they forced stuff on me; they didn’t make me feel like I could choose. I think it happens with most Chinese family businesses. There was expectation forced upon me: Someday you’ll take over, go to the work site with Dad; you will take over someday. It soaks in. If you’re the oldest son, they expect you to take everything they have—the money, the business, the home. That idea goes all the way back to China.

For me, though, it’s like multiple personality disorder. You’ll become thankful and grateful to them sometimes. And sometimes you hate them, and you hate the business, right? You just want to burn it to the ground. After they decided to give me the chance to let me invest in my own business, I ran it, everything. It was a bit harsh. So I start to understand that running a business is not easy. And I understand why they ask for any help they can, even from family.

I opened my own store, the Niu Shop, on May 1, 2016. That’s my birthday. The first year, my parents helped me figure out how to import things from China—dealing with importing, and forms, and officials. At first, I didn’t know there was so much to learn; they make it look easy.

They’re getting old; I want them to rest as soon as possible. If I take over the family business, I would feel good that I could basically take care of them. Chinese people expect that regardless. I grew up in America, so most of my values are from Western society, pretty modernized. But some traditional values still stay, some of them. Taking care of parents is one of them—filial piety, is that what you call it?



A legal struggle is unfolding over control of the Consumer Financial Protection Bureau, sparked by Richard Cordray’s resignation as director last week. Leandra English, the agency’s deputy director (promoted by Cordray) says she’s in charge, but President Trump says that his pick to run the agency, Mick Mulvaney, is the acting director. A federal district judge in Washington, D.C., will adjudicate these claims imminently, leaving Mulvaney or English as the agency’s temporary head—at least until an appeals court weighs in.

On its surface, the struggle for control of the agency is a question of law—or more specifically, a question of which of two laws takes precedence over the other. The Federal Vacancies Reform Act of 1998 says that the president “may direct” any Senate-confirmed official to head an agency in the event of a vacancy. (Mulvaney qualifies because the Senate voted 51–49 in February to confirm him as director of the Office of Management and Budget.) The Dodd-Frank Act of 2010 says that the deputy director of the CFPB becomes “acting Director in the absence or unavailability of the Director.” The question for the courts is whether the Federal Vacancies Reform Act, which gives the president the power of temporary appointment, takes precedence over the Dodd-Frank Act, which seems to imply that the deputy director’s ascension is automatic.

As I’ve written, there’s a good argument that the Dodd-Frank Act yields to the Federal Vacancies Reform Act. But while this statutory dispute is fascinating to law professors like me, whether the CFPB remains a robust champion of consumer interests does not depend on whether Mulvaney or English emerges victorious from this legal battle. Ultimately, the agency’s 1,700-plus employees will do more than any judge to determine the bureau’s fate.

Even if English prevails in court, her tenure as acting director wouldn’t last very long. First, President Trump has the authority to fire her at his whim: The director of the CFPB enjoys what’s called “for-cause” removal protection under the Dodd-Frank Act, which means that the president can remove her only “for inefficiency, neglect of duty, or malfeasance in office.” But the Dodd-Frank Act does not give for-cause protection to the deputy director, and it does not extend the director’s “for-cause” protection to a deputy serving in the director’s stead.

Second, even if Trump does not fire English, she will only serve until a replacement is appointed by Trump and confirmed by the Senate. With a Republican-controlled Senate that has mostly rubber-stamped Trump’s appointees so far, the confirmation process probably wouldn’t take long. Maybe English could retain the acting-director post for a few more weeks, but it’s a safe bet that she will be out by early 2018.

And in any event, it was always the case that President Trump was going to get to name a new CFPB director. The term of the agency’s outgoing head, Cordray, would have expired in July 2018. Even if it weren’t for Cordray’s premature departure, the president would have had an opportunity in the near future to put a foe of the agency in its top spot.

But by the same token, Mulvaney’s power over the agency as acting director would be seriously constrained even if he wins the court fight. As an initial matter, he remains the director of the Office of Management and Budget (OMB), which already is a full-time job. While he spent Monday morning at the CFPB headquarters distributing doughnuts to staff, he also has $4 trillion or so in government spending to oversee at his OMB job. And even if he had undivided time to devote to the CFPB, the head of any 1,700-person organization must rely on subordinates to get things done.

Those subordinates are overwhelmingly liberal—more than 99 percent of campaign contributions by CFPB employees since 2011 have gone to Democratic candidates or left-leaning political-action committees. And the very fact that they have chosen to work for the CFPB is a strong indication that they are committed to the agency’s pro-consumer agenda. Moreover, the agency’s employees are generally protected by the federal merit system, making it very difficult for the director to fire them. Endowed with job security and imbued with a sense of mission, these employees will likely continue to go about their business of enforcing the laws on the books.

Indeed, this is exactly what happened at the Environmental Protection Agency after President Reagan installed the archconservative Anne Gorsuch Burford at its helm in 1981. (Yes, that’s Gorsuch as in Neil Gorsuch—the most junior justice on the Supreme Court is her son.) As the political scientist B. Dan Wood has documented, “following the Reagan inauguration, the EPA bureaucracy bucked the administration and used its slack resources to substantially increase surveillance of pollution.” It took about eight months for the Reagan administration to rein in the EPA careerists and bring enforcement activity below the level of the Democratic Carter years. And after Burford was forced out of the EPA in early 1983, enforcement activity once again surged above the Carter administration’s high watermark.

There are, to be sure, several ways in which a CFPB director who is hostile to consumer interests can impede the agency’s efforts. First, the director has control over the agency’s budget, so he can try to starve it of cash—and budget cuts at the CFPB could begin as soon as January. Second, the director could freeze hiring at the agency. Indeed, Mulvaney already has imposed a 30-day hiring stoppage, but even with budget cuts and a hiring freeze, existing employees would hold onto their jobs—and in light of federal merit-system protections, their salaries can’t be slashed. Third, the director can prevent the agency from promulgating new rules. To this end, Mulvaney says that the agency won’t issue any new rules for a month. But it’s not so easy for the director to roll back existing regulations. That generally requires a process of notice and comment, which on average takes about 18 months. The process may last even longer if lower-level agency officials who oppose the new director’s deregulatory agenda drag their feet.

So in the final analysis, it does indeed matter who is head of the CFPB: A director set on deregulation can slow the agency significantly. But it also matters who staffs the agency, because those employees can stymie the director’s efforts to dismantle the bureau. The fight over the acting director title is thus only the first round in what’s likely to be a longer struggle between the Trump administration and the CFPB’s employees over the agency’s direction. At the end of the day, President Trump will get to decide who directs the CFPB, but that director may soon discover that being in charge is not always the same as being in control.



Since the day in late November when he showed up at the Consumer Financial Protection Bureau, doughnuts in hand, Mick Mulvaney has said that things were going to change. For almost two months, the acting director appointed by Trump has implemented seemingly small, but important, shifts that indicate what the bureau will look like in the years ahead. In a memo to bureau staff made public by ProPublica, Mulvaney finally laid out his vision for the agency: a government entity that doesn’t “push the envelope.”

In an email to the bureau’s staff, Mulvaney said that he had been struggling to come up with a central thesis for how exactly the agency would change. Mulvaney wrote that the philosophy of the previous director, Richard Cordray, was “to aggressively ‘push the envelope’ in pursuit of the ‘mission;’ that we were the ‘good guys’ and the ‘new sheriff in town,’ out to fight the ‘bad guys.’” The acting director then declared, “That is what is going to be different.”

Mulvaney went on to say the “entire governing philosophy of pushing the envelope frightens me a little ... it’s not appropriate for any government entity to ‘push the envelope.’” The acting director described concerns that the bureau would overstep and create long-lasting damage to individuals, reputations, and businesses. What will this new philosophy look like in practice? Mulvaney vowed to only pursue lawsuits if evidence of “quantifiable and unavoidable harm” is found. And the agency will rely more heavily on its rulemaking efforts as the engine of change, instead of enforcement, meaning that the bureau won’t focus on fines or lawsuits to cull bad behavior. Instead, the CFPB will primarily look to the creation and implementation of new rules, in hopes of changing dangerous practices—a process that is less punitive and more time-consuming.

This memo is in line with the plan that Mulvaney has already started enacting. In the nearly two months that Mulvaney has been at the helm of the bureau, he has instituted policies that have pulled back on the agency’s rulemaking, enforcement, and collection of personal data. According to Nick Bourke, the director of the consumer-finance project at the Pew Charitable Trusts, this strikes at some of the key areas of success for the bureau. “Enforcement has been the biggest impact the CFPB has had so far,” Bourke told me during an interview in November. And thus far, the implementations of new rules for prepaid cards, payday lenders, and mandatory arbitration clauses—all considered big victories for the bureau—have been slowed or killed since Mulvaney took on leadership of the bureau.

The process of paring back the scope of the bureau’s enforcement efforts is already underway, and already questions have been raised about Mulvaney’s close relationships with some of the entities that he is now in charge of regulating. On Monday, Mulvaney shuttered an investigation of World Acceptance Corporation, a small-dollar loan operation from his home state of South Carolina that contributed an estimated $4,500 to his political campaigns over a three-year period. Earlier this month, Mulvaney dropped a lawsuit against a group of payday lenders in Kansas accused of misleading customers and charging interest as high as 950 percent. Campaign donation records show between 2012 and 2016, Mulvaney received contributions totaling more than $60,000 from groups in the payday-lending industry.

This new trajectory of the agency will almost certainly ruffle longtime advocates of the bureau and supporters of its work under Cordray. Many have feared that Mulvaney, who has been a vocal critic of the CFPB, would shut down the agency, or, short of that, gut it from the inside. Tuesday’s memo didn’t exactly assuage those concerns. “When I arrived at the CFPB, I told folks that despite what they might have heard, I had no intention of shutting down the Bureau,” Mulvaney writes. “Indeed, the law doesn’t allow that.”

In January, the acting director asked the Federal Reserve to refrain from giving the agency any money for the second quarter of 2018, saying that instead, the bureau could use some of the $177 million reserve fund accrued during Cordray’s tenure to operate. “The request—or lack thereof—will serve to reduce the federal deficit by the amount that the Bureau might have requested under different leadership,” Mulvaney wrote.

With a new mission for the bureau articulated, Mulvaney has cemented the Trump administration’s vision of the CFPB: a smaller, quieter, and less active financial regulator—one that looks a lot more like the regulators of the pre-recession era.



True for all of those in his line of work, the weeks leading up to Thanksgiving were Casey Grogan’s busiest time of year. Earlier in November, he harvested 70,000 Noble and Nordmann firs at Silver Bells Tree Farm, his Christmas-tree farm in the foothills of Oregon’s Cascade Mountain Range. As the holiday neared, he watched his crop cruise off in the backs of around 100 semi-trucks, following the path of most of the Pacific Northwest’s holiday crop, 92 percent of which is shipped to outside the region. Nearly half of that lands in California, and most of the rest ends up elsewhere in the West, in Gulf states, or in Mexico.

This was a smaller season than Silver Bells has known in the past: The farm, which once shipped about 100,000 trees annually, downsized from 700 to 400 acres of Christmas trees in recent years. The reduction is part of a trend that has played out across the Pacific Northwest—the country’s leading Christmas tree–growing region, with Oregon the highest-producing state and Washington the fifth—and is the long-realized product of overzealous planting 20 years ago.

That was a period, Grogan explains, when prices were favorable, land and labor were affordable, and trendy new crops like hazelnuts, wine grapes, and blueberries hadn’t yet lured some farmers away from more traditional choices such as Christmas trees and grass seed. “I don’t think [farmers] realized how many trees were being planted compared to what demand was,” says Grogan, who sits on the board of the Pacific Northwest Christmas Tree Association (PNWCTA), a regional trade group.

The Northwest’s most popular variety, the noble fir, can take eight to 12 years to reach holiday height, which means that that spurt of over-planting two decades ago led to oversupply about 10 years ago. It was especially poor timing because this flooding of the market coincided with the Great Recession, when many people were scaling back their Christmas spending. “Prices fell off the roof and growers were losing money, so they didn’t have the incentive—and in some cases they didn’t have the equity—to invest in planting seedlings,” says Tim O’Connor, the executive director of the National Christmas Tree Association (NCTA), a Colorado-based industry organization.

Another 10 years on, the effects of that under-planting are now being felt around the country, in the form of shortages and higher prices. Grogan says that shoppers in the regions supplied by the Northwest can expect to pay 10 percent more for a tree this year and that those who wait to pick out a tree may not have many to choose from.

Silver Bells could be considered one of the lucky Northwestern farms: Over the last decade, some moved on to more lucrative crops, but many went out of business entirely, since prices dropped before the recession due to excess supply and took a while to tick up again. Grogan says that the number of growers in the PNWCTA, his trade group, was cut in half. “You would drive around and see the fields of trees coming out and not going back in,” he remembers. “We warned a lot of our customers that [the shortage] was coming, but I think they are still pretty shocked at what they are seeing now.”

Supply is also diminishing, although not to the same degree, in North Carolina and Michigan, which have the nation’s second and third largest Christmas-tree outputs. “It is something the whole industry is feeling, but it is more expressed in the Northwest,” O’Connor says.

The NCTA estimates that 27.4 million trees were purchased in the U.S. last year. This year’s shortage represents a not insignificant chunk of that: Exports from the Pacific Northwest will be down about 1.5 million trees this year, according to Ken Cook, whose McKenzie Farms has 8 million trees planted across nearly 10,000 acres in Oregon. “There’s a huge shortage of Christmas trees, and it’ll continue to be that way for at least 10 years,” says the 80-year-old farmer.

Cook’s enormous wholesale farm was able to ship between 800,000 and 850,000 trees this year—on par with its annual average—because Cook had the means to ride out the dip. “When there was an excess of inventory available, a lot of growers either stopped planting or reduced plantings,” he says. “I continued to put a million trees in the ground each year. I knew what would happen.” But even Cook hasn’t emerged from the cycle unscathed: He says that the autumns of 2016 and 2017 are the first seasons in more than 10 years that his business has turned a profit. “It’s been very tough on growers for the last 10 to 12 years in Oregon,” he says. “We’ve been selling trees at less than what it costs us to grow them and ship them.”

Eighty-five percent of Cook’s trees are claimed by big-box accounts, including Lowe’s, Home Depot, Walmart, Costco, and Orchard Supply Hardware. These large retailers work contracts out several years in advance, and so won’t be as impacted by this year’s squeeze as local garden centers, nurseries, nonprofit lots, and other small businesses. “With the shortage of trees, the small independent retailer is the one who is not finding trees in the market this year,” says Cook.

This has been the case for The Farm at El Mirlo, a two-acre family farm in northern San Diego County that grows seasonal vegetables, gourds, and loofahs, and transforms into a Christmas-tree lot during the holiday season. Patricia Vittoria, who runs the business, says it relies on year-end tree sales to fund the following year of farming. The shortage first became an issue for her farm last year, when it had trouble sourcing enough of its bestseller, the noble fir. “That’s because the majority were already committed to the big-box stores,” says Vittoria. Between having a smaller stock on offer and a decision to not raise prices, the farm saw its Christmas-tree income drop 50 percent in 2016. This year, unable to obtain trees from their usual Oregon supplier, Vittoria’s husband visited more than a dozen farms and wound up purchasing from four boutique-sized Oregon growers. Vittoria says she was left with no choice but to raise prices this year; they’re 15 percent higher than they were in 2016.

Times of short supply stoke existing fears in the farmed Christmas tree industry of its primary competition: faux trees, which more households now put up than real trees. O’Connor attributes fake trees’ popularity to empty nesters who like them for their ease and convenience, as well as younger, environmentally-minded consumers who believe that fake trees are the more responsible choice. (In fact, while both farmed and fake trees have environmental footprints, the debate over which is more sustainable mostly favors real trees. Real trees’ advantage stems from the facts that they capture carbon dioxide while they’re growing, that they are usually shipped regionally as opposed to overseas, and that they’re biodegradable.)

The market for Christmas trees has followed a certain rhythm: A shortage today drives prices up, which induces growers to plant more, the effects of which will be felt in the time it takes for a noble fir to mature. Last time that happened, the market became oversaturated. “I’m sure all growers would agree that that experience is not something we would like to repeat,” Grogan says. He thinks farmers will be more restrained this time around.



Ever since Nate Tullar was a toddler, when adults asked him what he wanted to be when he grew up, he knew what to tell them. In the ’50s, Tullar’s grandparents, George and Barbara, had bought Tullando Farm, a dairy farm located along the Connecticut River in Orford, a town in northwest New Hampshire, and started out milking a dozen cows; his parents, Rendell and Karen, had taken up the business after them. Tullar grew up milking and feeding cows, and showing them at fairs. He knew he would be a dairy farmer, too.

These days, this kind of career conviction is one—perhaps the only—logical reason for a young person to become a dairy farmer, especially at the small-scale dairy operations of the Northeast and Midwest. The high cost of barns, farm equipment, and cows, plus volatile prices for milk and feed, reward larger operations that can spread production costs over more animals. In 1987, 202,068 farms produced about 144 billion pounds of milk, according to the U.S. Department of Agriculture; by 2017, just 40,219 farms made 215 billion pounds of milk. While dairy farms had a median of 80 or fewer cows in 1987, that figure increased to 900 cows more than a quarter-century later. Nowadays, dairies in the West and Southwest can have 15,000 or 20,000 milking cows, Dave Swartz, an assistant director of programs for animal systems with Penn State Extension, told me.

Tullando Farm is among the smaller-scale farms that stayed in business. I visited Tullar, who is 38, on a grey summer day. He greeted me in a Red Sox shirt, Carhartt pants, steel-toed boots, and a red hat, in the Tullando Farm office. Inside hung a yellow and blue banner, stamped with the Tullars’ name, 1956 establishment date, and their enduring motto: “In Cows We Trust.”

While Tullar was growing up, he watched his parents and grandparents expand their herd size, build new barns, and embrace the latest technologies. In 2000, Tullar graduated from the University of New Hampshire’s dairy-management program to begin working full-time at the farm. The dairy’s schedule included six- or seven-hour sessions milking over 400 cows, three times a day. Tullar was on the morning shift—“from four to ten,” he said.

Tullar gradually began helping his parents manage the dairy while his younger sister, Emily Gray, kept track of finances. Tullando Farm has a long history of taking progressive steps to stay in the dairy business, which is why, in addition to adopting best practices for soil health, cattle genetics, and animal comfort, the Tullars decided to computerize as much as their operation as possible. In 2012, they built an enormous new free-stall barn with thermostat-controlled fans and curtains, automated manure-scrapers, and spinning, bristly yellow brushes that cows rub up against when they need a scratch.

In 2014, the Tullar family completed the last, and perhaps most dramatic, step in their long-term improvement plan: They bought eight cow-milking robots called Astronauts, invented by the Dutch company Lely in 1992. For three, 24-hour days after the robots’ arrival, Lely employees helped Tullando Farm herd every one of their 480 cows into and out of the new milking machines, three times each day, to get the animals acquainted. At three months, everything was working the way it was supposed to. These days, a number of European and North American manufacturers sell robotic milkers, which are used by an estimated 4.5 percent of dairy operations in the United States (including Tullando Farm), Joao Costa, an assistant professor at the University of Kentucky who researches dairy-precision technology, told me.

Over the four years since then, changes in the global economy and a glut in the domestic market have placed extra pressure on those, like the Tullars, who have weathered the industry’s longer-term restructuring. Historically, strong prices lead to increased milk production one year, oversupply lowers the price the next two years, then prices rebound. But three years ago, Europe eliminated a quota system that had limited the amount of fluid milk farmers could produce. That action, combined with Russia’s 2014 embargo on European Union products, decimated demand abroad for U.S. dairy products—and it came as people in the U.S. were drinking less milk. All this interrupted the normal three-year cycle for federal milk prices. Other recent events, such as President Trump’s trade war and Canada’s, China’s, and Mexico’s retaliatory tariffs on U.S. dairy, haven’t improved matters. Last week, however, the Trump administration agreed to sign the new United States-Mexico-Canada Trade Agreement, which is expected to open up more Canadian dairy market access for U.S. farmers by 2020.

U.S. dairy cooperatives—businesses owned and operated by member dairy farmers to market their milk—have had to close membership to new farmers and in some cases, even dump surplus milk. “We’ve never really had an extended four-year cycle where there weren’t things we could do in the U.S.,” Bob Wellington, an agricultural economist and a vice president at the northeast dairy cooperative Agri-Mark, said.  

Increasingly, many farms can’t offer job security for young people like Tullar. “The problem is they don’t have the income to support the kids coming back on the farm,” Wellington said. He added that some Agri-Mark farmers earn an income low enough to make them eligible for food stamps. After a member farmer committed suicide this past winter, Wellington included a list of mental health and suicide prevention resources in Agri-Mark’s February membership letter.

Despite the fraught economics (and emotions), there remain young farmers who are willing to take the risk. Some work second jobs off the farm. Others diversify with value-added products like meat, maple, or yogurt, or they invest in their own bottling plant to direct-market milk in the old-timey glass jugs that speak directly to a certain kind of consumer’s buy-local, know-your-food, support-your-farmer tendencies.

Nate Tullar continues his family legacy. On my tour of Tullando Farm, we passed a giant red cow statue that stood just outside the farm office—a gift from Lely. Just inside the barn and across the aisle from some chewing cows, I spotted a stationary red-and-gray machine that looked like R2-D2; Tullar told me it was an out-of-commission pusher that, when working, keeps feed within reach of cows’ mouths. As for the Astronauts, Tullar led me to the center of the barn and into the long, narrow milking parlor so I could see them in action. While the machinery’s pumping power and chemical supplies lived on the floor above, the eight red, refrigerator-like housings for the milk lined either side of the first-floor aisle.

Next to each Astronaut case, a horizontal gap in the wall offered a window into the automated milking process. A cow walked into the stall-like enclosure and stuffed her face in some grain while the rear gate closed behind her. Next, the robotic arm swung beneath her belly and cleaned her udder with spinning brushes and peroxide disinfectant. Red lasers located her four teats before cups suctioned onto each one. She continued eating as the robot pumped the milk. Eventually, one by one, the teat cups dropped off and the cow received an iodine spray. The stall’s front gate then opened and the cow went on her way.

“Before we put in the robots, we didn’t have enough help,” Tullar said. While the Lely Astronauts required a “substantial investment”—between $150,000 and $200,000 for each robot, not including barn costs—Tullar said they make up for four full-time employees. Using an app on his phone, which tracks the black transponders that hang from each cow’s neck like a bell, Tullar knows what’s going on with his animals at all times: when they’re sick, in heat, or moving around too much for the robot teat cups to get a good grip. And now, instead of herding them and hooking up the milking machines by hand, he has the time to walk among and observe his free-roaming cows, who like to come up and ask for a pat.

“We need to be more efficient as an industry, and that is a really good way to do so,” Costa told me. Dairies have struggled to retain employees, as farms often can’t match wages at warehouses or fast-food chains, and robots help solve that problem. In the future, Costa expects technology to not only perform the manual jobs and take down data for farmers, but to integrate all that information and make management decisions easier and faster. “We’re going to depend less on human labor,” he said.

Amid all this change, Tullar is trying to hang on to some semblance of what his grandparents started. What keeps him from despairing about the equipment repairs going undone, robots still to be paid off, and the stubbornly low milk prices, he said, is pretty simple: the tractor, the fields, the cows. Just before the rain came that August afternoon, I followed Tullar past an unlatched barbed wire fence, through tall grass and wildflowers and into one of his grandparents’ old pastures bordering the river and cornfields. He called out, “C’mon girls!” at the 20 dry cows grazing along the tree line and waited for them to trot over. Gathered in a loose semi-circle, Tullar’s herd pressed their wet noses to his arms, his legs, his face. “They just wish I had grain,” he said, but I wasn’t so sure that was true. I didn’t see them nuzzle the robots like that.



After Hurricane Irma hit three months ago in Orlando, Florida, the local police got a desperate 911 call from a 12-year-old boy reporting that his mother and siblings were unconscious. Fumes overcame the first deputy who rushed to the scene. After the police arrived at the property, they found Jan Lebron Diaz, age 13, Jan’s older sister Kiara, 16, and their mother Desiree, 34, lying dead, poisoned from carbon monoxide emitted by their portable generator. Four others in the house went to the hospital. If 12-year-old Louis hadn’t made that call, they might have died, too.

Portable generators release more carbon monoxide—which is particularly dangerous because it is odorless and invisible—than most cars. As a result, the devices can kill efficiently and quickly, though accidentally. The Diaz family usually placed the generator properly, outside the house, a neighbor told local reporters. But for some reason, they had brought it into their garage. From there, the generator’s murderous byproduct spread silently through the house.

During hurricanes, floods, and nor’easters, portable generators save lives—except when they take them. Irma, Harvey, and Maria all left thousands without power and reliant on their portable generators. The government has not yet done its official count, but 11 people using these generators died just from Irma, according to preliminary government estimates. Many more died from Harvey and Maria, experts say, especially in Puerto Rico, which has been without a functioning power grid for months.

These deaths rarely merit more than short stories on local news sites. Civil servants then accumulate the statistics into dry reports that end up buried somewhere on .gov websites. The latest of these shows that portable generators have killed on average 70 people a year since 2005. That’s a small fraction of the toll from car accidents. Still, generators rank as one of the deadliest consumer products on the market. A further 2,800 people a year suffer from carbon-monoxide poisoning caused by the equipment.

Portable-generator deaths are preventable, and for the past 16-plus years, the United States government has tried to do just that. The job has fallen to the Consumer Product Safety Commission, which, with its $126 million budget and 520 employees, oversees almost every product Americans use in their home, office, or out in the yard, save for food, drugs, and cars. The CPSC, based in Bethesda, Maryland, is tiny, especially compared to many of the corporations it regulates, and hamstrung by congressional rules that require it to seek voluntary standards before attempting to impose mandatory ones.

But the problem of portable generators was so obvious that the little agency felt it needed to make a stand. They were one of the “persistent deadly hazards we felt we had to address,” says Elliot Kaye, who was the chairman of the CPSC from 2014 to February of this year and remains a commissioner. (The CPSC has five commissioners who vote on agency measures; the party that controls the White House tends to have the majority.)

Throughout the 16 years the CPSC has been pushing the issue, the portable-generator industry fended off regulations that would have required it to reduce the carbon-monoxide emissions of its devices. The companies argued such changes would be too costly, and that they lacked the technology to make the machines safer. The industry lobbied hard, and also wielded an arsenal of delaying measures and misdirection, not to mention occasional strong-arm tactics to enforce industry discipline.

But in early November 2016, during the final months of the Obama Administration, the CPSC took one of the most significant steps it can take: The commission voted in favor of a rule to force manufacturers to lower their generators’ carbon-monoxide emissions. The vote was 4–1, with one Republican joining the majority of Democrats.

Donald Trump was elected a week later. In January, he elevated the only commissioner to vote against the rule—Ann Marie Buerkle, a 66-year-old former Republican congresswoman from upstate New York—to be the acting chair of the CPSC, and she took on the role in February. (She awaits Senate confirmation to become the chair.) The administration has nominated, as a potential commissioner, a lawyer from the corporate firm Jones Day who specializes in defending companies from product-liability cases; one other vacancy remains. So Buerkle will likely soon have new allies.

Self-effacing and warm, Buerkle wins universal praise from agency employees and fellow commissioners as a pleasant colleague. Even the Democratic appointees feel she listens to them. Indeed, the CPSC took pride that it wasn’t riven by the partisan rancor that infects so much of Washington. Kaye, a Democrat, brought his family to visit fellow commissioner Buerkle and her family when they vacationed in upstate New York.

Buerkle’s gentle personality, however, belies hardline views on regulation. Buerkle has never, in her fellow commissioners’ recollection, advocated for the agency to regulate a product that the CPSC staff thinks is unsafe. She is a government regulator who doesn’t appear to believe in government regulation.

Voluntary standards are “a better way to go,” Buerkle told me. “They are quick to complete. There’s much more efficiency in implementation. And there’s much more buy-in from stakeholders.” Never mind that in this instance it took more than a decade, and ongoing government prodding, for companies to get close to adopting a voluntary standard of its own. Pressed on which product hazards are her priorities, Buerkle says: “Fidget spinners are a big deal.” (They should not be placed in the mouth, the commission warns.) She also mentions children’s products and toys, pool safety, and portable generators.

Among her first actions as chair, Buerkle did two things. She sent a letter in August to Scott Pruitt, the head of the Environmental Protection Agency, agreeing with his assertion that the CPSC does not have the legal authority to make a rule about carbon-monoxide emissions from portable generators.

In a second move, Buerkle appointed Patricia Hanz to be her general counsel. Hanz comes from Briggs & Stratton, a manufacturer of engines in Wauwautosa, Wisconsin, where she was the assistant general counsel. Briggs & Stratton, which brings in $1.8 billion a year, happens to be one of the biggest portable-generator manufacturers in the world. Hanz also served as the vice president of the portable-generator trade group.

The rise of Hanz and Buerkle—and the issue of portable generators—has injected a new contentiousness into the CPSC. In an impassioned speech in October, decrying the future of her agency, CPSC commissioner Marietta Robinson called Hanz “the one person who fought the hardest against any safety measures” for portable generators.

Hanz declined to comment on a detailed list of questions. In a statement from the CPSC’s public-affairs office attributed to Hanz, she said she has recused herself. “Under the Trump Administration Ethics Pledge I cannot have any involvement with my former employer, nor with PGMA (Portable Generator Manufacturers Association) for two years, including contracts and regulations. In addition, to avoid any appearance of partiality, I will have no involvement in matters related to any PGMA members,” she wrote in an email. Briggs & Stratton also declined to respond to detailed questions. The company said in a statement it “is and has always been committed to safe operation of generators.”

While Trump has achieved few of his legislative priorities, his administration is succeeding in broadly eroding federal regulation. Having fought the long war, the portable-generator industry is now poised to benefit from the president’s success. The government’s portable-generator rule has not been finalized—and now with Buerkle at the helm, it probably will never be.

The Consumer Products Safety Commission’s efforts to fix portable generators owe their origins to what now seems like a silly panic just before the turn of the century. In the lead-up to the year 2000, people worried that computers wouldn’t be able to process, in their databases, the transition from the year 1999, a theoretical calamity referred to as the Y2K problem. If they went on the fritz, some predicted, the country might face catastrophes like mass blackouts. Regulators worried that people would rush out to buy portable generators, leading to a spike in carbon-monoxide deaths.

Y2K passed without incident, and those who purchased generators to protect against the apocalypse sheepishly stored them away unused. But the CPSC realized that it should do something about needless carbon-monoxide deaths. Portable generators were killing more people than all heating systems combined.

When the CPSC thinks about regulating products, it considers what it calls a “safety hierarchy.” The best solution is to design a product that is safe. Not all products, of course, can be perfectly safe—cars must go fast and table saws must be sharp. So the second-best remedy in the hierarchy is to mitigate the risk with, say, airbags or handguards. The third option is a warning label, but the CPSC staff typically views that as least desirable because people often don’t abide by the warnings.

In 2002, the commission contacted Underwriters Laboratories, a private company that tests product safety and helps develop industry standards, to see if it would help companies make safer generators. Seeing the government moving, the manufacturers began, with reluctance, to place warning labels on the machines. At the time, the companies claimed, a label that cautioned people not to operate the machines indoors was as far as they were able to go: The technology, they asserted, did not exist to make a generator engine that emitted less carbon monoxide.

The CPSC staff was happy enough at the time because third-best is better than nothing. Still, in the case of portable generators, the instructions can produce confusion. They tell consumers not to operate them indoors, but also not to let the machines get wet, which would seem to rule out placing them outside in many cases. Given that people tend to use their generators precisely when weather conditions are snowy or torrential, this is hard advice to follow. Some users solve this conundrum by doing things like putting the generator on their porch or in their garage.  Sometimes people have not put their generators far enough outside: More than a quarter of portable-generator deaths occur from these sorts of placements.

The companies were not sympathetic, says CPSC Commissioner Kaye. His impression of the industry view was: “If consumers are too stupid to read the label and they die, that’s their fault.”

In the short term, adopting the labels had one positive effect—at least for the manufacturers: It staved off stricter regulation for several years. Unfortunately, it was a different matter for consumers. The labels had no apparent effect. The number of carbon-monoxide deaths and injuries caused by generators did not decline.

The continuing deaths were disturbing enough that in 2006, under the George W. Bush administration—no fan of regulation—the CPSC decided to take more significant steps. The CPSC began work on a mandatory rule requiring manufacturers to make their machines safer. How the industry got there would be up to them. Companies could develop engines with lower emissions or install switches that automatically shut off the engine when carbon-monoxide levels got too high. The agency produced what it calls an “Advanced Notice of Proposed Rulemaking,” announcing its intentions and allowing the public to comment.

Comments flowed in, especially from the industry. In February 2007, manufacturers wrote to the CPSC urging it not to impose a mandatory standard. They said it would be costly. They also raised questions of whether the CPSC even had the power to require engines with low emissions. As for shutoff switches, the companies warned that “the presence of such [carbon-monoxide] detections capability may create a false sense of security,” lulling consumers into thinking they don’t need to take other precautions. One of the three signatories was Patricia Hanz, then working for Briggs & Stratton.

But with the warning label clearly no longer placating the government, the industry gave some ground, agreeing to begin developing its own voluntary standard in the hopes of avoiding a stricter mandatory standard from the government.

For the next three years, little happened. Underwriters Laboratories, today known as UL, again tried to help the industry come up with its voluntary standard, but in 2009, as UL worked toward guidelines manufacturers considered too stringent, they decided to go their own way.

The companies created their own trade group, the Portable Generator Manufacturers Association. The PGMA launched its own initiative to create a voluntary standard. But the CPSC remained skeptical. One problem was that the PGMA’s members don’t sell all the generators purchased in the U.S. Other makers wouldn’t be bound by anything that body came up with. (Today, the PGMA says it represents 80 percent of the market, which manufacturers I spoke to estimate to be anywhere from $700 million to $1 billion.)

The following year—a decade after the CPSC began trying to prevent deaths from carbon-monoxide poisoning—the PGMA held its first technical committee meeting to discuss the safety of portable generators. Among the attendees was Michael Gardner, the vice president of new product development at Techtronic Industries, a maker of generators and other products (including Hoover and Dirt Devil vacuum cleaners). He waited for a discussion of carbon-monoxide emissions. And waited.

Nobody ever brought them up. “The one topic the technical committee was not talking about—the elephant in the room—was the roughly 70 people dying [each year],” Gardner says. “The technical committee was established to write the safety standard but it did not include carbon monoxide in that standard.”

Carbon-monoxide poisoning is far and away the chief safety concern from portable generators. Nothing else comes close. But Hanz, then on the PGMA board of directors, argued that the industry should figure out all the easy things first, rather than tackle the most contentious issues right away.

With the voluntary standard going nowhere, the CPSC decided it needed to conduct the manufacturers’ research and development for them. It sent out a proposal asking for engineers to try to solve the problem. The University of Alabama answered, and came up with a prototype for a safer generator. In October 2012, the CPSC gave a technology demonstration to the industry showing the new engine could lower emissions by more than 90 percent.

Many of the companies scoffed. They argued the prototype was unproven and unreliable, and that the University of Alabama results were obtained in unrealistic conditions. They even suggested the new engine might be dangerous, giving users the sense that they needn’t worry. One company, however, embraced the new ideas: Techtronic. “That was a tipping point for us to say it can be done,” Gardner says.

Not until September 2014 did the PGMA release an initial voluntary technical safety standard for manufacturers. The detailed list included provisions for durability (generators had to survive being dropped from a height of eight inches onto a concrete surface); temperature tolerance (wind speed less than 6.7 miles per hour during testing), and rain resistance (a generator must be soaked, wiped off, and then run for 15 minutes).

But the standard was mute about the emissions that could kill customers. The CPSC sent a politely worded letter in January 2015 that the “staff notes with concern” that the proposal’s only mention of carbon monoxide was in the context of warning labels and external carbon-monoxide monitors. On average in the three years through 2012 (the most recent year for which official data is publicly available—the government’s death count lags as the tally only becomes official years later), carbon monoxide from portable generators killed 63 people per year. The CPSC’s displeasure carried a threat to the industry: If it didn’t get moving, the commission would move forward on its own mandatory standards effort.

To confront this threat, the industry countered with one of its own. In March 2014, the PGMA sent a letter to the commission insisting that it was “not appropriate” for the CPSC “to establish a working group” on the issue, statements that carried the implication it might sue the government if the commission tried to implement a mandatory rule. At that point, the PGMA finally formed two groups of its own to examine two engineering solutions: a low-emissions engine based on the University of Alabama prototype and an automatic shutoff valve. Most of the manufacturers, if pressed, preferred adding shutoff valves; they’re much cheaper. After two meetings, the PGMA picked that option and discontinued the group aimed at looking at lowering emissions.

A year later, the PGMA was ready to show off its progress. In March 2016, the trade group hosted a technical summit. Representatives from manufacturers flew in from all over the country. But only one PGMA member made a presentation regarding a new low-emission generator: Techtronic’s Gardner. In front of a crowd that included manufacturing employees, lobbyists, CPSC staff, and one CPSC commissioner, Republican appointee Joseph Mohorovic, Gardner demonstrated that the low-emissions technology worked. Techtronic’s engine produced 90 percent less carbon monoxide than a similar machine.

When Gardner finished, he looked around the room and heard nothing but silence. Then, in a scene out of Citizen Kane, he heard one lone person begin to clap: Mohorovic. After the talk, the commissioner stood up, came over, and shook Gardner’s hand.

At the meeting, someone asked whether companies were going to introduce a low-emissions engine, and if so when. Briggs & Stratton’s Hanz said it would be many years, perhaps five or six. Not so, Techtronic said. It was planning to introduce one in 2017.

Finally, in November of last year, the time had come. American society makes bargains with its machines. The country is willing to pay, sometimes in lives, for less expensive and more convenient products. But this deal seemed, to the government, too costly.

To make any rule, the CPSC is required to conduct a cost-benefit analysis. In this case, the commission estimated that new portable-generator restrictions would save $145 million annually, accounting for the government-computed value of the lives saved. (The industry took issue with those figures.) The commission rarely votes on mandatory rules. Indeed, Congress requires the agency to try to get industries to implement voluntary standards first. But the portable-generator makers had not done so.

The commissioners concluded they had no choice. They voted on a Notice of Proposed Rulemaking (NPR), a big—but not final—step toward a mandatory rule. It required manufacturers to build low-emissions machines. The CPSC staff said it was the best alternative. After investigating four different shutoff technologies, they determined that option was “not feasible.” With Mohorovic joining the Democrats, the vote was 4–1.

“Our staff engineers spent well over a decade trying to get manufacturers to make portable generators safer and all but a couple steadfastly refused to do so,” says Marietta Robinson, a commissioner appointed by President Obama. “This NPR was absolutely essential in forcing manufacturers to do the right thing to save lives.”

Meanwhile, the manufacturers were still dithering on a voluntary standard. They couldn’t even agree on how to measure how much carbon monoxide their engines emitted. In April of this year, UL tried to take a preliminary step; it proposed a uniform method for measuring emissions. Techtronic lobbied for it. Briggs & Stratton pushed against it. Things got heated: At one point, a Briggs & Stratton employee labeled Techtronic a “rogue company” in an email circulated to PGMA members. During the voting, some manufacturers changed their position, from being for the standard to being against. Briggs won and the measure was narrowly defeated.

Today, with Buerkle as chair, the fate of the mandatory standard seems doomed. She has already voted against it once, and stated that the CPSC has no power to regulate generators’ carbon-monoxide emissions. Installing Hanz as general counsel has only made some CPSC officials more pessimistic about regulating portable generators. Buerkle says Hanz is qualified and that her appointment was fully vetted by ethics officials.

Nearly two decades after carbon-monoxide concerns first arose, the industry says it is close to a voluntary standard. Even this move has twists and turns. PGMA is working on a less stringent guideline, only requiring a shutoff sensor. It is aiming to have it completed by this year.

At the same time, UL circulated a competing, stricter measure, requiring both a shutoff sensor and a low-emission engine. Again, members lobbied intensely. The nay votes had a surprising supporter: Mohorovic. The Republican commissioner has left the CPSC and taken a job at the law firm Dentons. And he has flipped from the position he held as a public servant. He now is against a low-emissions engine, sending a series of emails attacking UL’s standard and urging members to vote against. “There is no evidence, data or modeling” that UL’s standard will save lives, he wrote recently in an email to one voter. (He did not respond to questions about why or who his client was.)

Buerkle, too, advocates for a shutoff sensor. She contends they are the safer alternative. “I’m told by CPSC staff,” she says, that “shutoff technology will be far more effective” in saving lives. She says the staff told her that shutoff switches would reduce the figure by somewhere around 99 percent.

But in fact that 99 percent figure is an industry estimate. The CPSC acknowledges that it has neither calculated how many deaths the shutoff valves will save, nor concluded that they’re more effective at saving lives than low-emission technology. The staff at the commission has worried that carbon monoxide can migrate away from a machine such that it kills without ever triggering the shutoff switches. And staffers worry that the switches might trigger bothersome shutoffs, leading consumers to disable the switches. The industry says it has resolved those concerns, but Techtronic takes issue with the figure. Calling PGMA’s 99 percent claim “misleading,” the company says it has not been peer-reviewed and doesn’t account for many scenarios when portable generators are used.

Buerkle is satisfied with the industry’s progress: “I’m just happy where we are right now. We are on the verge with technology that will save lives.” Others at the CPSC remain skeptical. “I am extremely concerned that backing off now, as our chair and general counsel have made clear they intend to do, will, at a minimum, delay these life-saving efforts, and perhaps stop them altogether,” says Robinson, the Democratic commissioner whose term has expired. (She will leave when her replacement is confirmed.) But with Buerkle’s ascendancy, there’s not much Democratic commissioners can do.

The industry says some manufacturers aim to start marketing machines with shutoff switches next year. “This should be a good news story that industry stepped up to do the right thing,” says Edward Krenik, a lobbyist who represents the PGMA. “Though it took a while.”

For its part, Techtronic kept its promise to put a low-emissions generator on the market. They’re available now—and they sell for less than many other competing products. But to the industry, that makes Techtronic an outcast.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

At least 2,000 children have now been forcibly separated from their parents by the United States government. Their stories are wrenching. Antar Davidson, a former youth-care worker at an Arizona shelter, described to the Los Angeles Times children “huddled together, tears streaming down their faces,” because they believed that their parents were dead. Natalia Cornelio, an attorney with the Texas Human Rights Project, told CNN about a Honduran mother whose child had been ripped away from her while she was breastfeeding. “Inside an old warehouse in South Texas, hundreds of children wait in a series of cages created by metal fencing,” the Associated Press reported. “One cage had 20 children inside.”

About 65 million years ago, shortly after the time of the dinosaurs, a new critter popped up on the evolutionary scene. This “scampering animal,” as researchers described it, was likely small, ate bugs, and had a furry tail. It looked, according to artistic renderings, like an especially aggressive New York City rat. And it had a placenta, an organ that grows deep into the maternal body in order to nourish the fetus during pregnancy.

The rodentlike thing would become the common ancestor of the world’s placental mammals, with descendants that include whales, bats, dogs, and humans, among many other species. And today, the placenta might hold the key to one of the most enduring mysteries in human medicine: Why do women suffer much higher rates of autoimmune disease than men do?

Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.

There’s a moment about 15 minutes into the first episode of Years and Years that made me gasp at its audacity, its prescience, its visual horror. The new six-part series from the British writer Russell T. Davies (Doctor Who, A Very English Scandal) charts the life of the Lyons family over the course of 15 years, starting in 2019 and ending in 2034. It’s a kitchen-sink saga that barrels its way through births and marriages and betrayals, but also through the near-future. In 2024, Stephen Lyons (played by Rory Kinnear), a financial adviser, is at home with his wife, Celeste (T’nia Miller), both rushing their way through the morning routine. When the camera turns to their teenage daughter Bethany (Lydia West), her face isn’t recognizably human. Instead, she looks like a 3-D version of a Snapchat puppy, with vast cartoon eyes, wagging pink ears, and a brown snout. When she talks, her voice is grotesquely distorted, a robotic hallucination of a child’s cadence. “I might have to start limiting filter time,” Celeste says in the same exasperated, noncommittal way that you might think, I really should spend less time on Twitter.



It was a move as calculated as it was  stealthy. On Friday, Richard Cordray, the director of the Consumer Financial Protection Bureau (CFPB) officially appointed Leandra English to the agency’s number-two position, deputy director. By installing an official deputy, Corday, who will officially resign by the close of business on Friday, is providing the agency with its best defense against a Trump appointee taking over the Bureau’s leadership. And signaling that the agency is willing to put up a fight to maintain its current trajectory.

A provision of the Dodd-Frank Act, the same act that created the agency in the first place, stipulates that the deputy director shall “serve as acting Director in the absence or unavailability of the Director.” Until Friday, the agency had only an acting deputy director. Without an official deputy, the question of who would lead the agency once the director resigned was likely to be fiercely contested. The stakes are high—the agency enjoys an unusual degree of independence, with its funds not coming from Congress and its directors serving five-year terms—and it has become a key battleground in the long-running fight between consumer activists and financial institutions, and between political parties.

The Trump administration had signaled its intent to replace Cordray with an acting director, using the Federal Vacancies Act—a statute which generally empowers the president to fill vacancies on an interim basis, unless some other mechanism is specifically authorized. Some observers had concluded that the language on succession in the Dodd-Frank Act was too vague to count, leaving Trump free to appoint an acting director. But after the Georgetown law professor Adam Levitin pointed out that the version of Dodd-Frank passed by the House had explicitly applied the Vacancies Act to the CFPB, and that the conference committee had stripped out that language, many legal scholars told The Intercept’s David Dayen that they believed that control of the agency would pass to the deputy director.

That placed political pressure on Cordray—who may harbor ambitions to run for governor of Ohio as a Democrat—to act. By formally naming a deputy director on Friday, he strengthened the CFPB’s hand in any ensuing legal battle for control of the agency. The Trump administration must now decide whether to simply allow English to become acting director, running the agency while it attempts to get a new nominee for director confirmed by the Senate, or whether it wishes to name its own acting director, a move that offer immediate control but would almost certainly wind up being challenged in court.

In a letter to staff announcing his official resignation on Friday, Cordray wrote, “Since its inception, the Consumer Bureau has stood on the side of Consumers to see that they are treated fairly. The ongoing and future work of the Consumer Bureau makes key contributions to the health of our economy and the well-being of all Americans.”

Trump’s choice, CBS  News reported, is Mick Mulvaney, currently the head of the Office of Management and Budget. Mulvaney has been a vocal critic of the CFPB. In fact, Mulvaney once called the Bureau a “sick sad joke.” Though Mulvaney wouldn’t have run day-to-day operations of the agency, his appointment as acting director would allow him to hire someone to oversee daily work and to set the agency’s broader agenda. Given Mulvaney’s history, that would likely have included a push for less regulatory action. Paul Bland, the executive director of the advocacy group Public Justice, called the potential appointment of Mulvaney as the head of the Bureau “a great tragedy for American consumers.”

Since its inception in 2010, the Bureau has issued rules and regulations on consumer products including payday loans, prepaid debit cards, and mandatory arbitration clauses. The agency has also fined many financial industry companies, including Wells Fargo and Equifax, for actions that hurt customers and created new opportunities for consumers to air grievances with financial institutions and learn about consumer products. Those actions, applauded by consumer groups, have led to mounting complaints from banks, financial institutions, and conservatives that the agency has overstepped its proper role and needs to be reigned in.

Before she was appointed to the role of deputy director, English served as the chief of staff for the Bureau. David Silberman, who had been the agency’s acting deputy director, will continue in the role of associate director of Research, Markets, and Regulation.



In August, after decades of failing to pay property taxes on their private cul-de-sac in the hills of San Francisco, residents of Presidio Terrace were rudely awakened to the fact that their street no longer belonged to them. It had been sold at auction, perfectly legally—and the well-heeled homeowners would have to deal with whatever profiteering came of it.

As I noted at the time, there was some deeply satisfying irony here for anyone who has railed against the elitism of San Francisco’s housing market. But as of last week, the universe has returned to its usual order: The Presidio Terrace Association got its street back.

The homeowners’ association had sued the street’s buyers and enlisted a battalion of influencers to appeal to the city to reverse the sale. Among them was Senator Diane Feinstein, who used to live on the street. “In the United States, no one should lose property at the hands of the government without knowing it,” she wrote to the city in October on behalf of her old neighborhood. San Francisco officials caved, and reversed the tax-default sale—the first such reversal by the city in decades, and possibly ever, according to the San Francisco treasurer’s office. After casting his vote in support of the homeowners’ association, San Francisco Supervisor Mark Farrell called the San Jose couple who’d purchased it “speculators … attempting to extort San Francisco residents that I represent into a quick $1 million payday,” according to the San Francisco Chronicle.

Tina Lam and her husband Michael Cheng are that couple. Both Asian immigrants who would have once been banned from the neighborhood by its early racial covenant, they’d purchased the street for $90,000 at public auction in 2015, where it had wound up as many lesser tax-owed properties do. The Presidio Terrace HOA had apparently forgotten to provide the city with an updated billing address for some 30 years, causing them to default on a $14 annual property tax on their gated street and common green areas. By 2015, they’d racked up nearly $1,000 in outstanding fees.

After Lam and Cheng picked up the property, they spent a couple of years considering their options—charging for parking, say, or selling back the cul-de-sac at profit. That’s how Presidians found out the street was no longer theirs: The couple sent an agent door-to-door to assess the community’s interest in repurchasing the cul-de-sac.

When the story broke, the internet relished the optics of Bay Area mansion-owners suddenly beholden to a new landlord. But it was also symbolic of all kinds of depressingly antidemocratic trends. Homeowners’ associations have often stepped in to buy property off the hands of cash-strapped cities, but they’re infamously shadowy about how they operate, even for members—which is why it isn’t that crazy that the residents had been poorly informed of their shared delinquency. Furthermore, cities sell off public assets to developers, investors, and universities all the time, for all kinds of reasons. Citizens are frequently not informed of these (often more worrying) transactions, either.

For now, Presidio Terrace belongs to its residents again. Their victory isn’t cause for celebration, though. The city’s highly unusual tax-sale reversal smacks of preferential treatment. It’s hard to imagine elected leaders going to bat for, say, each homeless individual who has had property seized by the city. Farrell, the city supervisor quoted above, is also the author of Proposition Q, a controversial measure approved by San Francisco voters in 2016 that allows the city to clear homeless camps given 24 hours’ notice.

But the saga of Presidio Terrace may not be over yet. Although the city promised they’ll get their $90,000 purchase price back, Cheng and Lam have said they plan to sue. For progressive politics, San Francisco was once a city upon a hill. Now it’s rich people squabbling over one.

This post appears courtesy of CityLab.



On Friday, the stock market took a sharp tumble, with the Dow dropping more than 600 points, the biggest single-day decline since Brexit and the biggest weekly decline in two years.

It wasn’t just the Dow. The declines were widespread, affecting stocks, bonds, and commodities. And the major indices, including the Standard & Poor’s, NASDAQ, and Dow Jones, dropped about 2 percent each. (The Dow’s decline was closer to 2.5 percent.)

While those percentages may seem small, they represent notable drops for a market that has been on an upward trajectory—with only a few small and short-lived corrections—for the better part of nine years.

Why is this happening? The short answer is: panic over the possibility of higher interest rates. On Friday morning, the Bureau of Labor Statistics released its monthly jobs report, which showed that in January, average wages increased the most in any month since 2009. While that’s good news for most Americans, it can signal that inflation might soon increase, which might in turn cause the Federal Reserve to raise interest rates more quickly than expected—making borrowing money more expensive for companies (and individuals). That’s the sort of thing that might make investors think twice about putting their money into the market.

Still, most analysts don’t think that Friday’s performance spells trouble for the economy more broadly. Instead, the correction, which many say is overdue, may signal that the market is returning to more-normal growth patterns, which include more volatility than has been seen in recent years.



Jason Edward Harrington spent six years working the luggage-screening checkpoint at O’Hare International Airport in Chicago. A college graduate and freelance writer, he initially took the job as a stopgap, but found that he enjoyed meeting passengers from all over the world, some of whom showed a real interest in him. But while working for the TSA, Harrington noticed that his bosses were following and video-recording his every move, a practice they said was at least in part for his protection: If, perchance, a traveler’s iPad went missing, the videotapes would prove that Harrington was not to blame. Harrington was on board with that. His problem, he told me, was that supervisors would also view the tapes to search for the slightest infraction—anything from gum chewing to unauthorized trips to the bathroom. Eventually, these intrusions led him to quit. “If they trusted us, respected us, you could really enjoy the job,” Harrington told me. “But they didn’t.”

A TSA spokesman, Michael McCarthy, acknowledged the agency’s use of surveillance, though he attributed the “fairly rapid” turnover rate of TSA baggage screeners to other factors—in particular, to “low pay and high stress.” In fact, electronic surveillance of employees, through technologies including not just video cameras but also monitoring software, has grown rapidly across all industries. Randolph Lewis, a professor of American studies at the University of Texas at Austin and the author of Under Surveillance: Being Watched in Modern America, pointed to software that makes it possible for employers to monitor employee facial expressions and tone of voice to gauge their emotional states, such as rage or frustration. Among more conventional surveillance methods, employers can track employees’ website visits and keep tabs on their employees’ keystrokes. Employers can also monitor employees’ personal blogs and read their social-networking profiles. In one case in California, a sales executive at a money-transfer firm sued her employer, claiming she had been fired for disabling an app that used employer-issued cell phones to track workers via GPS, even when they were off the clock. (The suit was later settled out of court.)

The proliferation of surveillance is due, at least in part, to the rising sophistication and declining cost of spy technology: Employers monitor workers because they can. Michel Anteby, a Boston University sociologist and business scholar who has watched how monitoring affects employees at the TSA and other workplaces, has also noticed that the more employees are watched, the harder they try to avoid being watched, and the harder management tries to watch them. “Most TSA workers we observed do everything possible to stay under the radar, to essentially disappear,” he said. “They try to never speak up, never stick out, do nothing that might get noticed by management. This leads to a vicious cycle, whereby management grows more suspicious and feels justified in ratcheting up the surveillance.”

Perhaps the most common argument for surveillance—one often deployed by firms that make employee-monitoring products—is that it can make workers more productive. Purveyors of monitoring software claim they can help managers reduce the number of wasted hours and ensure that employees make better use of their time.

A Boston-based technology company called Humanyze applies what it calls “moneyball for business.” The term moneyball originated in Michael Lewis’s best seller about the Oakland Athletics baseball team and its general manager, Billy Beane, who used statistics to assemble a team of particularly gifted ballplayers. Humanyze gathers data by fitting employee ID badges with a microphone, location sensors, and an accelerometer to tease out patterns of employee behavior that affect a company’s performance. At one office, Humanyze’s data suggested that more frequent employee interactions improve productivity, so the employer installed larger, more central coffee stations to encourage those interactions.

In his essay “In Praise of Electronically Monitoring Employees,” the MIT researcher Andrew McAfee describes a study of surveillance he conducted in collaboration with colleagues at Washington University in St. Louis and Brigham Young University. Using theft-detection software, the researchers monitored waitstaff (with their knowledge) at 392 casual-dining restaurants in the United States. The installation of the software correlated with a reduction in employee theft by less than $25 a week for each location—not a whole lot. What was significant was that revenue grew by $2,975 a week per location—nearly $1,000 from drink orders alone. Employee’s tips also grew, and this, McAfee writes, suggests a “win-win.” He speculates, “As far as we can tell, performance improved simply because people started doing their jobs better.” Perhaps once the “bad actors” understood they were being watched, they realized their best bet for making more money was to improve their service in the hope of garnering larger tips, McAfee surmises—and that good behavior caught on among other employees, too.

The proposition that job performance improves when employees are monitored, and thereby theoretically deprived of the opportunity to steal, is not a hopeful one. An equally plausible explanation for the growth in revenue at the restaurants McAfee observed is that installing spy software was part of a larger commitment on the part of management to organize and streamline operations. Anteby notes, “It’s possible that almost any change—even changing the lighting—would have prompted a similar increase in productivity.” It’s also possible that observed employees felt pressured to push customers to order more—a practice that is not necessarily good for business in the long run, as few of us enjoy feeling pressured to overconsume.

In general, studies of surveillance suggest that it can increase workplace stress, promote worker alienation, lower job satisfaction, and convey the perception that the quantity of work one generates is more important than its quality. In an analysis aptly titled “Watching Me Watching You,” the British anthropologists Michael Fischer and Sally Applin conclude that workplace surveillance creates “a culture where … people more often alter their behavior to suit machines and work with them, rather than the other way around,” and that this tends to erode their sense of “agency.” That is, the constant surveillance of employees diminishes their capacity to operate as independent thinkers and actors.

Worse yet, some studies suggest that workers who sense they are monitored have lower self-esteem and are actually less productive. In fact, Anteby told me, those of us who do “cheat” on the job often do so in retaliation for the very lack of trust surveillance implies: For example, some TSA employees he observed wasted countless hours finding clever ways to evade the surveillance camera’s roving eye. So while surveillance can be beneficial under some conditions, it’s unclear precisely what those conditions might be—or whether there are limits.



Kay Coles James’s family was adamant that she pursue an education. James attended the historically black Hampton University, where she studied history and education. Growing up with an emphasis on education and self-sufficiency led her to a career in public policy and then the Heritage Foundation.

Coles James served during the George W. Bush administration as the director of the Office of Personnel Management. She began serving on the board of trustees for the Heritage Foundation in 2005, and became the president in 2017. In September, the White House named her to the Women’s Suffrage Centennial Commission. I recently spoke to Coles James about growing up in a “dysfunctional family,” her experience at Hampton University, and serving as the first black woman president of the Heritage Foundation. This interview has been lightly edited and condensed for clarity.

Lola Fadulu: Could you tell me a little bit about your parents’ work background, what jobs they were doing when you were growing up?

Kay Coles James: I came from what would be called today a dysfunctional family. My father did odd jobs. He was a guard. He worked unloading ships when he was younger. He did maintenance work. My mother was a dental tech for part of her life, working for her brother-in-law, and the rest of the time she was a domestic, cleaning houses and caring for people. So they were hard-working folks, but not with steady jobs or glamorous careers by any stretch of the imagination.

Fadulu: Did they have a specific profession that they wanted you to go into?

Coles James: I was the only girl out of five boys, and I think they were more interested in making sure that I had a good, solid education because with that, there would be lots of opportunities to do any number of things. My father left home when I was around 4 years old, and I ended up being raised by my aunt and uncle. They were professional people. He was a businessman, and she was a schoolteacher, but she suffered under the debilitating disease of alcoholism. And as a result of that, even as a young child, I had to learn to be self-sufficient and independent around the house.

So I learned domestic skills rather early: I could cook and clean and care for not only myself, but at a very early age took care of my aunt as well.

Fadulu: Did you have any jobs outside of the home before going to college?

Coles James: Not very much before college. I can tell you that being raised by an African American schoolteacher, even though she was a working alcoholic, she had all the values of a middle-class schoolteacher, and education was key. And my uncle, who was sort of the rock of the family, was very adamant about the fact that I was to get a good-quality education, and he felt that once that was done, then his task was done in that he would have equipped me for life.

So when I went off to college, he said, “No, you don’t have to work. No jobs, get your education, get that done and don’t get married. Don’t get serious about any guys. Focus.” Education was key. I grew up hearing about the United Negro College Fund. The slogan, “A mind is a terrible thing to waste.” I think I had my first job outside the home when I was in college, and I went to work for the Richmond public schools as an assistant for a summer reading program, where I was doing clerical work. When you are in college and you’re doing that kind of work, your job is pretty much to do everything in the office that nobody else wants to. And that’s what I did.

Fadulu: How did you cope with that?

Coles James: I didn’t expect to come in and be the manager or the supervisor or run the company initially. I expected to pay my dues. I expected to learn from the folks who were there and more experienced and older than I was. I expected to have a work ethic. The way I was brought up is, you get there early, you leave last, you do the best job possible, and all the doors will be opened for you. So for me, it wasn’t very much about coping. Those were the values that I was raised with. That was what I expected. And I heard every inspirational phrase one could hear in that kind of environment: The cream always rises to the top. The early bird catches the worm. Work hard and it’ll pay off in the end. Those were the things that were whispered in my ear from the time I was young. And so I grew up with those values and with that ethic.

Fadulu: I know that you went to Hampton. Were you considering other schools?

Coles James: I was considering other schools at that time. But I had had lots of incredible experience integrating the schools in the city of Richmond and had been through so much in the largely all-white environments that I really felt like I wanted the nurturing, caring environment of a historically black college and university, where I did not stand out as different, where I knew that the professors and instructors had my best interests in mind and at heart. They were committed to my education, and I think by the time I finished at Chandler Junior High School and John Marshall High School, I was ready for that environment. So while I had the opportunity to go to other colleges and universities, I specifically chose Hampton University because it was an HBCU and I wanted that environment.

I wanted to not be one of the two or three black kids in one class; I wanted to experience the rich culture and history and heritage, and I’m grateful for it. It came at a time in my life where I needed that.

Fadulu: Is there anything that you wish college prepared you for in your first jobs after college or your career in general?

Coles James: Well, if you know anything about Hampton University, you know that their motto is “Education for life.” And so at Hampton, not only did we get the academic skills that we needed and the knowledge, but we also got the other training that I think was so helpful for the first job. Hampton was then and probably still is now very strict about dress codes and about demeanor—about how you carry yourself on campus, how you carry yourself in the classroom—which can then translate into a work environment. And quite frankly, I’m not sure I would have gotten as much of that if I had gone to a predominantly white institution.

I think even with my middle-class upbringing, it was good to have those values reinforced, and they have served me well in a work environment. So the education for life that I received at Hampton University was truly that. It was an education for life.

Fadulu: And what was your major?

Coles James: History, secondary education. I studied history, and then [became] involved in public policy and government and watching history unfold before my very eyes.

Fadulu: To fast-forward to your time as director of the Office of Personnel Management, are there any experiences that are memorable to you from that time that maybe changed the way you view work and yourself as a worker?

Coles James: Well, I must confess that I, like everyone else who was around during that period in our country’s history, was affected in all kinds of ways by 9/11. I was the director of the Office of Personnel Management on 9/11. And on that particular day, I think every bit of knowledge, every bit of skill, every experience that I had, had to come together for quick decisions, for processing information, for inspiring a workforce, for coming together after that to figure out a pathway forward for our country. Being a part of standing up the Department of Homeland Security. And so I think every experience that I had had, and every bit of the education that I had, came together, and it was a seminal moment, I think, that changed me, and I think everyone else who was involved, for life.

Fadulu: You’ve served on the board of trustees for the Heritage Foundation since 2005, so you were already familiar with the organization. How did you feel when you found out that you were going to become president of the foundation?

Coles James: You may or may not know that I was actually chairing the search committee, and as we developed the profile of what the ideal candidate would look like, as we developed the document that talked about the culture of the Heritage Foundation and what was needed in order to preserve and grow that organization, it became clear to several of our trustees that perhaps the person they were looking for was sitting at the table. In my mind I was headed towards retirement, and I was looking forward to watching I Love Lucy reruns and researching ancestry.com, and writing my final book. So when given the opportunity, and it was a very humbling experience,  I felt that the stars were perfectly aligned.

I did have a background in public policy, had been the dean of a school of government. I did have the business experience to run a multimillion-dollar institution. I did have the knowledge of government, based on having served at the federal, state, and local levels. And I did have a love for the mission and vision and values of the institution, and as a result of that, when presented with the opportunity, I thought it was an opportunity of a lifetime. I am one of the people that has had the opportunity to do work worth doing, work that I feel passionately about and feel very equipped to do. And not everybody gets that opportunity.

Fadulu: Is there anything that has particularly surprised you about being the president of the foundation?

Coles James: There have been very few surprises as I took over the role of president at the Heritage Foundation. Probably the elephant in the room is an African American female being president of the leading conservative organization in America. I am absolutely convinced that it was a total afterthought. Having been a part of the process, sometimes we just stumble upon the right thing, and I think we did.



How can workers adapt to a constantly changing labor market and the oncoming threat of automation? One of the suggestions researchers and policymakers have is to go back to school and acquire new skills. As my colleague Derek Thompson wrote recently, “Making it easier for adults to attend college part-time is crucial if, as the White House has claimed, the U.S. economy [actually] suffers from a ‘skills gap.’” But the latest Republican tax plan, which passed in the House, would make it more difficult for many of these workers to tap into precisely the types of education and training they have been told they need.

The House Republican plan, which was unveiled earlier this month, would repeal the Lifetime Learning Credit (LLC), a 20 percent tax credit on tuition expenses at any eligible postsecondary program up to $10,000 for those who make $65,000 or less (or $130,000 or less for married couples filing jointly). Over 4 million tax filers claim the LLC annually, saving them about $2.6 billion a year.

Gutting the LLC wouldn’t completely eradicate tax credits for students. The LLC has a counterpart, the American Opportunity Tax Credit (AOTC), which the tax plan would not scrap. About 10 million people utilize the ATOC, saving them $17.5 billion per year. Only students going to school at least half-time, in their first four years of postsecondary education, whose income is less than $90,000 (or $180,000 for joint filers) are eligible for the credit. While the AOTC’s higher income cap captures more of the population, the credit’s limits on years of postsecondary study mean that it won’t be accessible to many who need longer-term retraining programs. To mitigate some of the damage done by repealing the LLC, the Republican tax bill offers to extend eligibility to a fifth year to serve some of those who would have been served under the LLC, but would offer them only half as much as what they’d get for the first four years.

Some experts say that eradicating the LLC particularly harms workers who have been told that the key to success in the labor market is learning new skills. The LLC, according to Kim Rueben of the nonpartisan Tax Policy Center, is the only real option for workers who have or need more than five years of schooling, or who are enrolled in school less than half-time. And that’s many of the workers whose jobs are at risk.

The House tax plan also would repeal the tax exclusion for employer-provided education assistance, which allows employers to offer up to $5,250 to an employee for educational needs, tax-free. In a letter to the Hartford Courant regarding the potential repeal, the president of Sacred Heart University, John Petillo, and the president of the Connecticut State Colleges and Universities system, Mark Ojakan, wrote that the “tax-excluded benefit is an important tool in any workforce strategy.”

Cutting that tax exclusion and the LLC could make it more expensive for workers to gain new skills or higher degrees. “Workers going back to school part-time or in non-degree programs wouldn’t be eligible for a tax credit and others would have to pay tax on the value of schooling paid for by their employers,” wrote Rueben and her Tax Policy Center colleague Gordon Mermin.

When asked about how the planned education-credit cuts will affect workers, a House Ways and Means Committee spokesperson touted estimates from the right-leaning Tax Foundation, which indicate that nearly 1 million new jobs will be created because of the bill, due to the proposed lowering of the corporate income tax.

If the tax bill passes in its current form, nontraditional workers who were hoping to retrain may face yet another blow. “It all feels like it is all part and parcel of decreasing federal support for individual workers and for having employers invest in workers or human capital,” says Rueben. The U.S. has funded employment and training programs since the 1930s, but that funding has consistently dwindled. Resources for employment and training programs peaked in the 1970s, according to the economists Burt Barnow and Jeffrey Smith, when funding was equivalent to about 0.64 percent of the U.S.’s GDP. In 2015, funding for these programs was equivalent to only 0.03 percent of GDP. The funding pales in comparison to what other nations spend on these programs: In 2015, Germany’s expenditures on training programs were equivalent to 0.22 percent of its GDP, and in France, expenditures were closer to around 0.34 percent of GDP.

The tax plan has yet to pass the Senate, which will start debating after Thanksgiving and vote sometime before the Christmas holiday. Because Republicans have a 52–48 majority in the Senate, if more than two Republican Senators vote no, the bill would be stifled. There’s reason for Republicans to be concerned though: Two Republican senators, Ron Johnson and Susan Collins, have already expressed hesitation about the contents of the bill.

This article is part of the “What Makes a Worker?” project, which is supported by a grant from Lumina Foundation.



The big Republican tax cut isn’t even three months old yet. But it’s already confounding.

For months, critics (like me) predicted that the new law would be a handout for large corporations, which would drive up their stock prices and enrich wealthy investors. Instead, the stock market has been a riot of volatility since Trump signed the tax cut into law. Many (myself included) predicted that companies wouldn’t pass on their fresh lucre to workers. Instead, several big firms celebrated the new law by publicly announcing a parade of bonuses and raises for workers. On top of that, wage growth in January accelerated to its highest level since the recession. The critics predicted rising stocks and flat wages. But reality seemed to deliver flat stocks and rising wages.

But, wait, maybe that narrative has got it all wrong. The most basic criticism of the GOP’s tax cut was that the boons for corporations and their shareholders would far outweigh the benefits for ordinary workers. That’s exactly what seems to be happening. Stock buybacks announced between January 1st and February 15th reached historically high levels, totaling about $170 billion in that period. That’s 28 times larger than the total value of end-of-year bonuses that were credited to the corporate tax bill—some of which had been announced months earlier and had nothing to do with the tax cuts. Companies might be advertising new bonuses. But they’re quietly reaping the benefits of higher profits.

There is, as well, a third possibility: The corporate tax cut might actually endanger Wall Street’s winning streak. When the Dow Jones plummeted by more than 1,000 points twice within a week in February, many analysts interpreted the flight from equities as a sign of fear—fear of inflation, fear of deficits, and fear of expedited rate hikes from the Federal Reserve. Where did that sudden fear come from? Some analysts point to the corporate tax bill, which injects hundreds of billions of dollars into the U.S. economy, buoying inflation, raising the deficit, and encouraging the Federal Reserve to raise rates accordingly. Just yesterday, stocks fell and the dollar rose after Federal Reserve Chairman Jerome Powell said the tax cut should boost consumer spending and increase productivity by making businesses invest in more technology.

In sum, the GOP tax cut is raising wages (except it isn’t); it’s good for stocks (except the market has been a nauseous mess all year); and it’s poised to grow the economy—so much so that the Fed is determined to choke off inflation and discourage more business investment, which will hurt economic growth.

If this is beginning to sound confusing, perhaps that’s because, well, it is confusing. Nothing like this has happened before—a massive, deficit-busting tax cut on capital during a period of steady growth and nearly full employment.

Economic historians can’t easily predict what’s going to happen because big rich countries practically never do what Republicans just did. The closest parallel in modern American history may be the early 1980s. Facing a deep recession in the midst of the Cold War, Ronald Reagan and the GOP slashed taxes and expanded military spending. When the economy recovered, the deficit bloomed and domestic spending increased. As the dollar strengthened, Americans bought more foreign goods than domestic goods. This created what the economist Martin Feldstein called the “twin deficits”—the budget deficit grew, of course, but so did the trade deficit.

Could that happen again? Maybe. But there is another possibility. Since the Republican tax cut effectively lowers the price of capital but not labor, it encourages large companies to invest in more buildings and technology. That could boost productivity growth, since a fixed number of workers plus a rising stock of capital should theoretically improve per-worker output.

It all adds up to this: The GOP law was always an enduring corporate tax cut advertised as fast middle-class tax relief. But because it represents a novel fiscal experiment, it’s not entirely clear what the short-term or long-term implications of the plan will be. If I wrote, “The GOP tax cut is essentially a discount coupon for technology that will raise corporate profits at the expense of labor in the long run,” I’d be telling a reasonable story. If I wrote, “The GOP tax cut is an inflation machine that will raise the price of goods and labor and encourage the Fed to raise rates accordingly, thus punishing corporate profits,” I’d also be telling a reasonable story.

Critics weren’t wrong in 2017 to say that the tax cut would exacerbate inequality, helping rich investors at the expense of workers. But the Republican tax plan is a radical and unprecedented experiment in fiscal policy, and time tends to make a mockery of certainty.



A decade after it started, the Great Recession has faded into memory. Corporate earnings and the stock market have fully recovered, with the financial sector thriving. The labor market has fully recovered, with middle-class earnings growing and the economy flirting with full employment. The government, at the state, local, and federal levels, has recovered too, and the economy is growing close to what economists think of as the fastest sustainable pace.

Yet, 10 years after the economy tipped into the deepest contraction of the post–World War II era, the Great Recession’s scars remain, as seen in academic studies and government figures, as well as the testimony of regional business experts and the families that lived through it. The country has rebounded in many ways, but is also more unequal, less vibrant, less productive, poorer, and sicker than it would have been had the crisis been less severe. And the extent of the scarring holds lessons for the politicians and policymakers who will confront the next recession, whenever it hits and however it starts.

Economists have long known that recessions cause hysteresis—a word derived from the Greek word for “scars”—in the labor market. Some workers do not rebound from a recession for years, if ever, their skills degraded and their earnings diminished. So too with the economy itself; a bad recession can make the unemployment rate higher for years and years, and permanently change a country’s potential for growth. Here, there are signs of that kind of scarring: The share of Americans between the ages of 25 and 54 who are working or looking for a job has dropped by more than a percentage point since 2007—a number that might sound minute, but translates into well more than a million people not participating in the current economic boom.

The recession lies at the heart of this. In research drawing on millions of anonymized tax returns, the Berkeley economist Danny Yagan has found that for every percentage point a local unemployment rate increased during the downturn, individuals were 0.4 percentage points less likely to be working in 2015. The intensity of the recession, in other words, squeezed workers out of the labor market. Moreover, as the Great Recession dampened employment, it also dampened earnings, with higher increases in a given area’s jobless rate leading to lower earnings there nearly a decade down the road.

More broadly, the downturn seems to have wiped away demand for certain types of work, skewing the jobs market in a way that has hurt the middle class—a middle class for whom wages only recently started increasing again, and a middle class that has been shrinking since before the Great Recession hit. Job losses from the downturn  were concentrated in so-called “middle skill” jobs—ones that require more education than a high-school diploma, but less than a college degree, things like parts manufacturing, assembly, telemarketing, mail delivery, cooking, and administrative-support work. “Unemployed middle-skill workers … appear to have few attractive or feasible employment alternatives outside of their skill class, and the drop in male participation rates during the past several decades can be explained in part by an erosion of middle-skill job opportunities,” one study found—arguing, in effect, that middle-class jobs were washed away and workers decided to give up rather than taking a fast-food or big-box retail gig.

Those jobs were washed away, economists have found, by employers using the recession as an opportunity to fire workers and invest in labor-saving machines. One look at recession-era data found that employers were much more likely to add skill requirements to their job-vacancy postings in areas with big unemployment spikes: Instead of asking potential workers to have an associate’s degree and three years of experience, say, they would ask applicants to have a bachelor’s degree and five years of experience. At the same time, those businesses in hard-hit areas would invest in machines that would reduce the need for human workers at all. All together, the effect was that the Great Recession hastened the economy toward rewarding better-educated workers and robots, to the detriment of people without an advanced degree.

These changes in the demand for work and the jobs available have caused income inequality to be worse now than it would have been otherwise. Indeed, the rich have rebounded completely from the recession in terms of unemployment, earnings, and total job count—they did so quickly, in fact, and have flourished through much of the recovery. It is the middle class and lower-income workers who have not. “The employment and earnings impacts were most negative for those with low 2006 earnings, indicating that the Great Recession caused a long-term increase in employment and earnings inequality not only within but also across skill levels,” Yagan has found.

Income bands and skill levels are not the only way to look at the deep scars left by the Great Recession. It seems to have permanently altered the economic geography of the country too, with study after study finding that many harder-hit places did not recover, while certain tech-heavy, coastal, and already rich areas snapped back quickly and then expanded. Parts of Florida, Nevada, Arizona, and California, for instance, experienced intense property bubbles, with their economies overly reliant on building activity and rising home values. Thus, they suffered severe shocks when the Great Recession hit, and have struggled to rebound below the surface, Yagan found.

Rural areas and so-called “distressed communities” also got hit hard and left behind, with the Great Recession amplifying longstanding trends that have seen rural areas, parts of the Rust Belt, and the South suffer. “The prime years of the national economic recovery bypassed many of America’s most vulnerable places altogether,” a report from the Economic Innovation Group, a Washington-based think tank and advocacy group, has found. “Far from achieving even anemic growth from 2011 to 2015, distressed communities instead experienced what amounts to a deep ongoing recession, with a 6 percent average decline in employment and a 6.3 percent average drop in business establishments.”

As the Great Recession has left scars in terms of jobs and income, it has also left scars in terms of housing and wealth—with the rich getting richer and the poor recovering far less, if at all. Indeed, data analyzed by The Washington Post shows that the housing recovery has been strongest in the wealthiest areas, and slowest in the poorest. The average price of a house in a zip code in the top 10 percent of the wealth distribution rose more than 20 percent between 2004 and 2015, versus just 13 percent in the rest. That is, at least in part, an artifact of the fact that lower-income individuals had higher unemployment rates during the Great Recession and were more likely to damage their credit scores and lose their homes—with, in some cases, profound effects on their health, wellbeing, and later earnings. After the Great Recession, many rich families saw their home prices climb, and had access to the cheapest credit available in years. Meanwhile, after the Great Recession, many poor families lost their homes, had their credit scores dinged, and could not buy property if they wanted to—with many forced into rental markets overheated by investors.

Indeed, credit scores and access to credit—and all that means for a family’s ability to buy a house, finance an education, get a job, and have a comfortable cash cushion during rough economic times—remains an area where the recovery feels far off for many lower-income Americans. The average credit score has hit an all-time high, but millions of Americans still have hits to their credit caused by a foreclosure or bankruptcy. Chi Chi Wu of the National Consumer Law Center has shown how bad credit caused by a foreclosure or job loss in some cases, particularly among lower-income families, becomes a kind of financial ouroboros. “The damage from a foreclosure or other adverse mortgage-related event could cause a consumer to be denied a job, lose out on a rental apartment after losing his or her home, and pay hundreds of dollars more in auto insurance premiums,” she writes. “The cumulative impact of these financial calamities could strand a consumer economically for years after the foreclosure itself. It could create a self-fulfilling downward spiral in a consumer’s economic life.”

In terms of housing and wealth, the recovery from the Great Recession also had a racial slant, with white families rebounding and black and Latino families still burdened, years later. Families of color were more likely to have their wealth wrapped up in a home, and less in financial investments like stocks. They were more likely to be pushed into risky mortgages, and thus into foreclosure, and far more likely to be targeted by predatory lenders. Controlling for all other factors, the interest rates that black families paid for their mortgages were higher than those of white families. Thus, the Great Recession amplified the racial wealth gap—a racial wealth gap that, statistically speaking, might never close, absent extraordinary government intervention. “In the lead-up to the financial crisis, economic opportunity remained deeply unequal across racial lines, but economic trends suggested that America was on a path toward narrowing the yawning wealth disparities between white and black families,” a report by the American Civil Liberties Union has found. “[It is] a tale of two recoveries: among families that owned homes, white households have started to rebound from the worst effects of the Great Recession while black households are still struggling to make up lost ground. The divergent recoveries are important in the immediate term, but they are also an especially ominous sign for the future.”

There are other deep scars on American life, as well. The joint crises of the jobs and housing markets spurred stress-related health problems, among them “declining fertility and self-rated health, and increasing morbidity, psychological distress, and suicide.” It led to falling neighborhood property values in places hit hard by foreclosure, and decreases in student achievement. It hurt children, too. In a deep and close look at the children of the Great Recession for the Russell Sage Foundation, Irwin Garfinkel, Sara S. McLanahan, and Christopher Wimer found that the recession “seriously exacerbated an already bad situation. This was true not only for families’ economic well-being but also for parents’ health. Even the effects on family stability were notable, though smaller. The near immunity of college-educated families and the large negative consequences for less-educated families mean that the Great Recession increased the already large divide between families at the top and bottom of the income distribution.”

The recession even might have intensified today’s opioid epidemic. Researchers have found that rising county unemployment rates lead directly to additional opioid overdoses and unemployment deaths. The twin factors of the opioid crisis and the downturn-fueled economic malaise seen in some parts of the country might also explain some of the decline in the labor force there. The Princeton economist Alan Krueger has estimated that half of prime-age men not working or looking for work take pain medication on a daily basis. “Labor force participation has fallen more in areas where relatively more opioid pain medication is prescribed, causing the problem of depressed labor force participation and the opioid crisis to become intertwined,” he found.

A sicker, more unequal, more racially divided country: This is the legacy of the Great Recession. And it has profound lessons for policymakers going forward. For one, the stimulus program and automatic stabilizers—the government programs that expand when the jobs market goes south, like unemployment insurance—did work well to blunt the worst effects of the downturn. But the stimulus was always too small—perhaps three-quarters or two-thirds the size it needed to be, economists have guessed—resulting in still-extraordinary rates of joblessness, long-term unemployment, and other forms of economic stress. Moreover, the Obama administration failed to enact a government policy to keep many families in their homes, with profound knock-on effects in terms of lost jobs, lost sleep, and lost health.

When the next recession comes, the data on what to do about it will be there. Economists have pulled together plenty of studies of the dollar-for-dollar effectiveness of initiatives like extending unemployment insurance and increasing the size of the food-stamp programs, and the relative ineffectiveness of things like corporate tax cuts. Social scientists, social workers, and local officials have urged the importance of acting as quickly as possible to intervene, with efforts to stabilize financial markets, increase the deficit, and make monetary policy more accommodative. The country has now gone through three consecutive jobless recoveries, with downturns tending to amplify long-existing trend to hollow out the middle class, polarize the labor market, and hit already ailing regions hard. It seems likely that the next recession will do much the same.

The question is whether policymakers will take such evidence of the pain and scars left by the Great Recession into account. Congress is today on the verge of pushing forward a tax cut aimed at rich families and profitable corporations that will add more than a trillion dollars to the debt, with no real need for new economic stimulus at the moment. Meanwhile, it has declined to do much for the poorer families that are still feeling the worst effects of the last recession and have not yet recovered. The risk is that next time, they will get left even further behind.



When Kol Peterson moved to Portland, Oregon, in 2010, affordable housing was a priority, as it was for many newcomers in this city’s booming real-estate market. He looked at two frequently discussed options for high-cost cities—tiny houses on wheels and communal living—but decided on another option: accessory dwelling units, or ADUs—also known as “granny flats,” or basement or garage apartments.

ADUs weren’t yet common in Portland—that year, the city issued only 86 permits for them—but when Peterson did the math, he decided that building one was his best option. “I could buy a house, construct an ADU in the backyard, and live in the ADU while renting out the house,” he said. That’s what he did: He bought a home in the city’s King-Sabin neighborhood, built a two-story mini-home in its backyard, and moved in. The experience, he says, has been life-changing: “Building an 800-foot ADU eventually eliminated my housing costs, and I’m living in my dream house.”

Eight years later, Peterson works full-time helping others build ADUs and teaching classes for other interested Portland homeowners. The number of ADU permits the city issues has risen dramatically; in 2016, it was 615. In Vancouver, Canada—an ADU pioneer—more than 2,000 ADUs have been built citywide in the last decade. But for most cities in North America, steep legal barriers are preventing this form of housing from taking off: Many cities ban them outright, and those that don’t often have severe restrictions on size, owner occupancy, and parking. Only a handful of cities have adjusted their regulations to encourage more ADUs—mostly on the West Coast, where severe housing affordability is a growing problem. But Peterson and other proponents of ADUs are predicting that the country is on the verge of welcoming more of them.

“By 2020, ADUs will take off in tens of cities,” he said. “This doesn’t mean there will be an explosion of them overnight, but the concept will become more popular in the next couple of years.”

Peterson recently wrote a book, Backdoor Revolution: The Definitive Guide to ADU Development, that walks potential ADU builders through the planning and construction process, and tackles the social, economic, and environmental issues that relate to such housing. I spoke with him recently about why ADUs are gaining traction and how cities could make them easier to build. The conversation that follows has been edited for length and clarity.

Peterson: There’s a lot of single-family zoning in the center of our cities, and urban planners, civil society, and city leaders are questioning whether these zoning rules make sense. We’re missing dwellings that can house more people and are more affordable, such as duplexes, triplexes, and ADUs.

I don’t think tiny houses on wheels will soon become a widespread form of housing, because they aren’t yet permittable. But media coverage of them has helped to spur more interest in small housing in general. These factors are positioning ADUs to become a popular movement.

Kirk: What are the benefits of ADUs for residents, cities, and the environment?

Peterson: ADUs allow people housing flexibility over time. You can design an ADU in which to age in place, and then rent out your main house, allowing you to stay in your neighborhood as you grow older, and at less cost. Parents, caregivers, or adult children can also live in ADUs.

ADUs use fewer resources like gas and electricity due to their size, and because they’re often built in walkable and bikeable areas, their residents generate less of an environmental impact that way as well. They also reduce the per-capita residential footprint. This is important because there are a lot of one- and two-person households in cities, but not the housing to match that demographic. ADUs can help fill this need.

And ADUs generally don’t have a significant infrastructural impact on a city, in contrast to, say, a 400-unit apartment building. They bring more housing to an area organically, and the city doesn’t have to build new infrastructure to accommodate it.

Kirk: Where are ADUs already taking off in the U.S.?

Peterson: A city must relax their ADU codes to increase their number. In 2017, the state of California did just that. While the legislation did not address one of the most problematic issues, the owner-occupancy requirement, it did relax the rules on providing parking spaces for ADUs. Los Angeles’s code already didn’t require owner occupancy, so the statewide reduction in other regulations has been especially effective there. L.A. went from having 142 ADU permits issued in 2016 to roughly 2,000 in 2017.

San Francisco, Oakland, Santa Barbara, and numerous other California cities have also experienced a significant uptick, though not as extreme as L.A.; Portland and Austin, Texas, are other fairly ADU-friendly cities. Though this is a pretty limited subset of cities, the interest and demand for ADUs is growing.

Kirk: What should people do if they want to build an ADU but they are illegal in their city, or the codes are too strict?

Peterson: One strategy is to point to other cities that are experiencing similar affordable-housing issues—basically every coastal U.S. city—and how those that allow and foster ADUs have benefited from them. As for codes, the owner-occupancy requirement is perhaps the most important to overcome. A strategy to eliminate the provision would be to request the city to drop it in a certain area, and then take stock of the consequences a year or two later. Inevitably, ADUs won’t generate problems, and then advocates can push for expanding the relaxed rule to the entire city.

The other argument worth noting is that cities in which ADUs aren’t legal still have many of them; people are just building them illegally. When a city relaxes ADU codes, it encourages people to construct more of them—and build them better so they’re safer.

Kirk: What should one keep in mind when designing an ADU?  

Peterson: Given the small size of an ADU, it’s necessary to have a “great room” that houses the living room, dining room, and kitchen in a contiguous space. Such a room with high ceilings and a visual connection to an outdoor area that’s adjacent to the ADU makes the space feel bigger than it is.

Also, ADUs are a form of urban-infill housing, so it’s a best practice to be respectful of neighbors and not infringe on their privacy. This means being careful in terms of placement of doors and windows.

Kirk: One critique of ADUs is that they encourage more short-term rentals, which actually exacerbate the dearth of affordable housing. What’s your response?

Peterson: My hope is that ADUs would be treated like any other house in regard to short-term rentals. By this I mean that if a city doesn’t allow short-term rentals, it shouldn’t allow them in ADUs or any other dwelling. The reason parity is important is that the rules should be the same across the board, such as regarding owner occupancy. Cities generally don’t require owner occupancy for a duplex, for instance, but do for an ADU. This rule should be equally applied, or permitted ADUs will not be viewed as a desirable housing form for homeowners.

This post appears courtesy of CityLab.



The Republicans’ sweeping $1.5 trillion tax legislation touches nearly every part of the federal code: shifting around brackets, creating major new business loopholes, encouraging companies to move hundreds of billions of dollars back from overseas, changing how state and federal taxes interact, and parceling out hundreds of billions of dollars of cuts, most to the wealthy and to corporations. But a few parts of the tax code remained largely unchanged during the reform process. That includes one of the government’s biggest and most effective programs to encourage poor Americans to work and to make that work worth the time and effort, with new research showing just how effective it is.

To hear more feature stories, see our full list.  

That program is the Earned Income Tax Credit, which supported roughly 28 million families with an average credit of $2,440 as of 2015, pushing 3.3 million kids above the poverty line. The policy is a rare bipartisan one, expanded both by Ronald Reagan and Bill Clinton and supported by both Republicans and Democrats, at least superficially, on the Hill today. Its popularity stems in no small part from the fact that the EITC is not just a handout, but a program that induces more people into the workforce and encourages them to work more, by bolstering their wages. To get the credit, a single mother needs to have earned income—meaning wages or other income she makes herself. And the credit is structured not to penalize her for earning more by eating away at her benefits if she does.

The incentive works: One study found that a $1,000 increase in the EITC led to a 7.3 percentage point increase in employment and a nearly 10 percentage-point reduction in the share of families in poverty. Its benefits are far-reaching, too. For lower-education single mothers, an additional $1,000 in the EITC is associated with a 6.7 to 10.8 percent drop in the share of infants being born with low birth weights, with bigger impacts for black mothers.

New research by David Neumark and Peter Shirley of the University of California, Irvine, shows that the effects are not just short-term, either. The EITC does not just boost earnings and reduce poverty rates when it is received, but improves the lifetime earnings trajectories of unmarried women with kids. A 10 percentage-point increase in the EITC rate for a single mother with two children at age 20—meaning that for every additional dollar a woman earned, she would get 10 more cents from the EITC—increased her earnings by 3.4 percent and her hourly wages by 1.6 percent at age 40, likely stemming from several months’ worth of additional work experience translating into higher wages and income in the longer run, they found.

“What this shows is that work incentives lead to the accumulation of skills, so that later your earnings are higher,” Neumark, an economist well-known for his studies of the minimum wage, told me. “It is not that you’re working some minimum-wage job because of the EITC, but you’re actually advancing in the labor market. It’s not that your earnings plus the EITC are getting higher, but your earnings alone are getting higher, and they’re rising over time.” The tax policy, in other words, improves workers’ skills and the country’s stock of human capital.

“I run something called the Economic Self-Sufficiency Policy Research Institute,” he added. “I don’t know exactly what ‘economic self sufficiency’ means. But increasing your independent earning power over time and decreasing your dependence on government programs, even if government programs are still helping you—that seems like it fits.”  

But the Republican tax legislation does not make the EITC more generous, as many Democratic and some Republican legislators have long called for. More than that, it actually erodes the value of the EITC, since the credit is now indexed to a less-generous measure of inflation. Chuck Marr of the Center on Budget and Policy Priorities, a Washington-based think tank, has estimated that a married couple with two kids earning $40,000 a year would see their EITC payment fall from $4,974 to $4,652 in 2027. Many changes in the legislation are temporary but that one is permanent, he notes.

Now, the White House is turning to welfare reform. “We will have done tax cuts, the biggest in history, health care, phenomenal health care,” President Donald Trump said in a major speech on his policy priorities in Missouri last month. “Welfare reform, I see it, and I’ve talked to people. I know people that work three jobs and they live next to somebody who doesn’t work at all. And the person who is not working at all and has no intention of working at all is making more money and doing better than the person that’s working his and her ass off. And it’s not going to happen. Not going to happen.” Republicans have discussed adding work requirements and more-stringent time limits to safety-net programs such as food stamps and Medicaid in order to induce more poor Americans to get a job.

But where the EITC has proven long- and short-term effects on the work effort of lower-skilled and lower-income workers, such policy initiatives have far more spotty records, and in some cases no demonstrated history of reducing the poverty rate. Consider the work requirements added to the cash-welfare program during the 1996 reform. They did boost employment among program participants, but the effects were modest and temporary, researchers have found. “Stable employment among recipients subject to work requirements proved the exception, not the norm,” LaDonna Pavetti of the CBPP has written. “Most recipients with significant barriers to employment never found work even after participating in work programs that were otherwise deemed successful,” and, moreover, a “large majority of individuals subject to work requirements remained poor, and some became poorer.”

With the forces of globalization and automation suppressing wages and with low-income men and women increasingly abandoning the labor force, the government has weakened a proven program to boost wages and improve labor-market outcomes for the working poor, in other words, and is moving to more-punitive and more-complicated initiatives to try to induce people to work. It is taking away a few highly effective carrots and turning to less-effective sticks.

Right now, with wages and employment among lower-income Americans growing, that might not seem like such a problem. But after another recession and jobless recovery, with the lower half of the earnings distribution still stagnant, it might be. “The sky is the limit here,” Neumark said, about expanding the EITC. “Is it insane to double it? If we really think because of technology and globalization, people at the bottom end of the income distribution can’t earn what they should earn, this is the way to fix it. Instead of taking money and just giving it to them, you are encouraging work and the accumulation of human capital as part of the process. I don’t see a better way to do it.”



The writer Elizabeth Kolbert’s grandfather, a refugee from Nazi Germany, was a huge fan of Westerns written by Karl May. They captivated Kolbert’s grandfather so much that when he immigrated to the United States, he took his kids out West for vacations. Later, Kolbert’s mother did the same.

As a child living in Westchester, New York, Kolbert dreamed of moving out West and having adventures of her own. She ended up mostly staying put in and around New England, but her job as a journalist helped fulfill her love of adventure, allowing her to spend much of her time following field scientists around remote locations.

I recently spoke with Kolbert about her dreams of going out West and her tendency to imagine alternative lives for herself. This interview has been lightly edited and condensed for length and clarity.

Lola Fadulu: When you were younger, what did you want to be when you grew up?

Elizabeth Kolbert: I didn’t have a clear plan. I’m going to be quite frank: I wanted to move out West. That’s what I wanted to do when I was a kid. I was going to go out West and do something, but I never got west of Albany.

Fadulu: Why did you want to go out West?

Kolbert: My parents took us out West in the summer a bunch of times, and I thought it was great. We used to go to Rocky Mountain National Park.

My grandfather was a refugee from Nazi Germany, but he had, as a kid, read these Westerns by a guy named Karl May. They’re very, very famous in Germany, and they are adventure stories set in the American West. When he immigrated to the U.S., he took his kids—my mother and her sister—out West to sort of live out these adventures he’d read as a kid. And then it obviously made a big impression on my mom, and then she took us. And so that was the background to these trips. And as I say, they did make a big impression on me and I thought I, too, should go have adventures out West.  

Fadulu: What did your parents do?

Kolbert: My dad was a doctor, an eye doctor. And my mom, throughout much of my childhood, was a stay-at-home mom, very active in local politics, on the school board, things like that.

Fadulu: Did they have a career path in mind for you?

Kolbert: They were not at all prescriptive in that way. I think my dad would’ve been happy if I had been interested in medicine. One summer when I was in high school he did arrange for me to have an internship, I guess you’d call it, at the hospital where he worked, and I proceeded to contaminate a lot of the equipment. I think it became clear pretty early on that [medicine] was not going to pan out.

Fadulu: How would you describe your younger self?

Kolbert: I grew up in the ’60s and ’70s, and I was probably very much a product of the time, of rebelling against, to a certain extent, what seemed to be the conventionality and 9-to-5-ism of suburban life.

Fadulu: There was something about suburban life that just didn’t feel like it was for you.

Kolbert: Well, it wasn’t just suburbia. It was really more the sense that you were just going to ... just tick off certain things. Do X, do Y, and then find yourself following a path that everyone had already followed before and that had been laid out for you before. That was very much part of the zeitgeist, and I definitely absorbed that. I didn’t want to just go off and work for some corporation, work for some institution and be subsumed in that.

Fadulu: Do you feel you’ve followed a path?

Kolbert: Well, as it turned out I did sort of follow a path, but it was not a path I knew about as a kid.

This is what happened: I studied German literature in college, and I thought I might go on and study German literature. I got a fellowship to go to Germany, and I very quickly decided that [becoming an academic] was not what I was going to do. I was kind of bumming around Europe, and I tried my hand at writing things.

I’d worked on the high-school paper; I’d worked on the college paper. I’ve always been attracted to journalism. And I wrote a bunch of stuff that actually made it into the travel section of The New York Times. And then I came back and got a really entry-level job.

This was a different era when, at the Times, there was a very clear path. You got a clerical job. You were not even a secretary; you were called a clerk or a copy person. Copy person was a term left over from the days when Times reporters would type stories on sheets of carbon paper. And then you would rip out—it was called a “take.” You’d rip out one take, which is basically one page, one sheet of carbon paper, and you’d yell, “Copy.” And the copy person would come take it from you, and then distribute these copies to the editors to lay out or whatever.

And by the time I arrived at the Times that system had long been gone, but you were still called a copy person. I arrived at a big transitional moment for journalism—not as transitional as the moment now, but that moment where everything was being computerized and all that.

And there was a path that you could take. You could be one of these clerks and copy people, and if you wrote furiously—and, basically, it meant spending 24 hours a day at the Times—you could get pieces in.

This was the mid-’80s. The front section on Sunday was divided into two sections, and in the second section was this place that they had ads. They basically just needed copy to go around the ad.

And so you would write these un-bylined stories, and if the editors liked them, essentially, they would actually hire you as a reporter. So that is how I became a journalist.

Fadulu: What do you think of career planning?

Kolbert: I went through much of my youth thinking a lot of things were equally interesting to me, and I was equally untalented in a lot of them. And so part of it was this process of trial and error, really, of trying to find something that I was interested in and also had enough ability to pursue. I play the clarinet, and it was very clear early on that I had no talent, but in some life I would’ve been a concert clarinetist. I still, even now, am afflicted by imagining alternative lives.

Obviously, there are 7.6 billion people on the planet, and they’re all leading different lives. And I’ve always found that a very fascinating and daunting fact. Why are you you? Why were you you? You happened to be born a certain person, but that seems really accidental. Could you become someone else? Could you have led a different life? Could you still lead a different life?

Fadulu: Are there any experiences that you particularly wish you’d had, or are just really curious about?

Kolbert: I guess it does get back to “Should I have gone out West and become a cowgirl?” or whatever. Some of the most intense experiences I’ve had have been out in really remote places, and I guess that’s a way of living that I sometimes wonder whether I should’ve pursued.

Fadulu: What sort of job do you think you would’ve had if you’d worked in a remote place?

Kolbert: I’ve been out with a lot of field scientists now. I’m not a field scientist; that’s not my temperament, and I don’t have quite enough patience for that kind of work. But I’ve always been filled with admiration for those people, and those are some of the greatest experiences I’ve had, being out in the field with these people in places where no one else was. We were the only people out there.

Fadulu: It seems like in journalism, because you’re out in the field and talking to so many different types of people, you’re kind of living different lives. Do you feel that way?

Kolbert: Yes, absolutely. And I think it’s also for people like me, who are interested in a lot of things but not absolutely committed to any particular vision of life. As you say, it does allow you to, if not exactly lead alternate lives, to have a glimpse into them and to always be doing something new.

I’m really, really grateful that I have been able to, if not actually lead multiple lives, chronicle multiple lives.



Technology has helped rid the American economy of many of the routine, physical, low-paid jobs that characterized the workplace of the last century. Gone are the women who sewed garments for pennies, the men who dug canals by hand, the children who sorted through coal. Today, more and more jobs are done at a computer, designing new products or analyzing data or writing code.

But technology is also enabling a new type of terrible work, in which Americans complete mind-numbing tasks for hours on end, sometimes earning just pennies per job. And for many workers living in parts of the country where other jobs have disappeared—obviated by technology or outsourcing—this work is all that’s available for people with their qualifications.

This low-paid work arrives via sites like CrowdFlower, Clickworker, Toluna, and Amazon’s Mechanical Turk, to name a few. Largely unregulated, these sites allow businesses and individuals to post short tasks and pay workers—in cash or, sometimes, gift cards—to complete them. A recent Mechanical Turk listing, for example, offered workers 80 cents to read a restaurant review and then answer a survey about their impressions of it; the time limit was 45 minutes. Another, which asked workers to fill out a 15-minute psychological questionnaire about what motivates people to do certain tasks, offered $1, but allowed that the job could take three hours.

These are not, by and large, difficult tasks—someone with just a high-school education could complete them easily. And they may seem like one-off jobs, done for money on the side by people with a surplus of idle time. But a growing number of people are turning to platforms like Mechanical Turk for the bulk of their income, despite the fact that the work pays terribly. It’s emblematic of the state of the economy in certain regions of the country that some people consider this type of work to be their only choice. A 2016 Pew Research Center survey found that 25 percent of workers who earned money from online job platforms like Mechanical Turk, Uber, and TaskRabbit went on these sites because there was no other available work in their area.

I talked to one such woman, a 29-year-old named Erica, who performs tasks for Mechanical Turk from her home in southern Ohio. (Erica asked to only use her first name because, she says, she read on Reddit that speaking negatively about Amazon has led to account suspensions. Amazon did not reply to a request for comment about this alleged practice.) Erica spends 30 hours a week filling out personality questionnaires, answering surveys, and performing simple tasks that ask her, for example, to press the “z” key when a blue triangle pops up on her screen. In the last month, she’s made an average of $4 to $5 an hour, by her calculations. Some days, she’ll make $7 over the course of three to four hours.

Erica, who has a GED and an associate’s degree in nursing administration, says the work for Mechanical Turk is the only option in the economically struggling town where she lives. The only other work she was able to find was a 10-hour-a-week minimum-wage job training workers at a factory how to use computers. “Here, it’s kind of a dead zone. There’s not much work,” she told me. In the county where Erica lives, only about half of people 16 years or over are employed, compared to 58 percent for the rest of the country. One-quarter of people there earn below the poverty line.

One reason Erica, who has filled out more than 6,000 surveys on Mechanical Turk and has a high rating on the site, earns so little is that the work simply doesn’t pay very well. But there are other reasons she makes so little that have to do with the nature of the platform. On Mechanical Turk, where she spends most of her working hours, Erica looks out for “HITs,” as assignments are called (for “human intelligence task”), that “requesters” are hiring for online. The tasks that pay the best and take the least time get snapped up quickly by workers, so Erica must monitor the site closely, waiting to grab them. She doesn’t get paid for that time looking, or for the time she spends, say, getting a glass of water or going to the bathroom. Sometimes, she has to “return” tasks—which means sending them back to the requester, usually because the directions are unclear—after she’s already spent precious time on them.

Requesters use Mechanical Turk because they can farm out menial work on the cheap and get that work done quickly—with hundreds of workers each transcribing one minute of an audio file, for example, a final product can be returned in short order. Other sites like Crowdspring, which is an online marketplace for graphic design and other creative services, and Snapwire, a photo-crowdsourcing site, allow companies to get creative work done at a low cost.

On most of these sites, requesters hold more leverage. While there are forums where workers advocate for being paid fairly, requesters on Mechanical Turk are free to set pay as they please—the site allows requesters to list payments as low as $0.01, merely telling requesters to “consider how long it will take a Worker to complete each assignment.” (Amazon takes a 20 percent fee on what requesters pay workers, double what it charged in 2015, an increase that some workers on the platform say has caused requesters to offer less money.) Requesters can then “reject” work that is submitted if it doesn’t meet their standards. Workers don’t get paid if their work is rejected, or if they have to return a task. Also, some Turk workers have complained of their accounts getting terminated without notice, or of preferential treatment that lets some workers get the special qualification of “Master,” which allows them to get different tasks.

Sometimes, requesters will say that a task will take 20 minutes when it actually takes an hour, Erica says, but by the time she realizes that, she’s devoted enough time to the task that it’s worth completing. Those times, she told me, “I’ve felt so ripped off that I’ve walked away and cried.”

But despite the problems with Mechanical Turk, when Erica and her partner, who works for a food company, have a big bill coming up, she’ll spend extra time in front of the computer. Workers can choose to get paid every day, rather than waiting for a paycheck for two weeks. “I do it because on certain weeks, I can have a guaranteed $20 to send out to pay our bills—when we are completely flat-out broke until the following pay period,” she told me. Recently, Erica says, Amazon’s payments system has been on the fritz, though, and she hasn’t been able to get the money as quickly. The inability to get that $20 or $30 is a big problem in her household—currently, it means she doesn’t have the money to buy food to make for dinner. “I guess I’ll have to improvise,” she wrote to me, in an email. (Amazon did not respond to multiple requests for comment about this article.)

Erica’s experience with Mechanical Turk is not an anomaly. A research paper published in December that analyzed 3.8 million tasks on Mechanical Turk, performed by 2,676 workers, found that those workers earned a median hourly wage of about $2 an hour. Only 4 percent of workers earned more than $7.25 an hour. Kotaro Hara, the lead author of the study and a professor at Singapore Management University, told me that workers earn so little because it’s hard to secure enough tasks to be working every minute they’re in front of the computer. He says workers spend a lot of time looking for tasks, waiting for the interface to load, and trying to complete poorly explained tasks before deciding to return them. (The paper did not research how many of the people it tracked depended on Mechanical Turk as their sole source of income.)

How is it legal to compensate workers so poorly? The federal minimum wage in America, after all, is $7.25 an hour. But Erica and other crowdsourced workers do not have to receive the minimum wage because they are considered independent contractors, not employees. They are not covered by the Fair Labor Standards Act, which guarantees workers minimum wage and overtime protections, as well as a host of other benefits. Just as small-business owners are allowed to work for hours on their own and not earn any money, independent contractors like Erica can spend significant time seeking work and completing tasks, and receive very little in return for doing so.

The problem is not necessarily that requesters are underpaying for the work. The average requester pays around $11 an hour for the work they get, according to Hara. But there are also many requesters who pay less than that, and there are many requesters who post tasks that take longer than they say to complete. Still, the root of the problem is that these platforms allow requesters to avoid paying workers for the downtime that would arise if workers did these tasks full-time.

This kind of piecemeal work is only expected to become a larger part of the economy in the coming years. Already, about 5 percent of Americans earn money by doing online tasks for a job platform, including for low-paying sites like Mechanical Turk and higher-paying IT support sites. That’s a larger share of people than the 2 percent who made money from driving through ride-sharing apps, according to that Pew Research Center survey. By 2027, nearly 1 in 3 Americans may transition to online platforms to support themselves with on-demand gig work, according to Siddharth Suri and Mary L. Gray, two researchers who have for about five years been studying the lives of people working on demand.

As fewer and fewer jobs are available to less-educated workers outside major cities, these workers may turn to online platforms to support themselves, only to find that they are facing a lot of competition from all the other workers like them. “There are more people on these platforms because there are fewer jobs elsewhere that allow people to control their time and workloads so that they can manage other constraints, like family care and other jobs,” Gray told me.

Indeed, another Turk user, Valerie, who lives in California’s Central Valley, told me that there are more people competing for good tasks now than there were when she started doing work on the site in 2009. “It wasn’t saturated like it is now,” she said. (Valerie also asked for her last name to be kept out of this story, because, like Erica, she was concerned that something might happen to her account.) The crowds are making the platform even worse for workers than it was before. To compete, Valerie keeps the site open all day, sometimes waking up at 2:00 or 3:00 in the morning, in order to grab tasks and earn enough money to keep her bills paid.

Even with all those hours, she told me, she’s struggling to make $30 a day. Valerie doesn't have a choice but to work for Mechanical Turk, she said—her car battery is dead, and even when she can turn it on, it makes strange noises. She doesn’t have enough money to repair it, so she’s stuck working from home. The call center she worked for full-time shut down a little over two years ago, and she said there are no other opportunities in her area.

As this type of work becomes more common, some academics have argued for a new model of labor law under which even independent contractors are entitled to some basic protections. Miriam Cherry, a law professor at Saint Louis University’s School of Law who has been studying these platforms for years, argues that workers on Mechanical Turk are no different than, say, construction workers who show up at job sites and work for a day or two on a project. Those construction workers can still file a lawsuit under the Fair Labor Standards Act for wage theft, even though they are not considered employees, she said. But there has been no legal decision determining that workers on crowdsourcing platforms can do the same.

There was a lawsuit filed over this discrepancy in 2012 in California, with workers who had done tasks on the website Crowdflower alleging violations of the Fair Labor Standards Act. But that lawsuit was settled before any decision could emerge that might change how these sites are regulated. “The technology is out in advance of the law,” Cherry said. “There’s no decision telling people they can’t do this, so they take advantage of that.” Cherry thinks that there’s a stigma towards work that takes place online—people assume that others are just doing it to earn a few extra dollars, not for a living, and so aren’t as concerned with protecting those workers.

Without the labor protections available to many other workers, some workers on Mechanical Turk have banded together to look out for themselves. They’ve created browser plugins to filter good tasks from bad ones, and use sites like Reddit to review requesters. They started Dynamo, a platform where workers could collectively (and anonymously) come up with suggestions for how to improve Mechanical Turk.

Many of these efforts to improve workers’ experiences have their limits. To sign up for Dynamo, for instance, workers had to complete a HIT and get a certain code, but Amazon closed the requester account that created those HITs, making it impossible for Dynamo to add new workers, Kristy Milland, a longtime Turk worker and the community manager of the forum TurkerNation, told me. And Erica told me that many of the plugins she had downloaded to find high-quality HITs are not compatible with a recent update Amazon made to Mechanical Turk’s website, one reason she’s making less money than she used to.

In the worst days of the Great Depression, when desperate workers were undercutting each other to bid for the meager work that was available, the government stepped in and created a floor for wages by passing the Fair Labor Standards Act in 1938. It required that workers be paid a minimum wage and receive overtime pay for the time they spent working over 40 hours a week. These are very different economic times, with historically low unemployment rates and jobs going unfilled. But for one segment of the labor market—less-educated workers in depressed areas—there is no economic boom. There’s little chance that in today’s political climate, the government will step in and protect these workers as it did in 1938. More and more workers will continue performing grueling work for pennies—much like Americans did a century ago—with no way out.



In a development that would have been hard to imagine a generation ago, when video games were poised to take over living rooms, board games are thriving. Overall, the latest available data shows that U.S. sales grew by 28 percent between the spring of 2016 and the spring of 2017. Revenues are expected to rise at a similar rate into the early 2020s—largely, says one analyst, because the target audience “has changed from children to adults,” particularly younger ones.

Much of this success is traceable to the rise of games that, well, get those adults acting somewhat more like children. Clever, low-overhead card games such as Cards Against Humanity, Secret Hitler, and Exploding Kittens (“A card game for people who are into kittens and explosions”) have sold exceptionally well. Games like these have proliferated on Kickstarter, where anyone with a great idea and a contact at an industrial printing company can circumvent the usual toy-and-retail gatekeepers who green-light new concepts. (The largest project category on Kickstarter is “Games,” and board games make up about three-quarters of those projects.)

Growth has also been particularly swift in the category of “hobby” board games, which comprises more sophisticated titles that are oriented toward older players—think Settlers of Catan. These games, compared to ones like Monopoly and Cards Against Humanity, represent a niche segment, but that segment is becoming something more than a niche: According to ICv2, a trade publication that covers board games, comic books, and other hobbyist products, sales of hobby board games in the U.S. and Canada increased from an estimated $75 million to $305 million between 2013 and 2016, the latest year for which data is available.

Hobby-game fanaticism is still very much a subculture, to be sure, but it is a growing one. At the 2017 iteration of Gen Con—North America’s largest hobby-gaming convention, in Indianapolis—turnstile attendance topped 200,000. For the first time in the event’s history, all the attendee badges were purchased before the event began. Whether they knew it or not, the many thousands of people carpeting the field level of Lucas Oil Stadium wouldn’t be there if it weren’t for a small group of obsessives on the other side of the Atlantic.

The rise of hobbyist games is legible in the career arc of one of the genre’s most famous present-day designers, Phil Eklund. He was born and raised in the United States. But tellingly, he didn’t really hit his stride until moving to Germany. Eklund took to game design early in life. As a teenager growing up in Tucson in the 1970s, he became frustrated with the narrow, child-oriented fare on offer at his local toy shops—roll-and-move games like Sorry! and Monopoly. So he started creating his own games, making photocopied print runs of a few hundred or so and mailing them out to customers.

Within America’s then-tiny board-game subculture, Eklund was making a name for himself. But he felt like part of the lowest caste of nerds. “I’d go to a gaming convention, and everyone would be crowded around the computers,” he tells me. “My board-game setup would be off in the corner. The only people who’d wander over were the folks looking for a garbage can so they could throw out their gum.”

That’s in the past. Eklund now lives in Germany, where he’s attained the status of cult celebrity. He has no plans to move back to the United States. “One of the reasons I came to this country is because I knew it was the place where people take board games really seriously,” he told me. “The designers have status. They put their name on the box, and people will buy based on their reputation.”

Now a board-game star in Germany, Eklund’s friends include such masterminds as Friedemann Friese, the creator of the game Power Grid, and the legendary Uwe Rosenberg, who designed award-winning classics such as Agricola, Le Havre, and Patchwork. At Germany’s world-leading Internationale Spieltage (“International Game Day”) fair in Essen—which now attracts an audience from all over the world numbering almost 200,000—bookish introverts are mobbed by groupies looking for selfies. “It’s not like I destroy hotel rooms or go out with movie stars,” Eklund tells me. “But it’s sufficiently intense that when I get back home, it takes a week just to recover.”

Hobbyists around the world started paying serious attention to German-style board games (or “Eurogames,” as they’re now more commonly known) following the creation of Settlers of Catan in 1995. While it took more than a decade for that game to gain a cultural foothold, there seems to be no going back: Much in the way that Cold War–era American beer connoisseurs gravitated to the higher quality and vastly larger variety offered by European imports in the era before stateside microbrews took off, players who’d become bored with the likes of Monopoly and Scrabble started to note the inventive new titles coming out of Germany.

Catan, as Klaus Teuber’s hyper-profitable franchise is usually called, has many of the signature features associated with Eurogames: randomized board layouts, flexible scoring systems, an aesthetic that tends toward rustic themes and wooden pieces. But as Eklund and other Eurogame pioneers explained to me, these games’ philosophy of play is rooted in trends dating to the Second World War.

In North America, the complex board games created during the latter half of the 20th century typically took the form of simulated warfare. In Risk, Axis & Allies, Star Fleet Battles, and Victory in the Pacific, players take on the role of generals moving their units around tabletop maps. But for obvious reasons, this wasn’t a model that resonated positively with the generation of Germans who grew up in the shadow of the Third Reich. Which helps explain why all of the most popular Eurogames are based around building things—communities (Catan), civilizations (Terra Mystica), farms (Agricola)—rather than annihilating opponents. The result is a vastly more pacifist style of a game that can appeal to women as much as men, and to older adults as much as high-testosterone adolescents.

“When I was young, one of my first creations was a Star Trek–type game with humans fighting other races in space,” Eklund says. “I now realize it was more or less a racist concept. It’s been done many times. It’s just not that interesting.” In Germany, by contrast, he’s created games such as Pax Renaissance, in which players take on the role of bankers navigating the vicissitudes of war and religious upheaval in 15th- and 16th-century Europe.

But the gulf between the traditional American games of yore—“Ameritrash,” as the genre is dismissively referred to by the board-game cognoscenti—goes beyond the divide between militarism and pacifism. In Monopoly, that great bonfire of friendships, the conflict between players is direct, brutal, and zero-sum: You bankrupt me or I bankrupt you. Which is why so many rounds of Monopoly finish on a note of bitterness. The one game of Monopoly I ever played with my wife ended with her staring me down icily and declaring, without any hint of warmth or irony, “I have never seen this side of your personality.”

In Eurogames, by contrast, such naked metaphors for capitalism and predation are outré. The Spanish-themed El Grande, for instance, does not permit players to attack their opponents directly. Rather, players maneuver their caballeros around a map of medieval Spain in a bid to win the favor of local courtiers. Players don’t beat their opponents so much as thwart them. The same is invariably true in rail-themed Eurogames such as Ticket To Ride, in which players rush to claim choice routes. The action is always passive-aggressive—never just aggressive.

This mode of play is pleasant on multiple levels. There is an enormous amount of fussy micromanagerial satisfaction that comes from amassing A so you can invest in B, so you can trade for C, so you can build a D, which in turn pumps out more A. To outsiders, this churn of wood, brick, sheep, ore, and wheat always makes Eurogames seem overly complicated. (In Friedemann Friese’s masterpiece Power Grid, there is even a step called the “bureaucracy” phase.) But in practice, all the busywork keeps players immersed in their own projects, and less spiteful in regard to others’ success. Which makes for gentler competition, fewer arguments, and (in my experience) less in the way of intra-spousal recrimination.

Since the Eurogame genre came into being roughly four decades ago (the inception of Germany’s Spiel des Jahres award, celebrating the “game of the year,” would indicate 1978 as a rough date of momentum-gathering), the earliest creators understood something fundamental about the psychology of gaming: While people can tolerate losing, they despise the feeling of being eliminated from a game in progress. And so most Eurogames are designed such that scoring comes at the end of the game, after some defined milestone or turn limit, so that every player can enjoy the experience of being a contender until the final moments. If this sounds somewhat Euro-socialistic, that’s because it is. But such mechanisms acknowledge that no one wants to block off three hours for gaming, only to get knocked out early and bide their time by watching TV as everyone else finishes up.

Perhaps no game encompasses this egalitarian ethos more fully than the aforementioned Power Grid (or Funkenschlag, as it’s known in Germany), in which players take on the role of CEOs in a highly regulated, centrally administered energy market. While the first player who builds houses and hotels in Monopoly can easily leverage their initial advantage to build yet more houses and hotels and crush the competition, the exact opposite dynamic takes place in Power Grid: The more players expand their energy network, the lower their priority in acquiring the coal, oil, uranium, and recyclables they need to actually fuel their power plants. The feature acts as a natural damping mechanism on runaway leaders, so that players tend toward parity as the action progresses, and almost every game is fairly close until the last turn.

This way of playing caters to what most people actually want out of game nights: to unwind, to avoid boredom and humiliation, and to end the night as friends. One of my current favorites, for instance, is a game called Biblios, in which each player takes on the role of an abbot seeking to amass the greatest possible library of sacred books. Buying up Boardwalk and Park Place, seizing Asia, sinking an opponent’s battleship: These are all fine for children. But for adults, none of it compares to the white-hot joy of creating a well-functioning library.



Good tech gone bad! Nefarious nerds! Dubious online platforms! Predatory late capitalism! Imagine if every tech and business motif from the past 12 months gathered to celebrate an end-of-year reunion in a single story.

This is that story. It is the story of the Fingerlings and the Grinch bots.

We begin, as Christmas stories sometimes do, in a toy store. Every holiday season has its must-have gizmo, like Cabbage Patch Kids or Tickle Me Elmo. This year’s sensation is the Fingerling, a plastic five-inch-tall baby monkey. Engineered to cling to an outstretched finger with its plastic hands and feet, the toy giggles, burps, and farts in response to petting and shaking. Imagine a manic pygmy marmoset robot with minor gastrointestinal issues, and you get the picture.

Many years ago, in the days when malls ruled the world, adoring mothers and fathers fearing the wrath of a wanting child would storm into stores and shove each other across aisles to grab a toy like the Fingerling. These days, however, the battle royale over popular toys has shifted online, where the dangers are more exotic than a mother’s flying elbow.

The new holiday showdown pits humans against software. It’s not a fair fight. A fleet of bots—software programs that can automate activities like search, chat, and online ordering—have been dispatched by anonymous online scalpers to buy up the most popular children’s toys on the internet. These bots overwhelm retail sites with bulk orders from multiple IP addresses and autofill payment and address information faster than humanly possible. Hence, the apt nickname: Grinch bots.

Fingerlings are currently sold out at the websites of Toys “R” Us, Walmart, and Target. Where did the toys go? To sites like Amazon and eBay, where the bots’ owners are listing the $15 playthings for $1,000, or more. (It’s not clear who these people are, but they evidently possess programming chops, yet no soul.) Cyber scalpers have used the same methods to deplete online retailers of other toys, like Barbie Hello Dreamhouse and L.O.L. Surprise! Doll, which they can resell at exorbitant prices. While offline toy scalpers and online ticket scalpers are an old trend, this seems to be the first case of mass-scale online toy scalping.

Retailers have failed to block the bots, and platforms have refused to stop the sellers. For example, eBay has claimed that there’s little it can do to halt the legal exchange of toys. “As an open marketplace, eBay is a global indicator of trends in which supply and demand dictate the pricing of items,” the company said in a statement. “As long as the item is legal to sell and complies with our policies, it can be sold on eBay.” The Grinch bots are not technically stealing or defrauding. They are practicing a form of legally sanctioned ransom.

The yuletide fleecing of middle-class parents has attracted political attention. “Grinch bots cannot be allowed to steal Christmas, or dollars, from the wallets of New Yorkers,” Senator Chuck Schumer of New York said. He has proposed legislation that bans bots on retail sites, expanding a law that already prohibits the use of bulk-buying tickets for concerts or theater. That law’s name is the Better Online Ticket Sales Act—or the BOTS Act.

But even if fines make scalpers fear, the law won’t pass before this year. As Grinch bots reap and hoard playthings, ‘twill be too late for Fingerlings.

* * *

Why is this story so fitting for 2017? The Grinch bot drama mashes together two moral panics about once-celebrated tech stories—platforms and automation—and sprinkles them with dread about predatory capitalism. Beyond the nimbus of presidential scandal and the watershed revelations of sexual harassment, these fears have dominated the tech and business news cycles this year.

A platform is a digital interface that offers consumers access to a wide range of products, which the platform itself doesn’t necessarily own. Think Netflix for video, or Google for information. In a widely shared 2015 essay, Tom Goodwin, a writer and marketing strategist, summarized the spectacle of platforms tech this way:

Uber, the world’s largest taxi company, owns no vehicles. Facebook, the world’s most popular media owner, creates no content. Alibaba, the most valuable retailer, has no inventory. And Airbnb, the world’s largest accommodation provider, owns no real estate. Something interesting is happening.

He was right: Something interesting is happening. But while Goodwin’s summary inspired sunny optimism back in 2015, the last 12 months have revealed the dark side of platforms, which often serve as clearinghouses of human indecency. Propaganda has thrived on Twitter, Google search results have elevated false breaking news stories, and Uber devised a controversial program called “greyball” to maneuver cars away from regulators trying to bust illegal ride-hailing. Most dramatically, a former executive at Facebook now claims the company is “ripping apart” society.

These scandals have not always damaged these companies’ utility or profit; while Uber’s valuation has declined, Facebook and Google’s stocks have grown dramatically. But they have pierced the prevailing techno-optimism by calling attention, again and again, to the same question: How can users trust platforms that are often no better than the worst of their users? That query has special resonance for families who are victims of today’s cyber scalpers. These high-tech scoundrels have scammed online retailers and turned the laissez faire rules of eBay’s platform against the interests of its shoppers. Like the Russian propagandists on Facebook and Twitter, the cyber scalpers succeeded, not by flouting their platforms rules, but by mastering them.

Bots and artificial intelligence have been hailed as the next great technological breakthrough. They populate a vision of a future where corporate bots replace customer-service agents and where personal AI assistants help people shop or manage household tasks, like Her, or, less creepily, Jarvis. In this future, bots serve as automators of tedium and toil, allowing companies and individuals to focus on what really matters to them.

But in the last 12 months, bots have been mastered by trolls and scam artists. They have automated the worst elements of human nature—the instinct to deceive, ridicule, and extort. Immediately after the first presidential debate last year, more than a third of pro-Trump tweets (and about a fifth of pro-Clinton tweets) came from bots. Facebook and Twitter were flooded with bots that, in mimicking the most obnoxious users, merely amplified the sites’ worst tendencies. These “bot-makers see an opportunity to exploit anonymity with a humanlike touch at an inhuman scale,” John Herrman wrote for The New York Times.

It is a perfect description for the Grinch bot programmers, as well. Scalping is an ancient practice. But cyber scalping allows these scammers to operate at an inhumanly vast scale and with inhuman speed, so that they can absorb the entire supply of popular toys at Walmart and Target’s websites.

Merriam-Webster’s word of the year is feminism—a worthy selection. But in economic circles, perhaps no term has been more emblematic of 2017 than the ubiquitous yet amorphous “late capitalism.”

The concept sounds vaguely Marxist. But it wasn’t coined by Karl Marx himself, according to William Clare Roberts, a political scientist at McGill University interviewed by The Atlantic’s Annie Lowrey. Rather, he said, the term came from Marxist acolytes alluding to the darkness that comes just before the dawn of socialism, the moment when “we see the ligaments of the international system that socialists will be able to seize and use.”

It’s hard to imagine a better advertisement for switching economic systems than anonymous scalpers ripping off well-intentioned parents in the name of free markets. But that’s essentially the attitude of the Grinch-bot coders and their ilk. Last year, two brothers bought a stockpile of Hatchimals—the it-toy of 2016—to force families to pay large markups to get the toy. It was like an analog version of the Grinch-bot scandal. Interviewed by Time magazine, the brothers were remorseless; in fact, they were proud. “We didn’t break any laws,” one brother, Mike Zappa, said. “And we aren’t dictating how the market is pricing the toys on eBay. What we are doing is capitalism at its best.”

It’s a shameless defense. But it’s not so different from the argument lurking in eBay’s corporate statement, which implies Grinch bots aren’t a scandal, because their behavior is technically legal. Indeed, that makes a fine summary for the worst storylines of the year, from politics to tech to business. Sometimes, the scandal is what’s permissible.



Bollea v. Gawker isn’t just one of the most consequential lawsuits in the history of modern American media. It’s also probably the strangest. In 2016, Hulk Hogan, the professional wrestler, won a nine-figure lawsuit that ultimately bankrupted Gawker Media, a fleet of sites that epitomized the barbed brilliance of New York’s young media crowd. The lawsuit concerned a video of Hogan (né Terry Gene Bollea) having consensual sex with his best friend’s wife, while that same friend recorded the encounter—secretly, according to Hogan and later reporting. Behind the scenes of this tawdry affair, a more shocking story was playing out, in which Peter Thiel, the billionaire investor, seemed to be exorcising a deep grudge against Gawker by bankrolling Hogan’s lawsuit to destroy the media company that published the sex tape.

This saga is the subject of a new book by the author and (controversial) media strategist Ryan Holiday, called Conspiracy: Peter Thiel, Hulk Hogan, Gawker, and the Anatomy of Intrigue. Shortly after the verdict, both Thiel and Gawker’s founder, Nick Denton, reached out to Holiday about his coverage of the lawsuit in the New York Observer. Over the next two years, Holiday turned that access into the first reported book that chronicles the lawsuit, from the offending blog post that sparked Thiel’s wrath to the aftermath of Gawker’s sale.

In the book’s biggest revelation, Holiday reports for the first time that a twentysomething acquaintance of Thiel’s, identified only as Mr. A, not only came up with the idea in April 2011—before the publication of the Hogan video—to target Gawker through an open-ended legal fund but also spearheaded the plot to take down Gawker using Thiel’s money.

I spoke to Holiday last week about the new information he’s uncovered, whether he thinks Gawker could have saved itself before the trial, and whether news reporters reflecting on Gawker’s demise should live in fear of upsetting rich people with their work. This interview has been edited and condensed for clarity.

Derek Thompson: On December 19, 2007, Gawker’s tech blog Valleywag published a post under the headline “Peter Thiel is totally gay, people,” ending with the sentence, “I think it's important to say this: Peter Thiel, the smartest VC in the world, is gay. More power to him.” Based on your conversations with Thiel, why do you think he’s so mad about this blog post, if most of his friends (and their friends) knew he was gay?

Ryan Holiday: My initial instinct was that it must have been pure anger. What was strange, though, is that in speaking to Peter Thiel, I never saw the anger. Of course, sources can present a mask. But I feel like I would have seen a flicker of it.

I think what happened was this: The article comes out, and it is a rude awakening for a private person. The article was legal, but it was also tasteless and deliberately insensitive. But what Peter reacts to the most is the comment on the bottom, which was written by Denton. [The comment is one sentence long: “The only thing that’s strange about Thiel’s sexuality: why on earth was he so paranoid about its discovery for so long?”] He thought Denton was implying that Peter had psychological problems. When you read the comment it doesn’t feel that way. But Thiel thought, here is the publisher of a media outlet, not just a blogger, going after me. That blog post felt like the first article in years of negative Gawker coverage against Thiel.

Thompson: Since Thiel’s war on Gawker bankrupted the company, that’s probably the most expensive internet comment in world history. I was really struck by your reporting that Thiel went around calling Gawker “the MBTO,” which stood for “Manhattan-Based Terrorist Organization.” Why did he feel terrorized?

Holiday: I think there is an element of unpredictability to it. Most of the media plays by certain rules. But Gawker wrote its own rules, and that scared certain powerful people. Outing was more or less off limits for most news outlets. So I think what kept Thiel and people like him up at night was: If they can out me, then what’s next? Will they publish a harmful rumor? Even a false rumor?

Thompson: Thiel ponders revenge for years. Then, as you report, in April 2011, he is in Berlin and he takes a dinner meeting with a then-26-year-old Thiel devotee, who you call Mr. A. This young man essentially tells Thiel, I know you’re obsessed with Gawker, and I have an idea to destroy them. He says Thiel should create a shell company to fund investigators and lawyers to find causes of action against Gawker and ultimately sue it into oblivion. He estimates that the plan will take up to five years and up to $10 million in funding, which is prophetic. What struck you most about Mr. A’s story?

Holiday: I was shocked by the very existence of Mr. A, this mysterious operative who put the plan in motion. Not only does nobody but me or the conspirators know his real name, but also nobody even realized that he exists. They don’t realize there was another senior-level person involved in the plot against Gawker. That’s fascinating for a story that has been reported so extensively for so many years.

I was also shocked that multiple people [who knew Mr. A’s identity] referred to him as a “professional son,” as Lyndon B. Johnson was sometimes called, for his ability to identify father figures in his life that would help his career. His secret strength was to understand what powerful people wanted to see in a protégé or lieutenant and to make himself into that person. Thiel was speaking about Gawker. He despaired that he couldn’t take on the media publisher. And Mr. A said, “Peter, if everyone thought that way, what would the world look like?”

I’m not sure there is a more perfectly tailored line for a person like Thiel, at that point in his life, to fund a project like this. At the time, Peter had figured out all the things that wouldn’t work. But he recognized the potential in Mr. A’s plan the way a venture capitalist recognizes a great idea. Here, he thought, I have the right person behind the right idea, and I’m going to support it.

Thompson: That brings us to Hulk Hogan, where the story takes a truly surreal turn. To summarize from your interviews and reading of the court documents: It’s 2006, a year before the blog post outing Peter Thiel is published. Hogan’s marriage is falling apart. A distraught Hogan is invited to go to the home of his best friend, a shock jock by the name of Bubba the Love Sponge. Bubba tells Hogan that he can have sex with his wife to cheer him up. Hogan asks if the sex will be taped. Bubba, lying, says no. Then Bubba leaves and secretly records Hogan having sex with his own wife.

In 2012, these tapes are leaked to Gawker, which publishes the video under the headline: “Even for a Minute, Watching Hulk Hogan Have Sex in a Canopy Bed is Not Safe For Work but Watch it Anyway.” Hogan is mortified and tells reporters that he’s going to sue for violation of privacy. News of this threat reaches Thiel’s legal team. They notify Hogan’s lawyers that they’re willing to bankroll a lawsuit against Gawker. And so, in October 2012, Hogan’s legal team files a lawsuit seeking damages of $100 million from Gawker Media for a handful of claims, including invasion of privacy, intentional infliction of emotional distress, and a violation of the Florida Security and Communications Act. Have I got that right?

Holiday: It’s even more unreal than that. Basically, Hogan had sex with his best friend’s wife. His friend kept those recordings in a desk by his radio station—that detail was verified by police reports. The Tampa Police and FBI both believed that a rival DJ broke into the desk and stole the videos. [Although police and FBI investigative notes revealed those suspicions, that DJ was never charged or convicted of any crime.] He started to leak the videos, not to embarrass Hogan, but to embarrass Bubba, whose time slot he was trying to steal. The speculation is that this entire series of events was triggered by a beef between two shock jocks in Florida. Gawker is a cat’s paw in an [alleged] extortion scheme. And Gawker was the only one punished for it. It is just so tragic and absurd.

Thompson: Now we get to the trial. I thought your book did a really great job of explaining how Hogan’s legal strategy so baffled Gawker’s lawyers, who seemed to gradually realize that they weren’t dealing with a rational legal strategy from a resource-constrained plaintiff.

Holiday: I read all 25,000 pages of legal documents from this case. That’s $2,000 dollars in printing costs. And what was so fascinating to me is that Gawker’s legal team doesn’t seem to take [Thiel’s strategy] into account at all. There is some reporting about Nick Denton growing suspicious about why Hogan wasn’t settling. [A legal analyst named] Dan Abrams published a piece, ”Might a Gawker Hater be Covering Hulk Hogan’s Legal Bills?”

If you’re fighting Hulk Hogan alone, you file motions and drag it out to be as painful as possible for Hogan, in the hopes that he’ll settle. But if you’re fighting a billionaire, what you do not do is try to drag out the trial as long as possible. That won’t work.

If Gawker suspected Thiel’s involvement, they should have publicly cast aspersions and even make a case to the jury that a billionaire was behind the whole thing. If you are being hounded by a billionaire, you want to make yourself as sympathetic as possible. But I suspect the Gawker team simply didn’t realize what was happening until it was too late.

Thompson: One thing I’ve always been so curious about is how did Nick Denton first begin to suspect that the Hogan trial was bankrolled by Peter Thiel?

Holiday: I don’t know. And he wouldn’t tell me. I suspect it was cumulative. Things added up. Thiel and Charles Harder [the lawyer paid by Thiel to pursue cases against Gawker] made a mistake by filing additional lawsuits as they were approaching trial and immediately after trial. It made it overwhelmingly suspicious that there was something else going on.

Denton always thought today’s rumor is tomorrow’s news, and it was particularly brilliant that Denton ran the Gawker playbook to expose the person behind the lawsuit. First he floated a rumor, saying maybe someone, and even someone from Silicon Valley, is funding Hulk Hogan. And then a few days later, Ryan Mac from Forbes broke the story that it was Peter Thiel. And then Thiel broke his silence in an interview with Andrew Ross Sorkin at The New York Times.

Thompson: Do you think Thiel could have avoided exposure entirely? Is there a way that his involvement might still be a secret?

Holiday: I don’t know how Ryan Mac from Forbes learned. He wouldn’t speak to me. But the circle of people who knew about Thiel’s plot was expanding to become a number too large to sustain by mid-2016. Peter had gotten so proud of what was happening that he was telling more people, which made his exposure inevitable. But, according to Charles Harder, even Harder did not know that Thiel was behind everything until the Forbes story broke. All Harder knew was he was working with Mr. A and an anonymous benefactor.

Thompson: You go to great lengths to demonstrate that Peter Thiel and Nick Denton are surprisingly alike—foreign-born, gay, entrepreneurial, libertarian in disposition, obsessed in their own way with the value of secrets. Their hostility in many ways seem like a narcissism of the small difference. If you could go back in time with Denton, how would you advise him to save his company?

Holiday: There was narcissism of the small difference. But their visions of the future were radically different. I’m not sure diplomacy could have worked even if they got in the same room with each other. From 2007 up until 2012, Denton was on a devil-may-care ride of breaking rules as a media publisher. And that was so diametrically opposed to Peter’s vision of quiet individuality, this belief that weirdos needed to be left alone if they were going to change the world. Peter saw that Gawker would punish people for that weirdness.

Thompson: In the book, you seem to side with Thiel over Denton and the plotters over Gawker. There is a section where you really seem to idolize Thiel and hold him up as a kind of hero conspirator. Am I wrong? Who did you find more persuasive?

Holiday: My intention was to take out as much judgment out as possible. One of the hardest things of writing the book, and I wrestle now even talking to you, is that the Nick Denton and A.J. Daulerio [Gawker’s editor in chief when the video was published] that I talked to in 2016 and 2017 were thoughtful and mature and circumspect about a lot of these issues. But it’s hard to find that same circumspection at Gawker in the events of 2007 to 2016.

There is a line from Mr. A [in the book] where he says the more they studied Gawker, the harder it was to find good. And when you look at some of these stories with the distance of time, it was extraordinarily difficult to find that sort of humanness and sympathy. There is a famous tweet where a Gawker writer says he wrote a story about the actor James Franco where he called him gay and a rapist.1 It was a toxic culture that spun out of control. And now that these writers are out of that culture, they’re sympathetic.

Thiel’s influence is scary and ominous. But what I found refreshing about it is the highly skilled competence. [The danger that readers will misunderstand the message of a book] is a worry for me personally because my first book, which was supposed to be an exposé of media manipulation, became quite popular with extremists that I don’t agree with. But the way Thiel took down Gawker is obviously a playbook to take down somebody like Donald Trump—a well-funded group of individuals probing for underlying weaknesses, doing the unpleasant and boring business of looking through the muck of old business dealings.

Thompson: I am much more sympathetic to Gawker in this case. I’m more nervous about the power of people like Thiel to silence the press and scared of juries’ power to determine newsworthiness and hand out $100 million punishments for true stories. As Tom Scocca, a former Gawker writer, put it, this is now “a country where a billionaire can put a publication out of business.”

Holiday: One of the things that’s most brilliant about Tom’s piece is that it sets into motion a lost cause mythology about Gawker. It recasts all sorts of things that Gawker did as rudeness or mere insensitivity. But Gawker Media had articles with leaked photos of female celebrities’ boobs. Those were real people on the other side of that article. That was a real violation of privacy.

That line from Tom redefines their past and redefines what happened. Denton was not extorted into shutting down the website. Gawker lost in a court of law in front of a jury and judge, for which they had numerous opportunities to push the verdict in another direction. But they lost the case in court as much as Thiel won it. There are many scary things this class of billionaires can do with their money. But meeting in open court about the illegal publication of a sex tape is not one of the scariest.



There were the hurricanes that rained down biblical floods on Texas and Florida and devastated Puerto Rico and the Virgin Islands. There were the fires that smoked wine country and coated Montana and Oregon in ash, and the fires that are burning down houses in Santa Barbara. Then, there were the king tides that flooded Miami, the heat waves that seared the southwest, the tornadoes that scarred the southeast, and the rains that never came in the Cascades. No wonder the National Oceanographic and Atmospheric Administration has deemed this to be the second most extreme year, weather-wise, in the past century.

That extreme weather has taken a devastating and unknowable human toll, on families from San Juan to San Francisco. And it has taken economic one as well. It now seems a near certainty that 2017 will be the most expensive year in American history in terms of natural disasters—and a preview of the trillions of dollars of costs related to climate change yet to come.  

The effect is perhaps clearest in terms of property damage, in the United States’ territories as well as in the states, with governments, insurers, and individuals counting up the losses from torn-apart homes, flooded cars, downed bridges, destroyed electrical grids, and shuttered hospitals. Early in the fall, Hurricane Maria devastated the island of Puerto Rico, which had already suffered a decade-long recession. The government there has asked for $95 billion to rebuild the electric grid, infrastructure, and homes, and the storm caused an estimated $85 billion in insured losses. The credit-rating agency Moody’s puts the estimate of the storm’s damage at $40 billion in lost economic output and $55 billion in property damage, in a region with a GDP of about $100 billion a year. The numbers are similarly devastating in the Virgin Islands, which were hit by Hurricane Irma.

Though Harvey and Irma did less catastrophic damage on the mainland, that damage was more costly because of the value of the homes, businesses, and public infrastructure there. “We’re going to have to rebuild everything,” Bonnie Stephenson, the mayor of the tiny town of Rose City, Texas, told me when I visited, with mold growing up the sides of homes and heaps of mucked-out garbage lining the streets, six weeks out. The whole town would have to be gutted, reframed, and rebuilt, like much of southwest Texas and western Florida. The government estimates the damages from the storms and floods at $131 billion.

Then, there were the wildfires that lit up a number of dry western states this year, and some of them continue to rage today. Fires in California alone have caused at least $9.4 billion in damages. “These numbers not only represent staggering losses to tens of thousands of Californians,” Dave Jones, the state’s insurance commissioner, said in a statement. “The October wildfires that devastated whole communities and tragically cost 44 people their lives have now proven to be the most destructive and deadliest in our state’s history.” That number is likely to prove a fractional  estimate, not taking into account the damages from the uncontained fires still alight in southern California and not accounting for uninsured losses.

All told, there were at least 15 weather events costing at least a billion dollars each in 2017, the second-most since 1980, the government estimates. To be fair, weather gets costlier over time because the value of America’s homes and businesses and the economy itself gets bigger over time, as noted by Roger Pielke Jr., a political scientist at the University of Colorado Boulder. Still, tallying up the damages, the winds, floods, and fires are likely to end up wiping away 0.2 or 0.3 percent of the nation’s wealth—causing as much of a hit in percentage terms, in other words, as the Great Chicago Fire of 1871 or the Great Mississippi Flood of 1927. This year really was different.

Another, related way of looking at the toll is in terms of the costs to the government to fight fires, move families, save stranded individuals, and rebuild. There are the significant direct costs for disaster relief, for one. Congress has provided more than $50 billion in emergency spending related to storms and floods, including emergency nutrition assistance for Puerto Rico, debt relief for the federal flood-insurance program, and new funds for the Federal Emergency Management Agency. The forest service has also spent $3 billion on firefighting, and state and local governments have committed similar sums.

But that does not fully capture the way that storms, fires, and droughts act as a drain on public resources. There is also the cost of cuts to other agencies to free up money for disasters, and the burden of increased spending on social insurance and safety-net programs, such as food stamps. Consider this analysis of the California fires—just one catastrophic event among many this year: “The cost to contain and fight the fire and deal with the aftermath will be in the billions,” wrote Joel N. Myers, the chairman of the forecasting firm AccuWeather. “The loss in tax revenue from businesses no longer around, including the vineyards; the workers who have lost their jobs and can no longer pay taxes as well as other impacts will be quite costly. This will create a hole in the California budget, which may necessitate an increase in taxes. If California has to borrow more this might negatively impact its bond ratings and it will have to pay higher interest rates on all borrowings.” He estimates the impact at $70 billion to $100 billion.

Despite the prevalence and devastation of storms like Katrina and Sandy and Maria, as well as fires and tornadoes and earthquakes, the government does not have a full accounting of the budget effect of extreme weather—nor a sense of how more-frequent and more-intense storms might tax public coffers in the years to come. “Little is known about the fiscal costs of natural disasters, especially regarding social safety nets,” writes Tatyana Deryugina, an economist at the University of Illinois. She notes “substantial” increases in unemployment insurance and medical costs for a full decade after a hurricane, with the government spending $780 to $1,150 more per capita on social insurance for every $155 to $160 it spent per person on disaster aid. “This implies, among other things, that the fiscal costs of natural disasters have been significantly underestimated,” she concludes.

Then, there is the cost to growth and jobs—those headline economic figures—where this year and in others there tends to be something of a yo-yo effect: A storm hits, or a fire strikes. Businesses close and stay closed. Families flee, and damage from water, wind, ash, and debris keeps them away for some time. Jobs and economic activity disappears. But soon after, the rebuilding starts. In Houston, for instance, the surge of activity caused by Hurricane Harvey was obvious when I visited. Volunteer crews were pulling down and replacing rotten siding. Families were restocking their cabinets and closets. Car dealerships were advertising deals. People were scavenging for metals and repairable goods in the debris. Lowe’s and Walmart were crowded with people who had lost something, or everything, and needed it replaced. “It has been crazy in here, crazy all the time,” a shift manager at a Home Depot in Beaumont, a coastal town west of Houston, told me. “Shop-Vacs, drywall, electrical, appliances.”

This surge in activity is financed, in part, with money pouring into a disaster area from insurers, volunteer groups, and the federal government. “FEMA has already filled hundreds of temporary positions to help rebuild communities impacted in Texas, Florida, Puerto Rico and the U.S. Virgin Islands,” wrote Rebecca Henderson, of the human-resources company Randstad Sourceright, in a research note. “Job openings for contingent talent have also spiked in the construction and hospitality sectors,” she continued, “and we expect to see similar demand from the engineering and environmental sectors.”

As such, the medium-term overall effect on GDP is often negligible, with a local economy slowing down to a halt and then speeding up again, and the national numbers rarely changing much. “Hurricanes Harvey, Irma, and Maria have devastated many communities, inflicting severe hardship,” the Federal Reserve said in a September statement. “Storm-related disruptions and rebuilding will affect economic activity in the near term, but past experience suggests that the storms are unlikely to materially alter the course of the national economy.”

But economists stress that GDP and jobs numbers are not necessarily a good way to capture the effect of extreme weather events—not this year, or any year, not for families and not for the government and not for the nation as a whole. “You’ve destroyed a bunch of housing stock and public buildings and disrupted for a short period of time people getting to work and dealing with tragedy, and then the rebuilding will start,” said Chris Varvares of the research firm Macroeconomic Advisers. “What you don’t measure is the welfare loss of what happened to people’s lives, their businesses, their pets, their photo albums. Part of the story is that GDP is perhaps not the best measure of the near-term impact of these storms, or the widening of the weather cycles.”

Natural disasters tend to have a disparate impact on the rich and the poor, for one, with not all families equally vulnerable to the terrible events and not all families equally capable of rebuilding. Studies have found that the rich and the poor are more likely than the middle class to live in flood zones, and are thus the most likely to be faced with property destruction and a mandate to try to rebuild. “Higher-income households often live in high-risk areas because of the aesthetic attributes of living next to water,” one study of flooding and income concludes. “Low-income households live in higher-risk areas than middle-income households in order to find affordable housing.” But the rich have greater capacity to flee a storm and to rebuild after it, given their likelihood of having insurance and their wealth. The poor, on the other hand, often get hit hard and struggle to recover. That seems true this year. Harvey has caused a spike in homelessness, and has hit the lowest-income communities the hardest. The Santa Rosa fires have been particularly devastating for people living in trailer parks and for migrant workers.

There is also the way in which natural disasters change the economic geography of a place, leading some families to flee and leaving others stuck. Higher-income residents of a given region tend to leave when devastation strikes, for instance. That might lead to higher earnings for them, but less economic vitality for the towns and cities that they left behind—something that seems a certainty in the case of Puerto Rico, with tens of thousands of people expected to relocate to Florida, New York, and elsewhere. “It is generally accepted among environmental geographers that there is no such thing as a natural disaster,” argues Neil Smith, an anthropologist and geographer at the City University of New York. “In every phase and aspect of a disaster—causes, vulnerability, preparedness, results and response, and reconstruction—the contours of disaster and the difference between who lives and who dies is to a greater or lesser extent a social calculus.” Who is exposed to storms, who is sheltered from tornadoes, who recovers from fires—all of these things are a matter of choice and public policy, in other words.

More broadly, catastrophic weather events change individuals’ and businesses’ economic decision-making—with a profound longer-term effect on the economy that is not always apparent in a jobs report or a GDP number. A family that lost its house might not be able to pay for a child to go to college. An entrepreneur might decide to retire early, rather than rebuilding. An insurer might decide to charge for more for building in a given region. Extreme weather, in some ways, acts as a tax on long-term economic vitality. “It affects people’s behavior and their investment decisions for many, many years, and that in turn affects economic growth,” says Solomon Hsiang, an economist at the University of California, Berkeley. “For the 10 years after a storm, there’s lower economic growth, in proportion to the intensity of the storm. It doesn’t show up as a huge spike, it’s much more like a gentle drift.” Part of the reason, he says, was that “people tend to shift their behavior away from things that look like investment, like education and health care, and tend to spend larger fraction of their earnings on things like consumption, things like food. Those are things they need in the short term, but don’t produce extra benefits in the long term.”

As hard as it might be to suss out the impact of extreme weather in 2017, yet harder is sussing out the impact of the changing climate, now and in the future—due to the difficulty of tying individual weather events to epochal changes like global warming, the inability of headline economic figures to capture the messy fullness of human life, and the inadequacy of the available data to measure changes in the natural and the economic world. “If people are giving you straight answers about this, they’re probably making it up,” Elizabeth Stanton, an economist at Global Development and Environment Institute at Tufts, told me when I asked her how much climate change had cost the U.S. in 2017. “I don’t think we can measure it, not at all. We’re missing vital information, and it’s impairing our ability to make decisions, decisions that are very important and very time-sensitive. It’s dangerous.”

But scientists have found a clear link between anthropogenic climate change and certain extreme weather events. Independent analyses have found that climate change intensified Harvey’s rainfall and has made similar storms wetter and more likely to occur, for instance. Hsiang and his co-authors have estimated that every degree Celsius the earth warms will cost the country more than a percentage point of GDP, worsening income inequality as well. If emissions are not contained, the climate effect would rival that of the Great Recession. Even those numbers are speculative and do not account for all the ways that a hotter planet might change human lives, researchers warn.

The country is pitching towards a more violent future, then, without a full sense of what storms, floods, and fires are costing it now and without a full sense of what is to come.



It has been a tumultuous year for Donald Trump, brimming with legal scandals and high-profile White House departures. But the president should give thanks this holiday season, because he is the recipient of an extraordinary present—an economy gift-wrapped and tied with a big, beautiful bow.

After a terrible recession and a slow recuperation, America’s economy is in a record-setting mood these days. The Dow has set an all-time high 70 times in 2017—once every five days—while the unemployment rate has neared an all-century low. Manufacturing confidence is higher than ever, and confidence among home builders has matched an all-century high. A yuletide glow illuminates even some of the darkest of corners of the economy: After a rough year for traditional retailers, holiday sales are projected to hit their highest level in three years.

Is this happening because of President Trump? Yes, according to President Trump.

“The reason our stock market is so successful is because of me—I’ve always been great with money,” Trump told reporters in November. “Virtually no President has accomplished what we have accomplished in the first 9 months, and [the] economy [is] roaring,” he said on Twitter. “At least we can all agree the economy is better under President Trump,” White House spokesperson Sarah Huckabee Sanders said, while also crediting job growth to a “Trump miracle.”

Like so many miracles, this is revisionist history. Even if Trump’s first 100 days had produced a bevy of new legislation, it typically takes about a year for policy to affect national economic statistics. But Trump’s first 100 days produced no major legislation, despite effectively unwinding Obama-era regulations for labor, environmental, and consumer protections. Instead, Trump is treating the U.S. economy the way he might treat the licensing of a fully built hotel: He has slapped his surname on the facade and shifted around the interior decor. But the foundation, scaffolding, and architecture of the thing either preexisted his term or are beyond his control.

Consider the stock market, whose performance in 2017 has been pretty remarkable. The Dow has added 5,000 points in a calendar year for the first time ever. And, to Trump’s credit, he’s probably responsible for some of those gains. Corporations have benefited from the president’s emphasis on tax cuts and deregulation. Indeed, corporate tax reform will increase profits, especially for large telecoms, large banks, and retailers. There is also evidence of Trump’s policies helping specific sectors. For-profit prisons and for-profit colleges—both of which were targeted by the Obama administration—soared after the election of President Trump and have since outperformed the rallying stock market.

But the overall rise in equity prices is part of a long, steady bull market. The S&P 500 has grown by about 20 percent under Trump. That’s great, but it’s actually less than the one-year increase in 2009 (26 percent) or, to pick a year that wasn’t starting from rock bottom, 2013 (32 percent) under Obama. What’s more, the U.S. stock market has actually done worse than most of the developed world in 2017. As a percent change in dollars, the U.S. has lagged behind the stock indices of France, Germany, Greece, Italy, Spain, Japan, China, India, Singapore, South Korea, Taiwan, Argentina, and Chile.

The most important reason for this global boomlet is somewhat boring: After eight years of central banks printing money to help businesses and companies recover from the global financial crisis, the entire world finally seems to be growing. Global trade in 2017—which has little to do with White House policy—has grown at its fastest pace in the last five years. “The percentage of countries in major expansion mode is about as good as it can get,” Michael Cembalest, the chairman of market and investment strategy at JP Morgan, told me. In short: With or without Trump, there would be a historic rally in U.S. stock prices, because American multinational corporations (which make almost half of their revenue from overseas) are enjoying a rare moment of nearly universal worldwide growth.

What about a Trump miracle for blue-collar workers? Trump promised “to restore manufacturing in the United States” during the campaign. And voila, manufacturing employment had its best year since 2014, with the unemployment rate in steel manufacturing declining to 1.4 percent (not a typo). Trump also promised to revive the mining industry during the campaign. Indeed, after declining for several years, mining jobs have suddenly rebounded under Trump, another ostensible victory for White House policy.

But upon closer examination, these aren’t Trump miracles. They’re part of a worldwide economic story that is affecting the U.S., because the U.S. is part of the world. The dollar has fallen 10 percent since December 2016—a gift for U.S. exporters—thanks to higher growth in Europe and the appreciation of the euro. Meanwhile, factories are on fire just about everywhere. By one measure, global manufacturing has surged higher than global services, a rare feat for an expanding global economy, and one that has nothing to do with the president.

Interesting chart. Global manufacturing PMI now above services PMI, which is fairly unusual. pic.twitter.com/yDu2iNmgYo



There is anecdotal evidence that some mining companies were encouraged by Trump’s rhetoric and deregulatory policies. But far more importantly, the global recovery has led to a global energy boom, particularly due to demand from China. The price of coal doubled in the first nine months of 2016. This has created new demand for mining contractors in western Texas and the swath of the country running from Utah through Wyoming into Montana and North Dakota. These contractors, working in what the Bureau of Labor Statistics calls “support activities,” have accounted for almost all the mining sector’s job growth.

The common theme to these stories of markets, manufacturing, and mining is that economics tends to be driven by faceless forces rather than the familiar face in the Oval Office. It’s generally fanciful to think that the commander-in-chief has a magical ability to control the economy, for good or bad. (The major exceptions to this rule are during crises, like the Great Depression and Great Recession, when immediate government spending is critical.) The 1980s recovery is often credited to Ronald Reagan. But now, some of his strongest supporters acknowledge that the key factor was the fact that the Fed loosened monetary policy in the early 1980s. On the Democratic side, the economy didn’t take off in the 1990s just because Bill Clinton found the perfect marginal tax rate. Rather, he presided over the integration of the internet into the services economy, which coincided with the large Baby Boomer generation entering its peak earnings years. This combination probably would have led to a productivity boom under almost any president.

Claiming individual credit for global phenomena is a risky long-term strategy for any president. If the price of energy plummets, the White House will find that the Trump miracle will end, through no fault of Trump. Between 2010 and 2014, Obama presided over a 30 percent boom in mining jobs, thanks to a burst in energy demand and a fracking revolution whose technology was decades in the making. Two years later, all of that net job growth had disappeared, as the global price for natural gas plummeted. Obama wasn’t the captain of the global market for energy; he was merely a powerful bystander. That’s just how it is: The president depends on the economy far more than the economy depends on the president.



When it comes to cities and urbanization, it is generally thought that bigger is better. But a pair of recent studies suggests that although industrialized nations may have benefited from larger cities, the same is not true for the rapidly urbanizing areas of the developing world. In these parts of the globe, there really might be such a thing as too much urbanization, too quickly.

The studies, by Susanne A. Frick and Andrés Rodríguez-Pose of the London School of Economics, take a close look at the connection between city size and nationwide economic performance. Their initial study, from last year, examines the relationship between economic development, as measured by GDP per capita, and average metropolitan-area size in 114 countries across the world between 1960 and 2010. To ensure robustness, the study controls for variables including national population size, physical land area, education levels, economic openness, and other factors.

Average City Size of High-Income and Developing Countries (in Thousands)

The size of cities or metro areas across the world has exploded over the past half-century, with cities in the developing world growing much faster and much larger than those in more developed nations. Between 1960 and 2010, the median city in high-income countries grew modestly from 500,000 to 650,000 people; but the median city in the developing world nearly quadrupled, expanding from 220,000 to 845,000 people. In 1960, 12 of the top 20 countries with the largest average city size were high-income countries; by 2010, 14 of the top 20 were in the developing world.

Urbanization has historically been thought of as a necessary feature of economic development and growth, but this study finds the connection is not so simple. While advanced nations benefit from having larger cities, developing nations do not. Advanced nations experience a 0.7 percent increase in economic growth for every additional 100,000 in average population among its large cities over a five-year period. But for developing nations, the addition of 100,000 people in large cities is associated with a 2.3 percent decrease in economic growth over a five-year period.

In their latest study, the researchers found that developing nations tend to get a bigger bang for their buck from smaller and medium-size cities. These countries see the most economic benefit from having a larger proportion of their urban population living in cities of 500,000 people or less. Bigger cities tend to have a more positive economic impact in larger countries. Having a metro with more than 10 million inhabitants produces a nationwide economic benefit only if the total urban population is 28.5 million or more, according to the study. This makes sense: Bigger, more developed countries are more likely to play host to knowledge-based industries that require urban agglomeration economies.

As I’ve written before, there are several reasons why megacities often fail to spur significant growth in rapidly urbanizing parts of the world. For one, the lion’s share of places that are urbanizing most rapidly today are in the poorest and least-developed parts of the world; a century ago, it was the richest and most developed places. This history has created a false expectation that urbanization is always associated with prosperity. Also, a good deal of urbanization today comes from massive migrations of people escaping wars, civil conflicts, or natural disasters, rather than from purely economic forces like increased demand for labor.

Additionally, globalization has severed the historical connection between cities, local agriculture, and local industry that powered the more balanced urban economic development of the past. In today’s globally interconnected economy, the raw materials that flowed from the surrounding countryside to the city can all be inexpensively imported from other parts of the world. The result is that the connection between large cities and growth has now become much more tenuous, producing a troubling new pattern of “urbanization without growth.”

That said, urbanization is still essential for developing countries, and cities remain the key drivers of their economic growth. My own analysis of the urban-productivity ratios of global cities shows that the cities of the developing world have far higher ratios than those of the advanced nations. In other words, developing cities, on a relative basis, are much more productive than the surrounding areas.

Developing countries surely need cities, but not necessarily megacities. This study upends a core assumption of economic and urban theory: that bigger cities are necessarily better. While this tends to be true in more-advanced nations, where innovative knowledge economies benefit from density and clustering, it is not the case in the developing and rapidly urbanizing world, where having a broad range of smaller and medium-size cities adds more to economic growth.

This study serves as yet another reminder that there is no one-size-fits-all pattern for urban and economic development.

This post appears courtesy of CityLab.



GLENDORA, California—In retrospect, refinancing their home was a bad idea. But the Santillan family never thought that it would lead them to foreclosure, or that they’d spend years bouncing among hotels and living in their car. The parents, Karina and Juan, never thought it would force three of their four children to leave the schools they’d been attending and take classes online, or require them to postpone college and their careers for years. They did not know they would still be recovering financially today, in 2017. “Having lived through everything I see life differently now,” Karina Santillan, who is now 47, told me. “I’m more cautious—I probably think through financial decisions three, four, five times.”

The Great Recession Is Still With Us

In the big picture, the U.S. economy has recovered from the Great Recession, which officially began a decade ago, in December of 2007. The current unemployment rate of 4.4 percent is lower than it was before the recession started, and there are more jobs in the economy than there were then (though the population is also bigger). But for some, the recession and its consequences are neverending, felt most strongly by families like the Santillans who lost jobs and homes. Understanding what these families have experienced, and why recovery has been so evasive, is key to assessing the economic risks the nation faces. Despite ever-sunnier economic conditions overall, the Great Recession is still rattling American families. When the next economic crisis hits, the losses could be even more profound. “There are people who still, to this day, are trying to get back on their feet,” Mark Zandi, the chief economist of Moody’s Analytics, told me. “These households are slowly finding their way back, but they’re still on a journey.”

Their struggles are present in the economic data, if you look closely enough. The labor-force participation rate, which measures the share of working-age adults who either have jobs or are looking for them, fell sharply during the recession, and remains at a decades-long low, at 62 percent. Lower-income families aren’t just not doing better; they are actually doing worse: The average household income of the bottom 20 percent of Americans fell $571 between 2006 and 2016, according to Census data, while for the top 20 percent of Americans it grew by $13,749.

The housing market, too, has not fully recovered from the recession. Although population growth means there are 8 million more households in the country than there were in 2006, there now are 400,000 fewer homeowners. Before the recession, the homeownership rate in the United States was 69 percent, according to the Federal Reserve. Now, it’s 63 percent. A drop of six percentage points may seem small, but it represents a tremendous amount of pain and suffering for the millions of families who once had homes and no longer do. These are all families, like the Santillans, who saw the money they had accumulated disappear, who saw their credit scores ruined, who have not caught back up to where they once were.

Perhaps worse, millions of families like the Santillans essentially put their lives on hold for years during the recession, figuring out how to survive rather than how to thrive. The foreclosure crisis and subsequent recession didn’t just deplete families’ wealth—the instability it caused also meant that families like the Santillans lost out on years of productive economic activity. For example, the family’s oldest son, whom they call Juanito to distinguish him from his father of the same name, graduated from high school in 2009, the year the family lost their home. His grades suffered as he watched his family struggle to hold on financially, and though he wanted to attend college, he knew the family couldn’t afford it. This year, Juanito, who is now 27, finally enrolled in the film school he had wanted to attend in 2009.

A foreclosure is a one-time event, but for many families it’s something that never ends, wrecking years of their lives and the hopes they once had. The story of the Santillans’ foreclosure illustrates the way that the recession changed the American economy, and for millions of Americans, forever changed their lives. Some nine million families lost their homes to foreclosure or short sale between 2006 and 2014. But many lost more than that: They lost their momentum, too. Families like the Santillans had been moving up a ladder towards the American Dream, and fell off into a deep pit. They’re still at the bottom of the ladder a decade later, trying to get back to where they had been.

Karina and Juan Santillan bought their home, a single-story bungalow in West Covina, 20 miles east of Los Angeles, for $152,000 in 1999. Juan, the solemn patriarch who feels more comfortable conversing in Spanish than English, had worked for two decades at an ink manufacturing plant in Commerce, California; Karina, who has a heart-shaped face and a strong faith in God, sold insurance. For a few years, everything was going well—their finances were stable enough that they put their two older sons, Juanito and Isaac, two lanky and talkative all-American kids, in private school.

A few years after they bought their home, the Santillans say, people started knocking on their door selling financial products. It was easy money, the Santillans were told. Borrow against your house, it’s sure to gain value. The Santillans refinanced their home in 2003, taking out an adjustable rate mortgage, which opened them up to the instability of changing interest rates. Records show they took out an additional mortgage in 2004, but Karina says she has no recollection of taking out a second mortgage. They refinanced again in 2004. They used the money to remodel their home, which they figured would give it more value. As housing prices in the region soared, they refinanced one more time, in 2005, borrowing $396,000 from New Century Financial Corp., which would itself file for bankruptcy two years later. At the time, their house worth less than $300,000, according to Zillow.

In retrospect, they didn’t look closely enough at the terms of the paperwork they were signing, they say now. They didn’t realize how much the amount they owed each month could change suddenly, depending on interest rates. Before they refinanced their home, their monthly payment was $1,200. By the time they lost their home, the payments had risen to $3,000. They contacted a company that said it would be able to save their home, and paid the company $6,800, only to lose their home anyway. (The proprietor of that company, Jose Casares, lost his license to practice business in California in 2012 as a result of a lawsuit against his company, court records show. “It is the Lord who will avenge us from your lies,” Karina wrote to him in an email in 2009. Casares did not respond to a request for comment.)

The payments would have been high even if both Karina and Juan had been working full-time. But Karina’s work selling insurance dried up as the housing bubble burst in 2007. Then the ink manufacturing company where Juan worked cut everyone’s pay 10 percent. They first fell behind on payments beginning in 2007, and received an eviction notice in early 2009. To keep their home, they would have had to pay $447,431. They moved out of their home on June 29, 2009, when their children were 10, 13, 16, and 18.

Their story is not unlike many of those who lost their homes during the recession. The foreclosure crisis was particularly concentrated among black and Latino families, who were targeted by high-cost lenders. One study found that Latino families were 78 percent more likely and African American families were 105 percent more likely than white borrowers to have high-cost mortgages. Many of these families were first-time homeowners who wanted desperately to own a house, and had limited access to more-traditional financial products.

These families tended to be more vulnerable than other middle-class families in the economy—as first-time homeowners, they had less savings, less education, and fewer connections than families who had owned homes for decades and accumulated wealth through real estate. Because of these disadvantages, and because of the variable nature of their loans, these families were more likely to fall behind on payments than higher-income borrowers with more-stable loans.

A foreclosure set them back them even further. Academic studies point to the many negatives associated with foreclosure: Families in foreclosure have more frequent emergency-room visits and worse mental-health outcomes. Their children do worse in school and have higher truancy rates. They are more likely than other families to rely on the social safety net. Losing a home can also mean becoming disconnected from the community where you lived, and the connections that might have helped you find a new job or get a loan, Roberto Quercia, the director of the Center for Community Capital at the University of North Carolina at Chapel Hill, told me. It’s for these reasons that many of those families are still struggling today. White families had largely recovered financially from the Great Recession by 2013, according to the Federal Reserve, while even today, the median income for black and Latino households has still not reached 2007 levels.

For the Santillans, the instability associated with foreclosure has lasted for years. After renting an apartment for a few months and then bouncing around at the homes of friends and family, they checked into a motel for a few nights so they wouldn’t have to keep asking family for help. They thought it would be a brief stay, but they ended up staying in various hotels like the Red Roof Inn and the GuestHouse Inn for the next two and a half years. All six of them would pile into one room, with two of the boys sleeping on the floor and everyone vying for bathroom time. They could rarely stay at a hotel longer than 28 days—many establishments have time limits—and so would have to pack up their bags every few weeks and find a new place to live. “I think the worst part of it was not having your privacy, your own room, we all had to share one big room,” Karina told me. “And not having a place to call home during Christmas.”

The Santillans had to stay in hotels because their credit was so bad from the foreclosure that landlords wouldn’t rent to them. The conventional wisdom is that a foreclosure will ruin your credit for a few years, but often the damage can last much longer. In many cases, these are families who, prior to the foreclosure, had income that varied from month to month. They sometimes took out loans or borrowed against their homes to smooth over that unpredictability. But going through a foreclosure shuts off those other avenues of credit at the same time these families are losing all the equity they put into their homes. “It makes it really hard to get back on your feet,” Laurie Goodman, co-director of the Housing Finance Policy Center at the Urban Institute, told me. “It’s incredible how long it actually takes families to recover.” For example, 52 percent of the consumers against whom foreclosures were filed in 2005 still have VantageScore credit scores below 620 in 2015, she said.

Staying in hotels led to even more turmoil. Because the family chose hotels close to Juan’s workplace, they were far from the West Covina school district, and Karina was worried that if she told the school district they were homeless, her children would be taken away. So the three youngest children left the schools they’d been attending and enrolled in an online school. They did their school work in hotel rooms or in Starbucks, where they could reliably get free WiFi. The children were prohibited from telling their extended family or friends what was going on, and their friendships slowly eroded as they tired of evading questions about where they were living and why their friends couldn’t come over. “We started to get isolated from everybody, and ended up becoming a little island,” Juanito told me.

Few of the hotel rooms had kitchens, so the family would split fast-food value meals from McDonald’s. To save money, Karina gave up her cell phone, which made it difficult for potential employers to contact her. To make matters worse, they had missed a tax payment around the time they lost their home, and found out in 2011 that they owed back taxes to the IRS. The government garnished Juan’s already meager wages for about nine months.

Having only one car, which Juan needed to get to work, meant that the rest of the family would be stranded for the day in whatever hotel they were staying. This meant interacting with shady characters very different from the neighbors they’d lived next to for years. One drunken man pounded on their door in the middle of the night, certain that Juanito had been talking to his daughter. Someone else stole their license plate right off of their car in a hotel parking lot. Two times, police looking for a different Hispanic middle-aged man put Juan in handcuffs until they could confirm he wasn’t the man they were seeking. When money got really tight, the family camped in the mountains above Los Angeles.

Perhaps hardest was watching as family and friends went on with their lives, while the Santillans’ lives felt essentially paused. Isaac, the second-oldest, for example, had to stop attending school his senior year and take online classes, watching while his friends made senior-year memories, graduated, and went onto college. “If I let it, it could bring me down, me not graduating high school or college and them going to their careers,” Isaac, who is now 25, told me. He applied for more than 100 jobs during the time the family was homeless, at places like Walmart and Taco Bell, but got none of them. He had dreams of being a personal trainer or working in fitness, but had to put them aside. In the course of a few years, he went from a normal teenager worrying about grades and sports to an adult isolated from all his friends and concerned with how to help keep his family afloat. He dealt with things that had been unimaginable, somehow contracting Hepatitis C and then recovering, his skin tinted yellow, in a shared queen-sized bed in a Red Roof Inn.

The end of their nightmare came slowly.

Karina finally found a full-time job in October of 2013. For one of her initial job interviews, the family was so low on money that they had slept overnight in their Chevy Suburban, and Karina freshened up in a McDonald’s bathroom before the interview. She began selling auto insurance, and then, when health-care exchanges were launched in late 2013 under the Affordable Care Act, she also began selling Obamacare plans. She encouraged her three oldest children, none of whom was working at the time, to get trained to sell Obamacare, and they studied together in hotel rooms, eventually passing the test to become insurance brokers.

By the fall of 2014, Karina, Juanito, Isaac, and Giovanni were all working selling Obamacare, and the family’s finances had stabilized. They started looking again for apartments, and in October of 2014, they finally found a small single-family rental in Glendora, not far from their old home. They were so excited to finally have a place of their own that the first night they got the keys, they slept on the hardwood floors on blankets, rather than in a hotel room with a bed. They’d sold all their furniture years ago. Moving into a place where they had a kitchen and some privacy was an almost indescribable relief. Karina posted pictures of scrambled eggs she made on Facebook, puzzling friends who didn’t know that the family had been homeless for two and a half years, because being able to cook in her own kitchen again filled her with joy.

Karina started a business in 2015, Branch Network Insurance Solutions, and all three boys work there now, selling insurance. The business is doing well, and the Santillans say that the ordeal made their family stronger and bolstered their faith in God. Because of their faith, they feel like everything happens for a reason.

But they’re still not back to where they were before they lost their home. Had they not lost their home, it’s possible that Juanito would be finished with film school and in a career, rather than just starting school; that Isaac would be working in the fitness industry, rather than selling insurance; that any of the three boys would be living on their own, rather than still sharing a house with their parents.

The fate of Juan’s sister’s family, who lived a few blocks from the Santillans in West Covina, put this fact into sharp relief. That family did not lose their home, and their children, who are the same age as Isaac and Juanito, graduated from high school and went onto college. One of their children is now a registered nurse. The other is about to finish college. By contrast, none of the Santillan children yet have a postsecondary degree.

The economy continues to be shaped by the experiences of the millions of Americans who, like the Santillans, made little economic progress for years. People who entered the labor market for the first time during the recession—like Juanito and Isaac and millions of other Millennials— made lower wages and were less able to save money than previous generations. These earnings reduction can last up to 15 years. “The entire Millennial generation has suffered to some degree,” Zandi, of Moody’s, told me. “They’re stunted in their financial and economic development.” Young people from lower-income families who had an especially hard time finding good, steady jobs, a recent study found.

It’s not just Millennials who lost ground during the recession. Anyone who was unemployed for a long period of time during those years—around 8 million people lost their jobs then—may never get back to where they were before losing work, Till von Wachter, an economics professor at UCLA, told me. There weren’t as many good jobs created after the recession, and some people’s skills atrophied during their unemployment.

The Santillans are now just happy to be living in a home, rather than in a hotel. They’re working on their credit and now meticulously document their finances and stay on a budget. “We don’t splurge too much because you don’t know what tomorrow will hold,” Karina told me. Juan’s company only returned his pay to where it had been before the recession this year.

They have thought about trying to buy a home again—they’re spending much more on rent than they would like to—but after going through their ordeal, they’re very cautious. This, too, is not unusual. Going through a foreclosure often makes people less likely to want to be homeowners again. Ken Rosen, the chair of the Fisher Center for Real Estate and Urban Economics at Berkeley, calls this “post-foreclosure stress syndrome.”

According to his data, Millennials like Juanito and Isaac in particular are not buying homes at the rate people their age once did. Among 30-to-34-year-olds, the homeownership rate, at 45.9 percent, is 11.5 percentage points lower than the peak rate for that same age group, which was in 2004. Among 25-to-29-year-olds, the homeownership rate, at 32.7 percent, is 9.1 percent lower than the peak rate in 2006. This could be because people in this age group have post-foreclosure stress syndrome and don’t want to buy homes, or just because they weren’t able to acquire the wealth that they might have been able to acquire in the absence of going through a foreclosure.

This has negative implications for the economy, too: Had the pace of homebuilding returned to a more historically normal level, there would have been $300 billion more in the U.S. economy last year, boosting the gross domestic product by 1.8 percent, according to Rosen. “The failure of the housing sector to recover is the main reason we have subpar economic growth,” Rosen told me. There are, of course, many other reasons the economy is still sluggish: Household net worth dropped by 18 percent during the recession, there are more low-wage, insecure jobs than ever before, and the recession may have accelerated the automation that has replaced many once-stable jobs. But the foreclosure crisis and resulting instability for millions of families also played a big role. The brittle state of these families’ finances, and consequentially, of the current economy—means that the country is much less prepared to weather another recession, when it inevitably comes.

The Santillans try not to go through those what-ifs, and say it’s not worth it to obsess over what would have happened if they had never refinanced their home, or if Karina’s work hadn’t dried up, or Juan’s wages had remained constant. Maybe they would have been able to build more wealth through homeownership, or send their kids to college, or allow their children to build enough savings to feel comfortable marrying and having their own kids. Thinking about how they are still economically behind where they were a decade ago doesn’t do much good, they say.

But they learned what many American families did during the financial crisis—that while America prides itself on being a place where people can climb up the economic ladder, it’s also a place where people can fall fast, and far. “We just can’t forget, that in any given moment, things can change,” Karina told me. This has implications beyond the fates of these individual families. The American economy thrives when people are in the jobs they want, being as productive as they can, and when they feel financially stable enough to make purchases that will raise their standard of living. The aftermath of the foreclosure crisis and recession means that many families have not felt secure like that in a long time.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

At least 2,000 children have now been forcibly separated from their parents by the United States government. Their stories are wrenching. Antar Davidson, a former youth-care worker at an Arizona shelter, described to the Los Angeles Times children “huddled together, tears streaming down their faces,” because they believed that their parents were dead. Natalia Cornelio, an attorney with the Texas Human Rights Project, told CNN about a Honduran mother whose child had been ripped away from her while she was breastfeeding. “Inside an old warehouse in South Texas, hundreds of children wait in a series of cages created by metal fencing,” the Associated Press reported. “One cage had 20 children inside.”

On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.

About 65 million years ago, shortly after the time of the dinosaurs, a new critter popped up on the evolutionary scene. This “scampering animal,” as researchers described it, was likely small, ate bugs, and had a furry tail. It looked, according to artistic renderings, like an especially aggressive New York City rat. And it had a placenta, an organ that grows deep into the maternal body in order to nourish the fetus during pregnancy.

The rodentlike thing would become the common ancestor of the world’s placental mammals, with descendants that include whales, bats, dogs, and humans, among many other species. And today, the placenta might hold the key to one of the most enduring mysteries in human medicine: Why do women suffer much higher rates of autoimmune disease than men do?

Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

There’s a moment about 15 minutes into the first episode of Years and Years that made me gasp at its audacity, its prescience, its visual horror. The new six-part series from the British writer Russell T. Davies (Doctor Who, A Very English Scandal) charts the life of the Lyons family over the course of 15 years, starting in 2019 and ending in 2034. It’s a kitchen-sink saga that barrels its way through births and marriages and betrayals, but also through the near-future. In 2024, Stephen Lyons (played by Rory Kinnear), a financial adviser, is at home with his wife, Celeste (T’nia Miller), both rushing their way through the morning routine. When the camera turns to their teenage daughter Bethany (Lydia West), her face isn’t recognizably human. Instead, she looks like a 3-D version of a Snapchat puppy, with vast cartoon eyes, wagging pink ears, and a brown snout. When she talks, her voice is grotesquely distorted, a robotic hallucination of a child’s cadence. “I might have to start limiting filter time,” Celeste says in the same exasperated, noncommittal way that you might think, I really should spend less time on Twitter.



Editor's Note: This article is part of Exit Interview, a series of conversations about leaving one’s career.

Like many theater rats, the actress Delissa Reynolds had juggled auditions with an on-and-off office job, “daylighting” as a temp at Citibank. She had some success as an actor, even landing two roles on Law and Order. But by 2002, Reynolds faced a reckoning in a field notoriously challenging for anyone who dares to age, particularly women. “I was 40, and did not want to be a 50-year-old temp,” she said.

9/11, still fresh in New Yorkers’ minds, had already led her to question how she could be more involved in her community. “So, while I figured out what’s next, I supported the firefighters because they had lost quite a few of their guys,” she said. “Once a week, I’d host a dinner. It was just beans and rice and boxed wine. And I was like, ‘Wouldn’t it be fantastic to have something like these gatherings, but in a bigger space?’” That idea became Bar Sepia, one of a few small businesses that helped build a vibrant block in a then-rough part of Prospect Heights, Brooklyn—before a wave of development gentrified the neighborhood, and a new landlord decided to sell the building where her business was located. Earlier this year, her bar closed.

As an African American woman, Reynolds was at the forefront of one of the fastest-growing groups of entrepreneurs in America—but her experience also showed her how banks, funders, and developers need to repeatedly invest to ensure those entrepreneurs’ businesses survive. I spoke with Reynolds for The Atlantic’s series Exit Interview to learn about what it feels like pour yourself into a business and run it with integrity. The conversation that follows has been edited for length and clarity.

Catie Lazarus: Walk me through how you opened the bar. How’d you make the transition and get banks to underwrite you?

Delissa Reynolds: My boss at Citibank helped. I got a lot of support in how I presented my proposal and business plan. I’m so grateful to everyone who supported me.

It took time. I did a lot of homework to support the idea that a neighborhood meeting place would be of value when I put together my business plan. I knew the median income, how many kids went to public school, and how many families owned their homes—and [this area has] one of the highest rates of minority private-home ownership in New York. So, I went to a couple banks and I got turned down.

Eventually, I bought an apartment down the block, turned that around to use as collateral to get a loan, went to a community bank, and they gave me an SBA [Small Business Administration] loan to open the bar.

Lazarus: How many people did you employ?

Reynolds: Anywhere from six to 12 people. We struggled every day to make sure our bills were paid on time and cover our staff. You make do; you just don’t pay yourself.

Lazarus: Ironically, your bar, plus affordable rents and access to the subway, was pivotal in making this location enticing to developers, buyers, and renters, many of whom may not have known or cared what the neighborhood was like 20 years ago.

Reynolds: When I first moved here, people wouldn’t visit. I couldn’t order a pizza or any deliveries on certain streets because the delivery people got robbed.

Lazarus: But your bar kept drawing a diverse crowd even while the neighborhood gentrified.

Reynolds: People don’t realize how diverse this neighborhood really was culturally, socially, economically—artists, actors, Caribbean and African American, white. Our client base was that cross-section, and it’s shifted a lot, but, for the most part, it’s always been a 23-to-91 age range, and everything in between.

When I’d started to notice the shift in demographics, I didn’t want to sit on the sideline and be marginalized. I didn’t want to be excluded from this neighborhood’s evolution.

My neighbors and I turned around a pretty desolate block, in what was considered one of the worst neighborhoods in the nation, and created a point of reference for others to come. It’s now a prime location. Why shouldn’t I benefit from it? Why should somebody else? So, it’s a question of ownership and who deserves ownership.

Lazarus: Your bar was more of a local favorite than a bougie or hipster joint, but it also wasn't a dive bar. Did your bar shutter because you couldn’t compete with the onslaught of upscale new bars or due to other financial issues?

Reynolds: No. We had a good year. I couldn’t get a mortgage [preapproved] in time [to buy the building, and by then it was under contract with someone else].

Lazarus: Why do you think it was so challenging to secure a mortgage?

Reynolds: It was baffling. My credit is excellent. My husband’s credit is excellent. I own two properties—my apartment down the block and a place upstate.

Lazarus: Are there other factors which might have made securing financing challenging?

Reynolds: You do the math. Put two and two together—and look at my face. It took two years to get the money. It wasn’t until right after we were closing that I finally got [preapproved for] a mortgage. Now the building is in contract with somebody else. So, everything I’ve worked for this for a decade and a half is now nonexistent.

Lazarus: I imagine it’s raw. Would you share what it’s like for you?

Reynolds: It’s surreal. It feels terrible. Don’t get me wrong, I am grateful to have formed relationships that I will have for the rest of my life. I have grown as a human being and as a business owner. I am grateful for the gifts you can’t name.

Lazarus: How will you and your husband survive now?

Reynolds: We’re prudent. We don’t go on vacation. I don’t go out to eat a lot because I’m a really good cook. My average day running the bar was 14 hours. I’m up by 5:30 every morning, and in this office until eight or nine at night, and that’s if I’m not in the bar until 2 or 3 a.m., or whatever.

Lazarus: Are there things you won’t miss?

Reynolds: Yeah—everything breaking down on a Friday night. I won’t miss trying to explain to someone that they’ve had enough, and I just want them to get home safely. I won’t miss the stress you experience being responsible for your employees’ lives. You are the bread-and-butter account that feeds your employees.

Lazarus: What will you miss?

Reynolds: Everything—even the bad. It’ll take me a while to walk down the block. I’m resilient, but it's a loss, not only for my livelihood, it’s a loss for the neighborhood’s community.

Lazarus: When your bar was about to close, customers started a GoFundMe page, a #SaveBarSepia campaign, and a rally. Can you talk about the ethos behind that sort of customer loyalty?

Reynolds: You have to fight for your financial and moral integrity, in how you run a business and how you treat people and, every day, getting up, you fight for it. I am navigating the bar’s closing with the same integrity and grace with which I opened and maintained it.

And it also depends on what your idea of success is. We were incredibly successful in creating a place where everyone felt immediately welcomed. We were not a dive bar. We were a neighborhood bar. I was successful in having my day-to-day work also parallel my values.

Lazarus: You live a block away from where you worked, so it’s harder to walk away.

Reynolds: I’m processing it every single day. Your heart breaks, so you have to remind yourself that you did good. I’m allowing myself to feel every single emotion. You can’t give so much to something and then all of a sudden that's gone. I’m human. I’m not bitter. I’m not angry. I’m motivated. I’m hopeful, excited for what comes. That’s just part of my DNA.



In April, officials in New York City decided to move the “Fearless Girl,” the statue commissioned by a financial firm to stare down the Charging Bull of Wall Street, in what became a symbol of female grit, to a spot outside the New York Stock Exchange. Just over a month later, the NYSE announced that Stacey Cunningham, the exchange’s chief operating officer, will soon become its president—the first time in the exchange’s 226-year history that it will be run by a woman.

The symmetry of it all is delightful to the many voices calling for greater gender equity, especially in an industry which has remained insular and largely male dominated. While the financial industry boasts a higher proportion of women in senior leadership positions, 29 percent, than any other sector, those positions often don’t translate to opportunities to helm organizations. The percentage of female CEOs in the industry is only 5 percent, slightly lower than average. While the #MeToo movement has felled executives in media, politics, and restaurants, among other industries, the same hasn’t happened in banking. It’s possible that this is due to a culture of silence regarding male predation. Earlier this year, Max Abelson of Bloomberg, citing interviews with 20 Wall Street women, wrote, “Some say they’ve been grabbed, kissed out of the blue, humiliated, and propositioned by colleagues and bosses but have stayed quiet because of cultural and financial forces that are particularly strong in banking.”

Cunningham, a 43-year-old with a careful, understated manner, has worked at the exchange for almost her entire career. She interned there while a college student at Lehigh University studying industrial engineering after her father, who worked at a brokerage firm, helped her land a job. Two years later, she became a floor clerk, one of about three dozen women among at least 1,300 men. The disparities weren’t just in representation. An article in the Wall Street Journal described the seventh-floor women’s restroom during that time as being located “inside an old phone booth.” The men’s room, by contrast, was described as “palatial,” with couches and a bathroom attendant. It may seem a small thing, but such details make clear the fact that until very recently, the presence of women at powerful institutions was an afterthought. Cunningham remained at the NYSE, with the exception of a break to attend cooking school and a stint at NASDAQ. Three years ago, she became the chief operating officer.

In a recent interview with CNBC, Cunningham touched on the historic nature of her ascent only in passing. She acknowledged that banking is male-dominated but added that this “is not something that’s been top of mind for me.” Last year, she told The Financial Times, “I never acted as though there was a question as to whether or not I should be where I was,” but then in a moment of deeper reflection added, “When I look back I think I took some things for granted.” Cunningham has mentioned her debt to a previous generation of women in finance, in particular, Muriel Siebert, who was the first woman to join the NYSE floor, in 1967, and became a Wall Street legend, moving around the floor in a multicolored fur-trading jacket. And Catherine Kinney served as a co-president of the exchange during the 2000s.

The CEO of the NYSE’s parent company, Jeff Sprecher, evoked that history in a press release announcing Cunningham’s new role: “More than a half-century after Muriel Siebert became the first woman to own a seat on the NYSE, Stacey represents a new generation of leadership for the NYSE Group.” What neither Cunningham nor Sprecher has emphasized is that her promotion comes at a particularly daunting time for the organization. In the past, going public on the exchange was a sought-after milestone for any entrepreneur. But the IPO market has been somewhat lackluster of late. The people running many of the most valuable companies in the world—the ones known as “unicorns,” such as Uber, Airbnb, SpaceX, and Palantir—are choosing to stay private, turned off by the regulatory and financial cost of an IPO, and the added stress of public shareholder pressure. Adding to the challenge are the changes that have been ushered in by technology. In the past, the NYSE and NASDAQ essentially had a duopoly on equities trading, but regulations and electronic trading have broken their hold. The NYSE’s share of U.S. stock-trading volume has fallen from nearly 40 percent, a decade ago, to 22 percent.

Cunningham is well aware of these challenges, and says she is ready to face them. Of the unicorns, she told CNBC, “There’s a lot of private capital out there—they have options,” and vowed to encourage more successful companies to go public. And she said the fragmentation of trading “has gone too far.” She hopes to address both by pushing for regulatory change, among other fixes. But the fact that she, the first woman to ever lead the exchange, is the one tasked with helping it endure some of its greatest challenges, may not be coincidental.

In 2005, Michelle Ryan and S. Alexander Haslam of the University of Exeter coined the phrase “the glass cliff,” in a reference to their observation that women seemed to be promoted to leadership roles during periods of corporate upheaval, leaving them on precarious footing. Ryan and Haslam studied the performance of companies on the FTSE 100 index and found that companies that appointed women to their boards “were more likely to have experienced consistently bad performance in the preceding five months” than the ones who appointed men. In separate research, they found that students and business leaders were more likely to select a female leader for a hypothetical organization during a time of performance decline.

Though there’s debate over whether the glass cliff really exists, the past decade of corporate drama has provided plenty of anecdotal evidence. Erin Callan, who became Lehman Brothers’ chief financial officer in 2007, just before the company started facing serious financial troubles, is sometimes said to have been placed on such a cliff. After the company’s precipitous decline, the result of many failings including those made long before she took on the role, she was forced to leave her job within months. There’s an example that closely mirrors Cunningham’s potential situation, too: In 2017, NASDAQ, facing similar challenges in a new age of corporate unicorns and fast-moving technology appointed Adena Friedman as its first female CEO and tasked her with figuring out how the exchange will move forward.

There are plenty of instances outside of finance that reflect a possible glass cliff. When Mary Barra became the first female CEO of General Motors in 2014, the company was in the midst of recalls after an ignition problem had killed more than a dozen people. The glass cliff has even been evoked in politics; when Theresa May became Britain’s post-Brexit prime minister, The New York Times ran the headline: “ ‘Glass Cliff,’ Not Just Ceiling, Often Impedes Women Rising in Politics.” There are plenty of other examples that seem similar: Marissa Mayer at Yahoo, and the many Democratic women winning primaries in contested U.S. congressional races after one of the party’s most notable defeats in recent memory.

It’s not clear that the glass cliff—to the extent that it exists—represents a deliberate effort to undermine women. It might even be the case that women are perceived as being especially suited to handle crisis situations. Still, the consequences can be serious: At a time when there are more men named James among Fortune 500 CEOs than women, female leaders aren’t especially expendable.

Of course, in Cunningham’s case, the NYSE’s challenges are nowhere near as serious as those faced by, say, Callan. And finding oneself on a glass cliff doesn’t necessarily mean that one will fall. Anne M. Mulcahy, a former Xerox CEO, is often cited as a glass-cliff success, who took over her company during troubled times and turned it around. In Barra’s case, GM has recovered well, beating Elon Musk’s Tesla at building the first mass-market electric car. Fortune just named Barra number 11 on its list of the world’s 50 greatest leaders. If Cunningham is standing on a glass cliff, she may be able to take solace in the fact that there are plenty of other women who arrived there long before and are still standing.



America’s newspapers and magazines have doggedly covered the nation’s reckoning with sexual harassment in recent months—yet there’s ongoing debate about how well those newsrooms are handling their own scandals.

Dozens of reporters and editors gathered at the Newseum in Washington, D.C., on Tuesday to talk about gender inequity and sexual misconduct in American newsrooms, and the extent to which newsroom culture has lagged behind coverage.

One panel conversation turned repeatedly to the topic of Glenn Thrush, the New York Times reporter who was suspended last year after the publication of a Vox story that contained allegations of inappropriate behavior against him. (Thrush apologized in a November statement for “any situation where I behaved inappropriately,” but said he recalled events differently than they were described in the Vox story.)  In December, the Times announced, after a month-long investigation, that Thrush would return to the newsroom, but would be removed from the White House beat. Speaking at the event on Tuesday, Carolyn Ryan, an assistant managing editor at the Times, described a thorough and transparent process leading to that decision—a characterization that was quickly challenged by another reporter in the room.

“I want to challenge you on the notion that you were truly transparent,” said Paul Farhi, a media reporter for The Washington Post. “There is an extensive report which you have not made public. Your top management was not available for interviews. And I’d like to know why and why this is a good way to explain to the public what you’re doing in the face of a harassment case.”

Ryan said that the report Farhi referenced was kept confidential because it contained interviews between a Times lawyer and several employees, and those interviews were conducted with the expectation that they would not be made public. She also suggested that the union representing Thrush pushed to keep details of the investigation private. “So it’s not like every last detail is going to come out, but what we have talked to people about in a lot of detail is the process,” Ryan said.

“In all kinds of behavior—ethical transgressions, journalistic infractions, journalist performance—we do draw lines,” Ryan later added. “And we have a responsibility to do that. The industry more broadly is having a hard time figuring out where some of those lines are.”

She said that she understood that some people appreciated the “nuance” of the decision to keep Thrush on staff, while others believed it was a bad idea to let him return to the newsroom. Erring on the side of nuance made sense, she said, in a situation where Times brass knew it would be under a microscope no matter what the outcome.

“The people who worked most closely with Glenn in the bureau—men, women, young, old—were supportive of him and did believe that he could contribute and hadn’t seen the kind of behavior that had been described,” Ryan said. “I keep kind of dancing up to the line here, but I think this is a conversation that not only are we having more broadly at The New York Times, but that we had as we were trying to figure out the punishment.”

The journalist who first reported the allegations against Thrush, Vox’s Laura McGann, also addressed the room at the Newseum event. Her comments came during a discussion about dating in the workplace.

“We all sort of nodded that the place we should be thinking about is consent versus non-consent, and that’s really hard to litigate,” McGann said. “I just want to push ourselves on—is that what we want to be doing? That’s something I’ve been struggling a lot with.”

McGann’s story about Thrush set off a robust debate among journalists—in part on the matter of whether the women featured in the article had truly consented to their sexual encounters with Thrush.

“I don’t see this uprising of 22-year-old women saying, ‘I want the right to sleep with my boss,’” she added. “That’s not happening. So I feel like overwhelmingly the problem here is more powerful men are putting women in a bad position.”

One of the women in the room who nodded in agreement with McGann was Addie Zinone, a former Today show production assistant who says she was the victim in an affair with Matt Lauer that she believed was consensual at the time—she was 24; Lauer was 43—but who later viewed their relationship as an abuse of power by Lauer.

“I was an intern-turned-PA, so that power dynamic was completely imbalanced,” Zinone said. “He was always incredibly professional. He always presented himself that way. Until he didn’t.”

And for decades, women in newsrooms were asked or forced to keep mum about their own experiences with sexual misconduct at work. Many kept quiet. Until they didn't.



For more than a decade, the number of American households that rent has expanded year after year, sometimes by more than a million renters annually. This year, the explosion of renters in the wake of the foreclosure crisis has maybe, finally, begun to fade: For the first time since 2004, the number of renter households declined.

Twelve years of growth has permanently transformed the housing landscape. High-income earners account for a much larger share of renters in the U.S. today than they did when the rise of renting began in 2005. Between 2006 and 2016, the share of households earning more than $100,000 that rented their housing grew from 12 percent to 18 percent—a spike of nearly 3 million people, or almost a third of the 9.9 million increase in renters overall.

This is a shift with big implications for high-cost cities and the economy at large. As a report from Harvard’s Joint Center for Housing Studies explains, it’s a testament to the reach and depth of the foreclosure crisis that so many former homeowners or would-be homeowners instead joined the ranks of renters. But even though the expansion of renters’ ranks may be slowing, the changes in rental housing, and in the people who choose to rent, are here for good.

A Decade-Long Expansion in New Rental Housing Has Slowed

The new normal, according to the Harvard report, is that today’s renters are older, wealthier, and more likely to have children. Between 2006 and 2016, the median age of renters in the U.S. jumped from 36 to 40. Families with children now represent a larger share of renter households (33 percent) than homeowner households (30 percent). Thanks to the entry of white households, renters also more closely resemble the U.S. as a whole demographically, much more so than homeowners do.

Much of the expansion in rental housing came in the conversion of single-family homes traditionally bought by households with children. Between 2006 and 2016, the report reads, “the number of single-family homes available for rent increased by nearly 4 million, lifting the total to 18.2 million.” Adding to single-family-home conversions was a multifamily-home construction boom in major metro downtown areas and commercial corridors.

Rising apartment and condo buildings, the source of great agita in rapidly gentrifying cities and neighborhoods, shows where a large and growing share of renters has settled. In these areas, soaring costs for three “L” factors—labor, land, and lumber (materials)—have conspired to produce rental buildings that overwhelmingly cater to high-income households. Between 2011 and 2016, the median monthly rent jumped by 27 percent, to $1,480, mostly because rental housing is so expensive to build where renters want to live.

This would work fine if incomes were keeping up with the costs of living, but they aren’t. For a household to pay $1,480 a month but not spend more than 30 percent of their income on rent, a household needs to make at least $59,000. The median renter income is $37,300. That isn’t enough to rent affordably.

Over the last two years, the pressure on some renters has eased a little bit. The number of cost-burdened households (those paying more than 30 percent of their income toward rent) fell from 21.3 million in 2014 to 20.8 million in 2016. The number of severely cost-burdened households (those with rents accounting for more than half their income) dipped too, from 11.4 million to 11.0 million.

The problem is the sheer number of people caught up in the housing crisis and its aftermath. The explosion in renters was matched by an astronomic rise in households that can’t afford their rent. It will take full-on rent triage to heal the damage of widespread foreclosures. “At the average rate of improvement from 2014 to 2016, it would take another 24 years for the number of cost-burdened renters to return to the 2001 level,” the report reads.

Despite Recent Declines, Renters Are Still More Cost-Burdened Than a Decade Ago

The next steps taken by the federal government could either lock in the modest gains that renters have made just recently—or quickly reverse them.

Tax reform will be especially important to the future of housing. One of the main instruments for building affordable housing for the most vulnerable families, the Low-Income Housing Tax Credit, could see its value diminished if the corporate tax rate is slashed. One version of the tax-reform bill threatened to eliminate part of the housing tax credit program altogether. And while Congress has yet to pass a new budget under the Trump administration, every proposal so far has included severe cuts to public assistance, including housing aid.

A tax-reform bill that squeezes the middle class after a decade, coupled with immediate budget cuts to low-income households, could return the country to foreclosure-crisis levels of renter despair. This is to say nothing about unpredictable threats, like a recession, or predicted changes, like looming demographic shifts as the bulk of the Baby Boomer generation retires and the youngest Millennials form their own households. Over the last decade, the country has ended up with a renter class that’s older, wealthier, whiter, and has more children. That transformation may end up becoming permanent.

This post appears courtesy of CityLab.



Here is a brief summary of the 2017 economy: In a tug-of-war between political surreality and global reality, reality won.

While President Donald Trump has been an instrument of chaos—goading nuclear powers, blasting the FBI, and mocking his enemies—the global economy scarcely seems to have noticed. In Europe, manufacturing confidence hit a 10-year high, according to JP Morgan. In Japan, business confidence has hit a 30-year high. The U.S. labor market has added jobs for 75 consecutive months—a record. In the likely event that the economy is still expanding in May, this will be the second-longest period of economic growth since the end of World War II. (GDP would have to keep growing for another 18 months to catch the all-time record, the 1991–2001 expansion.) On Wednesday, the Dow Jones Industrial Average surpassed 25,000 for the first time ever, after another round of strong jobs data.

It’s impossible to say for certain how long any of this will continue in 2018. The 2017 economy benefited from several trends, like the nice bump in oil and metal prices, that could be temporary boons. But if 2018 is indeed a redux of 2017, we may finally glimpse an emerald-rare phenomenon in the post-1970s economy: inflation higher than 2 percent.

There are two important questions regarding inflation: Can higher inflation, which can sometimes spin out of control, be good; and why aren’t we getting more of it?

The first question is easier to answer. Inflation in the economy is like yeast in bread; both too much and too little ruins the loaf, but a little bit makes the dough rise. The right amount of inflation—say, between 2 and 3 percent—can push up wages and stimulate economic expansion. Since the Great Recession ended, the most common measure of inflation, the “core” consumer price index (which discounts volatile food and energy costs), has been under the Federal Reserve’s target of 2 percent. That’s one reason why so much of the economic recovery has felt so feeble.

The second question—why is higher inflation so elusive—is one of the larger mysteries of the last few years. Since March 2009, the world’s central banks have pumped more than $11 trillion in stimulus into the global economy. Stock prices have tripled. But U.S. inflation hasn’t surpassed the Federal Reserve’s target of 2 percent for more than a few months total. Price and wage growth are dormant across developed economies like the U.S., Europe, and Japan.

There are several possible reasons. First, lower inflation is a natural feature of a moribund recovery following a financial crisis, like the Great Recession, when families spend less after they lose jobs and their housing values plummet. Second, aging populations in advanced economies might be restraining economic growth, since pensioners, by definition, don’t work much. Third, internet companies and communications technology might be keeping prices low; for example, Uber has made urban transit cheaper, and Amazon and Walmart have held down retail prices. Finally, it’s possible that larger companies—not necessarily monopolies, but monopoly-ish—have fewer competitors, so they can afford to restrain wage growth. (The average market cap of a public U.S. company is 10 times higher than it was four decades ago, according to JP Morgan.)

The specter of inflation haunts goldbugs and bond investors looking for risk-free returns. But 2018 might finally be the year where the apparition enters the realm of reality. This materialization would be great for workers, since median wage growth is still far below its late-1990s levels.

The first reason why inflation might finally be right around the corner is that the U.S. seems awfully close to full employment. The official unemployment rate is 4.1 percent, which is lower than any time between 1971 and 1999. But that’s not all: The share of part-time workers is lower than any time in a decade, and a survey of small businesses’ intention to hire recently returned an all-time high (the survey began in 1974).

Wage inflation and overall inflation are somewhat interlinked, since having to pay workers more can force companies to raise prices. One of the key signs of impending wage inflation is that industries struggle to fill low-wage jobs, since workers are constantly threatening to leave for a higher-paying position. Indeed, restaurants like Cheesecake Factory are finding it harder to keep workers around without raising wages and prices. Another low-wage job, delivery drivers who drop off packages for UPS or FedEx, is in such high demand that the occupation was the third–most popular job listing on Monster.com in 2017. More competition for low-wage workers should push up wages, and prices will likely follow.

Second, the Republican tax cut might provide an interesting experiment for 2018, because it does something rather unprecedented in U.S. budget policy. It purposefully increases deficits deep into a recovery with unemployment under 5 percent. And while the overall tax cut skews toward the rich, the 2018 distribution is more progressive because it includes the largest tax benefits for middle-class families, which later expire.

The last time that unemployment was this low, President Bill Clinton was presiding over budget surpluses. But the Joint Committee on Taxation estimates that the tax cut signed by Trump will add $135 billion to the deficit in the first nine months of 2018 (the remainder of the fiscal year) and another $280 billion to the deficit in the following 12 months. This is a bold experiment in expansionary fiscal policy. No modern American government has ever passed a tax cut this large with such low unemployment. It would be awfully surprising if cutting taxes by more than $100 billion a year in a growing economy with near full employment didn’t produce at least a little bump in inflation (even if the overall bill is largely a sop to the ultra-rich).

In the 1970s, inflation teamed up with high unemployment to deliver a miserable few years for working Americans. But a little bit of inflation isn’t a disaster. It would raise wages and stimulate economic growth after years of steady but sluggish expansion. The Federal Reserve has the power to quickly raise rates to cool the economy. But perhaps it should allow just a bit of overheating. We know what a decade of sluggishness looks like. Let’s see what a little bit of inflation can do.



Addiction to prescription pain medication has taken a staggering toll on America: According to one accounting, overdoses killed more people in one year than guns and car accidents combined.

Tens of thousands of Americans are dying each year from overdoses. It’s a grim trend that has touched just about every aspect of life—even, as the latest figures from the Bureau of Labor Statistics indicate, work. While traffic accidents, homicides, and suicides are still the top culprits of on-the-job fatalities, deaths related to addiction are increasing at a rapid clip. Last year alone, the number of workers who died at work because of drug- or alcohol-abuse-related incidents increased by more than 30 percent, to more than 200. While that number may seem small, it’s evidence of how rapidly the problem is growing—less than five years ago, fewer than 70 people died from overdoses at work.  Since 2012, the number of people dying from drug or alcohol related causes while on the job has been growing by at least 25 percent each year, according to the Bureau of Labor Statistics.

These deaths represent unspeakable individual tragedies. They also, in the larger picture, serve as a striking illustration of how America’s addiction epidemic is changing the landscape of work.  

Over the past few years, economists have struggled to explain why so many people appear to be dropping out of the workforce. The most telling measure of that is the labor-force participation rate—which measures the percentage of the population that is employed or actively looking for work—which now sits around 62.7 percent. That’s low by historical standards. For example, between 1986 and 2001, labor-force participation grew fairly steadily, to between 65 and 67 percent. There are many theories about why this figure has been declining in the past decade or so: Automation, a lack of quality jobs, and an aging workforce are all thought to play a role. Still, the shortage of 25-to-54-year old workers—a group economists call “prime age” workers—particularly male ones, remains a big problem for the future of the labor market.

The economist Alan Krueger’s work has shown that there’s a striking relationship between these missing workers and increasing opioid addiction. According to an analysis done by Krueger, over the past 15 years, labor-force participation among prime-age workers has declined the most in U.S. counties where opioids prescriptions are the most plentiful. He is sure to mention that cause and effect aren’t clear: It’s hard to say whether addiction breeds joblessness, or vice versa. “Regardless of the direction of causality, the opioid crisis and depressed labor force participation are now intertwined in many parts of the U.S.,” Krueger writes.

The increasing number of on-the-job deaths due to addiction is evidence of this. While the opioid crisis is often cast as a problem that predominantly plagues the jobless, some studies show that around two-thirds of those who report abusing painkillers are still employed. On top of the devastating aftermath of injuries and deaths, this can also lead to a lot of workers not performing to their potential.

According to a survey from the National Safety Council, an advocacy and consulting group that studies safety practices, around 70 percent of employers have seen some impact of prescription drug use on their workers, from missed shifts and impaired work. And yet fewer than 20 percent of employers said that they felt prepared to deal with issues related to addiction, such as knowing how to broach the topic with workers or get them help. That’s evidenced by companies’ approach to addressing drug use: The companies that did report testing employees for drug use were much more likely to screen for marijuana (which has been legalized in many states) than synthetic opioids such as oxycodone or hydrocodone that are major contributors to the current wave of addiction and death.  

According to the same survey, the vast majority of employers said that they would want to help workers struggling with addiction. And yet employers’ most common response to suspected drug use was that it is an offense that merits dismissal. As the country tries to address the crisis, it’s going to need to acknowledge how addiction touches many realms, including work and labor.



HEMET, California—Many cities across America are doing better today than they were before the recession. This is not one of them. A decade after the start of the Great Recession, it struggles with pervasive crime and poverty. “We’re still recovering—we were really hit hard on all levels,” Linda Krupa, the mayor of Hemet, told me. A fifth of the population lives below the poverty line, up from 13 percent in 2005.

Hemet is not alone in its troubles. A report released this year by the Economic Innovation Group, a research group started by Silicon Valley entrepreneurs, found that one in six Americans lives in what the group calls “economically distressed communities” that are “increasingly alienated from the benefits of the modern economy.” Such communities have high shares of poverty, many housing vacancies, a large proportion of adults without a high-school diploma, high joblessness, and a lower median income than the rest of the state in which they are located. They also lost jobs and businesses between 2011 and 2015.

Many of these distressed communities are located in Rust Belt states like Ohio, New York, and Michigan. They include Youngstown, Buffalo, and Flint. In the months after the 2016 election, there was a lot of conversation about how people living in these areas felt left behind by the changing economy and the prosperity in the rest of the country.

But there’s another type of left-behind community that’s gotten far less attention. These towns are located in the suburbs of the American west, in regions hit hard by the housing crisis—Southern California, Las Vegas, and Arizona. Hemet, a suburb of Riverside, California, with a population of 84,000, ranked eighth on EIG’s most distressed small-and-mid-sized-cities list. In Hemet, according to the group’s report, employment fell 15.5 percent between 2011 and 2015, while it grew 9.4 percent nationwide. The number of businesses in Hemet dropped 4.8 percent over that time period. The median home price, at $237,000, is still 30 percent lower than it was in 2006.

Why hasn’t Hemet found surer footing? For one thing, the region where Hemet is located was decimated by the housing crisis, with among the highest foreclosure and unemployment rates in the nation; many families are still recovering. But Hemet’s problems are also the result of structural changes in the economy—changes that have been underway for decades but were masked by the heady days of the housing boom. Middle-class jobs have been disappearing while high-wage and low-wage jobs have grown—but in different geographic locations. High-wage jobs are often located in big cities, while low-wage jobs are in relatively cheap locations like suburbs and small cities. This dynamic changes the housing markets of these cities, too, with big cities getting more expensive as more high-wage workers migrate there, and low-wage workers leaving cities to seek more affordable housing in the far-away suburbs they can afford. Now that the dust of the recession has cleared, it is evident that the geography of poverty has changed in America. Hemet is emblematic of just how fast—and just how dramatically—this has happened.

I first visited Hemet in 2010, when, as a reporter for the Los Angeles Times, I stumbled across a one-time luxury development that real-estate agents were, at the time, calling a “gated ghetto.” Dozens of families in the community, called Willowalk, had lost their homes to foreclosure and investors had swooped in, bought up the properties, and rented them out, often not checking references and not maintaining the properties. Homeowners were shocked when renters with Section 8 vouchers moved in next door.

When I returned to Hemet this November, I assumed that the development would have bounced back in the seven years since. The houses are huge and Willowalk features a community pool, a lake, and walking trails, all features that, in California’s booming real-estate market, would make the development seem like a steal. But not much has changed in the seven years since I first visited. If anything, the situation has gotten worse for people who remained.

“The crime level just keeps getting higher,” Toni Willden, who bought her home in 2005, told me recently, about Willowalk. The gates that keep out nonresidents get broken once or twice a week, she said. Just about everybody in town knows the code to the gates anyway—I got it by asking the clerk at the hotel where I was staying. Another woman, Amy Aschenberg, whose family in 2014 bought a five-bedroom home overlooking a pond, told me that she and her husband realized they’d made a mistake soon after buying their home. The gated community was filled with renters, who didn’t keep up their homes and who hosted parties late into the night, especially in the summer. Home burglaries—in the middle of the day—happened with alarming regularity. “I would never have moved here if I had known what this place was,” Aschenberg, 36, told me recently.

This gated community is an example of how some neighborhoods that were once middle-class are becoming poorer. “The lack of construction in coastal cities has forced people who are marginally educated and low-income to move inland,” said John Husing, the chief economist of the Inland Empire Economic Partnership. Median rents in Hemet rose just five percent between 2009 and 2016; in Los Angeles, they rose 20 percent, according to Census data.

Krupa, the mayor, has said that the recession caused Hemet to transition from a retirement community to a low-income community because of the influx of new, poor residents. In the suburbs of the Riverside-San Bernardino metro area, including Hemet, the number of people living below the poverty line grew 63 percent, to 596,310, between 2007 and 2016, according to Elizabeth Kneebone, the research director at the University of California-Berkeley’s Terner Center for Housing Innovation. In the suburbs around Las Vegas, the change was even more dramatic: There, the poor population grew 126 percent between 2006 and 2016, according to Kneebone. “It’s the new normal that suburbs are going to be struggling with poverty,” she said.  

Hemet problems are in some ways particular to the areas that suffered the most during the housing bust. Suburbs far away from Los Angeles, Las Vegas, and Phoenix, where people bought homes during the “drive til you qualify” housing boom, were plagued by a high number of foreclosures in the bust. After the homes went through foreclosure, they were purchased by investors and rented out, creating new, low-cost rentals. Before the recession, 63 percent of homes in Hemet were owner-occupied, today just 54 percent are, according to Census data.

Renters aren’t necessarily bad for a neighborhood, but the transition of a neighborhood from one of homeowners to one of renters can be disruptive. When a home is lost to foreclosure and then changes hands a number of times, it can upset the community ties in a neighborhood, according to Husing. When homeowners live in their own homes, they are invested in the community, and their own fortunes are bound to those around them. When they live far away and are renting them out, they’re often less able to put time into maintenance and upkeep. “Detached single-family rental housing tends to really upset the social structure of communities,” Husing said. “Many times they never get back.”

Research by Deirdre Pfeiffer, a professor at Arizona State University, found that after investors bought up single-family homes and rented them out in the Phoenix suburb of Chandler, Arizona, the neighborhoods had more service calls to police about violent crime. Husing did a similar study in San Bernardino, the next county over from Riverside, and found that in one city, Ontario, it was 47 percent more likely that police would be called to single-family rentals than to owner-occupied homes, 25 percent more likely that the fire department would be called to single-family rentals, and 36 more likely that the city would have to take out code enforcement actions on single-family rentals than owner-occupied homes.

The problem is not the influx of renters, necessarily, but instead the absentee landlords who don’t keep up homes. I talked to a woman named Domenica Azzolini, who moved into a big house in Willowalk after losing her home to foreclosure. She moved in without seeing the rental because she was desperate for a place, only to find that the floors were unfinished concrete, and that there was black mold growing in the bathroom. Her landlord refused to fix either, so Azzolini paid for the repairs out of her own pocket. The deteriorating upkeep of some neighborhoods like Willowalk has led to an exodus of those who can leave. The Lopezes, the family of first-time homeowners in Willowalk I had profiled in 2010, walked away from their home and moved to another town. “It got so bad that we had to move,” Maria Lopez told me.

Lower-income neighborhoods typically have higher crime rate than higher-income neighborhoods, and an influx of low-income renters has tracked with an uptick in crime in Hemet. According to FBI crime data, in 2016 in Hemet there were more motor-vehicle thefts (623), robberies (170), and aggravated assaults (398) than in any other year in the 21st century. “I’ve seen the community really go downhill since the recession,” Jim Ollerton, a lifelong Hemet resident and member of the Hemet Planning Commission told me. “The community is still suffering with a lot of quality-of-life criminal activity.” He recently voted against a new planned condominium in Hemet because he thinks the city has too many rentals.

Of course, the challenges in places like Hemet aren’t just caused by an uptick in low-income new arrivals. People who have lived in these areas for years are also struggling. It’s not that there aren’t jobs: In the last five years, the Inland Empire, as the area encompassing Riverside and San Bernardino counties is called, had the second-fastest rate of job growth in California, after San Francisco. But these jobs aren’t the kind that give families a comfortable middle-class life; rather, they are low-paying and unstable. The fastest-growing industry in the Inland Empire between 2011 and 2016 was warehousing and storage, which more than doubled employment. Other fields that saw big growth were food service and health care. The pay isn’t great in any of these fields—in the Inland Empire, the 40,000 or so food-preparation workers make an average of $24,000 a year; the 55,000 material movers make $29,000, and the 30,000 people working in health-care support make $34,000. “It is the whole nature of this economy not delivering rising real incomes to people in those types of jobs,” Husing said.

It’s not random chance that has concentrated these jobs in places like the Inland Empire. Well-paying jobs for people with college educations are increasingly located in cities. Meanwhile, jobs in retail, manufacturing, and warehousing have suburbanized as companies move to places with cheaper land and labor.“The types of jobs that are more suburbanized tend to be lower-paying,” Kneebone said. And the Inland Empire is essentially one big suburb. The Riverside–San Bernardino area has the worst annual average private-sector wage of the top 50 metropolitan statistical areas in the country, at $40,000 in 2015.

The inflated wages in the construction and finance industries during the housing boom gave suburbs like those in the Inland Empire a few good years in which people could live a middle-class life. Now that lifestyle is out of reach for many, a fact Tricia and Rich Powe know all too well. Before the recession, they did well for themselves—he worked in manufacturing, she was a mortgage counselor.

But they both lost their jobs during the recession, and then lost the home they’d bought in Corona, a suburb of Riverside, in 2008. After a long spell of unemployment, Rich found a new job in manufacturing three years ago, but he began as a temporary worker, and even though he was recently brought on as a full-time employee, he makes $6.25 an hour less than he did before the recession. They haven’t been able to accumulate any savings, and are still paying off loans; Rich for his daughter’s college education, Tricia for school. “We’re living paycheck to paycheck,” Tricia told me. “If we lost our jobs, we’d be in trouble.”

In the end, Hemet is stuck. The city itself can’t convince companies to pay better wages, and it has no control over the rents in big cities that are pushing people out to the suburbs. It has tried to force absentee landlords to keep up their homes, but has limited resources to do so, and struggles to smooth over its transition from a community of homeowners to one of renters. Like many other suburbs and small cities across the country, the economic tide has turned against its residents, leaving them seemingly no path back to vitality. As Hemet and many suburbs like it are finding, growing poverty can lead to even bigger problems—lower tax revenues, fewer businesses able to stay put, worse services like schools and police. This, of course, makes them even less attractive for people who have other choices about where to live. Over time, the situation only gets worse. As nearby cities prosper, and the recession appears as just a bump in the road in the rearview mirror, distressed areas are still there, unable to move ahead.



To get a job at the Museum of Ice Cream, hopeful future employees show up at the weekly casting call, Tuesdays at noon. They head to the former Savings Union Bank in San Francisco’s financial district, where pink banners announce, in minimalist font, the name of the employer-to-be. Inside, there are giant animal cookies on carousel mounts. Gardens of gummies. A minty scent wafting through a jungle of mint leaves. Each day, roughly 1,700 people pay $38 a ticket to march through the maze of rooms, licking pink vanilla soft-serve cones, following instructions from a cotton candy server to text someone in their life whom they consider the “cherry on top,” and, all the while, angling for photos. It is as if Willy Wonka had redesigned his factory for the selfie age.

And it’s a sold-out hit. What was going to be a summer pop-up in New York City has turned into a frothy cultural phenomenon at a troubled national moment. While the New York museum is now closed, new ones sprouted in San Francisco, Los Angeles, and Miami. Judging by visitors’ Instagram posts (including from such Queens of Personal Branding as Beyonce, Gwyneth Paltrow, and Kim Kardashian), you would be forgiven for forgetting there are any employees at all: Mostly, people go to the Museum of Ice Cream to photograph themselves at the Museum of Ice Cream. But just as Wonka had his Oompa Loompas, the Museum of Ice Cream requires a service staff. Each Tuesday, the museum closes to the throngs for maintenance and so that a parade of Pink Army recruits can appear before a casting panel of staffers intent on gently sorting the ice-cream die-hards from the pretenders.

The first question is always the same: “What’s your ice-cream name?”

A week after having succeeded at one such casting call, Golden Graham was starting his morning shift. Graham is 20 years old, with a voluminous fro. He’d memorized the script and tucked into an all-pink uniform: “Team MOIC” T-shirt, pants, cap, apron. He led a gaggle of parents and kids past a sparkly pink rope to enter the first room, where his role was to play museum hype man. His audience would have to recite a loopy, rhyming pinkie promise and then cheer with him, he explained, to “let the whole museum know we’re coming.” The kids were too young to get the cheer’s reference: “One, two, three… scoop, there it is.” A blonde mom exclaimed, “It’s an Instagram dream in here!”

All dreams require upkeep. In fact, it takes 25 staffers on any given shift, drawing from a San Francisco employee pool of 120. Someone must sweep sprinkles back into the sprinkle pool, mop scuff marks off the pink, alphabet-patterned linoleum, and replace the cracked whipped-cream cans on the wall, where people on swing sets have crashed into them. They must offer ice-cream cones and cotton candy and mint mochis at precise moments and subtle crowd control at the entrances to rooms, all while keeping a whimsical tone. (When a tour guide’s group has to wait to enter a crowded room, the guide will never explain, “The room is too crowded.” She will announce something like, “The unicorns are asleep right now.”) It’s no surprise that this gig caters to the young: The guides average about 20 years old, which Pew Research Center says is too young to even be called a Millennial. They’re people who are into being “photographed and socialed” on the job, as the ad states. They earn $15-an-hour starting wages to do so (one dollar over the city’s minimum), part-time work perhaps sweetened by “all the ice cream you can eat.” As I ambled through the exhibits to talk with the guides working a recent day shift, I found many of them to be the brand incarnate, talking about it less as a job than an identity. One Miami worker’s Instagram post of a staff photo reads: “@museumoficecream is my home away from home! Love every single person in this picture. Thank you @museumoficecream for creating this family.”

The first token of the identity is the ice-cream name. A 22-year-old manager (ice-cream name: Chip) explained, “We believe everyone has one in them.” Many of them are gloriously witty: Butter Pecanye West. Alicia Key Lime. Bernie Sundaes. Cherry Potter. Some use their ice-cream names as their profile names on Instagram, writing on-brand messaging that could basically double as ad copy (“I had a NeapoliTON of fun tonight”). The Pink Army hashtag their own on-the-job pictures #TeamMOIC: managers doing a choreographed dance routine, the guides posing in the exhibits in shots that are nearly indistinguishable from the ones taken by visitors. Madison Utendahl, the company’s full-time head of content and social, in New York, also posts professional shots of the guides at work in the carefully curated Museum of Ice Cream Instagram feed, with its 378,000 followers. Utendahl designs the procession of posts two weeks in advance, she told me in an email, using a consistent “color, texture, and narrative.” The result is like a months-long, pastel-hued magazine spread: This social-media presence is nominated for two Webby awards, competing in one category against the Instagram feed of the Guggenheim Museum.

Cowboy Cookie Dough Chris, an aspiring actor, began working at the New York museum in August 2016, when he was 20, and then followed the brand to San Francisco. He sometimes sends photos and videos to Utendahl for consideration for the museum’s Instagram Story, the slide show of media that disappears in 24 hours. He loves when his photos are included, and not just for the thrill of it. “That’s where I like to build my brand,” he says. “It kind of gets my name out there, too.”

The vibe among Team MOIC seems similar to that of summer camp counselors: coworkers as social clan. This helps keep people psyched, one manager explains: “You need that support in the back, so people will want to come and work this super-high-energy job every single day and not burn out.” They start each day with a team meeting and a question of the day (e.g., “Describe the room you grew up in”) and end it with another team meeting in which staff members share the day’s highlights. A couple arranged the pink magnet letters into “ITS A BOY” in the “Dream” room for a reveal to friends and social media, then came back months later with an infant and spelling “IM THE BOY.” A wedding proposal took place in the sprinkle pool. A man in the ice-cream diner recounted his first date with his wife of 50 years in an ice-cream parlor, and his wife marveled, “I didn’t know you remembered all that!”

Starting her shift as “lifeguard” at the pool filled with plastic sprinkles, which entails continuously circling the deck with a broom to sweep the errant fake candies back in as quickly as customers can splash them out, Soft Serve Syd described her path to the job more in the language of self-discovery than employment. Syd, who is 25, worked in hospital administration before this, but, she said, “In my 20s, it is my time to explore different things.” Plus, “I had a rough patch in my personal life, and I was looking for more joy. It’s pushed me as a human being, and I love it.”

Syd is one of what staffers call “the OGs”—the people who’ve worked here since it opened in September. That’s longer than most. The general manager—wearing a backwards baseball cap bearing the logo of Stanford’s business school, her alma mater—says the average tenure is two months (which, if anyone is keeping track, sets the Pink Army well below the roughly 16-month average job stint for Americans aged 20 to 24, according to the Bureau of Labor Statistics). People’s class schedules will change, she says, and they’ll drop off. Seasonal reinforcements come in just for the holidays.

It’s also true, of course, that there are easier ways to make just above minimum wage than constantly embodying the ice-cream dream: acting delighted by each visitor’s response to “What inspires you the most?” and competing to hear and be heard over the relentlessly pounding pop music in congested rooms filled with sugar-high kids. Gummy Gladis, who I found working in the “mint” room, handing out the mint mochis and squatting to comfort a crying toddler, says she spends the rare moments between catering to visitors dancing “to keep my energy up,” or practicing her lines. “Everyone has their threshold for dealing with the public,” she says. “Mine is very high.”

One Tuesday afternoon, I inched my seat closer to the Museum of Ice Cream’s founder, Maryellis Bunn, to hear her over the music—The Lion King’s “Circle of Life”—blasting through the atrium. Undistracted, Bunn spoke in frenetic bursts of TED Talk-isms: the cities of the future, the evolution of her ice-cream ideology, the horrendousness of white-collar office spaces. Bunn, who has lately been “nomadic,” had flown in from New York City earlier that day, and would take a red-eye back that night. She was here to attend the staff pajama party, in which the Pink Army was invited to come in, on their own time, to watch Coco in the sprinkle pool. Bunn wore cherry-printed boxers, fluffy slippers, and a pink blanket draped around her tiny shoulders as if it were an expensive shawl. She asked me, “What’s your favorite kind of ice cream?”

Bunn (ice-cream name: Scream, as in, what we all do for ice cream) is 26. She grew up in Laguna Beach, a few years behind the teen stars of MTV’s eponymous reality show, which packaged high-school life in beachy, filthy-rich California for Midwestern teen gawkers like myself. (Instagram before Instagram.) Bunn told me she was “always just hustling.” As a kid, she sold painted rocks to people heading to church, and then popsicles, at a markup, to tourists on the beach; by high school, she worked as a buyer for a high-end clothing boutique. She went to college at New York University, then worked as the head of forecasting and innovation at Time Inc. for a year before deciding, with a friend, Manish Vora, to launch her first museum. (Her much loftier, long-term goal was to someday build a city from scratch.) She figured many of the retail structures of old needed to be reinvented. Amazon and e-commerce were driving the retail totems of a Millennial childhood—Toys “R” Us, Claire’s—into bankruptcy. “What do we do,” she asked me, “with all that space?”

When Bunn scouted this prime location in downtown San Francisco, it was being used to house an Emporio Armani boutique. She saw few customers and a handful of bored employees. Now a Pink Army of 25 employees work the space at any given time, urging hundreds of people to bond over the “common denomination of ice cream.” She told me, “It’s not so damn serious. I like ice cream, so do you, that’s enough.” Bunn finds the fact that this social experience is dominated by smartphones to be “bittersweet”: She recently posted on her Instagram Story that she’d give free tickets to anyone who’d come without their phones, and got several replies.

At the end of our interview, Bunn had me duck out through a side staircase to avoid the Pink Army starting to arrive for movie night in onesies and blankets. She politely declined my request to view the event, explaining that a reporter’s presence might make the guides feel, mistakenly, that the movie night had been staged for PR purposes. “We create safe spaces,” she said, and that goes for the Pink Army as much as the public.

Recently, managers decided to rename a pair of unicorn sculptures in a rainbow-wallpapered room after activist icons Harvey Milk and Gloria Steinem. During my visit, a guide introduces the sculptures as “Gloria” and “Harvey”—an abrupt injection of social consciousness into an experience whose politics are otherwise sparkle-spangle decline-to-state. The guide follows with a question: “What do you believe in so strongly that you would fight for?”

Overheard:

“Equal opportunity in education.”

“Recycling.”

“Naps in the afternoon.”

Millennials, and whatever we’re calling the gen after them, are the most racially diverse generation this country has ever seen, embracing an inclusive, digitally imbued social progressivism. They also embody more somber trends: They are set to face enormous income inequality, with a select few becoming incredibly wealthy, while many more are underemployed, burdened with college debt, and still living with their parents. They are the first generation of Americans who will likely earn less in their lifetime than their parents.

If you think of the Museum of Ice Cream as a temple of Millennial-hood—with few people over 26 on staff—it’s one uniquely situated in this economic context. Bunn is the canny #girlboss who trademarks the generation’s aesthetic for profit. The full-time managers are polished graduates of Berkeley or Stanford, the region’s marquee universities, preparing for careers in, as one told me, experiential design. The reality of the even younger guides, in one of the country’s most expensive regions, seems more touch-and-go; they’re aspiring actors, models, and miscellaneous undecideds. Some are killing time before starting college or a graduate program in museum studies; others aren’t quite sure what they’ll do next. An employee told me, frankly, “I’ve been basically unemployed until now, living at home with my parents.” LinkedIn turns up guides with other positions at Chipotle or Victoria’s Secret; another said she just nabbed a second job at an IRL ice-cream parlor, because she wasn’t sure how long MOIC will stay open.

What It's Like to Work at an Ice Cream Factory

Given that the Museum of Ice Cream is a pop-up that has kept extending its run, a stint in the Pink Army is by definition fleeting. It seems that, for many in the Army, the ephemerality adds to the excitement; in their eyes, the museum’s glamorous trappings and dance parties help it transcend its status as near-minimum-wage service labor. “This place is magical,” one told me. In the gift shop that leads to the Museum of Ice Cream’s exit, a 25-year-old aspiring 3-D animator in a sprinkle tie tells me he slogs through an almost hour-and-a-half-long commute, by car and train, to get to this job from a cheaper city across the Bay. He sometimes arrives tired. “But once the shift starts, the energy just comes from nowhere. I’m happy, they’re happy, everyone is happy!”

Among the displays of MOIC-trademarked goods, one display caught my eye: shellacked sculptures in the shape of whipped-cream cans and chocolate-syrup bottles sat under a glass case, priced at $250 apiece. The placard read, “Artwork by Museum of Ice Cream Founder Maryellis Bunn, Signed, Limited Edition Pieces.” Some Millennials turn a profit on the $250 Cool Whip containers; others need to work about 17 hours to buy one.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

At least 2,000 children have now been forcibly separated from their parents by the United States government. Their stories are wrenching. Antar Davidson, a former youth-care worker at an Arizona shelter, described to the Los Angeles Times children “huddled together, tears streaming down their faces,” because they believed that their parents were dead. Natalia Cornelio, an attorney with the Texas Human Rights Project, told CNN about a Honduran mother whose child had been ripped away from her while she was breastfeeding. “Inside an old warehouse in South Texas, hundreds of children wait in a series of cages created by metal fencing,” the Associated Press reported. “One cage had 20 children inside.”

About 65 million years ago, shortly after the time of the dinosaurs, a new critter popped up on the evolutionary scene. This “scampering animal,” as researchers described it, was likely small, ate bugs, and had a furry tail. It looked, according to artistic renderings, like an especially aggressive New York City rat. And it had a placenta, an organ that grows deep into the maternal body in order to nourish the fetus during pregnancy.

The rodentlike thing would become the common ancestor of the world’s placental mammals, with descendants that include whales, bats, dogs, and humans, among many other species. And today, the placenta might hold the key to one of the most enduring mysteries in human medicine: Why do women suffer much higher rates of autoimmune disease than men do?

Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.

There’s a moment about 15 minutes into the first episode of Years and Years that made me gasp at its audacity, its prescience, its visual horror. The new six-part series from the British writer Russell T. Davies (Doctor Who, A Very English Scandal) charts the life of the Lyons family over the course of 15 years, starting in 2019 and ending in 2034. It’s a kitchen-sink saga that barrels its way through births and marriages and betrayals, but also through the near-future. In 2024, Stephen Lyons (played by Rory Kinnear), a financial adviser, is at home with his wife, Celeste (T’nia Miller), both rushing their way through the morning routine. When the camera turns to their teenage daughter Bethany (Lydia West), her face isn’t recognizably human. Instead, she looks like a 3-D version of a Snapchat puppy, with vast cartoon eyes, wagging pink ears, and a brown snout. When she talks, her voice is grotesquely distorted, a robotic hallucination of a child’s cadence. “I might have to start limiting filter time,” Celeste says in the same exasperated, noncommittal way that you might think, I really should spend less time on Twitter.



Since Amazon announced last year that it is going to build a second corporate campus, cities—238 of them in North America, in three countries—quickly started courting the company. They scrambled to propose the most generous package of financial incentives they could muster, in hopes of luring the online-retailing and cloud-computing giant.

On Thursday, Amazon announced that it had whittled its list down to 20 finalist cities spanning the country, from Los Angeles to Austin to Boston and Miami. What does the future hold for the lucky winner? In Amazon’s request for proposals, it dangled the promise of hiring up to 50,000 full-time employees (at an average salary of more than $100,000 a year) over the next 10 or 15 years, and spending $5 billion in the process of executing the project.

For cities, that means an influx of smart young workers (who then will spend a lot of their paychecks at existing local businesses) and the increased likelihood of long-term economic stability—things that many places want desperately. Indeed, Chicago (still in the running) offered to let Amazon keep $1.32 billion in taxes paid by its own employees. And the mayor of Fresno, California (no longer in the running), told Amazon the company would pay taxes alright, but 85 percent of those taxes would be poured into an “Amazon Community Fund” that would be half-controlled by Amazon’s own executives. Several other cities’ proposals haven’t been made public.

There are no doubt perks to being home to a huge, stable employer. But the way most cities pursue that goal—by offering to forfeit enormous amounts of tax revenues—produces outcomes that have worried many economists for years.

And while the competition that Amazon has put on is unique in its scale and fanfare, forgoing tax revenues is an all too popular way that cities try to attract even much smaller companies. In a 2012 series on incentives, The New York Times concluded that states, counties, and cities provide companies $80.4 billion per year through these arrangements. The practice of luring businesses with incentives such as tax breaks, grants, free land, and low-interest loans has become so ingrained it’s now a rote drill, complete with specialty consulting firms that help companies negotiate such giveaways.

Amazon’s beauty contest commenced shortly after Wisconsin signed a deal with Taiwan’s Foxconn, which makes products for Apple, the most valuable company in history. Wisconsin agreed to provide the Taiwanese firm with up to $3 billion in subsidies in exchange for building a new plant that would employ up to 13,000 people, at an estimated cost to the state of about $230,700 per employee if the deal reaches certain employment benchmarks. (That cost estimate may turn out to be low. The actual total incentives Wisconsin put forward now appear to include hundreds of millions more.)

“Alabama does it. Mississippi does it. Mexico,” an Ohio state legislator said to me one day back in December 2014, speaking of tax breaks and other incentives that aim to convince businesses to move to, or create, new facilities and jobs within their borders.

“But aren’t you just racing to the bottom?” I asked, thinking of dollars that would not find their way to schools, infrastructure, health care.

“We have to do it,” he answered. And he didn’t seem happy about it.  

Jeffry Harris, the chief of the Area Development Foundation of Knox County, Ohio, the umbrella economic-development agency representing county and town governments, is an incentives skeptic who says he has “been watching the Amazon thing with a smirk.” “I have seen communities across Ohio make very lucrative deals to get companies to move into their community and frankly believe those communities many times overpay for that development,” he told me. Local officials want to be seen as doing something to create jobs, and to project a pro-business image. Spreading taxpayers’ dollars to prospective businesses is one easy way to do it.

But Harris believes that’s unsustainable. Better, he argues, to put more effort into community development, the school system, the workforce, the roads: “What are we doing to address the overall aesthetics of our community so when I get a Lansing, Michigan, guy coming in, downtown looks sharp? If I have a plant manager who comes through with his wife, and she says, ‘This place is terrible,’ we’ve lost that opportunity.”

Harris does not eschew all incentives. He’s written six tax-break deals for companies that, for example, want to move to town and rehab an old building. But he avoids those that seem more interested in an incentive package than in becoming part of the community.

The question of whether, or how much, incentives actually spark a community’s economic growth is still unsettled. That’s partly because coming to any bottom-line answer is extremely difficult given all the possible variables in any scenario. “The overall conclusion is that effectiveness is there,” says Peter Fisher, a professor emeritus at the University of Iowa and the research director of the nonprofit Iowa Policy Project. “But it’s pretty small, and small enough that incentives end up being a very costly strategy.” In his opinion, far too many state and city boosters indiscriminately spray financial giveaway packages, which ends up costing them more than it should.

Fisher points to the example of Iowa, which has succeeded in drawing tech giants such as Google, Facebook, Apple, and Microsoft into its borders. It has given away generous incentive packages to support the creation of server farms. But such facilities can sometimes employ fewer than 100 people once they’re built, meaning the state and communities effectively pay hundreds of thousands of dollars per job gained.

“That makes no sense,” Fisher says. “It really does nothing for the high-tech sector in Iowa—it’s just a name on a big building.” The main reasons tech giants have built those farms is not the incentives. Rather, it’s Iowa’s abundant, cheap energy (thanks partly to the growth of wind power), lots of land, and few natural disasters.

Fisher notes that whether it’s a server farm, a manufacturing plant, or a new headquarters, states and communities often neglect to consider, or fail to publicize, ancillary costs beyond the actual incentives. In 1983, for example, after the little town of Wellston, Ohio, and the state, used tax breaks to attract a Jeno’s frozen-pizza plant from Minnesota, the town’s sewer system nearly collapsed while handling 400,000 gallons of pizza-ingredient sludge emerging from the factory. So the state had to use a federal block grant of over $500,000 to bail out the company and the town.

Most secondary costs are more prosaic. New business brings new growth and demands, which may be a net good, but also include costs like new roads, more children in the school system, more housing, more waterworks. All that has to be paid for, and when tax revenues are cut via incentives, there’s less money to pay for it.

And incentive deals can go sour in more dramatic ways. Companies have a long history of reneging on promised jobs and development, and states can fail to include strict job targets in their packages. Louisiana, for example, has lost over 36,000 manufacturing jobs even as it continued doling out expensive incentive packages. Chiquita Brands was seduced away from Cincinnati to Charlotte with a $22 million package including rebates on state payroll taxes, and millions in grant money. Three years later, it moved out of Charlotte, leaving city leaders to question the whole idea of incentives.  

Even those who aren’t so skeptical of incentives are aware of their limitations. The truth is, local and state tax structures aren’t really so critical to most businesses, especially large ones, for which such taxes can be a relatively small part of their total costs. “Economic development is a useful tool, but I would never advise a company to use economic incentives to ID a longlist of candidates,” says Josh Bays, a principal at Site Selection Group, a location-advisory firm. He likes incentives, and takes a dim view of academic research suggesting they don’t do much to improve the lives of cities. Even so, he advises clients to consider more-important attributes of a location, such as transportation costs, raw-materials availability, and the size and quality of the area’s workforce, before thinking about incentives. Only then should they be used to break a tie between one or more finalists.

The present state of affairs is exactly what policymakers in Washington, D.C., were worried about 21 years ago. “We’re here to talk about a war, an alleged war among states and localities right here in the U.S.A.,” Alice Rivlin, then the Vice Chairman of the Federal Reserve Board, said in her keynote address at a conference about the issue in the spring of 1996.

The conference was sparked by a 1994 essay, “Congress Should End the Economic War Among the States,” by two Minneapolis Fed staffers, Arthur J. Rolnick and Melvin L. Burstein. “While states spend billions of dollars competing with one another to retain and attract businesses,” Rolnick and Burstein wrote, “they struggle to provide such public goods as schools and libraries, police and fire protection, and the roads, bridges and parks that are critical to the success of any community.” America is one economic family, they argued, and unseemly competition to attract new businesses, or to retain existing businesses located within any particular state or city, “undermines the national economic union.”

One advantage of the American system, with powers divided between states and a national government, Rolnick and Burstein pointed out, is that states are free to compete with each other by trying different taxing and spending allocations. For example, one state may tax a bit more and provide more public goods—better schools, cheaper health care, smoother roads, more-pleasant parks—in return. Another state may tax less, and spend less, on such public goods. People and businesses could then choose where they preferred to live and locate. Those choices, in theory, help select which balance of taxing and spending emerge as the best.

But this competition is perverted when it’s applied to individual corporations. If one state fends off a poaching attempt by another state by offering bigger payouts, Rolnick and Burstein wrote, “competition has simply led states to give away a portion of their tax revenue to local businesses; consequently, they have fewer resources to spend on public goods, and the country as a whole has too few public goods.” If a state successfully draws a business into its borders through tax benefits, they go on, “there will be fewer public goods produced in the overall economy because, in the aggregate, states will have less revenue.”

Rolnick and Burstein believed there was a solution to all this: federal legislation. Congress, using its power to regulate interstate commerce, could change the way relocating companies get taxed (taxing them based on the estimated value of the benefits, perhaps) or threaten to withhold federal funds from states that try to poach businesses by offering to give up taxes. What with 238 cities having vied for Amazon’s favor—and Amazon now having made a show of narrowing its list down to 20 cities—such legislation seems mirage-like at the moment.



Federico Marques feared the worst for his farm as he watched live coverage of Hurricane Harvey ravaging fields across the Gulf Coast and inundating every pocket of Houston.

Marques was trapped at home during Harvey and could only monitor his crops from his couch, anxiously viewing footage from the farm’s single working indoor camera. “We couldn’t get in here for four days,” Marques said as he showed me around on an unseasonably warm afternoon this November. “I’m looking at all these aerial photos and thinking, ‘Oh my God, everything is underwater.’ When we finally got back, we had 10 inches of water on the floor—but we only lost maybe 5 percent of the product. The rest was perfectly fine.”

In a way, Harvey was a test for Moonflower Farms. Founded by Marques in December 2015, it was one of the state’s very first indoor “vertical” farms—where plants are stacked in trays on shelves, instead of laid out horizontally across larger plots of land. In these high-tech structures, plants don’t rely on sunlight or soil, rainwater or pesticides, but LED lights and minerals instead. The goal of vertical farms isn’t just to save space; it’s also to find a more economical way of producing food for the growing population—and to reduce the costs and consequences of getting that food to where people actually live.

Moonflower is in an industrial area about 15 miles south of downtown Houston, tucked away inside a relatively small, unassuming white shack. The small farm is housed in a 900-square-foot room with a 14-foot ceiling. There are hot-pink lights and a small irrigation system quietly feeding 20 varieties of micro-greens, which sprout up from a mineral-based substitute for soil called vermiculite. In Marques’s growing room, everything from the temperature to the lighting to the watering schedule has been engineered to replicate conventional outdoor farming, but without all the interruptions that plague it: seasonal changes, droughts, bitter cold, fires, and, of course, floods.

Houston has developed other vertical-farm concepts in the past two years. There’s Space City Farms, a backyard aeroponic vertical garden; Dream Harvest, a hydroponic system similar to Moonflower; and Acre in a Box, a literal take on the operation housed in a shipping container.

Acre in a Box’s founders—Andrew Abendshein, who works for an oil and gas trading firm in Houston, and Ana Buckman, a Rice University languages and creative-writing instructor—had no background in agriculture when they invested $80,000 in their first shipping-container farm. Abendshein said he has long had an interest in getting fresh produce to urban food deserts and hopes to one day start moving shipping-container vertical farms into those neighborhoods. For now, though, Acre in a Box’s two farms are hidden in the parking lot of an abandoned drill-bit factory at the end of a dead-end street in Houston’s East Downtown, a few blocks from where Houston’s two largest bayous intersect.

Harvey, and the deluge it brought, are exactly the kind of scenario that vertical farms are designed to withstand. Catastrophic flooding events like Harvey are only expected to become more frequent, and threats of food and water scarcity are projected to worsen in the years to come—all as the population grows. The United Nations projects that the world’s population will be 9.8 billion by 2050, with roughly two-thirds of those people living in urban areas, which aren’t exactly conducive to large-scale farming.

To meet the growing demand for food, the UN’s Food and Agriculture Organization estimates that there needs to be a 50 percent increase in global agriculture production—a distinct challenge, the UN warns, in the face of climate change and the growing need for water conservation. Vertical farms present a potential solution: There is no fertilizer runoff into the groundwater, fewer CO2 emissions from delivery trucks’ long journeys, and no land to till. They require only a fraction of the acreage and use only a fraction of the water—anywhere from 90 to 97 percent less—that traditional farms do.

“We are kind of at the beginning of a revolution,” Per Pinstrup-Andersen, a graduate-school professor at Cornell University’s College of Human Ecology, told me. “We’re at the beginning of a very rapid development in the use of indoor controlled facilities for producing vegetables and some fruits,” he said. “No matter what happens with climate change, you still have your controlled environment.”

The technology used for these farms has been around for decades. In fact, Marques began studying it in the 1990s after learning that NASA used it to grow plants in space. But only in the last several years has interest in using the technology for urban, commercial-scale agriculture picked up. Indoor farms have recently sprouted up in old warehouses, shipping containers, and small skyscrapers in New Jersey, South Korea, Germany, India, and Dubai—places where traditional farming is either difficult or impossible due to climate, population density, or the land itself. In Houston, sprawling commercial and residential developments were built on top of a swamp, making large-scale outdoor farming virtually impossible.

Marques and I hopped in his minivan and headed about a mile away from his garden to the site of the Moonflower Farms expansion, where men in hard hats were surveying the land. The new facility doesn’t look like much yet—just a large elevated mound of dirt with metal poles sticking out of it. But by the time it’s operational, Marques plans to have a 20,000-square-foot greenhouse that he expects will churn out 1,000 pounds of produce per day—compared with the 20 pounds that his tiny facility produces now. He currently sells to a couple dozen restaurants but plans to expand to regional and national distributors and local grocers once the new facility is up and running.

The elimination of long, cross-country transports to get the produce to grocery stores means consumers wind up with fresher food. Right now, Marques said, the time from harvest to table is sometimes only a matter of hours, which means that produce arrives in better shape and then lasts longer both in the store and in people’s homes. “If we can make this work in the city of Houston and produce 1,000 pounds a day or more of product—high-quality product that has three times the shelf life—then we have a good model that we can pretty much [take] to any city in the world and replicate,” Marques said.

The new greenhouse will operate like a research-and-development facility, helping Marques perfect a prototype that interested farmers around the world can use as a template. He already knows that he’ll need to make some changes. For starters, he’s not going to rely exclusively on LED lighting as he does now; instead he will mostly use sunlight, plugging in energy-efficient lighting as a supplement—a measure that will cut costs significantly. Marques said he has already had inquiries about this model from a food distributor in Cairo, where the arid climate and heavy reliance on imported crops make the food supply unpredictable. Marques says he has also talked to strawberry growers in Norway, where thousands of metric tons of strawberries are imported every year due to the short growing season. And he has heard from cattle farmers in Brazil, where the shrinking availability of pastureland and prohibitions on razing rainforests mean that some farmers may need to import grass to feed their cows.

Cutting the costs of building and maintaining the systems themselves will be crucial as vertical farms continue to evolve, according to Henry Gordon-Smith, the co-founder of the international Association for Vertical Farming and a consultant at the New York–based firm Agritecture. As a result of high costs, Gordon-Smith said, several vertical farms in North America have failed in recent years. That’s what happened at LocalGarden, a rooftop vertical farm in Vancouver that went bankrupt in 2014, and at PodPonics, a shipping-container vertical farm in Atlanta, where high labor and technology costs were consistently undermining return on investment.

Mike Nasseri, who was the harvest supervisor at LocalGarden, said that design flaws had inflated the endeavor’s operational and energy costs to the point that the farm couldn’t make enough money. Even though the farm had started small, Nasseri said the crew decided to scale up too quickly to a commercial operation. To make matters worse, Nasseri said, the costs of the real estate in the middle of downtown Vancouver—a central location he said he would not recommend for new vertical farmers —were way too high. “That placement [in the middle of downtown] is basically the first way you can screw up,” Nasseri said.

Still, he’s a major proponent of vertical farming, primarily because of its environmental benefits. He’s now working at a startup called Ava Technologies, developing indoor “smart gardens,” essentially mini vertical farms that can fit on kitchen counters.

Gordon-Smith said the industry-wide goal going forward has to be to minimize the risk of failure, financial or otherwise, as much as possible in order to make vertical farming more accessible to the younger generation of produce growers, who have been moving steadily away from rural areas and toward cities over the past few decades. Still, he said, the failures serve as lessons for new investors as they continue to develop various types of vertical farms.

Like Marques, Abendshein, the founder of Acre in a Box, was stuck at home monitoring his produce from the couch during Harvey. But he knew he could rest assured that, as the waters raged, his produce was safe. Without land that could be ruined for an entire season, the worst that could happen, he thought, was that his farms would float away.



In the mid-to-late 1800s, shoppers interested in purchasing many everyday products—from flour to crackers to pickles—usually had to ask store attendants to fish what they wanted out of a barrel for them. Customers would then transport their goods home in a cloth sack, a paper bag, or wrapped in paper.

Shortly after the turn of the century, the burgeoning field of marketing brought consumer products out of barrels and into individual jars, cans, tubes, and other containers emblazoned with corporate iconography. “Branding really led the way towards packaging that looks the same in Des Moines as it did in New York City,” says Sean Riley, a spokesperson for the trade group PMMI, which used to stand for the Packaging Machinery Manufacturers Institute.

Today, as people buy more and more products online, product packaging is again changing, in a way that reflects the differences between digital and physical retail: Anything bought online needs to be able to withstand being shipped individually, often necessitating extra plastic coverings. And on the internet, it’s images of products themselves, not their packaging, that usually show up in search results, which makes the visual appeal of any box or label a lesser concern than it once was.

Founded: 1963

Based in: Oak Brook, Illinois

Readership: 65,000 average monthly unique visitors

Primary competitor: Packaging World

Most-read article of 2017 (so far): “Amazon on creating ecommerce packaging that’s great for all”

Lisa Pierce is watching developments like these closely. She is the editor of Packaging Digest, a trade publication, and has been covering product packaging for about 35 years. She says her magazine’s purview is the packaging of “basically any product you can buy in a store.”

I recently talked to Pierce for “Tricks of the Trade,” a series of interviews with the editors of trade publications, and asked her about how online retail is changing product packaging, as well as how much packaging is too much and how she’s seen the industry change over three and a half decades. The conversation that follows has been edited for length and clarity.

Joe Pinsker: When you walk into a store, what do you notice that you think most people wouldn’t?

Lisa Pierce: There are a couple things. The first is when there’s a new packaging format for a product. I can look at a package on a shelf and pretty much guess how it was packaged. Sometimes that’s where the innovation is: on the production-machinery side of things, not necessarily on the physical-package side of things. For example, dairy beverages are typically sold in the refrigerator section because they’re dairy-based, right? But one company came out with a dairy-based beverage that was shelf-stable, meaning that it did not need refrigeration. Consumers expected dairy to be in the cold section, so they still put it there, but they were able to save immensely on the nonrefrigerated distribution, the shipping of it, because it didn’t need to stay cold.

The other thing I’m a little bit more aware of than some consumers is whether packaging is necessary or excessive. A lot of consumers, they just see layer upon layer of packaging without realizing the reasons behind it. There’s usually always a reason why a product is packaged the way it’s packaged. Sometimes it’s not necessarily a good reason, but there’s always a reason.

Take a skin-care product. I’m the right demographic for anti-aging skin-care products—that’s the polite way of putting it. And the majority of them, especially the higher-end products, are usually in a jar or a bottle, and then that is placed into a carton, and that’s how it’s sold. Do we really need the carton? Well, there are a couple of reasons why we really might need that carton: to communicate information a customer would want about the product, to contain an anti-theft tag, to cushion the jar during shipment. Also, when you’re looking at something on a shelf, if it’s round, you’re only seeing a portion of the front, whereas if it’s a square carton, you’re seeing the entire front panel. That has better merchandising—they call it “billboarding.” So overall, you need the carton, but a lot of consumers, they’ll open the carton, take out the jar, and think to themselves, as they’re throwing away the carton, “Why did they do that? All I’m doing is throwing it away.” But there are all those other considerations.

Pinsker: I get what you’re saying, but at the same time, I can think back to a time when I ordered a book online, and it came in this box that was three times the size of the book, and it also had all these packets of sealed air. Am I misunderstanding what the considerations are there, or is that an example of truly superfluous packaging?

Pierce: Well, in that particular instance, that definitely is over-packaging. However, there are things that have happened that will make that a problem of the past. In shipping, there’s something called dimensional weight, also known as “dim weight,” and it is a new pricing standard by UPS, FedEx, and the United States Postal Service, where they measure the size of the package, as well as its weight, to determine how much it’s going to cost to ship—packages that are big are going to cost more. So it’s to the benefit of everyone involved for the packages to be just the right size.

Pinsker: You’ve been following the industry for several decades. What are the most striking differences in how products are packaged between when you started and what you see now?

Pierce: Mostly how the variety and creativity of packaging has changed. We’ve had a lot of new types of packaging come up. Tuna in a pouch was a huge disrupter: You didn’t need a can opener and you didn’t need a spoon, really. With a pouch, you just tear it open and shake the product out. It was portable—you could take it to work with you and open it at your desk.

That was a major one that even the consumer would notice, but there are other ones that are a lot more subtle. In the ‘90s, we saw single-serve plastic bottles of milk, instead of those little cartons that nobody could ever open. That change really captured the on-the-go portability needs of consumers, which wasn’t just about food. Now there are these little nubby things that go on your finger, and you can “brush” your teeth on the go. That trend has continued—people want to be able to carry and consume products wherever, whenever. That’s a big change from when I started covering this. We’re just too busy these days.

Pinsker: Has packaging changed in response to online retail? I would guess that the needs are different when a product is sitting on a shelf, versus appearing in a set of search results. For instance, I just bought a pair of earbuds online, and I was looking at the earbuds themselves when I shopped, not the package they came in.

Pierce: Sure, so in e-commerce the design is not as important for the sale, but I would make the argument that it is still immensely important for the resale—getting a consumer to buy it not once, but twice or three times—because of the impression that the primary pack design has on the consumer when they receive it. But, I have to ask you, when you got those headphones at home, what was the packaging like?

Pinsker: They showed up in a little cardboard box that looked like it could have been on any sort of rack at an electronics store.

Pierce: Did that add to your experience? Or did it not matter to you at all? If you had just gotten the buds in a baggie, would you have been fine with that?

Pinsker: That is a really good question. It’s probably more a question for my subconscious brain than my conscious brain. But my conscious brain says I do not care, and that I would have happily taken whatever—as long as it arrives intact, I am happy with the thing that uses the fewest materials.

Pierce: Most people, I think, would be quite happy with no packaging, if they spent, like, $5.99 on a pair of earbuds. But if you were spending $35.99, I think you might feel like, “Wow, these are pretty cheesy for $35.99.”

Pinsker: So in a way, the packaging kind of becomes part of the product that you’re buying.

Pierce: Yes. Well, it becomes part of the experience.

Pinsker: What other ways has e-commerce influenced product packaging?

Pierce: I have to say, anytime we do an article and we have the word Amazon in the headline, the pageviews just go off the charts. Everybody wants to know, what does Amazon want in packaging?

So obviously Amazon is huge in e-commerce, and they’re being very active now in communicating some of these packaging needs and wants to their product vendors. One thing is the folks at Amazon admit that the aesthetics don’t matter as much when products are being sold online; the way one Amazon manager said it to me was, “Many of the fundamental design features for packaging in traditional retail are far less relevant online.” You know, nobody in the packaging industry wants to hear that the packaging is not important, because we don’t feel that way. But at times, it isn’t. And e-commerce could be one of those times.



During the winter of 2017, an 18-year old college student named Canon Reeves spent much of his time trailing a knee-high robot around Fayetteville, Arkansas, as it delivered Amazon packages to students. The robot, created by a start-up called Starship Technologies in 2014, is basically a cooler on wheels; it uses radars, ultrasonic sensors, and nine cameras to make deliveries. Reeves’s job was to monitor how it handled various terrains, field comments from the public, and press the off switch if necessary. He also took photos; many students asked for selfies with the bot, he said. “People would also ask if it could deliver beer.” It couldn’t.

As advances in autonomous technology have placed a huge number of self-driving machines on our roads and sidewalks, a side hustle has materialized in recent years: robot-babysitting. In Phoenix, human attendants will remotely monitor Google's upcoming Waymo robo-taxis, using the car's cameras to evaluate and adapt to passenger or road challenges. State safety regulations typically require that autonomous vehicles be accompanied at all times by humans. These professionals’ job titles range from “robot handler” to “safety driver,” but they have essentially the same responsibilities: monitoring robot behavior for safety and performance, and answering questions about the technology.

The unusual nature of the job lends it some cachet, despite the mundane nature of the work itself. (Job requirements posted by the driverless-car start-up Cruise Automation include: “Able to drive or spend time sitting in a car for six to eight hours a day.”) “I’ll tell my grandkids someday!” Reeves told me. The pay is good, too. Starship Technologies starts its robot handlers at $15 an hour, and Cruise pays $23 an hour, more than double California’s minimum wage of $11. Still, many of these above-minimum-wage jobs aren’t likely to be around for too much longer.

Broadly speaking, robot-babysitting jobs fall under the umbrella of careers in automation, which include maintenance, engineering, and programming. The demand for people with this skill set is considerable, with an expected 20 million to 50 million new jobs expected in this category by 2030, according to the McKinsey Global Institute. In the year that ended in June 2018, the number of postings on Indeed.com’s recruitment boards advertising positions in automation had almost tripled since the year ending in June 2016.

Automation workers include computer scientists, IT workers, and administrators. “Those people are in scarcity, and there’s an extreme demand,” Mike Ramsey, a research director at Gartner, said. But they also include less skilled workers—college students, like Reeves, or others without a degree. As autonomous technology gets more sophisticated, Ramsey expects to see a bifurcation of demand for these robot-keepers. Even as demand increases more technical roles—AI analysts, systems testers, and vehicle technicians—advances in tech and loosening legislation will lessen the need for blue-collar robot roles, like Reeves’ job with Starship Technologies. “We are in this squishy period where the human has to be heavily involved in testing, and that is likely to end,” Ramsey said.

In some cases, companies have already managed to get rid of their robot babysitters. Over the last year, a 34-year-old entrepreneur named David Rodriguez spent hundreds of hours following a machine called the KiwiBot around UC Berkeley’s campus while it delivered Soylent, Chipotle, and Red Bull to students.

Created in 2017 by a group of Colombian entrepreneurs at Launch, an accelerator program based at Berkeley, the KiwiBot exhibits Pixar-like sensibilities. To retrieve orders, the app prompts students to give the robot a thumbs-up or a wave; the bot’s digital eyes will wink or roll depending on its mood. Rodriguez, who heads business development for the start-up, was tasked, early on, with monitoring the KiwiBot for problems—even carrying it, should the motors fail. Since April 2018, though, the KiwiBot has been largely babysitter-free, and the majority of human interactions involve technical checks and loading food into the bot. To eliminate that grunt work, the team is developing a restaurant robot to collect and load orders—which could happen as soon as 2019. However, Rodriguez assured me that his staff won’t be out of work. Everyone holds dual roles in the company; greater bot autonomy just means employees will shift their focus to accounting, engineering, and design.

Some observers note that certain kinds of robot-babysitting—the kind that is monotonous and doesn’t require much education—can make for thankless work. The safety drivers who sit in self-driving cars have described their roles as “exhausting” and “demanding,” and many told me about the constant pressure to stay hyper-alert at all times. “It’s incredibly hard to sit in a chair and stare at a computer without doing anything for eight hours,” Ramsey said. “But you do not need a Ph.D. to do it.” In March 2018, the field of robot babysitting took a beating when a self-driving Uber in Tempe, Arizona, hit a 49-year-old named Elaine Herzberg. Dashcam footage showed that Rafaela Vasquez, the car’s safety driver, had not been looking at the road when the accident occurred. Investigators are deciding if Vasquez will face manslaughter charges.

Following the accident, a number of executives began pushing to shelve the program altogether, according to the New York Times. Uber suspended all its self-driving tests in the United States, and many of its 400-plus test drivers had to scramble for work. In May, it laid off all Arizona safety drivers, followed by more layoffs in July in Pittsburgh and San Francisco, which dropped Uber’s total test-driver pool to about 55 people. Despite this, Uber said testing will resume this summer and is actively recruiting self-driving-truck drivers and autonomous-vehicle engineers. “Our team remains committed to building safe self-driving technology, and we look forward to returning to public roads in the coming months,” said an Uber spokeswoman.



Robot babysitting was the first job that Jordan Zagerman, 21, ever held. In 2017, while completing an associate’s degree at San Francisco State University, he followed a delivery robot around San Francisco’s Parkmerced neighborhood, supplying condoms, chips, and soda on demand on behalf of a company called Dispatch. He also managed Dispatch’s Snapchat account and designed branded sweatshirts. Then, after four weeks, came the “it’s not you, it’s me” email. “Over the weeks, people were progressively less surprised with the robot,” he said. “Every robot handler was let go.” The experience convinced Zagerman that he needed to better prepare himself for the future. That fall, he moved to Philadelphia to start a bachelors degree in user-experience design at Drexel University; when he graduates, he hopes to return to Silicon Valley, but this time for a more white-collar, technical position. “I left,” he told me, “to make sure I wouldn’t get phased out with autonomy.”

McKinsey estimates 10 million to 800 million jobs globally could be lost to automation by 2030. In the long term, it’s inevitable that robot-babysitting gigs will go the way of elevator operators and lamplighters. But they’ll also birth new robot-related roles. “A huge number of jobs will be created as autonomous vehicles are loosed into the environment,” Ramsey said. In 2016, Bosch started training students from Schoolcraft College, a community college in Michigan, in autonomous-vehicle repair; Toyota has trained students in maintenance as well. “We might even see a return to low-level jobs where people come and fuel the car for you,” Ramsey said. “Until we can wirelessly charge, someone needs to refuel them.” The hardest-to-automate industries, as it happens, are the ones that require looking after humans: childcare, education, health-care aides. Robot babysitters might feel like they have scored the job of the future. But in fact, real babysitters might be better positioned.



The Dow Jones Industrial Average plunged more than 1,000 points on Monday. This was the largest nominal decline in the history of the index, and the first time that the Dow has lost more than a thousand points in a single day of trading.

This means the Dow suffered its first-ever four-digit point loss just hours after the Super Bowl witnessed its first-ever four-digit offensive output. I am not suggesting causality here—I am insisting on causality here.

That’s a joke. But it’s no more serious than many of the attempts to explain the daily gyrations of the stock market, a public synthesis of millions of investment decisions by millions of people reacting to myriad news stories while guessing at the trading behavior of strangers they will never meet. Stock nosedives such as this create a vacuum of chaos and confusion into which creative theories flood, often unhelpfully. For example, CNBC hosts reportedly suggested that the market was “testing” Jerome Powell, the new chairman of the Federal Reserve. It seems unlikely that institutional investors coordinated a trillion-dollar pop quiz for Powell, just to test his reflexes.

There is a less creative explanation: There are some large-scale investors (such as brokerages with large accounts) that are nervous about incipient inflation due to clear signs of strong wage growth. These investors are also concerned that the Federal Reserve might raise rates, thus making it more expensive for companies to borrow and invest money. Higher inflation, higher wage growth, and less corporate investment would mean smaller profits for corporations. Since the stock market is fundamentally a collective bet on the future profitability of publicly traded companies, these factors would altogether predict that investors would be willing to pay less to own a share in a typical company than they were a week ago.

This shows that, unfortunately, Wall Street and Main Street do not always move forward in tandem. The stock market has soared in the last nine years, as slow wage growth has constrained labor costs for large corporations. But when wages rise quickly, that can threaten to eat into corporate profitability. On Friday, the Bureau of Labor Statistics reported that annual wage growth hit 2.9 percent, its highest figure of the current expansion. Hours later, the Dow dropped precipitously.

Monday’s decline will certainly be terrifying to some investors, particularly if they just recently got into the market. Trading activity on the website E*Trade in November and December represented two of the three best months in the company’s history, suggesting that many retail investors have piled into the market recently. Monday was a scary day for them, as well as anyone who was planning on soon cashing out any retirement savings they’d stockpiled in the market.

But there are severals reasons to withhold panic. First, while this is the largest points decline in Dow history, there have been several worse days in the last 15 years by percentage terms, including September 17th, 2001, and September 29th, 2008. Second, even after Monday’s fall, the index is still higher than it was in November 2017.

The Dow Jones Industrial Average, February 2015–February 2018

Third, and most importantly, this has been one of the most astonishing bull markets in stock-market history. Since March 2009, the Dow has almost quadrupled in value. More recently, its historic last 12 months has been driven by a strong global economic expansion that should continue. As Michael Cembalest, the chairman of market and investment strategy at JP Morgan, told me last fall, “The percentage of countries in major expansion mode is about as good as it can get.”

Finally, President Trump has insisted that the economy is a flawless report card that validates his tumultuous term. But the last two trading sessions demonstrate perfectly why it’s so dangerous to attach any presidential reputation to economic indicators. The thing about the stock market is it goes up and down, sometimes by eye-popping margins, and the president almost always has nothing to do with the final figure.



Editor's Note: This article is part of Exit Interview, a series of conversations about leaving one’s career.

In 2014, Gordon Rothman, a multimedia producer who worked in TV news, lost his job at CBS in a mass layoff. He didn’t sit idle. Rothman had already been volunteering for Gatewave, a radio reading service for the blind, and became the nonprofit’s executive director. He saved the group from financial ruin, earning the title “New Yorker of the Week” from local news. But Rothman, who was in his late 50s, couldn’t support his family by volunteering. Despite picking up new skills and landing freelance work with big publishing houses, a full-time job remained elusive.

The share of older Americans in the workforce is growing: By 2024, 25 percent of workers will be 55 or older. But despite rules against age discrimination, ageism in recruiting and in the workplace crops up in subtle and not-so-subtle ways, from targeted job placements online to some corporations’ shunting out older hires to hit the “correct seniority mix. Of course, being young sometimes can hurt job applicants too: When Rothman’s daughter was let go from her entry-level job in her early 20s, she also had trouble finding work with reasonable wages and benefits.

I spoke with Rothman for The Atlantic’s series Exit Interview to learn how he adapted. The conversation that follows has been edited for length and clarity.

Catie Lazarus: You worked at CBS for decades. Did being part of a mass layoff help cushion the fall?

Gordon Rothman: The layoff was probably the least embarrassing part.  It was one of these terrible conference-room events. Twenty people at the same time all being told by the head of CBS News, trailed by two human-resources personnel. I was assured that this was nothing personal; I hadn’t screwed up. You don’t take that personally.

Lazarus: How soon did you find new work?

Rothman: After losing that job, I volunteered full-time as the executive director of Gatewave, a radio station that serves people who are blind or visually impaired. I thought, “This is really my opportunity.” Gatewave was in a death spiral—it owed a lot of money. I got us out of debt, to a place of sustainability. But it wound up not leading me anywhere. After two years volunteering full-time, there still was not enough money to pay me. I returned to media production. I landed a full-time freelance gig in February, but the assignment only lasted a couple of months. I am freelancing now, but there is not enough of it. It is seasonal.

Lazarus: How do you fit decades of experience into one page for a resume?

Rothman: Good question. I drew up a summary of the kinds of skills and projects I worked on and backed it up with real job titles. But, so often, I see signs that they’re looking for someone younger.

Lazarus: Like what?

Rothman: Ads ask for “digital natives” and people who “live, eat, and dream social media.” On occasion, I get past the anonymous algorithms of an online application and actually score a meeting, but experience silence afterwards. Companies get advice like “Hire someone on the way up, not on the way down.” I am probably not on the way up. People tell horror stories of hiring managers trying to bring in someone “over 50.”

Lazarus: How does ageism play out when it’s face-to-face?

Rothman: No one says to your face, “We thought you were 35.” I’ve had some interviews that seem like perfect fits, then someone else gets the job. They never tell you you are too old.

I am experienced. I have heard that my resume is impressive a lot; I expect that I will find something.

Lazarus: What do you think is behind ageism?

Rothman: The assumption is that the greater energy, drive, and willingness to work will come from younger applicants, and higher health-care expenditures are likely to come from older applicants. In my case, I was able to keep my CBS health plan, and will stay on it, so I wish I could jump in and say, “You don’t have to worry how much my health care would cost.” That may not be at the forefront of the recruiters’ minds, but it is there somewhere.

Lazarus: How do you deal with the frustration of being ready, willing, and able to work while work remains elusive?

Rothman: I want to be making audio and video projects that feel challenging and worth doing, but whatever it is, I will throw myself into it. Being “betwixt and between,” one of my favored euphemisms these days, is tough on the self-image. I know all the ways I could be valuable, but I’m not put to work on them. If you don’t manage to re-insinuate yourself, it is kind of embarrassing. For a lot of years, I was happy to identify with my work, even if I often had to explain to people what it meant to be a television producer. I miss the all-hands-on-deck election-night coverage. CBS created new job titles for me because my boss knew I could do whatever needed to be done.

Lazarus: Any upsides to the time off?

Rothman: It gave me a chance to throw myself full-time into a project, running the radio service for blind and visually impaired listeners. I was able to pry the project out of debt and make it sustainable. And having a sporadic working schedule has permitted some great trips and extracurricular projects—a week of biking around Italy, building a raised-bed garden—and I play piano daily.

Lazarus: Your daughter is in her early 20s, and is also looking for a job. What is it like undergoing this together?

Rothman: I am hoping we both get jobs, but the nature of today’s job environment makes it a challenge for both of us. At her age, she is finding employers do not want to hire her directly or pay her basic wages or benefits, so it can be frustrating.

Lazarus: Has it brought the two of you closer?

Rothman: There are parallels, and there are disconnects. She is living under our roof. She hears my nudging her on expanding her horizons for her work search more than she would like, I am sure. I wish I could approach that from having a full-time job of my own. I have a couple feelers out, so I don’t feel I am at the end of my rope.

Lazarus: Now that you’ve been freelancing, have you given up looking for a full-time job?

Rothman: I’d take the right full time-time job or full-time freelance opportunity, if there is enough of it. But I’ve spent the last year directing audiobooks and launching my own business, AuthorDirect Audio, to coach authors who record their own books. I have not let ageism defeat me.



On a recent sunny summer morning, Ben Roueche pulled into the parking lot at the corporate headquarters of HomeAdvisor, in a suburban office park near Denver. Once inside, Roueche, wearing jeans and a T-shirt, sat down at a desk, logged on to his computer, and started resolving support tickets submitted by HomeAdvisor employees seeking help for everything from password resets to problems accessing the company’s internal phone system. At one point, Roueche paused to chat with his supervisor about establishing a setup procedure for a new video prototype that some executives will soon begin using.

Ben Roueche is 17; he just finished his junior year of high school. For the past year, he has spent three days a week attending classes at a charter high school and two days a week working on the desktop-support team at HomeAdvisor. Earlier this summer, Roueche started working at HomeAdvisor three days a week, a schedule he’ll maintain throughout his senior year.

Roueche belongs to the inaugural class of apprentices in a Colorado program, started last summer, called CareerWise. It represents Colorado’s attempt to create an unusual, statewide youth-apprenticeship system. “This program has more scale than almost any other broad apprenticeship that I know of,” Harry Holzer, a public-policy professor at Georgetown University, told me. Its goals are ambitious: CareerWise’s founders are trying to both prepare today’s youth for well-paid jobs in the industries of the future and to change a culture that insists every 18-year-old should graduate high school and go straight to college.

CareerWise is the brainchild of Noel Ginsburg, the founder of a Colorado-based advanced manufacturing company called Intertech Plastics. Ginsburg visited Switzerland, which has a widely admired youth-apprenticeship program, while serving as the chairman of the Denver Public Schools College and Career Pathways council.“What I didn’t expect is that apprenticeship isn’t just for construction—they have over 250 pathways there, everything from manufacturing to banking,” Ginsburg told me. “Seventy percent of kids there enroll in apprenticeships instead of going directly to college.”

Switzerland’s not the only developed country with a robust apprenticeship program; the model has long been prevalent in Germany and Austria, and both Australia and the United Kingdom have launched initiatives in recent years to increase apprenticeship. Studies of programs in these countries have documented substantial economic benefits for both apprentices and their employees. However, the model remains rare in the United States. Ginsburg was convinced that a statewide apprenticeship program could both help address Colorado’s workforce challenges and widen access to well-paying jobs across a variety of industries not typically associated with apprenticeship.

He sold Colorado’s governor, John Hickenlooper, on the idea, and the two of them returned to Switzerland in 2015, along with 50 others—CEOs of local companies, leaders of school districts and community colleges, and philanthropists—to study the model more closely.

Ashley Carter, CareerWise’s chief operating officer, says the program was designed to duplicate several important components of the Swiss model. The first is that CareerWise’s business partners should receive a return on their investment in apprentices during the course of the apprenticeship. Also, CareerWise’s apprenticeships should increase students’ career options, not narrow them.

“The Swiss have created a youth-apprenticeship system that’s very permeable,” Carter told me. “And by that we mean that students who start an apprenticeship in Switzerland follow any number of paths. They can get a Ph.D., they can go straight into the workforce ... So participating in apprenticeship isn’t a dead end.”

What this means in practice is that if all goes well, at the end of his three-year apprenticeship, Ben Roueche, like all CareerWise apprentices, will have earned: a high-school diploma (on time); up to a year’s worth of college credit (at no cost to him); at least one valuable, recognized industry credential (also at no cost); and thousands of dollars worth of wages ($30,000, on average, among CareerWise apprentices). Roueche, who wants to ultimately work in cybersecurity, may enroll in college full-time, join HomeAdvisor as a full-fledged employee (with eligibility for tuition reimbursement for college), or perhaps go work elsewhere.

“The program’s not intended to say ‘You don’t need a four-year degree’ to everyone,” explains Ginsburg. “At the same time, there are other jobs where you don’t need a four-year degree to be successful. The ultimate goal is to make sure that kids are looking at their educational and career options and asking if that pathway puts them into a career that takes them into the middle class and beyond.”

Expanding apprenticeship in the United States is the rare policy proposal that garners bipartisan support. Earlier this month, Donald Trump signed an executive order establishing a National Council of the American Worker, which will be tasked with, among other things, increasing apprenticeships in the United States; scholars and politicians across the political spectrum have also expressed support for the concept.

There’s good reason for this broad support. While apprenticeship remains quite rare in the United States, evaluations of existing programs have documented impressive results. One evaluation of registered apprenticeship programs in the U.S. estimated that participants who complete their programs will earn about $240,000 more than non-participants over the course of a career. Studies conducted in the U.S. and elsewhere have found meaningful benefits for society and employers, as well.

There are, however, limitations to apprenticeship. The most common critique of apprenticeship—and work-based and vocational learning in general—concerns what’s known as “skill portability,” or whether the specialized expertise learned in a given apprenticeship is applicable in other industries or with other employers. If Roueche chooses to forgo college and later wants to leave HomeAdvisor, or move to a different state, will his apprenticeship experience be valued by employers?

“In a world where the sectors are dynamic, and a sector that’s in high demand today might not even be around tomorrow, there’s a danger in specializing,” Holzer, the Georgetown professor, said. “What you really hope for is that whatever sub-B.A. credentials people get, that they are portable ... at a minimum across firms, and ideally even across sectors and industries.”

CareerWise’s advocates note they are aware of these concerns and have incorporated a number of elements—namely, debt-free college credit and an industry-recognized credential—that researchers believe can help mitigate these effects. “At the end of the program, this kid has gone through the apprenticeship, and he has the choice,” Hickenlooper told me. “He can keep making money with this credential, or he can go to college with a year’s credit.” He adds, “not only does he not have any debt, he’s probably got $10,000 to $15,000 in the bank.” Colin Dean, a classmate of Roueche’s and a co-apprentice at HomeAdvisor, told me, “In high school, you learn a lot of skills that don’t really apply to real life right now, but here I’m learning real-life skills that I can use now. Also, compared to high school, I get paid.”

Both Dean and Roueche are from economically secure families; their school focuses on STEM. Indeed, apprenticeships have traditionally been disproportionately held by white men. A recent report from the Center for American Progress, a progressive think tank, found that last year, women made up only 7.3 percent of participants in Registered Apprenticeship programs, which are registered with the Department of Labor and subject to labor standards established by the National Apprenticeship Act. The report also noted that both female and African American (male and female) apprentices earned lower wages upon completing their apprenticeship than their white, male peers. This is at least partly a function of the types of industries that women more typically apprentice in: The median hourly wage for electricians, for example, is twice the median wage for child-care workers. The gender wage gap is narrower for women who participate in apprenticeships in traditionally male-dominated fields.

Angela Hanks, an author of the Center for American Progress report, notes that diversity needs to be a focus of the program if equity is a goal: “Apprenticeship is not inherently more equitable than other pathways to employment. There is potential to better engage women and people of color in these programs, but states and programs need to be intentional about hiring, training, and promoting those workers.”

In this respect, CareerWise’s emphasis on industries not typically associated with apprenticeship—financial services and business administration, for example—may reduce some of the gender and racial disparities in access to, and outcomes of, apprenticeship. In the first year, 49 percent of CareerWise apprentices were white, 26 percent were Hispanic, and 14 percent were African American. These demographics roughly correspond with the demographics of the partner school districts (although Hispanics represent a higher proportion of students in the school districts). A significant gender disparity exists, however. Women represented only 39 percent of apprentices, despite representing 49 percent of the student body at participating districts. This appears to be partly because women represented only 35 percent of applicants.

While socioeconomic data on CareerWise’s apprentices was not available, Tanya Jones, HomeAdvisor’s director of recruiting, told me that CareerWise applicants in the first year of the program were unusually high-performing, were highly motivated, and likely already planned to attend college. Roueche builds websites and drones in his spare time; he intends to complete a four-year degree at some point and likely would have done so even without CareerWise. Jones, however, noted that the apprentices who will join HomeAdvisor in the program’s second year are more socioeconomically diverse; several, if they ultimately attend college, will be the first in their families to do so.

CareerWise’s creators and advocates hope the program, which will be evaluated by an independent research firm, will serve as a replicable model for other states; Holzer, Hanks, and other researchers are watching the program closely. “This is more of an attempt to build a system, to really try to reach out to a lot of employers with some scale,” Holzer said. “We should be able to learn a lot from this attempt.”



The quest for ethical clothing production can seem futile. Many in the industry see low pay, unsafe labor conditions, and a host of other indignities commonly associated with garment-factory work abroad as vexing and intractable problems.

For one thing, there are real doubts that consumers’ desire for clothing made in less-abusive conditions could ever override their desire for low prices. Another issue is just how sprawling the global supply chain is—brands can have trouble accounting for every single factory and worker that has a hand in creating a garment. These are some of the things that brands have said can inhibit their ability to increase wages and weed out supply-chain abuses; they have also suggested that it’s up to local governments to establish a minimum wage that covers workers’ living expenses.

One factory in the Dominican Republic stands as a counter-argument to all of this. It’s called Alta Gracia, and it makes clothing, including T-shirts and sweatshirts, for university bookstores and sports teams around the U.S. Alta Gracia pays its workers a living wage in an industry that is notorious for skimping on worker salaries, and was opened about seven years ago by two executives at Knights Apparel, Donnie Hodge and Joe Bozich, with help from labor advocates at the nonprofit Worker Rights Consortium.

I spoke with Sarah Adler-Milstein, who has worked with the Workers Rights  and co-authored the book Sewing Hope: How One Factory Challenges the Apparel Industry’s Sweatshops, about Alta Gracia—why it was founded, how its model works, and what its successes and challenges reveal about the garment industry more broadly. The conversation below has been edited for length and clarity.

Gillian B. White: What was the biggest challenge that came with starting a factory like Alta Gracia that paid workers a living wage?

Sarah Adler-Milstein: It was not hard for any of the traditional reasons. It was actually very hard to try to establish a brand presence based on good working conditions, because you're competing against brands like Nike and Reebok that have quite a bit of market share and name recognition. It's also just challenging to set up factories. But the actual part of paying a living wage and working with a union? Those were the easy parts of the model.

White: So you think that model could be used elsewhere?

Adler-Milstein: Alta Gracia tells a very different story than the conventional one, which says that paying living wages and having decent conditions isn't possible. Alta Gracia shows that if a small start-up can do it, there's absolutely no reason that the Nikes and the Gaps and H&Ms of the world couldn't do it. They've already done the hard work of establishing a brand and setting up factories.

White: When it comes to pay, how much more would it take to get a typical factory worker up to a living wage?

Adler-Milstein: The living-wage premium is only 90 cents per garment. Take a $35 sweatshirt: Conventional factory workers are making less than 50 cents per garment, but at Alta Gracia they get paid just 90 cents more, and that triples wages. Most goods have about a 75 percent markup with both the retailer and the wholesaler, so for a $35 sweatshirt, about $25 of that is just retailer and wholesaler markup. So that 90 cents could easily be absorbed.

White: What do you make of claims that many customers won’t pay more for more ethically made goods?

Adler-Milstein: Obviously you get to a certain point and consumers are no longer willing to pay the difference, but 90 cents is well within the margin of what consumers are willing to pay. I think an unfortunate side effect of the niche fair-trade model that we've seen up until now is that many of those goods cost a lot, because of retail and wholesaler markups in the niche markets that they cater to. People have a concept that fair-trade, living-wage goods are necessarily expensive, and that's actually not true.

White: What did you think Alta Gracia would have the hardest time changing about the way most apparel factories operate?  

Adler-Milstein: We were really concerned about how we would get factory managers, who were used to very abusive conditions, to act right—like what kind of training we would have to give them, what kind of resources we would have to give them. What was surprising was that they were delighted to be able to work in a factory where they could work more cooperatively with employees and conditions were great. They loved it.

White: That’s interesting—often in stories of factory abuses, it's the managers and supervisors who come out looking like the biggest villains. Brands are often able to invoke the complexity of the supply chain to suggest that they had no idea what was going on. How does this change that argument?

Adler-Milstein: I think what we learned from Alta Gracia is that managers often are tasked with the industry's dirty work. They are given an untenable amount of money to produce goods, and then they have to push workers to work off the clock, and long garments. Alta Gracia's example has been really telling that many industry players who've been forced into these terrible positions really want to see change and are willing to make it, if the incentives are changed from the brand level and retailer level.

White: Aside from appealing to executives’ humanity and fear of bad press, is there an economic argument for why big companies should consider higher wages and better factory supervision?

Adler-Milstein: In a normal factory, we found there's 50 to 60 percent worker turnover every year.  It takes about three months to train a sewing machine operator, and they have lower output in the three-month period as they're getting trained. By contrast, Alta Gracia's turnover is 5 percent per year. There's all sorts of business benefits that start happening when you start paying a living wage. Many of those costs can even just be absorbed in attracting and keeping a more skilled workforce.

White: Toward the end of the book, you talk about how the primary goal of a factory like Alta Gracia shouldn’t be scalability. What do you mean by that?

Adler-Milstein: When we say it's not about scalability, we mean people should not try and start factories from zero and start a new brand, like Alta Gracia did. It's 100 percent scalable, and far easier, for Nike or H&M or Walmart to do this in their supply chains. It's not complicated—they just have to pay their factories more and make it clear that they actually want them to implement their health and safety standards. Paying a living wage and working with a union is super easy, and absolutely every brand in the global supply chain could do it tomorrow if they chose to.



It’s Christmastime for workers, and companies want everybody to know.

After Congressional Republicans passed their $1.5 trillion package of tax cuts on Wednesday, a number of companies responded by announcing raises or bonuses for their workers. Comcast said it would give $1,000 bonuses to more than 100,000 workers. Fifth Third Bancorp said it would give out bonuses and boost its minimum wage, with the cut giving the bank, in its words, “the opportunity to reevaluate its compensation structure and share some of those benefits with its talented and dedicated workforce.” AT&T, Boeing, Washington Federal, and Wells Fargo did much the same.

The announcements seemed the result of some basic financial logic: Lower corporate taxes— the Republicans’ bill cut the corporate rate to 21 percent from 35 percent and included provisions to encourage businesses to bring cash back from overseas—would mean higher corporate profits and thus more money to pay workers with.

Indeed, the White House itself has estimated that tax reform would add $4,000 to the average worker’s annual paycheck, as a conservative estimate. And President Trump lauded the companies’ announcements, tweeting: “Our big and very popular Tax Cut and Reform Bill has taken on an unexpected new source of ‘love’—that is big companies and corporations showering their workers with bonuses. This is a phenomenon that nobody even thought of, and now it is the rage. Merry Christmas!”

But many economists, including the government’s own nonpartisan scorekeepers, dispute the notion that workers will get much of the gains from corporate tax reform, which President Trump signed into law on Friday. They argue that shareholders, not workers, stand to benefit the most. Recent history suggests the same, with the wealthy the primary beneficiaries of soaring corporate earnings and a booming market.

Contrary to companies’ stated reasoning, many of those wage increases and bonuses would have happened anyway, it seems, given how low the unemployment rate is right now. Though wage growth has been in a long-term slump, paychecks are finally rising as the jobless rate has fallen below 5 percent and stayed there, with earnings growing the fastest for the lowest-wage workers. Plus, 18 states are raising their minimum wages in 2018, requiring businesses to pay out an estimated $5 billion more to 4.5 million workers.

Given those dynamics, businesses are likely using the tax cuts in part as a way to advertise pay increases that were already planned and to curry favor with the Trump administration and Republicans on the Hill. To wit: Wells Fargo waffled on whether its pay increases had anything to do with tax reform, first saying they did not and then correcting the record and saying they did. “Minimum pay is a topic that we continue to review as part of our efforts to attract and retain talent, and we have been on a path to increasing the minimum hourly rate,” a spokesman told The Los Angeles Times.

More broadly, while economic evidence suggests that cutting taxes on corporations does lead to some trickle-down benefits for workers, it also suggests that the sums are smaller than the White House has projected and would likely take some time to show up in paychecks. “These raises have zero economic connection with the tax cuts,” said Josh Bivens, an economist at the Economic Policy Institute, a left-of-center think tank. “We know this because the theory linking cuts to wage gains requires other mechanisms to fire first—mainly the rise in capital investment and productivity growth,” which would “permanently reset salaries at higher levels, not get firms to bestow one-time bonuses.” Businesses would need to use their additional funds to invest in machinery, equipment, and research and development, making their workers more productive, and then paying those workers for that additional productivity, in other words. Of course, these companies could claim they are issuing payouts now in anticipation of that chain of events, but the real process would take some time.  

Still, the Trump administration has argued that workers would get most of the benefit of the corporate tax cuts, through mechanisms like the one Bivens outlined. But while it expects workers to get 70 percent of the savings from tax reform, most economists argue they would get something like a quarter. That includes the Joint Committee on Taxation, the Congressional Budget Office, and the Treasury—three government sources of dependable economic projections. Workers very well might see some earnings gains because of the tax bill, but in all likelihood they will not be on the scale that the White House is talking about.

So, if corporations are about to start saving a lot of money, and most of it is not going to workers, where is it going? Most will go to shareholders, whether people with retirement accounts, rich investors, or corporate executives compensated with equity, economists think. Numerous companies—three dozen of them and counting—have announced that they will buy back shares with the additional funds. Home Depot is planning to spend $15 billion on buybacks, Oracle $12 billion, and Pfizer $10 billion. All in all, 15 companies have said they each plan to spend more than $1 billion on buybacks, and many have also announced plans to boost their dividends.  

Buybacks reduce the number of shares a company has in circulation, pushing up the price of the ones that remain on the market and making shareholders richer. The reason this primarily benefits the well-off is that lower-income and middle-income families do not tend to have many equity investments, if any at all. The New York University economist Edward Wolff has estimated that the top 1 percent of households in terms of wealth owned 40 percent of all stocks in 2016, and the top 20 percent of households owned 93 percent. The fact that these households gain so much from a rising stock market  is part of the reason that wealth inequality has increased so sharply.

Of course, it would have been possible to construct a tax plan that would have both cut the corporate income tax and ensured that workers earned more. Pairing the former with an increase in the federal minimum wage and mandatory paid leave for parents would have done so, for instance. Instead, Congress is leaving it up to businesses to benefit workers as they see fit.  



In late May, the Department of Homeland Security announced its plans to rescind the International Entrepreneur Rule, an Obama-era provision that allowed foreign-born entrepreneurs to stay in the United States for up to five years to expand their businesses, granted they could prove their companies’ potential for rapid business growth and job creation. The announcement came as no surprise, given the Trump administration’s rollback of other executive orders issued during Obama’s presidency, and earlier hints the administration would cancel the rule. But it dealt a particular punch to those who saw the rule as a gateway toward a long-held goal: a start-up visa, which would create a pathway to legal immigration for foreign-born entrepreneurs, thus drawing the best founders to the United States and improving its competitiveness at a time when other countries are launching more and more lucrative start-ups.

Immigrants are nearly twice as likely as American-born citizens to start businesses in the United States, according to the Kauffman Foundation, a nonprofit that promotes entrepreneurship. Fifty-one percent of all U.S. start-up companies valued at $1 billion—the so-called unicorns—have at least one immigrant founder, according to the National Foundation for American Policy, a nonpartisan public-policy research organization. But historically, there hasn’t been an immigrant-visa category tailored for entrepreneurs. Mike Krieger, the Brazilian-born co-founder of Instagram, came to Stanford University on a student visa before transitioning to a skilled-worker visa. The Google co-founder, Sergey Brin, was a child when his family immigrated to the United States from the Soviet Union as refugees. Elon Musk, the founder of SpaceX and co-founder of Tesla, first immigrated from South Africa to Canada in order to eventually immigrate to the United States.

During the Obama administration, lawmakers began pushing for a start-up visa and seemed to be gaining some traction. In August 2016, the Obama White House announced the Department of Homeland Security would propose the International Entrepreneur Rule. Hillary Clinton advocated for a start-up visa as part of her platform. Now, the death of the International Entrepreneur Rule—and, relatedly, the stalling of the start-up visa—have foreign-born entrepreneurs in the United States grappling with whether to stick it out or just leave. Silicon Valley, too, is coming to terms with losing the competitive advantage it took for granted for so long. For some, it’s the latest evidence that Donald Trump, who became president on a promise to revive the American dream, is, in fact, chipping away at it.

In the early 2000s, a person I'll call Gyan (who requested that his real name not be used in order to protect his immigration status in the United States) considered his options. He could stay in his home country, in Asia, and pay to attend a top university, as most people do. Or he could go to the United States, where, he thought, he could create a path toward a better future. The decision was clear, and he came to the United States. Gyan applied to Stanford University, which offered him an excellent financial-aid package. He accepted immediately.

During Gyan’s senior year, an entrepreneurship class motivated him and two other students to start a company. Their product, a productivity tool, never took off, but the experience gave him the entrepreneurship bug. Gyan’s student visa allowed him to stay for a year after graduating to pursue practical training. So, he started working for various start-ups, practiced writing code in his downtime, and met fellow ambitious techies at cafes around Silicon Valley: Red Rock Coffee in Mountain View, Starbucks on Stanford Avenue.

Not being a U.S. citizen, Gyan stayed in the country by securing an employee-sponsored H-1B visa through a job as a software engineer. “Ultimately I think I was just really aching to make things happen, to build things,” he told me. He started to tinker with new product ideas after work.

Around that time, Silicon Valley investors and entrepreneurs started lobbying for a start-up visa. In 2010, Senators John Kerry and Richard Lugar introduced the bipartisan Startup Visa Act, the first legislation of its kind to propose a visa category for international entrepreneurs. Recognizing the catch-22 of company founders being unable to sponsor themselves for visas, the act would allow a foreign-born entrepreneur to receive a two-year visa, and then be eligible for a green card, after proving job creation and acquiring $1 million in investment capital or revenue. The proposal was beloved within the tech community. But the bill, and subsequent iterations of it—including the popular Startup Act, which includes a start-up visa as part of other provisions aimed at helping the start-up industry—didn’t gain enough traction in Washington, D.C. “Nobody was committed to championing it,” said Craig Montuori, a partner at Venture Politics, a public-affairs consulting firm based in Silicon Valley, who lobbied for the start-up visa. Most people didn’t consider it a crisis; other foreign-born start-up founders had made it work, hadn’t they?

Back in the Bay Area, that’s what Gyan kept telling himself. In 2015, he built a prototype for another start-up, this time related to hospitality management. Gyan and his co-founder soon landed a meeting with a well-known incubator. The investors didn’t ask about his immigration status, but, to Gyan, it was the elephant in the room. When they ultimately didn’t invest, Gyan couldn’t stop thinking about how his immigration status might impact his success as an entrepreneur. He can’t remember the exact questions asked during the meeting, but they were along the lines of: Why haven’t you quit your job to work on this? Are you willing to quit your job? “They want to invest in someone who can work on this full-time,” Gyan said. But if Gyan quit his job, he’d lose his H-1B visa—his gateway to staying in the United States. He couldn’t.

Around October 2016, Gyan was reading the news when he came across an article about the International Entrepreneur Rule. The rule, inspired by the Startup Act, created a special immigration status for foreign-born start-up founders. When the rule was finalized, in January 2017, Gyan inspected the requirements: Have a young company, and own a substantial interest in it. Have either $250,000 or more from qualified U.S. investors with a history of successful investments, or $100,000 or more from government entities, or other compelling evidence of the start-up’s potential for growth and job creation.*

The IER would go into effect in July 2017. The DHS estimated about 2,940 entrepreneurs would be eligible for it each year, although one immigration attorney in Silicon Valley, Sophie Alcorn, told me she believes that’s a vast understatement, and that applications could have reached 10,000 or more given the excitement around it. The prospect of one day applying for the IER energized Gyan, and he was out the door again, networking with people and trying out new ideas. Every foreign kid with an entrepreneurial streak was eyeing the IER, he said.

But in July 2017, less than a week before the rule was set to start, the Trump administration delayed it and announced its intention to eventually rescind the rule. In December 2017, after some legal wrangling over the delay, U.S. Citizenship and Immigration Services (USCIS) announced in a press release it would begin accepting applications under the IER, and gave directions for how to apply—but added that it still planned to remove the rule. Finally, late last month, the DHS proposed to formally eliminate the IER, arguing it was too broad and didn’t protect U.S. workers and investors enough, and that other visa categories were available to foreign-born entrepreneurs.

Doug Rand, a former White House official who helped implement the IER during the Obama Administration and has since co-founded Boundless Immigration, which helps families navigate the U.S. immigration system, argues these other visa categories would be extraordinarily difficult to obtain for people from certain countries, or would require proof of current accomplishments rather than future promise. “For an administration that can’t stop talking about those that come in based on merit,” he said, “why would you torpedo a program that can benefit the super qualified?”

The rule had yet to make much of an impact. A spokesperson for USCIS said it has received about 12 applications for IER but hasn’t issued any final decisions. Brad Feld, an investor and an entrepreneur who advocates for a start-up visa, blamed the low numbers of applicants on the administration’s chilling actions. “Not surprisingly, the Trump White House stated relatively early on that they wanted to kill it. The second they did this, they made it unattractive to anyone, as the risk of it vanishing one day unexpectedly made it an extremely high-risk option,” he said. “It’s a self-fulfilling prophecy—if the current administration won’t support it, it’s not an attractive option.”

Along with IER’s folding, the Startup Act remains stuck—at least through this Congress. A bipartisan group of senators reintroduced the Startup Act last year, but the bill has gotten tied up in broader immigration politics. Neither party is willing to move on passing what they both want unless the Startup Act is bundled with either enhanced border security, for Republicans, or a pathway to legal residency, for Democrats, said John Dearie, the president of the Center for American Entrepreneurship. “Both insist on the ‘whole loaf’ rather than accepting half—and so nothing happens,” he added.

Meanwhile, since lawmakers in the U.S. first introduced the start-up visa eight years ago, other countries have followed their lead: Australia, Canada, Chile, France, Germany, Ireland, Israel, Italy, Japan, New Zealand, Portugal, Singapore, Spain, and the United Kingdom now all have versions of a start-up visa or other initiatives to bring in foreign workers.*

Silicon Valley may have written the script for how to build a start-up, but those practices are now global, said Natalie Novick, a sociologist and an ethnographer at the University of California at San Diego who studies start-up ecosystems around the world. Ten years ago, nearly 75 percent of the world’s venture-backed funding flowed into the United States; in 2017, the United States received 45 percent. Meanwhile, investment has grown enormously in Asia—especially in China, which now rivals the United States in VC funding and has three of the world’s five most valuable unicorns. India trails other countries in venture-capital flow, but when the United States denied Kunal Bahl, an Indian-born co-founder of the online retailer Snapdeal, an H-1B visa after he graduated from the University of Pennsylvania’s Wharton School, he returned to his home country and helped create more than 5,000 jobs with his new company.

As immigration reform remains at a standstill, and the Trump administration eyes even more restrictionist immigration policies, many in Silicon Valley are worried the United States is losing its competitive advantage—just what they were hoping to guard against with a start-up visa. In May, the Stanford Graduate School of Business’s career center hosted a “Working in Canada” event—organized largely because of student panic about jobs and visas, said Maria Pasos-Nuñez, the business school’s associate director for international-student career development. In addition to canceling the IER, the Trump administration has unveiled a new draft policy that may make it easier to force international students to leave if they’ve violated the terms of their visa. It also recently declared it wants to reform the popular practical-training program that gives foreign students a year or more to stay in the United States and work after college. Participation in the program grew by 400 percent among graduates with STEM degrees from 2008 to 2016, according to the Pew Research Center; it’s widely considered a pipeline that helps international students to eventually become U.S.-based entrepreneurs. While some people speculate the administration may eliminate the program altogether, Carissa Cutrell, a public-affairs officer for ICE, said the exact reforms to the program are still under discussion.

As students grow anxious about their ability to work in the U.S., employers now seem hesitant to hire international students due to the fear of losing them after hiring, Pasos-Nuñez said. The graduate school is increasingly sourcing jobs outside of the United States for its students. The immigration problems have “led to an escalation of challenges and frustration for highly skilled international students looking to launch their career or start-up ventures in the United States,” she said.

Veronica Zhou, a 35-year-old Chinese native who immigrated to Canada and became a citizen there before enrolling at Stanford, helped organize the Working in Canada event. Zhou has it a little easier than some of her peers if she wants to stay in the United States, thanks to a visa available to Canadian citizens through a provision of the North American Free Trade Agreement. But she’s already networked in China, France, Israel, and Peru; while she once idealized life in Silicon Valley, she’s now not sure she wants to stay. Zhou has found that hiring people for new ventures in the United States is becoming more difficult—especially when it comes to international talent, she said, because many foreign-born workers in the United States prefer the stability of securing a visa through an established corporation to joining a start-up. And fewer international students are coming to study in the United States in the first place. “Everyone on campus will have to face the decision of whether we stay here or leave,” Zhou told me. “That’s what we think about and worry about every day.”

When Gyan heard the news that the IER collapsed, he felt disappointed—though not entirely surprised. He tried to put things in perspective. Families are being separated and sent back across the border. I have nothing to complain about, he told himself. He repeats the upbeat mantras the industry is famous for: As an aspiring entrepreneur, if you get let down and upset, maybe you shouldn’t be in the field. You have to be resilient.

Now 31, Gyan has studied and worked in the United States for 13 years. He is still committed to starting a business, though he’s currently too preoccupied with interviewing for a new job to try to execute any of his ideas. He doesn’t want to waste away as a forever employee in the United States. But his H-1B visa is expiring soon, and he’s reached the maximum number of years he can be on the visa. So along with finding a new job that, he hopes, will sponsor a green card that will allow him to stay in the country as a legal permanent resident, he’s consulting his friends in the business community about the next best visa option.

Private U.S. initiatives focused on international entrepreneurs have emerged, including residency programs at universities and a venture-capital firm aimed at immigrant-founded start-ups. Gyan could also move to another country to be an entrepreneur if need be. He lists the other options off the top of his head: Canada, Germany, Chile. “There are so many people in this country who invested in my future,” Gyan said. “Universities teach these kids from abroad, they inspire them, they invest in them. But then, at this point, there is another group of people who want to shut them down.”

* This article originally misstated that the amount required from qualified U.S. investors was $245,000. It was $250,000. We regret the error.

* This article originally mischaracterized the nature of Chile's visa program. We regret the error.



In the final month of 2017, the U.S. economy added 148,000 jobs, while the unemployment rate remained at 4.1 percent, according to the Bureau of Labor Statistics. All told, an additional 2.11 million jobs were added in all of 2017—a performance that will be hard to repeat in 2018.

As the economy has steadily improved, adding jobs for one of the longest consecutive streaks in modern history, many experts have wondering when the impressive growth would stall. With the unemployment rate at its lowest levels in 18 years, and job growth already slowing from 2016 to 2017, this year’s growth could be significantly more lackluster. And while unemployment has ticked down significantly, there are still tons of missing workers: December’s report showed that the labor-force participation rate was still at 62.7 percent, still well below historical norms.

December’s performance fell short of economists’ expectations that an additional 190,000 jobs had been added during the month, according to a Bloomberg survey. December’s performance marks one of the few months in 2017 that job growth didn’t top 200,000. In 2018, surpassing the 2 million mark isn’t a sure thing, and months that fall short of the 200,000 mark will likely be more common.

It’s expected that job growth will wane after several years of brisk growth. While 2018 may not be able to deliver the impressive job-growth figures that Americans have become used to, there are still important areas of the economy that could, and need to, improve. In December, wages ticked up by 9 cents, bringing 2017’s overall wage growth to 2.5 percent. While that’s better than previous years when wages were flat, earnings haven’t been improving at the rate that most economists would expect in an otherwise healthy economy. And earnings growth is what makes a difference to Americans in their day-to-day lives.



For months, the local papers watched excitedly as a shopping center of unprecedented proportions rose on the outskirts of Detroit. When Northland Center finally opened in March 1954, they could hardly contain themselves.

“The size of such a mammoth group of stores as Northland Center is often hard for the layman to visualize,” marveled the Detroit Free Press, which added helpfully that the 9 million pounds of steel that would go into the structure represented the equivalent of “4,000 autos,” while the mall would be equipped with “enough refrigeration to make 200 million ice cubes daily.” Outside stretched a lot for 8,344 cars, then the largest public lot in the world. And should a customer lose their vehicle among the acres of Buicks and Packards, the “Lost Car Department” could dispatch a jeep to drive the customer around to find it.

The interior of this “stately pleasure dome”—embellished with gardens and sophisticated modern sculpture—would be lined with more than a mile of storefronts. “Wives who visit the new Northland Shopping Center will never want to go home,” declared the Free Press columnist Louis Cook. “When they are not shopping they will just sit on the benches under the trees, listening to the splashing of fountains and dreaming up new ways of spending money.”

Darla Van Hoey was three years old when Northland opened in Southfield Township, an event covered not only by local outlets but also by Time, Life, Architectural Forum, and The Wall Street Journal. “Coming to Northland was a big deal,” she says. “The gardens were beautiful. We would make a big shopping trip before Christmas, and we took family there when they were visiting from out of town.”

A retired French teacher who now serves as the president of the Southfield Historical Society, Van Hoey is quick to correct an out-of-towner’s pronunciation: Locals don’t say “NORTH-lund,” but “NORTH-LAND,” as if the monumental mall were actually a theme park along the lines of Disneyland. But while Northland still looms large in the minds of longtime residents—and in the history of American retail—the mall’s glory days are long gone; after decades of decline, Northland closed in 2015, and a partial demolition is underway as the city of Southfield shops the land to developers. It’s a sad, if not unexpected, end to a building that set suburban architectural standards for half a century. But local leaders hope that what happens next may just offer a model for suburbia’s future.

When it opened, Northland was the biggest shopping center in America, commissioned by J.L. Hudson Company, a Detroit department store that at the time was second only to Macy’s in sales. Northland was the creation of architect Victor Gruen, an Austrian immigrant who loathed the strip-mall–style shopping centers then growing like weeds along America’s arterial roads. But Gruen had equal disdain for his adopted country’s unruly and soot-choked urban cores. For years, he had been thinking about a way to marry the best of downtown’s walkable vitality with the sparkling modernity of the new suburbs. Hudson’s, whose owners had both money and moxie, finally offered the opportunity Gruen had been waiting for.

“Northland really put him on the map,” says M. Jeffrey Hardwick, author of the 2003 biography Mall Maker. At the time, Hardwick notes, the suburbs were constrained by a “bucolic ideal” that excluded commercial activity. “People worried that it would be a blight, that it would do to the suburbs the same things it did to cities.”

Northland’s fundamental innovation was allowing a single developer to control every element of construction and design over a vast area (Hudson’s originally purchased 460 acres for the project, although the current site occupies only 125). The architecture was tasteful and modern, there was no tacky exterior advertising, and from a distance the brick-and-concrete structure and its acres of parking were hidden from view behind grassy berms. A network of underground tunnels, some with ceilings high enough to accommodate a tractor trailer, kept the less appealing logistics out of sight. Beyond fashion and furniture, Gruen wanted Northland to offer all the necessities of everyday life—everything that had compelled previous generations to go downtown. When the mall opened, it housed a supermarket, a bank, a beauty salon, and a post office. There was a fallout shelter in the basement and a playground beneath a geodesic dome.

“This is not just the opening of a shopping center,” Gruen—never one for modesty—declared on opening day, “but an important milestone for city planners, architects, economists, merchandisers, and the American public at large.”

The model held immediate appeal—soon Hudson’s Northland was out-grossing the flagship store in downtown Detroit. “They had imagined that people were still going to go downtown,” Hardwick says, “which was a blind spot.”

Gruen went on to build dozens of malls over the next two decades. Beginning in 1956 with Southdale in Edina, Minnesota, he pioneered design elements like the two-level, all-enclosed, climate-controlled structure with central garden courts and skylights that became features of every mall in America. But by the late 1970s he had soured on the concept—the sprawl of tacky strips, parking lots, and gas stations that soon surrounded most malls went against his original vision. “I refuse to pay alimony for those bastard developments,” he famously declared.

For Southfield, long a sleepy farming community, Northland kickstarted rapid growth. Around the mall sprang subdivisions and high-rise apartments, and between 1960 and 1970 the population more than doubled. Still, as the suburbs sprawled ever outward, newer and shinier malls lured the wealthiest customers away. Northland’s owners worked to keep up with the latest trends in retail, expanding the mall and fully enclosing it in the 1970s. But by Northland’s 50th anniversary in 2004—despite multiple face-lifts—the number of shoppers had dropped to 9 million a year from a peak of 18 million. Tenants vanished, replaced by lower-end retailers, who disappeared in turn. The property itself changed hands repeatedly, until in 2014 when the latest owner defaulted on the mortgage. In 2015, the city of Southfield scooped Northland up for $2.4 million, less than a tenth of what it had cost to build back in 1954.

The city’s dream is that Amazon will choose the site for its second headquarters, and Southfield offered the space as part of Detroit’s bid this past fall. Mayor Kenson Siver points to Northland’s location at the geographic heart of metro Detroit, its proximity to highways and the airport, and the fact that all the infrastructure—electricity, sewers, road access—is already in place. And Gruen’s tunnels, Siver contends, would be perfect for housing data servers.

The poetry of today’s largest online retailer replacing what was once the cutting edge in brick-and-mortar may be appealing, but luring Amazon is a long shot, and the mayor acknowledges as much (“Nothing ventured, nothing gained,” he says cheerfully). So as bulldozers chip away at Northland three miles from City Hall, Siver lays out a future that includes new, walkable through-streets, adaptive reuse of the original Hudson’s store, medical office space for the adjacent Providence–Providence Park Hospital, a central park with a water feature and a band shell, and retail and restaurants anchoring mixed-use buildings.

If Southfield can find private partners to make this happen, Northland will not be the only dead mall converted to a New Urbanist town center. According to Ellen Dunham-Jones, a professor at Georgia Tech School of Architecture and co-author of the 2009 book Retrofitting Suburbia, out of some 1,500 one-time enclosed shopping centers in the United States, only a little more than two-thirds are still operating as such. About 200 are in redevelopment. A few dozen have been or are being rebuilt as mixed-used lifestyle centers, and some of these have proven very successful, Dunham-Jones says. While these developments do tend to share a certain aesthetic that may eventually feel just as dated as Northland does today, she believes that they will prove more resilient than Victor Gruen’s monolithic malls have.

“I think there’s reason to be hopeful that when you insert public streets and chop stuff up into blocks with multiple owners, you’re setting up a situation that allows for much more incremental change and responsiveness to the market,” she says.

That’s the hope of Southfield leaders, as the old-school suburb of office parks, strip retail, and single-family homes faces a future where that approach to planning seems increasingly an artifact of the past.

“Northland is never going to be a shopping center again,” says Mayor Siver. “But we have a vision. This city was built around the automobile, and we are trying to lessen that impact. Northland gives us the chance to start all over.”

This post appears courtesy of CityLab.



Editor's Note: This article is the second in a series about how the gig economy is shaping the future of labor and what that means for workers.

When Terrence Davenport first heard about the so-called gig economy, he was working at a free-meal program in his hometown of Dumas, Arkansas, a tiny village surrounded by cotton fields. Around 40 percent of Dumas’s roughly 5,000 residents lived in poverty. Most young people who left for college, as Davenport had done, never came back, and both the town’s population and its median salary—about $23,000 a year—were shrinking. “What did you eat today?” Davenport would ask kids he passed on the street. Often it wasn’t much, and he invited them to have a free meal. But what he really wanted to do was solve the deeper problems that made them hungry.

It was 2014, still the early days of Uber and Airbnb, and Silicon Valley was promoting the idea that its app-infused “gig economy”—which used digital technology to connect workers with projects—could solve the United States economy’s problems. “In many ways, we look at Uber as the safety net for a city,” then Uber-CEO Travis Kalanick said on a conference stage in 2016. He asked the audience to imagine that a factory had closed down. What would happen to those workers? “They can push a button and get to work.”

A San Francisco–non-profit called Samasource wanted to test the idea in Dumas. It already hired extremely poor people in East Africa and India to complete online projects for tech companies like Google. While the difference in living wages made that model impossible in the United States—the tech projects paid too little—Samasource hoped the gig economy could create similar opportunities for the unemployed here. It called the idea “Samaschool” and had chosen Dumas, along with Merced, California, to test the program; in Dumas, the local school district’s outgoing superintendent, who had sat in on Sunday-school classes taught by Davenport, had recommended him to run it.

As a child, Davenport had lived in Dumas with his grandmother and mother in an old sharecropper’s house, before attending some high school in nearby Pine Bluff, where his father lived. When he started classes at the University of Arkansas, he never thought he’d return to Dumas. But his little brother’s death, in 2012, brought him back. Now he was living with his grandmother, cooking her dinner.

Davenport had a habit of letting his phone go uncharged for days, but a hand-delivered message finally reached him at the food program, and he ran home, changed his shirt, and arrived in a sprint at the community-technology center on Dumas’s main street, still having only a vague idea of what the job entailed. As his interviewer explained Samaschool’s intentions—to teach residents how to get jobs in the gig economy—Davenport immediately saw it as a way to make a bigger difference. A few weeks later, Davenport got the job. Finally, he thought, he’d found a conduit to new work opportunities that had so far left his small town, and others like it, behind.

For a small town, attracting businesses, nurturing start-ups, and retraining workers for local jobs can be slow processes. In Dumas, Samaschool hoped it could sidestep these workforce-development challenges by connecting residents, through the internet, to gigs that had been created elsewhere. “The average student we work with is unemployed for 16 months prior to the program,” Samaschool’s then-managing director told me in 2015. “For them to take training that is months or years, they don’t have that time.”

Research, data entry, and customer service—all work that was plentiful on online freelancing websites—didn’t require college degrees or trade skills. All Dumas residents needed, the thinking went, was some instruction about self-promotion and digital literacy, and an internet connection. An 80-hour program, to teach all this, would span 10 weeks. Students would learn how to build an online portfolio of work, search for jobs, write proposals, and use the freelancing websites Elance and Odesk (which would later be combined into Upwork). Around 70 Dumas residents applied. Davenport chose 30 of them, including farm workers, home-care aides, and a few people who were chronically unemployed. The Dumas program quickly attracted attention both locally and nationally. But as he started teaching, Davenport knew almost instantly that the gig economy wasn’t going to provide the easy solution to unemployment that had been promised—at least, not in Dumas.

Before any of Davenport’s students could work in the gig economy, they had to apply and be selected for projects—which proved more challenging than expected. According to Samasource, 60 percent of the students who took Davenport’s class did not own a computer, and 44 percent did not have access to the internet, even on their phones. Some Dumas residents were so unfamiliar with computers that they didn’t know where to type the URL on a search browser, or how to send an email.

But familiarity with online work—and the inadequate internet speeds in Dumas—were far from the only hurdles to winning job contracts. Although 90 percent of Davenport’s students had high-school degrees, many couldn’t read or write at a high-school level. Davenport was trying to teach some students how to craft an online resume profile when they could barely write a grammatical sentence, and trying to coach them in deciphering online job postings when they struggled to read. Gigs on Upwork, Davenport learned, tended to fall into one of two categories. They either didn’t require any formal qualifications, which meant they could often be completed by workers in other countries who were willing to work for as little as $3 or $5 per hour, or they were specialized and well-remunerated, which meant they often went to workers with undergraduate or even master’s degrees.

Davenport’s students had another, deeper disadvantage. Most of his students faced bias against African-Americans. In a 2013 experiment, researchers tried to sell an iPod on online marketplaces, and found they received 13 percent fewer responses and 17 percent fewer offers when the photo showed the iPod being held by a black hand than when it was held by a white hand. In a more recent experiment, Airbnb users with distinctively African-American names were 16 percent less likely to be accepted as guests than identical users with white-sounding names. Most online work platforms show employers profile photos of applicants.

Beyond that, Davenport had begun to notice the many ways in which slavery had left a lingering mark on Dumas. That trauma had led to a feeling of hopelessness, which had been passed down in the culture through generations. On top of that, there was the added trauma of being systematically cheated out of land and voting rights, and of present-day racism. Davenport had trouble keeping students believing in themselves as they were rejected from gigs to which they’d applied—which was their primary experience.

One student landed a customer service job at $7 per hour. A few tried working for $3 or $5 per hour. Someone found a $50 project, but it took so many hours to complete that the hourly pay became meaningless. Outside of Upwork, Davenport found some of his students jobs as contract workers at call centers. But in the end, just five of the 30 students he’d admitted to the first class found digital work. Gary Foster, a Dumas Samaschool graduate, said that during his several weeks of mandatory unpaid training for the gig, he had trouble paying his bills. “I had disconnection notices everywhere,” he told me. He was one of the five students to find work, making $9 per hour as a contracted customer-service representative (in a nesting doll of contingent employment that made him a contractor to a contractor to a contractor to Sears), but that lasted less than a year before Foster, finding that he often could not rely on getting enough hours to make ends meet, instead applied for a license to drive a semitruck. Later, he moved to Milwaukee, Wisconsin (where he had lived once before).

Hazel Jackson, who enrolled in Samaschool after having trouble finding a traditional job, enjoyed working on new skills, but never found a gig. Previously, she’d worked as a cashier and as an operator of a machine used for testing the grade of cotton. “The most important thing is that I learned something I would never learn,” she said. “Hopefully someday I’ll be able to use it.”

Not everyone’s experience in the gig economy was so fraught. Two workers who graduated from Samaschool pilot programs in California told me they’d used the gig economy to find sustainable work. And throughout the years I spent reporting on gig-economy workers, I met plenty whose work matched the optimistic Silicon Valley vision. Most often, these workers had specialized skills, savings accounts that helped them weather slow work times and take vacations, and resources to pay for expensive health-insurance plans. (In the gig economy, none of the labor protections or benefits reserved for full-time employees apply.) Davenport’s students typically did not have these luxuries. Almost half of them said they did not have reliable transportation, and around 15 percent of them experienced homelessness while taking the Samaschool course. As Davenport put it: “If you have a water bill that you can’t pay, you’re not going to focus on a class.” It wasn’t that the gig economy didn’t solve problems; it just didn’t solve Dumas’s problems.

At the end of Davenport’s first course, the feedback was consistent: This is a nice platform and all, but we’re spending a lot of time working on it without getting paid. Where are the jobs? So Davenport and Samaschool pivoted. They thought students would win more gigs if they had been trained for specific ones. So, for the second class cohort, Davenport taught students not only how to use Upwork and promote themselves, but also how to do work in areas like customer service, social-media marketing, and virtual assistance (helping clients manage their email, calendars, and errands, from afar).

Still, only two people found digital work. For the third cohort, Samaschool narrowed the curriculum to one skill: social-media marketing. It also tried partnering with businesses to offer paid social-media-marketing internships to Dumas residents, outside of the gig-economy sites. The field paid fairly well and favored native English speakers. But it also required constant creative thinking and perfect grammar. “We’ve been doing physical labor,” Davenport told me, “where you get a job and obey what your boss tells you.” Marketing didn’t jibe with most of his students’ past experiences, and the training wasn’t enough to overcome that; only one student found gig-economy work.

Attendance dwindled, along with hope. One evening in 2015, I visited one of Davenport’s classes. It was supposed to start at 6 p.m., but when I arrived, 10 minutes late, the big classroom was empty, and I found Davenport leaning on a railing outside. “I don’t understand what is happening,” he told me. He had just hung up his cell phone after speaking with one of his students, who had a headache and wouldn’t be coming to class. Another student was watching her son’s football game. “This has never happened before,” he continued, his eyes wettening with frustration.

In the months that followed, Samaschool tried abandoning Upwork altogether and instead hiring Dumas residents itself to complete projects, similarly to how the original Samasource program hires workers in Kenya, Uganda, and India for virtual work. It tried recruiting students who had some college experience. But the problem didn’t seem to be a matter of iteration. After three years, only nine of the course’s 76 participants found gigs.

Late last year, I met Davenport again, at a McDonald’s in Pine Bluff, a city of about 44,000 people where he now lives. After the failure in Dumas, Samaschool had changed its strategy. Rather than providing stand-alone classes, it had begun partnering with existing training programs that prepare students for work in industries like IT, hospitality, and food service. The organization hoped students would use the gig economy to build their resumes and experience while they looked for more stable jobs. After all, while gig work alone might not be a quick fix to unemployment, it is growing faster than other segments of the workforce.

Samaschool had added a 10-hour training module to other organizations’ skills-focused courses. In it, the non-profit discusses how to use gig-economy platforms and how to plan for some of the shortcomings of the gig economy—that students should plan to save for a larger tax bill, plan for inconsistent work, look out for their own safety, and buy their own insurance.  Several months before my visit, Samasource had informed Davenport that it would be ending its program in Dumas; It wasn’t having the impact it intended. Davenport wasn’t all that surprised. “You can say, let’s go to Arkansas and get people jobs,” he said. “That’s a great ambition. It’s nice to talk about and write about. But then you start to think about what it takes.” As part of his training, he’d traveled to San Francisco, which he found to be a “place filled with the leaders of our world who are uninformed about it.” If Silicon Valley really wanted to make a difference in Dumas, he now felt, it should have studied the people first.

When it did, it would realize that the presence of the digital gig economy couldn’t alone halt a cycle of poverty that had begun with slavery. “You can’t change someone’s culture in two or three months,” he said. Davenport thought chronically unemployed people should have caseworkers who could help address the immediate needs, like transportation and childcare, that often prevented them from completing job-training courses or applying for work. It would require mentorship, caring for a whole person rather than only job skills. All of this, and other programs, would require at least ten times the financial resources that Samaschool had allocated to Dumas.

Davenport had also begun to consider how residents might make better use of the Arkansas Delta’s existing resources. He often thought about all of the land, and how “children grow up with food growing all around them, and they’re hungry.” Sometimes he thought about small things: At a meeting in which the city council decided to buy dumpsters, he thought about how, when he was looking for work in Dumas after his mother’s death, he’d dug up scrap metal to sell by the pound. Why not teach Dumas residents to weld and have them build the dumpsters themselves? Residents would learn a skill that is in demand nationwide and get paid to practice it, and the city might wind up with cheaper dumpsters as a result. Create enough of these types of opportunities by using resources differently, Davenport reasoned, and Dumas could create its own gig economy of sorts.

In Pine Bluff, Davenport had been putting together a final report on Samaschool’s Arkansas program, for its funders. As I listened to his ideas for alleviating poverty in his own community, they sounded nothing like the ones that had once been proposed by gig-economy entrepreneurs. Davenport’s ideas were multi-dimensional where Silicon Valley’s solutions were simple; they were individual rather than scalable; and, they would definitely not come on-demand.

As Davenport and I spoke, a boy in a white tank top and gym shorts ran, shoeless, past our booth. The kid, who looked about 10 years old, was one of Davenport’s neighbors. “Hey, how are you doing?” Davenport called. As the boy told us he was doing okay and bolted into the bathroom, a woman at another table yelled after him, “Where are your shoes?” The boy appeared again a few minutes later. “What did you eat today?” Davenport asked him. The child muttered that he could use a burger, and Davenport got up to order one.

This post is adapted from Kessler’s upcoming book, Gigged: The End of the Job and the Future of Work.



The United States is a low-tax country.

This is not a widely accepted point, granted. The share of Americans who say that their taxes are too high is at roughly 50 percent, a 15-year peak. Moreover, Republicans have sold their tax bill as an essential tax cut for America’s income-starved, tax-strangled families and businesses, promising to deliver $4,000 a year to the average family and huge boosts to corporate investment. “Today, America has one of the least competitive tax rates on planet Earth, 60 percent. Think of that, 60 percent higher than the average in the developed world. So our taxes are 60 percent higher,” President Trump said this month. “These massive tax cuts will be rocket fuel.”

But much of this rhetoric is incorrect. The United States is a low-tax country and is about to become a lower-tax country, assuming the Republicans manage to pass their $1.5 trillion in cuts. It is also a low-benefit country and is about to become a lower-benefit country, if Republicans can move forward with their long-planned cuts to safety-net and social-insurance programs. And it is becoming a lower-tax, lower-benefit country at a time when the economy needs more support for poor and middle-class families—not less.

Data from the Organization for Economic Cooperation and Development clearly shows that the United States is not a particularly heavily taxed country at all. Indeed, out of 35 developed economies, the United States’ tax burden as a share of GDP—26 percent—is the lowest save for four others: Turkey, Ireland, Chile, and Mexico. (Turkey, Mexico, and Chile are considerably poorer than the United States, and have considerably younger populations.) The social democracies of northern Europe, like Denmark and France, take in nearly 50 percent of their GDPs and spend the money on ample welfare states, including child-care benefits and old-age pensions. “From a global perspective, [our tax rate is lower] than average,” said Scott Hodge, the president of the Tax Foundation, a Washington-based think tank. “The difference is that other countries tend to have a value-added tax, in addition to the same system we have with income taxes, payroll, and all that stuff.”

Moreover, Trump has insisted that the United States has an extremely high corporate-tax burden, one that forces businesses to keep money overseas and hurts jobs and income growth here at home. He is correct that the United States has very high statutory tax rates on corporate incomes, with a top rate of 39 percent on business’ profits. But the American corporate tax code is also full of exceptions, special provisions, and loopholes that companies use to reduce their tax bills. Factoring in deductions, credits, and so on, the effective corporate tax rate is about 19 percent—lower than the top marginal rate that Republicans would put in place. The OECD has found that the United States is about average when it comes to hitting companies with income taxes.

Nor is the United States’ tax burden especially heavy now when compared with the country’s recent history. The measure of federal income as a share of GDP has waxed and waned around the same narrow band—15 to 20 percent, give or take—since the end of World War II, while nearly all other developed economies have chosen to increase tax revenue as a share of GDP to build bigger, stronger welfare states. Nor are taxes on America’s wealthy heavier than they have been historically. As noted by the economist Gabriel Zucman, the United States’ marginal tax rates on its top earners are similar to those in the 1920s, though the government is three times bigger now than it was then. Indeed, the top federal income tax rate has generally been far higher than it is right now: 92 percent in the 1950s, 70 percent in the 1970s and 1980s. Under the Senate proposal, the top rate would be set at 38.5 percent, higher than it was after the George W. Bush tax cuts but lower than at most other times since World War II.

All in all, the Republican plan cuts taxes, driving the bulk of benefits to businesses and wealthy families, with negligible effects for most lower-income and middle-class families a few years out. As a result, taxes as a share of GDP would fall. Current law and government forecasts suggest that government revenues would be 18 percent of GDP in 2020. Under the Senate bill, they would be just 16.7 percent after accounting for the slightly bolstered growth the legislation would generate—with the government taking in $245 billion less in tax revenue than current law would have it in that one year alone.

Those big tax cuts are paving the way for big spending cuts. Because it would increase the deficit so much, the Senate tax bill would trigger automatic budget reductions that would pull $25 billion from Medicare, $14 billion in farm aid, and $2 billion in block-grant money for community-development initiatives in 2018 alone, along with a number of other smaller cuts, were Congress not to act. Budget experts predict that some number of programs might get zeroed out entirely. Then, there are the sweeping changes that Republicans are planning to make to Social Security, Medicare, Medicaid, and the remainder of the safety net, including the welfare program and food stamps. “You cannot get the national debt under control, you cannot get that deficit under control, if you don’t do both—grow the economy, cut spending,” House Speaker Paul Ryan said this month at a town hall in Virginia.

The overall effect would be to make government far less redistributive, meaning post-tax, post-transfer inequality would become even more severe. Indeed, a new analysis by the Tax Policy Center found that most working families would end up with less money in pocket as a result of the Republican plans. “If you consider plausible ways of financing either the House or the Senate bill, most low- and middle-income households would eventually end up worse off than if the bill did not become law,” writes William Gale, the co-director of the TPC. “In other words, they would lose more from inevitable future spending cuts or tax hikes necessary to eventually offset the costs of the tax bill than they would gain from the tax cuts themselves.”

This would happen at a time when the country’s population is aging, requiring bigger outlays for government health and income-security programs. “We’re on the hook for a lot more spending in the years to come,” said Len Burman, an economist at the TPC and a professor at Syracuse. “It makes some sense to fund that rising spending obligation with a [value-added tax on goods]. But Republicans won’t even consider it.” It would also happen at a time when economic growth has failed to raise wages and earnings for millions and millions of working families, due to the forces of globalization, technological change, and the decline of unions, among other trends. Indeed, government programs—especially initiatives like the Earned Income Tax Credit—have become more and more important at reducing poverty and supporting families hit by shuttered factories, closing mills, and stagnant wages. The Republican plan would do little to cut taxes on those families, but would cut programs that aid them.

The result would be not just a lower-tax and lower-benefit country, but a more unequal one, and one more vulnerable to the forces suppressing incomes and reducing mobility for working families. The result would be not a vastly bigger, stronger economy, but one more tilted towards the rich. Trump describes his tax-cut plan as “rocket fuel,” but not everyone will be on his rocket.



In 2010, Margot Lee Shetterly, the author of Hidden Figures, was sitting in her parents’ home, catching up with her dad about some of his co-workers at NASA Langley Research Center, many of whom were black female scientists. “Why haven’t I heard this story before?” Shetterly’s husband asked.

It was then that she realized there were probably many people who didn’t realize the crucial role that women—and black women in particular—played in the early days of American space exploration. Not long after that, she wrote a book, Hidden Figures: The American Dream and the Untold Story of the Black Women Who Helped Win the Space Race, about the first African American women at NASA; it won the NAACP Image Award for Outstanding Literary Work and was adapted into an Oscar-nominated movie in 2016.

I recently spoke with  Shetterly about working on Wall Street, dealing with restlessness on the job, and matching one’s temperament to a profession. This interview has been lightly edited and condensed for length and clarity.

Lolade Fadulu: What did your parents do?

Margot Lee Shetterly: My mom taught English at Hampton [University]. My dad worked at NASA; he’s a retired research scientist. He spent his entire career as an atmospheric research scientist at NASA Langley. I grew up in Hampton, [Virginia,] and the women that I wrote about were people I knew growing up. That NASA connection was very much a part of my life from the very beginning.

Fadulu: Did you know all along that this was a story you wanted to write?

Shetterly: Yes and no. The genesis of the story really came out of a conversation that my husband and I had with my father. We were visiting my parents in December of 2010. My dad was talking about some of the women he had worked with. The facts of the story I knew growing up, because I knew what my father did. But it never really occurred to me to ask why there were so many women when I got to NASA to visit my dad at work. There were always women there, there were black women there. It was just part and parcel of my perception of what NASA was. There were black people, there were scientists, they did the scientific work and that was the nature of the thing. It was really that moment [in 2010] that called into question my understanding of that entire thing. Why the hell were there black women at Langley in the segregated south in the ’50s? How did they get there? Where did they come from?

The larger story of social mobility and work identity and race and gender—I think that is the story that has interested me forever. It's part of the reason why I went to work on Wall Street, which was something I wanted to do from the time I was really young. Writing Hidden Figures, for me, was a way of helping myself understand a lot of those things that I've always been trying to understand.

Fadulu: Did you write as a kid?

Shetterly: I did write as a kid. I've got this book of poetry that I wrote. A lot of times there were things that were part of a school project that I would turn into some elaborate thing, writing this whole kind of high-school soap opera.

I was always a good writer. I was a hugely voracious reader. I read everything, absolutely everything, and enjoyed it. I never knew that there was a possibility that one could be a professional writer. The idea that you could be a scientist—well, I totally understood that, because I grew up around scientists and engineers. You could be an English professor, an academic. There were a lot of things I had exposure to, but supporting yourself as a writer wasn’t really something I knew about as a kid.

Fadulu: You always wanted to work on Wall Street?

Shetterly: That was the core mission. Did you ever read the book The Westing Game by Ellen Raskin? I loved this book, partially because the protagonist was an adolescent girl whose name was Turtle Wexler, and she was into the stock market. I think I read this book when I was 8 or 9 years old. I was like, “Oh my God, the stock market thing, that’s what I want to do.” It totally captivated my sensibility. I started keeping track of selected stocks from the New York Stock Exchange. This was the 1980s. Wall Street was big in the ’80s.

Fadulu: Was working on Wall Street turn out the way you expected?

Shetterly: In a lot of ways. One of them was the excitement of Wall Street. And, of course, to be young in New York, that was very exciting—to be in a place where I wasn’t the only nerdy black woman.

Fadulu: How old were you when you were working in investment banking?

Shetterly: I was in my twenties when I was working in investment banking. It was great for my resume. It was a job that was well compensated. I learned a lot. I worked at J.P. Morgan and Merrill Lynch. I worked hard. I learned how to deal with a very stressful work environment. [Saving] up money during the times things were good made it possible to take some of the risks.

Fadulu: You ended up switching industries. What propelled that move?

Shetterly: In retrospect, I think it was part of a longer-term project of trying to find the right thing. A restlessness. There were so many interesting things going on. During the ’90s the internet really started to take off. I had friends who were working in that industry; it seemed really exciting.

There is really a fundamental part of me that is an entrepreneur and drawn to start-up ventures and drawn to the adventure. The idea of starting something new was really appealing and I think fundamentally closer to who I am as a person.

Fadulu: This whole idea of figuring out what your temperament is and matching it to a job—how do you figure that out?

Shetterly: I think it’s trial and error. I think it takes time. It would never have occurred to me to seek [a career as a]  writer directly. I don’t think there is any way I could have sought it directly. I had to go through all of these different things and collect all of these different skills, and meet people, and fail, and be unhappy, and question myself. Then, once those things happened, I could move on to the next thing. There’s no way I could have connected these dots in the beginning.



Months ago, inmates across the U.S. began planning a strike over prison conditions, including low or nonexistent wages. To start getting the word out, they didn’t target big news organizations. Instead, organizers posted about the imminent strikes to their own social-media followers. And they contacted publications with an activist bent, like Shadowproof, a press organization focused on marginalized communities, and the San Francisco Bay View, a black-liberation newspaper.

They worried, based on past experience, that mainstream outlets would emphasize that prisoners’ often anonymous accounts of the strike couldn’t be verified and the fact that the impact of the strike was hard to predict. But more radical publications, they believed, would focus on the strikers’ message, about unjust prison conditions and what should be done about them. That message could be amplified online, and picked up by bigger publications. “We intentionally went from the bottom up,” Brooke Terpstra, an organizer in Oakland with the Incarcerated Workers Organizing Committee, a group that has been supporting the strike, told me.

The strike began on August 21 and is set to last through September 9, the anniversary of the Attica prison uprising of 1971. In addition to calling for prisoners to be paid the prevailing wage where they live (under the current regime, they can be paid a couple of dollars an hour, or, in some states, nothing at all), the strikers’ list of 10 demands includes voting rights for “ex-felons” and better funding for rehabilitation services. Thus far, it’s not clear how widespread the protest has been. Organizers report that prisoners are striking in Washington, Georgia, South Carolina, and California, among several other states, where prisoners are refusing to work and eat. That’s a conservative estimate, Terpstra told me, as organizers want to remain cautious in order to maintain credibility. Early on, one organizer suggested in an interview that non-prisoners should demonstrate their solidarity by protesting outside prison gates, which appears to have happened at some facilities. In general, prison officials have largely countered the organizers’ claims, saying they’re not aware of any strikes at their facilities.*

Still, the strikers’ strategy, designed for the current media moment, has proved extraordinarily successful by the measures set by the strikers themselves. Following initial pieces in publications like Shadowproof and the Bay View, mainstream outlets including The New York Times, The Washington Post, and NPR started covering the protest. Social-media posts from the strike organizers and their supporters have gone viral. People are talking about the strike and, by extension, about poor prison conditions across the U.S. and prisoners’ demands to see them changed. In an era in which most people experience public events by reading, hearing, and watching videos about them online, the inability to get an inside look at the current prison protest doesn’t seem to have hampered its reach.

“Just as the men in Attica knew that it was important to reach out to the media when they protested inhumane prison conditions in 1971, so too do the folks inside today,” Heather Ann Thompson, a historian and the author of Blood in the Water: The Attica Prison Uprising of 1971 and its Legacy, told me in an email. “Prisons are allowed to be the terrible places they are because, despite being public institutions that we fund and are run in our name, we are allowed no look at what goes on inside.”

For all the public attention, Terpstra pointed out that mainstream lawmakers and political organizations, including labor unions, haven’t said much. A day after the strike began, Ro Khanna, a Democratic congressman representing Silicon Valley, tweeted his support. “Instead of focusing on rehabilitation, inmates are exploited for cheap labor,” he wrote, noting that prisoners working for a dollar an hour are fighting wildfires in his home state. “That is simply inexcusable.” Alexandria Ocasio-Cortez, the Democratic congressional candidate from New York, wrote, “I don’t believe slavery should exist anywhere in the United States. Including in our prison system.” But many higher-profile politicians have remained silent.

Terpstra says that this is to be expected. He argues that typical political processes tend to defang, and eventually kill, movements such as this one. Still, barring successful legal action on the part of prisoners, conditions aren’t likely to change much without politicians’ involvement. As Christie Thompson has written at The Marshall Project, several of the most prominent work stoppages of recent decades have ended with mixed results, and any gains have typically been achieved as the result of policy changes or legal action.

At the same time, if strikers are indeed generating considerable awareness of their issues among the voting public, that may be more valuable than any single politician’s tweets. And in an age of declining union membership in the U.S., they may be onto something that other labor groups can learn from: If strikers can use the internet to spread their message, such that the online propagation of that message overtakes the fact of the strike itself, perhaps it doesn’t matter how many people are actually carrying picket signs.

 * This article originally suggested that solidarity protests outside prison gates had not yet taken place.



Editor's Note: This article is part of Exit Interview, a series of conversations about leaving one’s career.

It’s comforting to know people like Meg Spinella, a hospice chaplain, exist. Spinella radiates empathy, even as she jokingly describes herself as “more of a ‘shit happens’” than “an ‘everything happens for a reason’ person.” It certainly felt more like the former when, in 2007, budget cuts bumped her out of the Catholic hospital she worked at in Oregon. Spinella didn’t get to say goodbye to her dying patients.

Spinella calls losing one’s job a form of “grief.” She has ample perspective. While counseling the bereaved for more than 15 years, Spinella, who suffers from multiple sclerosis (MS), lost her brother and her son. Job loss “isn’t near that category,” she said, “but you need to acknowledge that it is … a disenfranchised grief.”

I spoke with Spinella to understand how she understood her capacity for dealing with loss for The Atlantic’s series Exit Interview. The conversation that follows has been edited for length and clarity.

Catie Lazarus: When did you decide you wanted to work with the dying and bereaved?

Meg Spinella: I ran a bookstore, and would volunteer at a hospice, when a Borders and Barnes & Noble opened up around the corner, so mom-and-pop bookstores couldn’t compete. At the time, my mother-in-law and a neighbor across the street were dying, and I realized I had a gift for comforting them.

Lazarus: How did you deal with such emotional anguish while on the job, once you became a chaplain?

Spinella: None of us are getting out of here alive. I chose to work with people who were dying. You can choose to work with people who get better—and many chaplains do. A lot of my colleagues cannot be bedside with the dying. It is my calling.

You’re dealing with a lot of fear. I don’t shock easily. I’ve had a lot of therapy, and the training itself gets at your own issues. They make sure you are firm in your belief system. I was raised Catholic, and I’m now a Unitarian, which accepts all faiths: Buddhists, Muslims, people who don’t believe anything. The job is intense. It’s not for the faint of heart, but it was a good fit for me.

Lazarus: Did you have any idea you might lose your job?

Spinella: I was so blindsided. I had patients who were days away from death. Suddenly, they had to meet someone else. I asked, “Can I see this person one more time?” But no. It left my colleagues in a lurch. My team and I split patients across the county, and with me gone they couldn’t be as good a team for the whole area. It was a huge territory. Some days I would drive 100 miles round trip to see a patient.

Lazarus: How did you find out?

Spinella: It happened very quickly. At the time, I just accepted the reason they gave me, which was that “new management” told them they had to cut certain people. My boss was there, and someone from HR. To have another year or two doing the work I love would’ve been so different.

Lazarus: Do you remember what you felt when they told you?

Spinella: I was angry. It was horrible. I had to clean out my desk, and get that pathetic box of stuff—my pictures.

I couldn’t stop crying, and I am not a crier. My husband was worried about me. But when you are fortunate enough to find work that fits like a glove—and many, many people said that they could not do what I do—and then you lose that? I was in grief and shock. I loved my work, and I was attached to these people and wanted to do right by them. I wanted to say goodbye, so they would know it wasn’t my fault. I was brokenhearted. But I didn’t experience it as rejection as much as a system in such dysfunction.

Lazarus: Did your colleagues say anything?

Spinella: My hospice boss said, “We’ll give you a party.” I said, “Let’s not pretend, I don’t want cake.” Some of them wrote me notes, some called.

Lazarus: You still kept contact with your boss after being let go, right? What was that like?

Spinella: He was very sympathetic. We acknowledged my grief.

Lazarus: Was your family supportive?

Spinella: I’ve been with my husband since I was 18, so I had people who understood, as far as they could, what I was going through. He was a surgeon and got laid off, too. So did my sister, a nurse.

Lazarus: What did you do in the time after you lost your job?

Spinella: I was looking for jobs, and I was sure that younger candidates were getting the jobs I applied for. By the third year, I was looking really far afield—like 90 miles round-trip. I had to factor in if the stress of the commute was worth it, and, at that point, my husband and I were enjoying our time together. I wrote a novel. And I’m in a writing group—that’s a nice thing that I didn’t have time for before.

Besides that, I started counseling private clients almost immediately because people and doctors started calling. Private was more lucrative, but it wasn’t what I preferred doing. It was basic counseling work, not death and dying.

Lazarus: How did you get along financially?

Spinella: We downsized our lives. Unemployment [benefits] helped. I have had MS since 1983, and this was before ACA [Affordable Care Act]. As a family working in the medical field, we were not going to be without health insurance—it was a priority. After ACA passed, I had good coverage. Now, I am on Medicare. My husband and I have dual citizenship with Italy, and that’s our back-up plan if our health-care system gets any more messed up.

Lazarus: It’s been a decade since these events. How are you now?

Spinella: In terms of self-esteem, I am pretty solid. Plus, the recession hit full force in 2008, so I had tons of company. Practically everyone I knew had some effects from that recession. I am not sure if it is even over.

Lazarus: Do you hope to return to a full-time job?

Spinella: We’ve reached the point where we probably wouldn’t, but we were denied the opportunity when we were young enough and still could. It still stings. You just wonder if that hadn’t happened. My husband and I figure out ways to volunteer, and we do our work out of the kindness of hearts because that is who we are. And it benefits us as well: getting to be who you are, whether you get paid for it or not.

Lazarus: What do you recommend for other people coping with job loss?

Spinella: It is grief. I lost a son. I lost a sibling. It isn’t near that category, but you need to acknowledge that it is grief. And there is no place for that grief to go. If you can get help, do. It is a disenfranchised grief. It’s like you have a live-in partner, and you’re not exactly welcome at the funeral. People expect you to get over it in a weekend.

The unemployment statistics are skewed, because there are people who have stopped trying because they aren’t reabsorbed. And you really need help. You’re reinventing yourself.



Marlyn Perez had no choice but to take the job at C&C Agricultural Farms in Clewiston, Florida. She was new to farming, new to America, undocumented, and desperately in need of money.

Perez had just come from Guatemala. She had worked briefly at another farm in North Carolina, harvesting sweet potatoes, but when she got to C&C, a farm located in a remote area called Devil’s Garden, she “saw pretty quickly this was a different situation.” When she didn’t receive her full pay the first week, she went to the crew leader, Reyes Tapia-Ortiz, who told her he couldn’t do anything about it. “This is what I’m paying you. There’s no way to negotiate it differently,” she told me over the phone through a translator from the Coalition of Immokalee Workers (CIW), a farmworker-rights organization. Tapia-Ortiz could not be reached for comment.

The work was grueling, Perez and six other workers alleged in a 2014 lawsuit against Tapia-Ortiz, C&C, and the farm’s owners, Ernesto Ruben Cordero Jr. and Carlos Rodriguez. Ten- to 12-hour days with the threat of no pay from Tapia-Ortiz if they didn’t work the shifts he assigned, including those at night in the packinghouse and overtime, according to the lawsuit. No breaks except for a short pause for lunch, no bathroom nearby, no shelter from the Florida sun. Pesticides burned their eyes, according to the lawsuit, which also said the workers had limited access to food and water, and were instead charged $2.50 for beer and $1.50 for soda, as well as $7.00 for lunch by Tapia-Ortiz’s common-law wife. The workers were also charged for transportation to and from the farm by Tapia-Ortiz, $5 a day.

Perez told me that when she asked the owner about the pay situation, they said she had to figure it out with Tapia-Ortiz, who was a contractor hired to recruit laborers, and when she brought it up with him again he became angry. He told her she had no rights and no papers, so she shouldn’t complain.

Undocumented workers without papers and workers on temporary visas are extremely vulnerable to exploitation in the workplace. This exploitation takes many forms, including unfair labor practices, working without fair pay, and sexual harassment and assault. The agricultural industry in the United States is full of workers who are undocumented or on temporary work visas, people who are particularly vulnerable to exploitation. A report by Polaris, an anti-trafficking organization that runs the National Human Trafficking Hotline and the BeFree Textline, on the typology of modern slavery, found that 91 percent of the cases involving modern-day slavery in agriculture involved foreign nationals. The organization, which used data from the hotline and textline to generate the report, defines modern-day slavery as human-trafficking situations where workers are coerced, forced, or victims of fraud. Many of these workers are on “guest-worker” visas, or temporary work visas associated with an employment role, as is common with agriculture workers, who come on a visa called the H-2A. In another report, Polaris identified nearly 300 H-2A visa holders who had been potential victims of labor trafficking and exploitation in a 12-month period. Eighty-five percent of the victims worked in agriculture, with Florida being the state where the most cases were reported.

Perez kept pushing for what she believed she was owed. As the situation escalated, Tapia-Ortiz sexually harassed Perez, according to the lawsuit. In 2011,  she says, he promised to pay her more if she had sex with him, grabbed her from behind, and fondled her breasts. In August, according to the lawsuit, she says when she rejected his advances and threatened to call the police, he threatened to get her deported. In the fall of 2011, according to the lawsuit, he made sexual advances while she was working in a secluded area among tall tomato plants. After she rejected him, he showed her his pistol in his waistband, she says. He would often wave a rifle or show the pistol to the workers to threaten them, according to the complaint. “Truly I did feel very intimidated and very fearful. I just arrived and I didn’t know anything about the laws or who to call or what I could say or how to say it,” Perez said to me.

One thing she did know: The money was not enough. According to the case, she was making on average $35 a day. (The gender pay gap exists even at the very bottom of the labor market—the men on the farm were making an average of $45, according to the lawsuit.) What she wasn’t spending on food or rent she was sending back home. “My family was really desperately in need of financial support and I was worried about them,” she said. She felt it was hard to bring it up with other workers because the crew manager was always lurking, and when she did ask about it the others repeated the same refrain: He has papers and you don’t, so there’s nothing you can do. She threatened to quit; he threatened to kill her if she did, she says. “I was really scared and felt like I couldn’t leave,” she said.

In recent months, stories of sexual harassment and assault have been flowing on a daily basis from the entertainment, media, and tech industries. But low-wage workers, who are disproportionately women of color, are extremely susceptible to harassment in the workplace, and their stories receive far less attention. According to data compiled by the Center for American Progress (CAP) from the U.S. Equal Employment Opportunity Commission (EEOC), more than one-quarter of sexual-harassment charges were filed in industries with large numbers of low-wage service-sector jobs. This is particularly stunning given that low-wage workers often have few other opportunities, and may not have much padding if they lose their jobs in response to filing a complaint. The analysis by CAP found that almost three-quarters of the harassment cases include an allegation of retaliation.

In a 2012 Human Rights Watch report, nearly all of the farmworkers interviewed said they had experienced sexual violence or harassment or knew someone who had. In 2010, a study found that of 150 Mexican women working in the Central Valley in California, 80 percent had experienced sexual harassment. “Eighty percent—that’s a pandemic,” Noelle Damico, from the National Economic and Social Rights Initiative, told me. After explosive allegations of sexual assault against the Hollywood mogul Harvey Weinstein, Alianza Nacional de Campesinas, an association of farmworker women, submitted a signed letter of solidarity with the women of Hollywood: “We wish that we could say we’re shocked to learn that this is such a pervasive problem in your industry. Sadly, we’re not surprised because it’s a reality we know far too well.”

“The history of agriculture in the U.S. always been one of sexual violence,” said Mónica Ramírez, the president of Alianza Nacional de Campesinas, who comes from a family of farmworkers. “On farms, conditions are ripe for it.”

“This entire industry was founded on a system of slaves, who were brought over and who suffered more greatly than we do even today, “ said Nely Rodriguez, a former farmworker who now is a senior staff member and leader of the Coalition of Immokalee Workers (CIW). “Those roots remain generation after generation,” she told me over the phone through a translator.

In the second half of the 19th century, on the heels of the Mexican–American War and the abolition of slavery, Mexican immigrants grew as a share of the American agricultural workforce. Tens of thousand of migrant workers traveled between the U.S. and Mexico with few restrictions.

In 1942, the U.S. and Mexico created the Bracero Program, which allowed for millions of Mexican men to come across the border for short-term work, predominantly in agriculture. Although the program has long been abolished, the modern guest-worker visas perpetuate the industry’s reliance on inexpensive, plentiful foreign labor in agriculture. The H-2A visa, a temporary work visa issued for seasonal agricultural work, offers limited protection to workers, creating a power dynamic that sets the stage for labor exploitation and sexual harassment. Recruitment is a major pressure point with this visa, which permits an employee to only work for a single employer. If a worker is unhappy and wants to quit, her only way out is to leave the country altogether. “The H-2A program is very difficult program because the employer has control,” Damico said. “When you put that much control in the hands of an employer the situation is ripe for exploitation, through it doesn’t mean it happens all the time.”

For agricultural workers who are totally undocumented, the situation is even worse. In 2010 the Southern Poverty Law Center interviewed 150 immigrant women who were undocumented or spent time as undocumented workers in agriculture and food-processing jobs; all of them said harassment was a problem, and the majority had experienced it. Like Perez, these workers often don’t know their rights and work in isolation. “They are in different parts of the country and don’t even know where they are. Particularly for a migrant relying on a crew leader or someone to literally drive them state to state,” Ramirez said. They are reliant on the job to meet their basic needs for food and shelter, and they don’t speak English, and often don’t speak Spanish, but an indigenous language, such as Mayan. “They can’t access information to be able to get help. We have this huge problem with the immigration system and individuals don’t have a pathways. Perpetrators use their migration status to victimize them.”

For Perez, relief came with a flyer for the Coalition of Immokalee Workers, given to her by a woman in a store. She called a hotline and two women came to her home. In April 2014, Perez and six of her co-workers at C&C Farms filed a federal lawsuit against the farm, its owners, and Tapia-Ortiz, alleging violations of four federal statutes, including the Trafficking Victims Protections Act, as well as various state-law claims. All seven workers were named only as John and Jane Does in the initial complaint because they feared for their safety.

In 2015, the workers settled with the farm and its owners—but not Tapia-Ortiz—for full payment of back wages plus an equal amount in damages (the total sum to be paid was not disclosed). The attorney who represented the farm and its owners declined to comment beyond confirming in an email that “the matter was resolved fairly to the mutual satisfaction of the parties without any liability admitted” by his clients. But although the farm and its owners did not admit liability, they agreed to change practices on the farm by hiring laborers directly instead of through contractors and implementing new policies in regard to sexual harassment, according to a press release issued by the law firm that represented the workers. The farm has since gone out of business.

Tapia-Ortiz, meanwhile, did not participate in the lawsuit. After being personally served with the complaint against him in April 2014, neither he nor any attorney representing him ever appeared in the case.  In June 2016, the court awarded a default judgment against Tapia-Ortiz—a finding of liability based on his failure to appear—to the five workers who alleged that Tapia-Ortiz recruited them to the farm job. In February 2017 those five workers were awarded $3.5 million in damages from Tapia-Ortiz. The claim has yet to be paid, according to Susan French, the lawyer for the workers and the Coalition of Immokalee Workers.

There are signs of change in the industry. Organizations such as Alianza Nacional de Campesinas and the Coalition of Immokalee Workers have stepped in and pushed for important reforms and efforts within the industry. The Coalition of Immokalee Workers has developed the Fair Food Program to ensure major food suppliers purchased tomatoes from farms with good practices. It is a worker-developed partnership among farms, farmworkers, students, the faith community, and corporations. “We took deep experiential knowledge of what the issues are and turned that into a code of conduct and then went on to create all the necessary mechanisms to really change that power dynamic,” Rodriguez, the former farmworker and leader of the Coalition of Immokalee Workers, said.

Fair Food farms have a code of conduct and a series of mechanisms for workers to report sexual harassment and a monitoring system to make sure farms comply. The effort also leverages the power of large corporations to help individual farmworkers. There are 14 companies on board so far, including Walmart, McDonald’s, Subway, Whole Foods and Trader Joe’s. The system could be easily adapted to other industries, and CIW has already introduced it to dairy farms in Vermont. It represents hope for workers in an industry where, for generations, there’s been very little.

This article is part of a project called “The Unfree,” which is supported by Dignity Health Foundation and Silicon Valley Community Foundation.



On a rainy Saturday morning in May, Samantha Farr was standing in front of a steel table, drawing loops in the air with a welding gun. “You want to hear a nice sizzle—and you want to breathe,” Farr, the founder of a Detroit nonprofit called Women Who Weld, told the dozen women assembled around the table at a community workshop in Ann Arbor. “This should be meditative.” She pushed the trigger switch and lowered the welding gun onto a small, squarish slab of metal.

The women—from cities across Michigan, and clad in mint-green jackets and gloves, their hair encased under caps—were learning for the first time how to weld, or how to fuse metals together. Farr pointed to the legs and frame of the table. “Metal is all around you and it needs to be welded.”

Farr was speaking to a broad economic truth. Over the past 18 years, the rapid advancement of automation and globalization has helped contribute to the loss of about 5 million U.S. manufacturing jobs. But the Bureau of Labor Statistics reports that the employment of welders, and those in similar professions, in the United States is expected to grow 6 percent by 2026, compared with 2016 numbers. Much of the welding workforce is approaching retirement age just as the crumbling of infrastructure such as bridges, highways, and oil pipelines means a great deal of metal needs fusing. Unlike with many manufacturing jobs, large infrastructure projects typically require that welding takes place on site, which means the jobs can’t easily be transported abroad.

A deficit in skilled-trade workers emerged about a decade ago. At that time, welding organizations and employers realized that women could help fill the gap. Early efforts focused on recruiting women by emphasizing career perks such as high pay and job stability, and by establishing scholarships for college trade programs. Welding organizations also tried to generally destigmatize the industry through interactive exhibits and mentorship programs for younger recruits.

It’s unclear if those efforts actually increased the number of women pursuing education and careers in welding. In 2016, women made up 4 percent of the welding, soldering, and brazing workers in the United States, unchanged from the percentage in 2010, according to the Bureau of Labor Statistics. “The number of women has increased, but so has the total workforce,” said Monica Pfarr, the executive director of the American Welding Society Foundation, a charitable organization focused on welding research and education.

Women Who Weld and other similar initiatives are now pursuing different approaches. Instead of enticing women into established programs dominated by men at trade schools and colleges, they’re changing the programs altogether. Alternative instruction models are offering classes exclusively for women, many of which are taught by female instructors, and providing subsidized costs and intensive programs that are more affordable and take less time to complete than traditional classes. Bolstered by the #MeToo movement, which has largely bypassed blue-collar women, some are also incorporating sexual-harassment training.

Farr was working toward a master’s degree in urban planning at the University of Michigan in 2013 when she looked into a lab at the school one day and saw sparks flying. She had always been interested in welding and signed up for a class. “I was good at it, and I found it meditative and relaxing,” she says. “I wondered, Why aren’t there more women here with me?” When she started asking around, she concluded that a combination of factors, including socioeconomic challenges, fear, lack of encouragement, and harassment in the workplace, had mostly kept women away from welding.

The existing means of drawing in women seemed limited to Farr. Since 2011, the American Welding Society, an industry group, has been sending a “Careers in Welding” trailer to trade fairs in more than 25 states. It features a virtual welding simulator that allows visitors to experience welding firsthand. In 2012, the Manufacturing Institute, a nonprofit affiliate of the National Association of Manufacturers, launched an initiative to highlight the achievements of women in manufacturing, including welders, and to encourage mentorship of a new generation of female workers.

These efforts, however, tended to funnel interest into welding programs run by vocational schools or trade organizations. As Farr looked into these programs, she found that those offered by vocational schools were time-consuming and expensive (according to recent estimates, the average cost for a one-year associate program in welding is $17,787), and that the ones offered by trade organizations tended to be one-off programs that didn’t adequately prepare students for welding careers. She also found no intensive career-preparation programs designed for and available only to women.

Farr realized that a welding program for women that improved on the existing recruiting efforts might be a way for her to use her urban-planning and economic-development background to help her community. She began applying for grants and funds to start a women’s welding program (which originally cost $5,500 a student for a six-week track but changed to $6,000), and started a partnership with the Coalition on Temporary Shelter (COTS), a Detroit-based nonprofit that aims to alleviate homelessness. In 2014, she created Women Who Weld to teach women the craft and to help them find employment in the field. The organization offers several training programs, including a six-week workshop for unemployed and underemployed women—most of whom live in temporary shelters—who graduate the course prepared for full-time jobs in the aerospace, automotive, and defense industries, or for apprenticeships at welding shops.

Students in the six-week program meet four days a week. They take weekly weld tests and tour production facilities. Farr advises participants on their résumés, and the women take day-long workshops on financial literacy, home buying, and interviewing led by partner organizations. Women Who Weld also tackles ways to deal with harassment, providing guidance for newly minted welders before and after they’ve graduated. In addition, the organization holds single-day workshops as introductory courses, and week-long training classes that cram the intensive course into five days. To date, more than 100 women have completed training (across the one-day, five-day, and six-week options). Farr says everyone who has begun the program has finished it, and all of the graduates who went through the five-day and six-week tracks obtained full-time employment as welders within six weeks. This year, she says, Women Who Weld expects to train around 300 women.

Tiffany Collins, a single mother who was homeless and living at COTS in 2016, heard about the training program and decided to participate in the six-week workshop. She didn’t think anything would come of it, but she saw an opportunity to better herself, and a chance to spend time outside of the shelter. “It turns out I actually fell in love with the thing,” she says. “The idea of being a woman welder, of having a trade and a craft, and, one day, being able to have a career.”

Collins was hired three days after she graduated. She went from the homeless shelter to making $20 to $30 an hour at her job at a auto-parts manufacturer in Plymouth, Michigan, where she works on car frames and is considered an overhead welder—meaning she can weld at any angle, including over her head, horizontally, and vertically. She is the only woman on the line at her shift, but she’s hoping her presence attracts others, as women become encouraged to take on welding and businesses become more open to hiring them. “I feel like a real-life Rosie the Riveter,” she says.

Beyond Detroit, welding initiatives tailored for women include the Women in Welding program run by Chicago Women in Trades, the Latinas Welding Guild in Indianapolis, and Weld Like a Girl in Arizona. In small classrooms with female instructors, women are being prepared for entry-level welding jobs and are being taught strategies to deal with sexual harassment in the workplace. Traditional programs, too, have recognized the benefit of this approach and have begun incorporating women-only courses into their curriculums. A report published by the Institute for Women’s Policy Research about attracting women to middle-skill jobs such as welding cites women-only pre-apprenticeship programs and workshops as ways to make up for gender deficits in the job market.

Despite the inroads women are making in the industry, sexual harassment continues to be a challenge in the male-dominated welding business, and often goes undocumented. Amanda Todd, a former hairdresser who graduated from Women Who Weld last year and now works as a welder, said that although she has never felt harassed, she has received comments from male co-workers that someone else might interpret as harassment. “One time someone asked me if I wanted to cheat on my boyfriend and I said, ‘You know I could get you fired for that, right?’”

In her workshops, Farr makes sure to cover what women might face in their welding jobs, addressing how they can report and immediately document instances of harassment. She also vets the shops that she matches with female candidates, going on tours and meeting with human-resources departments to see if the working environment appears safe and comfortable for women. Farr believes that as more women join the industry, circumstances will change. “I want to walk into a shop and have no one even look up—that’s a good sign,” she says.

At her Ann Arbor class, the women got more comfortable as the day wore on. At one point, Farr yelled, “Flash!”—a warning about the bright light from a weld she was about to demonstrate—and everyone pulled their helmet down over their face. Farr guided the torch in a looping motion over the metal, until an even weld had formed. “It’s almost like frosting,” one of the women said. “Like cake decorating.” “I’ll try it,” said another.



Here is a brief modern history of Republican attitudes toward the deficit. For eight years under an Obama presidency, Republicans foretold of a debt apocalypse and urged lawmakers to slash deficits by trillions of dollars. Under Trump, both GOP-controlled houses passed a corporate tax bill that economists predict will grow deficits by at least $1 trillion in the next decade. Then, within hours after the tax bill passing the Senate, Republicans stepped up efforts to cut welfare spending on low-income Americans because, in the words of Sen. Orrin Hatch, “we don’t have any money anymore.”

This flip-flop—or, more accurately, a flip-flop/flop-flip—might strike some as a trivial double-reversal, or just quotidian hypocrisy. But it’s a microcosm of the GOP economic agenda, which has made regressive deficit-busting tax cuts the centerpiece of the party’s national agenda while using fears of the deficit as a stalking horse to attack progressive spending.

This is the long game of Republican economics, and it is the opposite of a secret. In fact, it is a published document. For years, House Speaker Paul Ryan, with broad party support, has proposed budget blueprints that both cut corporate taxes, thus returning trillions of dollars in post-tax income to business owners and investors, and slashed government spending on health care and anti-poverty programs.

Now Republicans seem poised to enact much of that very agenda. With corporate tax cuts nearly out the door—pending some ironing out in conference between the House and Senate—Republicans are turning their attention to the welfare system, arguing that neither the deficit nor the economy can afford current programs that help the sick or poor. In a recent radio interview, Ryan told radio host Ross Kaminsky that Republicans will try to reduce spending on Medicare, Medicaid, and anti-poverty programs in 2018, despite the absence of a filibuster-proof majority in the Senate. “We’re going to have to get back next year at entitlement reform, which is how you tackle the debt and the deficit,” he said. Meanwhile, The Wall Street Journal and The Washington Post report that the GOP might start by targeting the Supplemental Nutrition Assistance Program (also known as SNAP, or food stamps), the Temporary Assistance for Needy Families program (TANF), Social Security Disability Insurance, or Medicaid.

There are two major Republican arguments against anti-poverty spending and social insurance—an affordability argument and an efficiency argument. One Republican claim against these programs, as Senator Hatch and Ryan have previewed, will be that there is not enough revenue to support them. It’s a strange claim that’s even more strangely timed. Whether or not the U.S. is approaching a debt crisis in the next decade—I honestly don’t know—it seems bizarre to raise this alarm after passing a bill that greatly increases the debt. It’s like a husband who, after years of obsessing about the family’s finances, buys a Lamborghini on a lark, drives home, and rants to his wife about the mortgage.

A second angle of attack against anti-poverty spending will claim that welfare reform will alleviate poverty and grow the economy by forcing low-income layabouts back to work. “Sometimes we need to force people to go to work,” Representative Rod Blum, an Iowa Republican, said. “There will be no excuses for anyone who can work to sit at home and not work,” Representative Clay Higgins, from Louisiana, concurred. President Donald Trump, who once promised “I am going to take care of everybody,” has embraced and embellished the argument that welfare makes people lazy and rich. “The person who is not working at all and has no intention of working at all is making more money and doing better than the person that’s working his and her ass off,” he said at a speech last week in Missouri. (Ironically, the biggest winners of the GOP tax bill would be the lazy rich, since rich heirs and passive business owners would see their effective tax rates plummet.)

Economic research does not quite square with the Republican assessments. The welfare queen is a pernicious American myth. The left-leaning Center on Budget and Policy Priorities has published numerous reports showing that SNAP does little to discourage work among its recipients. Other research has shown that food stamps lift millions of non-seniors out of poverty, more than any program other than the Earned Income Tax Credit. To cut SNAP as a sequel to slashing the corporate income tax would be a rather explicit reverse–Robin Hood, fattening the after-tax income of the rich as a prelude to further impoverishing the poor.

Why are Republicans doing this?

Not to burnish their popularity, surely. There is no evidence of public pressure to cut welfare spending in this growing economy. Meanwhile, just 29 percent of the public approves of the corporate tax cut, according to the latest Quinnipiac poll. That makes it one of the least popular pieces of legislation in the last 30 years. (The Affordable Care Act, also quite controversial, received around 40 percent support according to most pollsters in March 2010, when it was signed.)

Perhaps the Republican economic agenda does not appeal to the public because it was never meant to do so. Rather, it is exquisitely designed to mollify a class of corporate-libertarian donors, like the Koch brothers, who are members of a coordinated multidecade effort to make tax cuts on the rich and the destruction  of welfare programs their core agenda.

The idea that donors are dictating GOP economic agenda is not some leftist conspiracy theory. It is the official testimony of the Republican Party. To quote evidence from a previous piece:

“My donors are basically saying, ‘Get it done or don’t ever call me again,’” Representative Chris Collins, a New York Republican, told The Hill.  

The “financial contributions will stop” if the GOP fails to deliver corporate tax cuts, Senator Lindsey Graham, a Republican from South Carolina, told NBC News.

“The donor class … has concluded that the inaction of this administration and Congress is totally unacceptable,” Josh Holmes, the former chief of staff to Senator Mitch McConnell, told CNN.

“(Donors) would be mortified if we didn’t live up to what we’ve committed to on tax reform,” Steven Law, the head of Senate Leadership Fund, a super PAC, told the New York Post.

It seems harsh to say that Republican politicians are mere servants to plutocracy. But when several members of the same organization independently claim the exact same motive, one is obligated to believe them.

Liberals wailed after the Senate passed the tax bill last week. Their reaction isn’t entirely wrong, perhaps, just premature. A corporate tax cut is not the end of the republic. But it’s not the end of the GOP economic agenda, either. The latter will only conclude with a war on the multidecade effort to protect the poor, sick, and old through federal social-insurance programs that, despite their prodigious and rising cost, have largely succeeded in doing so. If Republicans are as triumphant in their second effort as they were in cutting corporate rates, the wailing may be justified.



CORONA, Calif.—Roberta Gordon never thought she’d still be alive at age 76. She definitely didn’t think she’d still be working. But every Saturday, she goes down to the local grocery store and hands out samples, earning $50 a day, because she needs the money.

“I’m a working woman again,” she told me, in the common room of the senior apartment complex where she now lives, here in California’s Inland Empire. Gordon has worked dozens of odd jobs throughout her life—as a house cleaner, a home health aide, a telemarketer, a librarian, a fundraiser—but at many times in her life, she didn’t have a steady job that paid into Social Security. She didn’t receive a pension. And she definitely wasn’t making enough to put aside money for retirement.

So now, at 76, she earns $915 a month through Social Security and through Supplemental Security Income, or SSI, a program for low-income seniors. Her rent, which she has had to cover solo since her roommate died in August, is $1,040 a month. She’s been taking on credit-card debt to cover the gap, and to pay for utilities, food, and other essentials. She often goes to a church food bank for supplies.

More and more older people are finding themselves in a similar situation as Baby Boomers reach retirement age without enough savings and as housing costs and medical expenses rise; for instance, a woman in her 80s is paying on average $8,400 in out-of-pocket medical expenses each year, even if she’s covered by Medicare. Many people reaching retirement age don’t have the pensions that lots of workers in previous generations did, and often have not put enough money into their 401(k)s to live off of; the median savings in a 401(k) plan for people between the ages of 55 and 64 is currently just $15,000, according to the National Institute on Retirement Security, a nonprofit. Other workers did not have access to a retirement plan through their employer.

That means that as people reach their mid-60s, they either have to dramatically curtail their spending or keep working to survive. “This will be the first time that we have a lot of people who find themselves downwardly mobile as they grow older,” Diane Oakley, the executive director of the National Institute on Retirement Security, told me. “They’re going to go from being near poor to poor.”

The problem is growing as more Baby Boomers reach retirement age—between 8,000 to 10,000 Americans turn 65 every day, according to Kevin Prindiville, the executive director of Justice in Aging, a nonprofit that addresses senior poverty. Older Americans were the only demographic for whom poverty rates increased in a statistically significant way between 2015 and 2016, according to Census Bureau data. While poverty fell among people 18 and under and people 18 to 64 between 2015 and 2016, it rose to 14.5 percent for people over 65, according to the Census Bureau’s Supplemental Poverty Measure, which is considered a more accurate measure of poverty because it takes into account health-care costs and other big expenses. “In the early decades of our work, we were serving communities that had been poor when they were younger,” Prindiville told me. “Increasingly, we’re seeing folks who are becoming poor for the first time in old age.”

This presents a worrying preview of what could befall millions of workers who will retire in the coming decades. If today’s seniors are struggling with retirement savings, what will become of the people of working age today, many of whom hold unsteady jobs and have patchwork incomes that leave little room for retirement savings? The current wave of senior poverty could just be the beginning. Two-thirds of Americans don’t contribute any money to a 401(k) or other retirement account, according to Census Bureau researchers. And this could have larger implications for the economy. If today’s middle-class households curtail their spending when they retire, the whole economy could suffer.

The retirement-savings system in the United States has three pillars: Social Security, employer-sponsored pensions or retirement-savings plans, and individual savings. But with the rise of less stable jobs and the decline of pensions, a larger share of older Americans are relying only on Social Security, without either of the two other pillars to contribute to their finances. This by definition means they have less money than they did when they were working: Social Security replaces only about 40 percent of an average wage earner’s income when they retire, while financial advisors say that retirees need at least 70 percent of their pre-retirement earnings to live comfortably.

Today’s seniors are so reliant on Social Security in part because companies that once provided pensions began, in the 1970s, to turn the responsibility of retirement saving over to individuals. Rather than “defined benefit” plans, in which people are guaranteed a certain amount of money every year in retirement, they receive “defined contribution” plans, which means the employer sets aside a certain amount of money per year. This switch saved companies money because it asked employees, not employers, to take on the risks associated with long-term investing. This means that the amount people receive is more affected by the ups and downs of the stock market, their individual wages, and interest rates. In 1979, 28 percent of private-sector workers had participated in defined-benefit retirement plans—by 2014, just 2 percent did, according to the Employee Benefit Research Institute, a nonprofit. By contrast, 7 percent of private-sector workers participated in defined-contribution plans in 1979—by 2014, 34 percent did.  

The recession and economic trends in the years since have also worsened the finances of millions of seniors. Some bought homes during the housing boom and then found they owed more on their homes than they were worth, and had to walk away. Others invested in the stock market and saw their investments shrink dramatically. Jackie Matthews, now 76, lost her investments during the recession, and then had to sell her Arizona home in a short sale, netting only $3,000. She now lives near her family in Southern California, renting a room in a friend’s apartment, and budgets her finances carefully, skimping on meat and never buying anything new.

But even people who emerged from the recession relatively unscathed may have a hard time saving, according to a 2017 report from Government Accountability Office. Average wages, when adjusted for inflation, have remained near where they were in the 1970s, which makes it hard for workers to increase their savings. This has had a significant impact on the bottom 80 percent of workers, for whom average wages have remained relatively constant, even as income increased for the top 20 percent of households in the past three decades.

For many seniors, the answer to this lack of savings has meant working longer and longer, as Roberta Gordon is doing. Today, about 12.4 percent of the population aged 65 or older is still in the workforce, up from 3 percent in 2000, according to Oakley. I met a woman named Deborah Belleau who is 67 and works as a manager at a mobile-home park in Palm Springs, California. She worked as a waitress for 30 years, and often relied on government assistance as she raised her two children as a single mother. “You just don’t think about tomorrow” when you’re more worried about getting food on the table, she said. That means that today, though she receives money through Social Security, she can’t afford a cellphone or a TV. Her rent is $600 a month. She works full-time at the mobile-home park, despite aches and pains in her back and feet. Sometimes, when she wakes up, she can’t walk. But, she says, “I can’t quit. There’s no way I can live on $778 a month,” the amount she receives from Social Security.

These troubles can be particularly hard on women. That’s in part because they typically receive lower benefits than men do. In 2014, older women received on average $4,500 less annually in Social Security benefits than men did. They received lower wages when they worked, which leads to smaller monthly checks from Social Security. They also are more likely to take time off from work to care for children or aging parents, which translates to less time contributing to Social Security and thus lower monthly benefit amounts.

At least Belleau and others are physically able to work. Some seniors without retirement savings or a safety net have become homeless in recent years as housing costs have risen and they find themselves without the ability to generate income. “I see more homeless seniors than I’ve ever seen before” Rose Mayes, the executive director of the nonprofit Fair Housing Council of Riverside County, just east of Los Angeles, told me. In America in 2016, nearly half of all single homeless adults were aged 50 and older, compared to 11 percent in 1990.

What can be done to help today’s seniors and generations to come? There are two approaches, Prindiville says: help people save for old age and make retirement more affordable. As for the first approach, some states have been trying to establish programs that help people save for retirement through payroll deductions even if their employers don’t offer any retirement-savings accounts, for example. But the Trump administration in May repealed an Obama-era rule from the Department of Labor that would have made it easier for states to help people to set up these plans. And the federal government is winding down a program, called myRA, that tried to encourage middle- and low-income Americans to save for retirement. “There are no new initiatives or strategies coming out of the federal government at a time when the need is growing,” Prindiville said.

The second approach might mean expanding affordable housing options, creating programs to help seniors cover medical costs, and reforming the Supplemental Security Income program so that poor seniors can receive more benefits.But there does not seem to be much of an appetite for such ideas in Washington right now. In fact, the Trump administration has proposed cutting money from SSI as well as the Social Security Disability Income program.

These initiatives can make the difference between having a home—and some semblance of stability—and not. Roberta Gordon, in Corona, was barely scraping by when I talked to her. A few months later, she was much more stable. Why? She’d gotten off a wait list and been accepted into the housing-voucher program known as Section 8, which reduces the amount of income she has to put towards housing. She’s still working at 76, but she feels a little more secure now that she has more help. She knows, at least, that she’s one of the lucky ones—able, in her older years, to keep food on the table and a roof over her head.



In a video posted online in May, the actress and model Elle Fanning slouches up to a Tiffany store in an oversized hoodie, holding a take-out coffee cup, to admire the window display. It’s a deliberate play on Breakfast at Tiffany’s, with “Moon River” playing in the background. But as Fanning stands there, in black-and-white, looking both admiring and a bit glum—It’s all beautiful, but can she afford it?—the image turns to color, and a hip-hop beat, from A$AP Ferg, comes in. Soon, Fanning is prancing, bejeweled, through New York; her backup troupe includes a cop and a group of uniformed schoolgirls—all wearing hints of Tiffany blue.

As recently as last year, Tiffany, like a lot of luxury brands, was struggling to get Millennials to buy its products. Common wisdom would suggest that this is because Millennials are an unusually hard-up generation, thanks in part to student debt, the long hangover from the recession, and lower marriage rates (which translates to lower household income).

Tiffany, though, saw a marketing problem. In the past, it had managed to maintain a reputation as a luxury brand while also appealing to aspirationally minded, upper-middle-class Baby Boomers and Gen Xers who would buy lower-priced trinkets such as keychains. But in more recent years, the brand seemed to be losing its appeal, partly because its Upper East Side image meant young people weren’t as impressed by it as they used to be.

In October, Tiffany hired Alessandro Bogliolo, the former chief executive of the Italian apparel brand Diesel, as its CEO, and Bogliolo set out to rebrand the company for the Instagram age, introducing more personalizable jewelry (common wisdom is that Millennials care more about individualism than fitting in), graffitiing Tiffany’s flagship New York store (part of a trend in “brandalism”), planning a major renovation of that shop (built around young people’s preference for interesting experiences over products), and introducing a Millennial-oriented marketing campaign called “Believe in Dreams” (of which the Fanning video is the centerpiece).

On Tuesday, Tiffany reported better-than-expected quarterly sales and said its earnings for the year would be higher than it had earlier thought. In a call with analysts, Bogliolo credited the Believe in Dreams campaign for creating a “modern interpretation of the historical legacy of Tiffany.” The Fanning video’s message, according to a press release, is that “New York is a place where anything can happen, and Tiffany is where dreams come true.” There’s a Hepburnish, city-girl-next-door quality to Fanning’s character in the video that viewers seem to have responded to; it conveys an accessibility that hasn’t historically been associated with the Tiffany brand. “Can y’all invite [me] next time?” reads one top comment on the video, which has been viewed more than 10 million times. “This looked dope.”

Tiffany’s success might have more to do with broad economic conditions than with its marketing. In October, The New York Times, citing data from the consulting firm Bain, reported that people born between 1980 and 2010 had generated 80 percent of the growth in the luxury industry over the previous year. Other luxury companies are also thriving—Gucci and Michael Kors, among others, have also issued positive earnings reports—in part by appealing to the young.

But which young? It would seem impossible that the student-debt generation is responsible for a luxury boom—yet this is also the Crazy Rich Asians generation. Student debt and low minimum wages aren’t dragging down all Millennials. In 2003 and 2005, only one person under the age of 30 appeared on Forbes’s list of the world’s billionaires; by 2010, there were five of them, and by 2017, there were nine. The Credit Suisse Research Institute said in a report last year that Millennials are likely to face a bigger wealth gap than previous generations. “We expect only a minority of high achievers and those in high-demand sectors such as technology or finance to effectively overcome the ‘millennial disadvantage,’” the report’s authors wrote.

Is Tiffany gaining customers among the down-and-out-in-hoodies demographic? Of course not. Brands like Tiffany have never depended on the fortunes of the masses. As ever, the company makes a great deal of its money from items such as $175 silver pendants, which are considered small ticket, as far as the luxury industry goes, but aren’t exactly meant for working-class people. Meanwhile, the Tiffany Paper Flowers collection, which the Fanning video advertises, includes a $5,500 ring made of tiny diamonds in the shape of a flower and a $75,000 platinum-and-diamond necklace. Tiffany also sells $100 “paper” cups (actually made of china) that would seem to be marketed for beer pong—or magic tricks. It seems a complicated branding strategy is afoot—one fully grounded in the economics of the present moment. If the graffiti, the hip-hop video, and the dorm-room glassware can help cleanse Tiffany of its traditional air of snootiness, wealthy young people, aware of what the 99 percent thinks of them and their privilege, might feel a bit better while wearing its jewels.



On Wednesday morning, President Donald Trump—chief executive of a $19 trillion economy, leader of the free world, commander of a nuclear military force—finally weighed in on the stock market’s sudden decline, by arguing with it. “In the ‘old days,’ when good news was reported, the Stock Market would go up,” he wrote on Twitter. “Today, when good news is reported, the Stock Market goes down. Big mistake, and we have so much good (great) news about the economy!”

There is at least one thing he is right about: The stock market is indeed in a slump. For the past few days, indices from around the world have been in various states of free fall, correction, surge, and panic, with the Dow Jones Industrial Average experiencing its biggest-ever one-day point drop on Monday, Nasdaq halting trades in a few financial instruments linked to market volatility, and apocalyptic headlines piling up. Animal spirits, in the memorable phrasing of the economist John Maynard Keynes, are loose.

Trump is right about another thing too: The U.S. does have so much good (great) news about the economy at the moment. Every developed economy on earth is growing right now, for the first time in a decade. Corporate earnings are coming in higher than expected this season, and the jobs market is potentially close to full employment. The major leading indicators continue to look good, as well, dampening fears of an imminent correction or recession.

But his tweet evinces both a prurient interest in the market and a lack of knowledge about its gyrations. The stock market is not a reflection of the true state of the economy. It does not always go up as the economy strengthens, or decline as the economy falls. And no one, save for some day traders and investors with a very short time horizon, need to spend much time worrying what it is doing or why—at least not for now.

In Trump’s formulation, financial markets have a simplistic, monocausal relationship with economic data: good news, markets up; bad news, markets down. In reality, though, financial markets have an obtuse, metaphysical relationship with economic data: good news, who knows; bad news, who knows.   

As a very general point, the markets do tend to drift in the same direction as the economy. Recessions tend to come with declines in the Standard & Poor’s 500 (a far better index to keep an eye on than the Dow Jones, by the way). Expansions tend to come with bull markets. But the financial markets tend to be vastly more volatile than headline economic figures—and that is true even in the long period of unusually low volatility that appeared to end late last week. An economy growing 2 percent a year might see market surges of 2 percent a day, or swift year-on-year growth of 10 percent.

Plus, on a day-to-day level, good economic news does not cleanly translate into a higher market, nor does bad news translate into a worse one. Financial traders take in a huge number of economic and financial variables. They bet on what the other guy knows. They signal. They hedge. They construct algorithms to seek out strange correlations. As such, in the short term, it tends to be surprising news—not good or bad news—that forces market movements. And sometimes it is no news at all.

Indeed, it is often totally unclear what causes a given surge or sell-off. Trump was trumpeting the theory that better-than-expected jobs and wage numbers raised concerns about rising inflation and tighter monetary policy. “The U.S. Federal Reserve is raising interest rates to prevent the economy from overheating,” Ken Griffin, the founder of the investment behemoth Citadel, wrote in a note late last week, just as the market started to sour. “We are particularly concerned about the nascent signs of accelerating inflation in many countries around the world, given the general complacency around the risks of an inflationary shock.” But nobody knows for sure. Perhaps the gyrations have to do with interest rates. Perhaps they have to do with rising wages cutting into corporate profits. Perhaps they have to do with algorithmic trading. Perhaps traders are trolling the new Federal Reserve chairman.

The important thing—and the reason it seems that most Americans can safely ignore the turbulence—is that the economic and business outlook remains rosy. Global growth is secure for now; the Federal Reserve has telegraphed its intention to increase interest rates; businesses are competing for workers. “It seems like people are pricing in that the tax cut is going to have more of a near-term stimulative effect then maybe we appreciated a few months ago,” Neel Kashkari, the president of the Federal Reserve Bank of Minneapolis, said in a television interview this week.

Further, it would take a much more significant sell-off to mar the extraordinary bull run that has gone on for nearly a decade at this point. After the setbacks of the past few days, the Dow Jones is back where it was in December—which is still far higher than it was when President Trump took office, let alone when President Barack Obama took office. Anyone with an investment horizon longer than a few weeks is likely to be firmly in the black, and anyone with an investment horizon longer than a few days would probably do well to ignore the headlines and flashing lights.

That goes for President Trump, too. Presidents have historically tried to avoid talking about these volatile investments, given that what goes up so often goes down, and given that what is good for traders and investors is not always good for workers. But this president touted that the market has “smashed one record after another, gaining $8 trillion in value” in his State of the Union address, and argued that “the reason our stock market is so successful is because of me” a few months ago. That, to be clear, is not true either.



Capitalism has worked out really well for Jay-Z. So well, in fact, that he recently dedicated an entire song to promoting capitalism as a tool of black empowerment. But even with promises of lowered taxes, and financial incentives for the wealthy—things that a wealthy capitalist should in theory love— Sean “Jay-Z” Carter still doesn’t think that President Trump is doing that much good for the black community.

In an interview with the CNN* host Van Jones on Saturday, Jones brought up reports that Trump referred to a number of countries, including many in Africa, as “shithole countries” and then asked if it was okay  for Trump to “say terrible things but put money in our pockets.” Carter unequivocally said no, adding “it’s not about money at the end of the day. Money doesn’t equate to happiness. It doesn’t. That’s missing the whole point.”

Trump took umbrage at the remarks, tweeting, “Somebody please inform Jay-Z that because of my policies, Black Unemployment has just been reported to be at the LOWEST RATE EVER RECORDED!” As I’ve written before, Trump touting the black unemployment rate ignores some crucial context about the economy: First, the black unemployment rate has been dropping for the past eight years. Trump has only been president for one of them. Second, even at 6.8 percent, the black unemployment rate remains nearly twice as high as that of whites.
Trump’s response to Carter confirms precisely what the rapper was trying to say in the first place—that the president fundamentally misunderstands the aims of the black capitalism and the needs of the black community. Jay-Z, and many before him, have espoused capitalism and economic empowerment as a means to an end: racial equality. Being rich is a secondary benefit to the power, stability, and peace of mind that money can provide in a country that has forced blacks into poverty and segregation.

The president seems to think that a record-low unemployment rate for black Americans is a demonstration of how much he—Donald Trump himself—is improving the lives of black Americans, despite the fact that there’s no evidence that the decline is the result of his policies or leadership. But black Americans still earn significantly less than their white counterparts, even with similar levels of education. Their wealth is still around 13 times less. They are more likely to live in poverty and in poor housing conditions. They are more likely to be imprisoned, seriously hampering their earning potential for the rest of their lives. Those are all issues that Trump’s policies don’t even begin to tackle. And that’s to say nothing of persistent inequalities in other critical areas such as health care, mortality, and police violence.

Trump has frequently been criticized for his misreading of black America. He has talked constantly and inaccurately about the plight of black people living in “inner cities.” He has misrepresented his level of support in the black community. His tweet referencing Jay-Z is just the latest in an ongoing pattern of publicly feuding with prominent black Americans who don’t support him. Again and again, Trump has displayed an inability to grasp the actual problems that black Americans must contend with, and the fact that his policies do virtually nothing to address them.

*This article previously stated that Van Jones is a host on MSNBC. He is a host on CNN. We regret the error.



On Tuesday, the Senate quickly and easily made Jerome Powell the 16th head of the Federal Reserve Board with an 84 to 13 vote. Powell will officially begin his stint as the leader of the nation’s central bank in February.

The speed and ease of the confirmation of Trump’s nominee isn’t much of a surprise: Selecting Powell, instead of more conservative or hawkish options such as Kevin Warsh and John Taylor, was seen as a sensible compromise that could ensure a swift and painless vote. Powell offers qualifications that appease both the GOP and Democrats: He’s a moderate Republican with a track record as a Fed governor of supporting the previous Fed chair (and Obama appointee) Janet Yellen, while remaining open to the idea of deregulation, according to statements he’s made in the past—a key Trump goal.

Tuesday’s uneventful path to confirmation stands in stark contrast to Yellen’s experience in 2013. After harsh criticism from many Senate Republicans, mostly centering on concerns that she would keep interest rates low, Yellen was confirmed with a much narrower margin: 56 to 26. While few Senators spoke up against Powell during his hearing, Senator Elizabeth Warren, who cast a dissenting vote along with eight other Democrats, expressed concern about the nominee’s willingness “roll back critical rules that help guard against another financial crisis.”

Powell’s ascent to the Fed’s top job is a departure from historical norms in a few notable ways. Trump’s choice to replace Yellen with Powell marks the first time in modern history that a Fed chair who completed her first term wasn’t offered a second. The departure is even more striking given the fairly bipartisan assessment that the economy has consistently strengthened—with a historic period of job growth, falling unemployment, and increasing GDP—under Yellen’s tenure.

Moreover, at the time of her nomination, Yellen’s qualifications for the role of Fed chair were stronger than Powell’s are now. Prior to chairing the Fed, Yellen, who has a doctorate in economics, had served as the chair of the Council of Economic Advisors, the president of the San Francisco Fed, and as a Federal Reserve vice chair. Powell, a lawyer and banker, will be one of the first Fed chairs in recent history to not hold a Ph.D. in economics, a degree that many economists, most notably Alan Blinder of Princeton, have said is essentially a prerequisite for the job in modern times.

Not all of Trump’s Fed nominations have gone as smoothly as Powell’s. Also on Tuesday, Senate Democrats grilled Marvin Goodfriend, a conservative economist from Carnegie Mellon who criticized the Fed’s actions under Yellen. During his confirmation hearing for one of the board’s vacant governor seats, senators including Sherrod Brown and Elizabeth Warren, both Democrats, asked Goodfriend pointed questions about his predictions that the Fed’s policies after the economic crisis would lead to runaway inflation—a problem that never manifested. Elizabeth Warren stated that she wouldn’t vote to confirm Goodfriend, adding, “I think based on the kind of judgment you have demonstrated, American families are very lucky that you weren’t on the Fed board over the last several years.”

Trump’s nominees can move ahead without the blessing of Senate Democrats, since Republicans hold a majority. With a new Fed chair in place, and more likely to follow, Trump has successfully completed a major step in influencing the direction of the country’s monetary and economic future by moving his appointees into positions of power.

Still, Powell’s Fed, at least in the early days, will look a lot like Yellen’s—he supported just about all of her policy decisions and never cast a dissenting vote against her in Federal Open Markets Committee meetings during her tenure. That means a continuation of cautious interest-rate hikes and a slow unwinding of recession-era interventions. That formula likely pacifies Democrats who wanted Yellen appointed for a second term; it also appeals to conservatives who are now enjoying growth in both the stock and job markets—an upswing that was borne of Yellen-era policies.



President Donald Trump’s long-anticipated tariffs are finally here: 25 percent on imported steel and 10 percent on imported aluminum, with a formal announcement on the measures to be made next week.

The White House has argued that the tariffs would punish China for unfair trade practices and help American blue-collar workers afflicted by decades of manufacturing job losses and wage stagnation. “We must not let our country, companies and workers be taken advantage of any longer. We want free, fair and SMART TRADE!,” President Trump wrote on Twitter on Thursday. But business leaders and economists from across the ideological spectrum question how much good Trump’s tariffs would do—and whether they might even backfire, raising costs for American consumers, hurting American exporters, straining American economic relationships around the world, and ultimately slowing down growth.

That is not to say that the tariffs do not have a constituency among certain manufacturers, or that they are not meant to address real and painful changes in the American economy. Steel production has fallen to 82 million metric tons a year from nearly 100 million a decade ago, with three out of four domestic aluminum smelters shuttering over the past few decades. That has meant thousands and thousands of job losses. At the same time, foreign producers have ramped up production, pushing down prices and leading to increased American imports.

The issue, the Trump administration has argued, is not just one of jobs, wages, imports, and exports. It is also one of defense strategy: The U.S.’s reliance on imports leaves critical industries vulnerable to potential embargoes and trade actions by its enemies.

But trade experts see a number of problems with the White House’s argument for instituting tariffs on security grounds. Trump himself has repeatedly mentioned China’s trade practices as justification for the tariffs, for one. And the vast majority of  the U.S.’s imports come from strong allies: Canada, South Korea, Mexico, Germany, Japan, and Brazil all export more steel to the United States than China does. “There is no question that steel and aluminum, materials used in the production of weapons and military systems, are vital for America’s military superiority,” a group of conservative think-tank scholars argued in response to then-potential tariffs in late February. “But it is not realistic to expect that foreign producers would withhold supplies in the case of a national security emergency.”

The flimsiness of Trump’s justification raises the risk of retaliation by the United States’ trading partners, many of whom have lobbied against the tariffs since the earliest days of the Trump presidency and are expressing their frustration with the tariffs now. Trade experts expect tit-for-tat actions, meaning lower sales for American businesses abroad. “If the United States goes down this path for steel and aluminum, there is little to prevent other countries from arguing that they too are justified to use similar exceptions to halt U.S. exports of completely different products,” argues Chad P. Bown of the Peterson Institute for International Economics, a Washington-based think tank broadly supportive of free trade. “Because this leads to a downward spiral and erodes meaningful obligations under international trade rules, justifying import restrictions based on national security is really the ‘nuclear option.’”

To that end, China has indicated that is ready to take action. “China urges the U.S. to use trade protection tools with restraint and comply with multilateral trade rules so as to make positive contribution to the international economic and trade order,” its Ministry of Commerce warned last month, adding, “China will definitely take necessary measures to safeguard its legitimate rights.”

The specter of a trade war undercuts Trump’s economic argument. The president has promised that steel and aluminum tariffs will bolster domestic industries and boost American payrolls, with some labor leaders and business executives in agreement. “U.S. steel and aluminum industries have been heavily injured by massive growth of excess capacity and overproduction in China and other countries,” argues Robert E. Scott of the Economic Policy Institute, a left-of-center think tank. “More than 13,000 U.S. jobs have been lost in aluminum since 2000—and 14,000 steel jobs disappeared in [the] last two years alone.” But America’s steel and aluminum industries simply do not employ that many workers. Restoring all those jobs would be but a blip in a monthly payroll report.

More broadly, the tariffs will raise costs for a vast sweep of businesses, given that steel and aluminum are major inputs in auto manufacturing, oil and gas extraction, and construction, as well as in the production of everything from beer cans to golf clubs. Manufacturers “will be paying higher prices for our stainless steel going forward, ironically making us less competitive against foreign-finished goods,” said Greg Owens, the president of the flatware maker Sherrill Manufacturing, in a press release. He wants the White House to take measures to ensure that foreign goods would not be cheaper as a result of the tariffs, “a critical next step that if left unaddressed will turn this first positive step into a catastrophe for American manufacturing.”

Plus, the tariffs will invite retaliatory actions that could hit a huge number of American exporters. “Every time you do this, you get a retaliation, and agriculture is the number one target. I think this is terribly counterproductive,” Senator Pat Roberts, a Kansas Republican, told reporters on Thursday. There are numbers to back this economic case up: A study of a similar trade actions taken by the George W. Bush administration found that they cost the economy an estimated 200,000 jobs, including roughly 11,000 in Ohio, 10,000 in Michigan, 10,000 in Illinois, and 8,000 in Pennsylvania.

Trump’s “smart” trade action, then, might spark a trade war, hurt the auto industry, bleed jobs from the Rust Belt, and anger American allies around the world. A small number of companies and workers stand to benefit, but a far larger number are now at risk.



Editor's Note: This article is part of an oral-history series where Aaron Reiss interviewed the young-adult sons and daughters of Chinatown shopkeepers about how they are helping to keep their families’ businesses alive.

Alice Liu, a 24-year-old community advocate, lends a hand at her parents’ small shop, GTW Tea and Water, which sells Chinese cultural goods such as teas, Buddhist items, and tourist tchotchkes. Over the years, she’s helped her parents in all kinds of ways, including with food prep at a restaurant they once owned. “I have vivid memories of sitting over a giant box of takeout soy-sauce packets, using scissors to clip the corners, and draining them into a bucket,”

I spoke with Liu in the spring of 2018. Below is our conversation, lightly edited for clarity.

I started working with my parents when I was 6 or 7 years old, back when they were running a small Chinese-food restaurant on Rivington Street. After school, my mom or dad would pick up my sister and me and bring us back to the restaurant. When I wasn’t doing my homework, I would wait on customers, wipe down tables, or clear dirty dishes and bring them back to the kitchen.

Obviously, we weren’t, like, hard-laboring … a lot of the time, we were outside skipping rope or chalking the sidewalk. Really, it was child care, since my parents couldn’t leave the restaurant or afford someone to watch us. But when my dad wanted to “build character,” he would pull us into the back for whatever work we were capable of. I have vivid memories of sitting over a giant box of takeout soy-sauce packets, using scissors to clip the corners, and draining them into a bucket. We figured out you could clip five at a time. So we would make these little stacks, clip, drain, stack, clip, drain.

I would chop mushrooms in the morning on weekends. My hands would smell like them for the rest of the day. I peeled green onions, trimmed green beans—any non-dangerous job. Eventually I graduated to washing dishes, when I was around 8. Then I got to scoop rice or soup during the lunch rush. The vats were so big, I could have fit inside them. Delivery was my favorite—I’d walk orders over to nearby construction sites and get $1 tips, which I immediately traded in for ice pops or chips. I felt like a queen.

It wasn’t until high school that I started really being useful to the business. Business dried up at our restaurant, but we ended up opening a little shoe/jewelry/DVD/party-planning store at 250 Grand. Foot traffic was low, because we were on the second floor, so my sister and I would drag a box of shoes onto the street and just sell them on the sidewalk. They were $3 for children’s sizes and $5 for adults. We would get stopped by police, ticketed—it scared me out of my mind.

When I left for college, my parents moved to the place they are at now, GTW Tea and Water. GTW stands for “Good Tea and Water.” (I know, I’m working on a rebranding.) During college, I would come back on weekends to help out, working the register, doing bookkeeping, and things like that.

Right after my graduation, my grandmother died. My father had to go back to China to take care of things, and I had to step in to help my mom run the shop full-time. I wanted to be looking for work in the things I studied, but my grandma had just passed away, and I needed to do what I needed to do to make sure my dad had peace of mind while he was away.

I tried to take on new projects for them, to help them modernize. I was telling them to get a credit-card system for years. They liked working in cash; it was easier. My dad has kept all his financial records in handwritten notebooks, forever. Finally, I just set up a Square system. It took a year, but they got used to it, and now they can accept credit cards. I’m helping them set up an online shop, just trying to bring them into the modern era. I mean, this is a quickly dying business; my generation isn’t interested in fine tea or Buddhist items. It’s hard. I have to teach myself Photoshop, how to take product photos, how to style a website, how to write copy, and how to set up inventory. This is all new to me.

My dad wants to work until his last breath. In his mind, that would be a life well spent. And my sister and I want them to have success after all this bitterness—that’s the only way it’s sweet. That’s why we are investing so much of our time and money. We inherited from them a hunger, this nonstop pushing. The whole family, we want to break through with all the hard work we’ve put into this business. And with how hard they’re working, how could I work any less hard?

There’s also my own desire for a legacy. I learned from two full-Chinese people and ended up with this totally personal version of our culture. I can only imagine the shitty version of Chinese culture I would be able to pass on to my kids. I want my kids to have this. I want them to be Chinese.

Over the years they’ve offered to pay me, but I’ve never accepted. I know how hard the money is to come by; I can’t take it from them.

It’s our job to pull our parents out of poverty. If we don’t do it, who else will?



By the end of the day on Monday, the Dow had lost more than 1,100 points since the markets had opened that morning—its largest one-day drop ever. The day’s losses totalled up to around 4.6 percent percent of the index’s value, which is not insignificant, but also not unheard of: A drop of more than 3 percent followed Brexit back in 2016. And Monday’s losses weren’t on anywhere near the scale of Black Monday, a day in 1987 that earned its name from the erasure of more than 20 percent of the Dow’s value.

Watching the market tank, however precipitously, is always scary. That’s probably why several brokerage sites, such as Fidelity and Vanguard, crashed on Tuesday, as frantic investors clamored to check their portfolios. But even as the Dow slid in historic fashion, many analysts still weren’t panicking. Why? They’ve been expecting this type of adjustment for years.

For a moment on Tuesday morning, the stock market was on the way up. Then it plunged again, and continued to zig and zag as the day progressed. The Dow’s roller-coaster-like performance may seem unusual and dramatic, but it’s actually just a somewhat abrupt restoration of a fairly normal feature of markets: volatility.

The stock market has been on a historic bull run, hitting several new highs with mostly uninterrupted growth. This impressive streak has allowed the Dow to nearly quadruple since 2009. That’s why the impact of Monday’s enormous slide has been nowhere near as big as that of the crash in 1987, even though the recent drop-off seems large.

During the most recent run, there have been only a few small and short-lived moments when that upward trajectory has been halted or reversed. (When these moments are especially dramatic—when a major index loses 10 percent or more of its value—analysts call them “corrections.”) Historically, that type of uninterrupted growth isn’t normal. In fact, the lack of market dips is what led some, including Donald Trump at one time, to worry that perhaps a bubble was forming, and that stocks were artificially inflated.

Most analysts agree that there’s little evidence that a sizable bubble exists—that the markets have been on a tear because the economy has slowly and steadily been strengthening since the end of the Great Recession. Since then, an improving labor market, higher corporate profits, and interest rates kept low by the Fed have meant boom times for big businesses and the investors who poured their money into the markets. Now, some of that may be changing, even if the fundamentals of the economy aren’t.

There have been plenty of theories about why the market has sunk, even though it’s considered difficult (if not impossible) to point to any single explanation. One of the more outlandish ideas is that the market is “testing” the Fed’s new leader, Jerome Powell, but that’s more conspiracy theory than reality. Others suggest that recent political and economic shifts might be behind the losses. The January jobs report showed that average hourly earnings grew 2.9 percent over the past year—the most significant growth since 2009. While that’s great news for most Americans, it could mean tighter profit margins for corporations. Further, a strengthening economy could mean that the Federal Reserve chooses to raise rates more drastically than it has in the past—which would making securing credit and borrowing more expensive than they have been in years. As investors and business owners consider those potential changes, they could start making new calculations about where to put their money.

Even as the markets continue to fluctuate wildly, and volatility persists, it’s important to remember that the economy has lately been full of good news. Wages are growing, corporations are more profitable than ever, unemployment is low. While the most recent downturn might be unsettling, it’s actually pretty normal.



Over the past few weeks, Walmart executives have sketched a picture of the company’s future that features more self-checkouts and a grocery-delivery business—soon escalating to 100 cities from a pilot program in six cities. Personal shoppers will fill plastic totes with avocados and paper towels from Walmart store shelves, and hand off packages to crowdsourced drivers idling in the parking lot. Assembly will be outsourced, too: Workers on Handy, an online marketplace for home services, will mount televisions and assemble furniture.

The Walmart of the future relies more heavily on the gig economy and automation. This is an indication of the fierce competition between Walmart, the world’s largest private employer, and Amazon. A pair of recent studies suggests that it’s also a sign that the U.S. economy is tilting further toward jobs that give workers less market power.

One study, by Arindrajit Dube of the University of Massachusetts at Amherst, Jeff Jacobs and Suresh Naidu of Columbia University, and Siddharth Suri of Microsoft Research, sought to learn whether crowdsourced workers benefit from being able to choose their tasks and hours. The answer matters to a lot of workers. Flexible work arrangements, which include crowdsourcing platforms such as Uber, as well as freelancers and independent contractors, increased about 50 percent from 2005 to 2015. These jobs account for 94 percent—nearly all—of the net employment growth in the United States over that time.

This shift could be good for workers, in theory, if the flexibility of the gig economy lets them switch more easily between employers to take advantage of higher-paying offers. Yet in their analysis of the online-task marketplace Amazon Mechanical Turk, the researchers find that this isn’t necessarily happening. MTurk workers, or Turkers, get paid for repetitive tasks, such as tagging objects found in images or verifying restaurant phone numbers. According to the study, Turkers’ wages amount to less than 20 percent of their productivity—in other words, for every dollar of value produced on MTurk, workers receive less than 20 cents. The Turkers’ share compares with a share of 50 cents to 80 cents of every dollar for workers in the U.S. economy as a whole, Naidu says. “This suggests that much of the surplus created by this online labor-market platform is captured by employers,” the researchers write.

That doesn’t make intuitive sense; since workers can easily switch between tasks, it seems employers would be forced to compete for them by offering good wages. Why isn’t this generally taking place? One explanation is that while workers can shop around for a better deal, employers can do the same. And it may be more important for Amazon to design a crowdsourcing platform that keeps employers happy; after all, Amazon’s revenue comes from charging employers a fee. If other platforms such as Uber have a similar design favoring buyers, then the drivers dropping off Walmart’s groceries won’t have much bargaining power.

“Wages are going to fall,” Naidu predicts. “It’s interesting that Walmart is being so proactive in gig-ifying its own workforce. Retail is one of the sectors that you thought you couldn’t really outsource, but maybe that was wrong.”

The second pillar of Walmart’s approach, automation, could also be bad for workers. Walmart has doubled its use of self-checkouts in stores, according to a recent investor presentation, and newly remodeled locations have fewer lanes staffed with a cashier. What’s more, inside its Store No. 8 incubator, which is experimenting with technologies such as robotics, virtual and augmented reality, and artificial intelligence, Walmart is, according to Recode, developing Project Kepler—a store similar to Amazon Go with no checkout lines or cashiers.

In theory, automation doesn’t have to eliminate jobs, on balance, or drive down worker pay. It could free up workers to do higher value, better-paid tasks. It could generate consumer demand and create new categories of jobs.

David Autor of MIT and Anna Salomons of Utrecht University recently published a study on automation that examined data on 28 industries in 18 countries in the OECD. They find that, since 1970, automation hasn’t reduced jobs—in fact, it has slightly increased them. But since the beginning of the 2000s, automation has reduced workers’ share of national income. “This finding is consistent with automation having become in recent decades less labor-augmenting and more labor-displacing,” they write.

According to their research, workers’ employment, hours, or wages haven’t fallen. But wages have risen less rapidly than overall economic growth, with owners getting an increasingly large share. Autor suggests this trend could continue as automation increases. “No, the robots will not take all of our jobs,” he says in a Brookings video. “The concern should not be about the number of jobs, but whether those jobs are jobs that can support a reasonable standard of living.”

Walmart has been criticized for years for its low pay and skimpy health benefits. The company is also known for its obsession with holding down costs, a factor in its drive toward automation. “We’re maniacal about expenses,” said Brett Biggs, Walmart’s chief financial officer, at an investor conference in March. “I think we have lost some of the edge on that over the last year. You can feel it coming back.” Biggs told attendees a nostalgic tale about arriving at Walmart and experiencing his first “supplies roundup,” when he and his coworkers dug office supplies out of their desks and dropped them in a central location so they wouldn’t have to order more. Then he explained that Walmart employees recently got excited about figuring out ways to reduce the length of a receipt tape.

Still, in January, Walmart—benefiting from an enormous corporate tax break under Donald Trump’s tax reform—said it would raise its starting hourly wage to $11 (around $19,000 a year for 34-hour weeks), hand out bonuses, and provide more benefits to full-time employees. Low-wage workers seemed to be gaining power amid a tight labor market.

In fact, as its strategy unfolds, it seems that Walmart may cultivate a relatively smaller, better-compensated core of employees who are supplemented by automation and a flexible cadre of gig-economy workers. Ten years from now, “there will be fewer associates in the Walmart store ... and we will see the wage rate continue to go up,” Walmart’s chief executive Doug McMillon told The Economic Club of New York in November. “What we would love, not just for Walmart but for retail, is to earn a better reputation about the jobs themselves.”

Given high turnover in retail, McMillon said, Walmart expects to eliminate jobs mostly through attrition. As it automates tedious tasks, such as finding inventory in the back room, it expects to offer jobs that pay more, such as customer service and merchandising.

In all of this, Walmart is trying to adapt to the rapid growth of Amazon, which reported almost $178 billion in revenue last year—about $315,000 per employee. Walmart is much larger, with $500 billion in annual revenue, but because it employs about four times as many people, that revenue amounts to just $217,000 per employee. (According to the Wall Street Journal, Walmart is in early talks with the insurer Humana about possible business relationships such as an acquisition, which would be a way to diversify away from the retail business where it competes with Amazon.)

The changes to Walmart’s business model could be particularly hard on young people who seek retail work. People between the ages of 16 to 24 account for 23 percent of retail workers, nearly double their overall representation in the U.S. workforce. Not all of them can make a seamless shift into the gig economy; Uber, for example, requires workers to be at least 21 years old, and they have to use a four-door car that meets company standards.

It’s been ten years since the Pixar animated movie “Wall-E” depicted oversized humans exiled into space, catered to by robots and floating in armchairs like leaden balloons, far above Earth’s ruined landscape. A decade ago, the fictional villainous corporation Buy N Large was seen as a thinly veiled satire of Walmart. Today, some suggest Amazon is a more apt comparison. Perhaps before any of these companies eats the whole world, another competitor will rise to take its place. In any case, as Autor, Naidu, and their colleagues suggest, we should worry more about working ever harder to keep up than we should about being shoved aside by our robot overlords.



SAN BERNARDINO, Calif.—This community was still reeling from the recession in 2012 when it got a piece of what seemed like good news. Amazon, the global internet retailer, was opening a massive 950,000-square-foot distribution center, one of its first in California, and hiring more than 1,000 people here.“This opportunity is a rare and wonderful thing,” San Bernardino Mayor Pat Morris told a local newspaper at the time.

In the months and years that followed, Amazon dramatically expanded its footprint in and around San Bernardino, a city 60 miles east of Los Angeles. The company now employs more than 15,000 full-time workers in eight fulfillment centers (where goods are stored and then packed for shipment) and one sortation center (where packages are organized by delivery area) in the Inland Empire, the desert region bordering Los Angeles that encompasses Riverside and San Bernardino counties. This expansion provided a lifeline to the struggling region, creating jobs and contributing tax revenue to an area sorely in need of both. In San Bernardino, the unemployment rate that was as high as 15 percent in 2012 is now 5 percent.

Yet in many ways, Amazon has not been a “rare and wonderful” opportunity for San Bernardino. Workers say the warehouse jobs are grueling and high-stress, and that few people are able to stay in them long enough to reap the offered benefits, many of which don’t become available until people have been with the company a year or more. Some of the jobs Amazon creates are seasonal or temporary, thrusting workers into a precarious situation in which they don’t know how many hours they’ll work a week or what their schedule will be. Though the company does pay more than the minimum wage, and offers benefits like tuition reimbursement, health care, and stock options, the nature of the work obviates many of those benefits, workers say. “It’s a step back from where we were,” said Pat Morris, the former mayor, about the jobs that Amazon offers. “But it’s a lot better than where we would otherwise be,” he said.

San Bernardino is just one of the many communities across the country grappling with the same question: Is any new job a good job? These places, often located in the outskirts of major cities, have lost retail and manufacturing jobs and, in many cases, are still recovering from the recession and desperate to attract economic activity. This often means battling each other to lure companies like Amazon, which is rapidly expanding its distribution centers across the country. But as the experience of San Bernardino shows, Amazon can exacerbate the economic problems that city leaders had hoped it would solve. The share of people living in poverty in San Bernardino was at 28.1 percent in 2016, the most recent year for which census data is available, compared to 23.4 in 2011, the year before Amazon arrived.  The median household income in 2016, at $38,456, is 4 percent lower than it was in 2011. This poverty near Amazon facilities is not just an inland California phenomenon—according to a report by the left-leaning group Policy Matters Ohio, one in 10 Amazon employees in Ohio are on food stamps.

The arrival of Amazon has been bittersweet for people like Gabriel Alvarado, 35. He started working at Amazon’s San Bernardino distribution center in 2013, making $12 an hour, hoping that the job would help him support his new wife and two stepdaughters. Amazon proved a stressful place to work, with managers chewing out employees for not moving fast enough, he told me, which was tough to put up with for meager pay. (An Amazon spokeswoman, Nina Lindsey, told me that, like most companies, Amazon has performance expectations, but that it supports people not performing with dedicated coaches to help them improve.)

Meanwhile, Gabriel watched as his 39-year-old brother Jose worked across the street, doing the same type of job at a warehouse for the grocery chain Stater Brothers. The 1,000 workers there are unionized and get full medical benefits, pensions, and retiree medical benefits. Wages start at $26 an hour, but many workers make a lot more than that because Stater Brothers operates an incentive program in which people who grab orders—doing similar tasks to workers at Amazon—are rewarded if they go faster than the average speed. Jose Alvarado is able to support a wife and four children on his Stater Brothers salary. When his son was diagnosed with a rare form of anemia, his insurance covered everything.

Though Gabriel was doing the same type of work at Amazon, he had to shell out more money for health care, and made a lot less money. “I saw my brother doing the same type of work, but moneywise, he had better credit, he could afford more, while I was barely getting by,” Gabriel told me. He has tried to get a job with Stater Brothers to no avail, and says there are few other local options but at Amazon or at companies that work for Amazon. In 2016, he used Amazon’s tuition reimbursement to get his commercial driving license, attending school on the weekends while working during the week. But the best job he could find was working for a third-party contractor, driving a truck for Amazon. “It’s either Amazon or nothing,” he told me.

The lack of other opportunities for people like Gabriel Alvarado illuminates the problem these communities face when deciding to offer tax breaks and incentives to compete for Amazon to build warehouses in their towns. If these places don’t get a new Amazon facility, they won’t instead get companies like Stater Brothers that are willing to come in and pay double or triple the minimum wage for jobs that don’t require a college education. For many places, the choice is not between Amazon or another, better employer. The choice, instead, is Amazon or nothing. “There’s this way in which Amazon’s warehouses are perceived to be a good thing for a community, but that’s only because the context in which they are being proposed and built is so devoid of better opportunities,” said Stacy Mitchell, the co-director of the Institute for Local Self-Reliance, a nonprofit that advocates for sustainable community development. “It’s an indicator of how badly our economy is doing in terms of providing meaningful and valuable opportunities for people.”

Morris, the former mayor of San Bernardino, told me that in 2012, Amazon seemed like a lifesaver. San Bernardino’s unemployment rate was at 15 percent, home values had fallen 57 percent since 2007, and the city, facing a $45 million budget shortfall, would file for bankruptcy in August of that year. “At the point they came in, any job is a good job,” he said. But the jobs the company is offering are indicative of how the economy has changed in San Bernardino in the past few decades. “To a certain extent, based on the history, it’s a step down for families,” he said. The jobs that used to dominate San Bernardino were unionized ones with good benefits, at the Kaiser steel mill, the Santa Fe railroad maintenance yard, and the Norton Air Force Base. Now, jobs like the ones Amazon creates pay less and aren’t unionized, and require multiple members of a household to work, often more than one job.

As Amazon continues to grow at a rapid clip, more communities are in the same position as San Bernardino—desperate to attract new jobs, even ones that pale in comparison to past opportunities, in the absence of anything else. Although efforts to recruit new distribution centers garner less national attention than the race to attract Amazon’s HQ2— its second corporate headquarters, where the company is expected to add as many as 50,000 jobs—when added up, these other facilities create a large number of jobs. Amazon now has 342 facilities, including fulfillment centers, Prime hubs, and sortation centers, in the United States, up from 18 in 2007, according to MWPVL International, a supply-chain and logistics consulting firm. Amazon employed 180,000 people in the United States in 2016, and said last year that it planned to add more 100,000 full-time, full-benefit jobs by mid-2018. The company is a microcosm of the growing logistics industry, which is booming as more and more people order goods online. The company is growing even in places where it already has a substantial presence: Although it already has eight fulfillment centers near San Bernardino, Amazon recently announced it was adding two more facilities nearby, creating 2,000 more jobs.

Amazon allows visitors to tour one of its warehouses in San Bernardino, and I went late last year to try and understand how distribution centers work. The warehouse, called ONT2 internally, is a vast complex, where clean concrete floors stretch out in all directions covering the distance of about 16 football fields. Bright yellow posts divide the different sections of the building, where people unpack shipments, load shelves, unload shelves, and pack everything from puzzles to lightbulbs into Amazon’s ubiquitous brown boxes. Conveyor belts covering several miles whir throughout the facility, moving goods among floors.

For local residents, starting work in this facility or one like it can seem like a blessing. At around $12 an hour, 40 hours a week, full-time jobs pay higher than many others in the region, and the benefits are also better than many other jobs in the industry. But workers are required to be on their feet all day, and receive scant time for bathroom breaks or lunch. They’re pressured to meet certain production goals and are penalized by getting “written up”—the first step in getting fired—for not meeting them, they say. They’re also allowed very little time off, and written up if they go over a certain amount of time off, these workers say, even if they get sick. This is according to in-depth conversations I’ve had with 10 current and former Amazon employees. These employees work in the San Bernardino facility, as well as Amazon distribution and sortation centers in Moreno Valley, California; Jeffersonville, Indiana; and Kent, Washington. Amazon has been sued in the past by part-time, contract workers. All but one of the people I interviewed were full-time employees, not contract workers, and they didn’t think working directly for Amazon was so great, either. As one worker, John Burgett, a current employee in Indiana who has detailed his experiences on the blog Amazon Emancipatory, told me, “It’s very physically and emotionally grueling. They’re walking a fine line in the community—everybody knows someone who’s worked there, and no one says it’s a good place to work.”

Number of Amazon Facilities Over Time

Many people who start out at Amazon warehouses begin as “pickers.” These are the people who walk through the vast aisles in the Amazon warehouses where goods are stored, and, reading information from a handheld scanner, put items that have been ordered online into yellow bins, called totes. The scanner gives pickers an amount of time to “pick” an item based on where it is stored, and blue bars on the scanner count down the amount of time they have left to complete the task. Slightly more desirable than picking is stowing. “Stowers” take bins of items that have been shipped to Amazon and store them on the shelves for the pickers to grab when ordered. Other employees work as “packers.” They take items from yellow totes, scan them, grab a box and packing tape, the size of which is recommended by a computer, and pack individual customers’ orders, putting the finished boxes on a fast-moving conveyor belt.

The workers I talked to said that the problem with these jobs is not just that they’re physical or monotonous—which they are—but, rather, that Amazon puts an incredible amount of pressure on people to continue to work faster and faster. Many of the employees mentioned the fear of being “written up” and losing their jobs, which will thrust them into other low-paid jobs with fewer benefits. If pickers don’t grab an item in a certain amount of time, they get written up. If they take too long a bathroom break, they get written up. If they’re not walking as fast or performing as well as the majority of employees, they get written up. “You constantly feel like, ‘I’m not doing enough, I need to do a little more,’ and that’s their business model,” Burgett said. “The constant trying to chase your rate, trying to stay ahead of being written up—it affects you psychologically.” This pressure is not limited to warehouse workers; a 2015 New York Times story detailed a corporate culture where white-collar workers were pushed psychologically as well.

Another man, a former carpenter who works in the stow department in Moreno Valley who didn’t want his name used because he still works for Amazon, said that without warning, Amazon changed the amount of time workers had to stow an item from six minutes to four minutes and 12 seconds. “They make it like the Hunger Games,” he said. “That’s what we actually call it.” Workers are competing against an average time, and so they are, in essence, competing against each other. Those who can’t keep up are written up and then fired, he said.

Another Moreno Valley employee, who has been a picker at Amazon for two-and-a-half years, says the company constantly sends messages to workers’ scanners telling them to work faster. They’ll run competitions such as a “Power Hour” in which workers are encouraged to work as hard as they can for a prize. One recent prize was a cookie. Another time, the winner of Power Hour would be entered into a raffle to win a gift card. “I don’t want a cookie or a gift card. I’ll take it, but I’d rather a living wage. Or not being timed when you’re sitting on the toilet,” said the man, who lives with his father because he and his girlfriend can’t afford their own place, and didn’t want his name used because he hopes to get promoted at Amazon.

One woman I talked to in Moreno Valley, who didn’t want her name used because she is in the process of suing Amazon, said that working at the company strained her heart and caused her psychological problems that she’s still dealing with. She was written up for not working enough hours after she went to the emergency room because of her heart problem, she says. On the other hand, she says, she made enough money at Amazon to buy her first new car. “That’s what makes people not want to quit—the pay,” she said. “People say, ‘You can treat me any type of way, since this is the best money we can get out here in Moreno Valley.’”

I did talk to one Amazon worker who started as a picker and made his way up to management. David Koneck, now 34 years old, was one of the first workers hired by Amazon when the San Bernardino facility first opened. At the time, Koneck, who graduated from high school but not from college, was running a company that administered diagnostic tests for high-school students. That job was unstable in the aftermath of recession-era budget cuts, so when Amazon announced it was hiring, he applied right away, attracted by the benefits like health insurance and a program that allowed him and his wife to share paid leave when they had their first child. He started by working as a picker on the night shift, and within nine months was promoted. Both were good jobs, he told me—he and his wife bought their first house, in Hesperia, California, while he was an hourly associate. (Public records show it cost $182,500.) The company gave him lots of opportunities to move up and receive training in different areas, he said. After two years with the company, he was promoted again, and moved into management. Today, he’s an operations manager. “I wanted to come in here and achieve as much as I could, and nothing has stood in my way,” he told me. “It’s been nothing but positive support for me.” He’s now trying to help other hourly associates move up the Amazon ladder.

Amazon says that many employees have similar experience to Koneck. At one Kentucky facility, according to Lindsey, the Amazon spokeswoman, there are more than 100 employees who have been with Amazon for more than 15 years. But the workers I talked to say few employees make it more than a year. Their theory was that Amazon begins to cull employees when they are reaching the two-year mark, at which point their stock options would vest. (Lindsey says it is “strongly” in Amazon’s interest to retain employees to provide them with opportunities to develop, because the company is growing so quickly.) The former carpenter says employees call workers approaching the two-year mark “the walking dead” because they are working hard not to get fired, but many of them will be. “Very few Tier One employees ever make it to two years of continuous service,” Burgett writes. Anecdotally, he estimates that about 5 percent of new hires receive vested stock shares. “There are only two options,” Gabriel Alvarado told me. “You get tired—tired of trying to make rate every week, tired of the write-ups—or you get fired because you didn’t make quota or run out of unpaid time off.” Associates receive 10 hours of paid time off when they begin, Lindsey told me, which is essentially one day off. Most associates work four 10-hour shifts a week and only accrue a small amount of paid time off every pay period, workers said, which means it can take months to get another day off.

“When we’re thinking about Amazon coming in and creating a huge number of jobs, what’s the quality of jobs? We should also be really examining that,” said Beth Gutelius, a researcher at the Great Cities Institute at University of Illinois at Chicago who wrote her dissertation about the warehouse industry in the Chicago suburbs. “Sometimes these more exurban areas are really desperate for jobs, and you can’t deny that, but places do have to really think hard about it.”

Current officials in San Bernardino maintain that Amazon’s presence has been a positive one. The new mayor, R. Carey Davis, told me that the city has seen a number of benefits since Amazon opened its first warehouse. The company has contributed hundreds of thousands of dollars to local schools and charities, for example. “The city of San Bernardino has found that Amazon has been a very good neighbor and private partner for the city of San Bernardino,” he said. Amazon’s presence has signaled to other cities that San Bernardino is a good place to locate, with qualified workers, and an efficient city government, said Mike Burrows, the executive director of the Inland Valley Development Agency and the San Bernardino International Airport Authority. It’s helped create jobs on the land once used by the Norton Air Force Base until it closed two decades ago. Amazon recently surpassed Stater Brothers, which had been the largest employer on the land formerly occupied by the air force base with 2,000 employees, according to the Inland Valley Development Agency. Now, Amazon has 4,900 employees in San Bernardino.

The arrival of Amazon may have been good for other businesses in the Inland Empire, but its effects on individual residents seem less positive. While warehousing and storage was one of the fastest-growing sectors in the Inland Empire over the past decade, adding 35,800 jobs, the area also has the lowest annual private-sector average wage out of the country’s 50 largest metropolitan areas. A report from the Institute for Local Self-Reliance found that Amazon paid 11 percent less than the average warehouse in the Inland Empire; a similar analysis by The Economist found that workers earn about 10 percent less in areas where Amazon operates than similar workers employed elsewhere.

There is potential for Amazon to be the shining knight that city officials hope it will be when it opens in their cities. Amazon could become more like Stater Brothers—paying workers more, incentivizing efficiency rather than punishing workers who fall behind, supporting efforts to form a union. It could treat workers like Jose Alvarado is treated. After 11 years at Stater Brothers, Alvarado, who also plays on the company softball team, has no plans to leave. “I’m able to support my whole family and live a really good life,” he told me, a stark contrast to his brother.

But that would require a wholesale change in Amazon’s business practices, which would probably not sit well with consumers who have become accustomed to free shipping and cheap goods. (Amazon is losing money on its e-commerce operations, which are subsidized by other parts of its business.) “More opportunity for folks with less education is generally a good thing,” said Gutelius, the Chicago researcher. “It would be a much better thing if the job quality were better, if there were some real kind of job ladder over time,” she said.

Efforts to get Amazon to change its labor practices have been unsuccessful thus far. Randy Korgan, the business representative and director of the Teamsters Local 63, which represents the Stater Brothers employees, told me that his office frequently gets calls from Amazon employees wanting to organize. But organizing is difficult because there’s so much turnover at Amazon facilities and because people fear losing their jobs if they speak up. Burgett, the Indiana Amazon worker, repeatedly tried to organize his facility, he told me. The turnover was so high that it was difficult to get people to commit to a union campaign. The temps at Amazon are too focused on getting a full-time job to join a union, he said, and the full-time employees don’t stick around long enough to join. He worked with both the local SEIU and then the Teamsters to start an organizing drive, but could never get any traction. He told me that whenever Amazon hears rumors of a union drive, the company calls a special “all hands” meeting to explain why a union wouldn’t be good for the facility. (Lindsey said that Amazon has an open-door policy that encourages associates to bring concerns directly to the management team. “We firmly believe this direct connection is the most effective way to understand and respond to the needs of our workforce,” she wrote, in an email.)

Gabriel Alvarado, too, said he talked with some friends about starting a union in San Bernardino, after contrasting his situation with that of his brother. Amazon soon called a meeting and asked workers what they wanted to make their jobs better, he says, but few of the workers’ suggestions were carried out. No Amazon warehouse has been organized thus far. In 2014, workers at an Amazon warehouse in Middletown, Delaware, voted 21–6 against joining the International Association of Machinists and Aerospace Workers. Burgett thinks these outcomes are the result of, what he calls in his blog, Amazon's “well-oiled and well-financed anti-union machinery.”

There are many other reasons communities might pause before welcoming an Amazon warehouse. But many still welcome the company, believing that it’s better to have some jobs in the new Amazon economy than no jobs at all. Fresno, another economically depressed city in California, offered Amazon $15.3 million in property tax rebates and $750,000 in sales tax rebates to locate a facility there, an offer Amazon was happy to take up. Amazon won $23 million in local tax incentives over two years to open distribution centers in three Texas cities. The company has received $48 million in state, county, and city financial incentives to build facilities in Florida.

This race to the bottom may be preventing cities from holding Amazon—or other logistics companies—accountable. After all, most communities aren’t in a position to negotiate with Amazon to ensure that workers will be treated well. Last year, I interviewed Michael Tubbs, the mayor of Stockton, California, shortly after Amazon announced in August that it was locating a distribution center and 1,000 jobs in the inland city in Northern California. Tubbs is young and progressive, but still told me that Stockton had little power over Amazon. “I don’t think the city of Stockton currently, with an unemployment rate double the state average, is in a position to make a ton of demands on companies who can go anywhere,” he told me. San Bernardino had tried to negotiate that it would get a portion of the sales tax of all the goods that came through its distribution center, but ultimately spent money to build roads and provide police and fire protection to the warehouse and does not get any sales tax revenues from the warehouse, Morris said. (The state of California, not Amazon, quashed the deal.)

As the race for Amazon’s HQ2 shows, other cities competing for Amazon jobs offer up all sorts of concessions, and worry that in passing any wage and hour mandates, they’ll lose the jobs. “I think often, local policymakers are really eager to get companies in, they want employment, but they don’t necessarily give a lot of stipulations about how many of these workers are temps, how many are paid a living wage,” Ellen Reese, chair of the labor-studies program at the University of California, Riverside, told me.

It’s true that cities desperate for jobs may find it difficult to attract companies if they pass minimum-wage mandates or other labor laws. But the alternative, it seems, is jobs that don’t create a middle-class lifestyle for residents, which in turn affects local spending, the housing market, the tax base, and leads to a poor standard of living. Many cities, San Bernardino included, are calculating that any job creation is good news. They may soon find that with Amazon, that calculation does not apply.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

At least 2,000 children have now been forcibly separated from their parents by the United States government. Their stories are wrenching. Antar Davidson, a former youth-care worker at an Arizona shelter, described to the Los Angeles Times children “huddled together, tears streaming down their faces,” because they believed that their parents were dead. Natalia Cornelio, an attorney with the Texas Human Rights Project, told CNN about a Honduran mother whose child had been ripped away from her while she was breastfeeding. “Inside an old warehouse in South Texas, hundreds of children wait in a series of cages created by metal fencing,” the Associated Press reported. “One cage had 20 children inside.”

About 65 million years ago, shortly after the time of the dinosaurs, a new critter popped up on the evolutionary scene. This “scampering animal,” as researchers described it, was likely small, ate bugs, and had a furry tail. It looked, according to artistic renderings, like an especially aggressive New York City rat. And it had a placenta, an organ that grows deep into the maternal body in order to nourish the fetus during pregnancy.

The rodentlike thing would become the common ancestor of the world’s placental mammals, with descendants that include whales, bats, dogs, and humans, among many other species. And today, the placenta might hold the key to one of the most enduring mysteries in human medicine: Why do women suffer much higher rates of autoimmune disease than men do?

Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.

There’s a moment about 15 minutes into the first episode of Years and Years that made me gasp at its audacity, its prescience, its visual horror. The new six-part series from the British writer Russell T. Davies (Doctor Who, A Very English Scandal) charts the life of the Lyons family over the course of 15 years, starting in 2019 and ending in 2034. It’s a kitchen-sink saga that barrels its way through births and marriages and betrayals, but also through the near-future. In 2024, Stephen Lyons (played by Rory Kinnear), a financial adviser, is at home with his wife, Celeste (T’nia Miller), both rushing their way through the morning routine. When the camera turns to their teenage daughter Bethany (Lydia West), her face isn’t recognizably human. Instead, she looks like a 3-D version of a Snapchat puppy, with vast cartoon eyes, wagging pink ears, and a brown snout. When she talks, her voice is grotesquely distorted, a robotic hallucination of a child’s cadence. “I might have to start limiting filter time,” Celeste says in the same exasperated, noncommittal way that you might think, I really should spend less time on Twitter.



Last month, researchers found the most compelling evidence yet that Uber, Lyft, and other ride-hailing services are worsening traffic and reducing transit ridership in cities across the U.S. Rahm Emanuel, the mayor of Chicago, proposed a solution: Slap each ride with a fee to fund public transport.

Just before Thanksgiving, the Chicago city council approved a 15-cent increase to the 52-cent fee that is already added to every ride-sharing trip. The original per-trip fee, initiated in 2015, was directed to the city’s general fund, but the new ride-hailing increase is the first of its kind to directly fund public transit.

This city has many areas of transportation need, and the Chicago Transit Authority (CTA) will have to decide where the money should go. The tax is expected to raise $16 million for the CTA in 2018, and $30 million in 2019 with an additional 5-cent increase to the fee. CTA will likely use the funds for long-term infrastructure improvements. But what else could this added fee go toward? A transit planner, a transportation advocate, and a cab driver told us where they think the money could and should go.

Unlike certain metro systems, Chicago’s trains actually run on time. But they’re not perfect, and the CTA still has a substantial backlog of deferred maintenance and replacement on the 125-year-old rail system. “Even when CTA inherited the system in 1947, it was already not in a state of good repair,” said Leah Mooney, the director of strategic planning and policy at CTA. The transit authority would use the revenue from fees not just “to improve access or replace it, but to modernize the full system,” Mooney said.

That means more money to fix slow zones, improving signals and tracks, adding rider capacity with wider platforms and longer trains, and improving customer service. An example of the kind of project the fee could fund, Mooney said, is the Red and Purple Modernization program. The reconstruction of 10 miles of rail lines began at the start of her tenure at CTA; the procurement process is just now getting started. Once completed, the project should fix a major bottleneck between the lines and allow CTA to serve an additional 7,200 customers per hour.

These things take time, and a lot of money: “There isn’t some quick lever you can pull to add more Blue Line trains into the loop during morning rush,” Mooney said. “But that is a huge impact on someone’s daily life and [it] lets people access more jobs within a reasonable commute.”

Dorval Carter, the president of CTA, has said the agency would leverage the ride-hailing revenue to issue bonds worth $180 million over the next 10 to 15 years. The transit agency will decide how to allocate the money when it votes in December on its budget, as it considers a 25-cent fare hike to cover operating costs.

As for ride hailing, Mooney says it’s just no match for the efficiency of CTA trains. “It can never substitute high-capacity transit, without wreaking havoc on congestion,” she said. “We have to be really thoughtful and mindful about what types of cities we’re creating.”

To Kyle Whitehead, the government-relations director of the Active Transportation Alliance (ATA), a transit advocacy group, supporting trains would be undoubtedly important, but he thinks CTA should funnel funds toward the underdog of Chicago transit: the bus. Since 2012, CTA bus ridership has fallen by 17 percent, which is about 55 million fewer riders, according to a recent report from ATA. It attributes the steady drop-off to service cuts, declining gas prices, and the emergence of ride hailing, among other factors.

Increasing funding for buses, Whitehead said, would be a very efficient use of money. Even though they are waning, “bus riders still represent the majority of transit riders in the city,” making up some 52 percent of trips, Whitehead said. To help the mode become more competitive, he believes the city should give buses more priority at intersections, speed up boarding with new fare-payment systems, and expand the network of dedicated bus lanes.

That last fix is “the most obvious and beneficial way to speed up bus service,” the ATA report states. It’s also where Chicago lags most behind its peers. “Chicago has about four miles of dedicated lanes,” Whitehead said. “Compare that to other cities like New York that has 80-plus miles, or even Miami and Los Angeles that have about half that.”

Besides extracting higher fees from ride-hailing trips, the city needs more data, Whitehead added. Otherwise, it’s difficult to show the exact impact Uber and Lyft are having on transit ridership. He also worries that their cheap fares, supported by billions in venture capital, won’t stay cheap forever. As it is, many middle- and low-income riders already can’t afford the shortcut offered by ride-hailing, leaving them to ride increasingly unreliable buses in heavier traffic congestion created by on-demand car trips. These passengers shouldn’t be ignored. “We’re trying to build political will for those investments,” said Whitehead.

Cities are just beginning to grasp what ride-hailing is doing to public transportation. But what it’s done to the taxi industry is no mystery.

In Chicago, the value of taxi medallions, which give cab drivers the right to operate, have fallen precipitously since ride-sharing came to town. As CBS Chicago reports, the price of a medallion has gone from $385,000 in 2012 to a low of $50,000 this year. The industry has taken a nose dive: Drivers’ average monthly income has fallen by nearly half since 2014.   

Michael Agunloye has felt the pain firsthand. A cab driver for 15 years, Agunloye once expected to be able to sell his taxi medallion to pay for his retirement. Now, that’s no longer an option, so he’s continuing to drive. He said other drivers he knows are struggling to pay off their medallion loans, with some going into foreclosure.

“No one expected this when ride-sharing was introduced to the city,” said Agunloye, who advises the city’s Taxicab Driver Fairness Task Force as a representative of Cab Drivers United/AFSCME Council 31. “Our position has been [that the city should] create relief for the taxi-cab owners, medallion owners, and some of the drivers too.”

It might be a long shot, given that Emanuel has said the ride-hailing funds will pay for “mass transit.” Still, Agunloye thinks that the money could help reduce the renewal fees and licenses that cab drivers pay to the city. In general, he believes the ride-hailing industry ought to contribute more. While companies like Uber and Lyft pay a $10,000 fee for an unlimited license for their drivers in the city, he says cab drivers have to pay individually for licenses and ground-transportation fees, in addition to training, background checks, and vehicle upgrades. Most of all, he wants a leveled playing field. “We just want to continue to exist and remain a viable business,” Agunloye said. Even though, he admitted, “I doubt it will ever be what it used to be.”

This post appears courtesy of CityLab.



So many moments of female togetherness take place in proximity to a toilet. A couple of years ago, during early design meetings for The Wing, a women’s club that calls itself a space “between Work and Werk,” bathrooms were discussed at length; the whole place is a kind of ladies’ room. “Nobody had done a women-only co-working and event space before,” Alda Ly, the architect who directed the project, recalled.“It was a lot of sitting around the table and brainstorming, ‘What does that look like?’”

True gender equality requires a good deal of new construction. Materials were selected to optimize female comfort, furniture would be suitably proportioned; there would be spaces to socialize and others in which to retreat. A separate “Beauty” room was to be walled off from the toilets, for relaxed primping. The Wing’s first location opened in Manhattan’s Flatiron district, in 2016, and since then the clubs have been kept between 73 and 74 degrees, appreciably higher than New York’s mandated temperature of at least 68, and flouting typical guy-bod preference. (The Wing’s contractor, a man, still has a habit of lowering it to 70 when he comes by.)

Such are the concerns of designing for an emerging market’s needs, as women—likelier than those of previous generations to have attended college, and to take on white-collar jobs—are filling a rising share of seats in new kinds of work spaces. Yet at a moment when, from blueprints on, more buildings are being reconfigured and reapportioned to take women into account, only a quarter of all architects in the United States are female; a recent survey by Dezeen, a design magazine, found that among the world’s hundred biggest firms, women run three. “There’s a lot of partnerships—men and women, husband and wife,” Ly, who last January started her own firm, Alda Ly Architecture and Design, said. “But there’s not that many firms run by women without partners.” Even those who ascend to the highest levels may have to deal with weird flak. Five years ago, Zaha Hadid—the first woman to have won the Pritzker Prize, the top honor in architecture—was forced to respond to public criticisms that her mock-up for Qatar’s Al-Wakrah stadium, which will host the 2022 World Cup, resembled a “vulvic bulge.” (The inspiration was a dhow, a boat traditionally found in Qatar.) “What are they saying?” Hadid wondered to a reporter for Time. “Everything with a hole in it is a vagina?” After Hadid died, in 2016, Princeton University Press published a book called, Where Are the Women Architects?

So it’s almost by default that Ly, who is 38, has been called upon to bring a feminist’s eye to a new array of spaces. Lately, she can be found helping The Wing expand westward: A Washington, D.C., site is opening April 12th, to be followed by clubs in Los Angeles and San Francisco, among other cities. She has also worked on the Pennovation Center, an “idea factory” at the University of Pennsylvania meant to “inspire innovation” (it has a bar); open-plan offices for Triple Canopy, an arty-intellectual magazine supported by the Andy Warhol Foundation; a shop for a bespoke 3-D printed headphones; and communal housing. A new client is Bulletin, a millennial-run store that sells products from female-owned online vendors (“Nasty Woman” slippers, vibrators, embroidery that says “Put the seat down you fucker”); Ly has been hired to design Bulletin’s brick-and-mortar flagship, in Manhattan’s Union Square.

The Bulletin project is in its early stages, and the other day, Ly sat down with the company’s executives to share ideas over breakfast. She has long, straight black hair, which she’d pulled into a low ponytail; she wore a collarless black leather jacket, a large-faced black watch, and wool slipper booties. She was 38 weeks pregnant, and munched on granola. “I love these bowls,” she said between spoonfuls. Looking at slides that Ly and her team had pulled from Pinterest, Ali Kriegsman, Bulletin’s chief operating officer, in a beanie, observed, “It’s like a makeover show.” She pointed to an image showing a space filled with herringbone tile. “I like this,” she said. “It’s refreshing. It’s cool.” Ly reminded about the noise of click-clacking heels on ceramic floors; too much, she warned, and “It will feel like a kitchen—or a bathroom.” Kriegsman nodded, undeterred. “It doesn’t feel bathroomy to me, though.” Bulletin was open to embracing a locker-room vibe. “What I like about the tile is that it has this kind of sanitary, non-rustic feel to it,” Alana Branston, the CEO, with a creamy blonde bob, said. “I like cleanliness. Aesthetically, I feel like it’s on brand.” After they left, Ly said, “Pinterest is a blessing and a curse for architects. It really gets them”—the clients—“excited and engaged. But you see a lot of the same thing over and over. It’s kind of an echo chamber.”

Ly’s parents were Vietnam War refugees—their own parents fled the Communist Revolution in China—who made their way to New Zealand, where Ly was born. In the late 80s, they moved to a suburb of Los Angeles (“The architecture was as plain as possible,” Ly told me) and the family worked in restaurants, electrical-outlet factories, wherever they could get jobs. Her dad was a church janitor, and then became a contractor. “The fun thing we would do on Sundays was go to open houses in the fancy neighborhoods,” she recalled. That gave her an inkling of what might be even more fun: “I love building stuff.” Ly put herself through college, at UC Berkeley (her first job was folding shirts at JCPenney), and later went to Harvard’s Graduate School of Design. “I’ve always been a really visual and spatial person growing up, so it just made sense for me,” she said. “Everything is a problem to be solved.”

Solving for feminism in architecture, Ly believes, is a matter of making room for choice. “It’s having areas for women to have privacy, or to work in big groups,” she explained. To see, to be seen, to burrow down into work—all things men and non-binary people tend to find useful, too. (The underside of gender-specific spaces is now of interest to the New York City Commission on Human Rights, which has launched an investigation into The Wing on the basis of possible discrimination.) But there are some design features that are explicitly and thoughtfully female: “Like having a pumping station,” Ly went on. “Those are the obvious things that help. Especially now, as I know—and I’ll need it.”

On a morning in March, Ly arrived at The Wing’s Brooklyn outpost, which had been in business for a week but awaited final touches. Stopping at The Perch, the club’s coffee bar, she put down her purse, took out a large notepad, and turned to a blank page. She was there to complete the punch list—an inspection of the remaining details specified in the contract. Dozens of women had already made themselves comfortable in pink lounge chairs; they worked, drank lattes, slipped into “telephone booths” hidden behind shelves stocked with books by female authors. (The vintage dial phones inside were merely decorative.) Ly’s style is chic and sleek, and at The Wing, with its particular brand of for-profit feminism (access to a single location costs $2,350 a year), the ladylike touches can seem rather literal—the pink, the florals, wallpaper of naked women embracing. There are tucked-away rooms, arches everywhere, curved staircases.

“We’ll see how long this trend lasts,” Ly said, of the conspicuous roundness. “But for me, it’s not the pink, it’s not the curves.” It’s about offering a variety of spaces in which women feel comfortable. This is different from the man-cavey environments of certain start-ups, she added. “There are other things that get them excited. Foosball tables, beanbags, beer pong. For us, it’s not about toys. We’re not trying to give you free food. We’re just trying to make you feel comfortable.”

Ly was greeted by Nora Cady, a Wing employee who handles site openings; she wore jeans and blue socks patterned with seductively-posed nudes. The two reviewed their agenda. Creating an environment to satisfy every woman’s liking is an imperfect science. In the SoHo club, for instance, some patrons insisted that it was too cold in the conference room, and fussed with the thermostat. “They would try to adjust it themselves,” Ly said.

“Women would just touch every control we had,” Cady explained. “It was a control thing.” Her crew changed the system. “We had to lock them out.”

Cutting into the soft-hued scene, a pair of men walked by, one holding a ladder. Ly apologized. “What they’ve done in the past when a man comes in, is that they have to announce it, ‘We’re having some work done, there’s a gentleman coming through.’” These guys were HVAC subcontractors, who had to be escorted at all times by a woman on staff. (At the Colony Club—a social club for women established in the early 1900s—men could be admitted as guests, but they had to remain in The Strangers’ Room.)

As Ly set off on her nitpicking tour, it turned out there was another man around: Scott, the fire-safety officer on duty, in a black suit, who sat in the lobby drinking coffee from a paper cup. Noticing Ly, he pointed to some loose wires above the front door. She thanked him and turned to an associate: “Make sure you put that down.” Scott told her that in the early 90s he’d been a bartender at a restaurant that had previously occupied the space. “It was a place for couples to come that weren’t married,” he said. Now he was keeping to himself. “I’m just trying not to make anybody ill at ease.” Ly smiled at him and continued about her business.

1. The Disappearance

At 12:42 a.m. on the quiet, moonlit night of March 8, 2014, a Boeing 777-200ER operated by Malaysia Airlines took off from Kuala Lumpur and turned toward Beijing, climbing to its assigned cruising altitude of 35,000 feet. The designator for Malaysia Airlines is MH. The flight number was 370. Fariq Hamid, the first officer, was flying the airplane. He was 27 years old. This was a training flight for him, the last one; he would soon be fully certified. His trainer was the pilot in command, a man named Zaharie Ahmad Shah, who at 53 was one of the most senior captains at Malaysia Airlines. In Malaysian style, he was known by his first name, Zaharie. He was married and had three adult children. He lived in a gated development. He owned two houses. In his first house he had installed an elaborate Microsoft flight simulator.

"It’s not true that no one needs you anymore.”

These words came from an elderly woman sitting behind me on a late-night flight from Los Angeles to Washington, D.C. The plane was dark and quiet. A man I assumed to be her husband murmured almost inaudibly in response, something to the effect of “I wish I was dead.”

Again, the woman: “Oh, stop saying that.”

To hear more feature stories, see our full list or get the Audm iPhone app. 

I didn’t mean to eavesdrop, but couldn’t help it. I listened with morbid fascination, forming an image of the man in my head as they talked. I imagined someone who had worked hard all his life in relative obscurity, someone with unfulfilled dreams—perhaps of the degree he never attained, the career he never pursued, the company he never started.

In the faint predawn light, the ship doesn’t look unusual. It is one more silhouette looming pier-side at Naval Base San Diego, a home port of the U.S. Pacific Fleet. And the scene playing out in its forward compartment, as the crew members ready themselves for departure, is as old as the Navy itself. Three sailors in blue coveralls heave on a massive rope. “Avast!” a fourth shouts. A percussive thwack announces the pull of a tugboat—and 3,000 tons of warship are under way.

To hear more feature stories, see our full list or get the Audm iPhone app. 

But now the sun is up, and the differences start to show.

Most obvious is the ship’s lower contour. Built in 2014 from 30 million cans’ worth of Alcoa aluminum, Littoral Combat Ship 10, the USS Gabrielle Giffords, rides high in the water on three separate hulls and is powered like a jet ski—that is, by water-breathing jets instead of propellers. This lets it move swiftly in the coastal shallows (or “littorals,” in seagoing parlance), where it’s meant to dominate. Unlike the older ships now gliding past—guided-missile cruisers, destroyers, amphibious transports—the littoral combat ship was built on the concept of “modularity.” There’s a voluminous hollow in the ship’s belly, and its insides can be swapped out in port, allowing it to set sail as a submarine hunter, minesweeper, or surface combatant, depending on the mission.

Arguments before the United States Court of Appeals are usually dry, esoteric, and nerdy. What would it take to make one go viral? This week, in a clip that launched a million angry Facebook posts, we found out. It took a lawyer for the United States telling a panel of incredulous Ninth Circuit judges that it is “safe and sanitary” to confine immigrant children in facilities without soap or toothbrushes and to make them sleep on concrete floors under bright lights.

This assertion generated widespread outrage. Sarah Fabian, the senior attorney in the Department of Justice’s Office of Immigration Litigation who uttered it, was instantly excoriated online. As fate would have it, the clip of her argument went viral at the same time as a new wave of reports of brutal and inhumane conditions at immigrant confinement centers. It also immediately followed the raucous debate over Representative Alexandria Ocasio-Cortez referring to the confinement centers as concentration camps. The juxtaposition suggested, misleadingly, that the Trump administration was explicitly justifying the worst sorts of child mistreatment we were seeing on the news.

Americans often lament the rise of “extreme partisanship,” but this is a poor description of political reality: Far from increasing, Americans’ attachment to their political parties has considerably weakened over the past years. Liberals no longer strongly identify with the Democratic Party and conservatives no longer strongly identify with the Republican Party.

What is corroding American politics is, specifically, negative partisanship: Although most liberals feel conflicted about the Democratic Party, they really hate the Republican Party. And even though most conservatives feel conflicted about the Republican Party, they really hate the Democratic Party.

America’s political divisions are driven by hatred of an out-group rather than love of the in-group. The question is: why?

At least 2,000 children have now been forcibly separated from their parents by the United States government. Their stories are wrenching. Antar Davidson, a former youth-care worker at an Arizona shelter, described to the Los Angeles Times children “huddled together, tears streaming down their faces,” because they believed that their parents were dead. Natalia Cornelio, an attorney with the Texas Human Rights Project, told CNN about a Honduran mother whose child had been ripped away from her while she was breastfeeding. “Inside an old warehouse in South Texas, hundreds of children wait in a series of cages created by metal fencing,” the Associated Press reported. “One cage had 20 children inside.”

About 65 million years ago, shortly after the time of the dinosaurs, a new critter popped up on the evolutionary scene. This “scampering animal,” as researchers described it, was likely small, ate bugs, and had a furry tail. It looked, according to artistic renderings, like an especially aggressive New York City rat. And it had a placenta, an organ that grows deep into the maternal body in order to nourish the fetus during pregnancy.

The rodentlike thing would become the common ancestor of the world’s placental mammals, with descendants that include whales, bats, dogs, and humans, among many other species. And today, the placenta might hold the key to one of the most enduring mysteries in human medicine: Why do women suffer much higher rates of autoimmune disease than men do?

Updated at 12:07 p.m. on June 19, 2019

Like most other colleges across the country, Newbury College, a small, private liberal-arts school in Brookline, Massachusetts, held classes through the end of this past spring semester and then bid farewell to cap-and-gown-wearing seniors. But unlike almost every other college, those classes, and that farewell, were the school’s last: Newbury officially ceased operations at the end of May.

One of the first sources to publicly confirm the long-rumored closure was the president’s blog, where the news was shared last December. “It is with a heavy heart,” the school’s president, Joseph Chillo, wrote, “that I announce our intention to commence the closing of Newbury College, this institution we love so dearly.”

There’s a moment about 15 minutes into the first episode of Years and Years that made me gasp at its audacity, its prescience, its visual horror. The new six-part series from the British writer Russell T. Davies (Doctor Who, A Very English Scandal) charts the life of the Lyons family over the course of 15 years, starting in 2019 and ending in 2034. It’s a kitchen-sink saga that barrels its way through births and marriages and betrayals, but also through the near-future. In 2024, Stephen Lyons (played by Rory Kinnear), a financial adviser, is at home with his wife, Celeste (T’nia Miller), both rushing their way through the morning routine. When the camera turns to their teenage daughter Bethany (Lydia West), her face isn’t recognizably human. Instead, she looks like a 3-D version of a Snapchat puppy, with vast cartoon eyes, wagging pink ears, and a brown snout. When she talks, her voice is grotesquely distorted, a robotic hallucination of a child’s cadence. “I might have to start limiting filter time,” Celeste says in the same exasperated, noncommittal way that you might think, I really should spend less time on Twitter.

On Monday night, Alexandria Ocasio-Cortez declared in an Instagram video that “the United States is running concentration camps on our southern border.” The following morning, Liz Cheney tweeted, “Please @AOC do us all a favor and spend just a few minutes learning some actual history. 6 million Jews were exterminated in the Holocaust. You demean their memory and disgrace yourself with comments like this.” After that, the fight was on.

On its face, the fight was about using concentration camp outside the context of the Holocaust. In a subsequent tweet, Ocasio-Cortez linked to an Esquire article noting that the term pre-dates World War II. It quoted the historian Andrea Pitzer, who defines concentration camp as the “mass detention of civilians without trial.” To Ocasio-Cortez’s critics, this was too cute by half. Whatever the term’s historical origins or technical meaning, in American popular discourse concentration camp evokes the Holocaust. By using the term, they argued, the representative from New York was equating Donald Trump’s immigration policies with Nazi genocide, whether she admitted it or not.



Editor's Note: This article is part of Exit Interview, a series of conversations about leaving one’s career.

In 1966, Nancy Bancroft changed not just her career, but her name. After joining a convent, “I went from Nancy to Sister Dorothy, which was my mother’s name. Dorothy means ‘gift of God.’” While there, she wanted to continue to pursue a meaningful career, but was also curious about what it might be like to experience marriage and have children. Seven years after taking the habit, she took it off—and entered the dramatically changing world of the 1970s.

I spoke with Bancroft for The Atlantic’s series Exit Interview to understand what happens when leaving a career means not just a change in job description but in one’s core identity. The conversation that follows has been edited for length and clarity.

Catie Lazarus: What propelled you to become a nun?

Nancy Bancroft: To really understand why someone would enter the convent, people have to understand the culture before the feminist movement. We were raised to be wives and mothers. If we had a career, that always came third. Young women who were married, for example, weren’t accepted in nursing school. There were very few teachers who were married.

And there was altruistic beauty to being a nun. I was always interested in spirituality and a meaningful life of service. If you wanted to help people, you gave up on family and lived with other women who also wanted to make the world a better place. I started right after Christmas in 1965, and by August of 1966, took the habit. You might have seen this in The Sound of Music, when Maria looks like a bride—before that your head is not covered.

Lazarus: What was it like being Dorothy and, moreover, a sister?

Bancroft: I did parish work—like social work. I visited the sick and people at home. The whole focus was on God, not to have distractions. If a priest couldn’t accompany you, you couldn’t go out. Your friends couldn’t visit. You got mail once a month. I was also taking night courses and was a teaching assistant at a grammar school.

For several years, you make vows for one year: “This is the life I am choosing for one year.” Then the expectation is to make final vows. It’s like marriage, so you commit forever.

I spent seven years wrestling. Throughout, it was a struggle: I didn’t feel ready to commit, but didn’t feel confident that I should leave. I prayed constantly, asking God, “Do you want me to stay in or go out?”

Lazarus: What eventually pushed you to leave?

Bancroft: I liked the camaraderie and community, but the world was changing. The women’s movement made a difference because men could share in the housework and home chores.

Hormones also! Both sexual hormones and maternal instincts were raging. My friends were getting married. Every month I was falling in love with someone else. I saw only cute babies and was tempted to steal a few. It wasn’t a constant thing, but when the time came for final vows, I knew it was time to leave.

Lazarus: You’d been living in a convent for seven years. Did you experience culture shock?

Bancroft: It was like Rip Van Winkle waking up. People were smoking pot and sexually promiscuous. Everything was open. It was a huge shock. My life had been pretty sheltered from the drug culture and free love. I found a lot of that culture shallow and boring. I did miss the closeness of community life, and there was a depth of experience in religious life. Intentional communities are about more than sex, marriage, and poverty.

Lazarus: Being a nun is often described as a calling. Of course, these “calls” can change. What was that shift like?  

Bancroft: It was scary to go, because I had had an identity. And I didn’t have a good self-image as a woman. I feared I’d be alone the rest of my life, but I just knew I had to go. The peace was stronger than the fear, even if they both were there.

Lazarus: Logistically, what did you do after you left the convent?

Bancroft: I went to live with my parents. They did the best they could to make me comfortable in their home. Then I lived with my girlfriend. I worked nights. I didn’t have to answer to anyone, or ask anyone for permission. I had to start learning how to pay bills. How to shop. I smoked pot and drank alcohol when I went out with the people I worked with—this was the culture, and this was what people did to socialize. It was strange. I enjoyed smoking pot. I didn’t like drinking. The struggle was how to be true to myself, open to how the world had changed, and find a compass that had a true north.

I went out with a few guys. Eventually I met a man at the state hospital, and it was love at first sight. He was the one for me, and it was the first time I’d felt that way. We went out a month after we had started working together. Two weeks later, he asked me to marry him. We’ve been married for 44 years.

Lazarus: Your professional and personal life, to some degree, stayed intertwined. How did you stay committed to social service?

Bancroft: The lifestyle was different, but the motivation continued. I got my master’s in counseling and worked in a women’s substance-abuse program. I wasn’t sure if I’d like it or be any good at it, but I figured this could be a good field for me. Later, a superior I had written to suggested private-practice counseling, specializing in working with clergy and the religious.

Lazarus: There were enough people leaving religious careers who needed help for you to specialize?

Bancroft: It had been 10 years since Betty Friedan wrote The Feminine Mystique, so it took a while, but in the ’70s and ’80s there was an exodus of Protestants and Catholics who were practicing ministers and sisters. Some had anxiety, agoraphobia, substance abuse, family issues, health issues, and tough diagnoses. The superior said we need a counselor who understands religious life.

Lazarus: How did leaving the convent impact your religious practice?

Bancroft: In the 1990s, I left the Catholic Church for a number of reasons. I didn’t like the Church’s stance on sexuality, sexual identity, bishops’ response to priests’ sexual abuse, and not allowing women to be priests. Spirituality was always important to me, but I stopped being a churchgoer. Then, when my sons were in school, I started taking courses in ethics. I stopped taking new clients and I got my Ph.D. in ethics.

Lazarus: And you recently became an interim minister at a Protestant church.

Bancroft: I missed the community, and I’d never been in a Protestant church before. One Easter, our son and his wife and child were visiting, and we went. People were warm and welcoming, without being schmaltzy. At the time, I was working for the Sisters of Mercy doing leadership and organizational development. The first five years were creative, but the last three years were maintenance, and felt like it was a waste of my time. So, I thought I’d take a leap here. I quit my job. I felt like I was doing it for the money, and thought God has something else for me. The minister of the church was retiring. She’d been there 16 years. Before they hire someone else, they hire an interim minister, so they can take as long as they need to find the right person. So, I said to my husband, “I feel a calling.”

Lazarus: Did you work as a nun come in handy when you became a minister?

Bancroft: Being a Catholic nun and Protestant minister are very different beliefs, religions, and ways of celebrating. A priest and a minister may be closer, but a sister was never a leader, not in the Catholic Church. It was always men, men, men, never women, and that was one of my bugaboos. So, I applied, and they selected me. I served as the minister for a couple years.

Lazarus: Did you want to stay on, since it had felt like a calling?

Bancroft: I could have put my hat in the ring and applied for the position, but they wanted someone for the long run. It’s a very time-consuming job. It’s hard work, 60 to 70 hours a week. I turned 70 in June, so I didn’t think it would be fair to the church. I didn’t think I’d have that kind of stamina. I am hoping I’ll be healthy in 10 years, but I thought leaving in that position was the best way to serve that church.

Lazarus: Do you miss the structure of a place to go?

Bancroft: No. I’m a retired woman. A woman who is retired. When people see someone with gray hair, they just assume you don’t do anything. I am not saying I am not going to do anything! I have hobbies and grandchildren.

Maybe I will be astronaut. Who knows?



The Dow Jones Industrial Average has fallen by 1,000 points only twice in its 122-year history. The first time was Monday. The second was Thursday.

There are two points to make about this. First, stocks have had a miserable week. The Dow erased nearly $3 trillion in wealth with a 10 percent plunge that officially qualifies as what’s called a market “correction.”

Second, stocks have had a marvelous decade. The Dow has thousands of points to lose because it has accumulated thousands of points in the last few years, quadrupling since 2009. With this latest collapse, the index of 30 stocks has fallen way, way back to levels not glimpsed since the dystopian hellscape of … Thanksgiving 2017.

So, what’s this all about? The stock market is a synthesis of stories about the future, a global anthology of investors’ financial predictions. When stocks rise steadily with little volatility—as they have for the last few years—it suggests widespread agreement on the world’s economic narrative. For a long time, the story went that corporate profits were rising in global unison for the first time in years, as both inflation and interest rates stayed low, creating a relatively risk-free environment for equities.

Then, rather suddenly, the story changed. On Friday of last week, the Bureau of Labor Statistics announced that wages had grown by 2.9 percent over the previous 12 months, a record high for the current expansion. This seems to have triggered fears that higher wages chasing a finite number of goods and services would lead to higher prices and furthermore that higher prices would encourage the Federal Reserve to raise interest rates to combat inflation.

Just as low interest rates had buoyed stock prices for years, the fear of rising interest rates has the opposite effect, inspiring a “flight to safety” as traders switch from stocks to fixed-income investments, such as government bonds. As investors scrambled to move money from equities to bonds, many traders who had bet against this sort of volatility—through a (now controversial) financial instrument, called XIV, that essentially allowed people to place wagers on continued calmness in the markets—were nearly wiped out. It all led to the worst nominal loss in the history of the Dow.

And that was just Monday. On Tuesday and Wednesday, stocks whirled like a plastic bag in a hurricane, at one point recovering most of their losses. Then, on Thursday, everything fell apart all over again in the midst of a crowded news cycle, as China’s trade surplus narrowed, and Republicans announced their plan to pass a deficit-swelling budget.

The significance of this week’s market gyrations can be stated simply: There is no reason to believe that this is the beginning a global financial crisis. Nor is there reason to believe this is the foreshadowing of a U.S. recession. Assigning monocausal blame for soaring or plunging stocks is a rough business, but what happened this week is in all likelihood a tizzy over inflation.

But if markets are afraid of inflation, they are fearing a ghost. Ever since the 2008 financial crisis, warnings of incipient inflation have been both persistent and wrong. The Federal Reserve has routinely aimed for 2 percent inflation in the years following the housing crash, and its aim has been routinely low. In 2016 and 2017, wage growth accelerated for lower-income Americans. But annual growth in “core personal-consumption expenditures”—the Fed’s most commonly used inflation measure—was 1.7 and 1.5 percent in those years. Wages perked up a bit. Prices didn’t.

If investors are afraid of the Fed’s approach to inflation, it is ironic that this season’s research note from the Federal Reserve Bank of St. Louis is titled “Why is inflation so low?” “The U.S. inflation rate has been below the Fed’s 2 percent inflation target since 2012,” the paper begins, going on to cite “several reasons to be concerned about very low inflation,” such as the risk of a recession caused by falling prices, or deflation. This isn’t a purely American phenomenon, either. The world has been trapped for years in a steady state of low price growth. In 2017, annual inflation across the rich countries that make up the Organization for Economic Cooperation and Development was just 1.7 percent.

Is this story about to change? Nobody knows. But one data point of 2.9 percent wage growth is just that: one point of data. It’s not proof that wages are taking off. It’s certainly not proof that accelerating wage growth is driving up prices. For now, it’s just a statistic, yet it seems to have helped trigger a frenzy of fear across global markets that inflation—that ever-feared and never-appeared boogeyman—will finally materialize.

For years, stock prices have inflated in part due to constraints on labor costs. Now at the slightest sign that labor costs might themselves be inflating, equities seem to be crashing for fear the central banks might rein in their support of economic growth. That’s quite a shame. If investors are wary of central bankers because they think bankers are wary of labor’s gains, it sets up a dynamic where capital specifically defines risk-free success by its capacity to restrain the prospects of labor. Capitalism may be the best flawed economic system out there, but is it any wonder that more Americans are starting to doubt that it’s working?



It can be hard to fathom just how intertwined Americans’ lives are with the country’s financial industry. About 178 million Americans have at least one credit card, according to the Federal Reserve. Forty percent of adults under the age of 30 are paying off student loans. A record 107 million (43 percent) of adults have car loans. And about 80 percent of American adults have a credit score. The safety of the financial products that these hundreds of millions of Americans use fall under the purview of the Consumer Financial Protection Bureau.

Prior to the founding of the CFPB, disputes between individual customers and their banks could be daunting and expensive pursuits. The financial industry has never been known for its transparency or accessibility, and banks managed to sneak all types of dangerous, expensive, or exploitative provisions into the fine print of contracts on everything from credit-card applications to mortgages. The subprime-debt crisis highlights just how badly that can turn out for everyone. While state-level consumer protections existed and banks were regulated by entities such as the Federal Deposit Insurance Corporation and the Office of the Comptroller of the Currency, the CFPB was the first federal regulator to take a critical look at such a wide variety of banking practices with an eye toward fairness and protection of consumers above all else.

And yet, few Americans know much at all about the agency. A 2013 poll of 1,000 people done by a progressive nonprofit, Americans for Financial Reform, showed that only about 40 percent of Americans hadn’t heard of the CFPB or had no opinion about it. It doesn’t seem like awareness improved much with time. In a small but representative survey of around 500 adults conducted in 2017 by the financial product–recommendation website CreditCards.com, approximately 81 percent said they didn’t know enough about the agency to have an opinion about it.

However, in the past few weeks, the CFPB has gotten a bit more attention than usual. With the resignation of its leader, Richard Cordray, an ongoing lawsuit, and the appointment of an acting director who has openly called for the destruction of the agency, the bureau has been the latest entity sucked into a dramatic standoff with the Trump administration. But with other major battles over issues like taxes and health care brewing, is fighting over this tiny, relatively new agency worth it?

The fact that many Americans seem unaware of the Bureau’s work isn’t itself evidence that the Bureau’s work isn’t valuable. In fact, the agency’s low profile says nothing of its impact, and everything about how much easier the agency has made settling disputes with financial companies, says Joel Wertheimer, a civil-rights lawyer from New York. “Normally for a consumer to get a settlement, private lawyers like me have to find this case, find out about it, negotiate a settlement, they take a third of it, then they have to send out notices, get people to opt in, and administer the fund,” he told me. That of course, is a process that benefits Americans who have the time, knowledge, and often money to pursue their grievances. But Wertheimer, and millions of other Americans who received settlements, often don’t have to do any of that.  

Wertheimer told me that he recently opened his mail to find a check in the mail for around $1,600. “I sort of didn’t believe it,” he said. The notice that came along with the check said that he was receiving the payment in relation to “a debt-protection program offered by Citibank.” Wertheimer had opened up a credit card with Citibank when he graduated from college and vaguely remembers language about a credit-protection program. “I thought that was something I needed,” he remembers. It turns out that Wertheimer’s was one of the 7 million accounts that the CFPB determined fit the criteria of deceptive marketing and unfair billing practices at Citibank—where so-called “add-on” programs didn’t offer that much protection at all, and suckered customers into paying for the extraneous services with misleading promotions. Wertheimer’s $1,600 check came from the $700 million fine the Bureau levied against the bank for its practices—and he didn’t have to do anything to receive the money he was due.

These sort of day-to-day transactions and practices are ultimately what can hurt customers, sap their money, and leave them with little recourse. The CFPB was created explicitly with the intention of fixing that. Gene DeSantis, a now semiretired consumer lawyer, spent much of his career working on shoring up financial protections for people in the state of New York. Many of the issues he worked on, including things like mandatory-arbitration clauses and transparency initiatives, are problems that the bureau now tackles at a federal level. Still, despite his expertise in consumer law, DeSantis says he found himself with a dilemma that only the CFPB could tackle.

When DeSantis’s son went to college, he gave him a credit card from TD Bank to use in case of emergency. His son is really responsible, he told me, so he didn’t worry about him racking up an insane bill on something silly. DeSantis spends about five months every winter in Park City, Utah, where he likes to ski. When he heads out to Park City, he temporarily forwards his mail to ensure that he won’t miss anything while he’s across the country. But while in Utah, he got a call from a debt collector who told him they were calling about an overdue amount on the credit card he’d given his son. After being connected with the bank, he found out his son spent about $150, on car maintenance and gas. “I’d never even gotten a bill,” DeSantis said.

Given his profession, DeSantis was inclined to fight the bank on this. He learned that there was a clause in TD Bank’s credit-card policy that said that it wouldn’t allow credit-card statements to be forwarded, supposedly for his own protection. Because the bank refused to engage in this fairly common practice (which he said all of his other banks provided) a $150 charge had been collecting interest and penalties for months before the debt-collection agency called him. Now the bill was double the amount.

The bank told him he was liable, despite the fact he wasn’t receiving his bills. He wanted to sue, but his credit-card contract also included a mandatory-arbitration clause. “The only place I could turn to was the CFPB,” he said. Within a week, DeSantis says, the bureau had acknowledged his complaint, reached out to the bank, and TD Bank had agreed to accept his payment for the original charges and waive the additional fees and interest. “No matter how much you think you know, and how well versed you are in the law, there come times when even the most savvy or knowledgeable consumer is still going to get burned,” he told me. “That’s what happened to me.”

These sorts of stories—and the amounts of money they represent—may seem a bit small-bore, but together they amount to some $12 billion that banks or other financial institutions took in under terms that were later deemed unfair, and that they had to repay to Americans who would otherwise have been without much hope of recouping lost money. The bureau’s mandate, and relative freedom to pursue it, hasn’t exactly endeared the agency to the financial industry or the politicians who nurture (and benefit from) close ties with Wall Street.

The fight over the future of CFPB didn’t start when Richard Cordray, the agency’s first director, stepped down to reportedly run for governor of Ohio. It started almost as soon as the idea for the agency was conceived. “There are a lot of intense feelings about the CFPB and there always have been,” says Nick Bourke, the head of consumer finance at the Pew Charitable Trust. In creating the agency, the Dodd-Frank Act gave the bureau and its leadership an unusual amount of autonomy. The CFPB’s director is nominated by the president and confirmed by the Senate. After that, he or she can’t be forcibly removed during his or her five-year term. And the agency isn’t subject to congressional appropriations, since its funding comes from the Federal Reserve. It’s the agency’s independent structure, along with the fact that it was the brainchild of a progressive senator, Elizabeth Warren, and was founded under a Democratic president, that irks many Republicans. For many conservatives, who accused the Obama administration of government overreach and heavy-handed regulation, the CFPB stands out as a glaring example of the previous administration’s failings. “It was a foolish idea for Congress, in the Dodd-Frank Act, to create a regulatory body like the CFPB and make it completely independent of all the controls usually imposed under the Constitution,” Peter Wallison, a fellow at the conservative think tank, the American Enterprise Institute, told me via email.

It of course doesn’t help that the agency has been aggressive when it comes to creating new regulations, which have included new rules for payday lenders, prepaid debit cards, and mandatory-arbitration clauses. And then there are enforcement actions, which have cost financial firms billions of dollars in fines and restitution. Aside from Republicans, the most vocal critics of the CFPB have been financial firms and their lobbyists.

Republicans have spent much of Cordray’s tenure attempting to fight the Bureau for these reasons. In 2016, they scored their biggest victory yet when a judge ruled that the agency’s structure, namely the freedom of its leadership, was unconstitutional. That is to say, the uproar over the seemingly small question of who will lead the CFPB is just the latest battle in an ongoing war.

Right now, Republicans are seemingly winning. Last week, Tim Kelly, a federal judge, sided with the Trump administration in a question of who should lead the Consumer Financial Protection Bureau right now. The decision was the first of many legal decisions in what could be a prolonged lawsuit about who is at the helm of the agency. And that won’t be the end of it. Even after the matter of a temporary leader is settled, a new long-term leader will still need to be nominated and confirmed within six months. Trump recently said that he would nominate a new director in “upcoming weeks.”

Even though the acting director, Mick Mulvaney, who currently also leads the Office of Budget and Management, says that his intent isn’t to gut the agency, his previous criticisms, along with the fact that Trump would install a leader who has so publicly attacked an agency to lead it, don’t bode well for the agency now or in the future.  As one of his first acts as acting director, Mulvaney put a 30-day freeze on hiring, regulation, rulemaking, and payouts to consumers.

Right now the freeze leaves work such as the agency’s $10 million fine against the bank Santander for illegal overdraft practices and its lawsuit against the student-loan servicer, Navient, in limbo. These two actions, in particular, represent some of the bureau’s most common and impactful work, according to Bourke. In addition to Santander, the bureau is responsible for levying fines against Wells Fargo for its fake-account and auto-coverage scandals. And as student-loan debt has ballooned and the Trump administration has rolled back protections for some debtors, the agency has increased its scrutiny of the banks and financial entities servicing that debt. In addition to Navient, the Bureau fined Citibank more than $5 million for misleading customers about its student-loan repayment practices.

There are dozens of open enforcement actions that won’t see much progress for at least a month, which will delay affected customers from recouping their money. In both the short- and long-term the agency faces risk from instability. “Any system needs rules,” says Bourke. “If a new director comes in and slashes and changes the existing rules, that creates a lot of chaos that can actually be bad for the companies.”

Thus far, there are a few common threads of Trump’s administration, including a push for deregulation, a close relationship with Wall Street, and a commitment to undoing everything that can be credited to Obama. None of those mix well with the past work of the bureau. While the acting director of the CFPB doesn’t have the power to totally shutter the agency, loyal Trump appointees at the helm for the foreseeable future doesn’t bode well for it.



Editor's Note: This article is part of Exit Interview, a series of conversations about leaving one’s career.

James T. Green landed the job of his dreams fresh out of the University of St. Francis in Joliet, Illinois. At just 23 years old, he had a senior graphic-design position in advertising at a major media organization. But after landing in the hospital, not once but twice, he worried that stress might kill him.

Some stress is inevitable. But when a high-stakes work environment collided with a challenging time in his life, Green started suffering debilitating panic attacks. Eventually, as part of his recovery, he chose to leave his job. I spoke with Green about the role work played in the stress he was experiencing, and how he manages stress today, for The Atlantic’s series Exit Interview. The conversation that follows has been edited for length and clarity.

Catie Lazarus: You landed such a distinguished job right after art school, what was it like?

James T. Green: We essentially cranked out ads for like six or seven publications. I designed flash ads, coded and designed emails, marketing newsletters, and small website updates for my employer and pretty much all of their subsidiaries. My role was pretty senior. I was living my dream—or so I thought.

Lazarus: So, why did you leave?

Green: I’d been there for two years, and I had to go the hospital because I felt like I couldn’t breathe. At that time, I had a really, really bad pulmonary embolism. Then a blood clot developed in my leg, shot up to my lungs, and to my brain. It was almost fatal. I ended up going to the hospital twice. One time, the doctors thought I was having a stroke. I did physical therapy, and they realized I didn’t have a stroke—I had the symptoms, but I had had a panic attack.

Lazarus: Had you been at work when it happened?

Green: I was getting up to go to work, and, as I went to the bathroom, everything blacked out. I was essentially flatlined for like a minute. My fiancée—now my wife—heard the crash when I hit the floor.

It’s so weird to say—I saw what looked like a keyhole, and a lot of what I was seeing was this work, and I wasn’t happy. It put a lot of shit in perspective. I got shaken awake and was off to the hospital. The people at the ER said that if my wife wasn’t home, I would have died. But when I got out of the hospital, fresh out of surgery, I was still thinking about this job, and I realized it was driving me nuts. The stress at work was pretty much amplifying the issues going on in my body. Not to sound super corny, but I almost died. I had a second chance to get things right. And not to sound super Millennial, but if I am going to do something I better give a shit about it.

Lazarus: When did you know when you were going to quit?

Green: I was having panic attacks still. In this back-and-forth with a client over the smallest, cheapest ad, they wanted this in-depth animation, turned around in a day, and wanted changes, over and over and over, on very minute things. That ad took the cake. I felt dehumanized. In the midst of this, I realized that I was going to resign. I chatted my supervisor and asked, “Can we go over to the corner and talk?” I told her that I was putting in my two weeks.

My supervisor was understanding. We’d chatted out of and inside of work, and my bosses knew I was going in and out of the hospital. They understood I was different when I got back. So, it made the break kind of clean.

Lazarus: How did the stress you were experiencing at work figure in with other stresses in your life at the time?

Green: Before I quit, it was a dark time. My best friend was diagnosed with cancer, and it came back, and it rapidly tore him up, and he died. A couple weeks after that, my aunt—I was really close to her—she suddenly died as well. I was in a deep, dark depression, and tried to commit suicide. My wife said, “You should go to therapy.” I definitely give my therapist credit for seeing how [in addition to everything] a high-stress work environment may not be for me.

Lazarus: Did you already have a plan in place in place for what you'd do after you left?

Green: When I got back from the hospital, I started to build up a client base and give people a heads up, just to make sure I had a clean landing. I had a month’s worth of cash, and my wife was employed, so she was making money, but the day before I quit, the public radio station WBEZ offered me an assignment, so I had three months of padding.

Lazarus: What brought you to podcasting?

Green: I’d listened to podcasts as they had helped me feel less lonely. Essentially, when you are working in advertising and code, it’s time looking at a screen. The environment was also very cliquey, and it didn’t help that I was one of just a few black people on a predominantly white team. Podcasts felt like a kind of escape and it was a way to envelope myself in a world I wasn’t in. So, I wanted to try podcasting.

Lazarus: You’re also a musician. Why didn’t you pursue that instead of podcasting?

Green: Music is so difficult. I’d futzed around, but it was so difficult. I don’t like taking risks, and podcasts, if anything, felt like the perfect balance. I knew how to tell stories because I was already a visual artist. I knew the skills of cutting tape. It felt like the hard skills I had in technology.

Lazarus: How did you make ends meet?

Green: My wife and I are both artists. But she works in tech, for a digital-advertising agency, and she loves it. Right now, I am paying for insurance, and she is definitely the breadwinner.

Lazarus: How long did it take to turn podcasting into a job?

Green: I was pretty much doing that dance for a year and a half. It was a full-circle moment when I really dedicated myself to podcasting. Out of nowhere, I got an email from MTV News. Their representative and I met up for coffee, and he told me that MTV wanted to hire me to make a podcast division. This was the first time my hobby became a capital-J job.

It was a lot of fun, but the whole “pivot to video” happened [when newsrooms reorganized staff to focus on video platforms], and I resigned because I saw the rumblings. I quit MTV and, a week after, I was working at Gimlet.

Lazarus: It’s been four years since then. Have you had panic attacks and anxiety?

Green: Oh yes. Not as often. I’ve been medicated, and therapy has been really helpful, and my career took a real pivot. I don’t get as panicked.

Lazarus: Is podcasting less stressful than advertising, or have you changed?

Green: It’s how I manage it now. I can sit in it. Like when I was doing my first edit at Gimlet, I told my senior editor and producer about it, and excused myself, and did a lot of deep breaths. I realized these panic attacks were happening because I was nervous, and I wanted to do a good job. To be completely honest, after leaving advertising, aside from being in a crowded subway, they all come from a place of growth rather than pure panic.

Lazarus: Listening to podcasts is one thing, making them is work. Are you still passionate about it?

Green: I thought my passion was making ads. I really thought that was what I wanted to do for the rest of my life—and that’s why following your passion is bad advice, because you never really know where your passion is going to end up.



Editor's Note: This article is part of an oral-history series where Aaron Reiss interviewed the young-adult sons and daughters of Chinatown shopkeepers about how they are helping to keep their families’ businesses alive.

Ken Ma, a 32-year-old M.B.A. who is being groomed to become the CEO of his parents’ optical empire, Mott Optical Group, recalls the difficulty of taking over as a “boss’s son” in a family business: “I thought, I am the son of the owner; I can’t make mistakes. People are looking at me—I have to set a good example, I have to be flawless, I have to be knowledgeable about everything.”

I spoke with Ma in the spring of 2018. Below is our conversation, lightly edited for clarity.

There’s a stereotype that you grow up working really hard in Chinatown—and Chinatown is this and that, it’s dirty, it’s crowded—then you get a good degree and go off to work at McKinsey or a bank or a financial firm or some other white-collar professional job.

My dad was working hard here in the ’70s and ’80s, when it was relatively dangerous, with gang violence and all that. And when I was born, we moved from here, in Chinatown, to Bergen County, New Jersey.

My dad spent a lot of time at the store, helping customers, establishing himself as a pillar of the community. And we really saw him as a hero of ours. Like you know when people in school are supposed to come dressed like what they want to be when they grow up? Other kids came as a fireman, a police officer, a doctor. I came dressed as my dad, with a little eyeglass lapel pin. I always wanted to be part of the family business.

Growing up, I worked here in the summertime. I was mostly filing. That was the heyday, so I was really, really busy here. Once I graduated from high school, I worked a lot of other jobs. I worked at McDonald’s on Chambers Street, behind the counter and in the kitchen. That was my first real job outside the family business. I did sales at Abercrombie & Fitch, different campus jobs. But I really started to become interested in finance and banking.

My third summer in college, I got a sales-operations internship on Wall Street, and that world definitely started to have a draw for me; I wanted to go into consulting or investment banking. I think that they create structure and discipline. Also, you know, it’s kind of fancy. You work at Goldman Sachs or McKinsey, and you get to travel around different towns and countries. The next summer I went up to an internship at a private-equity firm specializing in family and closely held businesses in Greenwich. After that, I wanted to use that leverage to jump to the Citibanks and Merrill Lynches of the world. But that was during the recession of ’07 and ’08, and every time I called people, trying to network, there were hiring freezes. So I kind of saw the writing on the wall.

Rather than going back to the family business, I decided to go as far away from it as possible. I thought, I need to experience something more than I know. I was reading The Economist, and every other article is about how China is growing, China’s the next dynamic market. And I just wanted to experience it. So I traveled to China through a Christian organization. I taught English in a small town called Zhenjiang (although a small town in China is, like, 2 million people). Zhenjiang is famous for this special vinegar they make—that dark stuff that’s fantastic with dumplings—and the whole city just smells like vinegar.

I tried to start my own business in augmented reality, using webcam technology to try on glasses. I tried to copy what Ray-Ban did, but couldn’t find a trustworthy tech partner, so it didn’t go through. So I kept teaching English and then got a real job at an HR consulting firm in Shanghai. I was doing recruitment consulting, basically headhunting for the Fortune 500 companies that were coming into China, to try to find them local talent.

At this point, I knew I wanted to come back and work at the family business, but my mom was like, “You can’t come back to us without proving yourself.” Like, getting a promotion or a raise. I got my promotion from associate to senior associate that April, in 2012, and I came back six months later to start at my family’s shop.

I moved in with my uncle in Manhattan, and I started studying for the GMAT. I went to NYU’s business school in 2014 and finished last May. During that whole time, I was working at the family business.

My role has been overseeing finance and marketing. I set budgetary goals for each store, I look over profit and losses, salaries, inventory, all of that. I also deal a lot with our house brands. After I finished my M.B.A., I gave myself a promotion from manager to business-development director. It’s just a title bump. I gave my sister the title Kaleena the Konqueror, with a “K.” I work six days a week. That’s not enough! My sister works seven days—she calls me lazy! (Editor’s note: Kaleena is being groomed to take over for their uncle, as COO.)

The big shiny object in the distance was Warby Parker—like, Oh, why can’t we be like Warby Parker? And I thought that was where the industry was heading. I built an in-house brand for us, called Mott and Bayard Eyewear, after the intersection that our store, Mott Street Optical, is on. It was my brainchild, and my response to Warby Parker, with an Asian fit. The idea was to make affordable, Warby Parker–style plastic frames that are made for Asian faces. I would see all my friends from church—it’s, like, 30 percent Asian, a lot of young professionals—buying Warby Parker, and they love them, but they don’t fit them well. We need to have more substantial nose pads to prevent them from slipping down. We have elevated nose pads that are about 30 percent higher than on most designer eyewear frames. Often the nose pads are nonexistent to three millimeters. Ours are 11 millimeters.

The No. 1 obligation I feel is to maintain our family standing. I was hearing problems through emails or chats with my mom and sister: That employee left, or that competitor opened a shop nearby. My cousin actually opened a shop down the street, with our old manager. My dad’s old apprentice opened a shop right across the street from us, Eye Solutions. It’s like Game of Thrones. The basic idea is that if you don’t grow, if you don’t get better, then another person will do it better than you.

At first, it was definitely hard. I felt like I didn’t really know much about the business. A lot of things I proposed and tried to implement didn’t work out. And it was just very discouraging. I also took things like employee turnover really personally—I would be thinking, What could I have done differently? There is something wrong with me if they are leaving. If I ever didn’t know how some aspect of the business worked—like what was different between these two lenses or frames—I took it to heart. I thought, I am the son of the owner; I can’t make mistakes. People are looking at me—I have to set a good example, I have to be flawless, I have to be knowledgeable about everything. Also, a lot of people are seeing you only as the boss’s son. They don’t call me by my name—they used to just say, like, “boss’s son.” I mean, they used to call me that. It’s kind of disparaging, kind of disrespectful. I’m more than that; I have other interests. I’m very involved in my church—I’m a Christian. I feel that my identity is through Christ, not being the son of the owner.



Tim Chen had recently been laid off from his job as a financial analyst at a hedge fund, during the recession of 2008, when his sister asked him for help finding a good credit card. Much of the information he found online was confusing and disorganized, so he decided to start a personal-finance website; it would go on to become NerdWallet, which is now worth $500 million and employs almost 350 people. I recently spoke with Chen about how it feels to get laid off, starting a business during a recession, and why workers should pay attention to who their managers are. This interview has been lightly edited and condensed for length and clarity.

Lola Fadulu: Your parents were computer scientists. Did they want you to go into computer science?

Tim Chen: Yes. It’s a stable job. They knew it well. They had been able to provide for our family by working in the industry. My sister and I were really fortunate. My parents paid for our college education, which is huge.

Fadulu: It sounds like both your parents were steering you toward jobs that would lead to stable futures and high standards of living. How much were you thinking about money when you were applying to jobs post-graduation?

Chen: Growing up, I never felt well off, even though in hindsight we were at least much more stable than average. I think it’s part of the immigrant mentality to be really ambitious about providing for a good future for your kids. I think people base their perception of the world on what happened in their lifetimes, and both my parents fled from armed conflict in their very early years and grew up quite poor after World War II.

Fadulu: The way you grew up was very different from the way your parents grew up.

Chen: Until 2008, I thought that the economy was this super-stable thing, and everything was good. I didn’t realize that crazy economic shocks can happen. 2008 really changed my life. I lost my job, I lost a lot of my savings. I ended up starting a company as a result. It’s funny; my grandpa used to tell me, “You should take your money and go buy gold and jewelry with it, because you never know when the government’s gonna get overthrown by communists.” I’d go, “Grandpa, that’s such outdated thinking.” But it wasn’t that long ago when that happened to a huge country.

Fadulu: Were you completely surprised when you lost your job in 2008? Did you see it coming at all?

Chen: Absolutely not. [I was] totally blindsided. Never in a million years would I have thought that the institutions that I worked for, or the banks themselves, would be worried about going out of business. In hindsight I feel very fortunate that there was a recession, from a personal perspective, because I never would have gotten into entrepreneurship, even though it was an ambition of mine. It’s just too hard to take that risk when you have a stable job and you’re living in a really expensive city like New York. So the downturn forced me into it. In the early years, I wasn’t seeing much success with NerdWallet, and it was really the length of the recession that caused me to keep trying instead of taking another job.

Fadulu: Did you have any other business ideas you were considering, or was it NerdWallet all along?

Chen: I didn’t know that I wanted to start a business. I didn’t have anything that I was seriously considering outside of NerdWallet. It really came about when my sister asked me for help finding a credit card. I said, “Let me Google that for you.” I was kind of surprised when I didn’t find anything that helpful, in terms of breaking it down in an easy-to-understand way. I quickly realized that this is a problem with all financial products. They’re extremely hard to shop for because, basically, there’s no incentive for anyone to provide you with an easy-to-understand way to shop for them.

Fadulu: What was the hardest part of starting NerdWallet?

Chen: I think one of the hardest parts was convincing other people I wasn’t crazy. You can’t do something like this yourself. You need to convince people with perfectly good jobs to quit their jobs and come join you, which is a lot of responsibility to shoulder, especially in the early days. Fortunately, in the early days it was much easier because many of my friends in New York were unemployed. A lot of us were affected by the financial crisis. A lot of us were just sitting around twiddling our thumbs, going to Dave & Buster’s in the middle of the day because they have half-price tickets on Wednesdays. And it was easy at least to get a few people to hang out [and join NerdWallet] until they found gainful employment. The first two years, I basically told people I was unemployed because there was really very little traction in the business.

Fadulu: You had to convince people to quit perfectly good jobs. How did you do it? What were your selling points?

Chen: In the early days, it was really just hitting up people out of my personal network from college or people who had been laid off from their jobs and seeing if they [wanted to help out]. I couldn’t pay them at the time. Later on, as we started growing, it really became more about painting the vision of what [the business] could eventually become and getting people inspired by that.

Fadulu: What would you say is the best piece of advice you’ve received from a mentor or a colleague?

Chen: For me, personally, it was that you can’t just put your head down and work hard and do things. You have to communicate well what it is you’re trying to do—the vision behind what you’re trying to do—to get other people inspired to understand what you’re doing and help you out. I think that really applies for NerdWallet the company because … I, myself, have done very little. My one piece of advice from my early career is that I had no idea that my development and my happiness at each of these jobs was going to be almost completely driven by my manager. In my first job, I was in a different city than my manager, and people didn’t have time to develop me or guide me. I didn’t learn much my first two years of work. At my second job, I learned more in the first two months than I did in the first two years [of the first job]. In hindsight, my manager [at my second job] cared a lot about developing me and teaching me things, and that was huge. And then at my third job, my manager and I didn’t really get along. I got fired. I think these things are important to think about.

Fadulu: What do you think about the state of the workforce for young people?

Chen: I think what I’ve noticed about Millennials in our workforce is that they are some of the most passionate, inspiration-driven people, whereas the stereotype for the older generation is that they cared more about stability and were more willing to work in a factory manufacturing widgets all day in exchange for that stability. People are much more transitory in their careers now. If you find great alignment for three or four years with a job opportunity, and you say, “I really want to learn from the person I’m working for, and three or four years from now I’m going to come out with a different set of skills,” that seems like a great fit for three or four years. You can’t really think too far beyond that. It’s really hard to plan where you’re going to be in 30 years. If you keep on doing that, it’s kind of like rock climbing. You’ll end up in a good place.

I think the best opportunities in 30 years, while we can’t anticipate them now, are going to go to the people who have picked up a lot of skills along the way.



Fifty years ago next month, Dr. Martin Luther King Jr. spoke at the National Cathedral in Washington, D.C., at what turned out to be his last Sunday sermon. He talked about the perils and promises of a “triple revolution,” as he called it, consisting of automation, the emergence of nuclear weaponry, and the global fight for human rights. Regarding that first prong, he noted at the time, “Through our scientific and technological genius, we have made of this world a neighborhood and yet we have not had the ethical commitment to make of it a brotherhood.”

It’s this speech that Virginia Eubanks, an associate professor of political science at the University at Albany, SUNY, comes back to at the end of her new book Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor. In it, Eubanks studies some of the seemingly neutral—and even well-meaning—technologies that promise to streamline the U.S. welfare apparatus. Automated systems that gauge eligibility for Medicaid and food stamps, databases that match homeless people to resources, and statistical tools that detect cases of child abuse all hold the potential to revolutionize welfare programs. Eubanks examines these technologies, detailing the ways they can sometimes compromise the rights of the very people they supposedly help.

I recently spoke with Eubanks to about some of the main themes in her book. The conversation that follows has been edited for length and clarity.

Tanvi Misra: In your book, you lay out the troublesome history of poverty-management systems: from hellish “poorhouses” to the scientific charity movement, the New Deal welfare apparatus to the automation of welfare. What is the common thread?

Virginia Eubanks: Often when we talk about new technologies, we talk about them as “disruptors”—things that shake up the system that we're in right now. One of my big arguments in the book is that the tools that I’m talking about are more evolution than revolution. So that history really, really matters.

Why I start the book with a brick-and-mortar poorhouse is because it was the most innovative poverty-regulation system of its time, in the 1800s. It rose out of a huge economic catastrophe—the 1819 depression—and the social movements organized by folks to protect themselves and their families. What’s really important about the poorhouse—and this is the thread that goes throughout all of the things I talk about in the book—is that it was based on this distinction between what at the time were called the “impotent” and the “able” poor. The “impotent” poor were folks who, by reason of physical disability or age or infirmity, just couldn't work. The “able” poor were those folks who moral regulators at the time believed were probably able to work, but might just be shirking.

That distinction between the impotent and the able poor, which today we would talk about as “deserving” and “undeserving” poor, created a public-assistance system that was more of a moral thermometer than a floor that was under everybody protecting their basic human rights.

I think of that as the deep social programming of all of the administrative public-assistance systems that serve poor working-class communities. That social programming often shows up in invisible assumptions that drive the kind of automation of inequality that I talk about in the book.

Misra: You write about the “digital poorhouse” as an extension of these previous systems. What is that and when did it originate?

Eubanks: One of the most important historical moments that I talk about in the book is the rise of what I call the “digital poorhouse,” which is really the shift from quite sophisticated but analog systems of control to digital and integrated systems of control.

When I first started doing this book, I actually began in the New York State archives, looking for the technical documents of when the poverty-management system started to be computerized. I had just assumed that that would have happened in the 1980s with the widespread uptake of personal computers, or in the 1990s when the actual policy change happened around welfare reform, which required that local welfare offices computerize some of their processes.

But actually, where I found the move to computers in the administration of public assistance happened was in the late 1960s and early 1970s. That was really surprising to me. What I learned was that right at that moment, there was a very successful national welfare-rights movement that was challenging discriminatory eligibility rules in public-assistance programs. It was succeeding in opening up the welfare rolls to those folks who have been unjustly barred in the past, especially women of color and never-married mothers. As a result, the rolls expanded very quickly. Though it’s important to understand that public assistance has never reached even as many as 50 percent of people under the poverty line, right around 1970, it got close to 50 percent. Four-fifths of children living under the poverty line were receiving public assistance of some kind. At the same time, there’s a backlash against the Civil Rights movement, especially black power, and there’s a recession.

That is the moment that the “digital poorhouse” arises, that these new technologies come into play. And if you look at the size of the rolls, they basically start to drop off right at that moment and continue in a downward trajectory until today—with less than 10 percent of people under the poverty line receiving cash assistance.

Misra: One of the case studies in your book was of the “coordinated entry system” in L.A., which started in 2013. It’s based on the housing-first approach, which first aims to get a roof over people’s heads, and then helps them in other ways. The coordinated-entry system itself consists of a survey, which gathers information about people, and plugs it into a database. Then, an algorithm ranks the cases on a “vulnerability index” so that the most vulnerable ones can be helped first.

That seems pretty positive at first glance.

Eubanks: The housing-first approach is clearly a really positive approach to the housing crisis. And I think there’s a definite argument to be made for prioritization. There are 58,000 unhoused people in Los Angeles County alone, and there are not currently enough housing resources for everyone. So, I understand the impulse.

But one of the things that I did in this book that might be a little different is that I started from the point of view of unhoused folks themselves, who are the targets of this system. What really stood out to me from their stories is the difficult choices they have to make in how they interact with the system. Because that survey I talked about? It asks deeply private or even incriminating questions about personal behavior. It asks if you are having sex without protection, if you’re trading sex for money or drugs, if you’re thinking of harming yourself or others, if you’re running drugs for someone else, if there’s an open warrant on you. And if you answer “yes” to these questions, you potentially get a higher score on the vulnerability index, which prioritizes you for housing.

Under existing federal data standards, the information that’s stored in this Homeless Management Information System database can be accessed by law enforcement on the basis of only an oral request. So you don’t need a warrant—you don’t even need a written request. So to many people I spoke to, it was unclear where the line was between this system and the criminal-justice system.

I want to be really fair; there were definitely some people who said, “Coordinated entry was a gift from God. It is the best thing that ever happened to me because it helped me get housed.” I will also say that even the people who had success with it had moments of reflections about it: “It’s strange that I should get housed when so many other people I know who are going through similar things to me didn’t get housed. That doesn’t seem right.”

But for the folks who haven't had success being housed, folks like Gary Boatwright, this idea that the unhoused community was being assessed on a spectrum of deservingness for housing really, deeply troubled them. Gary was 64 at the time I spoke to him. He had been unhoused and living on the street for almost 10 years off and on. He said to me, “This is just another way of kicking the can down the road.” The problem is not scoring people—the problem is really that there’s just not enough housing for the 58,000 people in Los Angeles.

And exactly what people were afraid of really happened to Gary. It wasn’t directly attributable to the coordinated-entry system but he was on the street long enough that sort of everyday behaviors of being unhoused are often treated as crimes—sleeping on the sidewalk, leaving your stuff on the sidewalk, public urination—leaves people open to criminalization. As far as I could tell, he got really upset one day around public transportation and was arrested for attacking a bus. He spent close to nine months in jail. He is out now, and doing well.

Misra: So, it’s similar to the the argument Khiara M. Bridges makes in her book about privacy rights and mothers on welfare: That it isn’t that folks choose to exchange their privacy for a benefit, but that they don’t really have a meaningful choice.

Eubanks: Yes, and this question of consent is important here. In Los Angeles, the folks who are given this survey do sign an extensive informed-consent document. But, it seems to me that you are stretching the boundaries of informed consent if access to a basic human needs like housing is in any way contingent on you filling out this form.

Part of the consent form says that the information gets shared with a lot of other agencies and to know more about that you have to request another form. Folks who go through the process of requesting the second form get a list of 168 agencies this information is shared with. You can ask to be expunged from the database, but the process by which you do so is really unclear—and some of your information stays in the database. The consent lasts for seven years and you have to actively stop it—by writing in and saying, “I withdraw my consent.”

So, it’s legitimate that people can have fears about how that information is being used and shared.

Misra: After writing this book, what conclusions have you come to about the way the U.S. addresses inequality?

Eubanks: One issue is the conversation that’s happening at this moment around inequality in this country—not just economic inequality but inequality writ large. What I want people to take from this book is that though we often talk about these systems as disruptors or as equalizers, at least in the cases that I research, they really act more like intensifiers or amplifiers of the system we already have.

One of the things I most fear about these systems is they allow us the emotional distance that’s necessary to make what are inhuman decisions. I do not want to be the caseworker looking at the 58,000 people in Los Angeles and having just a handful of resources and deciding who gets them. That is an incredibly difficult decision to make. My fear is that sometimes these systems act as empathy overrides—that we are allowing these machines to make decisions that are too difficult for us to make as human beings. That’s something that we really need to pay attention to because in the long run that means that we're giving up on the shared goal of caring for each other.

This post appears courtesy of CityLab.



They are everywhere. Singing jingles in living rooms. Lining phone screens. Inhabiting the voices of podcast hosts. Looming like Dr. T.J. Eckleburg from highway billboards. They are ads.

But while the work of stealing attention might seem infinitely employable, something strange is happening behind the scenes of America’s most inescapable industry. For the first time on record, the number of advertising-specific jobs in the U.S. is declining in the middle of an economic expansion, according to government data.

Anyone following the slow-motion meltdown in the media industry in the last year might expect that advertising is suffering a similar downturn. But it’s a far more complicated story than that. For the last three decades—as far back as the relevant Bureau of Labor Statistics dataset goes—advertising jobs have grown in line with the economy. Today, however, a variety of traditional advertising jobs appear to be in recession mode. The number of jobs at ad agencies fell by about 5,000 last year, on net, while employment in media-buying agencies—firms that tend to focus on advertising strategy rather than designing or filming commercials—hasn’t grown since 2013.

Number of Net Jobs Created Annually in Media and Advertising, in Thousands

What’s going on? It’s certainly not a case of fewer advertisements. The typical American has gone from seeing about 500 ads each day in the 1970s to about 5,000 today, according to a common industry statistic (and some more-recent estimates are much higher). That is one corporate message for roughly every 10 seconds of waking life.

Instead, the mysterious decline can be explained by two developments, most prominently technology’s invasion of the ad sector and the phenomenon of more corporations trying to emulate outside media companies in-house, which leaves less work for traditional ad firms.

First, there are Facebook and Google. They are the largest advertising companies in the world—and, quite likely, the largest in the history of the world. Last year, 90 percent of the growth of the digital-advertising business went to just these two firms. Facebook and Google are so profitable because they use their enormous scale and data to deliver targeted advertising at a low cost. This has forced the world’s large advertising firms to preserve their profitability through a series of mergers, accompanied by jobs cuts in the name of efficiency.

So what has been the effect of these tech companies on advertising employment? The Bureau of Labor Statistics technically considers Facebook and Google to be “data processing” companies, rather than advertising companies. So, because of this label, what government records show is not that Facebook and Google have stopped hiring people in their advertising divisions, but rather that the growth of those divisions has caused the traditional advertising market to shrink.

The emergence of an advertising duopoly has coincided with the rise of “programmatic advertising,” a torpid term that essentially means “companies using algorithms to buy and place ads in those little boxes all over the internet.” As any Mad Men fan might intuit, advertising has long been a relationship-driven business, in which multimillion-dollar contracts are hammered out over one-on-one meetings, countless lunches, and even more-countless drinks. With programmatic technology, however, companies can buy access to specific audiences across several publishing platforms at once, bypassing the work of building relationships with each one. That process produces more ads and requires fewer people—or, at least, fewer traditional advertising jobs and more technical jobs.

The old story about programmatic advertising was that both marketers and digital publishers—think AOL, or any news site—embraced the technology, as it allowed companies to cheaply target specific audiences on a budget. But the new reality is that programmatic advertising has placed many advertisements in controversial places, next to low-quality news sources or outright offensive content. Between 2016 and 2017, a survey by the Association of National Advertisers found that a third of marketers cut back on media agencies running programmatic ad campaigns. Instead, brands brought those operations in-house, where they have more control over where their ads run and much more information about who actually sees them. The upshot: Programmatic ads have been a double blow to media agencies, first automating their function and then encouraging companies to insource the work.

Second, there is the merging of the advertising and entertainment businesses. As smartphone screens have edged out TV as the most important real estate for media, companies have invested more in “branded content”—corporate-sponsored media, such as an article or video, that resembles traditional entertainment more than it does traditional advertising. Some of the most prominent names in journalism, such as The New York Times, BuzzFeed, Vice, and The Atlantic, are owned by companies that have launched their own branded-content shops, which operate as stand-alone divisions. As many media companies have tried to become more like advertising companies, the value of the average “creative-account win,” an ad-industry term for a new contract, has declined, falling by about 40 percent between 2016 and 2017.

So there are two major themes of the decline of advertising jobs, one that has to do with the companies that now create them and one that has to do with the way brands prefer to market themselves nowadays. In short, the future of the advertising business is being moved to technology companies managing ad networks and media companies making branded content—that is, away from the ad agencies.



Updated on December 28 at 2:48 p.m. ET

The most recent chapter in the debate over net neutrality has been, like previous chapters, cacophonous. One notable difference this time around, though, was the relative quiet of many large tech companies. In previous years, these firms had been outspoken about the issue. What changed?

Netflix’s net-neutrality journey is an illuminating example. In 2014, Reed Hastings, the company’s CEO, issued a strongly worded warning about oppressive “internet tolls” that could threaten the web’s status as a “platform for progress.” His company had recently tussled with Comcast (ultimately agreeing to pay the cable company to get data for its streaming videos to customers smoothly) and Hastings felt a need to take a stand in favor of net neutrality. In advance of a 2015 Federal Communications Commission vote on the issue that went as Netflix hoped, the company’s representatives reportedly contacted or visited FCC officials more than a dozen times.

In the time between then and last week—when the FCC voted to undo its 2015 regulations—something, apparently, had changed. “We think net neutrality is incredibly important,” Hastings said at a tech conference in late May, but went on to say that it’s “not narrowly important to us because we’re big enough to get the deals we want.” The size of his company, his comments suggest, could come in handy when negotiating the agreements theoretically opened up by the repeal of net neutrality—such as fees that internet-service providers (like Comcast) could ask for from, well, just about anyone (like Netflix), in exchange for speeding their data along. Netflix did submit two filings to the FCC in the run-up to last week’s vote, but the commission didn’t have any record of lobbying visits on the company’s behalf during that time, according to Bloomberg.





What about that platform for progress? The reality is that Netflix and other large tech companies, such as Facebook and Google, have grown so dominant that net neutrality has become a nonissue for them. They’re aware that their extensive, loyal user bases can protect them from any unfavorable deals that internet-service providers (ISPs) might devise—there’s leverage to be gained from becoming a platform that broadband customers expect ready access to. And unlike smaller businesses, which lack that leverage, big tech companies have the political clout to fight policies they don’t want—should they choose to.

Basically, these companies are aware of how much they’ve grown. When Netflix’s CEO was complaining about “internet tolls” in 2014, the company’s annual revenues were $5.5 billion; just three years later, they’re estimated to be more than twice that. “From [these companies’] standpoint, it doesn’t really matter who’s enforcing net neutrality, or if there’s net neutrality at all—they don’t need it,” Larry Downes, a project director at Georgetown University’s Center for Business and Public Policy, told me. “They have all the leverage they need to make sure their content gets delivered as best it can be.”

Because of that, Downes says, they didn’t see the need to put up much of a fight this time. “You’ll have noted that their voices were extremely muted during this whole proceeding,” Downes says. “They said very little themselves. They didn’t even say that much through their trade associations.”

To be sure, tech companies did voice their displeasure with the outcome of last week’s vote. Amazon’s CTO tweeted that he was “extremely disappointed.” Sheryl Sandberg, Facebook’s chief operating officer, said the decision was “disappointing and harmful.” Microsoft’s chief legal officer tweeted that repealing net neutrality will hurt “consumers, business & the entire economy.”

Of the tech companies named in this article, only Netflix and Google provided responses to a request for comment. “We’ve actually been pretty vocal,” said Bao-Viet Nguyen, a Netflix spokesperson, pointing to pro–net-neutrality tweets sent out from the company’s account and the public comments it filed with the FCC. Nguyen added, “Although there are other companies for whom this is a bigger business issue today, we continue to support net neutrality protections so that the next Netflix has a fair shot.” And Scott Haber, a spokesperson for the Internet Association, a trade group that represents Facebook, Google, and Amazon (as well as a number of other big tech companies), said that the organization had “been incredibly active on behalf of our members” in trying to preserve net neutrality, issuing statements and publishing white papers on the subject.

Individual tech companies appear to be comfortable letting the trade group speak on their behalf—a clear departure from past years. After all, it is one thing to put out tweets and press releases, and quite another to be dogging the FCC for months about an upcoming vote. One reading of those post–FCC-vote laments from tech executives is that these companies see public-relations value in associating themselves with egalitarian digital ideals; another is that they are well aware that their employees care deeply about net neutrality as a political issue, even if it doesn’t threaten any bottom lines.

Indeed, when I asked Larry Downes how big tech firms might recalibrate their business strategies after last week’s vote, he warned me, “This is going to be very boring.” Ryan Singel, a fellow at Stanford Law School’s Center for Internet and Society and a former reporter at Wired, agrees that it’s hard to imagine the Googles and Facebooks of the world doing things differently after net neutrality’s repeal. “These guys can afford to pay for fast lanes”—the priority treatment that ISPs will soon be permitted to charge for—“they can afford to pay access fees, they have the clout to make sure that when they do pay for those, that they get a better rate than someone else,” Singel says. He remembers when, roughly a decade ago, Google strongly advocated for having net-neutrality–like rules govern the FCC’s auction of a newly available segment of the radio spectrum. This time around, he says, “Google was nowhere near the level of fight they put up in 2008, 2009, 2010.” (For Google’s part, a company spokesperson told me that it “remain[s] committed” to net neutrality and “will work with other net neutrality supporters large and small to promote strong, enforceable protections.”)

One thing that last week’s repeal could change, though, is the market for distributing content. These two markets have each become heavily consolidated—in both cases, a small number of large companies dominate—and there’s a concern that lifting net-neutrality protections would only speed up this process. Matt Stoller, a fellow at the Open Markets Institute, an antitrust research group, says that he expects last week’s vote to “accelerate the contest for the last monopoly standing,” because it enables ISPs to push for deals that large tech and media companies are best positioned to enter into. “There will still be competition,” he added, “but it will be competition among the telecom and big tech platforms over who controls access to customers and monopoly power.”

And because the repeal of net neutrality increases the upsides of being big, Stoller says, more companies will try to get bigger, which could speed up the race for lucrative business deals at the expense of product innovation. This is the race that led AT&T (a content-distribution company) to want to buy Time Warner (a content company) and Verizon (a content-distribution company) to want to buy Yahoo and AOL (both content companies). Stoller says he expects that last week’s vote will prompt similar companies to consider such deals of their own—perhaps a tech platform would even think about buying a telecom.

When it comes to large companies gaining power, the flip-side concern is about smaller companies losing it. Net neutrality’s proponents fear, among other things, that an internet with “fast lanes” will squeeze out smaller firms that don’t have the funds or negotiating power that large tech companies can use to push back against ISPs. “It’s the smaller retailers … that are going to feel more of that pain,” says Singel, adding, “Openness is the tool of insurgents.” Indeed, it was smaller companies that were most vocal leading up to last week’s vote, which makes sense: Some of yesterday’s voluble insurgents are today’s quiet behemoths.



Toys “R” Us announced on Wednesday that it will close about 180 stores in the U.S., or about one-fifth of its domestic locations, as the company emerges from bankruptcy proceedings to restructure $5 billion in debt.

On one level, this is just the latest chapter in the never-ending saga of brick-and-mortar calamity as the retail industry focuses more on online sales. The first half of 2017 was among the worst periods for retail stores on record, and the pain isn’t nearly over. In the last four months, Sears and Kmart have announced 63 imminent store closings (after shuttering 350 locations in 2017), Gap announced plans to close 200 locations in the next three years, and Walmart announced that it would close 63 Sam’s Club stores and lay off thousands of workers.

But while Toys “R” Us has suffered from some predictable brick-and-mortar burdens, its story is a complicated one that touches on family economics, modern leisure, and private-equity mismanagement. There are the three main culprits of the sad demise of America’s erstwhile titan of toys.

1. It’s the e-retailers.

This story begins—as all modern retail stories must—with Amazon. The “everything store” sells toys now—billions of dollars of toys, in fact. Between 2015 and 2017, Amazon toy sales grew 24 percent, to $4 billion. Toys “R” Us, whose revenue declined in those years by a similar sum, simply doesn’t have the same facility with digital shoppers. Last June, the company’s CEO criticized the store’s own website, including its kludgy baby-gift registry tool, acknowledging that the store had simply fallen behind contemporary shopping habits.

Failing to build an online presence is bad for any retailer, but it’s particularly deleterious for one whose core demographic includes parents short on time and cash. As my colleague Rebecca Rosen wrote last year, most households don’t have a stay-at-home parent anymore, which makes shopping excursions a luxury many families cannot afford. So more moms and dads are skipping the car trips and buying toys from a website they can trust.

2. It’s the debt, too.

It’s a mistake to consider Toys “R” Us nothing more than Sears, but for kids. Yes, the store was clearly hurt by the rise of Amazon and other large retailers; Walmart actually overtook it as the nation’s largest toy retailer all the way back in 1998.

But its collapse has been especially acute, due to terrible mismanagement by private-equity firms. After Toys “R” Us was taken private by KKR, Bain, and Vornado in 2005, it took on a lot of debt, leaving the company with repayments that have crippled it in a period of declining sales. Toys “R” Us has spent more than $250 million annually to pay back $5 billion in long-term debt. These repayments became unsustainable once revenue started to decline consistently, as it has each year since 2012. That left one option: for the company to declare bankruptcy and renegotiate the terms of its debt.

3. Blame the kids and their screens.

It would be satisfying to exclusively blame private-equity sharks and retail conglomerates for the fall of Toys “R” Us. But there’s another group that deserves consideration as a culprit: Kids.

Today’s teenagers and children have been shaped by smartphones, social-media apps, and living-room bingeing, as the psychologist Jean Twenge wrote in The Atlantic last year. This has coincided with a sharp rise in teen depression and suicide. Less gravely, it’s also depleted the marketplace for hardware toys. In the last year, Lego, Mattel, and Hasbro have all reported declining sales for key brands (like American Girl or Star Wars merchandise). Maybe tactile trinkets have simply lost their luster among kids.

Or maybe kids don’t even know which toys are out there. Last year, The Wall Street Journal reported that with Millennials watching far less cable television than they used to, young parents and their children simply aren’t seeing the commercials that toy makers rely on to market new products. As a result, much of Toys “R” Us’s merchandise is doubly cursed—kids can’t play with it on their screens, and parents won’t find out about it on their screens.

While bankruptcy might seem like corporate death, the truth is that Toys “R” Us is far from defunct. With $11.5 billion in 2017 sales, its toy business is still more than twice as big as Amazon’s. But in the last decade, it has faced a brutal set of economic and technological forces that has left it heavy in debt and light in new customers. Along with every other struggling brick-and-mortar company today, the scariest question is this: If Toys “R” Us can’t cut it with 4 percent unemployment nine years into a recovery, what happens when the recession comes?



Why has inequality increased so much over the past 40 years? Common answers to that question cite changes in trade, technology, globalization, and education. Cheap imports from low-wage countries, in particular China, sapped domestic manufacturing. Companies offshored jobs, fired people, and hired robots. Demand for skilled workers far outstripped the demand for unskilled workers, depressing earnings for those without an advanced degree.

In their excellent, slim new book, Brink Lindsey and Steven Teles—the former the director of the Open Society Project at the libertarian think tank the Niskanen Center, the latter a political scientist at Johns Hopkins—point to an important and overlooked additional cause. In The Captured Economy: How the Powerful Become Richer, Slow Down Growth, and Increase Inequality, they argue that it is not just that technology and offshoring have wiped away middle-income jobs, but that high-income individuals and big-profit businesses have rewritten the rules of the economy, “capturing” the regulatory system and using it to squeeze out their competition. The result is both  greater inequality, and a more sclerotic economy.

The “capture” of the economy shows up in preferential regulations enacted at the local, state, and federal level, Lindsey and Teles argue. Together, rules made to benefit not the public good, but big firms or rich people, have led to money and wealth being distributed from the poor to the rich and the small to the big. The result of all this “capture,” they write, is an overpaid white-collar professional class, a bloated financial sector, a lack of affordable housing, the growth of fewer and bigger companies, and a dearth of new startups.

The book offers four case studies, looking at land-use restrictions, professional-licensing requirements, intellectual-property law, and the regulation of big finance. Local zoning rules stifle the construction of affordable housing and pad the pockets of existing homeowners. Regulations prevent well-trained foreign doctors and nurses from meeting the country’s extraordinary demand for health care, and plump the salaries of existing workers. Patent protection, some of which can more fairly be described as patent trolling, raises new companies’ cost of doing business, with questionable and perhaps even nonexistent benefits for innovation overall. And federal subsidies for those taking on debt, along with the concomitant growth of Wall Street, have helped to blow bubbles that have caused widespread devastation when they pop.

Of course, wealthy families and big firms often make convincing arguments for such regulations as benefiting not just them but the public more generally. Homeowners argue that big, new apartment buildings would destroy the historic character of their neighborhoods. Companies argue that strong patents are necessary to protect their incentive to invest in risky new ventures. Trade groups argue that strict licensing requirements are necessary to keep consumers safe. All of these things might be true in some cases, of course. But taken together and projected economy-wide, regressive regulations kill new businesses and exacerbate wealth disparities. Removing land-use restrictions alone would boost American GDP by an estimated 9.5 percent, according to the economists Chang-Tai Hsieh and Enrico Moretti, translating to roughly $1.7 trillion more output as of this year—equivalent to the economic activity of the state of Texas.  

Recognizing regressive regulation as part of the reason the economy has slowed and inequality has increased also suggests reforming regulation as a way to bolster competitiveness and aid the middle class—and a potentially bipartisan one, too. Indeed, both Bernie Sanders and Donald Trump agree the system is rigged. “It’s not just the political system that’s rigged, it’s the whole economy,” President Trump told voters while campaigning last year. “It’s rigged by big donors who want to keep down wages. It’s rigged by big businesses who want to leave our country, fire our workers, and sell their products back into the U.S. with absolutely no consequences for them. It’s rigged by bureaucrats who are trapping kids in failing schools.” Similarly, Sanders argued during his campaign: “For the past 40 years, Wall Street and the billionaire class has rigged the rules to redistribute wealth and income to the wealthiest and most powerful people,” adding, “We must send a message to the billionaire class: You can’t have it all.” But the two and the two major parties could not be more diametrically opposed when it comes to how to deal that rigging or capture. Trump and the Republicans have been slashing regulations and pushing a tax plan that would bolster corporate profits, arguing against evidence that the benefits would trickle down to ordinary workers. Sanders has promoted a series of universal-benefit programs, to be paid for with hefty levies on millionaires and billionaires.  

Lindsey and Teles, a libertarian and a liberal, respectively, suggest a set of “liberaltarian” solutions. They argue for restructuring policy processes in the legislature, the courts, and the executive branch—and at the federal, state, and local levels—to promote competition, reduce rent-seeking, and thus help new businesses and the middle class. “There is no route to a competitive economy except through finding a way to a more deliberative politics,” they write. “Only when both sides to an economic question are represented in the political sphere, and when the side of those who pay the costs of regressive regulation can force a dispute to the political surface, is true deliberation on the merits possible.”

Of course, that will not be an easy thing to do. The rich and powerful are, it goes without saying, rich and powerful. Plus, reforming regulations requires working in every jurisdiction, and at all levels of government. “The sheer number of licensing and land-use restrictions in place over thousands of jurisdictions nationwide is more than even a well-resourced anti-rent organizational network could effectively challenge directly,” they write. “These restrictions are so pervasive and deeply ingrained that the political branches may never be able to root them out.” Still, their book suggests that regulatory reform is an overlooked and necessary, if not sufficient, answer to the country’s economic challenges—and one that both sides of the aisle might some day come to agree on.



On Monday, Amazon reportedly began a series of rare layoffs at its headquarters in Seattle, cutting several hundred corporate employees. But this week, something quite different is happening at the company’s warehouses and customer-service centers across the country: Amazon will politely ask its “associates”—full-time and part-time hourly employees—if they’d prefer to quit. And if they do, Amazon will pay them as much as $5,000 for walking out the door.

Officially called “The Offer,” this proposition is, according to Amazon, a way to encourage unhappy employees to move on. “We believe staying somewhere you don’t want to be isn’t healthy for our employees or for the company,” Ashley Robinson, an Amazon spokesperson, wrote to me in an email. The amount full-time employees get offered ranges from $2,000 to $5,000, and depends on how long they have been at the company; if they take the money, they agree to never work for Amazon again. (The idea for all this originated at Zappos, the online shoe retailer that Amazon bought in 2009.)

Considering that Amazon reportedly already has high turnover—it is a famously efficient company that asks a lot of its workers—it may seem surprising that it would incentivize workers to walk away. Many employees at Amazon’s warehouses, as I’ve written before, say that they are constantly pressured to work harder and faster (and get fired if they don’t), and that the jobs are physically and psychologically grueling.

When I asked Amazon about these workers’ complaints, the company said that the top priority of its fulfillment centers is the success and well-being of its employees. No worker is ever dismissed without good reason, Robinson told me. And as the company grows, she added, it is “strongly in our interests” to retain existing employees. But that just makes The Offer seem more puzzling. If Amazon wants to retain employees, why would it pay them to leave?

With The Offer, Amazon seems to be making the calculation that weeding out a single unengaged worker is worth as much as multiple thousands of dollars. But there might be other, less obvious effects of providing The Offer that serve to benefit Amazon, according to some behavioral economists. The Offer might in fact be a way to make employees stay longer than they otherwise might.

The reasoning goes like this: Employees resist an initial temptation—to quit Amazon and walk out with cash—and by resisting it, they may actually feel more committed to their jobs, said Ian Ayres, a professor at Yale Law School who wrote about the concept of The Offer in his book Carrots and Sticks: Unlock the Power of Incentives to Get Things Done. Amazon employees who evaluate The Offer and then turn it down have decided they like the company enough to stay a little longer. They then want their future behavior to match that feeling, Ayres said.

When I talked to Katherine Milkman, a professor at the Wharton School at the University of Pennsylvania, she brought up a similar idea, from the realm of social psychology. She talked about the mental pressure humans feel to resolve cognitive dissonance—if people have two conflicting beliefs, they’ll try to rationalize one to make it fit with the other. In this case, workers may dislike their jobs at Amazon, but if they turn down The Offer, it means they passed on a chance to quit. It’s likely that they’ll then try to convince themselves that they actually like working at Amazon, Milkman said. To pick a more extreme example of this phenomenon, when people join a cult that says the world is going to end on a certain date and then it doesn't end, they tend to end up believing more strongly in the cult, because they can’t put up with the cognitive dissonance between what they believe and what actually happened.

Milkman also brought up “escalation of commitment,” another concept studied by behavioral economists. The idea is that when people put a lot of money or effort into something and it appears to be going badly—perhaps they bought a stock and the share price is tanking—they often double down on their commitment. “They say, ‘I want to see this turn around—I don’t want it to turn out badly,’” Milkman said. When employees see that they’ve lost $5,000 by not taking The Offer, they might mentally recommit to the company, trying to do better at their jobs and enjoy them more.

Amazon is just one of dozens of companies (many of them tech firms) that are looking for ways to use behavioral-economics findings to try to make their companies run more efficiently, and, in some cases, make their employees happier and healthier. Google, for instance, has conducted a number of experiments in its cafeterias to nudge employees toward eating vegetables or cutting down on the number of M&M’s they consume. (Maya Shankar, who had founded the Social and Behavioral Sciences Team in the Obama White House, now runs a behavioral-science division at Google.) Uber uses digital nudges in its app to try and motivate its drivers to pick up more fares and work longer hours. “I think companies are recognizing that there’s a lot to be learned from research about how to build smart incentive systems and use behavioral science to design tools that aren’t just cash,” said Milkman.

An important caveat about The Offer is that—regardless of how it may register in an employee’s mind—the people who do take it don’t actually walk away with $5,000. A big chunk of the payment is taxed, and employees who might have received benefits (in the form of 401(k) contributions or shares of stock) if they stayed to a certain date might not be around long enough for those benefits to vest. John Burgett, a current Amazon employee who has worked various positions in a warehouse in Indiana since 2014 and blogs about his experiences at Amazon Emancipatory, estimated that if he took The Offer in early 2017, he would have received a $3,000 payout. But he says he also would have lost a portion of his 401(k), which would not vest until he had been with the company for three continuous years, and also would have lost four shares of Amazon stock that would not vest until the summer of 2017. He also figured the company can pay a new employee less than it pays him, since he has received a few raises over the years. (At the time of his calculations, he made $13 an hour.) “I’ve considered it, but I’ve always said it’s a bad deal,” he told me.

Behavioral economics aside, part of Amazon’s reasoning for issuing The Offer is probably straightforward: It wants to prod unhappy employees to leave. And each year, some people—“a small percentage,” according to Amazon—do take the company up on it. They include Jim Perota, who is now 60, and worked for Amazon’s distribution center in Chattanooga for three years. He says he hated the job. He says he lost 30 pounds working at Amazon because he was on his feet so much, picking items off shelves and putting them in bins, and also packing goods into boxes. His breaks were only 15 minutes, but it would take 10 minutes to get to the break room, so he’d sit on stairs, waiting for the work to begin again, he told me. Perota had worked for the postal service, as a disc jockey, and for the U.S. Census, but working for Amazon “was the most brutal, and it took the biggest toll on my body,” he said. But he couldn’t quit, because he needed the health insurance, he said.

But then Obamacare came to Tennessee. In 2014, Amazon presented The Offer to employees at Perota’s warehouse on a Tuesday in March. On Thursday of that week, Perota signed up for Obamacare. On Friday, he took The Offer and quit his job. It was one of the best decisions he ever made, he said. “I felt pretty liberated when I walked out those doors for the last time,” he said. He now works as a nighttime security guard.

In the end, The Offer wasn’t a financial boon for Perota. He received $3,000 from the company, but says he more or less broke even because the money was taxed heavily, and he lost the employer contributions in his 401(k), because he had not been with the company long enough to walk away with it. But that didn’t matter, he told me. What mattered was that he got out.



Larry Cagle is angry. At 54 years of age, he makes $34,500 a year teaching critical-reading skills to public high-school students in Tulsa, Oklahoma. “I do construction and lawn maintenance in the summer” to make ends meet, he said. “I moved here from Florida five years ago, and in Florida I made $25,000 a year more.”

He talked about the number of public-school teachers he knew working second jobs on nights and weekends, flipping burgers or hauling luggage at the airport. Teachers digging into their own pockets to pay for students’ basic needs and classroom supplies. Teachers living in cars, taking out loans, panhandling for more money, struggling to pay their own bills. “My school is one of the highest-performing schools in the state,” he said, estimating that two in three of the teachers he had worked with in the past half decade had left for other jobs or retired. “These are primary positions, not ancillary positions. This is math, science, foreign language, arts, history. We had two teachers who just walked out [and quit] recently.”

The successful two-week-long strike of public-school workers in West Virginia—as well as the imminent strike of teachers in Oklahoma, led by grassroots activists, including Cagle—has thrown into relief the financial difficulties that thousands of education professionals face. Yet those difficulties are not unique to those two states. Despite the perception that educator jobs are unionized, pay decently well, and are guaranteed-tenure, hundreds of thousands of American teachers have seen their wages and benefits erode in recent years, more so than for many other types of workers.

Teachers’ fortunes are emblematic of public workers’ more generally since the Great Recession. Because of the stable nature of government employment, such employees were largely spared the worst of the layoffs and wage cuts that afflicted private businesses. That said, these jobs have not rebounded in the same way that many private-sector ones have, either, with public finances still squeezed, public workforces still smaller than their pre-recession peak, and local government officials still hesitant to make critical investments in their workforces and infrastructure.

Granted, by many measures and in many places, teaching remains a solidly middle-class profession. Government data shows that the average teacher earns about $59,000 a year, with many school districts offering good benefits and generous retirement plans. Andrew Biggs, an economist at the conservative American Enterprise Institute, pushed against the notion that teachers are broadly underpaid. “It’s a good and a very family-friendly job,” he told me, citing its reasonable hours and long summer break. “Why should you pay them more? They’re on strike—that’s a reason to pay them more.”

Yet in some states, teachers are earning close to poverty wages, as the West Virginia strike and the threatened Oklahoma strike have demonstrated. Indeed, those two states offer compensation roughly a third lower than the national average for all public teachers, numbers that do not look much better adjusting for the cost of living. Moreover, there is data demonstrating that the teacher pay gap—meaning what public-school teachers earn compared with comparably qualified individuals in the private sector—is large and growing. The left-of-center Economic Policy Institute (EPI) has found that teachers’ average weekly wages actually fell $30 per week between 1996 and 2015 after adjusting for inflation, whereas they increased measurably among all college graduates. EPI also has estimated that public-school teachers were earning about 2 percent less than comparably qualified private-sector workers in 1994, a disparity measure that grew to 17 percent by 2015.

“Teachers actually gained ground in the depths of the recession, as their pay didn’t fall, whereas pay for other workers did,” Larry Mishel, an economist at EPI, told me. “But when there was a recovery, they didn’t get much recovery.” Indeed, as state and local finances rebounded, many red and purple states cut their income taxes, with property taxes remaining depressed due to the subprime-mortgage crisis. The result: sharp declines in public-school funding per student, reduced salary increases through the recovery, and widespread teacher shortages. Teacher enrollments dropped from 691,000 in 2009 to just 451,000 a year in 2014 as attrition—meaning the share of educators dropping out of the profession—hit 8 percent a year.* Nationwide, the number of teachers and other school workers has fallen by 135,000 since 2008, a recent analysis of government data by the Center for Budget and Policy Priorities, a left-of-center think tank, found. Yet as that number declined, the number of students rose by 1.4 million.

This squeeze on school funding has made teaching a less attractive or sustainable job in many cases. “Highly publicized teacher layoffs during the budget downturn left a mark on the public psyche, including that of individuals who might have been considering a teaching career,” argued one report by the Learning Policy Institute, a nonpartisan Palo Alto–based think tank. This post-recession combination of fewer teachers and less funding has also, the report noted, predictably led to larger class sizes and less in the way of learning materials.

Plus, teachers in a number of states have far fewer union protections than they had in previous years. Indeed, the share of teachers in a union has fallen to less than half, driven in part by older, unionized teachers retiring, the rise of certain districts’ reliance on charters and other private education options, and legal changes that have curtailed the ability of unions to bargain on behalf of workers. In some states, like Wisconsin, that decline in unionization has led straightforwardly to declines in compensation. “How much further can you fall behind? These teachers have had it and are standing up and hoping to educate the public on what’s been happening on pay, benefits, and retirement,” said Sylvia Allegretto, a labor economist at the University of California, Berkeley. “There’s been erosion in all these compensation factors over time, especially in states without the architecture for unionization.”

Cagle told me that he felt like some in Oklahoma were deaf to educators’ concerns because they wanted public schools to struggle. “This state absolutely would like to do away with public school systems and move to private schools, to voucher systems that let parents to take their kids where they want to go,” he told me. “They’re moving that agenda so aggressively that they’re looking for public schools to fail.” (Oklahoma does have a voucher movement, but also a lauded universal public preschool program, meaning its public-educational ideals are not purely conservative.)

In Oklahoma, educators are asking for a $6,000-a-year raise, to be granted by April 1. If not, teachers plan to walk out—and are encouraging and advising their peers in Arizona and Kentucky to do the same. With the economy finally near full employment and lower-wage workers finally getting a raise, it is time for teachers to get one too, they argue. And educators across the country might be listening.

*This article initially misstated the year that teacher enrollments dropped to 451,000. We regret the error.



After the most recent high-school massacre in Parkland, Florida, left 17 students and teachers dead, the National Rifle Association (NRA), the nonprofit gun-rights advocacy group, was rebuked by a surprising group of liberal activists: American corporations. Pressured by Parkland high-school students and others to boycott the NRA, more than 20 companies have cut ties with the pro-gun group.

The NRA exodus includes major airlines like United, six rental-car firms including Hertz and Avis Budget Group, and MetLife, the insurance giant. These companies are not rescinding NRA donations, nor are they refusing service to NRA members. Rather, they’re ending discount programs, which companies routinely offer to groups and companies, like the NRA or the AARP. For example, United Airlines offered discounts on flights to the NRA annual meeting, and MetLife auto insurance offered a $50 benefit to members for each year of claim-free driving.

It would be easy to write off this moment by saying these companies are simply reacting to an online mob, or following each other like lemmings. But the fact that companies, rather than Congress or the courts, are shifting in response to political activism in the United States says something profound—about American tribalism, the demise of political cooperation, and the rise of a sort of liberal corporatocracy.

Why have the Parkland shootings forced corporate action in a way that previous school shootings could not? To put it another way: United and Delta both serve more than 100 million domestic passengers each year, while the NRA only has a few million members. So, why has it taken so long for these companies to distance themselves from one of America’s most controversial associations, despite 30,000 annual firearms deaths and so many mass shootings?

In this case, there has been a perfect storm of articulate student outrage and savvy online activism, merging with a rising tide of resentment against Trump and Trump-affiliated organizations. The students of Marjory Stoneman Douglas High School in Parkland, Florida, have shown poise and passion before the camera—and laconic brilliance on Twitter—that has galvanized the gun-control movement. On social media, they have joined other activists in naming and shaming companies (“Hey @LifeLock why do you support the NRA? #NeverForget”) and even encouraging people to contact NRA-sponsoring firms. One message, with more than 33,000 retweets, sent people to an Amazon webpage where they could submit a prewritten request for the company to stop hosting the NRA’s digital-video channel, NRATV. As more companies canceled their NRA affiliations, it put additional pressure on other companies that had initially resisted doing the same. Within a 12-hour period, Delta Airlines went from defending its relationship with the NRA as “routine” to requesting that the association “remove our information from their website.”

This avalanche of companies abandoning the NRA is just the latest chapter in the gradual politicization of every square inch of the public sphere, which has compelled traditionally nonpartisan companies to take one partisan stand after another. One year ago, in the fallout over the president’s proposed travel ban, Uber’s CEO, Travis Kalanick, left the White House advisory council. Four months later, the tech entrepreneur Elon Musk and Disney’s CEO, Bob Iger, left the same forum after the president withdrew from the Paris climate agreement. When Trump refused to explicitly condemn the far-right protesters in Charlottesville, more business leaders, including Merck’s CEO, Kenneth Frazier, exited en masse from his manufacturing council.

Uber is not an immigration firm. Disney is not a climate-advocacy organization. Merck is not a civil-rights group. But under Trump, they have completed their development into activists on the issues of migration, carbon emissions, and white racism anyway. Trump’s language often forces companies to take sides in political debates, and his unpopularity makes it safe—even necessary—to side against him.

Many business leaders are getting political because they have determined that, in this environment, the noisiest position is often to remain silent in the face of national condemnation. But in politics, responding to one group of consumers invariably means angering another. Several conservative writers tweeted that they would boycott United, Hertz, and other companies that eliminated their discount policies with the NRA. “Corporations boycotting NRA should be boycotted,” the conservative commentator Mark R. Levin wrote. The choice for companies is simple and stark: Suffer the slings and arrows of liberal activism, or endure the rage and resentment of spurned conservatives. In today’s culture wars, for-profits are the new nonprofits.

One important question raised by all this is if there is a deeper force at work. Have America’s corporations shifted to the left, even as national government has moved toward the Republican Party? Or are companies just more sensitive to protests than a divided government is?

In many cases, America’s corporate community has become a quiet defender of socially liberal causes. Nearly 400 companies filed an amicus brief in 2015 urging the Supreme Court to legalize same-sex marriage, including Amazon, Aetna, Apple, American Airlines, American Express, and AT&T (and those are just the ones starting with the first letter of the alphabet). Hundreds of executives, many from tech companies, signed a 2017 letter urging the president to protect immigrants brought to the U.S. as children by saving the Deferred Action for Childhood Arrivals (DACA) program. When North Carolina passed a law against transgender-friendly bathrooms, the NCAA announced in 2016 that it would pull its college-basketball tournament from the state (and other companies withdrew their business, too).

It would be strange to call these corporations “liberal.” By and large, they support the GOP’s economic policies, which in just the last year have eased regulations and slashed corporate taxes by several trillion dollars. But on social issues, national and multinational companies have moved left of the GOP, even as many Republican figures (particularly the president) have found it useful, or at least tantalizing, to play up cultural flash points, like trans rights and undocumented labor. This has created a bizarre dynamic, where many companies feel public pressure to assert their values by rebuking Republican politics, even as many of them directly benefit from the GOP’s economic platform.

But there is something else happening: Corporations are becoming more democratic than democratic governance itself. Or, at least, they have proven to be far more responsive to political outcries and scandals than political parties. In the #MeToo movement, many corporate boards quickly dismissed their credibly accused executives, while Republicans (and some Democrats) wavered over how to punish accused officials and candidates, like Representative Patrick Meehan, the Alabama Senate contender Roy Moore, and, well, the president of the United States. In the gun debate, too, many companies moved to distance themselves from the NRA before the state of Florida or the federal government could propose or act on new legislation to limit gun violence.

National government in an age of Republican control is mostly unresponsive to liberal protests. So, many activists are focusing their ire on the business community. A corporation is a knot of products, services, and policies, and activists have seen that any one string can be grabbed, pulled, and scrutinized, until the company agrees to cut it away.

Businesses have to respond to political crises even faster than political parties do, says William Klepper, a professor of corporate leadership at the Columbia Business School. Politics is competitive, but the competition is constrained—by time (e.g., elections only happen every two, four, or six years), by geography (e.g., the gerrymandering of districts), and by partisanship, in which every issue often boils down to “the other side is worse.” Many companies cannot rely on time, geography, or negative advertising to save them. Every week is a primary for a consumer brand; the global nature of business exposes companies to more rivals; and no company can thrive by making nothing and investing exclusively in hostile marketing. “Politicians assume they can wait out the outrage, but national companies have to respond to the immediacy of demand,” Klepper told me.

Social media, and its capacity to foment outrage, has helped create this dynamic, contributing to both the virulence of partisanship and the concurrent rise of the activist corporation. Angry tweets and Facebook memes help political groups rally around anger and perceived villainy; but also, they create unavoidable choices for multinational companies that have to respond to political crises by picking a side.

American democracy is not a free market. It is, at best, a two-party duopoly, in which vilification of the opposition often passes for a party platform. As a result, many liberal activists are asking corporations to express the values that they cannot impress upon a Republican-dominated government. Corporations are no longer bystanders in the culture wars. They are on the front lines.



When the PepsiCo CEO Indra Nooyi’s younger daughter, Tara, was a child, she would call her mother’s office to ask for permission to play Nintendo. The receptionist would answer the phone and run down a list of questions Nooyi had prepared—“Have you finished your homework?” and so on. “She goes through the questions and she says, ‘Okay, you can play Nintendo half an hour,’ Nooyi recalled in a 2014 interview with The Atlantic. “[My receptionist] leaves me a message, ‘Tara called at 5, this is the sequence of questions I went through, I’ve given her permission.’” She added, a bit archly, “It’s seamless parenting.”

In that interview, Nooyi had been discussing whether women can “have it all”—successful careers, personal lives, and the rest. To outside observers, it may have seemed that she did: During her tenure at Pepsi, one of the largest and most influential food-and-beverage companies in world, the company’s revenue increased from $35 billion to $63.5 billion, as it added healthier drinks and snacks to its previous repertoire of largely sodas and junk food. Nooyi accomplished this while parenting two daughters—one of whom ended up attending Yale’s business school, Nooyi’s alma mater. Still Nooyi had concluded that “having it all” is illusory, though there are nonetheless some “coping mechanisms” involving, in part, a more creative approach to managing family and work.

When Nooyi announced Monday morning, at the age of 62, that she will step down from Pepsi this fall after a 12-year-run as its chief executive, she became the latest of several female leaders to leave companies on the S&P 500, including Campbell Soup’s Denise Morrison, Hewlett-Packard’s Meg Whitman, and Mondelez International’s Irene Rosenfeld. Nooyi will be replaced by a male Pepsi executive named Ramon Laguarta, at which point the S&P 500 will include 24 female CEOs (assuming no other changes in their ranks), according to the nonprofit Catalyst, which advocates for inclusive workplaces for women. The tally will return to 25 early next year, when Kathy Warden becomes CEO of the aerospace and defense company Northrop Grumman. The percentage of female CEOs has been on an upward trend for many years, but the progress has been uncomfortably slow.

On an episode of the podcast Freakonomics earlier this year, the host, Stephen J. Dubner, asked Nooyi whether she believes there are so few female CEOs because of a gendered cultural understanding of how a leader should behave. Nooyi told him, “I don’t think that’s the issue.” Instead, she said, there’s a pipeline problem. There are plenty of women in entry-level positions, but the period when people typically begin to move up the career ladder—their thirties and forties—coincides with the child-rearing years (not to mention the years in which one’s parents are aging and more likely to need extra care).

The imperative to work long, hard hours in order to move ahead competes with responsibilities at home; and something has to give. “How are you going to attract women to the workforce, where we need them, but allow them to balance having a family and taking care of aging parents … and still allow them to contribute productively to the workforce?” she asked. “I don’t have an answer to that. It’s got to be a concerted effort on the part of governments, societies, families, companies—all of us coming together.”

Nooyi’s assessment is backed by evidence. Women make up 44 percent of employees of S&P 500 companies; they also make up 37 percent of first-level and mid-level officials and managers, and 27 percent of executive and senior-level officials and managers. A similar pattern exists in other fields—law, medicine, politics. “Women have gotten into entry-level positions very successfully, and then they get to middle management, and things stall out,” Ilene Lang, the interim CEO of Catalyst, told me.

Research suggests that workplace policies that reward time spent at the office (and penalize time away), in a culture in which women often expected to be primary caregivers at home, have played a role; so have more overt forms of bias, such as gendered assumptions about what leaders should look like. On top of that, the relatively few women who make it to the executive suite aren’t often in positions in which they might make decisions directly related to how the company makes, or loses, money—the kinds of roles that lead to 90 percent of CEO appointments; instead, they’re in jobs such as chief financial officer that don’t provide the operational experience desired in a CEO.

Silicon Valley, with all its millennial-led startups going public, would seem to offer something of a workaround to all this, and yet, according to Catalyst, a severe underrepresentation of women among venture capitalists and the CEOs they back, combined with bias against female leaders by potential IPO investors, has meant that virtually all of the recent Silicon Valley public offerings have been led by male CEOs.



It appears that while research on what keeps women from becoming CEOs has gotten more sophisticated, attitudes have not fully caught up. Women, on average, still spend far more time on childcare and housework than men. (Single motherhood is also far more common than single fatherhood.) American corporate culture continues to value—even fetishize—long hours at the office. People in management positions, followed by lawyers, are likeliest to spend more than 40 hours a week working. One of the habits for which Indra Nooyi is most admired is that she wakes up at four o’clock in the morning and works until midnight.

Two years ago, the Rockefeller Campaign launched a campaign called 100 X 25, aimed at getting the Fortune 500 to include 100 women, up from 21 at the time, by 2025. Later that year, a small number of female executives spearheaded the creation of Paradigm for Parity, a pledge, signed by the CEOs of more than two dozen prominent companies, to increase the proportion of women in senior “operating roles”—the kind that lead to CEO positions—so that they fill half of them by 2030. The pledge’s backers created a five-point plan to get there, including basing employee’s career progress on their results, rather than their presence at the office. Both group’s goals are ambitious. But Nooyi’s departure is the latest reminder that, based on current progress, they seem unlikely to be met.



Rex Tillerson is hardly the first person to be targeted in a tweet from Donald Trump, but on Tuesday morning, he became the first Cabinet official to be fired by one. It was an ignominious end to Tillerson’s 13-month stint as secretary of state, a tenure that would have been undistinguished if it weren’t so entirely destructive.

Compared with expectations for other members of Trump’s Cabinet, the disastrous results of Tillerson’s time in office are somewhat surprising. Unlike the EPA’s Scott Pruitt, Tillerson did not have obvious antipathy for the department he headed; unlike HUD’s Ben Carson, he had professional experience that was relevant to the job; and unlike Education’s Betsy DeVos, his confirmation hearing wasn't a disaster.

The fact that Tillerson publicly clashed with Trump over everything from North Korea policy to relative IQ did nothing to make his job any easier, but his sorry legacy as secretary of state was sealed by a complete misunderstanding of the job before him. Rather than the nation’s top diplomat and an embodiment abroad of American values, Tillerson appeared to regard his mandate as little more than an exercise in cost-cutting and corporate reorganization. His time at the State Department seemed to test beliefs that are popular among many private sector professionals: skills that business executives bring to Washington can outweigh government experience, and almost every problem can be reduced to a matter of efficiency. That Tillerson should succumb to these beliefs is not altogether surprising given the benefits and blind spots of his experience in business.

Just a few weeks before he became the nation’s highest diplomat, Tillerson was CEO of ExxonMobil, one of the largest companies on Earth. It was a position he had held for more than a decade, one that required him to supervise a highly complex organization with nearly 70,000 employees and an annual budget that routinely topped $40 billion, all while successfully conducting business the world over. In other words, by the time he accepted the offer to join the Trump Administration, the Fortune 10 CEO had already enjoyed a long and distinguished career in the private sector, a track record that had endowed him with the experience, expertise, and administrative excellence that one could assume would make him a highly capable, even accomplished, secretary of state.

Tillerson certainly seemed to think so, notwithstanding the fact that he hadn’t spent any time in diplomacy or, for that matter, government affairs. He had barely introduced himself to the career civil servants at Foggy Bottom before he concluded that the agency they staffed was a portrait of bureaucratic mismanagement. “We had very long-standing disciplined processes and decision-making, I mean highly structured, that allows you to accomplish a lot,” he told reporters in July of his time at ExxonMobil. “Those are not the characteristics of the United States government.”

Initially, career diplomats were not unreceptive to the idea that a successful CEO might draw on his experience in the private sector to help renovate the bureaucracy at State. “To a person, we felt the department was in need of reform,” Linda Thomas-Greenfield, a 35-year veteran diplomat and former assistant secretary of state for African affairs, told Bloomberg in the fall. They withdrew their welcome, however, when, in Thomas-Greenfield’s words, they came to “understand” that the goal of the new secretary of state “was not to improve the organization but to deconstruct it.”

Or “redesign” it, the term Tillerson favored and one he used interchangeably as a noun and verb. “We’re going to redesign,” he told State Department staff during a town-hall meeting in December. “We’re not going to reorg. Reorg is taking boxes and pushing some of them together this way and pushing some of them together that way and then say we’re done. But what I’ve learned over 41 and a half years is when you do that, if you look behind the box, nothing’s changed about the way the work gets done. People are still dealing with the same inefficiencies; they’re still dealing with the same frustrations, complexities. You didn’t address the work. You just addressed the boxes.”

Tillerson’s delight for the eye-glazing jargon of management consulting was a hallmark of his “redesign.” In a report submitted to Congress in August, he rhapsodically outlined “an evidence-based and data-driven process to enhance policy formulation and execution, as well as optimize and realign our global footprint.” Less attention was lavished on the fact that, in his relish for optimization and realignment, Tillerson was also making a virtue of budgetary necessity. Indeed, even before he had had a chance to evaluate the institution with which he was now entrusted, Tillerson had largely acceded to the White House’s stated goal of slashing the State Department’s budget by nearly a third, this notwithstanding the objections of Republican Senators Lindsey Graham, John McCain, and Bob Corker, as well as the more than 120 retired admirals and generals who wrote a letter to Congress last February objecting to the cuts.

Tillerson’s acquiescence to the administration’s demands hardly endeared him to the career foreign-service staff, many of whom understood what Tillerson’s ambition for the State Department effectively amounted to: “No one is ever going to be as excited about the redesign as the secretary himself,” a State Department official told Vanity Fair after the town-hall meeting. “Everyone understands what that really means—it means people losing their jobs.”

A lot of people, in fact. Roughly 2,300, or 8 percent of the State Department’s total staff, is the target number for personnel cuts by the end of 2018. Tillerson got some help from the more than 300 civil servants who have already departed since the beginning of the Trump administration, many of them senior-level diplomats. One, Elizabeth Shackelford, blasted the secretary in her resignation letter when she exited in November. “I have deep respect for the career Foreign and Civil Service staff who, despite the stinging disrespect this administration has shown our profession, continue the struggle to keep our foreign policy on the positive trajectory necessary to avert global disaster in increasingly dangerous times,” she wrote. “With each passing day, however, this task grows more futile, driving the Department’s experienced and talented staff away in ever greater numbers.”

The brain drain, together with a startling delinquency in filling top spots—dozens of ambassadorships remain vacant, including those for Germany, Egypt, and South Korea, and, with Tillerson’s ouster, six of the nine top jobs at State are now empty—have been devastating for the department’s esprit de corps. “The place empties out at 4 p.m.,” a former assistant secretary of state told The New Yorker’s Dexter Filkins in the fall. “The morale is completely broken.”

In many respects, Tillerson’s efforts may be regarded as a textbook example of a familiar phenomenon of new administrations—testing, in real time, theories of how government ought to work. Sometimes chief executives are explicit in this aim—say, Barack Obama’s attempt to transcend partisan politics or Sam Brownback’s endeavor to turn Kansas into a small-government utopia—but more often than not, the success or failure in discharging the responsibilities before them provides a referendum on implicit assumptions about government.

Having interviewed Tillerson and written a profile ​​​​​of the man during his tenure as secretary of state, Filkins concluded: “As far as I could gather, Tillerson doesn’t have much of an ideology, apart from efficiency.” Fair enough, but efficiency is always a matter of the means to a certain end; it is never an end in itself. Unfortunately, the latter view is common among many business professionals, for whom greater efficiency is synonymous with greater profit, the ultimate end of their labors. The same logic doesn’t apply to government agencies, however. They can always benefit from greater efficiency, but their ultimate success is never measured by profit margins. This may seem like a simple fact, but for corporate executives, like Tillerson, who have adhered to the mantra of efficiency for decades, it can lead to a confusion of ends and means when they enter government service. Such confusion threatens their ability to discharge their duties responsibly, but it can be lethal if it is supported by two assumptions that are fairly common among conservatives: The American government is hopelessly inefficient, and resolving this problem is the key to government working for a change.

These assumptions can hamstring executives entering government by convincing them that they have nothing essential to learn from their new peers who, in turn, have everything to gain from their experience. “I have sympathy with everyone with experience in the private sector who comes into a government agency and thinks ‘this is not how things worked at my old office,’” Daniel Baer, the former United States ambassador for the Organization for Security and Co-operation in Europe in the Obama administration, noted in an email. “I have less sympathy for folks who think, after a month or two, that they can simply import their prior world and impose it on their new one.”

Of course, for one who is certain that a system is fundamentally flawed, blithe dismissal is not only tempting, it seems downright efficient. If government is little more than an unwieldy machine that smokes and sputters, why waste time on the engineers who tend it?

But even beyond the risk of degrading the State Department’s mission in a misguided attempt to improve its operations, Tillerson made the greatest mistake for any CEO:  he misallocated his time. According to Bloomberg, in the first eight months of his tenure, Tillerson traveled less than half as much as either of his predecessors in the Obama administration, preferring to hole himself up with a small coterie of subordinates in the executive suite of the Harry S. Truman Building and tinker with the elements of his “redesign.” For many observers, the choice communicated that Tillerson failed to appreciate or perhaps even fully understand the human elements of diplomacy, either as a global ambassador for American values or the leader of an essential organ of government. “When it comes to building a State Department for the next generation, I am hard pressed to name a single thing Tillerson has said or done to attract the best talent,” Derek Chollet, a former assistant secretary of defense for international-security affairs in the Obama administration, wrote in a column for Foreign Policy. “If anything, he’s driving people away.”

Given his successful tenure at ExxonMobil, this failure makes for perhaps the most surprising oversight of Tillerson’s tenure, that he seemed to forget the fact that, while the requirements of leadership and management can be usefully sorted, they remain symbiotic. Just as gross mismanagement can try the commitment of even the most dedicated team member, no amount of efficiency gains in an organization can compensate for sending a message that an employee’s work is meaningless. “People need to be brought into a vision of what is possible,” Baer wrote of Tillerson’s stewardship of the State Department in another piece for Foreign Policy. “Their good work deserves to be acknowledged, and they need to feel that the secretary of state has their backs.”

At the December town hall, sensing that his job was in peril, Tillerson tried to win some allies and make amends. “When I came to the State Department, I didn’t know any of you,” he said. “I didn’t know anything about your culture, I didn’t know anything about what motivates you, I didn’t know anything about your work, I didn’t know anything about how you get your work done.” It was a bracing admission, courageous even, but insofar as Tillerson would go on to highlight the crucial importance of having integrated the USAID and State Department global address lists—“if you’re spending 30 seconds to a minute every time you try to engage with that system, sitting there watching it, and I multiply that times 25,000 people times how many encounters a year”—in more ways than one, it seems clear he never learned his lessons.



On Sunday night, the enormous drugstore company CVS said it had agreed to buy the enormous health-insurance company Aetna for almost $70 billion. It’s a deal that, if government regulators and both companies’ shareholders give it their blessing, would be the biggest deal in the U.S. this year.

There are two main reasons CVS would benefit from acquiring a health insurer—one that’s specific to the economics of the health-care industry, and one that applies to just about any company that is trying to make money at brick-and-mortar stores in 2017.

First, if CVS does buy Aetna, it might be able to win over more business—both from individual consumers and from employers buying plans on behalf of their workers. In theory, that’s because CVS could gain a competitive edge by reducing the cost of providing care to Aetna’s customers.

How could it do this? CVS is not just drugstores. In 2006, it acquired a company called MinuteClinic, which operates walk-in clinics. CVS now has more than 1,000 of them, including in its stores and also in some Target locations. This is one of the main reasons CVS and Aetna could, together, save money: A company that sells insurance could start providing care directly, and steer customers not immediately to doctors but rather first to its own ensemble of nurses and pharmacists working at CVS locations.

An example illustrates why this could be powerful: If an Aetna customer has diabetes, it can be extremely costly (for both Aetna and the customer) for them to frequently see doctors for help managing their condition. Instead, a merged CVS-Aetna could encourage this customer to go to its walk-in clinics regularly for check-ins, potentially limiting those higher-cost doctor visits. A similarly salutary outcome could arise from having patients with other chronic conditions visit these clinics, perhaps to make sure they’re taking their medication—because when they aren’t, their conditions could worsen and they are likelier to need to see a doctor. In this way, CVS-Aetna could reduce the cost of the care it provides, perhaps prompting competitors to lower their prices in response.

The second reason CVS might see an advantage in buying Aetna is a single word that has appeared in a striking number of stories this year about any retailer that wants to keep making money: Amazon. Amazon is thought to be plotting a foray into pharmaceuticals—it reportedly has secured licenses that would allow it to sell, in 12 states, drugs, among other things. It could be the case that the company secured these licenses only to be able to sell medical devices, but analysts expect it has bigger ambitions—perhaps it will start up an online pharmacy that could ship medications. These reports have health-care companies like CVS bracing for the presence of a new, ruthless competitor that has record of completely changing entire industries. The proposed CVS-Aetna merger was not exactly unexpected—the two companies, after first partnering seven years ago, have been growing ever closer—but anticipation of Amazon’s next moves could have hastened things.

From this vantage, CVS’s pursuit of a deal is of a piece with all the other unusual things stores are doing to defend themselves from online shopping, such as installing juice bars and spas. “They’re trying to figure out how to utilize their footprint better, and by merging with an insurer, their hope clearly must be to be driving more foot traffic into their facilities and figure out a way how to be more on the front line of health-care delivery,” says Leemore Dafny, a professor of business administration at Harvard Business School.

Of course, there might be still another reason for the deal, Dafny noted. “There’s a question as to whether these two companies couldn’t figure out ways to get [the same] benefits without merging,” she told me. “Obviously, Wall Street loves mergers.” Indeed, the financial firms arranging the deal stand to earn in the neighborhood of $130 million if it goes through.

And if it does, will it save consumers money or give them better care? Because the proposed merger is between such large companies, that’s a little hard to predict. In general, consolidation in the health-care industry has primarily benefited the companies making the deals. That said, two experts I talked to said that this one could be different. Dafny said she sees more risk for CVS’s shareholders—the company could turn out to overpay for the acquisition—than for consumers. Atul Gupta, a professor at Wharton, agreed: “In the short term it will probably benefit existing CVS/Aetna customers if they start providing some innovative new services or pass through cost benefits to them,” he wrote to me in an email.

Others—granted, people who are skeptical of mergers more generally—are skeptical of this one too. Brian Feldman, of the antitrust research group Open Markets Institute, argues that mergers in the past few decades have “created a funhouse mirror situation—the drug industry’s incentives have become incredibly warped.” The market for drugs is shaped by five different types of companies: drug manufacturers, wholesalers, pharmacies, insurers, and pharmacy benefit managers (which function as middlemen between manufacturers and insurers). If the CVS-Aetna deal goes through, Feldman argues, CVS would have a foothold in every category but manufacturing, meaning that it would encounter competition from other companies less often.

As government regulators weigh whether to greenlight the CVS-Aetna deal, it’s points like these that they will mull on. One clause I included at the top of this piece—“if government regulators and both companies’ shareholders give it their blessing”—may have read as a formality, but, more so than in the past, there’s a real question of whether the Department of Justice will approve of a merged CVS-Aetna.

Broadly speaking, there are two types of mergers: horizontal and vertical. A horizontal merger is between rivals, and is the type that tends to make regulators worried that companies benefit, via decreased competition, at the expense of consumers. A vertical merger is between companies that do different things in the same industry. The case that these mergers hurt consumers is not always as straightforward. Consider this example: If one company that makes T-shirts bought the rest (a horizontal merger), it could dictate the price of T-shirts. But if a department store bought one T-shirt maker (a vertical merger), it wouldn’t have so much sway over the market.

Antitrust regulators have tended to be more permissive of deals like the latter than deals like the former. Lately, though, the DOJ’s stance on vertical mergers—which is what the CVS-Aetna deal represents—appears to have changed, as my colleague Derek Thompson has written. In 2011, the Obama administration approved of a merger between NBCUniversal (a media company) and Comcast (a media-distribution company). But last month, the DOJ said it would sue to block a very similar deal, between Time Warner (a media company) and AT&T (a media-distribution company).

That seemed unusual under an administration that is outspokenly opposed to government regulation. What changed? Makan Delrahim, DOJ’s head of antitrust, explained his thinking in a speech last month. In the case of the Comcast-NBCUniversal merger, the government gave a thumbs-up, but only a conditional one: Regulators have been keeping close tabs on the company to make sure it hasn’t been engaging in any anticompetitive tactics. Delrahim said this isn’t how it should be: If a merged company is potentially anticompetitive, it just shouldn’t be approved in the first place, so the government doesn’t have to keep watch.

CVS, Aetna, and their shareholders—as well as those bankers who engineered the merger—will be eager to know if Delrahim feels the same about this deal. Another company will too: If CVS’s deal goes unchallenged, AT&T will probably want a good reason why its vertical merger did not.



The rising wealth of the top tier of earners seems to be inaugurating a new age of charitable giving. More than 150 billionaires from around the world have now signed Bill and Melinda Gates’ Giving Pledge, promising to donate at least half of their fortunes to charity. Others give money to hospitals, parks, or schools, renaming them in the process; in New York City, Lincoln Center’s Avery Fisher Hall is now known as David Geffen Hall, while the historic 42nd Street library is called the Steven A. Schwarzman Building.

Such grand philanthropic donations are visible and public-facing, but they distract from a broader pattern in charitable giving: As a group, the wealthy do donate more money overall, but as a proportion of earnings, many of them give less than those with far less wealth. The Philanthropy Roundtable, an organization of philanthropic groups, has found that while households with annual earnings of less than $50,000 were less likely to donate any money to charity than those earning more than that, if they did donate, they gave a greater percentage of their income than those wealthier than them. A survey by The Chronicle of Philanthropy released in 2014 reached a similar finding: Those earning $200,000 or more per year reduced their giving during the Great Recession and its aftermath by 4.6 percent, while those bringing home less than $100,000 upped their donations by very nearly as much—4.5 percent, to be specific.

In other words, many wealthy people can afford to give away much more money than they do. Why don’t they? When I spoke with David Callahan, the founder and editor of Inside Philanthropy and the author of The Givers, a recently published book on big-money giving, he named several reasons. He said that many wealthy people are too busy to research charities, and can find their money tied up in their businesses. He also suggested it’s hard to part with money. “I think there is a sort of visceral desire for people not to see their bank account go down,” he told me.

Those reasons may well explain some of the gulf in giving, but one limitation is that some of them apply just as much to the middle class as to the 1 percent. Perhaps there is another way to think about this: Why would it be expected that society’s richest give money at all? After all, wealth doesn’t bestow unique insight, nor is it proof of empathy. Instead, there’s a body of psychological and behavioral-economics research suggesting that wealthy people are generally less caring, generous, and aware of how others think, feel, and live. Whether this is the case because money corrupts or because a certain type of person tends to want to accumulate it, this finding could at least partly explain why the well-off don’t give more than they do.

In a study published last year in the journal Psychological Science, for instance, Pia Dietze and Eric D. Knowles of New York University gave each of their subjects a pair of Google Glass and asked them to take a walk on a busy street. Using the technology to track people’s eye movements, the researchers discovered that their upper-income subjects spent significantly less time looking at other people in their field of vision. In another study, from 2010, researchers had their participants compare themselves with people either lower or higher on the income stratum. The men and women participating in the experiments picked up on emotional cues better when they looked to someone who earned more than they did, but not less. In other words, they read the situation better when they believed their status to be lower than others. And when they thought of themselves as higher-income, the ability dissipated.

The best-known study in this branch of research, titled “Higher Social Class Predicts Increased Unethical Behavior,” was published in 2012. It found that the higher a subject’s self-described social rank, the more candy they took from a jar labeled as being for children. In another experiment for that same paper, the nicer the car, the more likely a driver would cut off a pedestrian in a crosswalk or fail to yield to others at a four-way stop. As Jerry Useem described in The Atlantic earlier this year, there is a similar body of research about how power affects the brain, making people “more impulsive, less risk-aware, and, crucially, less adept at seeing things from other people’s point of view.”

What explains these patterns of behavior? Well, one way to think of social networks is as a form of insurance: If I look out for you, you’ll do the same for me when I need help. But this isn’t as much a concern for the wealthy. “You need people less,” says Michael Kraus, an assistant professor of organizational behavior at Yale University. “You have the resources to deal with any kind of threat you might experience.”

There is another finding the field of behavioral finance that is probably also at play. In a 2009 paper published in the Journal of Personality and Social Psychology, researchers asked their student subjects to view graphs showing the growth of economic inequality during various historic eras. The students from wealthier backgrounds were much more likely to attribute the inequities to innate talent or hard work than their less financially fortunate peers. For those who believe success is a matter of innate ability, it’s easier to dismiss others as irresponsible. This effect seems to have been on display earlier this year when, for instance, former Representative Jason Chaffetz claimed many people needed to choose between buying the latest iPhone and health care, and when an Australian 1 percenter provoked international outrage by insisting that 20-somethings could afford to buy homes if only they stopped throwing away money on avocado toast.

These dynamics are not unique to the present age of high inequality—they were a feature of the first Gilded Age too. Then, moralists complained the poor wasted their limited funds on alcohol, and community centers offered classes in budgeting. And way back in 1892, The Boston Globe published an op-ed arguing that the United States’ wealthiest citizens needed to give more money to charity. It was emblematic of America’s long streak of what Benjamin Soskis, a research associate at the Center of Nonprofits and Philanthropy at the Urban Institute, calls “philanthro-shaming.” As Soskis once noted of this era in a piece in The Washington Post, “Enterprising journalists began compiling lists of the nation’s millionaires and determining who donated the most—and the least. And some of them began to issue demands that these philanthropic slackers shape up.”

If this question has bugged Americans for more than a hundred years, maybe it’s time to view it in a different way. Most other developed countries tax people at higher rates, leaving their societal well-being less dependent on convincing individuals to donate to charity. But America is moving in the opposite direction. The Trump administration, in coordination with Republicans in Congress, is promoting a tax-reform package that would shower benefits on the wealthy, while giving much less to those at the lower end of the earning spectrum. When congressional Republicans were asked why they supported such lopsided legislation, despite polls showing how unpopular it is with voters, a few replied that it was because their donors insisted on it.

Those donors likely include many wealthy philanthropists. Charitable giving is certainly good for society, but it’s also important to recognize it as a way for the well-off to exert control. Yes, the wealthy philanthropist is doing a service, but that’s a choice—not a legal obligation, as taxes are. And givers are the ones determining what the money goes toward, which means a much narrower range of interests gets represented compared with if the allocation were up to the government. If many Americans want the richest among them to give more, maybe taxation, not philanthropy, is the more effective approach.



ISIS, tax cuts, public trust. Race, immigration, the Empire State Building. Civil-service reform, North Korea, manufacturing. President Donald Trump’s State of the Union speech addressed a broad sweep of issues. But one central economic topic went notably missing: the country’s growing annual deficits and its increasing burden of debt.

The omission was a sign of the remarkable volte-face the Republican Party has taken on the country’s fiscal situation in just a few years. Republicans spent the early years of the recovery obsessed with the national debt, castigating Democrats for their supposed irresponsibility, warning about the dangers of the almighty bond market, and helping to construct complicated mechanisms to slash federal outlays. They are now spending what might very well be the late years of the recovery ignoring it, having passed a tax plan that will add more to the debt than President Obama’s stimulus package did and having forgotten their once-urgent plans to make cuts to Social Security and Medicare.

It might be nothing more than politics. Shaming the other guy for doing something, and then doing it oneself as soon as one gets into power: It is cynical, it is hypocritical, it is Washington. But it also reflects a profound change in policymakers’ understanding of deficits and debt. Maybe it is not that Republicans should be more obsessed with the debt now. Maybe it is that nobody in Washington should have been so obsessed with the deficit back then.

Back then, in this case, means 2010 through 2014, give or take. Congress passed a trillion-dollar stimulus to help wrest the country back from free fall, and the economy entered a sluggish recovery from the pain of the recession. Shortly after, Republicans started whipping up concern over the country’s fiscal situation, even as many economists from across the political spectrum argued that workers needed more help from deficit-financed stimulus. Democrats, in many cases, agreed with their colleagues across the aisle, expressing deep concern over the long-term fiscal situation. Next came a commission, endless budget negotiations, a tax increase, struggles with the debt ceiling, sequestration, a government shutdown.

More than anything else, there was obsession. Obsession with the idea that the bond market would punish the United States like it punished Greece, making the country’s debt burden unsustainable, and soon. Obsession with the idea of frivolous budgetary irresponsibility. “In this generation, a defining responsibility of government is to steer our nation clear of a debt crisis while there is still time,” Paul Ryan, now the speaker of the House, warned, adding that “President Obama has added more debt than any other president before him, and more than all the troubled governments of Europe combined.”

Sure, Republicans still cast themselves as the party of budgetary responsibility today. “We must impose firm caps on future debt, accelerate the repayment of the trillions we now owe in order to reaffirm our principles of responsible and limited government, and remove the burdens we are placing on future generations,” the party’s 2016 platform reads. And while President Trump has never been much of a budget hawk, he did campaign on a promise to not just reduce the annual deficit, but to balance the budget outright and “relatively quickly.”

But how things have changed. President Trump and congressional Republicans pushed through a package of tax cuts financed almost entirely through deficit spending—tax cuts that benefit corporations and the rich at the expense of the middle class and the working poor, no less. Absent any other budgetary changes, the legislation will add an estimated $1.8 trillion to the country’s debt over the next 10 years. It is likely that the country’s annual budget deficit will top $1 trillion next year, even if the unemployment rate remains low and the economy keeps growing.

With the tax cuts now law, Republicans are seeking to increase deficits even further. Gone are the promises to tackle entitlement reform, or to seek huge cuts from programs across the government. Instead, Republicans are pushing to shunt more money to military operations. “Around the world, we face rogue regimes, terrorist groups, and rivals like China and Russia that challenge our interests, our economy, and our values,” President Trump said, to rapturous applause, during Tuesday’s address. “For this reason, I am asking the Congress to end the dangerous defense sequester and fully fund our great military.” (Democrats are negotiating over the increase, and are pushing for more money for the opioid epidemic and disaster relief.)

The rhetoric has changed too, with Republicans no longer talking about the deficit and the debt in the heated, worried way they once did. During the 2016 GOP debates, the fiscal situation came up far less often than it did in 2012, and with far less urgency too. The Senate Budget Committee held no dedicated hearings on the debt, the deficit, fiscal stability, or balanced budgets in 2017, unlike in many years past. And, as a great FiveThirtyEight analysis has found, mentions of the deficit during congressional proceedings peaked at more than 8,000 in 2011 and fell to just more than 1,500 by 2015. For their part, administration officials refer to it infrequently, and often with little sense of outrage or concern. “The president is very much concerned about the rate of increase of the debt,” Steven Mnuchin, the Treasury secretary, said at a hearing of the Senate Banking Committee this week. “Over time, we need to figure out where we can have government savings to deal with the deficit.”

So what happened? How did the same Republicans who balked at a stimulus to get the country out of a recession rubber-stamp a bigger stimulus to fuel the best economy since the 1990s? How are the same Republicans who helped to construct an automatic mechanism to slash spending now lifting caps, spending more, and leaving entitlement programs untouched?

I asked both Democratic and Republican aides those questions, and got mostly shrugs. In some sense, President Trump is just doing what Presidents George W. Bush and Ronald Reagan did before him, aided by Republicans in Congress. Both swore to balance the budget or to bring down the debt. Both signed legislation that increased deficits instead, primarily through tax cuts and increased military spending.

Many Democrats, for their part, now believe that Republicans exploited their sincere concern over the long-term fiscal situation to score short-term political points—with some Democrats privately vowing not to worry about paying for things once they are back in power. “Republicans never really cared about the budget deficit. It was always a political tactic. With their own tax cut, they said, ‘Go ahead and finance it with massive deficit spending,’” Jared Bernstein, an Obama economic adviser, told me. Democrats struggled to ensure everything they did was paid for, while, Bernstein argues, “Republican fiscal irresponsibility has enabled them to provide all kinds of goodies to their donor base.”

But Washington’s understanding of the economic situation has changed, too, as Bernstein admits. It now seems clear that the degree of deficit panic whipped up in the post-crisis years overestimated the risk of a bond-market reaction, overstated the risk of the government crowding out private investment, and underestimated the capacity of the United States government to run deficits and build up debts—as well as overestimating how much voters ever really cared about the deficit. “If you go around yelling about pressure on interest rates and public borrowing crowding out private, you don’t have a lot to point to in terms of data,” Bernstein told me. “You have virtually nothing in terms of data. That’s not just here. That’s in Japan, other advanced economies as well.”

The risk that the country would not be able to fight a future recession due to its heavy debt burden might have been overinterpreted, as well. “It’s something the left has invented because they lost the tax war,” Doug Holtz-Eakin, the former director of the Congressional Budget Office and a Republican economic analyst, told me. The country has room to expand its budget deficits even now, he said. “If we were in a position where additional tax cuts or spending would be beneficial in a rapid way to help a falling economy, markets would reward, not punish, you for that.”

Plus, broad segments of the public seem uninterested in punishing even archconservative politicians who increase the debt, despite the promises of the Tea Party. Indeed, the many seem not to care much about the debt at all, now that Washington has stopped talking about it. The share of Americans who say that they see the deficit as a top priority has fallen to 48 percent today from 72 percent in 2013, according to a survey by the Pew Research Center. Corporate executives used to travel to Washington to express their concern over the country’s fiscal future. But on the tax legislation, they mostly remained mum. “Voters, frankly, after these huge deficits, are saying, ‘Well, how much do deficits really matter?'” Rick Santorum, the former Republican presidential candidate, told the Associated Press last September. “We’re not Greece yet, right?”

Of course, the country’s true budget hawks remain unmoved—and continue to push for putting the country on a different fiscal path. “High debt is a drag on the economy, and the more positive effects of the tax bill will eventually be overtaken by historic red ink. The president also did not address the ongoing need to address our nation’s largest entitlements, which need to be strengthened,” Maya MacGuineas, the president of the Committee for a Responsible Federal Budget, said in a statement after President Trump’s address. “We sincerely hope President Trump and Congress lay out a plan soon to put it on a downward and sustainable path. An excellent first step would be to agree to stop making it worse.”

But for now, nobody from either side of the aisle seems to want to listen. “The thing I can’t say for sure but I wonder about is what happens when we hit $1 trillion in annual deficits,” Holtz-Eakin told me. “When it happened back in 2010, people flipped out.” Given how Washington’s shouts about the debt have fast become whispers, that seems unlikely.



About 20 years ago, an attorney named Kitty Grubb saw an advertisement in her local paper that said the basketball referees’ association in Pinellas County, Florida, was looking for officials. Grubb, 65 years old, had first hoped to become a referee in 1977, having played basketball in high school and college. By the time she saw the advertisement, she had a successful career as a lawyer and extra time on her hands.

Grubb’s officiating career would eventually span about two decades and three sports: basketball, rowing, and football. Early on, she began reading the Florida High School Athletic Association Officials Guidebook. On page two, one guideline reads: “Officials shall … dress neatly and appropriately.”

There was one problem with that: The FHSAA’s official supplier, Gerry Davis Sports, didn’t provide much clothing in women’s sizes. Grubb tried to have her referee clothing tailored to fit, but it can cost a lot of money to try to adjust men’s clothing to fit a woman’s body, and even with tailoring, she told me, her clothes looked “less than ideal.”

This went on until last year, when Grubb—who is now a scoreboard and clock operator for football games—decided to complain. She had made a name for herself as a top arbitration and mediation attorney in Alabama and Tennessee, taking on high-profile gender-discrimination cases. Now, she began to see the uniform issue as another example of gender discrimination. Grubb emailed the FHSAA in June 2017 to complain: “Your female officials, myself included, grow weary of looking baggy, saggy in ill-fitting men’s apparel.”

Jeremy Hernandez, the assistant director of officials for the FHSAA, told me the association “will be doing our best to work with the vendors moving forward to ensure our official’s uniform concerns are being heard.” When Hernandez first received Grubb’s email, he said he would look into the matter. But when Hernandez looked around to see if he could find other vendors who had more options for women—and for football officials, specifically—he found that they didn’t exist.

The lack of appropriate clothing for female sports officials is a widespread problem. When Sarah Thomas, the first female NFL referee, was hired in 2015, the league had to figure out what uniform she would wear, since they only made them in men’s sizes. And not having appropriate uniforms hinders female officials in significant ways. Having pants that fit properly can help add height, which matters when a 5’6 female official is trying to establish on-field authority with a 6’2 male player. And if a woman doesn’t look as polished as the men on her officiating team, she can immediately appear out of place—a perception women are already trying to shake. “It’s hard enough being a female and walking out on that ball field and giving everybody the impression you belong there,” Ila Valcarcel, a baseball umpire, told me. “They don’t know you, so your impression is what they get to see and if what they see is equipment and clothing that don’t fit, you already have one strike against you.”

Valcarcel, who has umpired Major League Baseball spring-training games and now works as an umpire supervisor for Perfect Game USA, an organization that promotes baseball, found that the chest plates and shin guards meant to fit men tended to leave gaps where balls could hit her. She began teaching women how to take apart and mold their chest plates, which are built for flatter, wider, male chests, so that they “don’t look like Ninja Turtles.” She heats up shin guards with a heat gun and remolds them to fit the women’s legs.*

In the male-dominated field of professional baseball umpiring, there are few mentors who can help women dress: Only eight women have ever umpired in the minor leagues, and there has never been a woman umpire at the major-league level. “For us, that’s half the battle right away, just presenting as polished and professional,” said Perry Barber, who has been an umpire for 38 years.

Sports officiating isn’t the only field that has failed to consider women’s bodies when making uniforms. Some women who play sports themselves find it difficult to find the right equipment. While there are shoulder pads made explicitly for women who play tackle football, some smaller players have trouble finding pads that both fit and are constructed to withstand adult impact; junior-sized shoulder pads may fit adult women well, but they aren’t built to take the kind of hits dished out in an adult league like the Women’s Football Alliance.

Female professionals in non-sports fields contend with ill-fitting attire, too. With women making up more than half of all medical-school students in the U.S., it makes sense that they should be able to find lab coats that fit. Having a properly fitting coat is also important for scientists, who sometimes work with dangerous chemicals and are put at risk if parts of their skin are exposed. In a story for Racked last year, though, Alexandra Bausch wrote that most lab coats aren’t designed with women in mind. Even when lab coats are made specifically for women, they’re often a smaller version of men’s coats, which fail to take into consideration differences in women’s wardrobes, such as lower cuts on the necklines of shirts.

The dearth of women’s clothing for certain professions reflects a broader numbers issue: The fields with limited clothing choices for women—sports, science—tend to be ones in which women are underrepresented. While women have made leaps in many fields, they still have a long way to go when it comes to officiating. And for many apparel companies, it doesn’t make business sense to carry items that don’t seem likely to sell well. Scott Kennedy, a business-development specialist at Ump-Attire.com, which provides uniforms for Minor League Baseball as well as other sports attire, said in an email, “We make multiple requests with manufacturers to fill the female’s industry needs, but the minimums”—the number of items required in a bulk order—“are so high that it’s not economically feasible” to offer many options for women.

The FHSAA began a new contracting partnership with multiple uniform suppliers, as opposed to the single supplier it had worked with in the past. Of the uniform suppliers from which FHSAA officials can now purchase logoed clothing, a couple of their websites advertise women’s shirt sizes for some FHSAA sports, and some items can be made upon request. Still, no FHSAA-logoed pants, or umpire equipment, seem to be available in women’s sizes. It’s an improvement, but, as far as Grubb is concerned, not a big enough one.

Not long ago, Grubb followed up with Hernandez, of the FHSAA, to ask that the absence of women’s clothing be addressed at the association’s annual conference. Hernandez promised a discussion but added, “We tried to base our decision on what was best for our associations as a whole and not based on a specific gender.” Refereeing is a shrinking field, though, and it’s hard to recruit women when there isn’t clothing available that fits them.

    * This article originally stated that Ila Valcarcel heats up shin guards with a hot-glue gun. We regret the error.



Big philanthropy is having something of a moment. There is the Giving Pledge, the promise made by more than a hundred of the United States’ wealthiest citizens, including Bill Gates and Warren Buffett, to give the vast majority of their fortunes to charity. Then there is the related “giving while living” movement, whose best known proponent is Charles Feeney, now 86, who has given away almost the entirety of his multi-billion dollar fortune during his lifetime.

Some, though, are cautious about these donations’ ultimate effects. There’s an argument that no matter how well intentioned, the scale of the money being directed toward philanthropic efforts by the wealthiest Americans is further contributing to an unequal balance of power in society, even as the givers claim that’s exactly what they are attempting to address.

Joel Fleishman knows these issues well. The director of the Center for Strategic Philanthropy and Civil Society at Duke University (and a professor there as well), Fleishman served for more than a decade as an executive at the Atlantic Philanthropies, the charitable foundation set up in 1982 by Feeney to carry out his own giving-while-living pledge.

Fleishman’s new book, Putting Wealth to Work: Philanthropy for Today or Investing for Tomorrow, is a survey of the world of charitable foundations, circa 2017. I recently spoke with him about philanthropic giving, including his surprising (for someone with his background) critique of giving while living, and strong defense of perpetual foundations, meaning foundations set up to continue on after their founders pass away. The conversation that follows is lightly edited and condensed for clarity and length.

Helaine Olen: What are the origins of the “giving while living” movement?

Joel Fleishman: Giving while living really originated with Andrew Carnegie. In a very famous document called "The Gospel of Wealth," which he published in 1888, he said you really should spend your money during your lifetime because if you do that, you'll be in a better position to be sure that it accomplishes what you hope. Of course, Andrew Carnegie didn’t, in the end, do that. He ended up with about a quarter of his fortune left at the point at which he was about to die which he still hadn't given away. He decided then to give it to a perpetual foundation, which he created. That’s now called the Carnegie Corporation of New York.

In our time, the person who is best known for giving while living is Chuck Feeney, the founder of Atlantic Philanthropies. The goal, the theory behind it, is that you could give away all of your assets during your lifetime and achieve much more. A lot of my book is about the question of how valid that assumption is.

Olen: And what do you think about that assumption?

Fleishman: If you say, “Can you achieve more in terms of diminishing hunger at present?,” I think you obviously can: If you give away a billion dollars to feed people, it's better than giving away 5 percent of a billion dollars annually. But if you're talking about curing cancer, it's a different story, because cancer is going to be cured, and indeed virtually every disease is going to be cured, by repetitive attempts to understand how cancer works and that requires hypotheses that are tested sequentially. You can't do it all at once.

My point here is that whether you can achieve significant impact really depends on what kind of problem you're trying to attack. The question is, do you care entirely about satisfying hunger or would you rather do something like figure out what's causing hunger in our system and trying to do something to correct those things that are perpetuating hunger or poverty?

Olen: But both approaches have their advantages, right?

Fleishman: Right. It’s clear that both kinds of philanthropy are needed. Solving social problems requires energetic persistence over time. It requires not only work by government, but it also requires a lot of other actors, like nonprofit organizations.

Look at the major nonprofit organizations that exist in the United States now. There are approximately 2 million nonprofit organizations that focus on a variety of problems, from the environment to race issues, to human rights, civil liberties, all those kind of things. And it has been primarily the perpetual foundations that were responsible for starting, nurturing, and indeed supporting many, if not most of the largest nonprofit organizations in the United States. As they say, Rome wasn't built in a day, and no public-policy problems have been solved in a day. The Green Revolution, for which Norman Borlaug of the Rockefeller Foundation earned a Nobel Peace Prize, took 35 to 40 years before they actually did develop the new grains that transformed countries like Pakistan and Bangladesh from chronically starving countries to chronically grain-exporting countries. It couldn’t be done in a short period of time.

I think those who have gone about this best are those that recognize that they cannot get instant impact on the problems that they care a lot about, in the short run. It just can't be done, because the problems don't lend themselves to it.

Olen: So if you are a philanthropist who wants to give while living, why set up a foundation? Couldn’t you just give the money to existing groups?

Fleishman: Most the people who are attracted to the idea of giving while living are attracted to the idea of getting some psychic satisfaction from what they do in the short run. Most major philanthropists who want to give away a lot of money are looking for a bigger bang. Most people who choose to give away a large amount of money during their lifetime are really wanting a more immediate sense of impact.

Olen: Is there a type of person who's more attracted to giving while living than others?

Fleishman: Most giving while living is done by people who have made a lot of money when they are young. My sense is that the reason is that they would like to replicate in the social sector the same level of achievement that they had in making their money in the for-profit sector. For example, look at the tech billionaires who are trying to figure out what to do with their money. They're not all motivated by a quest for instant impact, but many of them are. The more thoughtful people who want to give away a lot of money in the short run, they recognize the problems: There are constraints on their capacity to solve a problem in the short run, and they really need to support institutions like universities, like think tanks, that are working on these problems over the long run.

Olen: There is a critique that all this big-money philanthropy, no matter how well meant, is problematic: It’s allowing the wealthy to determine policy that is really the responsibility of an elected government. Do you think big philanthropy affords the giver too much power?

Fleishman: The United States has the First Amendment. The First Amendment is interpreted as not just about speaking out but also deploying your wealth on behalf of things that you care about. So, do these people have too much power? Under our Constitution, people are encouraged to spend their private resources to try to benefit society. And that tradition was one of the reasons that the United States has the largest amount of giving as a percentage of GDP of any country in the world.

Olen: But some of that giving is political.

Fleishman: If you read Jane Mayer's book Dark Money, you'll see how wealthy individuals can, in the case of the Koch Brothers, basically use nonprofit organizations to advance their political agendas. It's a very interesting book and it's very persuasive. One of the reasons that Trump’s support appears to be so widely spread around the country has to do, at least in part, with the fact that they have had these organizations there, these outposts of right, far-right, radical-right thinking.

Olen: Do you see similar moves on the left at all, or not to the same extent?

Fleishman: Not to the same extent. The left has not taken anywhere near as active a role. Only now is it starting to do that, and it has a lot of catching up to do. This is not something that happened instantly—it started with the creation of a number of explicitly right-leaning foundations, like the Olin Foundation, which I write about in my book. These foundations built the infrastructure.

Olen: This goes back to my question, though: Is this system giving too much power to the wealthy?

Fleishman: Well, the answer is we’ve never figured out whether it's a good idea to try to constrain the expenditure of funds for these kinds of things. And if we had to try to figure it out, it would be very complex to try to do that.

In Europe there's a long history of unwillingness to permit wealthy individuals and foundations to get involved in some areas of public policy, for the reasons that you are pointing out. My concern is that I cannot figure out how you are going to design laws and regulations that would in fact restrain people from spending the money on what they want to. And when you look at the record of the foundations over the course of the last century that they've been around, you have to say they’ve done a lot of very good things. There are many communities that continuously benefit from the existence of those foundations, locally—you don't hear any criticism from people in those towns about what the foundations are doing, nor do you hear much criticism from people around the country about what the big foundations are doing.

Ideologues can find anything they want wrong with the situation, but the fact is, government cannot do everything. We know about the fickleness of government and how it can change, as we've seen from going from Obama to Trump. So if you have more individuals who want to spend their wealth in ways that they think benefits society, I believe society benefits significantly from it.



Every year, the story of the Super Bowl is partly a story of its gargantuan audience. Of the 20 most-watched TV broadcasts in U.S. history, 19 are Super Bowls. (The other one is the series finale of M*A*S*H.)

But this superlative legacy is in tension with an equal and opposite force: the steady collapse in NFL viewership. The size of the league’s average per-game audience has declined by about 17 percent since 2015, an astonishing fall for the crown jewel of pay TV.

To explain the mystery of cascading football ratings, observers have pointed to several potential culprits. In the autumn of 2016, analysts blamed the election and Donald Trump’s nonstop antics for pulling viewers’ attention from football to the presidential campaigns. Last year, they blamed players’ protests and the president’s relentless tweeting. But now evidence is mounting that the NFL’s problems are deeper than political story lines and social-media distractions.

Quite simply, televised football has a television problem and a football problem. The television problem is prominent yet simple. Fewer people are subscribing to pay TV, which means that ratings are declining for just about everything on cable and broadcast. To pick an example quite different from football: The audience for last weekend’s Grammys telecast declined by nearly 10 million, a stunning 30 percent drop in one year that is related to the fact that cord-cutting is accelerating, leaving fewer people (especially young people) with access to cable TV. Attention has shifted from pay TV to mobile devices, which aggregate football highlights, stats, and fantasy scores, allowing more fans to closely follow the sport without actually watching it live on television.

The football problem, though, is more complicated, in part because there are so many fan conjectures and politically motivated conspiracy theories competing for explanatory power. Are viewers turning away from football because of concussions? Players’ protests? Donald Trump’s poisoning the league with political tweets? Players having too much fun? Players not having enough fun? There isn’t much hard evidence to prove any of these hypotheses correct.

Instead there is evidence, sometimes circumstantial and often crystal clear, that football has suffered as its most popular players and teams have disappointed, in various ways. NFL ratings peaked several years ago, when some of the greatest quarterbacks in history were in their record-setting primes and most of the league’s most popular teams were competitive.

That’s simply not the case anymore. Many of the most popular and marketable players in the NFL in 2017 are either injured (like Aaron Rodgers, Andrew Luck, and J.J. Watt), playing for mediocre or noncompetitive teams (like Russell Wilson, Von Miller, and Eli Manning), or both (like Odell Beckham Jr.). It ought to concern the league that the remainder is composed mostly of quarterbacks aged 35 and over (Tom Brady, Drew Brees, Ben Roethlisberger). Of the 10 NFL players with the best-selling jerseys, only one made the playoffs without being injured or suspended: Tom Brady.

Compare this sorry picture to the NBA, where 14 of the 15 players with the best-selling jerseys are healthy and active, and 13 are projected to make the playoffs. Basketball telecasts on ESPN and TNT are attracting 15 percent more viewers than last year, even though their average viewership is still just one-tenth the size of Sunday Night Football. The upshot is straightforward: Live sports are blockbuster events that fans attend (either in person or virtually) to watch superheroic performances. When those superheroes are playing, ratings stabilize or rise. When those same players are just wearing sweatpants on the sidelines, ratings drop.

But it’s not just a dearth of star players; the NFL also suffers when its most popular franchises are suffering. This has been particularly clear in the playoffs, which have shown some of the worst ratings declines of the year. An analysis by the media research firm MoffettNathanson ranked the league’s teams by internet traffic to their official websites. Just four of the 13 most popular teams made the playoffs. But of the 10 least popular teams in the league, half of them made the postseason and played in the first round of the playoffs. It will surprise no one that ratings for that week were dismal, down 20 percent from the previous year.

The Most Popular NFL Teams, by Traffic to Their Websites

The implication is straightforward: Ratings dive when the most popular teams take a dive, too. As long as the Dallas Cowboys, Green Bay Packers, or another popular team is playing and winning and throwing touchdown passes all over the place, football audiences are still astronomical and fairly bulletproof. (Indeed, the six most-watched playoff games from last year all involved the No. 2 Packers or No. 4 Steelers.) But when Kansas City plays Tennessee in the first round of the playoffs, ratings plummet. By this analysis, Tom Brady’s Super Bowl–clinching comeback against the unheralded Jacksonville Jaguars may have saved NBC and its advertisers tens of millions of dollars’ worth of captive attention.

And this is precisely why the decline and fall of the NFL is such a big deal for television—and, truly, for much of the retail industry. Television is a $70 billion advertising business, and the NFL is its keystone. The Super Bowl is by far the largest live broadcast event in the U.S. Football accounts for almost half of Fox’s “gross ratings points” (a common proxy in the ad industry for audience reach) and at least one-eighth of the same measure for CBS, NBC, and ESPN. Its demise will encourage more large media companies to merge—as Disney and Fox have proposed and CBS is allegedly discussing—and nudge even more commercial dollars to internet advertising companies, where Google and Facebook stand to benefit. Football’s rise to cultural dominance mirrored the ascent of pay TV as the single best business model in American entertainment history. Today, both industries are falling back to earth together.



In a recent letter to listeners, Minnesota Public Radio’s president, John McTaggart, depicted damning allegations of sexual harassment against Garrison Keillor, the recently ousted host of the popular show A Prairie Home Companion. “If the full 12-page letter or even a detailed summary of the alleged incidents were to be made public, we believe that would clarify why MPR ended its business relationship with Garrison,” he wrote. The statement is likely geared toward shocked fans, some of whom criticized the station for severing ties with Keillor over what he said was a “more complicated” version of events. McTaggart’s letter may quell some of MPR’s critics, but it doesn’t answer the bigger question many listeners have: How could Keillor and so many other beloved public-media stars have gotten away with such inappropriate behavior for so long?

Within the span of a few weeks, accusations against other high-ranking and well-known figures have surfaced in the public-broadcasting realm, leading to their dismissal or suspension from organizations including NPR, WNYC, and WBUR. There was David Sweeney and Michael Oreskes and Charlie Rose. And John Hockenberry, Tom Ashbrook, Leonard Lopate, and Jonathan Schwartz. There’s something odd about how many of the allegations of sexual misconduct in the media industry have come out of public media—with its reputation for thoughtfulness and civility. Hollywood was one thing, with its legacy of casting couches, hypersexualization of women, and clear gender imbalances—but gentle, egalitarian public radio?

The industry’s swift and aggressive response has been notable. Stations have been quick to cut ties with those accused of sexual harassment. That stands in contrast to the choices made by other organizations who have sometimes chosen different and less severe forms of censure, such as the reassignment of Glenn Thrush at The New York Times or the six-month sabbatical taken by Pixar’s John Lasseter.

According to the Corporation for Public Broadcasting (CPB), a nonprofit formed in 1967 to act as a steward for the federal government’s investments in public broadcasting, the purpose of public media is to “provide programs and services that inform, educate, enlighten, and enrich the public and help inform civil discourse essential to American society.” And that mandate requires the “development of content that involves creative risk and that addresses the needs of unserved and underserved audiences, especially children and minorities.” This guiding premise tasks public media with upholding a higher moral standard than for-profit media, and many presume that by virtue of working there, its employees adhere to those standards too. That’s part of what makes these allegations so difficult for audiences to stomach.

Public media is donor-based, meaning these outlets must appeal for their audiences’ support. In recent years, individual giving has increased for local public-radio funding and broadcasts such as PBS NewsHour. That may be part of what’s driving dismissals in public broadcasting. A donor-supported model “gives people a sense of ownership and investment that I think is different,” Pete Vernon, a staff writer covering media for the Columbia Journalism Review, told me. When it comes to stations trying to manage the fallout of sexual harassment, they “understand how bad the optics are on this, and they understand their listeners are now incensed about it.” They also understand that, especially for smaller stations, their livelihood can depend on their ability to court donations.

Public media is made up of a large constellation of local, independent radio and television stations, which receive federal funding to help them provide free programming and services to their local audience. These stations can differ vastly in size, audience, and resources. Some choose to become member stations to national outfits such as Public Broadcasting Service (PBS) or NPR, which give them access to additional programming. But often smaller stations find themselves strapped for cash, which can inhibit the ability to build up human-resources departments, or train staff and leadership about how to create an inclusive and safe work environment. Many of the outlets implicated in recent harassment allegations certainly don’t qualify as small or under-resourced, but if stations aren’t effectively managing these problems when they’re still tiny, they can wind up with big problems as they grow.  

At WNYC, for example, the newsroom grew to around 70 workers up from three, in the span of about 20 years, according to The New York Times.* But even as the station drew in more revenue and grew its staff, some current and former employees told The New York Times that human resources simply didn’t keep pace. Now, after the firings of John Hockenberry, who hosted The Takeway;  Leonard Lopate, who hosted The Leonard Lopate Show; and Jonathan Schwartz, who hosted programs on American musical standards; Laura Walker, the president of New York Public Radio, has called for a review of HR policies related to harassment retaliation and discrimination. At a board meeting following the accusations of sexual harassment, Walker said that she was “profoundly pained and sorry” that the WNYC workplace “did not, at times, live up to the values our programming embodies.”

While many people I spoke with say public media’s harassment problem isn’t worse than other segments of media, it’s clear that the systems in place to cope with issues of sexual harassment have been woefully inadequate. Julie Drizin, the executive director of Current, a nonprofit publication focused on public media, says that the lack of robust human-resources departments that would include training and specific reporting mechanisms in instances of harassment may be a part of the problem, at least at some stations. “A lot of corporations invest a lot more in HR. I think that’s one of the things that separates public media from other kinds of media,” she says.

Still, even with its well-known deficiencies, public media doesn’t quite fit the stereotypes of a male-dominated, hostile work environment. Vivian Schiller, the former CEO of National Public Radio, told me that public broadcasting, particularly NPR, has long been considered a space where women can thrive. “When I was there, most of the leadership was women,” Schiller said. In fact, four women, Cokie Roberts, Nina Totenberg, Linda Wertheimer, and Susan Stamberg, are often referred to as the “founding mothers” of NPR. And the organization’s most recent data on newsroom makeup shows that more than half of newsroom employees are women. The fact that a culture of harassment and bullying were allowed to fester for for years, all while women sat in positions of power and control, makes the issue all the more confusing. But if you consider the discord on other issues, such as between public media’s stated commitment to diversity and its predominantly white audiences and newsrooms, it’s clear that the overarching vision of public broadcasting often doesn’t manifest in real and critical ways.

Schiller told me that she was shocked by the wave of allegations, and even more so by the fact that so many at NPR had remained quiet about them for so long. “My experience with the NPR newsroom is that they had absolutely no hesitation to speak out about things that they felt weren’t right, unfair, or that were bothering them,” she said. She sees the recent upheaval in a positive light—an indication that public media is going to be a leader when it comes to coping with these issues. “There is a seriousness of purpose to make things right, and to try to fix whatever systems were and weren’t in place that allowed this to happen,” she said.

For now though, most stations I spoke with are still in the process of conducting investigations to determine just how far issues of discrimination go, and what systems have allowed them to flourish. As public broadcasting attempts to cope with its #MeToo moment, leadership will have make sense of the dissonance of widespread sexual harassment in a space known for nurturing women’s careers.  They may find themselves facing other contradictions, as well— such as persistent racial inequality in a space that has a mandate to be thoughtful about diversity. Stations have an opportunity not only to contend with individual harassers or failing policies, but to also think broadly about how to create newsrooms that live up to the values public media purports to uphold.

*This article originally mischaracterized the size of WNYC's newsroom. We regret the error. 



Within a week, Republicans will probably pass a corporate tax cut that is one of the most unpopular major pieces of legislation in modern American history. This is a rather curious distinction for a bill that cuts taxes for nearly every American family.

How can a trillion-dollar tax cut be so unpopular?

One possibility is that Americans don’t like the bill because they don’t understand what it does. More than half of Americans don’t think that the Republicans’ bill will reduce their taxes in 2018. That’s a striking statistic, since new research from the nonpartisan Tax Policy Center (TPC) finds that the vast majority of the country, including 90 percent of middle-class families, will get a tax break.

But another possibility is that Americans don’t like the tax bill because they understand exactly what it does. Most Americans seem to think that the GOP tax bill overwhelmingly benefits the rich at a moment when large corporations and affluent families don’t need much legislative assistance in their multi-decade dominion over the economy. In fact, the GOP tax bill does just that.

Why are Republicans doing this? First, it is conservative economic dogma that low taxes on the wealthy encourage business expansion and job creation, so that tax cuts for the penthouse “trickle down” to the lower floors of the economy, in the form of jobs and higher wages. Recent history has either punctured or demolished this point of view, as the Reagan and Bush tax cuts quite clearly failed to produce additional revenue or benefit middle-class wages. Second, as a practical matter, Republicans, like Democrats, need lots of money to run for office. But on the right, these funds are mostly supplied by a small base of corporate-libertarian donors, like the Koch brothers, who have for decades encouraged lawmakers to cut taxes and welfare spending to galvanize the economy. Republican politicians might prefer to support an unpopular bill, and risk losing some votes, than pass nothing and lose the critical donor support required to procure any votes.

The GOP tax bill operates by two simple principles. First, families at every income level can expect a tax cut—but the richer the family, the bigger the cut, both in absolute terms and in proportional income. Households making between $500,000 and $1 million would get a $21,000 tax cut in 2019 and their after-tax income would rise by 4.3 percent. That proportional gain is four times larger than the average after-tax benefit for a family making $40,000.

Second, as time goes by, most families’ tax benefits would shrink—with the major exception being the most affluent. Most of the plan’s individual tax cuts end after 2025. This provision is necessary (because of the procedure congressional Republicans chose for the bill) to pay for a permanent corporate tax cut whose benefits flow mostly through capital gains and dividends to shareholders. The bars below illustrate this effect:  The tax cuts shrink between 2018 and 2025 before disappearing for all levels in 2027—except for the richest households, the ones with the most money invested in stocks, who will still be reaping the benefits of lower corporate taxes.

The richest 1 percent now own 40 percent of the country’s wealth—their highest share in more than 60 years. Perhaps 40 percent seems like enough? Well, the GOP disagrees. In 2018, the 670,000 households earning more than $1 million a year will collectively benefit more from this bill than the 113 million families earning less than $75,000 (many of whom are, to be fair, pensioners who are earning little to no income).

How Families Benefit from the GOP Tax Bill: $75,000 vs. $1 Million

Wealth inequality is a thorny problem. The rich have more money, which means they have more savings. When they invest those savings in stocks during a bull market, their wealth rises faster than the wages of the middle class. The richest 10 percent of U.S. families owns 80 percent of all publicly traded stock, while more than half of Americans don’t have one dollar in a 401(k).

The Great Recession exacerbated the wealth gap by striking at the heart of middle-class assets—the housing market—while the post-recession recovery in equities benefited the core of upper-class wealth—investments. Today, the median American household is poorer than it was before the housing crash, while the richest households are much richer, thanks to the remarkable rally in equity prices since 2009. That explains the sharp divergence in the net worth of households since the Great Recession visible in the chart below. Families at the 25th percentile have scarcely recovered since the Great Recession while households at the 90th, 95th, and 99th percentiles have all exceeded their pre-recession highs.



The last few decades have been an extraordinary time for income and wealth inequality. This bill is an extraordinary inequality accelerant that may do very little for growth. Economists know it. Judging by its approval rating, Americans know it, too.



When I walked into Sidra Qasim and Waqas Ali’s apartment in San Francisco, the couple looked straight at my feet. “Your shoes are 12.5?” Ali asked. I nodded. “He’s very good at that,” Qasim, his wife, said, a smile tugging at the sides of her mouth. The couple have been designing shoes for nearly a decade, but they never intended to be shoemakers. They were just looking for a way to leverage the power they saw in the internet.

Qasim and Ali grew up in small towns in Pakistan, 30 miles apart. Qasim’s aunt, who was Ali’s teacher, introduced them, and for years they were just friends, dog-earing sections of philosophy books to share with each other and talking about the world outside their small Muslim communities. Eventually they got married.

In 2011, when they started their first shoe company together—an online retailer called Markhor for handcrafted leather shoes—national bank regulations made it very difficult for Pakistanis to accept online payments. (Services such as PayPal and Alipay are still not available in Pakistan.) So, in 2014, Ali applied for and received a B-1 visa, reserved for short-term business trips, to travel to the United States and open a bank account there. Today, as the couple starts their second business, an online retailer for minimalist sneakers, the market is changing in ways that would seem to favor entrepreneurs from the developing world. The low cost of essential business services such as cloud computing has made online entrepreneurship possible from almost anywhere. At the same time, inexpensive smartphones and a growing middle class have created demand for new products and services in developing countries such as Pakistan.

Venture capitalists have already invested nearly $8 billion into developing countries (Brazil, Chile, Colombia, India, Indonesia, Malaysia, Mexico, and Pakistan) in the first 10 months of 2018, a 40 percent increase from all of 2017, according to data from the investment-analytics platform PitchBook. “More venture capital is going to the developing world because that’s where the growth opportunity is,” Dave Richards, a managing partner at Capria, an emerging-market investment firm, told me. Richards believes that burgeoning tech ecosystems in the developing world, and the millions of potential customers there, have made it an attractive place to invest. Now that prominent venture-capital firms such as Sequoia Capital and private-equity firms such as TPG have started investing in emerging markets, other early-stage investors are following suit.

Still, venture-capital investment in these developing countries accounts only for some 3 percent of all venture-capital money invested in 2018, compared with a little over 1 percent a decade ago. Despite more venture capital being invested in the developing world, there are also significantly fewer deals: The boom has been led by an increase in so-called megarounds of $100 million or more, mostly in India and Brazil. (Investment in Chinese companies has also ballooned, so much so that China has surpassed North America in venture-capital investment so far in 2018.)

“Investing in emerging markets is still associated with considerable risk,” Joelle Sostheim, a venture-capital analyst at PitchBook, told me. “Investment tends to go to the places where investors have some on-the-ground knowledge.”



In 2010, when Qasim and Ali first came up with the idea to sell shoes online, they couldn’t afford to set up their own website. They spent their mornings passing a single laptop back and forth at a local Kentucky Fried Chicken (KFC had the best Wi-Fi) to build the website and apply to local business competitions; their afternoons were taken up by working with local craftsmen to perfect the shoes’ designs; and their evenings were devoted to reading back issues of Harvard Business Review to “learn how business worked.”

Their first success came in 2011, when P@SHA Social Innovation Fund, a Google-backed grant program for Pakistani entrepreneurs, awarded them $10,000. “It was the worst pitch I had ever seen,” said William Fitzgerald, a former Google policy and communications lead who saw their application after they were awarded the grant. But he was impressed by their determination. They wanted to create a product from the ground up and lift up their countrymen in the process.

But for Qasim and Ali, as for many other entrepreneurs (with those in China a notable exception), it seemed there were intangible benefits that could be absorbed only by living in Silicon Valley, in close proximity to capital and talent. In 2014, the couple took out a $3,000 loan to attend a conference in Las Vegas organized by the Zappos CEO, Tony Hsieh. The plan was to send Ali, who spoke better English than Qasim, to the U.S. to attend the conference and register their company as a Delaware C corporation, which would allow them to open a U.S. bank account.

While in the U.S., Ali met with other e-commerce entrepreneurs from companies such as Warby Parker and Everlane, and met the company’s first two angel investors, who each invested $15,000 to help get Markhor (then called Hometown) off the ground. The success of a $107,000 Kickstarter campaign, a few months later, was due in part to the connections Ali made on his trip to the U.S.

The experience underscored their sense that there were far more opportunities for them in the U.S. than in Pakistan. In 2015, Qasim and Ali were accepted into the prestigious Y Combinator accelerator, which would give them additional access to mentorship and potential investors. Moving to the Bay Area also gave them the chance to interact with a number of Markhor’s original customers. “We noticed people were buying Markhor shoes for the story and the design, but they were not actually wearing them to work,” Ali told me. If the couple were going to truly succeed, they thought, they needed to design a product Americans would use every day. So, in 2017, they began designing their second brand, Atoms.

Soon, they found themselves drifting farther from their roots. Their first brand had been built around Pakistani leather and handcrafted care—Markhor was named after Pakistan’s national animal, a wild goat, which, like the local craftsmen, was an endangered species—but they found that scaling the production of a handcrafted product was very difficult. Qasim and Ali made the decision to outsource the production of Atoms to South Korea, where factories had more experience producing high-end sneakers at scale and could ramp up production without skimping on quality.

While customers had gotten excited about Markhor’s narrative about itself, they hadn’t bought the shoes in great numbers—but with Atoms, people loved the design. (The shoe has elastic laces that allow it to easily slip on and off. It also comes in quarter sizes, which allows customers to mix and match, depending on the size of their feet.) In recent months, famous entrepreneurs and venture capitalists have been tweeting about the shoes nonstop. TechCrunch called them “the minimalist startup shoe you’ll actually wear.”

Qasim and Ali’s origin tale, about the new opportunities the internet had brought to the developing world, would have a more complicated second chapter. While more capital had begun flowing to countries such as Pakistan, in the years since Markhor’s founding, Ali told me he and his wife wouldn’t be returning home anytime soon. (Markhor is still in business, with a team in Lahore running operations, but Ali and Qasim are mostly focused on Atoms now.) In Silicon Valley, Ali said, “we have easier access to the right kind of talent, capital, and advice.”

The irony of two entrepreneurs from small towns in Pakistan designing the next addition to the Silicon Valley uniform is not lost on Qasim and Ali. But for them, the “problem” they are trying to solve has never been about footwear—it’s about paving the way for future Pakistani entrepreneurs, even if they had to leave Pakistan to do it. In their minds, what budding entrepreneurs in the developing world need more than anything else is role models who show that success is possible—regardless of where the company matures.



Not long ago, India’s underwhelming manufacturing industry was symbolized by its best-known car: the Ambassador. Modeled on a British car from the ‘50s, the boxy Hindustan Motors sedan dominated Indian roads for decades. Well into the 1990s, it was to India what the Lada was to the Soviet Union or the Trabant to East Germany, testimony to the technological shortcomings of an economy cut off from the world and shaped more by bureaucrats than by market forces.

Manufacturing in India still faces problems, including poor infrastructure, red tape, disconnectedness from global supply chains, and restrictive labor laws that have stymied the growth of business and limited economic dynamism. Nonetheless, over the past decade, hardly noticed by much of the world, the country’s auto industry has quietly scripted a success story. The land of the clunky Ambassador now houses one of the world’s major automobile industries. In terms of output—nearly 3.8 million cars a year, according to the most recent figures—India now nearly matches South Korea, an automobile powerhouse, and is on track to catch up with Germany.

This story holds lessons for Asia’s third largest economy. If automobiles, and by extension manufacturing more broadly, take off in India, the country may be able to generate many of the jobs required to employ the 12 million new entrants to the labor market each year. If manufacturing fails to thrive, India’s economic future could come into question, and along with it the country’s dream of emerging as a global power.

A manufacturing enclave in the high-growth state of Gujarat provides a glimpse of the industry’s possible future. Ford Motor Company’s sprawling, 460-acre facility can churn out 240,000 vehicles and 270,000 engines a year. Nearly two dozen suppliers have set up shop next door, creating a just-in-time manufacturing ecosystem. The plant manager at the time of my visit, Kel Kearns, a former Royal Australian Air Force flight lieutenant, said the highly automated Ford facility is “more like what you’d see in North America or Europe than traditionally in Asia-Pacific.”

It’s hard to overemphasize the importance for India of getting manufacturing right. While the country’s world-class information-technology sector put it on virtually every global boardroom’s agenda, Indian manufacturing trails that of East Asian powerhouses such as South Korea and Taiwan, or even much smaller economies like Vietnam or Bangladesh. As a percentage of GDP, manufacturing in India contributes only about 17 percent, essentially unchanged from the amount it contributed at the advent of economics reforms back in 1991.

To put this in perspective, manufacturing accounts for 29 percent of economic output in China and South Korea, and 27 percent in Thailand, according to World Bank data. Moving millions of workers from farms to factories has played a pivotal role in reducing poverty and raising living standards across East Asia.

It should come as no surprise, then, that India seeks to raise manufacturing as a percentage of GDP from 17 percent to 25 percent, and to create 100 million jobs within a decade. Shortly after his 2014 election, Prime Minister Narendra Modi launched the “Make in India” campaign with the avowed goal of transforming India “into a global design and manufacturing hub.”

Against this backdrop of patchy industrialization, the relative success of India’s car industry reveals how a once-closed sector gradually—and without receiving much attention—became the world’s sixth-largest automobile manufacturer. Ford is just one of many firms with a presence in India. Suzuki, Toyota, Honda, Hyundai, Volkswagen, BMW, General Motors, Mercedes Benz, Mitsubishi, Renault, Audi, Nissan, and Skoda all manufacture in the country now. They add to the variety of models available from India’s dominant domestic makers: Maruti Suzuki (a pioneering joint venture now majority-owned by Japan’s Suzuki), Tata Motors (which includes Jaguar Land Rover), Mahindra and Mahindra, Hindustan Motors, and Premier Automobile. That list does not include manufacturers focused on the motorcycle and scooter markets that still account for the vast majority of vehicle sales in India.

Even before India’s economic opening in 1991, a state-led experiment planted the seeds of India’s auto flowering. In 1981, the state-owned enterprise Maruti Udyog sought an international partner to manufacture subcompact cars for India’s growing middle class through a government-licensed joint venture. Suzuki was selected the next year, and the partnership flourished. The first car, a boxy white knockoff of the Japanese-made Suzuki Fronte, rolled off a factory floor outside Delhi in 1983.

The Maruti Suzuki brand remains India’s top seller; even the tiny Maruti 800 still lives on in the restyled Alto 800. But it was not until the mid-1990s, after liberalization, that India opened the automobile industry to major investment by foreign manufacturers. That’s when the major U.S., Asian, and European automakers, faced with stagnating home markets, began streaming into India.

In the 2000s, Indian automakers began to look abroad. Tata Motors acquired Jaguar Land Rover from Ford in 2008, and by 2012 had turned the loss-making company around. Mahindra and Mahindra took a majority stake in Korea’s Ssangyong Motor in 2011, and in the Italian design house Pininfarina S.p.A. in 2015. As a showcase for the industry, India’s Auto Expo took off internationally in 2008, receiving accreditation from the Organisation Internationale des Constructeurs d’Automobiles, a Paris-based trade group. I attended in 2010, and was blown away by the scale and variety on display, from the micro-sized Tata Nano to sleek Audi sedans to Mahindra and Mahindra SUVs to motorcycles of every variety.

By the early 2000s, supplying to global car manufacturers for their local as well as global supply chains had helped India emerge as a high-quality global source for auto components. (Think radiator caps and the like.) The Chennai-based Sundram Fasteners won Japanese quality awards and became the first Indian company to supply General Motors. But India had not yet emerged as a global auto hub in the way that Thailand and South Korea had become, and lagged far behind China. In 2004, India produced a little under 1.18 million cars, while South Korea produced 3.12 million. By the end of 2016, India’s 3.68 million produced had nearly caught up with South Korea’s 3.86 million.

India’s urge to industrialize reflects its ambition to join the front ranks of the world’s powers. But it also reflects a more pressing concern: About 50 percent of India’s employed depend on agriculture for a living, but, according to the World Bank, the country’s small and unproductive farms contribute only 17.4 percent of GDP. With 12 million Indians coming of working age each year, the country needs to ensure there are enough jobs to employ its fast-growing and youthful (by global standards) workforce. This means creating jobs across a wider range of occupations, unshackling manufacturing from artificial constraints that have limited its growth, and also training workers for available opportunities.

India’s automobile industry created 25 million jobs between 2006 and 2016. It accounts for 7 percent of GDP and employs, directly or indirectly, around 19 million people. It has the potential to spur more extensive industrialization, just as it has in every major country that has emerged as an auto powerhouse.

Indeed, the auto industry boasts one of the highest “employment multipliers” of any industry in the U.S., meaning it helps create jobs even beyond the realm of manufacturing. While the structure of the industry in the U.S. differs significantly from that in India, it’s nonetheless useful as a point of comparison. According to the Ann Arbor, Michigan–based nonprofit Center for Automotive Research, each U.S. vehicle-manufacturing job creates nearly seven other jobs across the U.S. economy (ranging from supply-chain manufacturing to dealers to finance to after-market services and others). As the case of Maruti Suzuki illustrates, the involvement of foreign manufacturers has provided technology that can bring Indian parts and vehicles up to global standards, and therefore make them export-ready, another major benefit.

For all these reasons, the auto industry offers a special opportunity for Indian manufacturing, and one shared with other advanced manufacturing industries such as defense, steel, aircraft, and shipbuilding. Defense and shipbuilding have been the targets of recent policy reforms—similarly geared toward spurring growth in large industries that can have powerful knock-on employment effects. And for aircraft, not India’s traditional strength, change may come soon: Lockheed Martin has just proposed to relocate its entire F-16 production line to India, and is now signed up with the Tata group as its partner. (Whether the Indian government selects this aircraft is of course another matter.)

Car manufacturers have bet on the expansion of India’s domestic market. Ford estimated in 2015 that India's compact-car segment, which has accounted for around 45 percent of the passenger-vehicle market, would grow from 1.1 million in 2014 to 1.6 million in 2018.This figure still looks small compared to the size of India’s population, because passenger vehicles do not yet dominate Indian roads. But it also indicates India’s vast room for further growth as its middle class expands and seeks to transport families more safely by moving up to a car from a scooter or motorcycle. In 2016, Americans bought more than 17.5 million passenger vehicles (meaning cars and SUVs); the Chinese bought a little over 28 million.

Of course, not everybody believes that India will be able to replicate the manufacturing success of its East Asian peers. Even assuming that further (and long-overdue) reforms advance expeditiously, India’s manufacturing prospects will intersect with global technological and economic trends. Changes have been unfolding worldwide that raise questions about whether a focus on manufacturing can bring prosperity. Around the world, the rise of automation has raised quality standards and productivity, but at the cost of jobs. The rise of 3-D printing has only just begun, and could affect supply-chain considerations to an as-yet-unknown extent. These two trends alone are just in their infancy.

For the developing world in particular, there are concerns about the prospect of “premature deindustrialization,” to cite the Harvard economist Dani Rodrik’s work. The term describes a downturn in the share of manufacturing in developing countries well before their economies match those of wealthier nations. Rodrik attributes this in part to the effects of trade and globalization—competition from China and other major manufacturers on the global market—which suggests that India (and sub-Saharan Africa for that matter) would have a hard time patterning its growth on China’s labor-intensive strategy.

These developments, while potentially destabilizing, are no reason for Indian officials to stop trying to promote manufacturing. Morgan Stanley’s Ruchir Sharma, reflecting on the implications of technological change, notes in his Rise and Fall of Nations that the robotics revolution “is likely to be gradual enough to complement rather than destroy the human workforce.” He ventures that “new jobs we can’t yet imagine” will help fill the gap. Development institutions like the World Bank, along with management consultancies like McKinsey, continue to see opportunity for India to do more to reform laws and policies that inhibit manufacturing’s growth, whether for the domestic market or for export. In 2016, a World Bank report recommended policy changes to help the countries of South Asia, with India a notable focus, benefit from rising wages in China that result in the relocation of apparel sourcing and the potential for job growth. The same year, McKinsey Global Institute issued a set of recommendations that included “Manufacturing for India, in India” in its top five “opportunities for growth and transformation.”

McKinsey believes that the technological impact on India may take some time to be fully felt. In a recent discussion paper focused on labor, the firm’s researchers cite scenarios in which it could take “two decades or more” for automation to hit more than half of work in some countries, which means India has a window in which to ramp up its manufacturing sector as a job-creating engine before automation becomes more widespread.

India has big ambitions for its place in the global order—and seeks to amp up its economy up to help deliver that transformation. The automobile sector has its own part to play in this vision. India’s “Automotive Mission Plan 2026,” a joint vision of the country’s government and car makers, aims for the auto industry to become one of the world’s top three, contribute 12 percent of India’s GDP, make up 40 percent of India’s manufacturing sector, and generate 65 million jobs by 2026. These goals are part of India’s larger quest to emerge as a major industrial power.

If it succeeds, it will likely secure the place it seeks as a leading global power. Like the Hindustan Motors Ambassador, India’s status as a country perpetually on the brink of arrival—but never quite there—might at last belong to history.

This article has been adapted from Alyssa Ayres's book, Our Time Has Come: How India Is Making Its Place in the World.



