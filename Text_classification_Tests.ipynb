{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_classification_Tests.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CmRk0QP_xIS",
        "colab_type": "text"
      },
      "source": [
        "#### Text Classification Comparisons\n",
        "\n",
        "The objective of this notebook is to compare various text classification models. The goal each model is to classify input texts as one of the ten categories. We choose the model that maximizes the accuracy of classification prediction \n",
        "\n",
        "- Naive Bayesian Classifier\n",
        "\n",
        "- Support Vector Machine (optimized through Stochastic Gradient Descent)\n",
        "\n",
        "- Logistic Regression Classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpaVck-__xIU",
        "colab_type": "code",
        "outputId": "c2ea6c26-db3a-4716-9da8-7fc86361d47b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Packages\n",
        "import pandas as pd\n",
        "import math, scipy, numpy\n",
        "import re\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from numpy import random\n",
        "import time\n",
        "\n",
        "# used in the count of words/\n",
        "import string\n",
        "\n",
        "# natural language tool kit\n",
        "import nltk.data \n",
        "\n",
        "# for tokenizing sentences according by the words\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize # $ pip install nltk\n",
        "from nltk.corpus import stopwords\n",
        "from bs4 import BeautifulSoup\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Metrics and Feature Extraction\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "\n",
        "# Pipeline \n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeYvfoOcsZ2u",
        "colab_type": "code",
        "outputId": "3a55f296-39e5-475e-d57c-d3384c5be931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from sklearn.externals import joblib"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlgRdUiFPi8H",
        "colab_type": "code",
        "outputId": "9c829d1b-d857-4841-c71f-bf65969ad7ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeiM7IZQ_xIe",
        "colab_type": "text"
      },
      "source": [
        "### Loading Data Files\n",
        "\n",
        "Puts essays into data frame with associated labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "631R-g07_xIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "    For the given path, get the List of all files in the directory tree \n",
        "    From: https://thispointer.com/python-how-to-get-list-of-files-in-directory-and-sub-directories/\n",
        "'''\n",
        "def getListOfFiles(dirName):\n",
        "    # create a list of file and sub directories \n",
        "    # names in the given directory \n",
        "    listOfFile = os.listdir(dirName)\n",
        "    allFiles = list()\n",
        "    # Iterate over all the entries\n",
        "    for entry in listOfFile:\n",
        "        # Create full path\n",
        "        fullPath = os.path.join(dirName, entry)\n",
        "        # If entry is a directory then get the list of files in this directory \n",
        "        if os.path.isdir(fullPath):\n",
        "            allFiles = allFiles + getListOfFiles(fullPath)\n",
        "        else:\n",
        "            allFiles.append(fullPath)\n",
        "                \n",
        "    return allFiles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWRqbsOHHMy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags = ['business',\n",
        " 'education',\n",
        " 'entertainment',\n",
        " 'health',\n",
        " 'ideas',\n",
        " 'international',\n",
        " 'politics',\n",
        " 'science',\n",
        " 'technology']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GloXR1iv_xIm",
        "colab_type": "code",
        "outputId": "50c8fae1-ca47-4a81-84df-2a8e274adb10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "start_time = time.time()\n",
        "# Creating list of essays and associated labels for Atlantic essays\n",
        "essay = [] \n",
        "label1 = [] # word label\n",
        "for k in range(len(tags)):\n",
        "  #name of directory\n",
        "  \n",
        "    dirname = '/content/drive/My Drive/writrly_proj_files/Atlantic_essays/'+tags[k] #gdrive implementation\n",
        "    #dirname = './Atlantic_subj_essays/'+tags[k]\n",
        "\n",
        "    # getting raw list of files\n",
        "    raw_file_list = getListOfFiles(dirname)\n",
        "\n",
        "    # eliminating the .DS Store files\n",
        "    raw_file_list = [x for x in raw_file_list if not ('.DS_Store' in x)];\n",
        "    \n",
        "    for elem in raw_file_list:   \n",
        "\n",
        "        with open(elem, 'r') as file:\n",
        "            data = file.read().replace('\\n\\n', '   ')\n",
        "            essay.append(data)\n",
        "            label1.append(tags[k])\n",
        "    \n",
        "    \n",
        "# Creating list of short stories \n",
        "tag_short = 'short-story'\n",
        "  \n",
        "dirname = '/content/drive/My Drive/writrly_proj_files/short_stories/' #gdrive implementation\n",
        "#dirname = './Atlantic_subj_essays/'+tags[k]\n",
        "\n",
        "# getting raw list of files\n",
        "raw_file_list = getListOfFiles(dirname)\n",
        "\n",
        "# eliminating the .DS Store files\n",
        "raw_file_list = [x for x in raw_file_list if not ('.DS_Store' in x)];\n",
        "\n",
        "for elem in raw_file_list:   \n",
        "\n",
        "  with open(elem, 'r') as file:\n",
        "      data = file.read().replace('\\n\\n', '   ')\n",
        "      essay.append(data)\n",
        "      label1.append(tag_short)\n",
        "            \n",
        "print('Run Time:', str(time.time()-start_time), ' sec')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run Time: 2.501847982406616  sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_133sNfDMdC",
        "colab_type": "code",
        "outputId": "06150509-e9af-4542-c551-587eda6d453e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Checking length\n",
        "len(essay)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2174"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lh1A28SKbpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## cleaning text\n",
        "\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zbJOy5qK9ZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## cleaning essay text\n",
        "essay = [clean_text(elem) for elem in essay]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOca5w49_xIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a dataframe using essays and labels\n",
        "masterDF = pd.DataFrame()\n",
        "masterDF['essay'] = essay\n",
        "masterDF['topic'] = label1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBKPNl0zbH1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save data frame to csv [already saved]\n",
        "# masterDF.to_csv('master_df.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzaJwfrg_xIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split data into training and test sets \n",
        "train_x, test_x, train_y, test_y = train_test_split(masterDF['essay'], masterDF['topic'], random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv-Ckdrp_xIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classes for classifier keyed on index\n",
        "reverse_encode = ['business',\n",
        " 'education',\n",
        " 'entertainment',\n",
        " 'health',\n",
        " 'ideas',\n",
        " 'international',\n",
        " 'politics',\n",
        " 'science',\n",
        " 'short-story',\n",
        " 'technology']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fku7V2rqNcBG",
        "colab_type": "text"
      },
      "source": [
        "### Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuOg8f7iNy7J",
        "colab_type": "code",
        "outputId": "8f509b5e-9a6f-4803-b6df-0783dcd01ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# Naive bayesian classifier pipeline\n",
        "nb = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ])\n",
        "nb.fit(train_x, train_y)\n",
        "\n",
        "# %%time\n",
        "pred_y = nb.predict(test_x)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(pred_y, test_y))\n",
        "print(classification_report(test_y, pred_y,target_names=reverse_encode))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6525735294117647\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.72      0.49      0.58        47\n",
            "    education       0.57      0.95      0.72        62\n",
            "entertainment       0.96      0.73      0.83        62\n",
            "       health       1.00      0.21      0.35        62\n",
            "        ideas       0.30      0.56      0.40        57\n",
            "international       1.00      0.03      0.07        29\n",
            "     politics       0.61      0.87      0.72        55\n",
            "      science       0.72      0.84      0.78        56\n",
            "  short-story       1.00      0.96      0.98        47\n",
            "   technology       0.78      0.63      0.69        67\n",
            "\n",
            "     accuracy                           0.65       544\n",
            "    macro avg       0.77      0.63      0.61       544\n",
            " weighted avg       0.75      0.65      0.63       544\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOy3oCCLNyqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-7veUsANbez",
        "colab_type": "text"
      },
      "source": [
        "### Linear Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i24C1j0SNyZo",
        "colab_type": "code",
        "outputId": "16baba34-0f95-4180-825e-2b18ff64ab4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# Support vector machine pipeline\n",
        "sgd = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
        "               ])\n",
        "sgd.fit(train_x, train_y)\n",
        "pred_y = sgd.predict(test_x)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(pred_y, test_y))\n",
        "print(classification_report(test_y, pred_y,target_names=reverse_encode))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.7996323529411765\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.72      0.72      0.72        47\n",
            "    education       0.87      0.85      0.86        62\n",
            "entertainment       0.78      0.90      0.84        62\n",
            "       health       0.85      0.66      0.75        62\n",
            "        ideas       0.73      0.42      0.53        57\n",
            "international       0.83      0.86      0.85        29\n",
            "     politics       0.75      0.91      0.82        55\n",
            "      science       0.77      0.96      0.86        56\n",
            "  short-story       0.90      1.00      0.95        47\n",
            "   technology       0.80      0.76      0.78        67\n",
            "\n",
            "     accuracy                           0.80       544\n",
            "    macro avg       0.80      0.81      0.80       544\n",
            " weighted avg       0.80      0.80      0.79       544\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWYLTSEgNbvF",
        "colab_type": "text"
      },
      "source": [
        "### Multiclass Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTNjDWHnQT8r",
        "colab_type": "code",
        "outputId": "458d3f50-6810-4cfd-e534-808d7ac899b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# Multiclass logistic regression pipeline\n",
        "logreg = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(solver = 'liblinear', \n",
        "                                           multi_class = 'ovr' ,\n",
        "                                           n_jobs=1, C=1e5)),\n",
        "               ])\n",
        "logreg.fit(train_x, train_y)\n",
        "pred_y = logreg.predict(test_x)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(pred_y, test_y))\n",
        "print(classification_report(test_y, pred_y,target_names=reverse_encode))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.8308823529411765\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.70      0.79      0.74        47\n",
            "    education       0.93      0.82      0.87        62\n",
            "entertainment       0.82      0.90      0.86        62\n",
            "       health       0.89      0.76      0.82        62\n",
            "        ideas       0.71      0.60      0.65        57\n",
            "international       0.81      0.86      0.83        29\n",
            "     politics       0.84      0.89      0.87        55\n",
            "      science       0.84      0.95      0.89        56\n",
            "  short-story       0.94      1.00      0.97        47\n",
            "   technology       0.82      0.79      0.80        67\n",
            "\n",
            "     accuracy                           0.83       544\n",
            "    macro avg       0.83      0.84      0.83       544\n",
            " weighted avg       0.83      0.83      0.83       544\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7eBm9KAQTqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}